{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef50705",
   "metadata": {},
   "source": [
    "# Import and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b3ec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a505b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 22:51:21.527973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# standard numerical library imports\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import os\n",
    "\n",
    "from pfn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45667e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "train, val, test = 0.6, 0.3, 0.1\n",
    "Phi_sizes, F_sizes = (256, 256, 256), (256, 256, 256)\n",
    "num_epoch = 500\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505a2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_dir = \"/global/home/users/yifengh3/VAE/vec_data/recon_data\"\n",
    "raw_b_signals = np.load(os.path.join(data_base_dir, \"reconstructed_B_signal_vector.npz\")) \n",
    "raw_hv_signals = np.load(os.path.join(data_base_dir, \"reconstructed_hv_vector.npz\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3d3b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'recon', 'beta']\n"
     ]
    }
   ],
   "source": [
    "print(list(raw_b_signals.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5aa5d4",
   "metadata": {},
   "source": [
    "# Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25276321",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal1 = raw_b_signals[\"data\"]\n",
    "signal2 = raw_hv_signals[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b559b182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal_1 data shape: (163600, 50, 3)\n",
      "signal_2 data shape: (155841, 50, 3)\n",
      "shape of X: (319441, 150)\n",
      "shape of Y: (319441,)\n",
      "Weight for background: 0.98\n",
      "Weight for signal: 1.02\n",
      "Finished preprocessing\n",
      "shape of X: (319441, 50, 3)\n",
      "shape of Y: (319441,)\n",
      "Model summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 22:51:24.137041: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-09-26 22:51:24.138209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-09-26 22:51:24.161532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-09-26 22:51:24.161555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-26 22:51:24.162837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-09-26 22:51:24.162866: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-09-26 22:51:24.164374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-09-26 22:51:24.164603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-09-26 22:51:24.165884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-09-26 22:51:24.166684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-09-26 22:51:24.169887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-09-26 22:51:24.172506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-09-26 22:51:24.172918: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-26 22:51:24.174809: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-09-26 22:51:24.176111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-09-26 22:51:24.176133: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-26 22:51:24.176149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-09-26 22:51:24.176159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-09-26 22:51:24.176170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-09-26 22:51:24.176180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-09-26 22:51:24.176190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-09-26 22:51:24.176200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-09-26 22:51:24.176210: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-09-26 22:51:24.178632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-09-26 22:51:24.178680: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-26 22:51:24.706580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-09-26 22:51:24.706627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-09-26 22:51:24.706637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-09-26 22:51:24.710592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22475 MB memory) -> physical GPU (device: 0, name: Quadro RTX 6000, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 22:51:25.139221: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-09-26 22:51:25.139711: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2994530000 Hz\n",
      "2022-09-26 22:51:25.545341: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 - 3s - loss: 7.7106 - acc: 0.8413 - val_loss: 0.3550 - val_acc: 0.9161\n",
      "Epoch 2/200\n",
      "192/192 - 2s - loss: 0.2381 - acc: 0.9267 - val_loss: 0.2095 - val_acc: 0.9270\n",
      "Epoch 3/200\n",
      "192/192 - 2s - loss: 0.2452 - acc: 0.9257 - val_loss: 0.1226 - val_acc: 0.9603\n",
      "Epoch 4/200\n",
      "192/192 - 2s - loss: 0.1323 - acc: 0.9525 - val_loss: 0.1072 - val_acc: 0.9587\n",
      "Epoch 5/200\n",
      "192/192 - 2s - loss: 0.1197 - acc: 0.9581 - val_loss: 0.0906 - val_acc: 0.9680\n",
      "Epoch 6/200\n",
      "192/192 - 2s - loss: 0.1388 - acc: 0.9544 - val_loss: 0.0830 - val_acc: 0.9760\n",
      "Epoch 7/200\n",
      "192/192 - 2s - loss: 0.0982 - acc: 0.9664 - val_loss: 0.0717 - val_acc: 0.9783\n",
      "Epoch 8/200\n",
      "192/192 - 2s - loss: 0.0931 - acc: 0.9693 - val_loss: 0.0626 - val_acc: 0.9822\n",
      "Epoch 9/200\n",
      "192/192 - 2s - loss: 0.0805 - acc: 0.9736 - val_loss: 0.0524 - val_acc: 0.9838\n",
      "Epoch 10/200\n",
      "192/192 - 2s - loss: 0.0981 - acc: 0.9682 - val_loss: 0.0684 - val_acc: 0.9773\n",
      "Epoch 11/200\n",
      "192/192 - 2s - loss: 0.0825 - acc: 0.9736 - val_loss: 0.0549 - val_acc: 0.9819\n",
      "Epoch 12/200\n",
      "192/192 - 2s - loss: 0.0668 - acc: 0.9794 - val_loss: 0.0662 - val_acc: 0.9785\n",
      "Epoch 13/200\n",
      "192/192 - 2s - loss: 0.0707 - acc: 0.9771 - val_loss: 0.0473 - val_acc: 0.9860\n",
      "Epoch 14/200\n",
      "192/192 - 2s - loss: 0.0448 - acc: 0.9871 - val_loss: 0.0319 - val_acc: 0.9934\n",
      "Epoch 15/200\n",
      "192/192 - 2s - loss: 0.0811 - acc: 0.9752 - val_loss: 0.0496 - val_acc: 0.9893\n",
      "Epoch 16/200\n",
      "192/192 - 2s - loss: 0.0365 - acc: 0.9908 - val_loss: 0.0278 - val_acc: 0.9946\n",
      "Epoch 17/200\n",
      "192/192 - 2s - loss: 0.1097 - acc: 0.9665 - val_loss: 0.0505 - val_acc: 0.9904\n",
      "Epoch 18/200\n",
      "192/192 - 2s - loss: 0.0609 - acc: 0.9831 - val_loss: 0.0732 - val_acc: 0.9760\n",
      "Epoch 19/200\n",
      "192/192 - 2s - loss: 0.0383 - acc: 0.9897 - val_loss: 0.0276 - val_acc: 0.9919\n",
      "Epoch 20/200\n",
      "192/192 - 2s - loss: 0.0447 - acc: 0.9868 - val_loss: 0.0351 - val_acc: 0.9944\n",
      "Epoch 21/200\n",
      "192/192 - 2s - loss: 0.0280 - acc: 0.9932 - val_loss: 0.0233 - val_acc: 0.9937\n",
      "Epoch 22/200\n",
      "192/192 - 2s - loss: 1.2542 - acc: 0.9211 - val_loss: 0.1472 - val_acc: 0.9473\n",
      "Epoch 23/200\n",
      "192/192 - 2s - loss: 0.1163 - acc: 0.9591 - val_loss: 0.0968 - val_acc: 0.9672\n",
      "Epoch 24/200\n",
      "192/192 - 2s - loss: 0.0920 - acc: 0.9697 - val_loss: 0.0735 - val_acc: 0.9767\n",
      "Epoch 25/200\n",
      "192/192 - 2s - loss: 0.0725 - acc: 0.9774 - val_loss: 0.0657 - val_acc: 0.9791\n",
      "Epoch 26/200\n",
      "192/192 - 2s - loss: 0.0546 - acc: 0.9847 - val_loss: 0.0432 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.000630957374449059.\n",
      "Epoch 27/200\n",
      "192/192 - 2s - loss: 0.0403 - acc: 0.9903 - val_loss: 0.0344 - val_acc: 0.9904\n",
      "Epoch 28/200\n",
      "192/192 - 2s - loss: 0.0352 - acc: 0.9918 - val_loss: 0.0331 - val_acc: 0.9915\n",
      "Epoch 29/200\n",
      "192/192 - 2s - loss: 0.0380 - acc: 0.9902 - val_loss: 0.0289 - val_acc: 0.9943\n",
      "Epoch 30/200\n",
      "192/192 - 2s - loss: 0.0337 - acc: 0.9916 - val_loss: 0.0295 - val_acc: 0.9954\n",
      "Epoch 31/200\n",
      "192/192 - 2s - loss: 0.0283 - acc: 0.9934 - val_loss: 0.0282 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0003981071838171537.\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "pfn_original, hist1, original_training_data = train_pfn(signal1, signal2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a351597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PFN AUC: 0.9983008669869332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/yifengh3/VAE/EMD_VAE/PFN/pfn_utils.py:147: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  plt.plot(pfn_tp, 1/pfn_fp, '-', color='black', label='PFN')\n",
      "/global/home/users/yifengh3/VAE/EMD_VAE/PFN/pfn_utils.py:148: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  plt.plot(pfn_tp, 1/pfn_tp, '-', color='red', label='random')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis(pfn_original,original_training_data[1][2], original_training_data[1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e141e",
   "metadata": {},
   "source": [
    "# Test of recon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87bf1afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_betas = raw_b_signals[\"beta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a706d425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.1428572 -1.8571428 -2.5714285 -3.2857144]\n"
     ]
    }
   ],
   "source": [
    "beta_idx = np.logical_and(log_betas<-1, log_betas>-4)\n",
    "new_betas = log_betas[beta_idx]\n",
    "new_betas = new_betas[::5]\n",
    "print(new_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca4d8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_1_recons = raw_b_signals[\"recon\"][beta_idx][::5]\n",
    "signal_2_recons = raw_hv_signals[\"recon\"][beta_idx][::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307d1349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal_1 data shape: (163600, 50, 3)\n",
      "signal_2 data shape: (155841, 50, 3)\n",
      "shape of X: (319441, 150)\n",
      "shape of Y: (319441,)\n",
      "Weight for background: 0.98\n",
      "Weight for signal: 1.02\n",
      "Finished preprocessing\n",
      "shape of X: (319441, 50, 3)\n",
      "shape of Y: (319441,)\n",
      "Model summary:\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "192/192 - 2s - loss: 12.0194 - acc: 0.8715 - val_loss: 0.6316 - val_acc: 0.8793\n",
      "Epoch 2/200\n",
      "192/192 - 2s - loss: 0.4314 - acc: 0.9117 - val_loss: 0.2657 - val_acc: 0.9150\n",
      "Epoch 3/200\n",
      "192/192 - 2s - loss: 0.2650 - acc: 0.9239 - val_loss: 0.1776 - val_acc: 0.9406\n",
      "Epoch 4/200\n",
      "192/192 - 2s - loss: 0.2020 - acc: 0.9328 - val_loss: 0.1359 - val_acc: 0.9469\n",
      "Epoch 5/200\n",
      "192/192 - 2s - loss: 0.1561 - acc: 0.9419 - val_loss: 0.1265 - val_acc: 0.9540\n",
      "Epoch 6/200\n",
      "192/192 - 2s - loss: 0.1505 - acc: 0.9432 - val_loss: 0.1360 - val_acc: 0.9474\n",
      "Epoch 7/200\n",
      "192/192 - 2s - loss: 0.1424 - acc: 0.9459 - val_loss: 0.1494 - val_acc: 0.9417\n",
      "Epoch 8/200\n",
      "192/192 - 2s - loss: 0.1381 - acc: 0.9480 - val_loss: 0.1150 - val_acc: 0.9542\n",
      "Epoch 9/200\n",
      "192/192 - 2s - loss: 0.1290 - acc: 0.9503 - val_loss: 0.1219 - val_acc: 0.9497\n",
      "Epoch 10/200\n",
      "192/192 - 2s - loss: 0.1428 - acc: 0.9472 - val_loss: 0.2128 - val_acc: 0.9388\n",
      "Epoch 11/200\n",
      "192/192 - 2s - loss: 0.1853 - acc: 0.9383 - val_loss: 0.1215 - val_acc: 0.9544\n",
      "Epoch 12/200\n",
      "192/192 - 2s - loss: 0.1222 - acc: 0.9543 - val_loss: 0.1198 - val_acc: 0.9567\n",
      "Epoch 13/200\n",
      "192/192 - 2s - loss: 0.1279 - acc: 0.9514 - val_loss: 0.1204 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.000630957374449059.\n",
      "Epoch 14/200\n",
      "192/192 - 2s - loss: 0.1059 - acc: 0.9607 - val_loss: 0.0994 - val_acc: 0.9629\n",
      "Epoch 15/200\n",
      "192/192 - 2s - loss: 0.1084 - acc: 0.9586 - val_loss: 0.1057 - val_acc: 0.9599\n",
      "Epoch 16/200\n",
      "192/192 - 2s - loss: 0.1071 - acc: 0.9593 - val_loss: 0.0957 - val_acc: 0.9675\n",
      "Epoch 17/200\n",
      "192/192 - 2s - loss: 0.0990 - acc: 0.9627 - val_loss: 0.1015 - val_acc: 0.9580\n",
      "Epoch 18/200\n",
      "192/192 - 2s - loss: 0.0984 - acc: 0.9631 - val_loss: 0.1183 - val_acc: 0.9543\n",
      "Epoch 19/200\n",
      "192/192 - 2s - loss: 0.1213 - acc: 0.9553 - val_loss: 0.2163 - val_acc: 0.9160\n",
      "Epoch 20/200\n",
      "192/192 - 2s - loss: 0.1092 - acc: 0.9590 - val_loss: 0.1031 - val_acc: 0.9633\n",
      "Epoch 21/200\n",
      "192/192 - 2s - loss: 0.1052 - acc: 0.9609 - val_loss: 0.0838 - val_acc: 0.9717\n",
      "Epoch 22/200\n",
      "192/192 - 2s - loss: 0.0949 - acc: 0.9647 - val_loss: 0.0919 - val_acc: 0.9669\n",
      "Epoch 23/200\n",
      "192/192 - 2s - loss: 0.0954 - acc: 0.9644 - val_loss: 0.1175 - val_acc: 0.9502\n",
      "Epoch 24/200\n",
      "192/192 - 2s - loss: 0.1205 - acc: 0.9565 - val_loss: 0.1896 - val_acc: 0.9377\n",
      "Epoch 25/200\n",
      "192/192 - 2s - loss: 0.0994 - acc: 0.9634 - val_loss: 0.1018 - val_acc: 0.9631\n",
      "Epoch 26/200\n",
      "192/192 - 2s - loss: 0.0932 - acc: 0.9655 - val_loss: 0.0883 - val_acc: 0.9699\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0003981071838171537.\n",
      "Epoch 27/200\n",
      "192/192 - 2s - loss: 0.0745 - acc: 0.9753 - val_loss: 0.0742 - val_acc: 0.9737\n",
      "Epoch 28/200\n",
      "192/192 - 2s - loss: 0.0748 - acc: 0.9743 - val_loss: 0.0703 - val_acc: 0.9768\n",
      "Epoch 29/200\n",
      "192/192 - 2s - loss: 0.0718 - acc: 0.9762 - val_loss: 0.0739 - val_acc: 0.9752\n",
      "Epoch 30/200\n",
      "192/192 - 2s - loss: 0.0747 - acc: 0.9745 - val_loss: 0.0922 - val_acc: 0.9624\n",
      "Epoch 31/200\n",
      "192/192 - 2s - loss: 0.1021 - acc: 0.9633 - val_loss: 0.0897 - val_acc: 0.9635\n",
      "Epoch 32/200\n",
      "192/192 - 2s - loss: 0.0765 - acc: 0.9731 - val_loss: 0.0647 - val_acc: 0.9810\n",
      "Epoch 33/200\n",
      "192/192 - 2s - loss: 0.0741 - acc: 0.9748 - val_loss: 0.0693 - val_acc: 0.9730\n",
      "Epoch 34/200\n",
      "192/192 - 2s - loss: 0.0729 - acc: 0.9747 - val_loss: 0.0732 - val_acc: 0.9727\n",
      "Epoch 35/200\n",
      "192/192 - 2s - loss: 0.0819 - acc: 0.9714 - val_loss: 0.0866 - val_acc: 0.9646\n",
      "Epoch 36/200\n",
      "192/192 - 2s - loss: 0.0775 - acc: 0.9727 - val_loss: 0.0657 - val_acc: 0.9794\n",
      "Epoch 37/200\n",
      "192/192 - 2s - loss: 0.0727 - acc: 0.9752 - val_loss: 0.0670 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002511886574257803.\n",
      "Epoch 38/200\n",
      "192/192 - 2s - loss: 0.0599 - acc: 0.9815 - val_loss: 0.0559 - val_acc: 0.9839\n",
      "Epoch 39/200\n",
      "192/192 - 2s - loss: 0.0586 - acc: 0.9820 - val_loss: 0.0538 - val_acc: 0.9844\n",
      "Epoch 40/200\n",
      "192/192 - 2s - loss: 0.0572 - acc: 0.9825 - val_loss: 0.0612 - val_acc: 0.9798\n",
      "Epoch 41/200\n",
      "192/192 - 2s - loss: 0.0583 - acc: 0.9821 - val_loss: 0.0611 - val_acc: 0.9819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200\n",
      "192/192 - 2s - loss: 0.0571 - acc: 0.9825 - val_loss: 0.0565 - val_acc: 0.9839\n",
      "Epoch 43/200\n",
      "192/192 - 2s - loss: 0.0809 - acc: 0.9734 - val_loss: 0.0616 - val_acc: 0.9827\n",
      "Epoch 44/200\n",
      "192/192 - 2s - loss: 0.0656 - acc: 0.9785 - val_loss: 0.0796 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.00015848933651346973.\n",
      "Epoch 45/200\n",
      "192/192 - 2s - loss: 0.0546 - acc: 0.9843 - val_loss: 0.0611 - val_acc: 0.9781\n",
      "Epoch 46/200\n",
      "192/192 - 2s - loss: 0.0527 - acc: 0.9852 - val_loss: 0.0493 - val_acc: 0.9873\n",
      "Epoch 47/200\n",
      "192/192 - 2s - loss: 0.0535 - acc: 0.9845 - val_loss: 0.0528 - val_acc: 0.9875\n",
      "Epoch 48/200\n",
      "192/192 - 2s - loss: 0.0503 - acc: 0.9856 - val_loss: 0.0626 - val_acc: 0.9797\n",
      "Epoch 49/200\n",
      "192/192 - 2s - loss: 0.0500 - acc: 0.9862 - val_loss: 0.0565 - val_acc: 0.9836\n",
      "Epoch 50/200\n",
      "192/192 - 2s - loss: 0.0519 - acc: 0.9845 - val_loss: 0.0512 - val_acc: 0.9841\n",
      "Epoch 51/200\n",
      "192/192 - 2s - loss: 0.0501 - acc: 0.9856 - val_loss: 0.0469 - val_acc: 0.9858\n",
      "Epoch 52/200\n",
      "192/192 - 2s - loss: 0.0481 - acc: 0.9866 - val_loss: 0.0456 - val_acc: 0.9881\n",
      "Epoch 53/200\n",
      "192/192 - 2s - loss: 0.0511 - acc: 0.9851 - val_loss: 0.0528 - val_acc: 0.9860\n",
      "Epoch 54/200\n",
      "192/192 - 2s - loss: 0.0464 - acc: 0.9868 - val_loss: 0.0449 - val_acc: 0.9890\n",
      "Epoch 55/200\n",
      "192/192 - 2s - loss: 0.0521 - acc: 0.9847 - val_loss: 0.0449 - val_acc: 0.9904\n",
      "Epoch 56/200\n",
      "192/192 - 2s - loss: 0.0441 - acc: 0.9880 - val_loss: 0.0464 - val_acc: 0.9870\n",
      "Epoch 57/200\n",
      "192/192 - 2s - loss: 0.0599 - acc: 0.9821 - val_loss: 0.0453 - val_acc: 0.9877\n",
      "Epoch 58/200\n",
      "192/192 - 2s - loss: 0.0439 - acc: 0.9882 - val_loss: 0.0469 - val_acc: 0.9868\n",
      "Epoch 59/200\n",
      "192/192 - 2s - loss: 0.0463 - acc: 0.9872 - val_loss: 0.0498 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.00010000000838432616.\n",
      "Epoch 60/200\n",
      "192/192 - 2s - loss: 0.0386 - acc: 0.9900 - val_loss: 0.0420 - val_acc: 0.9869\n",
      "Epoch 61/200\n",
      "192/192 - 2s - loss: 0.0395 - acc: 0.9896 - val_loss: 0.0368 - val_acc: 0.9906\n",
      "Epoch 62/200\n",
      "192/192 - 2s - loss: 0.0374 - acc: 0.9905 - val_loss: 0.0366 - val_acc: 0.9906\n",
      "Epoch 63/200\n",
      "192/192 - 2s - loss: 0.0406 - acc: 0.9889 - val_loss: 0.0386 - val_acc: 0.9881\n",
      "Epoch 64/200\n",
      "192/192 - 2s - loss: 0.0396 - acc: 0.9897 - val_loss: 0.0372 - val_acc: 0.9894\n",
      "Epoch 65/200\n",
      "192/192 - 2s - loss: 0.0360 - acc: 0.9907 - val_loss: 0.0365 - val_acc: 0.9904\n",
      "Epoch 66/200\n",
      "192/192 - 2s - loss: 0.0367 - acc: 0.9906 - val_loss: 0.0390 - val_acc: 0.9880\n",
      "Epoch 67/200\n",
      "192/192 - 2s - loss: 0.0362 - acc: 0.9907 - val_loss: 0.0390 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 6.30957374449059e-05.\n",
      "Epoch 68/200\n",
      "192/192 - 2s - loss: 0.0331 - acc: 0.9918 - val_loss: 0.0375 - val_acc: 0.9880\n",
      "Epoch 69/200\n",
      "192/192 - 2s - loss: 0.0332 - acc: 0.9918 - val_loss: 0.0357 - val_acc: 0.9913\n",
      "Epoch 70/200\n",
      "192/192 - 2s - loss: 0.0342 - acc: 0.9914 - val_loss: 0.0326 - val_acc: 0.9910\n",
      "Epoch 71/200\n",
      "192/192 - 2s - loss: 0.0317 - acc: 0.9921 - val_loss: 0.0329 - val_acc: 0.9919\n",
      "Epoch 72/200\n",
      "192/192 - 2s - loss: 0.0320 - acc: 0.9920 - val_loss: 0.0336 - val_acc: 0.9928\n",
      "Epoch 73/200\n",
      "192/192 - 2s - loss: 0.0325 - acc: 0.9919 - val_loss: 0.0358 - val_acc: 0.9926\n",
      "Epoch 74/200\n",
      "192/192 - 2s - loss: 0.0330 - acc: 0.9917 - val_loss: 0.0346 - val_acc: 0.9900\n",
      "Epoch 75/200\n",
      "192/192 - 2s - loss: 0.0322 - acc: 0.9920 - val_loss: 0.0495 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 3.981071838171537e-05.\n",
      "Epoch 76/200\n",
      "192/192 - 2s - loss: 0.0294 - acc: 0.9928 - val_loss: 0.0336 - val_acc: 0.9900\n",
      "Epoch 77/200\n",
      "192/192 - 2s - loss: 0.0299 - acc: 0.9927 - val_loss: 0.0341 - val_acc: 0.9901\n",
      "Epoch 78/200\n",
      "192/192 - 2s - loss: 0.0287 - acc: 0.9929 - val_loss: 0.0326 - val_acc: 0.9919\n",
      "Epoch 79/200\n",
      "192/192 - 2s - loss: 0.0291 - acc: 0.9929 - val_loss: 0.0297 - val_acc: 0.9930\n",
      "Epoch 80/200\n",
      "192/192 - 2s - loss: 0.0285 - acc: 0.9931 - val_loss: 0.0291 - val_acc: 0.9925\n",
      "Epoch 81/200\n",
      "192/192 - 2s - loss: 0.0288 - acc: 0.9929 - val_loss: 0.0328 - val_acc: 0.9900\n",
      "Epoch 82/200\n",
      "192/192 - 2s - loss: 0.0292 - acc: 0.9928 - val_loss: 0.0292 - val_acc: 0.9918\n",
      "Epoch 83/200\n",
      "192/192 - 2s - loss: 0.0294 - acc: 0.9928 - val_loss: 0.0304 - val_acc: 0.9940\n",
      "Epoch 84/200\n",
      "192/192 - 2s - loss: 0.0279 - acc: 0.9931 - val_loss: 0.0293 - val_acc: 0.9936\n",
      "Epoch 85/200\n",
      "192/192 - 2s - loss: 0.0271 - acc: 0.9935 - val_loss: 0.0300 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 2.5118865283496142e-05.\n",
      "Epoch 86/200\n",
      "192/192 - 2s - loss: 0.0267 - acc: 0.9935 - val_loss: 0.0296 - val_acc: 0.9938\n",
      "Epoch 87/200\n",
      "192/192 - 2s - loss: 0.0265 - acc: 0.9936 - val_loss: 0.0277 - val_acc: 0.9921\n",
      "Epoch 88/200\n",
      "192/192 - 2s - loss: 0.0261 - acc: 0.9937 - val_loss: 0.0280 - val_acc: 0.9932\n",
      "Epoch 89/200\n",
      "192/192 - 2s - loss: 0.0263 - acc: 0.9935 - val_loss: 0.0282 - val_acc: 0.9928\n",
      "Epoch 90/200\n",
      "192/192 - 2s - loss: 0.0264 - acc: 0.9935 - val_loss: 0.0276 - val_acc: 0.9935\n",
      "Epoch 91/200\n",
      "192/192 - 2s - loss: 0.0262 - acc: 0.9936 - val_loss: 0.0278 - val_acc: 0.9935\n",
      "Epoch 92/200\n",
      "192/192 - 2s - loss: 0.0256 - acc: 0.9937 - val_loss: 0.0289 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1.5848932274101303e-05.\n",
      "Epoch 93/200\n",
      "192/192 - 2s - loss: 0.0250 - acc: 0.9939 - val_loss: 0.0274 - val_acc: 0.9939\n",
      "Epoch 94/200\n",
      "192/192 - 2s - loss: 0.0247 - acc: 0.9940 - val_loss: 0.0270 - val_acc: 0.9929\n",
      "Epoch 95/200\n",
      "192/192 - 2s - loss: 0.0247 - acc: 0.9940 - val_loss: 0.0284 - val_acc: 0.9940\n",
      "Epoch 96/200\n",
      "192/192 - 2s - loss: 0.0248 - acc: 0.9940 - val_loss: 0.0269 - val_acc: 0.9924\n",
      "Epoch 97/200\n",
      "192/192 - 2s - loss: 0.0247 - acc: 0.9940 - val_loss: 0.0267 - val_acc: 0.9929\n",
      "Epoch 98/200\n",
      "192/192 - 2s - loss: 0.0245 - acc: 0.9940 - val_loss: 0.0275 - val_acc: 0.9921\n",
      "Epoch 99/200\n",
      "192/192 - 2s - loss: 0.0243 - acc: 0.9940 - val_loss: 0.0264 - val_acc: 0.9936\n",
      "Epoch 100/200\n",
      "192/192 - 2s - loss: 0.0241 - acc: 0.9941 - val_loss: 0.0262 - val_acc: 0.9935\n",
      "Epoch 101/200\n",
      "192/192 - 2s - loss: 0.0240 - acc: 0.9942 - val_loss: 0.0272 - val_acc: 0.9923\n",
      "Epoch 102/200\n",
      "192/192 - 2s - loss: 0.0245 - acc: 0.9941 - val_loss: 0.0270 - val_acc: 0.9927\n",
      "Epoch 103/200\n",
      "192/192 - 2s - loss: 0.0244 - acc: 0.9940 - val_loss: 0.0256 - val_acc: 0.9934\n",
      "Epoch 104/200\n",
      "192/192 - 2s - loss: 0.0237 - acc: 0.9943 - val_loss: 0.0269 - val_acc: 0.9939\n",
      "Epoch 105/200\n",
      "192/192 - 2s - loss: 0.0241 - acc: 0.9942 - val_loss: 0.0259 - val_acc: 0.9941\n",
      "Epoch 106/200\n",
      "192/192 - 2s - loss: 0.0236 - acc: 0.9942 - val_loss: 0.0254 - val_acc: 0.9933\n",
      "Epoch 107/200\n",
      "192/192 - 2s - loss: 0.0237 - acc: 0.9942 - val_loss: 0.0276 - val_acc: 0.9948\n",
      "Epoch 108/200\n",
      "192/192 - 2s - loss: 0.0239 - acc: 0.9941 - val_loss: 0.0258 - val_acc: 0.9929\n",
      "Epoch 109/200\n",
      "192/192 - 2s - loss: 0.0234 - acc: 0.9943 - val_loss: 0.0258 - val_acc: 0.9934\n",
      "Epoch 110/200\n",
      "192/192 - 2s - loss: 0.0235 - acc: 0.9943 - val_loss: 0.0261 - val_acc: 0.9933\n",
      "Epoch 111/200\n",
      "192/192 - 2s - loss: 0.0232 - acc: 0.9943 - val_loss: 0.0259 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 1.0000000608891671e-05.\n",
      "Epoch 112/200\n",
      "192/192 - 2s - loss: 0.0228 - acc: 0.9944 - val_loss: 0.0247 - val_acc: 0.9934\n",
      "Epoch 113/200\n",
      "192/192 - 2s - loss: 0.0228 - acc: 0.9945 - val_loss: 0.0252 - val_acc: 0.9939\n",
      "Epoch 114/200\n",
      "192/192 - 2s - loss: 0.0226 - acc: 0.9945 - val_loss: 0.0263 - val_acc: 0.9932\n",
      "Epoch 115/200\n",
      "192/192 - 2s - loss: 0.0228 - acc: 0.9945 - val_loss: 0.0257 - val_acc: 0.9925\n",
      "Epoch 116/200\n",
      "192/192 - 2s - loss: 0.0226 - acc: 0.9945 - val_loss: 0.0253 - val_acc: 0.9935\n",
      "Epoch 117/200\n",
      "192/192 - 2s - loss: 0.0224 - acc: 0.9945 - val_loss: 0.0245 - val_acc: 0.9940\n",
      "Epoch 118/200\n",
      "192/192 - 2s - loss: 0.0223 - acc: 0.9946 - val_loss: 0.0255 - val_acc: 0.9945\n",
      "Epoch 119/200\n",
      "192/192 - 2s - loss: 0.0224 - acc: 0.9946 - val_loss: 0.0246 - val_acc: 0.9942\n",
      "Epoch 120/200\n",
      "192/192 - 2s - loss: 0.0225 - acc: 0.9945 - val_loss: 0.0244 - val_acc: 0.9943\n",
      "Epoch 121/200\n",
      "192/192 - 2s - loss: 0.0223 - acc: 0.9946 - val_loss: 0.0244 - val_acc: 0.9935\n",
      "Epoch 122/200\n",
      "192/192 - 2s - loss: 0.0223 - acc: 0.9946 - val_loss: 0.0245 - val_acc: 0.9939\n",
      "Epoch 123/200\n",
      "192/192 - 2s - loss: 0.0223 - acc: 0.9946 - val_loss: 0.0245 - val_acc: 0.9937\n",
      "Epoch 124/200\n",
      "192/192 - 2s - loss: 0.0223 - acc: 0.9946 - val_loss: 0.0242 - val_acc: 0.9941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "192/192 - 2s - loss: 0.0221 - acc: 0.9947 - val_loss: 0.0243 - val_acc: 0.9938\n",
      "Epoch 126/200\n",
      "192/192 - 2s - loss: 0.0221 - acc: 0.9946 - val_loss: 0.0244 - val_acc: 0.9941\n",
      "Epoch 127/200\n",
      "192/192 - 2s - loss: 0.0222 - acc: 0.9947 - val_loss: 0.0246 - val_acc: 0.9941\n",
      "Epoch 128/200\n",
      "192/192 - 2s - loss: 0.0219 - acc: 0.9948 - val_loss: 0.0240 - val_acc: 0.9939\n",
      "Epoch 129/200\n",
      "192/192 - 2s - loss: 0.0216 - acc: 0.9948 - val_loss: 0.0240 - val_acc: 0.9942\n",
      "Epoch 130/200\n",
      "192/192 - 2s - loss: 0.0217 - acc: 0.9948 - val_loss: 0.0246 - val_acc: 0.9936\n",
      "Epoch 131/200\n",
      "192/192 - 2s - loss: 0.0218 - acc: 0.9947 - val_loss: 0.0252 - val_acc: 0.9927\n",
      "Epoch 132/200\n",
      "192/192 - 2s - loss: 0.0223 - acc: 0.9945 - val_loss: 0.0237 - val_acc: 0.9940\n",
      "Epoch 133/200\n",
      "192/192 - 2s - loss: 0.0216 - acc: 0.9947 - val_loss: 0.0245 - val_acc: 0.9933\n",
      "Epoch 134/200\n",
      "192/192 - 2s - loss: 0.0214 - acc: 0.9948 - val_loss: 0.0238 - val_acc: 0.9937\n",
      "Epoch 135/200\n",
      "192/192 - 2s - loss: 0.0214 - acc: 0.9948 - val_loss: 0.0234 - val_acc: 0.9940\n",
      "Epoch 136/200\n",
      "192/192 - 2s - loss: 0.0215 - acc: 0.9949 - val_loss: 0.0247 - val_acc: 0.9933\n",
      "Epoch 137/200\n",
      "192/192 - 2s - loss: 0.0213 - acc: 0.9949 - val_loss: 0.0240 - val_acc: 0.9944\n",
      "Epoch 138/200\n",
      "192/192 - 2s - loss: 0.0218 - acc: 0.9948 - val_loss: 0.0242 - val_acc: 0.9944\n",
      "Epoch 139/200\n",
      "192/192 - 2s - loss: 0.0213 - acc: 0.9949 - val_loss: 0.0243 - val_acc: 0.9934\n",
      "Epoch 140/200\n",
      "192/192 - 2s - loss: 0.0216 - acc: 0.9949 - val_loss: 0.0240 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 141/200\n",
      "192/192 - 2s - loss: 0.0213 - acc: 0.9949 - val_loss: 0.0236 - val_acc: 0.9948\n",
      "Epoch 142/200\n",
      "192/192 - 2s - loss: 0.0213 - acc: 0.9949 - val_loss: 0.0238 - val_acc: 0.9950\n",
      "Epoch 143/200\n",
      "192/192 - 2s - loss: 0.0210 - acc: 0.9949 - val_loss: 0.0235 - val_acc: 0.9936\n",
      "Epoch 144/200\n",
      "192/192 - 2s - loss: 0.0212 - acc: 0.9949 - val_loss: 0.0257 - val_acc: 0.9927\n",
      "Epoch 145/200\n",
      "192/192 - 2s - loss: 0.0211 - acc: 0.9949 - val_loss: 0.0238 - val_acc: 0.9941\n",
      "Epoch 00145: early stopping\n",
      "signal_1 data shape: (163600, 50, 3)\n",
      "signal_2 data shape: (155841, 50, 3)\n",
      "shape of X: (319441, 150)\n",
      "shape of Y: (319441,)\n",
      "Weight for background: 0.98\n",
      "Weight for signal: 1.02\n",
      "Finished preprocessing\n",
      "shape of X: (319441, 50, 3)\n",
      "shape of Y: (319441,)\n",
      "Model summary:\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "192/192 - 2s - loss: 8.5217 - acc: 0.8653 - val_loss: 0.2881 - val_acc: 0.9345\n",
      "Epoch 2/200\n",
      "192/192 - 2s - loss: 0.4396 - acc: 0.9156 - val_loss: 0.1617 - val_acc: 0.9503\n",
      "Epoch 3/200\n",
      "192/192 - 2s - loss: 0.4829 - acc: 0.9223 - val_loss: 0.1360 - val_acc: 0.9518\n",
      "Epoch 4/200\n",
      "192/192 - 2s - loss: 0.1584 - acc: 0.9459 - val_loss: 0.1210 - val_acc: 0.9536\n",
      "Epoch 5/200\n",
      "192/192 - 2s - loss: 0.1456 - acc: 0.9474 - val_loss: 0.1371 - val_acc: 0.9486\n",
      "Epoch 6/200\n",
      "192/192 - 2s - loss: 0.1474 - acc: 0.9492 - val_loss: 0.1124 - val_acc: 0.9550\n",
      "Epoch 7/200\n",
      "192/192 - 2s - loss: 0.1165 - acc: 0.9572 - val_loss: 0.0935 - val_acc: 0.9677\n",
      "Epoch 8/200\n",
      "192/192 - 2s - loss: 0.1006 - acc: 0.9633 - val_loss: 0.0867 - val_acc: 0.9659\n",
      "Epoch 9/200\n",
      "192/192 - 2s - loss: 0.1085 - acc: 0.9600 - val_loss: 0.1852 - val_acc: 0.9374\n",
      "Epoch 10/200\n",
      "192/192 - 2s - loss: 0.1110 - acc: 0.9599 - val_loss: 0.0906 - val_acc: 0.9699\n",
      "Epoch 11/200\n",
      "192/192 - 2s - loss: 0.1602 - acc: 0.9468 - val_loss: 0.0922 - val_acc: 0.9689\n",
      "Epoch 12/200\n",
      "192/192 - 2s - loss: 0.0984 - acc: 0.9638 - val_loss: 0.1135 - val_acc: 0.9595\n",
      "Epoch 13/200\n",
      "192/192 - 2s - loss: 0.0866 - acc: 0.9689 - val_loss: 0.0758 - val_acc: 0.9766\n",
      "Epoch 14/200\n",
      "192/192 - 2s - loss: 0.0781 - acc: 0.9723 - val_loss: 0.0718 - val_acc: 0.9744\n",
      "Epoch 15/200\n",
      "192/192 - 2s - loss: 0.0895 - acc: 0.9687 - val_loss: 0.0641 - val_acc: 0.9794\n",
      "Epoch 16/200\n",
      "192/192 - 2s - loss: 0.0762 - acc: 0.9730 - val_loss: 0.0913 - val_acc: 0.9686\n",
      "Epoch 17/200\n",
      "192/192 - 2s - loss: 0.0715 - acc: 0.9754 - val_loss: 0.0609 - val_acc: 0.9824\n",
      "Epoch 18/200\n",
      "192/192 - 2s - loss: 0.1178 - acc: 0.9609 - val_loss: 0.0801 - val_acc: 0.9734\n",
      "Epoch 19/200\n",
      "192/192 - 2s - loss: 0.0789 - acc: 0.9720 - val_loss: 0.0603 - val_acc: 0.9799\n",
      "Epoch 20/200\n",
      "192/192 - 2s - loss: 0.0755 - acc: 0.9738 - val_loss: 0.0767 - val_acc: 0.9767\n",
      "Epoch 21/200\n",
      "192/192 - 2s - loss: 0.0583 - acc: 0.9812 - val_loss: 0.0457 - val_acc: 0.9874\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 - 2s - loss: 0.0661 - acc: 0.9777 - val_loss: 0.0680 - val_acc: 0.9780\n",
      "Epoch 23/200\n",
      "192/192 - 2s - loss: 0.0456 - acc: 0.9869 - val_loss: 0.0406 - val_acc: 0.9893\n",
      "Epoch 24/200\n",
      "192/192 - 2s - loss: 0.0658 - acc: 0.9780 - val_loss: 0.0481 - val_acc: 0.9853\n",
      "Epoch 25/200\n",
      "192/192 - 2s - loss: 0.0552 - acc: 0.9821 - val_loss: 0.0687 - val_acc: 0.9786\n",
      "Epoch 26/200\n",
      "192/192 - 2s - loss: 0.0494 - acc: 0.9844 - val_loss: 0.0737 - val_acc: 0.9727\n",
      "Epoch 27/200\n",
      "192/192 - 2s - loss: 1.3384 - acc: 0.9241 - val_loss: 0.1383 - val_acc: 0.9483\n",
      "Epoch 28/200\n",
      "192/192 - 2s - loss: 0.1083 - acc: 0.9612 - val_loss: 0.1043 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.000630957374449059.\n",
      "Epoch 29/200\n",
      "192/192 - 2s - loss: 0.0883 - acc: 0.9700 - val_loss: 0.0818 - val_acc: 0.9696\n",
      "Epoch 30/200\n",
      "192/192 - 2s - loss: 0.0761 - acc: 0.9744 - val_loss: 0.0720 - val_acc: 0.9775\n",
      "Epoch 31/200\n",
      "192/192 - 2s - loss: 0.0663 - acc: 0.9783 - val_loss: 0.0602 - val_acc: 0.9828\n",
      "Epoch 32/200\n",
      "192/192 - 2s - loss: 0.0568 - acc: 0.9829 - val_loss: 0.0505 - val_acc: 0.9864\n",
      "Epoch 33/200\n",
      "192/192 - 2s - loss: 0.0532 - acc: 0.9846 - val_loss: 0.0501 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0003981071838171537.\n",
      "Epoch 00033: early stopping\n",
      "signal_1 data shape: (163600, 50, 3)\n",
      "signal_2 data shape: (155841, 50, 3)\n",
      "shape of X: (319441, 150)\n",
      "shape of Y: (319441,)\n",
      "Weight for background: 0.98\n",
      "Weight for signal: 1.02\n",
      "Finished preprocessing\n",
      "shape of X: (319441, 50, 3)\n",
      "shape of Y: (319441,)\n",
      "Model summary:\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "192/192 - 2s - loss: 7.4099 - acc: 0.8700 - val_loss: 0.2562 - val_acc: 0.9461\n",
      "Epoch 2/200\n",
      "192/192 - 2s - loss: 0.6666 - acc: 0.9176 - val_loss: 0.2114 - val_acc: 0.9500\n",
      "Epoch 3/200\n",
      "192/192 - 2s - loss: 0.5537 - acc: 0.9245 - val_loss: 0.1501 - val_acc: 0.9491\n",
      "Epoch 4/200\n",
      "192/192 - 2s - loss: 0.1885 - acc: 0.9429 - val_loss: 0.1112 - val_acc: 0.9598\n",
      "Epoch 5/200\n",
      "192/192 - 2s - loss: 0.1439 - acc: 0.9518 - val_loss: 0.0940 - val_acc: 0.9665\n",
      "Epoch 6/200\n",
      "192/192 - 2s - loss: 0.1151 - acc: 0.9598 - val_loss: 0.1300 - val_acc: 0.9568\n",
      "Epoch 7/200\n",
      "192/192 - 2s - loss: 0.1023 - acc: 0.9635 - val_loss: 0.0710 - val_acc: 0.9704\n",
      "Epoch 8/200\n",
      "192/192 - 2s - loss: 0.2610 - acc: 0.9381 - val_loss: 0.1307 - val_acc: 0.9548\n",
      "Epoch 9/200\n",
      "192/192 - 2s - loss: 0.0862 - acc: 0.9692 - val_loss: 0.1199 - val_acc: 0.9557\n",
      "Epoch 10/200\n",
      "192/192 - 2s - loss: 0.0746 - acc: 0.9742 - val_loss: 0.0583 - val_acc: 0.9804\n",
      "Epoch 11/200\n",
      "192/192 - 2s - loss: 0.0618 - acc: 0.9793 - val_loss: 0.0753 - val_acc: 0.9715\n",
      "Epoch 12/200\n",
      "192/192 - 2s - loss: 0.0697 - acc: 0.9757 - val_loss: 0.0577 - val_acc: 0.9806\n",
      "Epoch 13/200\n",
      "192/192 - 2s - loss: 0.0688 - acc: 0.9765 - val_loss: 0.0453 - val_acc: 0.9876\n",
      "Epoch 14/200\n",
      "192/192 - 2s - loss: 0.0744 - acc: 0.9770 - val_loss: 0.0473 - val_acc: 0.9838\n",
      "Epoch 15/200\n",
      "192/192 - 2s - loss: 0.0485 - acc: 0.9846 - val_loss: 0.0862 - val_acc: 0.9697\n",
      "Epoch 16/200\n",
      "192/192 - 2s - loss: 0.0387 - acc: 0.9885 - val_loss: 0.2379 - val_acc: 0.9294\n",
      "Epoch 17/200\n",
      "192/192 - 2s - loss: 2.3369 - acc: 0.9062 - val_loss: 0.1085 - val_acc: 0.9618\n",
      "Epoch 18/200\n",
      "192/192 - 2s - loss: 0.0967 - acc: 0.9666 - val_loss: 0.0948 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.000630957374449059.\n",
      "Epoch 19/200\n",
      "192/192 - 2s - loss: 0.0746 - acc: 0.9755 - val_loss: 0.0652 - val_acc: 0.9774\n",
      "Epoch 20/200\n",
      "192/192 - 2s - loss: 0.0636 - acc: 0.9808 - val_loss: 0.0573 - val_acc: 0.9841\n",
      "Epoch 21/200\n",
      "192/192 - 2s - loss: 0.0575 - acc: 0.9826 - val_loss: 0.0685 - val_acc: 0.9725\n",
      "Epoch 22/200\n",
      "192/192 - 2s - loss: 0.0509 - acc: 0.9855 - val_loss: 0.0463 - val_acc: 0.9864\n",
      "Epoch 23/200\n",
      "192/192 - 2s - loss: 0.0467 - acc: 0.9867 - val_loss: 0.0408 - val_acc: 0.9923\n",
      "Epoch 24/200\n",
      "192/192 - 2s - loss: 0.0490 - acc: 0.9854 - val_loss: 0.0341 - val_acc: 0.9905\n",
      "Epoch 25/200\n",
      "192/192 - 2s - loss: 0.0471 - acc: 0.9865 - val_loss: 0.0477 - val_acc: 0.9843\n",
      "Epoch 26/200\n",
      "192/192 - 2s - loss: 0.0394 - acc: 0.9894 - val_loss: 0.0303 - val_acc: 0.9932\n",
      "Epoch 27/200\n",
      "192/192 - 2s - loss: 0.0349 - acc: 0.9909 - val_loss: 0.0316 - val_acc: 0.9907\n",
      "Epoch 28/200\n",
      "192/192 - 2s - loss: 0.0434 - acc: 0.9873 - val_loss: 0.0277 - val_acc: 0.9930\n",
      "Epoch 29/200\n",
      "192/192 - 2s - loss: 0.0301 - acc: 0.9924 - val_loss: 0.0324 - val_acc: 0.9924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200\n",
      "192/192 - 2s - loss: 0.0384 - acc: 0.9893 - val_loss: 0.0357 - val_acc: 0.9885\n",
      "Epoch 31/200\n",
      "192/192 - 2s - loss: 0.0395 - acc: 0.9895 - val_loss: 0.0231 - val_acc: 0.9957\n",
      "Epoch 32/200\n",
      "192/192 - 2s - loss: 0.0337 - acc: 0.9909 - val_loss: 0.0368 - val_acc: 0.9884\n",
      "Epoch 33/200\n",
      "192/192 - 2s - loss: 0.0387 - acc: 0.9893 - val_loss: 0.0259 - val_acc: 0.9933\n",
      "Epoch 34/200\n",
      "192/192 - 2s - loss: 0.0258 - acc: 0.9936 - val_loss: 0.0194 - val_acc: 0.9953\n",
      "Epoch 35/200\n",
      "192/192 - 2s - loss: 0.0248 - acc: 0.9939 - val_loss: 0.0344 - val_acc: 0.9901\n",
      "Epoch 36/200\n",
      "192/192 - 2s - loss: 0.0303 - acc: 0.9919 - val_loss: 0.0222 - val_acc: 0.9939\n",
      "Epoch 37/200\n",
      "192/192 - 2s - loss: 0.0575 - acc: 0.9851 - val_loss: 0.0962 - val_acc: 0.9682\n",
      "Epoch 38/200\n",
      "192/192 - 2s - loss: 0.0442 - acc: 0.9875 - val_loss: 0.0425 - val_acc: 0.9865\n",
      "Epoch 39/200\n",
      "192/192 - 2s - loss: 0.0341 - acc: 0.9912 - val_loss: 0.0222 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0003981071838171537.\n",
      "Epoch 40/200\n",
      "192/192 - 2s - loss: 0.0213 - acc: 0.9950 - val_loss: 0.0178 - val_acc: 0.9972\n",
      "Epoch 41/200\n",
      "192/192 - 2s - loss: 0.0189 - acc: 0.9957 - val_loss: 0.0158 - val_acc: 0.9965\n",
      "Epoch 42/200\n",
      "192/192 - 2s - loss: 0.0161 - acc: 0.9963 - val_loss: 0.0162 - val_acc: 0.9974\n",
      "Epoch 43/200\n",
      "192/192 - 2s - loss: 0.0180 - acc: 0.9957 - val_loss: 0.0220 - val_acc: 0.9969\n",
      "Epoch 44/200\n",
      "192/192 - 2s - loss: 0.0189 - acc: 0.9956 - val_loss: 0.0205 - val_acc: 0.9942\n",
      "Epoch 45/200\n",
      "192/192 - 2s - loss: 0.0246 - acc: 0.9937 - val_loss: 0.0133 - val_acc: 0.9965\n",
      "Epoch 46/200\n",
      "192/192 - 2s - loss: 0.0160 - acc: 0.9964 - val_loss: 0.0127 - val_acc: 0.9968\n",
      "Epoch 47/200\n",
      "192/192 - 2s - loss: 0.0185 - acc: 0.9956 - val_loss: 0.0202 - val_acc: 0.9950\n",
      "Epoch 48/200\n",
      "192/192 - 2s - loss: 0.0200 - acc: 0.9954 - val_loss: 0.1072 - val_acc: 0.9711\n",
      "Epoch 49/200\n",
      "192/192 - 2s - loss: 0.0200 - acc: 0.9952 - val_loss: 0.0129 - val_acc: 0.9972\n",
      "Epoch 50/200\n",
      "192/192 - 2s - loss: 0.0217 - acc: 0.9944 - val_loss: 0.0170 - val_acc: 0.9978\n",
      "Epoch 51/200\n",
      "192/192 - 2s - loss: 0.0140 - acc: 0.9968 - val_loss: 0.0126 - val_acc: 0.9979\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0002511886574257803.\n",
      "Epoch 52/200\n",
      "192/192 - 2s - loss: 0.0101 - acc: 0.9979 - val_loss: 0.0087 - val_acc: 0.9982\n",
      "Epoch 53/200\n",
      "192/192 - 2s - loss: 0.0092 - acc: 0.9981 - val_loss: 0.0091 - val_acc: 0.9983\n",
      "Epoch 54/200\n",
      "192/192 - 2s - loss: 0.0093 - acc: 0.9980 - val_loss: 0.0094 - val_acc: 0.9979\n",
      "Epoch 55/200\n",
      "192/192 - 2s - loss: 0.0092 - acc: 0.9980 - val_loss: 0.0116 - val_acc: 0.9981\n",
      "Epoch 56/200\n",
      "192/192 - 2s - loss: 0.0094 - acc: 0.9980 - val_loss: 0.0099 - val_acc: 0.9974\n",
      "Epoch 57/200\n",
      "192/192 - 2s - loss: 0.0142 - acc: 0.9967 - val_loss: 0.0091 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.00015848933651346973.\n",
      "Epoch 58/200\n",
      "192/192 - 2s - loss: 0.0072 - acc: 0.9986 - val_loss: 0.0082 - val_acc: 0.9982\n",
      "Epoch 59/200\n",
      "192/192 - 2s - loss: 0.0069 - acc: 0.9986 - val_loss: 0.0096 - val_acc: 0.9986\n",
      "Epoch 60/200\n",
      "192/192 - 2s - loss: 0.0070 - acc: 0.9986 - val_loss: 0.0081 - val_acc: 0.9981\n",
      "Epoch 61/200\n",
      "192/192 - 2s - loss: 0.0065 - acc: 0.9988 - val_loss: 0.0071 - val_acc: 0.9986\n",
      "Epoch 62/200\n",
      "192/192 - 2s - loss: 0.0068 - acc: 0.9985 - val_loss: 0.0072 - val_acc: 0.9986\n",
      "Epoch 63/200\n",
      "192/192 - 2s - loss: 0.0072 - acc: 0.9984 - val_loss: 0.0120 - val_acc: 0.9967\n",
      "Epoch 64/200\n",
      "192/192 - 2s - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0149 - val_acc: 0.9963\n",
      "Epoch 65/200\n",
      "192/192 - 2s - loss: 0.0065 - acc: 0.9987 - val_loss: 0.0076 - val_acc: 0.9984\n",
      "Epoch 66/200\n",
      "192/192 - 2s - loss: 0.0071 - acc: 0.9985 - val_loss: 0.0109 - val_acc: 0.9989\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.00010000000838432616.\n",
      "Epoch 67/200\n",
      "192/192 - 2s - loss: 0.0053 - acc: 0.9989 - val_loss: 0.0080 - val_acc: 0.9979\n",
      "Epoch 68/200\n",
      "192/192 - 2s - loss: 0.0052 - acc: 0.9990 - val_loss: 0.0105 - val_acc: 0.9976\n",
      "Epoch 69/200\n",
      "192/192 - 2s - loss: 0.0050 - acc: 0.9989 - val_loss: 0.0062 - val_acc: 0.9988\n",
      "Epoch 70/200\n",
      "192/192 - 2s - loss: 0.0047 - acc: 0.9990 - val_loss: 0.0064 - val_acc: 0.9985\n",
      "Epoch 71/200\n",
      "192/192 - 2s - loss: 0.0048 - acc: 0.9990 - val_loss: 0.0063 - val_acc: 0.9989\n",
      "Epoch 72/200\n",
      "192/192 - 2s - loss: 0.0050 - acc: 0.9989 - val_loss: 0.0068 - val_acc: 0.9986\n",
      "Epoch 73/200\n",
      "192/192 - 2s - loss: 0.0045 - acc: 0.9990 - val_loss: 0.0067 - val_acc: 0.9985\n",
      "Epoch 74/200\n",
      "192/192 - 2s - loss: 0.0045 - acc: 0.9991 - val_loss: 0.0083 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 6.30957374449059e-05.\n",
      "Epoch 75/200\n",
      "192/192 - 2s - loss: 0.0035 - acc: 0.9993 - val_loss: 0.0068 - val_acc: 0.9984\n",
      "Epoch 76/200\n",
      "192/192 - 2s - loss: 0.0038 - acc: 0.9992 - val_loss: 0.0070 - val_acc: 0.9989\n",
      "Epoch 77/200\n",
      "192/192 - 2s - loss: 0.0036 - acc: 0.9993 - val_loss: 0.0076 - val_acc: 0.9990\n",
      "Epoch 78/200\n",
      "192/192 - 2s - loss: 0.0035 - acc: 0.9993 - val_loss: 0.0056 - val_acc: 0.9989\n",
      "Epoch 79/200\n",
      "192/192 - 2s - loss: 0.0034 - acc: 0.9993 - val_loss: 0.0067 - val_acc: 0.9989\n",
      "Epoch 80/200\n",
      "192/192 - 2s - loss: 0.0033 - acc: 0.9994 - val_loss: 0.0055 - val_acc: 0.9990\n",
      "Epoch 81/200\n",
      "192/192 - 2s - loss: 0.0037 - acc: 0.9992 - val_loss: 0.0071 - val_acc: 0.9984\n",
      "Epoch 82/200\n",
      "192/192 - 2s - loss: 0.0036 - acc: 0.9993 - val_loss: 0.0055 - val_acc: 0.9989\n",
      "Epoch 83/200\n",
      "192/192 - 2s - loss: 0.0030 - acc: 0.9994 - val_loss: 0.0070 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 3.981071838171537e-05.\n",
      "Epoch 84/200\n",
      "192/192 - 2s - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0059 - val_acc: 0.9988\n",
      "Epoch 85/200\n",
      "192/192 - 2s - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0059 - val_acc: 0.9988\n",
      "Epoch 86/200\n",
      "192/192 - 2s - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0053 - val_acc: 0.9990\n",
      "Epoch 87/200\n",
      "192/192 - 2s - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0055 - val_acc: 0.9989\n",
      "Epoch 88/200\n",
      "192/192 - 2s - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0059 - val_acc: 0.9987\n",
      "Epoch 89/200\n",
      "192/192 - 2s - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0068 - val_acc: 0.9985\n",
      "Epoch 90/200\n",
      "192/192 - 2s - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0056 - val_acc: 0.9989\n",
      "Epoch 91/200\n",
      "192/192 - 2s - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0067 - val_acc: 0.9989\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 2.5118865283496142e-05.\n",
      "Epoch 92/200\n",
      "192/192 - 2s - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0057 - val_acc: 0.9988\n",
      "Epoch 93/200\n",
      "192/192 - 2s - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0049 - val_acc: 0.9991\n",
      "Epoch 94/200\n",
      "192/192 - 2s - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0054 - val_acc: 0.9990\n",
      "Epoch 95/200\n",
      "192/192 - 2s - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0049 - val_acc: 0.9991\n",
      "Epoch 96/200\n",
      "192/192 - 2s - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0057 - val_acc: 0.9989\n",
      "Epoch 97/200\n",
      "192/192 - 2s - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0052 - val_acc: 0.9990\n",
      "Epoch 98/200\n",
      "192/192 - 2s - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0062 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.5848932274101303e-05.\n",
      "Epoch 99/200\n",
      "192/192 - 2s - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0053 - val_acc: 0.9990\n",
      "Epoch 100/200\n",
      "192/192 - 2s - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0049 - val_acc: 0.9991\n",
      "Epoch 101/200\n",
      "192/192 - 2s - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0063 - val_acc: 0.9987\n",
      "Epoch 102/200\n",
      "192/192 - 2s - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0051 - val_acc: 0.9991\n",
      "Epoch 103/200\n",
      "192/192 - 2s - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0047 - val_acc: 0.9992\n",
      "Epoch 104/200\n",
      "192/192 - 2s - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0050 - val_acc: 0.9990\n",
      "Epoch 105/200\n",
      "192/192 - 2s - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0056 - val_acc: 0.9989\n",
      "Epoch 106/200\n",
      "192/192 - 2s - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0051 - val_acc: 0.9990\n",
      "Epoch 107/200\n",
      "192/192 - 2s - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0050 - val_acc: 0.9991\n",
      "Epoch 108/200\n",
      "192/192 - 2s - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0067 - val_acc: 0.9986\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 1.0000000608891671e-05.\n",
      "Epoch 109/200\n",
      "192/192 - 2s - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0056 - val_acc: 0.9989\n",
      "Epoch 110/200\n",
      "192/192 - 2s - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0052 - val_acc: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "192/192 - 2s - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0054 - val_acc: 0.9990\n",
      "Epoch 112/200\n",
      "192/192 - 2s - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0061 - val_acc: 0.9988\n",
      "Epoch 113/200\n",
      "192/192 - 2s - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0051 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 00113: early stopping\n",
      "signal_1 data shape: (163600, 50, 3)\n",
      "signal_2 data shape: (155841, 50, 3)\n",
      "shape of X: (319441, 150)\n",
      "shape of Y: (319441,)\n",
      "Weight for background: 0.98\n",
      "Weight for signal: 1.02\n",
      "Finished preprocessing\n",
      "shape of X: (319441, 50, 3)\n",
      "shape of Y: (319441,)\n",
      "Model summary:\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "192/192 - 2s - loss: 12.1029 - acc: 0.8729 - val_loss: 0.1844 - val_acc: 0.9390\n",
      "Epoch 2/200\n",
      "192/192 - 2s - loss: 0.2301 - acc: 0.9323 - val_loss: 0.1193 - val_acc: 0.9623\n",
      "Epoch 3/200\n",
      "192/192 - 2s - loss: 0.1482 - acc: 0.9490 - val_loss: 0.1446 - val_acc: 0.9441\n",
      "Epoch 4/200\n",
      "192/192 - 2s - loss: 0.1489 - acc: 0.9500 - val_loss: 0.2320 - val_acc: 0.9253\n",
      "Epoch 5/200\n",
      "192/192 - 2s - loss: 0.1037 - acc: 0.9630 - val_loss: 0.0884 - val_acc: 0.9691\n",
      "Epoch 6/200\n",
      "192/192 - 2s - loss: 0.1277 - acc: 0.9578 - val_loss: 0.0697 - val_acc: 0.9769\n",
      "Epoch 7/200\n",
      "192/192 - 2s - loss: 0.0578 - acc: 0.9825 - val_loss: 0.0516 - val_acc: 0.9859\n",
      "Epoch 8/200\n",
      "192/192 - 2s - loss: 0.0526 - acc: 0.9843 - val_loss: 0.1289 - val_acc: 0.9426\n",
      "Epoch 9/200\n",
      "192/192 - 2s - loss: 0.1762 - acc: 0.9550 - val_loss: 0.0768 - val_acc: 0.9733\n",
      "Epoch 10/200\n",
      "192/192 - 2s - loss: 0.0650 - acc: 0.9782 - val_loss: 0.0468 - val_acc: 0.9882\n",
      "Epoch 11/200\n",
      "192/192 - 2s - loss: 0.0530 - acc: 0.9839 - val_loss: 0.0433 - val_acc: 0.9864\n",
      "Epoch 12/200\n",
      "192/192 - 2s - loss: 0.0465 - acc: 0.9863 - val_loss: 0.0424 - val_acc: 0.9860\n",
      "Epoch 13/200\n",
      "192/192 - 2s - loss: 0.0404 - acc: 0.9885 - val_loss: 0.0364 - val_acc: 0.9903\n",
      "Epoch 14/200\n",
      "192/192 - 2s - loss: 0.0393 - acc: 0.9891 - val_loss: 0.0562 - val_acc: 0.9799\n",
      "Epoch 15/200\n",
      "192/192 - 2s - loss: 0.0768 - acc: 0.9772 - val_loss: 0.1328 - val_acc: 0.9583\n",
      "Epoch 16/200\n",
      "192/192 - 2s - loss: 0.0358 - acc: 0.9903 - val_loss: 0.0200 - val_acc: 0.9954\n",
      "Epoch 17/200\n",
      "192/192 - 2s - loss: 0.0311 - acc: 0.9915 - val_loss: 0.0324 - val_acc: 0.9932\n",
      "Epoch 18/200\n",
      "192/192 - 2s - loss: 0.0628 - acc: 0.9812 - val_loss: 0.0402 - val_acc: 0.9879\n",
      "Epoch 19/200\n",
      "192/192 - 2s - loss: 0.0264 - acc: 0.9936 - val_loss: 0.0233 - val_acc: 0.9935\n",
      "Epoch 20/200\n",
      "192/192 - 2s - loss: 0.0222 - acc: 0.9945 - val_loss: 0.0171 - val_acc: 0.9968\n",
      "Epoch 21/200\n",
      "192/192 - 2s - loss: 0.0684 - acc: 0.9808 - val_loss: 0.3068 - val_acc: 0.8950\n",
      "Epoch 22/200\n",
      "192/192 - 2s - loss: 0.0553 - acc: 0.9842 - val_loss: 0.0261 - val_acc: 0.9943\n",
      "Epoch 23/200\n",
      "192/192 - 2s - loss: 0.0484 - acc: 0.9866 - val_loss: 0.0933 - val_acc: 0.9662\n",
      "Epoch 24/200\n",
      "192/192 - 2s - loss: 0.0365 - acc: 0.9901 - val_loss: 0.0300 - val_acc: 0.9969\n",
      "Epoch 25/200\n",
      "192/192 - 2s - loss: 0.0264 - acc: 0.9933 - val_loss: 0.0158 - val_acc: 0.9966\n",
      "Epoch 26/200\n",
      "192/192 - 2s - loss: 0.0201 - acc: 0.9951 - val_loss: 0.0329 - val_acc: 0.9916\n",
      "Epoch 27/200\n",
      "192/192 - 2s - loss: 1.3481 - acc: 0.9296 - val_loss: 0.1109 - val_acc: 0.9586\n",
      "Epoch 28/200\n",
      "192/192 - 2s - loss: 0.0900 - acc: 0.9683 - val_loss: 0.0703 - val_acc: 0.9760\n",
      "Epoch 29/200\n",
      "192/192 - 2s - loss: 0.0616 - acc: 0.9812 - val_loss: 0.0493 - val_acc: 0.9844\n",
      "Epoch 30/200\n",
      "192/192 - 2s - loss: 0.0455 - acc: 0.9885 - val_loss: 0.0420 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.000630957374449059.\n",
      "Epoch 31/200\n",
      "192/192 - 2s - loss: 0.0366 - acc: 0.9918 - val_loss: 0.0333 - val_acc: 0.9909\n",
      "Epoch 32/200\n",
      "192/192 - 2s - loss: 0.0324 - acc: 0.9926 - val_loss: 0.0288 - val_acc: 0.9945\n",
      "Epoch 33/200\n",
      "192/192 - 2s - loss: 0.0280 - acc: 0.9938 - val_loss: 0.0256 - val_acc: 0.9948\n",
      "Epoch 34/200\n",
      "192/192 - 2s - loss: 0.0261 - acc: 0.9939 - val_loss: 0.0252 - val_acc: 0.9955\n",
      "Epoch 35/200\n",
      "192/192 - 2s - loss: 0.0293 - acc: 0.9929 - val_loss: 0.0239 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0003981071838171537.\n",
      "Epoch 00035: early stopping\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for signal_1, signal_2 in zip(signal_1_recons,signal_2_recons):\n",
    "    result.append(train_pfn(signal_1, signal_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9bfe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_res = []\n",
    "for i, (pfn_original, hist1, original_training_data) in enumerate(result):\n",
    "    preds = pfn.predict(original_training_data[1][2], batch_size=10000)\n",
    "    pfn_fp, pfn_tp, threshs = roc_curve(original_training_data[1][-1], preds[:,1])\n",
    "    roc_res.append([pfn_fp, pfn_tp, threshs])\n",
    "    auc = roc_auc_score(original_training_data[1][-1], preds[:,1])\n",
    "    print('reconstruct PFN AUC(beta = {}):{}', auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
