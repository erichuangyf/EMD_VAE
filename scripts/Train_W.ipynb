{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on W-jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "# from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization\n",
    "# from tensorflow.keras.layers import Conv1D\n",
    "# from tensorflow.keras.layers import Flatten, Reshape, Lambda\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# from tensorflow.keras import Model\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "#from scipy import linalg as LA\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.tf_sinkhorn import ground_distance_tf_nograd, sinkhorn_knopp_tf_scaling_stabilized_class\n",
    "import utils.VAE_model_tools\n",
    "from utils.VAE_model_tools import build_and_compile_annealing_vae, betaVAEModel, reset_metrics\n",
    "\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir_path):\n",
    "    ''' Creates a directory (or nested directories) if they don't exist.\n",
    "    '''\n",
    "    if not osp.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    return dir_path\n",
    "\n",
    "def ptetaphiE_to_Epxpypz(jets):\n",
    "    pt = jets[:,:,0]\n",
    "    eta = jets[:,:,1]\n",
    "    phi = jets[:,:,2]\n",
    "    E = jets[:,:,3]\n",
    "    \n",
    "    px = pt * np.cos(phi)\n",
    "    py = pt * np.sin(phi)\n",
    "    pz = pt * np.sinh(eta)\n",
    "    \n",
    "    newjets = np.zeros(jets.shape)\n",
    "    newjets[:,:,0] = E\n",
    "    newjets[:,:,1] = px\n",
    "    newjets[:,:,2] = py\n",
    "    newjets[:,:,3] = pz\n",
    "    \n",
    "    return newjets\n",
    "\n",
    "def ptetaphiE_to_ptyphim(jets):\n",
    "    pt = jets[:,:,0]\n",
    "    eta = jets[:,:,1]\n",
    "    phi = jets[:,:,2]\n",
    "    E = jets[:,:,3]\n",
    "    \n",
    "    pz = pt * np.sinh(eta)\n",
    "    y = 0.5*np.nan_to_num(np.log((E+pz)/(E-pz)))\n",
    "    \n",
    "    msqr = np.square(E)-np.square(pt)-np.square(pz)\n",
    "    msqr[np.abs(msqr) < 1e-6] = 0\n",
    "    m = np.sqrt(msqr)\n",
    "    \n",
    "    newjets = np.zeros(jets.shape)\n",
    "    newjets[:,:,0] = pt\n",
    "    newjets[:,:,1] = y\n",
    "    newjets[:,:,2] = phi\n",
    "    newjets[:,:,3] = m\n",
    "    \n",
    "    return newjets\n",
    "    \n",
    "def ptyphim_to_ptetaphiE(jets):\n",
    "    \n",
    "    pt = jets[:,:,0]\n",
    "    y = jets[:,:,1]\n",
    "    phi = jets[:,:,2]\n",
    "    m = jets[:,:,3]\n",
    "    \n",
    "    eta = np.nan_to_num(np.arcsinh(np.sinh(y)*np.sqrt(1+np.square(m/pt))))\n",
    "    pz = pt * np.sinh(eta)\n",
    "    E = np.sqrt(np.square(pz)+np.square(pt)+np.square(m))\n",
    "    \n",
    "    newjets = np.zeros(jets.shape)\n",
    "    newjets[:,:,0] = pt\n",
    "    newjets[:,:,1] = eta\n",
    "    newjets[:,:,2] = phi\n",
    "    newjets[:,:,3] = E\n",
    "    \n",
    "    return newjets\n",
    "    \n",
    "def center_jets_ptetaphiE(jets):\n",
    "    cartesian_jets = ptetaphiE_to_Epxpypz(jets)\n",
    "    sumjet_cartesian = np.sum(cartesian_jets,axis=1)\n",
    "    \n",
    "    sumjet_phi = np.arctan2(sumjet_cartesian[:,2],sumjet_cartesian[:,1])\n",
    "    sumjet_y = 0.5*np.log((sumjet_cartesian[:,0] + sumjet_cartesian[:,-1])/(sumjet_cartesian[:,0] - sumjet_cartesian[:,-1]))\n",
    "    \n",
    "    ptyphim_jets = ptetaphiE_to_ptyphim(jets)\n",
    "    #print(ptyphim_jets[:3,:,:])\n",
    "    \n",
    "    transformed_jets = np.copy(ptyphim_jets)\n",
    "    transformed_jets[:,:,1] = ptyphim_jets[:,:,1] - sumjet_y[:,None]\n",
    "    transformed_jets[:,:,2] = ptyphim_jets[:,:,2] - sumjet_phi[:,None]\n",
    "    transformed_jets[:,:,2] = transformed_jets[:,:,2] + np.pi\n",
    "    transformed_jets[:,:,2] = np.mod(transformed_jets[:,:,2],2*np.pi)\n",
    "    transformed_jets[:,:,2] = transformed_jets[:,:,2] - np.pi\n",
    "\n",
    "    transformed_jets[transformed_jets[:,:,0] == 0] = 0\n",
    "    \n",
    "    newjets = ptyphim_to_ptetaphiE(transformed_jets)\n",
    "    return newjets\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess train/val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(602055, 200)\n",
      "Memory in GB: 1.803235039114952\n"
     ]
    }
   ],
   "source": [
    "# path to file\n",
    "fn =  '/home/jcollins/projects/EMD_VAE/in_data/monoW-data-3.h5'\n",
    "# fn =  '/media/jcollins/MAGIC!/monoW-data-3.h5'\n",
    "\n",
    "# Option 1: Load everything into memory\n",
    "df = pandas.read_hdf(fn,stop=1000000)\n",
    "print(df.shape)\n",
    "print(\"Memory in GB:\",sum(df.memory_usage(deep=True)) / (1024**3)+sum(df.memory_usage(deep=True)) / (1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-c1d138f24178>:36: RuntimeWarning: invalid value encountered in true_divide\n",
      "  y = 0.5*np.nan_to_num(np.log((E+pz)/(E-pz)))\n",
      "<ipython-input-2-c1d138f24178>:57: RuntimeWarning: invalid value encountered in true_divide\n",
      "  eta = np.nan_to_num(np.arcsinh(np.sinh(y)*np.sqrt(1+np.square(m/pt))))\n"
     ]
    }
   ],
   "source": [
    "# Data file contains, for each event, 50 particles (with zero padding), each particle with pT, eta, phi, E.\n",
    "data = df.values.reshape((-1,50,4))\n",
    "\n",
    "# Normalize pTs so that HT = 1\n",
    "HT = np.sum(data[:,:,0],axis=-1)\n",
    "data[:,:,0] = data[:,:,0]/HT[:,None]\n",
    "data[:,:,-1] = data[:,:,-1]/HT[:,None]\n",
    "\n",
    "# Center jet (optional)\n",
    "data = center_jets_ptetaphiE(data)\n",
    "\n",
    "# Inputs x to NN will be: pT, eta, cos(phi), sin(phi), log E\n",
    "# Separated phi into cos and sin for continuity around full detector, so make things easier for NN.\n",
    "# Also adding the log E is mainly because it seems like it should make things easier for NN, since there is an exponential spread in particle energies.\n",
    "# Feel free to change these choices as desired. E.g. px, py might be equally as good as pt, sin, cos.\n",
    "sig_input = np.zeros((len(data),50,5))\n",
    "sig_input[:,:,:2] = data[:,:,:2]\n",
    "sig_input[:,:,2] = np.cos(data[:,:,2])\n",
    "sig_input[:,:,3] = np.sin(data[:,:,2])\n",
    "sig_input[:,:,4] = np.log(data[:,:,3]+1e-8)\n",
    "\n",
    "\n",
    "data_x = sig_input\n",
    "# Event 'labels' y are [pT, eta, phi], which is used to calculate EMD to output which is also pT, eta, phi.\n",
    "data_y = data[:,:,:3]\n",
    "\n",
    "\n",
    "train_x = data_x[:500000]\n",
    "train_y = data_y[:500000]\n",
    "valid_x = data_x[500000:600000]\n",
    "valid_y = data_y[500000:600000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, 50, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 50, 2048)     12288       inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_39 (ReLU)                 (None, 50, 2048)     0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 50, 2048)     4196352     re_lu_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_40 (ReLU)                 (None, 50, 2048)     0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 50, 1028)     2106372     re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_41 (ReLU)                 (None, 50, 1028)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 50, 1024)     1053696     re_lu_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_42 (ReLU)                 (None, 50, 1024)     0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_3 (TensorFlowOp multiple             0           re_lu_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1028)         1053700     tf_op_layer_Sum_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_43 (ReLU)                 (None, 1028)         0           dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 1028)         1057812     re_lu_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_44 (ReLU)                 (None, 1028)         0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 1028)         1057812     re_lu_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_45 (ReLU)                 (None, 1028)         0           dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 512)          526848      re_lu_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_46 (ReLU)                 (None, 512)          0           dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 128)          65664       re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 128)          65664       re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            [(None, 128), (None, 11196208    inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack_3 (TensorFlow multiple             0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, 50, 3)        11765126    encoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gauss_distribution (Dis ((None, 128), (None, 11196208    tf_op_layer_stack_3[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 22,961,335\n",
      "Trainable params: 22,961,334\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 953.9962 - recon_loss: 3.0859 - KL loss: 950.9103 - beta: 1.0000 - val_val_loss: 332124960.0000 - val_val_recon_loss: 69259.8516 - val_val_KL loss: 332055712.0000 - val_beta: 1.0000\n"
     ]
    }
   ],
   "source": [
    "output_dir = './data/'\n",
    "\n",
    "experiment_name = 'W-test'\n",
    "train_output_dir = create_dir(osp.join(output_dir, experiment_name))\n",
    "vae, encoder, decoder = build_and_compile_annealing_vae(optimizer=keras.optimizers.Adam(lr=0.001,clipnorm=0.1),\n",
    "                                    encoder_conv_layers = [2048,2048,1028,1024],\n",
    "                                    dense_size = [1028,1028,1028,512],\n",
    "                                    decoder = [4026,2048,1028,512,512],\n",
    "                                    numItermaxinner = 40,   # EMD approximation params\n",
    "                                    numIter=10,\n",
    "                                    reg_init = 1.,\n",
    "                                    reg_final = 0.01,\n",
    "                                    stopThr=1e-3,\n",
    "                                    num_inputs=5,           # Size of x (e.g. pT, eta, sin, cos, log E)\n",
    "                                    num_particles_in=50)    # Num particles per event.\n",
    "\n",
    "batch_size=100\n",
    "save_period=2\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=0)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(train_output_dir + '/model_weights_{epoch:02d}.hdf5', save_freq = save_period*5000, save_weights_only=True)\n",
    "reset_metrics_inst = reset_metrics()\n",
    "\n",
    "callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "\n",
    "\n",
    "# Need to train on at least one example before model params can be loaded for annoying reasons.\n",
    "\n",
    "history = vae.fit(x=train_x[:10], y=train_y[:10], batch_size=batch_size,\n",
    "                epochs=1,verbose=1,#initial_epoch=int(vae.optimizer.iterations/numbatches),\n",
    "                validation_data = (valid_x[:10],valid_y[:10]),\n",
    "                callbacks = callbacks\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_epoch = 3957\n",
    "beta = 1.6e-4\n",
    "# vae.load_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + str(beta) + '.hdf5')\n",
    "vae.load_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3958/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 384.8230 - recon_loss: 3.3332e-04 - KL loss: 51.5036 - beta: 0.0010 - val_val_loss: 405.9765 - val_val_recon_loss: 3.6890e-04 - val_val_KL loss: 37.0715 - val_beta: 0.0010\n",
      "Epoch 3959/10000\n",
      "1000/1000 [==============================] - 145s 145ms/step - loss: 378.9243 - recon_loss: 3.4185e-04 - KL loss: 37.0766 - beta: 0.0010 - val_val_loss: 383.6831 - val_val_recon_loss: 3.4731e-04 - val_val_KL loss: 36.3773 - val_beta: 0.0010\n",
      "Epoch 3960/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 378.9336 - recon_loss: 3.4243e-04 - KL loss: 36.5063 - beta: 0.0010 - val_val_loss: 376.4502 - val_val_recon_loss: 3.4081e-04 - val_val_KL loss: 35.6357 - val_beta: 0.0010\n",
      "Epoch 3961/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 375.7469 - recon_loss: 3.4004e-04 - KL loss: 35.7102 - beta: 0.0010 - val_val_loss: 373.5909 - val_val_recon_loss: 3.3871e-04 - val_val_KL loss: 34.8765 - val_beta: 0.0010\n",
      "Epoch 3962/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 371.5775 - recon_loss: 3.3685e-04 - KL loss: 34.7299 - beta: 0.0010 - val_val_loss: 370.9254 - val_val_recon_loss: 3.3708e-04 - val_val_KL loss: 33.8462 - val_beta: 0.0010\n",
      "Epoch 3963/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 363.8833 - recon_loss: 3.2981e-04 - KL loss: 34.0771 - beta: 0.0010 - val_val_loss: 378.8667 - val_val_recon_loss: 3.4525e-04 - val_val_KL loss: 33.6159 - val_beta: 0.0010\n",
      "Epoch 3964/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 372.6578 - recon_loss: 3.3866e-04 - KL loss: 33.9981 - beta: 0.0010 - val_val_loss: 373.3633 - val_val_recon_loss: 3.3979e-04 - val_val_KL loss: 33.5725 - val_beta: 0.0010\n",
      "Epoch 3965/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 374.3309 - recon_loss: 3.4040e-04 - KL loss: 33.9319 - beta: 0.0010 - val_val_loss: 405.3111 - val_val_recon_loss: 3.7023e-04 - val_val_KL loss: 35.0819 - val_beta: 0.0010\n",
      "Epoch 3966/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 395.4954 - recon_loss: 3.6119e-04 - KL loss: 34.3014 - beta: 0.0010 - val_val_loss: 390.4078 - val_val_recon_loss: 3.5606e-04 - val_val_KL loss: 34.3523 - val_beta: 0.0010\n",
      "Epoch 3967/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 397.0219 - recon_loss: 3.6231e-04 - KL loss: 34.7105 - beta: 0.0010\n",
      "Epoch 03967: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 397.0223 - recon_loss: 3.6231e-04 - KL loss: 34.7104 - beta: 0.0010 - val_val_loss: 404.5710 - val_val_recon_loss: 3.7010e-04 - val_val_KL loss: 34.4720 - val_beta: 0.0010\n",
      "Epoch 3968/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 392.7803 - recon_loss: 3.5822e-04 - KL loss: 34.5598 - beta: 0.0010 - val_val_loss: 378.3103 - val_val_recon_loss: 3.4437e-04 - val_val_KL loss: 33.9379 - val_beta: 0.0010\n",
      "Epoch 3969/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 375.4458 - recon_loss: 3.4122e-04 - KL loss: 34.2256 - beta: 0.0010 - val_val_loss: 375.7667 - val_val_recon_loss: 3.4144e-04 - val_val_KL loss: 34.3268 - val_beta: 0.0010\n",
      "Epoch 3970/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 373.5380 - recon_loss: 3.3947e-04 - KL loss: 34.0670 - beta: 0.0010 - val_val_loss: 371.6024 - val_val_recon_loss: 3.3775e-04 - val_val_KL loss: 33.8502 - val_beta: 0.0010\n",
      "Epoch 3971/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 365.8062 - recon_loss: 3.3201e-04 - KL loss: 33.8006 - beta: 0.0010 - val_val_loss: 371.5221 - val_val_recon_loss: 3.3779e-04 - val_val_KL loss: 33.7327 - val_beta: 0.0010\n",
      "Epoch 3972/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 373.1311 - recon_loss: 3.3933e-04 - KL loss: 33.8029 - beta: 0.0010\n",
      "Epoch 03972: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 373.1344 - recon_loss: 3.3933e-04 - KL loss: 33.8030 - beta: 0.0010 - val_val_loss: 376.7235 - val_val_recon_loss: 3.4277e-04 - val_val_KL loss: 33.9490 - val_beta: 0.0010\n",
      "Epoch 3972/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 236.1780 - recon_loss: 3.4599e-04 - KL loss: 31.9102 - beta: 0.0013 - val_val_loss: 239.7204 - val_val_recon_loss: 3.5423e-04 - val_val_KL loss: 30.5868 - val_beta: 0.0013\n",
      "Epoch 3973/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 239.5980 - recon_loss: 3.5392e-04 - KL loss: 30.6491 - beta: 0.0013 - val_val_loss: 233.2922 - val_val_recon_loss: 3.4449e-04 - val_val_KL loss: 29.9116 - val_beta: 0.0013\n",
      "Epoch 3974/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 234.0617 - recon_loss: 3.4582e-04 - KL loss: 29.8929 - beta: 0.0013 - val_val_loss: 235.0231 - val_val_recon_loss: 3.4803e-04 - val_val_KL loss: 29.5504 - val_beta: 0.0013\n",
      "Epoch 3975/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 230.5751 - recon_loss: 3.4044e-04 - KL loss: 29.5846 - beta: 0.0013 - val_val_loss: 233.7339 - val_val_recon_loss: 3.4557e-04 - val_val_KL loss: 29.7171 - val_beta: 0.0013\n",
      "Epoch 3976/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 233.0609 - recon_loss: 3.4469e-04 - KL loss: 29.5599 - beta: 0.0013 - val_val_loss: 237.1996 - val_val_recon_loss: 3.5172e-04 - val_val_KL loss: 29.5528 - val_beta: 0.0013\n",
      "Epoch 3977/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 243.3589 - recon_loss: 3.6153e-04 - KL loss: 29.9148 - beta: 0.0013 - val_val_loss: 242.3257 - val_val_recon_loss: 3.6019e-04 - val_val_KL loss: 29.6782 - val_beta: 0.0013\n",
      "Epoch 3978/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 250.8137 - recon_loss: 3.7404e-04 - KL loss: 29.9862 - beta: 0.0013\n",
      "Epoch 03978: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 250.8166 - recon_loss: 3.7405e-04 - KL loss: 29.9862 - beta: 0.0013 - val_val_loss: 243.8697 - val_val_recon_loss: 3.6338e-04 - val_val_KL loss: 29.3390 - val_beta: 0.0013\n",
      "Epoch 3979/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 237.0542 - recon_loss: 3.5115e-04 - KL loss: 29.7432 - beta: 0.0013 - val_val_loss: 233.3706 - val_val_recon_loss: 3.4476e-04 - val_val_KL loss: 29.8280 - val_beta: 0.0013\n",
      "Epoch 3980/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 234.8759 - recon_loss: 3.4723e-04 - KL loss: 29.8749 - beta: 0.0013 - val_val_loss: 234.9137 - val_val_recon_loss: 3.4701e-04 - val_val_KL loss: 30.0420 - val_beta: 0.0013\n",
      "Epoch 3981/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 232.4985 - recon_loss: 3.4323e-04 - KL loss: 29.8607 - beta: 0.0013 - val_val_loss: 234.5174 - val_val_recon_loss: 3.4663e-04 - val_val_KL loss: 29.8738 - val_beta: 0.0013\n",
      "Epoch 3982/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 232.4421 - recon_loss: 3.4311e-04 - KL loss: 29.8772 - beta: 0.0013 - val_val_loss: 234.4790 - val_val_recon_loss: 3.4635e-04 - val_val_KL loss: 29.9990 - val_beta: 0.0013\n",
      "Epoch 3983/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 234.2461 - recon_loss: 3.4613e-04 - KL loss: 29.8941 - beta: 0.0013\n",
      "Epoch 03983: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 234.2438 - recon_loss: 3.4613e-04 - KL loss: 29.8940 - beta: 0.0013 - val_val_loss: 234.5329 - val_val_recon_loss: 3.4674e-04 - val_val_KL loss: 29.8219 - val_beta: 0.0013\n",
      "Epoch 3983/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 149.5017 - recon_loss: 3.4938e-04 - KL loss: 27.7225 - beta: 0.0017 - val_val_loss: 160.6354 - val_val_recon_loss: 3.8262e-04 - val_val_KL loss: 27.2713 - val_beta: 0.0017\n",
      "Epoch 3984/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 157s 157ms/step - loss: 160.2492 - recon_loss: 3.8175e-04 - KL loss: 27.1907 - beta: 0.0017 - val_val_loss: 156.0661 - val_val_recon_loss: 3.7080e-04 - val_val_KL loss: 26.8232 - val_beta: 0.0017\n",
      "Epoch 3985/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 152.8389 - recon_loss: 3.6246e-04 - KL loss: 26.5019 - beta: 0.0017 - val_val_loss: 152.3174 - val_val_recon_loss: 3.6030e-04 - val_val_KL loss: 26.7338 - val_beta: 0.0017\n",
      "Epoch 3986/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 159.3390 - recon_loss: 3.8018e-04 - KL loss: 26.8278 - beta: 0.0017 - val_val_loss: 165.1037 - val_val_recon_loss: 3.9755e-04 - val_val_KL loss: 26.5348 - val_beta: 0.0017\n",
      "Epoch 3987/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 162.9314 - recon_loss: 3.9145e-04 - KL loss: 26.4917 - beta: 0.0017 - val_val_loss: 159.3339 - val_val_recon_loss: 3.8040e-04 - val_val_KL loss: 26.7459 - val_beta: 0.0017\n",
      "Epoch 3988/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 156.5355 - recon_loss: 3.7282e-04 - KL loss: 26.5878 - beta: 0.0017 - val_val_loss: 163.3255 - val_val_recon_loss: 3.9083e-04 - val_val_KL loss: 27.1002 - val_beta: 0.0017\n",
      "Epoch 3989/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 161.4716 - recon_loss: 3.8707e-04 - KL loss: 26.5581 - beta: 0.0017 - val_val_loss: 160.4913 - val_val_recon_loss: 3.8409e-04 - val_val_KL loss: 26.6166 - val_beta: 0.0017\n",
      "Epoch 3990/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 154.6808 - recon_loss: 3.6830e-04 - KL loss: 26.3082 - beta: 0.0017\n",
      "Epoch 03990: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 154.6822 - recon_loss: 3.6831e-04 - KL loss: 26.3082 - beta: 0.0017 - val_val_loss: 159.5710 - val_val_recon_loss: 3.8136e-04 - val_val_KL loss: 26.6470 - val_beta: 0.0017\n",
      "Epoch 3991/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 153.3944 - recon_loss: 3.6377e-04 - KL loss: 26.6009 - beta: 0.0017 - val_val_loss: 153.5393 - val_val_recon_loss: 3.6431e-04 - val_val_KL loss: 26.5583 - val_beta: 0.0017\n",
      "Epoch 3992/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 151.5766 - recon_loss: 3.5905e-04 - KL loss: 26.4296 - beta: 0.0017 - val_val_loss: 151.5266 - val_val_recon_loss: 3.5919e-04 - val_val_KL loss: 26.3310 - val_beta: 0.0017\n",
      "Epoch 3993/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 150.3615 - recon_loss: 3.5583e-04 - KL loss: 26.3356 - beta: 0.0017 - val_val_loss: 153.9009 - val_val_recon_loss: 3.6613e-04 - val_val_KL loss: 26.2850 - val_beta: 0.0017\n",
      "Epoch 3994/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 150.6135 - recon_loss: 3.5619e-04 - KL loss: 26.4638 - beta: 0.0017 - val_val_loss: 149.9440 - val_val_recon_loss: 3.5495e-04 - val_val_KL loss: 26.2266 - val_beta: 0.0017\n",
      "Epoch 3995/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 148.2269 - recon_loss: 3.5015e-04 - KL loss: 26.1825 - beta: 0.0017 - val_val_loss: 148.9938 - val_val_recon_loss: 3.5234e-04 - val_val_KL loss: 26.1863 - val_beta: 0.0017\n",
      "Epoch 3996/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 147.6245 - recon_loss: 3.4828e-04 - KL loss: 26.2306 - beta: 0.0017 - val_val_loss: 147.6506 - val_val_recon_loss: 3.4865e-04 - val_val_KL loss: 26.1261 - val_beta: 0.0017\n",
      "Epoch 3997/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 146.2355 - recon_loss: 3.4467e-04 - KL loss: 26.0998 - beta: 0.0017 - val_val_loss: 147.9754 - val_val_recon_loss: 3.4947e-04 - val_val_KL loss: 26.1659 - val_beta: 0.0017\n",
      "Epoch 3998/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 146.1519 - recon_loss: 3.4488e-04 - KL loss: 25.9447 - beta: 0.0017 - val_val_loss: 146.9772 - val_val_recon_loss: 3.4745e-04 - val_val_KL loss: 25.8728 - val_beta: 0.0017\n",
      "Epoch 3999/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 146.6376 - recon_loss: 3.4607e-04 - KL loss: 26.0146 - beta: 0.0017 - val_val_loss: 147.3470 - val_val_recon_loss: 3.4840e-04 - val_val_KL loss: 25.9129 - val_beta: 0.0017\n",
      "Epoch 4000/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 145.6894 - recon_loss: 3.4351e-04 - KL loss: 25.9580 - beta: 0.0017 - val_val_loss: 149.5320 - val_val_recon_loss: 3.5417e-04 - val_val_KL loss: 26.0834 - val_beta: 0.0017\n",
      "Epoch 4001/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 147.2279 - recon_loss: 3.4771e-04 - KL loss: 26.0328 - beta: 0.0017 - val_val_loss: 147.3223 - val_val_recon_loss: 3.4836e-04 - val_val_KL loss: 25.9015 - val_beta: 0.0017\n",
      "Epoch 4002/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 145.2300 - recon_loss: 3.4239e-04 - KL loss: 25.8906 - beta: 0.0017 - val_val_loss: 146.6766 - val_val_recon_loss: 3.4706e-04 - val_val_KL loss: 25.7089 - val_beta: 0.0017\n",
      "Epoch 4003/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 143.6117 - recon_loss: 3.3813e-04 - KL loss: 25.7561 - beta: 0.0017 - val_val_loss: 146.2126 - val_val_recon_loss: 3.4522e-04 - val_val_KL loss: 25.8849 - val_beta: 0.0017\n",
      "Epoch 4004/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 145.0631 - recon_loss: 3.4207e-04 - KL loss: 25.8350 - beta: 0.0017 - val_val_loss: 146.0103 - val_val_recon_loss: 3.4520e-04 - val_val_KL loss: 25.6892 - val_beta: 0.0017\n",
      "Epoch 4005/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 143.5449 - recon_loss: 3.3781e-04 - KL loss: 25.8018 - beta: 0.0017 - val_val_loss: 145.9549 - val_val_recon_loss: 3.4486e-04 - val_val_KL loss: 25.7530 - val_beta: 0.0017\n",
      "Epoch 4006/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 145.4912 - recon_loss: 3.4370e-04 - KL loss: 25.6934 - beta: 0.0017 - val_val_loss: 147.0264 - val_val_recon_loss: 3.4822e-04 - val_val_KL loss: 25.6531 - val_beta: 0.0017\n",
      "Epoch 4007/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 146.2250 - recon_loss: 3.4563e-04 - KL loss: 25.7554 - beta: 0.0017 - val_val_loss: 147.6752 - val_val_recon_loss: 3.5002e-04 - val_val_KL loss: 25.6748 - val_beta: 0.0017\n",
      "Epoch 4008/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 146.0887 - recon_loss: 3.4510e-04 - KL loss: 25.8035 - beta: 0.0017 - val_val_loss: 149.0415 - val_val_recon_loss: 3.5341e-04 - val_val_KL loss: 25.8585 - val_beta: 0.0017\n",
      "Epoch 4009/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 146.2384 - recon_loss: 3.4551e-04 - KL loss: 25.8116 - beta: 0.0017 - val_val_loss: 150.3692 - val_val_recon_loss: 3.5692e-04 - val_val_KL loss: 25.9636 - val_beta: 0.0017\n",
      "Epoch 4010/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 146.6922 - recon_loss: 3.4691e-04 - KL loss: 25.7764 - beta: 0.0017\n",
      "Epoch 04010: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 146.6922 - recon_loss: 3.4691e-04 - KL loss: 25.7763 - beta: 0.0017 - val_val_loss: 147.0218 - val_val_recon_loss: 3.4822e-04 - val_val_KL loss: 25.6501 - val_beta: 0.0017\n",
      "Epoch 4011/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 144.7813 - recon_loss: 3.4170e-04 - KL loss: 25.6796 - beta: 0.0017 - val_val_loss: 145.0844 - val_val_recon_loss: 3.4250e-04 - val_val_KL loss: 25.7035 - val_beta: 0.0017\n",
      "Epoch 4012/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 143.6515 - recon_loss: 3.3825e-04 - KL loss: 25.7538 - beta: 0.0017 - val_val_loss: 145.5449 - val_val_recon_loss: 3.4372e-04 - val_val_KL loss: 25.7393 - val_beta: 0.0017\n",
      "Epoch 4013/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 144.7207 - recon_loss: 3.4103e-04 - KL loss: 25.8545 - beta: 0.0017 - val_val_loss: 145.6275 - val_val_recon_loss: 3.4392e-04 - val_val_KL loss: 25.7538 - val_beta: 0.0017\n",
      "Epoch 4014/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 156s 156ms/step - loss: 142.5600 - recon_loss: 3.3529e-04 - KL loss: 25.6951 - beta: 0.0017 - val_val_loss: 145.0309 - val_val_recon_loss: 3.4243e-04 - val_val_KL loss: 25.6755 - val_beta: 0.0017\n",
      "Epoch 4015/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 144.2151 - recon_loss: 3.3999e-04 - KL loss: 25.7108 - beta: 0.0017 - val_val_loss: 144.7515 - val_val_recon_loss: 3.4131e-04 - val_val_KL loss: 25.7885 - val_beta: 0.0017\n",
      "Epoch 4016/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 143.3266 - recon_loss: 3.3728e-04 - KL loss: 25.7665 - beta: 0.0017 - val_val_loss: 144.9068 - val_val_recon_loss: 3.4175e-04 - val_val_KL loss: 25.7877 - val_beta: 0.0017\n",
      "Epoch 4017/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 144.1237 - recon_loss: 3.3954e-04 - KL loss: 25.7758 - beta: 0.0017 - val_val_loss: 144.9988 - val_val_recon_loss: 3.4221e-04 - val_val_KL loss: 25.7221 - val_beta: 0.0017\n",
      "Epoch 4018/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 141.5172 - recon_loss: 3.3200e-04 - KL loss: 25.7965 - beta: 0.0017 - val_val_loss: 144.7078 - val_val_recon_loss: 3.4103e-04 - val_val_KL loss: 25.8396 - val_beta: 0.0017\n",
      "Epoch 4019/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 143.5284 - recon_loss: 3.3774e-04 - KL loss: 25.8068 - beta: 0.0017 - val_val_loss: 143.9925 - val_val_recon_loss: 3.3912e-04 - val_val_KL loss: 25.7903 - val_beta: 0.0017\n",
      "Epoch 4020/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 142.8781 - recon_loss: 3.3594e-04 - KL loss: 25.7850 - beta: 0.0017 - val_val_loss: 143.5438 - val_val_recon_loss: 3.3814e-04 - val_val_KL loss: 25.6844 - val_beta: 0.0017\n",
      "Epoch 4021/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 141.9869 - recon_loss: 3.3349e-04 - KL loss: 25.7496 - beta: 0.0017 - val_val_loss: 144.0300 - val_val_recon_loss: 3.3972e-04 - val_val_KL loss: 25.6213 - val_beta: 0.0017\n",
      "Epoch 4022/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 143.0856 - recon_loss: 3.3677e-04 - KL loss: 25.7048 - beta: 0.0017 - val_val_loss: 143.5823 - val_val_recon_loss: 3.3788e-04 - val_val_KL loss: 25.8133 - val_beta: 0.0017\n",
      "Epoch 4023/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 142.0981 - recon_loss: 3.3385e-04 - KL loss: 25.7339 - beta: 0.0017 - val_val_loss: 142.9819 - val_val_recon_loss: 3.3640e-04 - val_val_KL loss: 25.7300 - val_beta: 0.0017\n",
      "Epoch 4024/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 141.9100 - recon_loss: 3.3344e-04 - KL loss: 25.6880 - beta: 0.0017 - val_val_loss: 143.7494 - val_val_recon_loss: 3.3875e-04 - val_val_KL loss: 25.6763 - val_beta: 0.0017\n",
      "Epoch 4025/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 142.1338 - recon_loss: 3.3396e-04 - KL loss: 25.7319 - beta: 0.0017 - val_val_loss: 143.2465 - val_val_recon_loss: 3.3728e-04 - val_val_KL loss: 25.6871 - val_beta: 0.0017\n",
      "Epoch 4026/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 141.2197 - recon_loss: 3.3139e-04 - KL loss: 25.7139 - beta: 0.0017 - val_val_loss: 142.8381 - val_val_recon_loss: 3.3627e-04 - val_val_KL loss: 25.6313 - val_beta: 0.0017\n",
      "Epoch 4027/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 141.6240 - recon_loss: 3.3247e-04 - KL loss: 25.7392 - beta: 0.0017 - val_val_loss: 143.1594 - val_val_recon_loss: 3.3727e-04 - val_val_KL loss: 25.6040 - val_beta: 0.0017\n",
      "Epoch 4028/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 141.8854 - recon_loss: 3.3344e-04 - KL loss: 25.6640 - beta: 0.0017 - val_val_loss: 143.5020 - val_val_recon_loss: 3.3807e-04 - val_val_KL loss: 25.6670 - val_beta: 0.0017\n",
      "Epoch 4029/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 142.1668 - recon_loss: 3.3408e-04 - KL loss: 25.7234 - beta: 0.0017 - val_val_loss: 143.7455 - val_val_recon_loss: 3.3864e-04 - val_val_KL loss: 25.7112 - val_beta: 0.0017\n",
      "Epoch 4030/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 142.2414 - recon_loss: 3.3425e-04 - KL loss: 25.7386 - beta: 0.0017 - val_val_loss: 143.0790 - val_val_recon_loss: 3.3661e-04 - val_val_KL loss: 25.7515 - val_beta: 0.0017\n",
      "Epoch 4031/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 141.4098 - recon_loss: 3.3213e-04 - KL loss: 25.6445 - beta: 0.0017 - val_val_loss: 142.4925 - val_val_recon_loss: 3.3510e-04 - val_val_KL loss: 25.6908 - val_beta: 0.0017\n",
      "Epoch 4032/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 141.7662 - recon_loss: 3.3291e-04 - KL loss: 25.7305 - beta: 0.0017 - val_val_loss: 143.0311 - val_val_recon_loss: 3.3679e-04 - val_val_KL loss: 25.6409 - val_beta: 0.0017\n",
      "Epoch 4033/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 140.9236 - recon_loss: 3.3052e-04 - KL loss: 25.7182 - beta: 0.0017 - val_val_loss: 142.8371 - val_val_recon_loss: 3.3626e-04 - val_val_KL loss: 25.6342 - val_beta: 0.0017\n",
      "Epoch 4034/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 141.3782 - recon_loss: 3.3204e-04 - KL loss: 25.6431 - beta: 0.0017 - val_val_loss: 143.4700 - val_val_recon_loss: 3.3797e-04 - val_val_KL loss: 25.6697 - val_beta: 0.0017\n",
      "Epoch 4035/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 142.2715 - recon_loss: 3.3427e-04 - KL loss: 25.7606 - beta: 0.0017 - val_val_loss: 142.8245 - val_val_recon_loss: 3.3613e-04 - val_val_KL loss: 25.6665 - val_beta: 0.0017\n",
      "Epoch 4036/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 141.7232 - recon_loss: 3.3283e-04 - KL loss: 25.7148 - beta: 0.0017\n",
      "Epoch 04036: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 141.7226 - recon_loss: 3.3283e-04 - KL loss: 25.7148 - beta: 0.0017 - val_val_loss: 142.7719 - val_val_recon_loss: 3.3595e-04 - val_val_KL loss: 25.6770 - val_beta: 0.0017\n",
      "Epoch 4037/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 142.6138 - recon_loss: 3.3557e-04 - KL loss: 25.6488 - beta: 0.0017 - val_val_loss: 142.2904 - val_val_recon_loss: 3.3475e-04 - val_val_KL loss: 25.6121 - val_beta: 0.0017\n",
      "Epoch 4038/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 140.8190 - recon_loss: 3.3052e-04 - KL loss: 25.6140 - beta: 0.0017 - val_val_loss: 141.8846 - val_val_recon_loss: 3.3365e-04 - val_val_KL loss: 25.5899 - val_beta: 0.0017\n",
      "Epoch 4039/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 140.3963 - recon_loss: 3.2923e-04 - KL loss: 25.6416 - beta: 0.0017 - val_val_loss: 142.1533 - val_val_recon_loss: 3.3448e-04 - val_val_KL loss: 25.5687 - val_beta: 0.0017\n",
      "Epoch 4040/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 140.7849 - recon_loss: 3.3040e-04 - KL loss: 25.6222 - beta: 0.0017 - val_val_loss: 141.9197 - val_val_recon_loss: 3.3363e-04 - val_val_KL loss: 25.6304 - val_beta: 0.0017\n",
      "Epoch 4041/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 139.5492 - recon_loss: 3.2672e-04 - KL loss: 25.6693 - beta: 0.0017 - val_val_loss: 142.1304 - val_val_recon_loss: 3.3433e-04 - val_val_KL loss: 25.5982 - val_beta: 0.0017\n",
      "Epoch 4042/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 139.6741 - recon_loss: 3.2726e-04 - KL loss: 25.6061 - beta: 0.0017 - val_val_loss: 142.0770 - val_val_recon_loss: 3.3398e-04 - val_val_KL loss: 25.6680 - val_beta: 0.0017\n",
      "Epoch 4043/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 140.6034 - recon_loss: 3.2966e-04 - KL loss: 25.7003 - beta: 0.0017\n",
      "Epoch 04043: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 140.6033 - recon_loss: 3.2966e-04 - KL loss: 25.7003 - beta: 0.0017 - val_val_loss: 142.1352 - val_val_recon_loss: 3.3436e-04 - val_val_KL loss: 25.5919 - val_beta: 0.0017\n",
      "Epoch 4044/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 156s 156ms/step - loss: 140.3836 - recon_loss: 3.2920e-04 - KL loss: 25.6400 - beta: 0.0017 - val_val_loss: 142.0058 - val_val_recon_loss: 3.3396e-04 - val_val_KL loss: 25.6042 - val_beta: 0.0017\n",
      "Epoch 4045/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 139.7889 - recon_loss: 3.2742e-04 - KL loss: 25.6663 - beta: 0.0017 - val_val_loss: 141.8732 - val_val_recon_loss: 3.3356e-04 - val_val_KL loss: 25.6093 - val_beta: 0.0017\n",
      "Epoch 4046/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 140.1793 - recon_loss: 3.2863e-04 - KL loss: 25.6332 - beta: 0.0017 - val_val_loss: 141.7715 - val_val_recon_loss: 3.3313e-04 - val_val_KL loss: 25.6579 - val_beta: 0.0017\n",
      "Epoch 4047/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 139.7910 - recon_loss: 3.2745e-04 - KL loss: 25.6589 - beta: 0.0017 - val_val_loss: 141.5583 - val_val_recon_loss: 3.3258e-04 - val_val_KL loss: 25.6369 - val_beta: 0.0017\n",
      "Epoch 4048/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 141.0191 - recon_loss: 3.3086e-04 - KL loss: 25.6968 - beta: 0.0017 - val_val_loss: 141.7459 - val_val_recon_loss: 3.3328e-04 - val_val_KL loss: 25.5785 - val_beta: 0.0017\n",
      "Epoch 4049/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 139.3034 - recon_loss: 3.2607e-04 - KL loss: 25.6508 - beta: 0.0017 - val_val_loss: 141.7027 - val_val_recon_loss: 3.3312e-04 - val_val_KL loss: 25.5932 - val_beta: 0.0017\n",
      "Epoch 4050/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 140.4254 - recon_loss: 3.2929e-04 - KL loss: 25.6504 - beta: 0.0017 - val_val_loss: 141.7775 - val_val_recon_loss: 3.3328e-04 - val_val_KL loss: 25.6117 - val_beta: 0.0017\n",
      "Epoch 4051/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 140.8591 - recon_loss: 3.3044e-04 - KL loss: 25.6843 - beta: 0.0017 - val_val_loss: 141.6514 - val_val_recon_loss: 3.3286e-04 - val_val_KL loss: 25.6313 - val_beta: 0.0017\n",
      "Epoch 4052/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 139.7351 - recon_loss: 3.2717e-04 - KL loss: 25.6995 - beta: 0.0017\n",
      "Epoch 04052: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 139.7351 - recon_loss: 3.2717e-04 - KL loss: 25.6994 - beta: 0.0017 - val_val_loss: 141.7149 - val_val_recon_loss: 3.3312e-04 - val_val_KL loss: 25.6043 - val_beta: 0.0017\n",
      "Epoch 4053/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 139.7446 - recon_loss: 3.2747e-04 - KL loss: 25.6056 - beta: 0.0017 - val_val_loss: 141.6791 - val_val_recon_loss: 3.3300e-04 - val_val_KL loss: 25.6100 - val_beta: 0.0017\n",
      "Epoch 4054/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 139.6771 - recon_loss: 3.2715e-04 - KL loss: 25.6486 - beta: 0.0017 - val_val_loss: 141.5432 - val_val_recon_loss: 3.3262e-04 - val_val_KL loss: 25.6090 - val_beta: 0.0017\n",
      "Epoch 4055/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 139.4770 - recon_loss: 3.2663e-04 - KL loss: 25.6287 - beta: 0.0017 - val_val_loss: 141.7185 - val_val_recon_loss: 3.3311e-04 - val_val_KL loss: 25.6108 - val_beta: 0.0017\n",
      "Epoch 4056/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 139.9351 - recon_loss: 3.2787e-04 - KL loss: 25.6536 - beta: 0.0017 - val_val_loss: 141.7523 - val_val_recon_loss: 3.3322e-04 - val_val_KL loss: 25.6089 - val_beta: 0.0017\n",
      "Epoch 4057/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 139.5156 - recon_loss: 3.2669e-04 - KL loss: 25.6459 - beta: 0.0017 - val_val_loss: 141.6522 - val_val_recon_loss: 3.3295e-04 - val_val_KL loss: 25.6031 - val_beta: 0.0017\n",
      "Epoch 4058/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 139.6214 - recon_loss: 3.2699e-04 - KL loss: 25.6495 - beta: 0.0017 - val_val_loss: 141.7757 - val_val_recon_loss: 3.3331e-04 - val_val_KL loss: 25.6012 - val_beta: 0.0017\n",
      "Epoch 4059/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 139.1953 - recon_loss: 3.2581e-04 - KL loss: 25.6329 - beta: 0.0017 - val_val_loss: 141.4422 - val_val_recon_loss: 3.3231e-04 - val_val_KL loss: 25.6137 - val_beta: 0.0017\n",
      "Epoch 4060/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 139.4275 - recon_loss: 3.2645e-04 - KL loss: 25.6437 - beta: 0.0017 - val_val_loss: 141.6372 - val_val_recon_loss: 3.3288e-04 - val_val_KL loss: 25.6110 - val_beta: 0.0017\n",
      "Epoch 4061/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 139.4895 - recon_loss: 3.2664e-04 - KL loss: 25.6373 - beta: 0.0017 - val_val_loss: 141.5603 - val_val_recon_loss: 3.3266e-04 - val_val_KL loss: 25.6104 - val_beta: 0.0017\n",
      "Epoch 4062/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 140.5516 - recon_loss: 3.2951e-04 - KL loss: 25.6992 - beta: 0.0017 - val_val_loss: 141.7192 - val_val_recon_loss: 3.3313e-04 - val_val_KL loss: 25.6048 - val_beta: 0.0017\n",
      "Epoch 4063/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 139.2982 - recon_loss: 3.2607e-04 - KL loss: 25.6460 - beta: 0.0017 - val_val_loss: 141.6381 - val_val_recon_loss: 3.3290e-04 - val_val_KL loss: 25.6053 - val_beta: 0.0017\n",
      "Epoch 4064/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 138.2119 - recon_loss: 3.2296e-04 - KL loss: 25.6418 - beta: 0.0017\n",
      "Epoch 04064: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 138.2133 - recon_loss: 3.2297e-04 - KL loss: 25.6418 - beta: 0.0017 - val_val_loss: 141.8773 - val_val_recon_loss: 3.3357e-04 - val_val_KL loss: 25.6088 - val_beta: 0.0017\n",
      "Epoch 4065/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 139.8651 - recon_loss: 3.2765e-04 - KL loss: 25.6622 - beta: 0.0017 - val_val_loss: 141.7239 - val_val_recon_loss: 3.3313e-04 - val_val_KL loss: 25.6115 - val_beta: 0.0017\n",
      "Epoch 4066/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 139.4273 - recon_loss: 3.2629e-04 - KL loss: 25.6963 - beta: 0.0017 - val_val_loss: 141.8948 - val_val_recon_loss: 3.3362e-04 - val_val_KL loss: 25.6114 - val_beta: 0.0017\n",
      "Epoch 4067/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 138.9355 - recon_loss: 3.2512e-04 - KL loss: 25.6149 - beta: 0.0017 - val_val_loss: 141.7932 - val_val_recon_loss: 3.3333e-04 - val_val_KL loss: 25.6117 - val_beta: 0.0017\n",
      "Epoch 4068/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 139.3964 - recon_loss: 3.2627e-04 - KL loss: 25.6745 - beta: 0.0017 - val_val_loss: 141.6010 - val_val_recon_loss: 3.3275e-04 - val_val_KL loss: 25.6197 - val_beta: 0.0017\n",
      "Epoch 4069/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 140.3380 - recon_loss: 3.2898e-04 - KL loss: 25.6710 - beta: 0.0017\n",
      "Epoch 04069: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 140.3378 - recon_loss: 3.2898e-04 - KL loss: 25.6709 - beta: 0.0017 - val_val_loss: 141.6688 - val_val_recon_loss: 3.3295e-04 - val_val_KL loss: 25.6165 - val_beta: 0.0017\n",
      "Epoch 4069/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 97.2376 - recon_loss: 3.5789e-04 - KL loss: 23.5917 - beta: 0.0022 - val_val_loss: 96.4256 - val_val_recon_loss: 3.5670e-04 - val_val_KL loss: 23.0246 - val_beta: 0.0022\n",
      "Epoch 4070/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 97.4151 - recon_loss: 3.6175e-04 - KL loss: 22.9736 - beta: 0.0022 - val_val_loss: 97.5732 - val_val_recon_loss: 3.6457e-04 - val_val_KL loss: 22.5526 - val_beta: 0.0022\n",
      "Epoch 4071/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 96.4053 - recon_loss: 3.5823e-04 - KL loss: 22.6898 - beta: 0.0022 - val_val_loss: 97.5668 - val_val_recon_loss: 3.6407e-04 - val_val_KL loss: 22.6482 - val_beta: 0.0022\n",
      "Epoch 4072/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 157s 157ms/step - loss: 99.5954 - recon_loss: 3.7227e-04 - KL loss: 22.9897 - beta: 0.0022 - val_val_loss: 97.2200 - val_val_recon_loss: 3.6258e-04 - val_val_KL loss: 22.6094 - val_beta: 0.0022\n",
      "Epoch 4073/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 95.3490 - recon_loss: 3.5355e-04 - KL loss: 22.5966 - beta: 0.0022 - val_val_loss: 97.4821 - val_val_recon_loss: 3.6511e-04 - val_val_KL loss: 22.3503 - val_beta: 0.0022\n",
      "Epoch 4074/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 99.3654 - recon_loss: 3.7408e-04 - KL loss: 22.3873 - beta: 0.0022\n",
      "Epoch 04074: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 99.3666 - recon_loss: 3.7409e-04 - KL loss: 22.3872 - beta: 0.0022 - val_val_loss: 99.9790 - val_val_recon_loss: 3.7489e-04 - val_val_KL loss: 22.8340 - val_beta: 0.0022\n",
      "Epoch 4075/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 97.1701 - recon_loss: 3.6278e-04 - KL loss: 22.5179 - beta: 0.0022 - val_val_loss: 96.0884 - val_val_recon_loss: 3.5814e-04 - val_val_KL loss: 22.3906 - val_beta: 0.0022\n",
      "Epoch 4076/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 95.4480 - recon_loss: 3.5490e-04 - KL loss: 22.4170 - beta: 0.0022 - val_val_loss: 94.8955 - val_val_recon_loss: 3.5184e-04 - val_val_KL loss: 22.4949 - val_beta: 0.0022\n",
      "Epoch 4077/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 94.1058 - recon_loss: 3.4847e-04 - KL loss: 22.3979 - beta: 0.0022 - val_val_loss: 94.2749 - val_val_recon_loss: 3.4850e-04 - val_val_KL loss: 22.5603 - val_beta: 0.0022\n",
      "Epoch 4078/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 94.4480 - recon_loss: 3.4971e-04 - KL loss: 22.4845 - beta: 0.0022 - val_val_loss: 93.7707 - val_val_recon_loss: 3.4702e-04 - val_val_KL loss: 22.3608 - val_beta: 0.0022\n",
      "Epoch 4079/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 93.0517 - recon_loss: 3.4345e-04 - KL loss: 22.3758 - beta: 0.0022 - val_val_loss: 93.7646 - val_val_recon_loss: 3.4763e-04 - val_val_KL loss: 22.2292 - val_beta: 0.0022\n",
      "Epoch 4080/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 92.8339 - recon_loss: 3.4223e-04 - KL loss: 22.4095 - beta: 0.0022 - val_val_loss: 92.6923 - val_val_recon_loss: 3.4198e-04 - val_val_KL loss: 22.3192 - val_beta: 0.0022\n",
      "Epoch 4081/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 91.9541 - recon_loss: 3.3798e-04 - KL loss: 22.4046 - beta: 0.0022 - val_val_loss: 92.4915 - val_val_recon_loss: 3.4054e-04 - val_val_KL loss: 22.4154 - val_beta: 0.0022\n",
      "Epoch 4082/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 92.4997 - recon_loss: 3.4072e-04 - KL loss: 22.3860 - beta: 0.0022 - val_val_loss: 92.6317 - val_val_recon_loss: 3.4079e-04 - val_val_KL loss: 22.5045 - val_beta: 0.0022\n",
      "Epoch 4083/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 92.1553 - recon_loss: 3.3860e-04 - KL loss: 22.4788 - beta: 0.0022 - val_val_loss: 92.1352 - val_val_recon_loss: 3.3926e-04 - val_val_KL loss: 22.3233 - val_beta: 0.0022\n",
      "Epoch 4084/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 91.4542 - recon_loss: 3.3555e-04 - KL loss: 22.4045 - beta: 0.0022 - val_val_loss: 92.3614 - val_val_recon_loss: 3.4028e-04 - val_val_KL loss: 22.3378 - val_beta: 0.0022\n",
      "Epoch 4085/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 91.4651 - recon_loss: 3.3614e-04 - KL loss: 22.2952 - beta: 0.0022 - val_val_loss: 93.1550 - val_val_recon_loss: 3.4310e-04 - val_val_KL loss: 22.5529 - val_beta: 0.0022\n",
      "Epoch 4086/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 92.7997 - recon_loss: 3.4105e-04 - KL loss: 22.6189 - beta: 0.0022 - val_val_loss: 92.3115 - val_val_recon_loss: 3.3920e-04 - val_val_KL loss: 22.5115 - val_beta: 0.0022\n",
      "Epoch 4087/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 93.0593 - recon_loss: 3.4264e-04 - KL loss: 22.5501 - beta: 0.0022 - val_val_loss: 92.5377 - val_val_recon_loss: 3.3927e-04 - val_val_KL loss: 22.7223 - val_beta: 0.0022\n",
      "Epoch 4088/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 91.3834 - recon_loss: 3.3534e-04 - KL loss: 22.3781 - beta: 0.0022 - val_val_loss: 91.7182 - val_val_recon_loss: 3.3706e-04 - val_val_KL loss: 22.3576 - val_beta: 0.0022\n",
      "Epoch 4089/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 91.8373 - recon_loss: 3.3739e-04 - KL loss: 22.4094 - beta: 0.0022 - val_val_loss: 92.1940 - val_val_recon_loss: 3.3991e-04 - val_val_KL loss: 22.2470 - val_beta: 0.0022\n",
      "Epoch 4090/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 92.5555 - recon_loss: 3.4078e-04 - KL loss: 22.4291 - beta: 0.0022 - val_val_loss: 92.2132 - val_val_recon_loss: 3.3824e-04 - val_val_KL loss: 22.6096 - val_beta: 0.0022\n",
      "Epoch 4091/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 91.5051 - recon_loss: 3.3594e-04 - KL loss: 22.3755 - beta: 0.0022 - val_val_loss: 92.7481 - val_val_recon_loss: 3.4249e-04 - val_val_KL loss: 22.2703 - val_beta: 0.0022\n",
      "Epoch 4092/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 91.4957 - recon_loss: 3.3590e-04 - KL loss: 22.3750 - beta: 0.0022 - val_val_loss: 91.6590 - val_val_recon_loss: 3.3676e-04 - val_val_KL loss: 22.3600 - val_beta: 0.0022\n",
      "Epoch 4093/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 92.1736 - recon_loss: 3.3898e-04 - KL loss: 22.4188 - beta: 0.0022 - val_val_loss: 92.6327 - val_val_recon_loss: 3.4119e-04 - val_val_KL loss: 22.4224 - val_beta: 0.0022\n",
      "Epoch 4094/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 92.1003 - recon_loss: 3.3848e-04 - KL loss: 22.4485 - beta: 0.0022 - val_val_loss: 92.6894 - val_val_recon_loss: 3.4113e-04 - val_val_KL loss: 22.4922 - val_beta: 0.0022\n",
      "Epoch 4095/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 92.0029 - recon_loss: 3.3782e-04 - KL loss: 22.4869 - beta: 0.0022 - val_val_loss: 91.9445 - val_val_recon_loss: 3.3830e-04 - val_val_KL loss: 22.3286 - val_beta: 0.0022\n",
      "Epoch 4096/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 91.6258 - recon_loss: 3.3648e-04 - KL loss: 22.3843 - beta: 0.0022 - val_val_loss: 92.7200 - val_val_recon_loss: 3.4057e-04 - val_val_KL loss: 22.6383 - val_beta: 0.0022\n",
      "Epoch 4097/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 91.8424 - recon_loss: 3.3744e-04 - KL loss: 22.4034 - beta: 0.0022 - val_val_loss: 91.5652 - val_val_recon_loss: 3.3593e-04 - val_val_KL loss: 22.4369 - val_beta: 0.0022\n",
      "Epoch 4098/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 90.7422 - recon_loss: 3.3255e-04 - KL loss: 22.3101 - beta: 0.0022 - val_val_loss: 91.7510 - val_val_recon_loss: 3.3599e-04 - val_val_KL loss: 22.6111 - val_beta: 0.0022\n",
      "Epoch 4099/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 90.6570 - recon_loss: 3.3129e-04 - KL loss: 22.4848 - beta: 0.0022 - val_val_loss: 91.2183 - val_val_recon_loss: 3.3464e-04 - val_val_KL loss: 22.3570 - val_beta: 0.0022\n",
      "Epoch 4100/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 90.7589 - recon_loss: 3.3241e-04 - KL loss: 22.3548 - beta: 0.0022 - val_val_loss: 91.1227 - val_val_recon_loss: 3.3366e-04 - val_val_KL loss: 22.4631 - val_beta: 0.0022\n",
      "Epoch 4101/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 92.0909 - recon_loss: 3.3896e-04 - KL loss: 22.3390 - beta: 0.0022 - val_val_loss: 92.5185 - val_val_recon_loss: 3.4020e-04 - val_val_KL loss: 22.5113 - val_beta: 0.0022\n",
      "Epoch 4102/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 91.9233 - recon_loss: 3.3750e-04 - KL loss: 22.4732 - beta: 0.0022 - val_val_loss: 92.4707 - val_val_recon_loss: 3.4004e-04 - val_val_KL loss: 22.4969 - val_beta: 0.0022\n",
      "Epoch 4103/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 157s 157ms/step - loss: 91.7205 - recon_loss: 3.3657e-04 - KL loss: 22.4605 - beta: 0.0022 - val_val_loss: 92.0027 - val_val_recon_loss: 3.3765e-04 - val_val_KL loss: 22.5212 - val_beta: 0.0022\n",
      "Epoch 4104/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 91.3140 - recon_loss: 3.3472e-04 - KL loss: 22.4354 - beta: 0.0022 - val_val_loss: 91.9161 - val_val_recon_loss: 3.3824e-04 - val_val_KL loss: 22.3139 - val_beta: 0.0022\n",
      "Epoch 4105/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 92.0486 - recon_loss: 3.3839e-04 - KL loss: 22.4154 - beta: 0.0022\n",
      "Epoch 04105: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 92.0480 - recon_loss: 3.3838e-04 - KL loss: 22.4154 - beta: 0.0022 - val_val_loss: 91.9046 - val_val_recon_loss: 3.3773e-04 - val_val_KL loss: 22.4060 - val_beta: 0.0022\n",
      "Epoch 4106/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 90.2330 - recon_loss: 3.2959e-04 - KL loss: 22.4108 - beta: 0.0022 - val_val_loss: 91.1269 - val_val_recon_loss: 3.3395e-04 - val_val_KL loss: 22.4058 - val_beta: 0.0022\n",
      "Epoch 4107/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 89.9472 - recon_loss: 3.2857e-04 - KL loss: 22.3340 - beta: 0.0022 - val_val_loss: 90.8896 - val_val_recon_loss: 3.3261e-04 - val_val_KL loss: 22.4452 - val_beta: 0.0022\n",
      "Epoch 4108/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 91.0821 - recon_loss: 3.3371e-04 - KL loss: 22.4116 - beta: 0.0022 - val_val_loss: 91.1243 - val_val_recon_loss: 3.3331e-04 - val_val_KL loss: 22.5359 - val_beta: 0.0022\n",
      "Epoch 4109/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 90.3787 - recon_loss: 3.2970e-04 - KL loss: 22.5341 - beta: 0.0022 - val_val_loss: 90.8250 - val_val_recon_loss: 3.3279e-04 - val_val_KL loss: 22.3441 - val_beta: 0.0022\n",
      "Epoch 4110/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 90.1170 - recon_loss: 3.2880e-04 - KL loss: 22.4564 - beta: 0.0022 - val_val_loss: 90.8725 - val_val_recon_loss: 3.3299e-04 - val_val_KL loss: 22.3508 - val_beta: 0.0022\n",
      "Epoch 4111/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 89.6294 - recon_loss: 3.2696e-04 - KL loss: 22.3478 - beta: 0.0022 - val_val_loss: 90.7299 - val_val_recon_loss: 3.3172e-04 - val_val_KL loss: 22.4680 - val_beta: 0.0022\n",
      "Epoch 4112/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 89.6048 - recon_loss: 3.2644e-04 - KL loss: 22.4291 - beta: 0.0022 - val_val_loss: 90.6391 - val_val_recon_loss: 3.3180e-04 - val_val_KL loss: 22.3622 - val_beta: 0.0022\n",
      "Epoch 4113/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 90.2969 - recon_loss: 3.3009e-04 - KL loss: 22.3717 - beta: 0.0022 - val_val_loss: 90.6866 - val_val_recon_loss: 3.3177e-04 - val_val_KL loss: 22.4160 - val_beta: 0.0022\n",
      "Epoch 4114/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 90.2103 - recon_loss: 3.2917e-04 - KL loss: 22.4738 - beta: 0.0022 - val_val_loss: 90.7759 - val_val_recon_loss: 3.3277e-04 - val_val_KL loss: 22.2995 - val_beta: 0.0022\n",
      "Epoch 4115/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 89.8089 - recon_loss: 3.2746e-04 - KL loss: 22.4242 - beta: 0.0022 - val_val_loss: 90.4860 - val_val_recon_loss: 3.3067e-04 - val_val_KL loss: 22.4414 - val_beta: 0.0022\n",
      "Epoch 4116/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 89.4715 - recon_loss: 3.2601e-04 - KL loss: 22.3858 - beta: 0.0022 - val_val_loss: 90.7404 - val_val_recon_loss: 3.3176e-04 - val_val_KL loss: 22.4708 - val_beta: 0.0022\n",
      "Epoch 4117/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 90.0825 - recon_loss: 3.2886e-04 - KL loss: 22.4090 - beta: 0.0022 - val_val_loss: 90.7372 - val_val_recon_loss: 3.3234e-04 - val_val_KL loss: 22.3480 - val_beta: 0.0022\n",
      "Epoch 4118/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 89.9563 - recon_loss: 3.2829e-04 - KL loss: 22.4011 - beta: 0.0022 - val_val_loss: 90.4293 - val_val_recon_loss: 3.3098e-04 - val_val_KL loss: 22.3201 - val_beta: 0.0022\n",
      "Epoch 4119/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 90.2443 - recon_loss: 3.2970e-04 - KL loss: 22.3983 - beta: 0.0022 - val_val_loss: 91.1247 - val_val_recon_loss: 3.3262e-04 - val_val_KL loss: 22.6774 - val_beta: 0.0022\n",
      "Epoch 4120/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 89.9486 - recon_loss: 3.2823e-04 - KL loss: 22.4055 - beta: 0.0022 - val_val_loss: 90.5756 - val_val_recon_loss: 3.3196e-04 - val_val_KL loss: 22.2653 - val_beta: 0.0022\n",
      "Epoch 4121/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 89.4247 - recon_loss: 3.2621e-04 - KL loss: 22.2969 - beta: 0.0022 - val_val_loss: 90.2939 - val_val_recon_loss: 3.3001e-04 - val_val_KL loss: 22.3839 - val_beta: 0.0022\n",
      "Epoch 4122/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 90.2128 - recon_loss: 3.2973e-04 - KL loss: 22.3602 - beta: 0.0022 - val_val_loss: 90.5650 - val_val_recon_loss: 3.3194e-04 - val_val_KL loss: 22.2591 - val_beta: 0.0022\n",
      "Epoch 4123/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 89.8706 - recon_loss: 3.2793e-04 - KL loss: 22.3893 - beta: 0.0022 - val_val_loss: 90.5138 - val_val_recon_loss: 3.3114e-04 - val_val_KL loss: 22.3728 - val_beta: 0.0022\n",
      "Epoch 4124/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 90.0071 - recon_loss: 3.2852e-04 - KL loss: 22.4034 - beta: 0.0022 - val_val_loss: 90.4778 - val_val_recon_loss: 3.3117e-04 - val_val_KL loss: 22.3295 - val_beta: 0.0022\n",
      "Epoch 4125/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 89.7563 - recon_loss: 3.2740e-04 - KL loss: 22.3834 - beta: 0.0022 - val_val_loss: 90.3679 - val_val_recon_loss: 3.2995e-04 - val_val_KL loss: 22.4706 - val_beta: 0.0022\n",
      "Epoch 4126/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 89.5168 - recon_loss: 3.2590e-04 - KL loss: 22.4530 - beta: 0.0022\n",
      "Epoch 04126: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 89.5169 - recon_loss: 3.2590e-04 - KL loss: 22.4529 - beta: 0.0022 - val_val_loss: 90.3320 - val_val_recon_loss: 3.3081e-04 - val_val_KL loss: 22.2586 - val_beta: 0.0022\n",
      "Epoch 4127/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 89.2597 - recon_loss: 3.2504e-04 - KL loss: 22.3730 - beta: 0.0022 - val_val_loss: 90.2422 - val_val_recon_loss: 3.2974e-04 - val_val_KL loss: 22.3875 - val_beta: 0.0022\n",
      "Epoch 4128/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 89.6527 - recon_loss: 3.2684e-04 - KL loss: 22.3965 - beta: 0.0022 - val_val_loss: 90.1943 - val_val_recon_loss: 3.2934e-04 - val_val_KL loss: 22.4218 - val_beta: 0.0022\n",
      "Epoch 4129/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 89.4479 - recon_loss: 3.2550e-04 - KL loss: 22.4674 - beta: 0.0022 - val_val_loss: 90.2185 - val_val_recon_loss: 3.3019e-04 - val_val_KL loss: 22.2715 - val_beta: 0.0022\n",
      "Epoch 4130/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 89.3792 - recon_loss: 3.2554e-04 - KL loss: 22.3889 - beta: 0.0022 - val_val_loss: 90.1498 - val_val_recon_loss: 3.2917e-04 - val_val_KL loss: 22.4138 - val_beta: 0.0022\n",
      "Epoch 4131/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 89.0375 - recon_loss: 3.2368e-04 - KL loss: 22.4313 - beta: 0.0022 - val_val_loss: 90.1438 - val_val_recon_loss: 3.2944e-04 - val_val_KL loss: 22.3515 - val_beta: 0.0022\n",
      "Epoch 4132/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 89.1639 - recon_loss: 3.2460e-04 - KL loss: 22.3674 - beta: 0.0022 - val_val_loss: 90.0719 - val_val_recon_loss: 3.2892e-04 - val_val_KL loss: 22.3865 - val_beta: 0.0022\n",
      "Epoch 4133/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 158s 158ms/step - loss: 89.5000 - recon_loss: 3.2620e-04 - KL loss: 22.3746 - beta: 0.0022 - val_val_loss: 90.1354 - val_val_recon_loss: 3.2886e-04 - val_val_KL loss: 22.4627 - val_beta: 0.0022\n",
      "Epoch 4134/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 89.5506 - recon_loss: 3.2600e-04 - KL loss: 22.4655 - beta: 0.0022 - val_val_loss: 90.0505 - val_val_recon_loss: 3.2942e-04 - val_val_KL loss: 22.2632 - val_beta: 0.0022\n",
      "Epoch 4135/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 89.2063 - recon_loss: 3.2502e-04 - KL loss: 22.3235 - beta: 0.0022 - val_val_loss: 89.9261 - val_val_recon_loss: 3.2853e-04 - val_val_KL loss: 22.3213 - val_beta: 0.0022\n",
      "Epoch 4136/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 88.9628 - recon_loss: 3.2359e-04 - KL loss: 22.3754 - beta: 0.0022 - val_val_loss: 90.0680 - val_val_recon_loss: 3.2842e-04 - val_val_KL loss: 22.4860 - val_beta: 0.0022\n",
      "Epoch 4137/10000\n",
      "1000/1000 [==============================] - 160s 160ms/step - loss: 88.9390 - recon_loss: 3.2319e-04 - KL loss: 22.4322 - beta: 0.0022 - val_val_loss: 90.1932 - val_val_recon_loss: 3.2968e-04 - val_val_KL loss: 22.3508 - val_beta: 0.0022\n",
      "Epoch 4138/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 89.1945 - recon_loss: 3.2477e-04 - KL loss: 22.3640 - beta: 0.0022 - val_val_loss: 89.9252 - val_val_recon_loss: 3.2855e-04 - val_val_KL loss: 22.3164 - val_beta: 0.0022\n",
      "Epoch 4139/10000\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 89.5177 - recon_loss: 3.2619e-04 - KL loss: 22.3946 - beta: 0.0022 - val_val_loss: 90.0689 - val_val_recon_loss: 3.2923e-04 - val_val_KL loss: 22.3206 - val_beta: 0.0022\n",
      "Epoch 4140/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 89.0720 - recon_loss: 3.2416e-04 - KL loss: 22.3663 - beta: 0.0022 - val_val_loss: 90.3154 - val_val_recon_loss: 3.3036e-04 - val_val_KL loss: 22.3340 - val_beta: 0.0022\n",
      "Epoch 4141/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 89.2084 - recon_loss: 3.2461e-04 - KL loss: 22.4111 - beta: 0.0022 - val_val_loss: 90.1256 - val_val_recon_loss: 3.2948e-04 - val_val_KL loss: 22.3252 - val_beta: 0.0022\n",
      "Epoch 4142/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 89.4402 - recon_loss: 3.2585e-04 - KL loss: 22.3864 - beta: 0.0022 - val_val_loss: 89.9920 - val_val_recon_loss: 3.2857e-04 - val_val_KL loss: 22.3785 - val_beta: 0.0022\n",
      "Epoch 4143/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 89.2347 - recon_loss: 3.2476e-04 - KL loss: 22.4047 - beta: 0.0022\n",
      "Epoch 04143: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 89.2348 - recon_loss: 3.2477e-04 - KL loss: 22.4047 - beta: 0.0022 - val_val_loss: 90.0567 - val_val_recon_loss: 3.2891e-04 - val_val_KL loss: 22.3734 - val_beta: 0.0022\n",
      "Epoch 4144/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 88.7951 - recon_loss: 3.2267e-04 - KL loss: 22.3960 - beta: 0.0022 - val_val_loss: 90.0889 - val_val_recon_loss: 3.2916e-04 - val_val_KL loss: 22.3538 - val_beta: 0.0022\n",
      "Epoch 4145/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 89.1492 - recon_loss: 3.2449e-04 - KL loss: 22.3749 - beta: 0.0022 - val_val_loss: 89.9381 - val_val_recon_loss: 3.2834e-04 - val_val_KL loss: 22.3732 - val_beta: 0.0022\n",
      "Epoch 4146/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 88.8082 - recon_loss: 3.2268e-04 - KL loss: 22.4082 - beta: 0.0022 - val_val_loss: 89.9941 - val_val_recon_loss: 3.2868e-04 - val_val_KL loss: 22.3584 - val_beta: 0.0022\n",
      "Epoch 4147/10000\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 88.7232 - recon_loss: 3.2242e-04 - KL loss: 22.3755 - beta: 0.0022 - val_val_loss: 90.0198 - val_val_recon_loss: 3.2899e-04 - val_val_KL loss: 22.3211 - val_beta: 0.0022\n",
      "Epoch 4148/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 89.6756 - recon_loss: 3.2687e-04 - KL loss: 22.4121 - beta: 0.0022\n",
      "Epoch 04148: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 89.6755 - recon_loss: 3.2687e-04 - KL loss: 22.4121 - beta: 0.0022 - val_val_loss: 89.9897 - val_val_recon_loss: 3.2847e-04 - val_val_KL loss: 22.3963 - val_beta: 0.0022\n",
      "Epoch 4148/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 63.6565 - recon_loss: 3.5697e-04 - KL loss: 20.2883 - beta: 0.0029 - val_val_loss: 63.7559 - val_val_recon_loss: 3.6158e-04 - val_val_KL loss: 19.8281 - val_beta: 0.0029\n",
      "Epoch 4149/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 64.2579 - recon_loss: 3.6562e-04 - KL loss: 19.8390 - beta: 0.0029 - val_val_loss: 65.4277 - val_val_recon_loss: 3.7569e-04 - val_val_KL loss: 19.7850 - val_beta: 0.0029\n",
      "Epoch 4150/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 65.3008 - recon_loss: 3.7400e-04 - KL loss: 19.8640 - beta: 0.0029 - val_val_loss: 67.6726 - val_val_recon_loss: 3.9295e-04 - val_val_KL loss: 19.9338 - val_beta: 0.0029\n",
      "Epoch 4151/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 66.5323 - recon_loss: 3.8373e-04 - KL loss: 19.9128 - beta: 0.0029 - val_val_loss: 65.5452 - val_val_recon_loss: 3.7742e-04 - val_val_KL loss: 19.6926 - val_beta: 0.0029\n",
      "Epoch 4152/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 65.6338 - recon_loss: 3.7718e-04 - KL loss: 19.8105 - beta: 0.0029 - val_val_loss: 65.2680 - val_val_recon_loss: 3.7589e-04 - val_val_KL loss: 19.6014 - val_beta: 0.0029\n",
      "Epoch 4153/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 65.3024 - recon_loss: 3.7675e-04 - KL loss: 19.5318 - beta: 0.0029\n",
      "Epoch 04153: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 65.3018 - recon_loss: 3.7674e-04 - KL loss: 19.5318 - beta: 0.0029 - val_val_loss: 65.7626 - val_val_recon_loss: 3.7976e-04 - val_val_KL loss: 19.6259 - val_beta: 0.0029\n",
      "Epoch 4154/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 64.1295 - recon_loss: 3.6688e-04 - KL loss: 19.5580 - beta: 0.0029 - val_val_loss: 63.3046 - val_val_recon_loss: 3.5989e-04 - val_val_KL loss: 19.5814 - val_beta: 0.0029\n",
      "Epoch 4155/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 62.6068 - recon_loss: 3.5437e-04 - KL loss: 19.5552 - beta: 0.0029 - val_val_loss: 62.7706 - val_val_recon_loss: 3.5486e-04 - val_val_KL loss: 19.6592 - val_beta: 0.0029\n",
      "Epoch 4156/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 62.8224 - recon_loss: 3.5560e-04 - KL loss: 19.6214 - beta: 0.0029 - val_val_loss: 62.5555 - val_val_recon_loss: 3.5372e-04 - val_val_KL loss: 19.5826 - val_beta: 0.0029\n",
      "Epoch 4157/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 62.3987 - recon_loss: 3.5225e-04 - KL loss: 19.6045 - beta: 0.0029 - val_val_loss: 62.3497 - val_val_recon_loss: 3.5173e-04 - val_val_KL loss: 19.6179 - val_beta: 0.0029\n",
      "Epoch 4158/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 62.5214 - recon_loss: 3.5344e-04 - KL loss: 19.5827 - beta: 0.0029 - val_val_loss: 62.2162 - val_val_recon_loss: 3.5119e-04 - val_val_KL loss: 19.5499 - val_beta: 0.0029\n",
      "Epoch 4159/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.9064 - recon_loss: 3.4867e-04 - KL loss: 19.5463 - beta: 0.0029 - val_val_loss: 62.0354 - val_val_recon_loss: 3.4917e-04 - val_val_KL loss: 19.6156 - val_beta: 0.0029\n",
      "Epoch 4160/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 62.2872 - recon_loss: 3.5170e-04 - KL loss: 19.5589 - beta: 0.0029 - val_val_loss: 63.0827 - val_val_recon_loss: 3.5959e-04 - val_val_KL loss: 19.3970 - val_beta: 0.0029\n",
      "Epoch 4161/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 62.2142 - recon_loss: 3.5191e-04 - KL loss: 19.4604 - beta: 0.0029 - val_val_loss: 63.4514 - val_val_recon_loss: 3.6009e-04 - val_val_KL loss: 19.7038 - val_beta: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4162/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 62.1479 - recon_loss: 3.5169e-04 - KL loss: 19.4209 - beta: 0.0029 - val_val_loss: 62.9505 - val_val_recon_loss: 3.5583e-04 - val_val_KL loss: 19.7204 - val_beta: 0.0029\n",
      "Epoch 4163/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 62.0327 - recon_loss: 3.4999e-04 - KL loss: 19.5122 - beta: 0.0029 - val_val_loss: 62.7183 - val_val_recon_loss: 3.5656e-04 - val_val_KL loss: 19.4004 - val_beta: 0.0029\n",
      "Epoch 4164/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 62.3337 - recon_loss: 3.5277e-04 - KL loss: 19.4758 - beta: 0.0029\n",
      "Epoch 04164: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 62.3337 - recon_loss: 3.5277e-04 - KL loss: 19.4758 - beta: 0.0029 - val_val_loss: 62.8289 - val_val_recon_loss: 3.5747e-04 - val_val_KL loss: 19.3997 - val_beta: 0.0029\n",
      "Epoch 4165/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 62.4397 - recon_loss: 3.5334e-04 - KL loss: 19.5133 - beta: 0.0029 - val_val_loss: 62.1285 - val_val_recon_loss: 3.5040e-04 - val_val_KL loss: 19.5585 - val_beta: 0.0029\n",
      "Epoch 4166/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.7878 - recon_loss: 3.4754e-04 - KL loss: 19.5657 - beta: 0.0029 - val_val_loss: 62.1541 - val_val_recon_loss: 3.5148e-04 - val_val_KL loss: 19.4531 - val_beta: 0.0029\n",
      "Epoch 4167/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.7550 - recon_loss: 3.4793e-04 - KL loss: 19.4858 - beta: 0.0029 - val_val_loss: 62.2819 - val_val_recon_loss: 3.5251e-04 - val_val_KL loss: 19.4563 - val_beta: 0.0029\n",
      "Epoch 4168/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.9585 - recon_loss: 3.4933e-04 - KL loss: 19.5187 - beta: 0.0029 - val_val_loss: 62.0515 - val_val_recon_loss: 3.5031e-04 - val_val_KL loss: 19.4930 - val_beta: 0.0029\n",
      "Epoch 4169/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 62.0261 - recon_loss: 3.5027e-04 - KL loss: 19.4718 - beta: 0.0029 - val_val_loss: 61.9234 - val_val_recon_loss: 3.4951e-04 - val_val_KL loss: 19.4616 - val_beta: 0.0029\n",
      "Epoch 4170/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.1827 - recon_loss: 3.4379e-04 - KL loss: 19.4164 - beta: 0.0029 - val_val_loss: 61.9433 - val_val_recon_loss: 3.5015e-04 - val_val_KL loss: 19.4040 - val_beta: 0.0029\n",
      "Epoch 4171/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.1936 - recon_loss: 3.4364e-04 - KL loss: 19.4447 - beta: 0.0029 - val_val_loss: 61.7945 - val_val_recon_loss: 3.4799e-04 - val_val_KL loss: 19.5178 - val_beta: 0.0029\n",
      "Epoch 4172/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.2955 - recon_loss: 3.4397e-04 - KL loss: 19.5071 - beta: 0.0029 - val_val_loss: 61.8388 - val_val_recon_loss: 3.4898e-04 - val_val_KL loss: 19.4415 - val_beta: 0.0029\n",
      "Epoch 4173/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.1496 - recon_loss: 3.4297e-04 - KL loss: 19.4827 - beta: 0.0029 - val_val_loss: 61.6349 - val_val_recon_loss: 3.4693e-04 - val_val_KL loss: 19.4862 - val_beta: 0.0029\n",
      "Epoch 4174/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.3794 - recon_loss: 3.4483e-04 - KL loss: 19.4866 - beta: 0.0029 - val_val_loss: 61.8763 - val_val_recon_loss: 3.4974e-04 - val_val_KL loss: 19.3865 - val_beta: 0.0029\n",
      "Epoch 4175/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 61.3099 - recon_loss: 3.4469e-04 - KL loss: 19.4334 - beta: 0.0029 - val_val_loss: 61.7123 - val_val_recon_loss: 3.4729e-04 - val_val_KL loss: 19.5200 - val_beta: 0.0029\n",
      "Epoch 4176/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.4236 - recon_loss: 3.4480e-04 - KL loss: 19.5341 - beta: 0.0029 - val_val_loss: 61.7229 - val_val_recon_loss: 3.4780e-04 - val_val_KL loss: 19.4688 - val_beta: 0.0029\n",
      "Epoch 4177/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.3432 - recon_loss: 3.4492e-04 - KL loss: 19.4397 - beta: 0.0029 - val_val_loss: 61.6089 - val_val_recon_loss: 3.4719e-04 - val_val_KL loss: 19.4292 - val_beta: 0.0029\n",
      "Epoch 4178/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 61.0336 - recon_loss: 3.4233e-04 - KL loss: 19.4443 - beta: 0.0029 - val_val_loss: 61.5777 - val_val_recon_loss: 3.4652e-04 - val_val_KL loss: 19.4791 - val_beta: 0.0029\n",
      "Epoch 4179/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.3937 - recon_loss: 3.4519e-04 - KL loss: 19.4573 - beta: 0.0029 - val_val_loss: 61.4662 - val_val_recon_loss: 3.4587e-04 - val_val_KL loss: 19.4473 - val_beta: 0.0029\n",
      "Epoch 4180/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.9159 - recon_loss: 3.4124e-04 - KL loss: 19.4595 - beta: 0.0029 - val_val_loss: 61.4763 - val_val_recon_loss: 3.4614e-04 - val_val_KL loss: 19.4239 - val_beta: 0.0029\n",
      "Epoch 4181/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.4090 - recon_loss: 3.4505e-04 - KL loss: 19.4897 - beta: 0.0029 - val_val_loss: 61.6034 - val_val_recon_loss: 3.4714e-04 - val_val_KL loss: 19.4293 - val_beta: 0.0029\n",
      "Epoch 4182/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.1812 - recon_loss: 3.4337e-04 - KL loss: 19.4661 - beta: 0.0029 - val_val_loss: 61.4778 - val_val_recon_loss: 3.4628e-04 - val_val_KL loss: 19.4086 - val_beta: 0.0029\n",
      "Epoch 4183/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.2328 - recon_loss: 3.4327e-04 - KL loss: 19.5295 - beta: 0.0029 - val_val_loss: 61.3715 - val_val_recon_loss: 3.4511e-04 - val_val_KL loss: 19.4439 - val_beta: 0.0029\n",
      "Epoch 4184/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.7726 - recon_loss: 3.3989e-04 - KL loss: 19.4802 - beta: 0.0029 - val_val_loss: 61.4817 - val_val_recon_loss: 3.4582e-04 - val_val_KL loss: 19.4690 - val_beta: 0.0029\n",
      "Epoch 4185/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.8628 - recon_loss: 3.4043e-04 - KL loss: 19.5040 - beta: 0.0029 - val_val_loss: 61.3933 - val_val_recon_loss: 3.4503e-04 - val_val_KL loss: 19.4758 - val_beta: 0.0029\n",
      "Epoch 4186/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 61.5263 - recon_loss: 3.4608e-04 - KL loss: 19.4811 - beta: 0.0029 - val_val_loss: 61.4303 - val_val_recon_loss: 3.4480e-04 - val_val_KL loss: 19.5410 - val_beta: 0.0029\n",
      "Epoch 4187/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.9857 - recon_loss: 3.4164e-04 - KL loss: 19.4798 - beta: 0.0029 - val_val_loss: 61.2998 - val_val_recon_loss: 3.4450e-04 - val_val_KL loss: 19.4469 - val_beta: 0.0029\n",
      "Epoch 4188/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.1967 - recon_loss: 3.4345e-04 - KL loss: 19.4711 - beta: 0.0029 - val_val_loss: 61.2104 - val_val_recon_loss: 3.4409e-04 - val_val_KL loss: 19.4076 - val_beta: 0.0029\n",
      "Epoch 4189/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.8117 - recon_loss: 3.4021e-04 - KL loss: 19.4802 - beta: 0.0029 - val_val_loss: 61.2508 - val_val_recon_loss: 3.4354e-04 - val_val_KL loss: 19.5143 - val_beta: 0.0029\n",
      "Epoch 4190/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.9315 - recon_loss: 3.4134e-04 - KL loss: 19.4630 - beta: 0.0029 - val_val_loss: 61.2237 - val_val_recon_loss: 3.4314e-04 - val_val_KL loss: 19.5356 - val_beta: 0.0029\n",
      "Epoch 4191/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.1871 - recon_loss: 3.4325e-04 - KL loss: 19.4866 - beta: 0.0029 - val_val_loss: 61.1787 - val_val_recon_loss: 3.4295e-04 - val_val_KL loss: 19.5146 - val_beta: 0.0029\n",
      "Epoch 4192/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.0173 - recon_loss: 3.4184e-04 - KL loss: 19.4875 - beta: 0.0029 - val_val_loss: 61.3216 - val_val_recon_loss: 3.4421e-04 - val_val_KL loss: 19.5035 - val_beta: 0.0029\n",
      "Epoch 4193/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.9415 - recon_loss: 3.4107e-04 - KL loss: 19.5057 - beta: 0.0029 - val_val_loss: 61.4892 - val_val_recon_loss: 3.4603e-04 - val_val_KL loss: 19.4507 - val_beta: 0.0029\n",
      "Epoch 4194/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.3366 - recon_loss: 3.4461e-04 - KL loss: 19.4706 - beta: 0.0029 - val_val_loss: 61.2098 - val_val_recon_loss: 3.4344e-04 - val_val_KL loss: 19.4855 - val_beta: 0.0029\n",
      "Epoch 4195/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.6265 - recon_loss: 3.3903e-04 - KL loss: 19.4377 - beta: 0.0029 - val_val_loss: 61.3152 - val_val_recon_loss: 3.4382e-04 - val_val_KL loss: 19.5445 - val_beta: 0.0029\n",
      "Epoch 4196/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 60.9809 - recon_loss: 3.4153e-04 - KL loss: 19.4882 - beta: 0.0029\n",
      "Epoch 04196: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.9807 - recon_loss: 3.4153e-04 - KL loss: 19.4882 - beta: 0.0029 - val_val_loss: 61.2235 - val_val_recon_loss: 3.4418e-04 - val_val_KL loss: 19.4100 - val_beta: 0.0029\n",
      "Epoch 4197/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.5346 - recon_loss: 3.3837e-04 - KL loss: 19.4264 - beta: 0.0029 - val_val_loss: 61.1073 - val_val_recon_loss: 3.4333e-04 - val_val_KL loss: 19.3969 - val_beta: 0.0029\n",
      "Epoch 4198/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.8840 - recon_loss: 3.4074e-04 - KL loss: 19.4878 - beta: 0.0029 - val_val_loss: 61.0715 - val_val_recon_loss: 3.4198e-04 - val_val_KL loss: 19.5246 - val_beta: 0.0029\n",
      "Epoch 4199/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.5136 - recon_loss: 3.3741e-04 - KL loss: 19.5222 - beta: 0.0029 - val_val_loss: 60.9991 - val_val_recon_loss: 3.4167e-04 - val_val_KL loss: 19.4896 - val_beta: 0.0029\n",
      "Epoch 4200/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.6928 - recon_loss: 3.3925e-04 - KL loss: 19.4776 - beta: 0.0029 - val_val_loss: 60.9822 - val_val_recon_loss: 3.4180e-04 - val_val_KL loss: 19.4574 - val_beta: 0.0029\n",
      "Epoch 4201/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.8609 - recon_loss: 3.4048e-04 - KL loss: 19.4965 - beta: 0.0029 - val_val_loss: 61.0331 - val_val_recon_loss: 3.4241e-04 - val_val_KL loss: 19.4346 - val_beta: 0.0029\n",
      "Epoch 4202/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.4124 - recon_loss: 3.3726e-04 - KL loss: 19.4389 - beta: 0.0029 - val_val_loss: 61.0821 - val_val_recon_loss: 3.4239e-04 - val_val_KL loss: 19.4851 - val_beta: 0.0029\n",
      "Epoch 4203/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.8598 - recon_loss: 3.4039e-04 - KL loss: 19.5058 - beta: 0.0029 - val_val_loss: 61.0738 - val_val_recon_loss: 3.4282e-04 - val_val_KL loss: 19.4253 - val_beta: 0.0029\n",
      "Epoch 4204/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.6156 - recon_loss: 3.3876e-04 - KL loss: 19.4606 - beta: 0.0029 - val_val_loss: 61.0754 - val_val_recon_loss: 3.4287e-04 - val_val_KL loss: 19.4201 - val_beta: 0.0029\n",
      "Epoch 4205/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 60.2732 - recon_loss: 3.3572e-04 - KL loss: 19.4870 - beta: 0.0029\n",
      "Epoch 04205: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.2734 - recon_loss: 3.3572e-04 - KL loss: 19.4869 - beta: 0.0029 - val_val_loss: 61.1276 - val_val_recon_loss: 3.4320e-04 - val_val_KL loss: 19.4330 - val_beta: 0.0029\n",
      "Epoch 4206/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.8836 - recon_loss: 3.4072e-04 - KL loss: 19.4898 - beta: 0.0029 - val_val_loss: 61.0070 - val_val_recon_loss: 3.4193e-04 - val_val_KL loss: 19.4657 - val_beta: 0.0029\n",
      "Epoch 4207/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.6114 - recon_loss: 3.3847e-04 - KL loss: 19.4905 - beta: 0.0029 - val_val_loss: 61.0351 - val_val_recon_loss: 3.4215e-04 - val_val_KL loss: 19.4679 - val_beta: 0.0029\n",
      "Epoch 4208/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.5218 - recon_loss: 3.3799e-04 - KL loss: 19.4594 - beta: 0.0029 - val_val_loss: 60.9669 - val_val_recon_loss: 3.4169e-04 - val_val_KL loss: 19.4551 - val_beta: 0.0029\n",
      "Epoch 4209/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.8676 - recon_loss: 3.4028e-04 - KL loss: 19.5277 - beta: 0.0029 - val_val_loss: 60.9231 - val_val_recon_loss: 3.4124e-04 - val_val_KL loss: 19.4662 - val_beta: 0.0029\n",
      "Epoch 4210/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.5904 - recon_loss: 3.3824e-04 - KL loss: 19.4975 - beta: 0.0029 - val_val_loss: 61.0158 - val_val_recon_loss: 3.4210e-04 - val_val_KL loss: 19.4540 - val_beta: 0.0029\n",
      "Epoch 4211/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.7036 - recon_loss: 3.3918e-04 - KL loss: 19.4975 - beta: 0.0029 - val_val_loss: 60.9573 - val_val_recon_loss: 3.4160e-04 - val_val_KL loss: 19.4569 - val_beta: 0.0029\n",
      "Epoch 4212/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.4014 - recon_loss: 3.3690e-04 - KL loss: 19.4712 - beta: 0.0029 - val_val_loss: 61.0343 - val_val_recon_loss: 3.4222e-04 - val_val_KL loss: 19.4582 - val_beta: 0.0029\n",
      "Epoch 4213/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.1677 - recon_loss: 3.3523e-04 - KL loss: 19.4409 - beta: 0.0029 - val_val_loss: 60.9253 - val_val_recon_loss: 3.4161e-04 - val_val_KL loss: 19.4238 - val_beta: 0.0029\n",
      "Epoch 4214/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 61.0127 - recon_loss: 3.4156e-04 - KL loss: 19.5168 - beta: 0.0029\n",
      "Epoch 04214: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.0127 - recon_loss: 3.4156e-04 - KL loss: 19.5168 - beta: 0.0029 - val_val_loss: 60.9789 - val_val_recon_loss: 3.4140e-04 - val_val_KL loss: 19.5024 - val_beta: 0.0029\n",
      "Epoch 4215/10000\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 60.7059 - recon_loss: 3.3904e-04 - KL loss: 19.5158 - beta: 0.0029 - val_val_loss: 61.0091 - val_val_recon_loss: 3.4163e-04 - val_val_KL loss: 19.5042 - val_beta: 0.0029\n",
      "Epoch 4216/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.5286 - recon_loss: 3.3770e-04 - KL loss: 19.5017 - beta: 0.0029 - val_val_loss: 60.9811 - val_val_recon_loss: 3.4155e-04 - val_val_KL loss: 19.4860 - val_beta: 0.0029\n",
      "Epoch 4217/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.3249 - recon_loss: 3.3585e-04 - KL loss: 19.5223 - beta: 0.0029 - val_val_loss: 60.8831 - val_val_recon_loss: 3.4065e-04 - val_val_KL loss: 19.4985 - val_beta: 0.0029\n",
      "Epoch 4218/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.0964 - recon_loss: 3.3452e-04 - KL loss: 19.4560 - beta: 0.0029 - val_val_loss: 60.9537 - val_val_recon_loss: 3.4132e-04 - val_val_KL loss: 19.4865 - val_beta: 0.0029\n",
      "Epoch 4219/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.5112 - recon_loss: 3.3739e-04 - KL loss: 19.5223 - beta: 0.0029 - val_val_loss: 60.9140 - val_val_recon_loss: 3.4099e-04 - val_val_KL loss: 19.4874 - val_beta: 0.0029\n",
      "Epoch 4220/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.5338 - recon_loss: 3.3783e-04 - KL loss: 19.4908 - beta: 0.0029 - val_val_loss: 60.8965 - val_val_recon_loss: 3.4091e-04 - val_val_KL loss: 19.4800 - val_beta: 0.0029\n",
      "Epoch 4221/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.8279 - recon_loss: 3.3995e-04 - KL loss: 19.5272 - beta: 0.0029 - val_val_loss: 60.9241 - val_val_recon_loss: 3.4105e-04 - val_val_KL loss: 19.4906 - val_beta: 0.0029\n",
      "Epoch 4222/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 60.6384 - recon_loss: 3.3866e-04 - KL loss: 19.4945 - beta: 0.0029\n",
      "Epoch 04222: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.6384 - recon_loss: 3.3866e-04 - KL loss: 19.4945 - beta: 0.0029 - val_val_loss: 60.9469 - val_val_recon_loss: 3.4152e-04 - val_val_KL loss: 19.4562 - val_beta: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4223/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.5156 - recon_loss: 3.3786e-04 - KL loss: 19.4692 - beta: 0.0029 - val_val_loss: 60.9513 - val_val_recon_loss: 3.4150e-04 - val_val_KL loss: 19.4626 - val_beta: 0.0029\n",
      "Epoch 4224/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.5753 - recon_loss: 3.3830e-04 - KL loss: 19.4754 - beta: 0.0029 - val_val_loss: 60.8927 - val_val_recon_loss: 3.4096e-04 - val_val_KL loss: 19.4697 - val_beta: 0.0029\n",
      "Epoch 4225/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.4522 - recon_loss: 3.3722e-04 - KL loss: 19.4839 - beta: 0.0029 - val_val_loss: 60.8618 - val_val_recon_loss: 3.4064e-04 - val_val_KL loss: 19.4780 - val_beta: 0.0029\n",
      "Epoch 4226/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.5874 - recon_loss: 3.3827e-04 - KL loss: 19.4914 - beta: 0.0029 - val_val_loss: 60.8880 - val_val_recon_loss: 3.4082e-04 - val_val_KL loss: 19.4817 - val_beta: 0.0029\n",
      "Epoch 4227/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.6851 - recon_loss: 3.3879e-04 - KL loss: 19.5253 - beta: 0.0029 - val_val_loss: 60.8717 - val_val_recon_loss: 3.4063e-04 - val_val_KL loss: 19.4890 - val_beta: 0.0029\n",
      "Epoch 4228/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.3493 - recon_loss: 3.3609e-04 - KL loss: 19.5176 - beta: 0.0029 - val_val_loss: 60.9488 - val_val_recon_loss: 3.4137e-04 - val_val_KL loss: 19.4764 - val_beta: 0.0029\n",
      "Epoch 4229/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.4909 - recon_loss: 3.3740e-04 - KL loss: 19.5004 - beta: 0.0029 - val_val_loss: 60.9972 - val_val_recon_loss: 3.4174e-04 - val_val_KL loss: 19.4800 - val_beta: 0.0029\n",
      "Epoch 4230/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 60.5928 - recon_loss: 3.3835e-04 - KL loss: 19.4868 - beta: 0.0029\n",
      "Epoch 04230: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.5928 - recon_loss: 3.3835e-04 - KL loss: 19.4868 - beta: 0.0029 - val_val_loss: 60.9984 - val_val_recon_loss: 3.4174e-04 - val_val_KL loss: 19.4803 - val_beta: 0.0029\n",
      "Epoch 4231/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.5744 - recon_loss: 3.3819e-04 - KL loss: 19.4878 - beta: 0.0029 - val_val_loss: 60.9236 - val_val_recon_loss: 3.4114e-04 - val_val_KL loss: 19.4788 - val_beta: 0.0029\n",
      "Epoch 4232/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 61.0030 - recon_loss: 3.4154e-04 - KL loss: 19.5096 - beta: 0.0029 - val_val_loss: 61.0296 - val_val_recon_loss: 3.4203e-04 - val_val_KL loss: 19.4772 - val_beta: 0.0029\n",
      "Epoch 4233/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.5287 - recon_loss: 3.3781e-04 - KL loss: 19.4886 - beta: 0.0029 - val_val_loss: 61.0118 - val_val_recon_loss: 3.4187e-04 - val_val_KL loss: 19.4781 - val_beta: 0.0029\n",
      "Epoch 4234/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.7097 - recon_loss: 3.3926e-04 - KL loss: 19.4936 - beta: 0.0029 - val_val_loss: 61.0112 - val_val_recon_loss: 3.4185e-04 - val_val_KL loss: 19.4800 - val_beta: 0.0029\n",
      "Epoch 4235/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.6032 - recon_loss: 3.3842e-04 - KL loss: 19.4890 - beta: 0.0029 - val_val_loss: 60.8540 - val_val_recon_loss: 3.4058e-04 - val_val_KL loss: 19.4767 - val_beta: 0.0029\n",
      "Epoch 4236/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.5172 - recon_loss: 3.3771e-04 - KL loss: 19.4894 - beta: 0.0029 - val_val_loss: 60.9519 - val_val_recon_loss: 3.4140e-04 - val_val_KL loss: 19.4759 - val_beta: 0.0029\n",
      "Epoch 4237/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.4250 - recon_loss: 3.3715e-04 - KL loss: 19.4647 - beta: 0.0029 - val_val_loss: 60.9781 - val_val_recon_loss: 3.4163e-04 - val_val_KL loss: 19.4743 - val_beta: 0.0029\n",
      "Epoch 4238/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.0839 - recon_loss: 3.3427e-04 - KL loss: 19.4733 - beta: 0.0029 - val_val_loss: 60.9274 - val_val_recon_loss: 3.4122e-04 - val_val_KL loss: 19.4726 - val_beta: 0.0029\n",
      "Epoch 4239/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.8957 - recon_loss: 3.4073e-04 - KL loss: 19.5009 - beta: 0.0029 - val_val_loss: 60.9342 - val_val_recon_loss: 3.4125e-04 - val_val_KL loss: 19.4763 - val_beta: 0.0029\n",
      "Epoch 4240/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.3202 - recon_loss: 3.3609e-04 - KL loss: 19.4883 - beta: 0.0029 - val_val_loss: 60.9437 - val_val_recon_loss: 3.4134e-04 - val_val_KL loss: 19.4748 - val_beta: 0.0029\n",
      "Epoch 4241/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 60.5553 - recon_loss: 3.3806e-04 - KL loss: 19.4850 - beta: 0.0029 - val_val_loss: 61.0004 - val_val_recon_loss: 3.4181e-04 - val_val_KL loss: 19.4739 - val_beta: 0.0029\n",
      "Epoch 4242/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.4646 - recon_loss: 3.3732e-04 - KL loss: 19.4836 - beta: 0.0029 - val_val_loss: 60.9226 - val_val_recon_loss: 3.4117e-04 - val_val_KL loss: 19.4739 - val_beta: 0.0029\n",
      "Epoch 4243/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.8328 - recon_loss: 3.4019e-04 - KL loss: 19.5039 - beta: 0.0029 - val_val_loss: 60.9920 - val_val_recon_loss: 3.4174e-04 - val_val_KL loss: 19.4738 - val_beta: 0.0029\n",
      "Epoch 4244/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.5652 - recon_loss: 3.3792e-04 - KL loss: 19.5117 - beta: 0.0029 - val_val_loss: 61.0175 - val_val_recon_loss: 3.4196e-04 - val_val_KL loss: 19.4730 - val_beta: 0.0029\n",
      "Epoch 4245/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 60.4221 - recon_loss: 3.3714e-04 - KL loss: 19.4633 - beta: 0.0029 - val_val_loss: 60.9845 - val_val_recon_loss: 3.4168e-04 - val_val_KL loss: 19.4740 - val_beta: 0.0029\n",
      "Epoch 4245/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 44.2030 - recon_loss: 3.7384e-04 - KL loss: 17.3892 - beta: 0.0037 - val_val_loss: 46.0331 - val_val_recon_loss: 4.0245e-04 - val_val_KL loss: 17.1673 - val_beta: 0.0037\n",
      "Epoch 4246/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 45.7340 - recon_loss: 3.9965e-04 - KL loss: 17.0689 - beta: 0.0037 - val_val_loss: 45.9732 - val_val_recon_loss: 4.0959e-04 - val_val_KL loss: 16.5955 - val_beta: 0.0037\n",
      "Epoch 4247/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 47.1491 - recon_loss: 4.2142e-04 - KL loss: 16.9224 - beta: 0.0037 - val_val_loss: 48.5868 - val_val_recon_loss: 4.3840e-04 - val_val_KL loss: 17.1429 - val_beta: 0.0037\n",
      "Epoch 4248/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 47.5927 - recon_loss: 4.2577e-04 - KL loss: 17.0545 - beta: 0.0037 - val_val_loss: 47.6079 - val_val_recon_loss: 4.2700e-04 - val_val_KL loss: 16.9813 - val_beta: 0.0037\n",
      "Epoch 4249/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 47.5130 - recon_loss: 4.2535e-04 - KL loss: 17.0051 - beta: 0.0037 - val_val_loss: 47.3447 - val_val_recon_loss: 4.2354e-04 - val_val_KL loss: 16.9664 - val_beta: 0.0037\n",
      "Epoch 4250/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 46.5794 - recon_loss: 4.1411e-04 - KL loss: 16.8773 - beta: 0.0037 - val_val_loss: 46.0059 - val_val_recon_loss: 4.0856e-04 - val_val_KL loss: 16.7016 - val_beta: 0.0037\n",
      "Epoch 4251/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 46.9367 - recon_loss: 4.1959e-04 - KL loss: 16.8412 - beta: 0.0037\n",
      "Epoch 04251: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 46.9366 - recon_loss: 4.1959e-04 - KL loss: 16.8412 - beta: 0.0037 - val_val_loss: 49.7282 - val_val_recon_loss: 4.4817e-04 - val_val_KL loss: 17.5834 - val_beta: 0.0037\n",
      "Epoch 4252/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 158s 158ms/step - loss: 47.5978 - recon_loss: 4.2842e-04 - KL loss: 16.8695 - beta: 0.0037 - val_val_loss: 46.4436 - val_val_recon_loss: 4.1370e-04 - val_val_KL loss: 16.7710 - val_beta: 0.0037\n",
      "Epoch 4253/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 45.7740 - recon_loss: 4.0447e-04 - KL loss: 16.7636 - beta: 0.0037 - val_val_loss: 45.1469 - val_val_recon_loss: 3.9667e-04 - val_val_KL loss: 16.6960 - val_beta: 0.0037\n",
      "Epoch 4254/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 44.8578 - recon_loss: 3.9219e-04 - KL loss: 16.7277 - beta: 0.0037 - val_val_loss: 45.3307 - val_val_recon_loss: 3.9755e-04 - val_val_KL loss: 16.8164 - val_beta: 0.0037\n",
      "Epoch 4255/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 44.9421 - recon_loss: 3.9228e-04 - KL loss: 16.8061 - beta: 0.0037 - val_val_loss: 45.1441 - val_val_recon_loss: 3.9442e-04 - val_val_KL loss: 16.8540 - val_beta: 0.0037\n",
      "Epoch 4256/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 44.7263 - recon_loss: 3.9021e-04 - KL loss: 16.7386 - beta: 0.0037 - val_val_loss: 44.7032 - val_val_recon_loss: 3.9053e-04 - val_val_KL loss: 16.6923 - val_beta: 0.0037\n",
      "Epoch 4257/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 44.3793 - recon_loss: 3.8513e-04 - KL loss: 16.7556 - beta: 0.0037 - val_val_loss: 44.4316 - val_val_recon_loss: 3.8621e-04 - val_val_KL loss: 16.7306 - val_beta: 0.0037\n",
      "Epoch 4258/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 44.5519 - recon_loss: 3.8699e-04 - KL loss: 16.7947 - beta: 0.0037 - val_val_loss: 44.4826 - val_val_recon_loss: 3.8790e-04 - val_val_KL loss: 16.6604 - val_beta: 0.0037\n",
      "Epoch 4259/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.8642 - recon_loss: 3.7862e-04 - KL loss: 16.7073 - beta: 0.0037 - val_val_loss: 44.0216 - val_val_recon_loss: 3.8000e-04 - val_val_KL loss: 16.7661 - val_beta: 0.0037\n",
      "Epoch 4260/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.9794 - recon_loss: 3.8081e-04 - KL loss: 16.6659 - beta: 0.0037 - val_val_loss: 43.9979 - val_val_recon_loss: 3.7847e-04 - val_val_KL loss: 16.8523 - val_beta: 0.0037\n",
      "Epoch 4261/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.7853 - recon_loss: 3.7692e-04 - KL loss: 16.7509 - beta: 0.0037 - val_val_loss: 44.4956 - val_val_recon_loss: 3.8661e-04 - val_val_KL loss: 16.7659 - val_beta: 0.0037\n",
      "Epoch 4262/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 44.0914 - recon_loss: 3.8131e-04 - KL loss: 16.7422 - beta: 0.0037 - val_val_loss: 44.1778 - val_val_recon_loss: 3.8300e-04 - val_val_KL loss: 16.7074 - val_beta: 0.0037\n",
      "Epoch 4263/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.9991 - recon_loss: 3.7901e-04 - KL loss: 16.8144 - beta: 0.0037 - val_val_loss: 43.9185 - val_val_recon_loss: 3.7674e-04 - val_val_KL loss: 16.8965 - val_beta: 0.0037\n",
      "Epoch 4264/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.8458 - recon_loss: 3.7718e-04 - KL loss: 16.7928 - beta: 0.0037 - val_val_loss: 45.2560 - val_val_recon_loss: 3.9536e-04 - val_val_KL loss: 16.8986 - val_beta: 0.0037\n",
      "Epoch 4265/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 45.2868 - recon_loss: 3.9608e-04 - KL loss: 16.8780 - beta: 0.0037 - val_val_loss: 45.1862 - val_val_recon_loss: 3.9639e-04 - val_val_KL loss: 16.7550 - val_beta: 0.0037\n",
      "Epoch 4266/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 44.5774 - recon_loss: 3.8776e-04 - KL loss: 16.7655 - beta: 0.0037 - val_val_loss: 44.4694 - val_val_recon_loss: 3.8741e-04 - val_val_KL loss: 16.6823 - val_beta: 0.0037\n",
      "Epoch 4267/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 44.3272 - recon_loss: 3.8395e-04 - KL loss: 16.7882 - beta: 0.0037 - val_val_loss: 44.2155 - val_val_recon_loss: 3.8266e-04 - val_val_KL loss: 16.7688 - val_beta: 0.0037\n",
      "Epoch 4268/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 43.7640 - recon_loss: 3.7669e-04 - KL loss: 16.7458 - beta: 0.0037\n",
      "Epoch 04268: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.7640 - recon_loss: 3.7669e-04 - KL loss: 16.7458 - beta: 0.0037 - val_val_loss: 44.0083 - val_val_recon_loss: 3.7877e-04 - val_val_KL loss: 16.8407 - val_beta: 0.0037\n",
      "Epoch 4269/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.6646 - recon_loss: 3.7493e-04 - KL loss: 16.7729 - beta: 0.0037 - val_val_loss: 43.8805 - val_val_recon_loss: 3.7824e-04 - val_val_KL loss: 16.7515 - val_beta: 0.0037\n",
      "Epoch 4270/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.5573 - recon_loss: 3.7327e-04 - KL loss: 16.7846 - beta: 0.0037 - val_val_loss: 43.8719 - val_val_recon_loss: 3.7715e-04 - val_val_KL loss: 16.8207 - val_beta: 0.0037\n",
      "Epoch 4271/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.6981 - recon_loss: 3.7553e-04 - KL loss: 16.7632 - beta: 0.0037 - val_val_loss: 43.6659 - val_val_recon_loss: 3.7536e-04 - val_val_KL loss: 16.7434 - val_beta: 0.0037\n",
      "Epoch 4272/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.4877 - recon_loss: 3.7314e-04 - KL loss: 16.7242 - beta: 0.0037 - val_val_loss: 43.7584 - val_val_recon_loss: 3.7556e-04 - val_val_KL loss: 16.8212 - val_beta: 0.0037\n",
      "Epoch 4273/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.6736 - recon_loss: 3.7378e-04 - KL loss: 16.8639 - beta: 0.0037 - val_val_loss: 43.8116 - val_val_recon_loss: 3.7796e-04 - val_val_KL loss: 16.7027 - val_beta: 0.0037\n",
      "Epoch 4274/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.7114 - recon_loss: 3.7523e-04 - KL loss: 16.7980 - beta: 0.0037 - val_val_loss: 43.8539 - val_val_recon_loss: 3.7965e-04 - val_val_KL loss: 16.6236 - val_beta: 0.0037\n",
      "Epoch 4275/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.5059 - recon_loss: 3.7353e-04 - KL loss: 16.7146 - beta: 0.0037 - val_val_loss: 43.5706 - val_val_recon_loss: 3.7244e-04 - val_val_KL loss: 16.8576 - val_beta: 0.0037\n",
      "Epoch 4276/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.3296 - recon_loss: 3.7005e-04 - KL loss: 16.7877 - beta: 0.0037 - val_val_loss: 43.6163 - val_val_recon_loss: 3.7386e-04 - val_val_KL loss: 16.8014 - val_beta: 0.0037\n",
      "Epoch 4277/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.0909 - recon_loss: 3.6772e-04 - KL loss: 16.7158 - beta: 0.0037 - val_val_loss: 43.5909 - val_val_recon_loss: 3.7386e-04 - val_val_KL loss: 16.7756 - val_beta: 0.0037\n",
      "Epoch 4278/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.2299 - recon_loss: 3.6925e-04 - KL loss: 16.7455 - beta: 0.0037 - val_val_loss: 43.5863 - val_val_recon_loss: 3.7337e-04 - val_val_KL loss: 16.8064 - val_beta: 0.0037\n",
      "Epoch 4279/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.2328 - recon_loss: 3.6981e-04 - KL loss: 16.7079 - beta: 0.0037 - val_val_loss: 43.5371 - val_val_recon_loss: 3.7321e-04 - val_val_KL loss: 16.7688 - val_beta: 0.0037\n",
      "Epoch 4280/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.0290 - recon_loss: 3.6762e-04 - KL loss: 16.6612 - beta: 0.0037 - val_val_loss: 43.5726 - val_val_recon_loss: 3.7449e-04 - val_val_KL loss: 16.7123 - val_beta: 0.0037\n",
      "Epoch 4281/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 42.9415 - recon_loss: 3.6530e-04 - KL loss: 16.7404 - beta: 0.0037 - val_val_loss: 43.4399 - val_val_recon_loss: 3.7179e-04 - val_val_KL loss: 16.7732 - val_beta: 0.0037\n",
      "Epoch 4282/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.2236 - recon_loss: 3.6930e-04 - KL loss: 16.7358 - beta: 0.0037 - val_val_loss: 43.6031 - val_val_recon_loss: 3.7555e-04 - val_val_KL loss: 16.6665 - val_beta: 0.0037\n",
      "Epoch 4283/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.2192 - recon_loss: 3.6939e-04 - KL loss: 16.7244 - beta: 0.0037 - val_val_loss: 43.4488 - val_val_recon_loss: 3.7267e-04 - val_val_KL loss: 16.7186 - val_beta: 0.0037\n",
      "Epoch 4284/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.2678 - recon_loss: 3.7027e-04 - KL loss: 16.7099 - beta: 0.0037 - val_val_loss: 43.5612 - val_val_recon_loss: 3.7337e-04 - val_val_KL loss: 16.7814 - val_beta: 0.0037\n",
      "Epoch 4285/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 42.9183 - recon_loss: 3.6540e-04 - KL loss: 16.7102 - beta: 0.0037 - val_val_loss: 43.4802 - val_val_recon_loss: 3.7422e-04 - val_val_KL loss: 16.6394 - val_beta: 0.0037\n",
      "Epoch 4286/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.0880 - recon_loss: 3.6861e-04 - KL loss: 16.6495 - beta: 0.0037 - val_val_loss: 43.4207 - val_val_recon_loss: 3.7285e-04 - val_val_KL loss: 16.6780 - val_beta: 0.0037\n",
      "Epoch 4287/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.0252 - recon_loss: 3.6694e-04 - KL loss: 16.7061 - beta: 0.0037 - val_val_loss: 43.3597 - val_val_recon_loss: 3.7163e-04 - val_val_KL loss: 16.7048 - val_beta: 0.0037\n",
      "Epoch 4288/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.1622 - recon_loss: 3.6892e-04 - KL loss: 16.7010 - beta: 0.0037 - val_val_loss: 43.3954 - val_val_recon_loss: 3.7175e-04 - val_val_KL loss: 16.7314 - val_beta: 0.0037\n",
      "Epoch 4289/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.1348 - recon_loss: 3.6813e-04 - KL loss: 16.7305 - beta: 0.0037 - val_val_loss: 43.4717 - val_val_recon_loss: 3.7292e-04 - val_val_KL loss: 16.7241 - val_beta: 0.0037\n",
      "Epoch 4290/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 42.9337 - recon_loss: 3.6570e-04 - KL loss: 16.7039 - beta: 0.0037 - val_val_loss: 43.4220 - val_val_recon_loss: 3.7140e-04 - val_val_KL loss: 16.7834 - val_beta: 0.0037\n",
      "Epoch 4291/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.1117 - recon_loss: 3.6745e-04 - KL loss: 16.7561 - beta: 0.0037 - val_val_loss: 43.4070 - val_val_recon_loss: 3.7254e-04 - val_val_KL loss: 16.6862 - val_beta: 0.0037\n",
      "Epoch 4292/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 43.1208 - recon_loss: 3.6764e-04 - KL loss: 16.7519 - beta: 0.0037\n",
      "Epoch 04292: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 43.1208 - recon_loss: 3.6764e-04 - KL loss: 16.7519 - beta: 0.0037 - val_val_loss: 43.4026 - val_val_recon_loss: 3.7208e-04 - val_val_KL loss: 16.7154 - val_beta: 0.0037\n",
      "Epoch 4293/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.0768 - recon_loss: 3.6713e-04 - KL loss: 16.7445 - beta: 0.0037 - val_val_loss: 43.3098 - val_val_recon_loss: 3.7023e-04 - val_val_KL loss: 16.7547 - val_beta: 0.0037\n",
      "Epoch 4294/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.0338 - recon_loss: 3.6652e-04 - KL loss: 16.7449 - beta: 0.0037 - val_val_loss: 43.2346 - val_val_recon_loss: 3.6885e-04 - val_val_KL loss: 16.7790 - val_beta: 0.0037\n",
      "Epoch 4295/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 42.7881 - recon_loss: 3.6322e-04 - KL loss: 16.7362 - beta: 0.0037 - val_val_loss: 43.2177 - val_val_recon_loss: 3.6942e-04 - val_val_KL loss: 16.7212 - val_beta: 0.0037\n",
      "Epoch 4296/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 42.7920 - recon_loss: 3.6302e-04 - KL loss: 16.7543 - beta: 0.0037 - val_val_loss: 43.2844 - val_val_recon_loss: 3.7044e-04 - val_val_KL loss: 16.7142 - val_beta: 0.0037\n",
      "Epoch 4297/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 42.6705 - recon_loss: 3.6232e-04 - KL loss: 16.6834 - beta: 0.0037 - val_val_loss: 43.2244 - val_val_recon_loss: 3.6909e-04 - val_val_KL loss: 16.7517 - val_beta: 0.0037\n",
      "Epoch 4298/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 42.9267 - recon_loss: 3.6554e-04 - KL loss: 16.7081 - beta: 0.0037 - val_val_loss: 43.2792 - val_val_recon_loss: 3.7033e-04 - val_val_KL loss: 16.7169 - val_beta: 0.0037\n",
      "Epoch 4299/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 42.8139 - recon_loss: 3.6398e-04 - KL loss: 16.7077 - beta: 0.0037 - val_val_loss: 43.2480 - val_val_recon_loss: 3.6948e-04 - val_val_KL loss: 16.7472 - val_beta: 0.0037\n",
      "Epoch 4300/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 42.7934 - recon_loss: 3.6385e-04 - KL loss: 16.6964 - beta: 0.0037\n",
      "Epoch 04300: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 42.7937 - recon_loss: 3.6385e-04 - KL loss: 16.6964 - beta: 0.0037 - val_val_loss: 43.2568 - val_val_recon_loss: 3.6940e-04 - val_val_KL loss: 16.7616 - val_beta: 0.0037\n",
      "Epoch 4301/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 42.9226 - recon_loss: 3.6472e-04 - KL loss: 16.7633 - beta: 0.0037 - val_val_loss: 43.2376 - val_val_recon_loss: 3.6903e-04 - val_val_KL loss: 16.7688 - val_beta: 0.0037\n",
      "Epoch 4302/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 42.8976 - recon_loss: 3.6444e-04 - KL loss: 16.7584 - beta: 0.0037 - val_val_loss: 43.3116 - val_val_recon_loss: 3.7062e-04 - val_val_KL loss: 16.7288 - val_beta: 0.0037\n",
      "Epoch 4303/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 42.7955 - recon_loss: 3.6373e-04 - KL loss: 16.7067 - beta: 0.0037 - val_val_loss: 43.2051 - val_val_recon_loss: 3.6885e-04 - val_val_KL loss: 16.7492 - val_beta: 0.0037\n",
      "Epoch 4304/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 42.8266 - recon_loss: 3.6370e-04 - KL loss: 16.7400 - beta: 0.0037 - val_val_loss: 43.2328 - val_val_recon_loss: 3.6938e-04 - val_val_KL loss: 16.7391 - val_beta: 0.0037\n",
      "Epoch 4305/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 42.8476 - recon_loss: 3.6418e-04 - KL loss: 16.7266 - beta: 0.0037 - val_val_loss: 43.2386 - val_val_recon_loss: 3.6932e-04 - val_val_KL loss: 16.7488 - val_beta: 0.0037\n",
      "Epoch 4306/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.0168 - recon_loss: 3.6589e-04 - KL loss: 16.7730 - beta: 0.0037 - val_val_loss: 43.2588 - val_val_recon_loss: 3.6946e-04 - val_val_KL loss: 16.7594 - val_beta: 0.0037\n",
      "Epoch 4307/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 43.0532 - recon_loss: 3.6670e-04 - KL loss: 16.7513 - beta: 0.0037 - val_val_loss: 43.2610 - val_val_recon_loss: 3.6967e-04 - val_val_KL loss: 16.7462 - val_beta: 0.0037\n",
      "Epoch 4308/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 42.7428 - recon_loss: 3.6244e-04 - KL loss: 16.7470 - beta: 0.0037\n",
      "Epoch 04308: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 42.7429 - recon_loss: 3.6244e-04 - KL loss: 16.7470 - beta: 0.0037 - val_val_loss: 43.3020 - val_val_recon_loss: 3.7017e-04 - val_val_KL loss: 16.7514 - val_beta: 0.0037\n",
      "Epoch 4309/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 42.7353 - recon_loss: 3.6257e-04 - KL loss: 16.7302 - beta: 0.0037 - val_val_loss: 43.2701 - val_val_recon_loss: 3.6969e-04 - val_val_KL loss: 16.7541 - val_beta: 0.0037\n",
      "Epoch 4310/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 42.7481 - recon_loss: 3.6240e-04 - KL loss: 16.7548 - beta: 0.0037 - val_val_loss: 43.2724 - val_val_recon_loss: 3.6974e-04 - val_val_KL loss: 16.7527 - val_beta: 0.0037\n",
      "Epoch 4311/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 42.8805 - recon_loss: 3.6450e-04 - KL loss: 16.7369 - beta: 0.0037 - val_val_loss: 43.1617 - val_val_recon_loss: 3.6824e-04 - val_val_KL loss: 16.7495 - val_beta: 0.0037\n",
      "Epoch 4312/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 42.6324 - recon_loss: 3.6120e-04 - KL loss: 16.7249 - beta: 0.0037 - val_val_loss: 43.2338 - val_val_recon_loss: 3.6925e-04 - val_val_KL loss: 16.7491 - val_beta: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4313/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 42.9631 - recon_loss: 3.6579e-04 - KL loss: 16.7267 - beta: 0.0037 - val_val_loss: 43.2369 - val_val_recon_loss: 3.6938e-04 - val_val_KL loss: 16.7428 - val_beta: 0.0037\n",
      "Epoch 4314/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 42.9061 - recon_loss: 3.6502e-04 - KL loss: 16.7247 - beta: 0.0037 - val_val_loss: 43.2377 - val_val_recon_loss: 3.6941e-04 - val_val_KL loss: 16.7413 - val_beta: 0.0037\n",
      "Epoch 4315/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 42.9266 - recon_loss: 3.6507e-04 - KL loss: 16.7417 - beta: 0.0037 - val_val_loss: 43.2444 - val_val_recon_loss: 3.6951e-04 - val_val_KL loss: 16.7413 - val_beta: 0.0037\n",
      "Epoch 4316/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 42.7619 - recon_loss: 3.6291e-04 - KL loss: 16.7323 - beta: 0.0037\n",
      "Epoch 04316: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 42.7620 - recon_loss: 3.6291e-04 - KL loss: 16.7323 - beta: 0.0037 - val_val_loss: 43.2452 - val_val_recon_loss: 3.6948e-04 - val_val_KL loss: 16.7442 - val_beta: 0.0037\n",
      "Epoch 4317/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 42.7261 - recon_loss: 3.6254e-04 - KL loss: 16.7231 - beta: 0.0037 - val_val_loss: 43.2071 - val_val_recon_loss: 3.6893e-04 - val_val_KL loss: 16.7453 - val_beta: 0.0037\n",
      "Epoch 4318/10000\n",
      "1000/1000 [==============================] - 151s 151ms/step - loss: 42.9948 - recon_loss: 3.6597e-04 - KL loss: 16.7458 - beta: 0.0037 - val_val_loss: 43.1957 - val_val_recon_loss: 3.6875e-04 - val_val_KL loss: 16.7467 - val_beta: 0.0037\n",
      "Epoch 4319/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 42.9294 - recon_loss: 3.6491e-04 - KL loss: 16.7563 - beta: 0.0037 - val_val_loss: 43.2210 - val_val_recon_loss: 3.6909e-04 - val_val_KL loss: 16.7483 - val_beta: 0.0037\n",
      "Epoch 4320/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 42.8420 - recon_loss: 3.6373e-04 - KL loss: 16.7535 - beta: 0.0037 - val_val_loss: 43.2404 - val_val_recon_loss: 3.6937e-04 - val_val_KL loss: 16.7475 - val_beta: 0.0037\n",
      "Epoch 4321/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 42.9555 - recon_loss: 3.6528e-04 - KL loss: 16.7555 - beta: 0.0037\n",
      "Epoch 04321: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 42.9554 - recon_loss: 3.6528e-04 - KL loss: 16.7555 - beta: 0.0037 - val_val_loss: 43.1655 - val_val_recon_loss: 3.6819e-04 - val_val_KL loss: 16.7574 - val_beta: 0.0037\n",
      "Epoch 4321/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 32.4084 - recon_loss: 4.1526e-04 - KL loss: 14.8239 - beta: 0.0049 - val_val_loss: 32.8433 - val_val_recon_loss: 4.2996e-04 - val_val_KL loss: 14.6366 - val_beta: 0.0049\n",
      "Epoch 4322/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 32.6095 - recon_loss: 4.2881e-04 - KL loss: 14.4512 - beta: 0.0049 - val_val_loss: 32.8114 - val_val_recon_loss: 4.3113e-04 - val_val_KL loss: 14.5549 - val_beta: 0.0049\n",
      "Epoch 4323/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 33.0524 - recon_loss: 4.4031e-04 - KL loss: 14.4074 - beta: 0.0049 - val_val_loss: 33.7183 - val_val_recon_loss: 4.4713e-04 - val_val_KL loss: 14.7844 - val_beta: 0.0049\n",
      "Epoch 4324/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 33.9115 - recon_loss: 4.6002e-04 - KL loss: 14.4320 - beta: 0.0049 - val_val_loss: 32.7239 - val_val_recon_loss: 4.3738e-04 - val_val_KL loss: 14.2027 - val_beta: 0.0049\n",
      "Epoch 4325/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 32.6614 - recon_loss: 4.3382e-04 - KL loss: 14.2909 - beta: 0.0049 - val_val_loss: 32.8481 - val_val_recon_loss: 4.3765e-04 - val_val_KL loss: 14.3155 - val_beta: 0.0049\n",
      "Epoch 4326/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 32.6594 - recon_loss: 4.3525e-04 - KL loss: 14.2287 - beta: 0.0049 - val_val_loss: 33.1802 - val_val_recon_loss: 4.4852e-04 - val_val_KL loss: 14.1876 - val_beta: 0.0049\n",
      "Epoch 4327/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 32.7999 - recon_loss: 4.3865e-04 - KL loss: 14.2250 - beta: 0.0049 - val_val_loss: 32.9636 - val_val_recon_loss: 4.4503e-04 - val_val_KL loss: 14.1187 - val_beta: 0.0049\n",
      "Epoch 4328/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 33.2737 - recon_loss: 4.4971e-04 - KL loss: 14.2304 - beta: 0.0049 - val_val_loss: 33.6864 - val_val_recon_loss: 4.5881e-04 - val_val_KL loss: 14.2580 - val_beta: 0.0049\n",
      "Epoch 4329/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 33.0827 - recon_loss: 4.4994e-04 - KL loss: 14.0300 - beta: 0.0049\n",
      "Epoch 04329: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 33.0825 - recon_loss: 4.4993e-04 - KL loss: 14.0301 - beta: 0.0049 - val_val_loss: 33.0320 - val_val_recon_loss: 4.4818e-04 - val_val_KL loss: 14.0536 - val_beta: 0.0049\n",
      "Epoch 4330/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 32.5175 - recon_loss: 4.3325e-04 - KL loss: 14.1716 - beta: 0.0049 - val_val_loss: 32.6145 - val_val_recon_loss: 4.4142e-04 - val_val_KL loss: 13.9223 - val_beta: 0.0049\n",
      "Epoch 4331/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 32.2340 - recon_loss: 4.2601e-04 - KL loss: 14.1945 - beta: 0.0049 - val_val_loss: 32.3836 - val_val_recon_loss: 4.2975e-04 - val_val_KL loss: 14.1857 - val_beta: 0.0049\n",
      "Epoch 4332/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 32.2321 - recon_loss: 4.2697e-04 - KL loss: 14.1518 - beta: 0.0049 - val_val_loss: 32.3235 - val_val_recon_loss: 4.1832e-04 - val_val_KL loss: 14.6096 - val_beta: 0.0049\n",
      "Epoch 4333/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 32.1223 - recon_loss: 4.2392e-04 - KL loss: 14.1714 - beta: 0.0049 - val_val_loss: 32.2280 - val_val_recon_loss: 4.2688e-04 - val_val_KL loss: 14.1514 - val_beta: 0.0049\n",
      "Epoch 4334/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 32.0815 - recon_loss: 4.2326e-04 - KL loss: 14.1586 - beta: 0.0049 - val_val_loss: 32.3325 - val_val_recon_loss: 4.2753e-04 - val_val_KL loss: 14.2284 - val_beta: 0.0049\n",
      "Epoch 4335/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 32.2803 - recon_loss: 4.2819e-04 - KL loss: 14.1484 - beta: 0.0049 - val_val_loss: 32.0698 - val_val_recon_loss: 4.2454e-04 - val_val_KL loss: 14.0924 - val_beta: 0.0049\n",
      "Epoch 4336/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 31.8674 - recon_loss: 4.1912e-04 - KL loss: 14.1197 - beta: 0.0049 - val_val_loss: 32.2525 - val_val_recon_loss: 4.2728e-04 - val_val_KL loss: 14.1592 - val_beta: 0.0049\n",
      "Epoch 4337/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 31.9666 - recon_loss: 4.2030e-04 - KL loss: 14.1689 - beta: 0.0049 - val_val_loss: 31.9359 - val_val_recon_loss: 4.1905e-04 - val_val_KL loss: 14.1910 - val_beta: 0.0049\n",
      "Epoch 4338/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 31.8905 - recon_loss: 4.1923e-04 - KL loss: 14.1379 - beta: 0.0049 - val_val_loss: 31.9024 - val_val_recon_loss: 4.1892e-04 - val_val_KL loss: 14.1630 - val_beta: 0.0049\n",
      "Epoch 4339/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 32.0668 - recon_loss: 4.2161e-04 - KL loss: 14.2135 - beta: 0.0049 - val_val_loss: 32.1520 - val_val_recon_loss: 4.2470e-04 - val_val_KL loss: 14.1678 - val_beta: 0.0049\n",
      "Epoch 4340/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 32.1041 - recon_loss: 4.2282e-04 - KL loss: 14.1994 - beta: 0.0049 - val_val_loss: 31.9123 - val_val_recon_loss: 4.2095e-04 - val_val_KL loss: 14.0869 - val_beta: 0.0049\n",
      "Epoch 4341/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 31.9461 - recon_loss: 4.2106e-04 - KL loss: 14.1161 - beta: 0.0049 - val_val_loss: 31.9500 - val_val_recon_loss: 4.1930e-04 - val_val_KL loss: 14.1948 - val_beta: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4342/10000\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 31.9146 - recon_loss: 4.1938e-04 - KL loss: 14.1558 - beta: 0.0049 - val_val_loss: 31.9238 - val_val_recon_loss: 4.1945e-04 - val_val_KL loss: 14.1622 - val_beta: 0.0049\n",
      "Epoch 4343/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 31.6598 - recon_loss: 4.1335e-04 - KL loss: 14.1564 - beta: 0.0049 - val_val_loss: 31.8340 - val_val_recon_loss: 4.1802e-04 - val_val_KL loss: 14.1328 - val_beta: 0.0049\n",
      "Epoch 4344/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.8898 - recon_loss: 4.1803e-04 - KL loss: 14.1883 - beta: 0.0049 - val_val_loss: 31.8212 - val_val_recon_loss: 4.1796e-04 - val_val_KL loss: 14.1225 - val_beta: 0.0049\n",
      "Epoch 4345/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.5708 - recon_loss: 4.1305e-04 - KL loss: 14.0802 - beta: 0.0049 - val_val_loss: 31.8156 - val_val_recon_loss: 4.1959e-04 - val_val_KL loss: 14.0480 - val_beta: 0.0049\n",
      "Epoch 4346/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.7873 - recon_loss: 4.1653e-04 - KL loss: 14.1491 - beta: 0.0049 - val_val_loss: 32.2034 - val_val_recon_loss: 4.3048e-04 - val_val_KL loss: 13.9747 - val_beta: 0.0049\n",
      "Epoch 4347/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.7031 - recon_loss: 4.1570e-04 - KL loss: 14.1002 - beta: 0.0049 - val_val_loss: 31.9462 - val_val_recon_loss: 4.2233e-04 - val_val_KL loss: 14.0625 - val_beta: 0.0049\n",
      "Epoch 4348/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.7732 - recon_loss: 4.1705e-04 - KL loss: 14.1131 - beta: 0.0049 - val_val_loss: 32.0747 - val_val_recon_loss: 4.2477e-04 - val_val_KL loss: 14.0877 - val_beta: 0.0049\n",
      "Epoch 4349/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 31.8697 - recon_loss: 4.1975e-04 - KL loss: 14.0951 - beta: 0.0049 - val_val_loss: 31.7936 - val_val_recon_loss: 4.1695e-04 - val_val_KL loss: 14.1376 - val_beta: 0.0049\n",
      "Epoch 4350/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.8794 - recon_loss: 4.1935e-04 - KL loss: 14.1217 - beta: 0.0049 - val_val_loss: 31.7895 - val_val_recon_loss: 4.1566e-04 - val_val_KL loss: 14.1881 - val_beta: 0.0049\n",
      "Epoch 4351/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.8055 - recon_loss: 4.1704e-04 - KL loss: 14.1457 - beta: 0.0049 - val_val_loss: 31.8642 - val_val_recon_loss: 4.1978e-04 - val_val_KL loss: 14.0884 - val_beta: 0.0049\n",
      "Epoch 4352/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.7673 - recon_loss: 4.1847e-04 - KL loss: 14.0471 - beta: 0.0049 - val_val_loss: 32.0637 - val_val_recon_loss: 4.2471e-04 - val_val_KL loss: 14.0791 - val_beta: 0.0049\n",
      "Epoch 4353/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.9142 - recon_loss: 4.2088e-04 - KL loss: 14.0919 - beta: 0.0049 - val_val_loss: 31.8905 - val_val_recon_loss: 4.1942e-04 - val_val_KL loss: 14.1298 - val_beta: 0.0049\n",
      "Epoch 4354/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 31.7260 - recon_loss: 4.1552e-04 - KL loss: 14.1305 - beta: 0.0049 - val_val_loss: 31.8879 - val_val_recon_loss: 4.2117e-04 - val_val_KL loss: 14.0534 - val_beta: 0.0049\n",
      "Epoch 4355/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31.6846 - recon_loss: 4.1685e-04 - KL loss: 14.0330 - beta: 0.0049\n",
      "Epoch 04355: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 31.6847 - recon_loss: 4.1685e-04 - KL loss: 14.0330 - beta: 0.0049 - val_val_loss: 31.8144 - val_val_recon_loss: 4.2015e-04 - val_val_KL loss: 14.0229 - val_beta: 0.0049\n",
      "Epoch 4356/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.6079 - recon_loss: 4.1295e-04 - KL loss: 14.1215 - beta: 0.0049 - val_val_loss: 31.6289 - val_val_recon_loss: 4.1165e-04 - val_val_KL loss: 14.1974 - val_beta: 0.0049\n",
      "Epoch 4357/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 31.6006 - recon_loss: 4.1261e-04 - KL loss: 14.1283 - beta: 0.0049 - val_val_loss: 31.6350 - val_val_recon_loss: 4.1328e-04 - val_val_KL loss: 14.1346 - val_beta: 0.0049\n",
      "Epoch 4358/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.5438 - recon_loss: 4.1149e-04 - KL loss: 14.1193 - beta: 0.0049 - val_val_loss: 31.6367 - val_val_recon_loss: 4.1306e-04 - val_val_KL loss: 14.1456 - val_beta: 0.0049\n",
      "Epoch 4359/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.5270 - recon_loss: 4.1131e-04 - KL loss: 14.1101 - beta: 0.0049 - val_val_loss: 31.6870 - val_val_recon_loss: 4.1551e-04 - val_val_KL loss: 14.0919 - val_beta: 0.0049\n",
      "Epoch 4360/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.4998 - recon_loss: 4.1070e-04 - KL loss: 14.1087 - beta: 0.0049 - val_val_loss: 31.6632 - val_val_recon_loss: 4.1639e-04 - val_val_KL loss: 14.0311 - val_beta: 0.0049\n",
      "Epoch 4361/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.4606 - recon_loss: 4.1084e-04 - KL loss: 14.0634 - beta: 0.0049 - val_val_loss: 31.5703 - val_val_recon_loss: 4.1374e-04 - val_val_KL loss: 14.0504 - val_beta: 0.0049\n",
      "Epoch 4362/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 31.5701 - recon_loss: 4.1150e-04 - KL loss: 14.1448 - beta: 0.0049 - val_val_loss: 31.5150 - val_val_recon_loss: 4.1064e-04 - val_val_KL loss: 14.1263 - val_beta: 0.0049\n",
      "Epoch 4363/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.4711 - recon_loss: 4.0928e-04 - KL loss: 14.1402 - beta: 0.0049 - val_val_loss: 31.5505 - val_val_recon_loss: 4.1093e-04 - val_val_KL loss: 14.1494 - val_beta: 0.0049\n",
      "Epoch 4364/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.4633 - recon_loss: 4.0964e-04 - KL loss: 14.1169 - beta: 0.0049 - val_val_loss: 31.5156 - val_val_recon_loss: 4.1074e-04 - val_val_KL loss: 14.1229 - val_beta: 0.0049\n",
      "Epoch 4365/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.4220 - recon_loss: 4.0885e-04 - KL loss: 14.1092 - beta: 0.0049 - val_val_loss: 31.5574 - val_val_recon_loss: 4.1136e-04 - val_val_KL loss: 14.1381 - val_beta: 0.0049\n",
      "Epoch 4366/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.4383 - recon_loss: 4.0925e-04 - KL loss: 14.1084 - beta: 0.0049 - val_val_loss: 31.4622 - val_val_recon_loss: 4.1068e-04 - val_val_KL loss: 14.0716 - val_beta: 0.0049\n",
      "Epoch 4367/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.3621 - recon_loss: 4.0781e-04 - KL loss: 14.0935 - beta: 0.0049 - val_val_loss: 31.4836 - val_val_recon_loss: 4.0919e-04 - val_val_KL loss: 14.1563 - val_beta: 0.0049\n",
      "Epoch 4368/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.4283 - recon_loss: 4.0948e-04 - KL loss: 14.0889 - beta: 0.0049 - val_val_loss: 31.4868 - val_val_recon_loss: 4.1072e-04 - val_val_KL loss: 14.0945 - val_beta: 0.0049\n",
      "Epoch 4369/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.4662 - recon_loss: 4.1047e-04 - KL loss: 14.0847 - beta: 0.0049 - val_val_loss: 31.5741 - val_val_recon_loss: 4.1479e-04 - val_val_KL loss: 14.0096 - val_beta: 0.0049\n",
      "Epoch 4370/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.5605 - recon_loss: 4.1267e-04 - KL loss: 14.0861 - beta: 0.0049 - val_val_loss: 31.7114 - val_val_recon_loss: 4.1741e-04 - val_val_KL loss: 14.0358 - val_beta: 0.0049\n",
      "Epoch 4371/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31.6483 - recon_loss: 4.1412e-04 - KL loss: 14.1124 - beta: 0.0049\n",
      "Epoch 04371: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 31.6483 - recon_loss: 4.1412e-04 - KL loss: 14.1124 - beta: 0.0049 - val_val_loss: 31.5757 - val_val_recon_loss: 4.1414e-04 - val_val_KL loss: 14.0387 - val_beta: 0.0049\n",
      "Epoch 4372/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.4173 - recon_loss: 4.0916e-04 - KL loss: 14.0914 - beta: 0.0049 - val_val_loss: 31.5386 - val_val_recon_loss: 4.1045e-04 - val_val_KL loss: 14.1579 - val_beta: 0.0049\n",
      "Epoch 4373/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.4602 - recon_loss: 4.0857e-04 - KL loss: 14.1591 - beta: 0.0049 - val_val_loss: 31.4922 - val_val_recon_loss: 4.1077e-04 - val_val_KL loss: 14.0981 - val_beta: 0.0049\n",
      "Epoch 4374/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.5067 - recon_loss: 4.0955e-04 - KL loss: 14.1640 - beta: 0.0049 - val_val_loss: 31.4942 - val_val_recon_loss: 4.1144e-04 - val_val_KL loss: 14.0718 - val_beta: 0.0049\n",
      "Epoch 4375/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.4462 - recon_loss: 4.0946e-04 - KL loss: 14.1074 - beta: 0.0049 - val_val_loss: 31.5123 - val_val_recon_loss: 4.1114e-04 - val_val_KL loss: 14.1022 - val_beta: 0.0049\n",
      "Epoch 4376/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31.4524 - recon_loss: 4.0916e-04 - KL loss: 14.1261 - beta: 0.0049\n",
      "Epoch 04376: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 31.4523 - recon_loss: 4.0916e-04 - KL loss: 14.1261 - beta: 0.0049 - val_val_loss: 31.4961 - val_val_recon_loss: 4.1118e-04 - val_val_KL loss: 14.0845 - val_beta: 0.0049\n",
      "Epoch 4376/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 24.3761 - recon_loss: 4.8035e-04 - KL loss: 12.3673 - beta: 0.0063 - val_val_loss: 24.5551 - val_val_recon_loss: 5.0283e-04 - val_val_KL loss: 11.9843 - val_beta: 0.0063\n",
      "Epoch 4377/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 24.5302 - recon_loss: 5.0009e-04 - KL loss: 12.0280 - beta: 0.0063 - val_val_loss: 24.3660 - val_val_recon_loss: 4.9214e-04 - val_val_KL loss: 12.0624 - val_beta: 0.0063\n",
      "Epoch 4378/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 24.5030 - recon_loss: 4.9931e-04 - KL loss: 12.0202 - beta: 0.0063 - val_val_loss: 24.8205 - val_val_recon_loss: 5.1435e-04 - val_val_KL loss: 11.9619 - val_beta: 0.0063\n",
      "Epoch 4379/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 24.6270 - recon_loss: 5.0787e-04 - KL loss: 11.9304 - beta: 0.0063 - val_val_loss: 24.6486 - val_val_recon_loss: 5.1346e-04 - val_val_KL loss: 11.8120 - val_beta: 0.0063\n",
      "Epoch 4380/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 24.5468 - recon_loss: 5.0637e-04 - KL loss: 11.8875 - beta: 0.0063 - val_val_loss: 24.9573 - val_val_recon_loss: 5.1999e-04 - val_val_KL loss: 11.9576 - val_beta: 0.0063\n",
      "Epoch 4381/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 25.1194 - recon_loss: 5.3092e-04 - KL loss: 11.8465 - beta: 0.0063 - val_val_loss: 24.9059 - val_val_recon_loss: 5.1207e-04 - val_val_KL loss: 12.1043 - val_beta: 0.0063\n",
      "Epoch 4382/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 24.6444 - recon_loss: 5.1093e-04 - KL loss: 11.8712 - beta: 0.0063\n",
      "Epoch 04382: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 24.6443 - recon_loss: 5.1093e-04 - KL loss: 11.8711 - beta: 0.0063 - val_val_loss: 24.4083 - val_val_recon_loss: 5.0650e-04 - val_val_KL loss: 11.7459 - val_beta: 0.0063\n",
      "Epoch 4383/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 24.2919 - recon_loss: 4.9819e-04 - KL loss: 11.8371 - beta: 0.0063 - val_val_loss: 24.1018 - val_val_recon_loss: 4.8673e-04 - val_val_KL loss: 11.9337 - val_beta: 0.0063\n",
      "Epoch 4384/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 24.0959 - recon_loss: 4.8959e-04 - KL loss: 11.8562 - beta: 0.0063 - val_val_loss: 24.1349 - val_val_recon_loss: 4.9229e-04 - val_val_KL loss: 11.8276 - val_beta: 0.0063\n",
      "Epoch 4385/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.9700 - recon_loss: 4.8677e-04 - KL loss: 11.8007 - beta: 0.0063 - val_val_loss: 24.0994 - val_val_recon_loss: 4.9333e-04 - val_val_KL loss: 11.7661 - val_beta: 0.0063\n",
      "Epoch 4386/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 24.0628 - recon_loss: 4.8864e-04 - KL loss: 11.8467 - beta: 0.0063 - val_val_loss: 23.9813 - val_val_recon_loss: 4.8444e-04 - val_val_KL loss: 11.8703 - val_beta: 0.0063\n",
      "Epoch 4387/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 24.1366 - recon_loss: 4.8981e-04 - KL loss: 11.8913 - beta: 0.0063 - val_val_loss: 24.0626 - val_val_recon_loss: 4.8847e-04 - val_val_KL loss: 11.8507 - val_beta: 0.0063\n",
      "Epoch 4388/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 24.0865 - recon_loss: 4.8917e-04 - KL loss: 11.8574 - beta: 0.0063 - val_val_loss: 24.0966 - val_val_recon_loss: 4.9153e-04 - val_val_KL loss: 11.8082 - val_beta: 0.0063\n",
      "Epoch 4389/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 24.0136 - recon_loss: 4.8836e-04 - KL loss: 11.8046 - beta: 0.0063 - val_val_loss: 24.0009 - val_val_recon_loss: 4.8624e-04 - val_val_KL loss: 11.8449 - val_beta: 0.0063\n",
      "Epoch 4390/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 24.0736 - recon_loss: 4.9135e-04 - KL loss: 11.7898 - beta: 0.0063 - val_val_loss: 24.0637 - val_val_recon_loss: 4.8754e-04 - val_val_KL loss: 11.8751 - val_beta: 0.0063\n",
      "Epoch 4391/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 24.0049 - recon_loss: 4.8737e-04 - KL loss: 11.8206 - beta: 0.0063\n",
      "Epoch 04391: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 24.0049 - recon_loss: 4.8737e-04 - KL loss: 11.8206 - beta: 0.0063 - val_val_loss: 24.0714 - val_val_recon_loss: 4.9214e-04 - val_val_KL loss: 11.7678 - val_beta: 0.0063\n",
      "Epoch 4392/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 23.8324 - recon_loss: 4.8207e-04 - KL loss: 11.7807 - beta: 0.0063 - val_val_loss: 23.9600 - val_val_recon_loss: 4.8458e-04 - val_val_KL loss: 11.8456 - val_beta: 0.0063\n",
      "Epoch 4393/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.9165 - recon_loss: 4.8237e-04 - KL loss: 11.8573 - beta: 0.0063 - val_val_loss: 23.9409 - val_val_recon_loss: 4.8501e-04 - val_val_KL loss: 11.8157 - val_beta: 0.0063\n",
      "Epoch 4394/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.9231 - recon_loss: 4.8311e-04 - KL loss: 11.8453 - beta: 0.0063 - val_val_loss: 23.8626 - val_val_recon_loss: 4.8411e-04 - val_val_KL loss: 11.7599 - val_beta: 0.0063\n",
      "Epoch 4395/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.8651 - recon_loss: 4.8304e-04 - KL loss: 11.7891 - beta: 0.0063 - val_val_loss: 23.8736 - val_val_recon_loss: 4.8162e-04 - val_val_KL loss: 11.8330 - val_beta: 0.0063\n",
      "Epoch 4396/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.8205 - recon_loss: 4.7967e-04 - KL loss: 11.8288 - beta: 0.0063 - val_val_loss: 23.8402 - val_val_recon_loss: 4.7939e-04 - val_val_KL loss: 11.8554 - val_beta: 0.0063\n",
      "Epoch 4397/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 23.7896 - recon_loss: 4.7767e-04 - KL loss: 11.8479 - beta: 0.0063 - val_val_loss: 23.8497 - val_val_recon_loss: 4.7905e-04 - val_val_KL loss: 11.8735 - val_beta: 0.0063\n",
      "Epoch 4398/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.8310 - recon_loss: 4.7798e-04 - KL loss: 11.8815 - beta: 0.0063 - val_val_loss: 23.8596 - val_val_recon_loss: 4.8108e-04 - val_val_KL loss: 11.8328 - val_beta: 0.0063\n",
      "Epoch 4399/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.8781 - recon_loss: 4.8049e-04 - KL loss: 11.8658 - beta: 0.0063 - val_val_loss: 23.9490 - val_val_recon_loss: 4.8963e-04 - val_val_KL loss: 11.7082 - val_beta: 0.0063\n",
      "Epoch 4400/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.8298 - recon_loss: 4.8089e-04 - KL loss: 11.8076 - beta: 0.0063 - val_val_loss: 23.8489 - val_val_recon_loss: 4.8073e-04 - val_val_KL loss: 11.8306 - val_beta: 0.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4401/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.8521 - recon_loss: 4.7982e-04 - KL loss: 11.8567 - beta: 0.0063 - val_val_loss: 23.8206 - val_val_recon_loss: 4.7746e-04 - val_val_KL loss: 11.8841 - val_beta: 0.0063\n",
      "Epoch 4402/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7924 - recon_loss: 4.7793e-04 - KL loss: 11.8441 - beta: 0.0063 - val_val_loss: 23.8413 - val_val_recon_loss: 4.8001e-04 - val_val_KL loss: 11.8411 - val_beta: 0.0063\n",
      "Epoch 4403/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.8550 - recon_loss: 4.7904e-04 - KL loss: 11.8789 - beta: 0.0063 - val_val_loss: 23.8581 - val_val_recon_loss: 4.7968e-04 - val_val_KL loss: 11.8661 - val_beta: 0.0063\n",
      "Epoch 4404/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7698 - recon_loss: 4.7739e-04 - KL loss: 11.8350 - beta: 0.0063 - val_val_loss: 23.8410 - val_val_recon_loss: 4.8055e-04 - val_val_KL loss: 11.8272 - val_beta: 0.0063\n",
      "Epoch 4405/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7414 - recon_loss: 4.7748e-04 - KL loss: 11.8044 - beta: 0.0063 - val_val_loss: 23.8914 - val_val_recon_loss: 4.8576e-04 - val_val_KL loss: 11.7473 - val_beta: 0.0063\n",
      "Epoch 4406/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 23.8843 - recon_loss: 4.8391e-04 - KL loss: 11.7867 - beta: 0.0063\n",
      "Epoch 04406: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.8842 - recon_loss: 4.8390e-04 - KL loss: 11.7867 - beta: 0.0063 - val_val_loss: 23.8255 - val_val_recon_loss: 4.7822e-04 - val_val_KL loss: 11.8700 - val_beta: 0.0063\n",
      "Epoch 4407/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.6526 - recon_loss: 4.7215e-04 - KL loss: 11.8490 - beta: 0.0063 - val_val_loss: 23.8229 - val_val_recon_loss: 4.7933e-04 - val_val_KL loss: 11.8396 - val_beta: 0.0063\n",
      "Epoch 4408/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 23.8449 - recon_loss: 4.7951e-04 - KL loss: 11.8571 - beta: 0.0063 - val_val_loss: 23.8361 - val_val_recon_loss: 4.7983e-04 - val_val_KL loss: 11.8404 - val_beta: 0.0063\n",
      "Epoch 4409/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7298 - recon_loss: 4.7620e-04 - KL loss: 11.8249 - beta: 0.0063 - val_val_loss: 23.7978 - val_val_recon_loss: 4.7819e-04 - val_val_KL loss: 11.8429 - val_beta: 0.0063\n",
      "Epoch 4410/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.8500 - recon_loss: 4.7995e-04 - KL loss: 11.8513 - beta: 0.0063 - val_val_loss: 23.8248 - val_val_recon_loss: 4.7847e-04 - val_val_KL loss: 11.8630 - val_beta: 0.0063\n",
      "Epoch 4411/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7969 - recon_loss: 4.7671e-04 - KL loss: 11.8793 - beta: 0.0063 - val_val_loss: 23.7799 - val_val_recon_loss: 4.7829e-04 - val_val_KL loss: 11.8226 - val_beta: 0.0063\n",
      "Epoch 4412/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7409 - recon_loss: 4.7672e-04 - KL loss: 11.8229 - beta: 0.0063 - val_val_loss: 23.7862 - val_val_recon_loss: 4.7559e-04 - val_val_KL loss: 11.8965 - val_beta: 0.0063\n",
      "Epoch 4413/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 23.5928 - recon_loss: 4.7234e-04 - KL loss: 11.7842 - beta: 0.0063 - val_val_loss: 23.7812 - val_val_recon_loss: 4.7769e-04 - val_val_KL loss: 11.8389 - val_beta: 0.0063\n",
      "Epoch 4414/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.6221 - recon_loss: 4.7285e-04 - KL loss: 11.8009 - beta: 0.0063 - val_val_loss: 23.7894 - val_val_recon_loss: 4.7906e-04 - val_val_KL loss: 11.8128 - val_beta: 0.0063\n",
      "Epoch 4415/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 23.7476 - recon_loss: 4.7660e-04 - KL loss: 11.8325 - beta: 0.0063 - val_val_loss: 23.8291 - val_val_recon_loss: 4.8015e-04 - val_val_KL loss: 11.8254 - val_beta: 0.0063\n",
      "Epoch 4416/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 23.7030 - recon_loss: 4.7543e-04 - KL loss: 11.8172 - beta: 0.0063\n",
      "Epoch 04416: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7029 - recon_loss: 4.7543e-04 - KL loss: 11.8171 - beta: 0.0063 - val_val_loss: 23.8044 - val_val_recon_loss: 4.8037e-04 - val_val_KL loss: 11.7953 - val_beta: 0.0063\n",
      "Epoch 4417/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.6495 - recon_loss: 4.7456e-04 - KL loss: 11.7853 - beta: 0.0063 - val_val_loss: 23.7820 - val_val_recon_loss: 4.7897e-04 - val_val_KL loss: 11.8078 - val_beta: 0.0063\n",
      "Epoch 4418/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 23.7914 - recon_loss: 4.7874e-04 - KL loss: 11.8228 - beta: 0.0063 - val_val_loss: 23.7717 - val_val_recon_loss: 4.7780e-04 - val_val_KL loss: 11.8267 - val_beta: 0.0063\n",
      "Epoch 4419/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7300 - recon_loss: 4.7461e-04 - KL loss: 11.8649 - beta: 0.0063 - val_val_loss: 23.7706 - val_val_recon_loss: 4.7706e-04 - val_val_KL loss: 11.8441 - val_beta: 0.0063\n",
      "Epoch 4420/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7440 - recon_loss: 4.7634e-04 - KL loss: 11.8356 - beta: 0.0063 - val_val_loss: 23.8164 - val_val_recon_loss: 4.7843e-04 - val_val_KL loss: 11.8555 - val_beta: 0.0063\n",
      "Epoch 4421/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.6514 - recon_loss: 4.7298e-04 - KL loss: 11.8269 - beta: 0.0063 - val_val_loss: 23.7997 - val_val_recon_loss: 4.7875e-04 - val_val_KL loss: 11.8309 - val_beta: 0.0063\n",
      "Epoch 4422/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7527 - recon_loss: 4.7603e-04 - KL loss: 11.8519 - beta: 0.0063 - val_val_loss: 23.8020 - val_val_recon_loss: 4.7894e-04 - val_val_KL loss: 11.8286 - val_beta: 0.0063\n",
      "Epoch 4423/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7157 - recon_loss: 4.7542e-04 - KL loss: 11.8301 - beta: 0.0063 - val_val_loss: 23.7843 - val_val_recon_loss: 4.7797e-04 - val_val_KL loss: 11.8350 - val_beta: 0.0063\n",
      "Epoch 4424/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 23.6956 - recon_loss: 4.7369e-04 - KL loss: 11.8533 - beta: 0.0063\n",
      "Epoch 04424: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.6957 - recon_loss: 4.7369e-04 - KL loss: 11.8534 - beta: 0.0063 - val_val_loss: 23.7804 - val_val_recon_loss: 4.7725e-04 - val_val_KL loss: 11.8491 - val_beta: 0.0063\n",
      "Epoch 4425/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.8602 - recon_loss: 4.7936e-04 - KL loss: 11.8763 - beta: 0.0063 - val_val_loss: 23.7626 - val_val_recon_loss: 4.7678e-04 - val_val_KL loss: 11.8431 - val_beta: 0.0063\n",
      "Epoch 4426/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 23.8151 - recon_loss: 4.7823e-04 - KL loss: 11.8593 - beta: 0.0063 - val_val_loss: 23.7460 - val_val_recon_loss: 4.7634e-04 - val_val_KL loss: 11.8376 - val_beta: 0.0063\n",
      "Epoch 4427/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.6297 - recon_loss: 4.7271e-04 - KL loss: 11.8120 - beta: 0.0063 - val_val_loss: 23.7842 - val_val_recon_loss: 4.7803e-04 - val_val_KL loss: 11.8333 - val_beta: 0.0063\n",
      "Epoch 4428/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.6479 - recon_loss: 4.7323e-04 - KL loss: 11.8172 - beta: 0.0063 - val_val_loss: 23.7777 - val_val_recon_loss: 4.7773e-04 - val_val_KL loss: 11.8344 - val_beta: 0.0063\n",
      "Epoch 4429/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7076 - recon_loss: 4.7529e-04 - KL loss: 11.8254 - beta: 0.0063 - val_val_loss: 23.7796 - val_val_recon_loss: 4.7834e-04 - val_val_KL loss: 11.8210 - val_beta: 0.0063\n",
      "Epoch 4430/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 157s 157ms/step - loss: 23.8097 - recon_loss: 4.7862e-04 - KL loss: 11.8443 - beta: 0.0063 - val_val_loss: 23.7798 - val_val_recon_loss: 4.7829e-04 - val_val_KL loss: 11.8225 - val_beta: 0.0063\n",
      "Epoch 4431/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 23.6841 - recon_loss: 4.7376e-04 - KL loss: 11.8402 - beta: 0.0063\n",
      "Epoch 04431: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.6841 - recon_loss: 4.7376e-04 - KL loss: 11.8402 - beta: 0.0063 - val_val_loss: 23.7911 - val_val_recon_loss: 4.7902e-04 - val_val_KL loss: 11.8157 - val_beta: 0.0063\n",
      "Epoch 4432/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7619 - recon_loss: 4.7656e-04 - KL loss: 11.8478 - beta: 0.0063 - val_val_loss: 23.7964 - val_val_recon_loss: 4.7926e-04 - val_val_KL loss: 11.8150 - val_beta: 0.0063\n",
      "Epoch 4433/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.7548 - recon_loss: 4.7781e-04 - KL loss: 11.8095 - beta: 0.0063 - val_val_loss: 23.7686 - val_val_recon_loss: 4.7812e-04 - val_val_KL loss: 11.8157 - val_beta: 0.0063\n",
      "Epoch 4434/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 23.6967 - recon_loss: 4.7608e-04 - KL loss: 11.7947 - beta: 0.0063 - val_val_loss: 23.7492 - val_val_recon_loss: 4.7686e-04 - val_val_KL loss: 11.8277 - val_beta: 0.0063\n",
      "Epoch 4435/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 23.6764 - recon_loss: 4.7416e-04 - KL loss: 11.8224 - beta: 0.0063 - val_val_loss: 23.7954 - val_val_recon_loss: 4.7870e-04 - val_val_KL loss: 11.8278 - val_beta: 0.0063\n",
      "Epoch 4436/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 23.6801 - recon_loss: 4.7428e-04 - KL loss: 11.8230 - beta: 0.0063\n",
      "Epoch 04436: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 23.6801 - recon_loss: 4.7428e-04 - KL loss: 11.8231 - beta: 0.0063 - val_val_loss: 23.7711 - val_val_recon_loss: 4.7780e-04 - val_val_KL loss: 11.8261 - val_beta: 0.0063\n",
      "Epoch 4436/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.7808 - recon_loss: 5.7433e-04 - KL loss: 10.3039 - beta: 0.0082 - val_val_loss: 19.3464 - val_val_recon_loss: 6.2388e-04 - val_val_KL loss: 10.1382 - val_beta: 0.0082\n",
      "Epoch 4437/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 19.0680 - recon_loss: 6.1068e-04 - KL loss: 10.0547 - beta: 0.0082 - val_val_loss: 19.2892 - val_val_recon_loss: 6.3967e-04 - val_val_KL loss: 9.8480 - val_beta: 0.0082\n",
      "Epoch 4438/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 19.0232 - recon_loss: 6.1738e-04 - KL loss: 9.9110 - beta: 0.0082 - val_val_loss: 18.8625 - val_val_recon_loss: 6.0373e-04 - val_val_KL loss: 9.9517 - val_beta: 0.0082\n",
      "Epoch 4439/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 19.0375 - recon_loss: 6.1605e-04 - KL loss: 9.9449 - beta: 0.0082 - val_val_loss: 19.0065 - val_val_recon_loss: 6.1636e-04 - val_val_KL loss: 9.9093 - val_beta: 0.0082\n",
      "Epoch 4440/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 18.8666 - recon_loss: 6.0629e-04 - KL loss: 9.9180 - beta: 0.0082 - val_val_loss: 18.8980 - val_val_recon_loss: 6.0921e-04 - val_val_KL loss: 9.9063 - val_beta: 0.0082\n",
      "Epoch 4441/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.9896 - recon_loss: 6.1717e-04 - KL loss: 9.8805 - beta: 0.0082 - val_val_loss: 18.9212 - val_val_recon_loss: 6.1472e-04 - val_val_KL loss: 9.8482 - val_beta: 0.0082\n",
      "Epoch 4442/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 18.8705 - recon_loss: 6.1361e-04 - KL loss: 9.8138 - beta: 0.0082 - val_val_loss: 19.1362 - val_val_recon_loss: 6.2829e-04 - val_val_KL loss: 9.8629 - val_beta: 0.0082\n",
      "Epoch 4443/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 19.0665 - recon_loss: 6.1966e-04 - KL loss: 9.9205 - beta: 0.0082\n",
      "Epoch 04443: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 19.0666 - recon_loss: 6.1967e-04 - KL loss: 9.9205 - beta: 0.0082 - val_val_loss: 19.0659 - val_val_recon_loss: 6.1760e-04 - val_val_KL loss: 9.9504 - val_beta: 0.0082\n",
      "Epoch 4444/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.8636 - recon_loss: 6.0835e-04 - KL loss: 9.8846 - beta: 0.0082 - val_val_loss: 18.7956 - val_val_recon_loss: 6.0865e-04 - val_val_KL loss: 9.8123 - val_beta: 0.0082\n",
      "Epoch 4445/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.8323 - recon_loss: 6.0669e-04 - KL loss: 9.8777 - beta: 0.0082 - val_val_loss: 18.6948 - val_val_recon_loss: 6.0290e-04 - val_val_KL loss: 9.7963 - val_beta: 0.0082\n",
      "Epoch 4446/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.6776 - recon_loss: 5.9741e-04 - KL loss: 9.8600 - beta: 0.0082 - val_val_loss: 18.6185 - val_val_recon_loss: 5.9091e-04 - val_val_KL loss: 9.8969 - val_beta: 0.0082\n",
      "Epoch 4447/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.6775 - recon_loss: 5.9952e-04 - KL loss: 9.8288 - beta: 0.0082 - val_val_loss: 18.6492 - val_val_recon_loss: 6.0131e-04 - val_val_KL loss: 9.7741 - val_beta: 0.0082\n",
      "Epoch 4448/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 18.6159 - recon_loss: 5.9625e-04 - KL loss: 9.8155 - beta: 0.0082 - val_val_loss: 18.5820 - val_val_recon_loss: 5.9599e-04 - val_val_KL loss: 9.7855 - val_beta: 0.0082\n",
      "Epoch 4449/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 18.5749 - recon_loss: 5.9126e-04 - KL loss: 9.8482 - beta: 0.0082 - val_val_loss: 18.7203 - val_val_recon_loss: 6.1664e-04 - val_val_KL loss: 9.6190 - val_beta: 0.0082\n",
      "Epoch 4450/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 18.5891 - recon_loss: 5.9940e-04 - KL loss: 9.7421 - beta: 0.0082 - val_val_loss: 18.6724 - val_val_recon_loss: 5.9598e-04 - val_val_KL loss: 9.8761 - val_beta: 0.0082\n",
      "Epoch 4451/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 18.6871 - recon_loss: 6.0314e-04 - KL loss: 9.7850 - beta: 0.0082 - val_val_loss: 18.7866 - val_val_recon_loss: 6.0095e-04 - val_val_KL loss: 9.9168 - val_beta: 0.0082\n",
      "Epoch 4452/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 18.6355 - recon_loss: 5.9905e-04 - KL loss: 9.7939 - beta: 0.0082 - val_val_loss: 18.6638 - val_val_recon_loss: 5.9896e-04 - val_val_KL loss: 9.8234 - val_beta: 0.0082\n",
      "Epoch 4453/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18.5907 - recon_loss: 5.9729e-04 - KL loss: 9.7750 - beta: 0.0082\n",
      "Epoch 04453: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.5907 - recon_loss: 5.9729e-04 - KL loss: 9.7750 - beta: 0.0082 - val_val_loss: 18.6217 - val_val_recon_loss: 5.9838e-04 - val_val_KL loss: 9.7898 - val_beta: 0.0082\n",
      "Epoch 4454/10000\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 18.5702 - recon_loss: 5.9305e-04 - KL loss: 9.8171 - beta: 0.0082 - val_val_loss: 18.5360 - val_val_recon_loss: 5.9166e-04 - val_val_KL loss: 9.8033 - val_beta: 0.0082\n",
      "Epoch 4455/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.5341 - recon_loss: 5.8933e-04 - KL loss: 9.8358 - beta: 0.0082 - val_val_loss: 18.5237 - val_val_recon_loss: 5.8858e-04 - val_val_KL loss: 9.8365 - val_beta: 0.0082\n",
      "Epoch 4456/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.4445 - recon_loss: 5.8453e-04 - KL loss: 9.8170 - beta: 0.0082 - val_val_loss: 18.5130 - val_val_recon_loss: 5.9052e-04 - val_val_KL loss: 9.7972 - val_beta: 0.0082\n",
      "Epoch 4457/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 18.4314 - recon_loss: 5.8416e-04 - KL loss: 9.8095 - beta: 0.0082 - val_val_loss: 18.4950 - val_val_recon_loss: 5.9181e-04 - val_val_KL loss: 9.7601 - val_beta: 0.0082\n",
      "Epoch 4458/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.4463 - recon_loss: 5.8556e-04 - KL loss: 9.8037 - beta: 0.0082 - val_val_loss: 18.4344 - val_val_recon_loss: 5.8722e-04 - val_val_KL loss: 9.7672 - val_beta: 0.0082\n",
      "Epoch 4459/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.4299 - recon_loss: 5.8417e-04 - KL loss: 9.8077 - beta: 0.0082 - val_val_loss: 18.4490 - val_val_recon_loss: 5.8378e-04 - val_val_KL loss: 9.8327 - val_beta: 0.0082\n",
      "Epoch 4460/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.3795 - recon_loss: 5.7914e-04 - KL loss: 9.8317 - beta: 0.0082 - val_val_loss: 18.4713 - val_val_recon_loss: 5.8247e-04 - val_val_KL loss: 9.8743 - val_beta: 0.0082\n",
      "Epoch 4461/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.4407 - recon_loss: 5.8110e-04 - KL loss: 9.8639 - beta: 0.0082 - val_val_loss: 18.4897 - val_val_recon_loss: 5.8523e-04 - val_val_KL loss: 9.8520 - val_beta: 0.0082\n",
      "Epoch 4462/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.4238 - recon_loss: 5.8299e-04 - KL loss: 9.8191 - beta: 0.0082 - val_val_loss: 18.4668 - val_val_recon_loss: 5.8557e-04 - val_val_KL loss: 9.8240 - val_beta: 0.0082\n",
      "Epoch 4463/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18.4133 - recon_loss: 5.8410e-04 - KL loss: 9.7923 - beta: 0.0082\n",
      "Epoch 04463: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.4133 - recon_loss: 5.8410e-04 - KL loss: 9.7923 - beta: 0.0082 - val_val_loss: 18.4703 - val_val_recon_loss: 5.8908e-04 - val_val_KL loss: 9.7758 - val_beta: 0.0082\n",
      "Epoch 4464/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.4503 - recon_loss: 5.8533e-04 - KL loss: 9.8110 - beta: 0.0082 - val_val_loss: 18.4724 - val_val_recon_loss: 5.8508e-04 - val_val_KL loss: 9.8369 - val_beta: 0.0082\n",
      "Epoch 4465/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.4330 - recon_loss: 5.8255e-04 - KL loss: 9.8349 - beta: 0.0082 - val_val_loss: 18.4645 - val_val_recon_loss: 5.8651e-04 - val_val_KL loss: 9.8079 - val_beta: 0.0082\n",
      "Epoch 4466/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.3953 - recon_loss: 5.8046e-04 - KL loss: 9.8279 - beta: 0.0082 - val_val_loss: 18.4645 - val_val_recon_loss: 5.8613e-04 - val_val_KL loss: 9.8134 - val_beta: 0.0082\n",
      "Epoch 4467/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.4145 - recon_loss: 5.8116e-04 - KL loss: 9.8367 - beta: 0.0082 - val_val_loss: 18.4761 - val_val_recon_loss: 5.8598e-04 - val_val_KL loss: 9.8273 - val_beta: 0.0082\n",
      "Epoch 4468/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18.4441 - recon_loss: 5.8306e-04 - KL loss: 9.8384 - beta: 0.0082\n",
      "Epoch 04468: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 18.4441 - recon_loss: 5.8306e-04 - KL loss: 9.8384 - beta: 0.0082 - val_val_loss: 18.4486 - val_val_recon_loss: 5.8563e-04 - val_val_KL loss: 9.8050 - val_beta: 0.0082\n",
      "Epoch 4468/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.7732 - recon_loss: 7.1788e-04 - KL loss: 8.5178 - beta: 0.0107 - val_val_loss: 14.7971 - val_val_recon_loss: 7.5675e-04 - val_val_KL loss: 8.2029 - val_beta: 0.0107\n",
      "Epoch 4469/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 14.8280 - recon_loss: 7.5915e-04 - KL loss: 8.2130 - beta: 0.0107 - val_val_loss: 14.9838 - val_val_recon_loss: 7.7561e-04 - val_val_KL loss: 8.2253 - val_beta: 0.0107\n",
      "Epoch 4470/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.9777 - recon_loss: 7.8190e-04 - KL loss: 8.1644 - beta: 0.0107 - val_val_loss: 14.8749 - val_val_recon_loss: 7.6106e-04 - val_val_KL loss: 8.2432 - val_beta: 0.0107\n",
      "Epoch 4471/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.8647 - recon_loss: 7.6793e-04 - KL loss: 8.1731 - beta: 0.0107 - val_val_loss: 14.8573 - val_val_recon_loss: 7.7216e-04 - val_val_KL loss: 8.1288 - val_beta: 0.0107\n",
      "Epoch 4472/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.7805 - recon_loss: 7.6571e-04 - KL loss: 8.1082 - beta: 0.0107 - val_val_loss: 14.8139 - val_val_recon_loss: 7.6471e-04 - val_val_KL loss: 8.1504 - val_beta: 0.0107\n",
      "Epoch 4473/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.8623 - recon_loss: 7.7666e-04 - KL loss: 8.0947 - beta: 0.0107 - val_val_loss: 14.7156 - val_val_recon_loss: 7.5885e-04 - val_val_KL loss: 8.1031 - val_beta: 0.0107\n",
      "Epoch 4474/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 14.7573 - recon_loss: 7.6480e-04 - KL loss: 8.0929 - beta: 0.0107 - val_val_loss: 14.8049 - val_val_recon_loss: 7.5919e-04 - val_val_KL loss: 8.1895 - val_beta: 0.0107\n",
      "Epoch 4475/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.8634 - recon_loss: 7.7728e-04 - KL loss: 8.0903 - beta: 0.0107 - val_val_loss: 15.1398 - val_val_recon_loss: 8.2253e-04 - val_val_KL loss: 7.9724 - val_beta: 0.0107\n",
      "Epoch 4476/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.9973 - recon_loss: 7.9023e-04 - KL loss: 8.1114 - beta: 0.0107 - val_val_loss: 14.8062 - val_val_recon_loss: 7.8642e-04 - val_val_KL loss: 7.9534 - val_beta: 0.0107\n",
      "Epoch 4477/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.7934 - recon_loss: 7.7453e-04 - KL loss: 8.0443 - beta: 0.0107 - val_val_loss: 14.7867 - val_val_recon_loss: 7.7910e-04 - val_val_KL loss: 7.9978 - val_beta: 0.0107\n",
      "Epoch 4478/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.7292 - recon_loss: 7.7090e-04 - KL loss: 8.0116 - beta: 0.0107\n",
      "Epoch 04478: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.7291 - recon_loss: 7.7090e-04 - KL loss: 8.0117 - beta: 0.0107 - val_val_loss: 14.8657 - val_val_recon_loss: 7.8531e-04 - val_val_KL loss: 8.0227 - val_beta: 0.0107\n",
      "Epoch 4479/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.6451 - recon_loss: 7.5862e-04 - KL loss: 8.0346 - beta: 0.0107 - val_val_loss: 14.7329 - val_val_recon_loss: 7.6840e-04 - val_val_KL loss: 8.0372 - val_beta: 0.0107\n",
      "Epoch 4480/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.6631 - recon_loss: 7.6336e-04 - KL loss: 8.0113 - beta: 0.0107 - val_val_loss: 14.6623 - val_val_recon_loss: 7.6105e-04 - val_val_KL loss: 8.0307 - val_beta: 0.0107\n",
      "Epoch 4481/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.7181 - recon_loss: 7.6628e-04 - KL loss: 8.0409 - beta: 0.0107 - val_val_loss: 14.6822 - val_val_recon_loss: 7.6908e-04 - val_val_KL loss: 7.9806 - val_beta: 0.0107\n",
      "Epoch 4482/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.6656 - recon_loss: 7.6230e-04 - KL loss: 8.0231 - beta: 0.0107 - val_val_loss: 14.7942 - val_val_recon_loss: 7.7871e-04 - val_val_KL loss: 8.0086 - val_beta: 0.0107\n",
      "Epoch 4483/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.7085 - recon_loss: 7.6745e-04 - KL loss: 8.0211 - beta: 0.0107 - val_val_loss: 14.6212 - val_val_recon_loss: 7.6463e-04 - val_val_KL loss: 7.9584 - val_beta: 0.0107\n",
      "Epoch 4484/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 14.5593 - recon_loss: 7.5186e-04 - KL loss: 8.0077 - beta: 0.0107 - val_val_loss: 14.5989 - val_val_recon_loss: 7.5480e-04 - val_val_KL loss: 8.0218 - val_beta: 0.0107\n",
      "Epoch 4485/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5287 - recon_loss: 7.5014e-04 - KL loss: 7.9921 - beta: 0.0107 - val_val_loss: 14.6249 - val_val_recon_loss: 7.6404e-04 - val_val_KL loss: 7.9672 - val_beta: 0.0107\n",
      "Epoch 4486/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5595 - recon_loss: 7.5219e-04 - KL loss: 8.0051 - beta: 0.0107 - val_val_loss: 14.5821 - val_val_recon_loss: 7.5438e-04 - val_val_KL loss: 8.0086 - val_beta: 0.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4487/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5732 - recon_loss: 7.5065e-04 - KL loss: 8.0321 - beta: 0.0107 - val_val_loss: 14.5663 - val_val_recon_loss: 7.4894e-04 - val_val_KL loss: 8.0402 - val_beta: 0.0107\n",
      "Epoch 4488/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5085 - recon_loss: 7.4277e-04 - KL loss: 8.0362 - beta: 0.0107 - val_val_loss: 14.5599 - val_val_recon_loss: 7.4737e-04 - val_val_KL loss: 8.0474 - val_beta: 0.0107\n",
      "Epoch 4489/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5746 - recon_loss: 7.4951e-04 - KL loss: 8.0434 - beta: 0.0107 - val_val_loss: 14.5894 - val_val_recon_loss: 7.5379e-04 - val_val_KL loss: 8.0209 - val_beta: 0.0107\n",
      "Epoch 4490/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5634 - recon_loss: 7.5363e-04 - KL loss: 7.9964 - beta: 0.0107 - val_val_loss: 14.6096 - val_val_recon_loss: 7.5722e-04 - val_val_KL loss: 8.0113 - val_beta: 0.0107\n",
      "Epoch 4491/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.6179 - recon_loss: 7.5816e-04 - KL loss: 8.0115 - beta: 0.0107 - val_val_loss: 14.6298 - val_val_recon_loss: 7.5751e-04 - val_val_KL loss: 8.0290 - val_beta: 0.0107\n",
      "Epoch 4492/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5604 - recon_loss: 7.5453e-04 - KL loss: 7.9855 - beta: 0.0107 - val_val_loss: 14.6734 - val_val_recon_loss: 7.6733e-04 - val_val_KL loss: 7.9870 - val_beta: 0.0107\n",
      "Epoch 4493/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.6105 - recon_loss: 7.5843e-04 - KL loss: 8.0017 - beta: 0.0107\n",
      "Epoch 04493: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.6105 - recon_loss: 7.5843e-04 - KL loss: 8.0017 - beta: 0.0107 - val_val_loss: 14.6627 - val_val_recon_loss: 7.6248e-04 - val_val_KL loss: 8.0186 - val_beta: 0.0107\n",
      "Epoch 4494/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.6893 - recon_loss: 7.6405e-04 - KL loss: 8.0314 - beta: 0.0107 - val_val_loss: 14.6361 - val_val_recon_loss: 7.5705e-04 - val_val_KL loss: 8.0393 - val_beta: 0.0107\n",
      "Epoch 4495/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.6347 - recon_loss: 7.6015e-04 - KL loss: 8.0109 - beta: 0.0107 - val_val_loss: 14.5968 - val_val_recon_loss: 7.5463e-04 - val_val_KL loss: 8.0210 - val_beta: 0.0107\n",
      "Epoch 4496/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5467 - recon_loss: 7.4927e-04 - KL loss: 8.0177 - beta: 0.0107 - val_val_loss: 14.5764 - val_val_recon_loss: 7.5391e-04 - val_val_KL loss: 8.0069 - val_beta: 0.0107\n",
      "Epoch 4497/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5986 - recon_loss: 7.5252e-04 - KL loss: 8.0412 - beta: 0.0107 - val_val_loss: 14.5542 - val_val_recon_loss: 7.4951e-04 - val_val_KL loss: 8.0232 - val_beta: 0.0107\n",
      "Epoch 4498/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 14.5543 - recon_loss: 7.5085e-04 - KL loss: 8.0116 - beta: 0.0107 - val_val_loss: 14.5722 - val_val_recon_loss: 7.5440e-04 - val_val_KL loss: 7.9985 - val_beta: 0.0107\n",
      "Epoch 4499/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5697 - recon_loss: 7.5291e-04 - KL loss: 8.0090 - beta: 0.0107 - val_val_loss: 14.5430 - val_val_recon_loss: 7.5050e-04 - val_val_KL loss: 8.0033 - val_beta: 0.0107\n",
      "Epoch 4500/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 14.5131 - recon_loss: 7.4546e-04 - KL loss: 8.0173 - beta: 0.0107 - val_val_loss: 14.5285 - val_val_recon_loss: 7.4968e-04 - val_val_KL loss: 7.9959 - val_beta: 0.0107\n",
      "Epoch 4501/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5626 - recon_loss: 7.4945e-04 - KL loss: 8.0320 - beta: 0.0107 - val_val_loss: 14.5322 - val_val_recon_loss: 7.5021e-04 - val_val_KL loss: 7.9950 - val_beta: 0.0107\n",
      "Epoch 4502/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5114 - recon_loss: 7.4726e-04 - KL loss: 7.9999 - beta: 0.0107 - val_val_loss: 14.5332 - val_val_recon_loss: 7.5046e-04 - val_val_KL loss: 7.9938 - val_beta: 0.0107\n",
      "Epoch 4503/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5030 - recon_loss: 7.4582e-04 - KL loss: 8.0040 - beta: 0.0107 - val_val_loss: 14.5179 - val_val_recon_loss: 7.4631e-04 - val_val_KL loss: 8.0147 - val_beta: 0.0107\n",
      "Epoch 4504/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5661 - recon_loss: 7.5012e-04 - KL loss: 8.0296 - beta: 0.0107 - val_val_loss: 14.5319 - val_val_recon_loss: 7.4947e-04 - val_val_KL loss: 8.0012 - val_beta: 0.0107\n",
      "Epoch 4505/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5167 - recon_loss: 7.4746e-04 - KL loss: 8.0035 - beta: 0.0107 - val_val_loss: 14.5504 - val_val_recon_loss: 7.5140e-04 - val_val_KL loss: 8.0028 - val_beta: 0.0107\n",
      "Epoch 4506/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5097 - recon_loss: 7.4611e-04 - KL loss: 8.0082 - beta: 0.0107 - val_val_loss: 14.5347 - val_val_recon_loss: 7.4604e-04 - val_val_KL loss: 8.0338 - val_beta: 0.0107\n",
      "Epoch 4507/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5170 - recon_loss: 7.4469e-04 - KL loss: 8.0279 - beta: 0.0107 - val_val_loss: 14.4990 - val_val_recon_loss: 7.4732e-04 - val_val_KL loss: 7.9869 - val_beta: 0.0107\n",
      "Epoch 4508/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.4928 - recon_loss: 7.4482e-04 - KL loss: 8.0026 - beta: 0.0107 - val_val_loss: 14.5082 - val_val_recon_loss: 7.4539e-04 - val_val_KL loss: 8.0130 - val_beta: 0.0107\n",
      "Epoch 4509/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5164 - recon_loss: 7.4479e-04 - KL loss: 8.0265 - beta: 0.0107 - val_val_loss: 14.5041 - val_val_recon_loss: 7.4123e-04 - val_val_KL loss: 8.0451 - val_beta: 0.0107\n",
      "Epoch 4510/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5491 - recon_loss: 7.4629e-04 - KL loss: 8.0461 - beta: 0.0107 - val_val_loss: 14.4834 - val_val_recon_loss: 7.4145e-04 - val_val_KL loss: 8.0226 - val_beta: 0.0107\n",
      "Epoch 4511/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.4582 - recon_loss: 7.4013e-04 - KL loss: 8.0089 - beta: 0.0107 - val_val_loss: 14.5311 - val_val_recon_loss: 7.4783e-04 - val_val_KL loss: 8.0146 - val_beta: 0.0107\n",
      "Epoch 4512/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.4724 - recon_loss: 7.3843e-04 - KL loss: 8.0379 - beta: 0.0107 - val_val_loss: 14.5207 - val_val_recon_loss: 7.4766e-04 - val_val_KL loss: 8.0057 - val_beta: 0.0107\n",
      "Epoch 4513/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.4739 - recon_loss: 7.4082e-04 - KL loss: 8.0186 - beta: 0.0107 - val_val_loss: 14.5043 - val_val_recon_loss: 7.4156e-04 - val_val_KL loss: 8.0426 - val_beta: 0.0107\n",
      "Epoch 4514/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5129 - recon_loss: 7.4390e-04 - KL loss: 8.0307 - beta: 0.0107 - val_val_loss: 14.5022 - val_val_recon_loss: 7.4063e-04 - val_val_KL loss: 8.0485 - val_beta: 0.0107\n",
      "Epoch 4515/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.4589 - recon_loss: 7.3894e-04 - KL loss: 8.0199 - beta: 0.0107\n",
      "Epoch 04515: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.4589 - recon_loss: 7.3894e-04 - KL loss: 8.0199 - beta: 0.0107 - val_val_loss: 14.4899 - val_val_recon_loss: 7.4239e-04 - val_val_KL loss: 8.0209 - val_beta: 0.0107\n",
      "Epoch 4516/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.4925 - recon_loss: 7.4258e-04 - KL loss: 8.0218 - beta: 0.0107 - val_val_loss: 14.5050 - val_val_recon_loss: 7.4520e-04 - val_val_KL loss: 8.0114 - val_beta: 0.0107\n",
      "Epoch 4517/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.4559 - recon_loss: 7.3887e-04 - KL loss: 8.0175 - beta: 0.0107 - val_val_loss: 14.4854 - val_val_recon_loss: 7.4223e-04 - val_val_KL loss: 8.0177 - val_beta: 0.0107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4518/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.4581 - recon_loss: 7.3787e-04 - KL loss: 8.0285 - beta: 0.0107 - val_val_loss: 14.4562 - val_val_recon_loss: 7.3990e-04 - val_val_KL loss: 8.0089 - val_beta: 0.0107\n",
      "Epoch 4519/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.4772 - recon_loss: 7.4124e-04 - KL loss: 8.0182 - beta: 0.0107 - val_val_loss: 14.4709 - val_val_recon_loss: 7.4206e-04 - val_val_KL loss: 8.0048 - val_beta: 0.0107\n",
      "Epoch 4520/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.4714 - recon_loss: 7.3946e-04 - KL loss: 8.0279 - beta: 0.0107 - val_val_loss: 14.4717 - val_val_recon_loss: 7.3945e-04 - val_val_KL loss: 8.0282 - val_beta: 0.0107\n",
      "Epoch 4521/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.5215 - recon_loss: 7.4412e-04 - KL loss: 8.0374 - beta: 0.0107 - val_val_loss: 14.4832 - val_val_recon_loss: 7.4372e-04 - val_val_KL loss: 8.0026 - val_beta: 0.0107\n",
      "Epoch 4522/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.4767 - recon_loss: 7.3936e-04 - KL loss: 8.0340 - beta: 0.0107 - val_val_loss: 14.4725 - val_val_recon_loss: 7.3979e-04 - val_val_KL loss: 8.0261 - val_beta: 0.0107\n",
      "Epoch 4523/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.4665 - recon_loss: 7.3880e-04 - KL loss: 8.0287 - beta: 0.0107\n",
      "Epoch 04523: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.4664 - recon_loss: 7.3879e-04 - KL loss: 8.0287 - beta: 0.0107 - val_val_loss: 14.4752 - val_val_recon_loss: 7.4259e-04 - val_val_KL loss: 8.0044 - val_beta: 0.0107\n",
      "Epoch 4524/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 14.4650 - recon_loss: 7.4027e-04 - KL loss: 8.0144 - beta: 0.0107 - val_val_loss: 14.4859 - val_val_recon_loss: 7.4248e-04 - val_val_KL loss: 8.0161 - val_beta: 0.0107\n",
      "Epoch 4525/10000\n",
      "1000/1000 [==============================] - 154s 154ms/step - loss: 14.4502 - recon_loss: 7.3780e-04 - KL loss: 8.0211 - beta: 0.0107 - val_val_loss: 14.4632 - val_val_recon_loss: 7.4131e-04 - val_val_KL loss: 8.0036 - val_beta: 0.0107\n",
      "Epoch 4526/10000\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 14.4501 - recon_loss: 7.3933e-04 - KL loss: 8.0077 - beta: 0.0107 - val_val_loss: 14.4958 - val_val_recon_loss: 7.4334e-04 - val_val_KL loss: 8.0185 - val_beta: 0.0107\n",
      "Epoch 4527/10000\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 14.4646 - recon_loss: 7.4099e-04 - KL loss: 8.0077 - beta: 0.0107 - val_val_loss: 14.4580 - val_val_recon_loss: 7.4022e-04 - val_val_KL loss: 8.0079 - val_beta: 0.0107\n",
      "Epoch 4528/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.4445 - recon_loss: 7.3700e-04 - KL loss: 8.0224 - beta: 0.0107\n",
      "Epoch 04528: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 14.4445 - recon_loss: 7.3700e-04 - KL loss: 8.0224 - beta: 0.0107 - val_val_loss: 14.4589 - val_val_recon_loss: 7.4020e-04 - val_val_KL loss: 8.0089 - val_beta: 0.0107\n",
      "Epoch 4528/10000\n",
      "1000/1000 [==============================] - 154s 154ms/step - loss: 11.7041 - recon_loss: 9.3137e-04 - KL loss: 6.9127 - beta: 0.0139 - val_val_loss: 11.6548 - val_val_recon_loss: 9.7064e-04 - val_val_KL loss: 6.6614 - val_beta: 0.0139\n",
      "Epoch 4529/10000\n",
      "1000/1000 [==============================] - 154s 154ms/step - loss: 11.6413 - recon_loss: 9.7160e-04 - KL loss: 6.6430 - beta: 0.0139 - val_val_loss: 11.7188 - val_val_recon_loss: 9.8852e-04 - val_val_KL loss: 6.6334 - val_beta: 0.0139\n",
      "Epoch 4530/10000\n",
      "1000/1000 [==============================] - 154s 154ms/step - loss: 11.7058 - recon_loss: 9.8918e-04 - KL loss: 6.6169 - beta: 0.0139 - val_val_loss: 11.6821 - val_val_recon_loss: 9.9222e-04 - val_val_KL loss: 6.5776 - val_beta: 0.0139\n",
      "Epoch 4531/10000\n",
      "1000/1000 [==============================] - 154s 154ms/step - loss: 11.8369 - recon_loss: 0.0010 - KL loss: 6.5797 - beta: 0.0139 - val_val_loss: 11.9586 - val_val_recon_loss: 0.0010 - val_val_KL loss: 6.5741 - val_beta: 0.0139\n",
      "Epoch 4532/10000\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 11.9137 - recon_loss: 0.0010 - KL loss: 6.5440 - beta: 0.0139 - val_val_loss: 11.9406 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.4847 - val_beta: 0.0139\n",
      "Epoch 4533/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.9738 - recon_loss: 0.0011 - KL loss: 6.5036 - beta: 0.0139\n",
      "Epoch 04533: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 11.9739 - recon_loss: 0.0011 - KL loss: 6.5036 - beta: 0.0139 - val_val_loss: 12.1320 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.5672 - val_beta: 0.0139\n",
      "Epoch 4534/10000\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 12.0799 - recon_loss: 0.0011 - KL loss: 6.5440 - beta: 0.0139 - val_val_loss: 11.9728 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.5049 - val_beta: 0.0139\n",
      "Epoch 4535/10000\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 12.0038 - recon_loss: 0.0011 - KL loss: 6.5447 - beta: 0.0139 - val_val_loss: 12.1232 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.5292 - val_beta: 0.0139\n",
      "Epoch 4536/10000\n",
      "1000/1000 [==============================] - 154s 154ms/step - loss: 12.1023 - recon_loss: 0.0011 - KL loss: 6.5370 - beta: 0.0139 - val_val_loss: 12.0922 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.5427 - val_beta: 0.0139\n",
      "Epoch 4537/10000\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 12.0205 - recon_loss: 0.0011 - KL loss: 6.5018 - beta: 0.0139 - val_val_loss: 11.9903 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.5592 - val_beta: 0.0139\n",
      "Epoch 4538/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.9809 - recon_loss: 0.0011 - KL loss: 6.5004 - beta: 0.0139\n",
      "Epoch 04538: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 11.9809 - recon_loss: 0.0011 - KL loss: 6.5003 - beta: 0.0139 - val_val_loss: 12.0810 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.4697 - val_beta: 0.0139\n",
      "Epoch 4538/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.5977 - recon_loss: 0.0013 - KL loss: 5.5181 - beta: 0.0181 - val_val_loss: 9.5545 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.3179 - val_beta: 0.0181\n",
      "Epoch 4539/10000\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 9.4911 - recon_loss: 0.0014 - KL loss: 5.2507 - beta: 0.0181 - val_val_loss: 9.4319 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.1981 - val_beta: 0.0181\n",
      "Epoch 4540/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.4379 - recon_loss: 0.0014 - KL loss: 5.2098 - beta: 0.0181 - val_val_loss: 9.4271 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.1664 - val_beta: 0.0181\n",
      "Epoch 4541/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.4390 - recon_loss: 0.0014 - KL loss: 5.1564 - beta: 0.0181 - val_val_loss: 9.3983 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.0727 - val_beta: 0.0181\n",
      "Epoch 4542/10000\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 9.4273 - recon_loss: 0.0014 - KL loss: 5.1481 - beta: 0.0181 - val_val_loss: 9.4661 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.1039 - val_beta: 0.0181\n",
      "Epoch 4543/10000\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 9.5134 - recon_loss: 0.0014 - KL loss: 5.1165 - beta: 0.0181 - val_val_loss: 9.4185 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.1148 - val_beta: 0.0181\n",
      "Epoch 4544/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.4098 - recon_loss: 0.0014 - KL loss: 5.0939 - beta: 0.0181 - val_val_loss: 9.4431 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.2820 - val_beta: 0.0181\n",
      "Epoch 4545/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.4267 - recon_loss: 0.0014 - KL loss: 5.0713 - beta: 0.0181 - val_val_loss: 9.4257 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.0960 - val_beta: 0.0181\n",
      "Epoch 4546/10000\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 9.3839 - recon_loss: 0.0014 - KL loss: 5.0547 - beta: 0.0181 - val_val_loss: 9.3850 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9891 - val_beta: 0.0181\n",
      "Epoch 4547/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.4197 - recon_loss: 0.0014 - KL loss: 5.0573 - beta: 0.0181 - val_val_loss: 9.3957 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9541 - val_beta: 0.0181\n",
      "Epoch 4548/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.4036 - recon_loss: 0.0014 - KL loss: 5.0409 - beta: 0.0181 - val_val_loss: 9.3503 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.0355 - val_beta: 0.0181\n",
      "Epoch 4549/10000\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 9.3846 - recon_loss: 0.0014 - KL loss: 5.0190 - beta: 0.0181 - val_val_loss: 9.3455 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.0315 - val_beta: 0.0181\n",
      "Epoch 4550/10000\n",
      "1000/1000 [==============================] - 151s 151ms/step - loss: 9.3540 - recon_loss: 0.0014 - KL loss: 5.0237 - beta: 0.0181 - val_val_loss: 9.3854 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9482 - val_beta: 0.0181\n",
      "Epoch 4551/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.3644 - recon_loss: 0.0014 - KL loss: 5.0086 - beta: 0.0181 - val_val_loss: 9.3408 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.0059 - val_beta: 0.0181\n",
      "Epoch 4552/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.3384 - recon_loss: 0.0014 - KL loss: 5.0094 - beta: 0.0181 - val_val_loss: 9.5134 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9241 - val_beta: 0.0181\n",
      "Epoch 4553/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.4489 - recon_loss: 0.0015 - KL loss: 4.9937 - beta: 0.0181 - val_val_loss: 9.4323 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9678 - val_beta: 0.0181\n",
      "Epoch 4554/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.4057 - recon_loss: 0.0015 - KL loss: 4.9572 - beta: 0.0181 - val_val_loss: 9.5197 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.1179 - val_beta: 0.0181\n",
      "Epoch 4555/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.4614 - recon_loss: 0.0015 - KL loss: 4.9508 - beta: 0.0181 - val_val_loss: 9.4028 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9211 - val_beta: 0.0181\n",
      "Epoch 4556/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.3661 - recon_loss: 0.0015 - KL loss: 4.9472 - beta: 0.0181\n",
      "Epoch 04556: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.3662 - recon_loss: 0.0015 - KL loss: 4.9472 - beta: 0.0181 - val_val_loss: 9.4261 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8805 - val_beta: 0.0181\n",
      "Epoch 4557/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.3598 - recon_loss: 0.0015 - KL loss: 4.9133 - beta: 0.0181 - val_val_loss: 9.3121 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8976 - val_beta: 0.0181\n",
      "Epoch 4558/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2951 - recon_loss: 0.0014 - KL loss: 4.9338 - beta: 0.0181 - val_val_loss: 9.3262 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9647 - val_beta: 0.0181\n",
      "Epoch 4559/10000\n",
      "1000/1000 [==============================] - 151s 151ms/step - loss: 9.2922 - recon_loss: 0.0014 - KL loss: 4.9400 - beta: 0.0181 - val_val_loss: 9.3037 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9902 - val_beta: 0.0181\n",
      "Epoch 4560/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.3152 - recon_loss: 0.0014 - KL loss: 4.9669 - beta: 0.0181 - val_val_loss: 9.2813 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9668 - val_beta: 0.0181\n",
      "Epoch 4561/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2850 - recon_loss: 0.0014 - KL loss: 4.9520 - beta: 0.0181 - val_val_loss: 9.2862 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9457 - val_beta: 0.0181\n",
      "Epoch 4562/10000\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 9.3068 - recon_loss: 0.0014 - KL loss: 4.9518 - beta: 0.0181 - val_val_loss: 9.2861 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9853 - val_beta: 0.0181\n",
      "Epoch 4563/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2842 - recon_loss: 0.0014 - KL loss: 4.9560 - beta: 0.0181 - val_val_loss: 9.2661 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9787 - val_beta: 0.0181\n",
      "Epoch 4564/10000\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 9.2584 - recon_loss: 0.0014 - KL loss: 4.9383 - beta: 0.0181 - val_val_loss: 9.2822 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9556 - val_beta: 0.0181\n",
      "Epoch 4565/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2733 - recon_loss: 0.0014 - KL loss: 4.9576 - beta: 0.0181 - val_val_loss: 9.2766 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9471 - val_beta: 0.0181\n",
      "Epoch 4566/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2486 - recon_loss: 0.0014 - KL loss: 4.9501 - beta: 0.0181 - val_val_loss: 9.2948 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9270 - val_beta: 0.0181\n",
      "Epoch 4567/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2681 - recon_loss: 0.0014 - KL loss: 4.9619 - beta: 0.0181 - val_val_loss: 9.2720 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9610 - val_beta: 0.0181\n",
      "Epoch 4568/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2239 - recon_loss: 0.0014 - KL loss: 4.9483 - beta: 0.0181 - val_val_loss: 9.2416 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9576 - val_beta: 0.0181\n",
      "Epoch 4569/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2348 - recon_loss: 0.0014 - KL loss: 4.9564 - beta: 0.0181 - val_val_loss: 9.2635 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9600 - val_beta: 0.0181\n",
      "Epoch 4570/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2434 - recon_loss: 0.0014 - KL loss: 4.9686 - beta: 0.0181 - val_val_loss: 9.2989 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9579 - val_beta: 0.0181\n",
      "Epoch 4571/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2643 - recon_loss: 0.0014 - KL loss: 4.9750 - beta: 0.0181 - val_val_loss: 9.2866 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9999 - val_beta: 0.0181\n",
      "Epoch 4572/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2712 - recon_loss: 0.0014 - KL loss: 4.9725 - beta: 0.0181 - val_val_loss: 9.2650 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.0029 - val_beta: 0.0181\n",
      "Epoch 4573/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2952 - recon_loss: 0.0014 - KL loss: 4.9865 - beta: 0.0181 - val_val_loss: 9.2258 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.0254 - val_beta: 0.0181\n",
      "Epoch 4574/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2454 - recon_loss: 0.0014 - KL loss: 4.9789 - beta: 0.0181 - val_val_loss: 9.2753 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9969 - val_beta: 0.0181\n",
      "Epoch 4575/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2827 - recon_loss: 0.0014 - KL loss: 4.9864 - beta: 0.0181 - val_val_loss: 9.2503 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9690 - val_beta: 0.0181\n",
      "Epoch 4576/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2805 - recon_loss: 0.0014 - KL loss: 4.9923 - beta: 0.0181 - val_val_loss: 9.2862 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.0164 - val_beta: 0.0181\n",
      "Epoch 4577/10000\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 9.2989 - recon_loss: 0.0014 - KL loss: 5.0050 - beta: 0.0181 - val_val_loss: 9.3633 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.0498 - val_beta: 0.0181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4578/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.3233 - recon_loss: 0.0014 - KL loss: 5.0202 - beta: 0.0181\n",
      "Epoch 04578: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 9.3233 - recon_loss: 0.0014 - KL loss: 5.0202 - beta: 0.0181 - val_val_loss: 9.2985 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.0471 - val_beta: 0.0181\n",
      "Epoch 4579/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2918 - recon_loss: 0.0014 - KL loss: 5.0109 - beta: 0.0181 - val_val_loss: 9.2602 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.0217 - val_beta: 0.0181\n",
      "Epoch 4580/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2475 - recon_loss: 0.0014 - KL loss: 4.9987 - beta: 0.0181 - val_val_loss: 9.2674 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9971 - val_beta: 0.0181\n",
      "Epoch 4581/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2758 - recon_loss: 0.0014 - KL loss: 4.9957 - beta: 0.0181 - val_val_loss: 9.2539 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9894 - val_beta: 0.0181\n",
      "Epoch 4582/10000\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2453 - recon_loss: 0.0014 - KL loss: 4.9916 - beta: 0.0181 - val_val_loss: 9.2632 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.0060 - val_beta: 0.0181\n",
      "Epoch 4583/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.2314 - recon_loss: 0.0014 - KL loss: 4.9821 - beta: 0.0181\n",
      "Epoch 04583: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 9.2314 - recon_loss: 0.0014 - KL loss: 4.9822 - beta: 0.0181 - val_val_loss: 9.2825 - val_val_recon_loss: 0.0014 - val_val_KL loss: 4.9824 - val_beta: 0.0181\n",
      "Epoch 4583/10000\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 7.3480 - recon_loss: 0.0018 - KL loss: 4.2063 - beta: 0.0236 - val_val_loss: 7.3567 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0025 - val_beta: 0.0236\n",
      "Epoch 4584/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.3581 - recon_loss: 0.0019 - KL loss: 4.0267 - beta: 0.0236 - val_val_loss: 7.3641 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.9494 - val_beta: 0.0236\n",
      "Epoch 4585/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.3424 - recon_loss: 0.0019 - KL loss: 3.9511 - beta: 0.0236 - val_val_loss: 7.3920 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.9291 - val_beta: 0.0236\n",
      "Epoch 4586/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.3512 - recon_loss: 0.0019 - KL loss: 3.9320 - beta: 0.0236 - val_val_loss: 7.3692 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.9255 - val_beta: 0.0236\n",
      "Epoch 4587/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 7.3304 - recon_loss: 0.0019 - KL loss: 3.9044 - beta: 0.0236 - val_val_loss: 7.3326 - val_val_recon_loss: 0.0020 - val_val_KL loss: 3.8320 - val_beta: 0.0236\n",
      "Epoch 4588/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.3422 - recon_loss: 0.0019 - KL loss: 3.8743 - beta: 0.0236 - val_val_loss: 7.3175 - val_val_recon_loss: 0.0020 - val_val_KL loss: 3.7963 - val_beta: 0.0236\n",
      "Epoch 4589/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.3566 - recon_loss: 0.0019 - KL loss: 3.8750 - beta: 0.0236 - val_val_loss: 7.3495 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8599 - val_beta: 0.0236\n",
      "Epoch 4590/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.3468 - recon_loss: 0.0019 - KL loss: 3.8777 - beta: 0.0236 - val_val_loss: 7.3272 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8323 - val_beta: 0.0236\n",
      "Epoch 4591/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.3452 - recon_loss: 0.0019 - KL loss: 3.8576 - beta: 0.0236 - val_val_loss: 7.3295 - val_val_recon_loss: 0.0020 - val_val_KL loss: 3.8281 - val_beta: 0.0236\n",
      "Epoch 4592/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.3437 - recon_loss: 0.0019 - KL loss: 3.8601 - beta: 0.0236 - val_val_loss: 7.3630 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8846 - val_beta: 0.0236\n",
      "Epoch 4593/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.3526 - recon_loss: 0.0020 - KL loss: 3.8524 - beta: 0.0236\n",
      "Epoch 04593: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 7.3526 - recon_loss: 0.0020 - KL loss: 3.8523 - beta: 0.0236 - val_val_loss: 7.3365 - val_val_recon_loss: 0.0020 - val_val_KL loss: 3.8251 - val_beta: 0.0236\n",
      "Epoch 4594/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.3248 - recon_loss: 0.0019 - KL loss: 3.8379 - beta: 0.0236 - val_val_loss: 7.2799 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8693 - val_beta: 0.0236\n",
      "Epoch 4595/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2717 - recon_loss: 0.0019 - KL loss: 3.8493 - beta: 0.0236 - val_val_loss: 7.2864 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8634 - val_beta: 0.0236\n",
      "Epoch 4596/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2883 - recon_loss: 0.0019 - KL loss: 3.8506 - beta: 0.0236 - val_val_loss: 7.3112 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8537 - val_beta: 0.0236\n",
      "Epoch 4597/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2790 - recon_loss: 0.0019 - KL loss: 3.8417 - beta: 0.0236 - val_val_loss: 7.3105 - val_val_recon_loss: 0.0020 - val_val_KL loss: 3.7893 - val_beta: 0.0236\n",
      "Epoch 4598/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2887 - recon_loss: 0.0019 - KL loss: 3.8351 - beta: 0.0236 - val_val_loss: 7.2888 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8497 - val_beta: 0.0236\n",
      "Epoch 4599/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.3089 - recon_loss: 0.0019 - KL loss: 3.8521 - beta: 0.0236\n",
      "Epoch 04599: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.3089 - recon_loss: 0.0019 - KL loss: 3.8521 - beta: 0.0236 - val_val_loss: 7.2870 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8482 - val_beta: 0.0236\n",
      "Epoch 4600/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2494 - recon_loss: 0.0019 - KL loss: 3.8445 - beta: 0.0236 - val_val_loss: 7.2832 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8541 - val_beta: 0.0236\n",
      "Epoch 4601/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2621 - recon_loss: 0.0019 - KL loss: 3.8441 - beta: 0.0236 - val_val_loss: 7.2947 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8408 - val_beta: 0.0236\n",
      "Epoch 4602/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2742 - recon_loss: 0.0019 - KL loss: 3.8451 - beta: 0.0236 - val_val_loss: 7.2913 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8533 - val_beta: 0.0236\n",
      "Epoch 4603/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2739 - recon_loss: 0.0019 - KL loss: 3.8445 - beta: 0.0236 - val_val_loss: 7.2724 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8585 - val_beta: 0.0236\n",
      "Epoch 4604/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2507 - recon_loss: 0.0019 - KL loss: 3.8381 - beta: 0.0236 - val_val_loss: 7.2872 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8561 - val_beta: 0.0236\n",
      "Epoch 4605/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2641 - recon_loss: 0.0019 - KL loss: 3.8487 - beta: 0.0236 - val_val_loss: 7.2539 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8345 - val_beta: 0.0236\n",
      "Epoch 4606/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2611 - recon_loss: 0.0019 - KL loss: 3.8495 - beta: 0.0236 - val_val_loss: 7.2624 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8397 - val_beta: 0.0236\n",
      "Epoch 4607/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2717 - recon_loss: 0.0019 - KL loss: 3.8420 - beta: 0.0236 - val_val_loss: 7.2556 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8552 - val_beta: 0.0236\n",
      "Epoch 4608/10000\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 7.2492 - recon_loss: 0.0019 - KL loss: 3.8409 - beta: 0.0236 - val_val_loss: 7.2524 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8447 - val_beta: 0.0236\n",
      "Epoch 4609/10000\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 7.2847 - recon_loss: 0.0019 - KL loss: 3.8467 - beta: 0.0236 - val_val_loss: 7.2677 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8524 - val_beta: 0.0236\n",
      "Epoch 4610/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2457 - recon_loss: 0.0019 - KL loss: 3.8401 - beta: 0.0236 - val_val_loss: 7.2757 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8314 - val_beta: 0.0236\n",
      "Epoch 4611/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2407 - recon_loss: 0.0019 - KL loss: 3.8441 - beta: 0.0236 - val_val_loss: 7.2703 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8311 - val_beta: 0.0236\n",
      "Epoch 4612/10000\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 7.2645 - recon_loss: 0.0019 - KL loss: 3.8463 - beta: 0.0236 - val_val_loss: 7.2633 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8450 - val_beta: 0.0236\n",
      "Epoch 4613/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.2435 - recon_loss: 0.0019 - KL loss: 3.8429 - beta: 0.0236\n",
      "Epoch 04613: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 7.2434 - recon_loss: 0.0019 - KL loss: 3.8429 - beta: 0.0236 - val_val_loss: 7.2686 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8124 - val_beta: 0.0236\n",
      "Epoch 4614/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2712 - recon_loss: 0.0019 - KL loss: 3.8272 - beta: 0.0236 - val_val_loss: 7.2580 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8327 - val_beta: 0.0236\n",
      "Epoch 4615/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2633 - recon_loss: 0.0019 - KL loss: 3.8373 - beta: 0.0236 - val_val_loss: 7.2632 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8377 - val_beta: 0.0236\n",
      "Epoch 4616/10000\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 7.2576 - recon_loss: 0.0019 - KL loss: 3.8437 - beta: 0.0236 - val_val_loss: 7.2301 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8454 - val_beta: 0.0236\n",
      "Epoch 4617/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2639 - recon_loss: 0.0019 - KL loss: 3.8417 - beta: 0.0236 - val_val_loss: 7.2623 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8355 - val_beta: 0.0236\n",
      "Epoch 4618/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2408 - recon_loss: 0.0019 - KL loss: 3.8360 - beta: 0.0236 - val_val_loss: 7.2484 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8346 - val_beta: 0.0236\n",
      "Epoch 4619/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2586 - recon_loss: 0.0019 - KL loss: 3.8410 - beta: 0.0236 - val_val_loss: 7.2578 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8375 - val_beta: 0.0236\n",
      "Epoch 4620/10000\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 7.2666 - recon_loss: 0.0019 - KL loss: 3.8346 - beta: 0.0236 - val_val_loss: 7.2570 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8427 - val_beta: 0.0236\n",
      "Epoch 4621/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.2890 - recon_loss: 0.0019 - KL loss: 3.8488 - beta: 0.0236\n",
      "Epoch 04621: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2889 - recon_loss: 0.0019 - KL loss: 3.8488 - beta: 0.0236 - val_val_loss: 7.2492 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8312 - val_beta: 0.0236\n",
      "Epoch 4622/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2334 - recon_loss: 0.0019 - KL loss: 3.8340 - beta: 0.0236 - val_val_loss: 7.2570 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8291 - val_beta: 0.0236\n",
      "Epoch 4623/10000\n",
      "1000/1000 [==============================] - 148s 148ms/step - loss: 7.2364 - recon_loss: 0.0019 - KL loss: 3.8364 - beta: 0.0236 - val_val_loss: 7.2415 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8347 - val_beta: 0.0236\n",
      "Epoch 4624/10000\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 7.2541 - recon_loss: 0.0019 - KL loss: 3.8331 - beta: 0.0236 - val_val_loss: 7.2425 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8380 - val_beta: 0.0236\n",
      "Epoch 4625/10000\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2551 - recon_loss: 0.0019 - KL loss: 3.8413 - beta: 0.0236 - val_val_loss: 7.2553 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8390 - val_beta: 0.0236\n",
      "Epoch 4626/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.2666 - recon_loss: 0.0019 - KL loss: 3.8411 - beta: 0.0236\n",
      "Epoch 04626: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 7.2666 - recon_loss: 0.0019 - KL loss: 3.8411 - beta: 0.0236 - val_val_loss: 7.2601 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8381 - val_beta: 0.0236\n",
      "Epoch 4626/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7463 - recon_loss: 0.0024 - KL loss: 3.2459 - beta: 0.0307 - val_val_loss: 5.7481 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1922 - val_beta: 0.0307\n",
      "Epoch 4627/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7703 - recon_loss: 0.0024 - KL loss: 3.2023 - beta: 0.0307 - val_val_loss: 5.7615 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1824 - val_beta: 0.0307\n",
      "Epoch 4628/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7647 - recon_loss: 0.0024 - KL loss: 3.1907 - beta: 0.0307 - val_val_loss: 5.7865 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.2046 - val_beta: 0.0307\n",
      "Epoch 4629/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7964 - recon_loss: 0.0025 - KL loss: 3.1860 - beta: 0.0307 - val_val_loss: 5.7711 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.2133 - val_beta: 0.0307\n",
      "Epoch 4630/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7598 - recon_loss: 0.0024 - KL loss: 3.1798 - beta: 0.0307 - val_val_loss: 5.7862 - val_val_recon_loss: 0.0025 - val_val_KL loss: 3.1616 - val_beta: 0.0307\n",
      "Epoch 4631/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.7809 - recon_loss: 0.0025 - KL loss: 3.1746 - beta: 0.0307\n",
      "Epoch 04631: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7809 - recon_loss: 0.0025 - KL loss: 3.1746 - beta: 0.0307 - val_val_loss: 5.7627 - val_val_recon_loss: 0.0025 - val_val_KL loss: 3.1641 - val_beta: 0.0307\n",
      "Epoch 4632/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7582 - recon_loss: 0.0024 - KL loss: 3.1719 - beta: 0.0307 - val_val_loss: 5.7370 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1928 - val_beta: 0.0307\n",
      "Epoch 4633/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7466 - recon_loss: 0.0024 - KL loss: 3.1840 - beta: 0.0307 - val_val_loss: 5.7530 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1962 - val_beta: 0.0307\n",
      "Epoch 4634/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7465 - recon_loss: 0.0024 - KL loss: 3.1768 - beta: 0.0307 - val_val_loss: 5.7305 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1971 - val_beta: 0.0307\n",
      "Epoch 4635/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7508 - recon_loss: 0.0024 - KL loss: 3.1819 - beta: 0.0307 - val_val_loss: 5.7513 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1856 - val_beta: 0.0307\n",
      "Epoch 4636/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7511 - recon_loss: 0.0024 - KL loss: 3.1806 - beta: 0.0307 - val_val_loss: 5.7494 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1851 - val_beta: 0.0307\n",
      "Epoch 4637/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7516 - recon_loss: 0.0024 - KL loss: 3.1772 - beta: 0.0307 - val_val_loss: 5.7486 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1877 - val_beta: 0.0307\n",
      "Epoch 4638/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7601 - recon_loss: 0.0024 - KL loss: 3.1856 - beta: 0.0307 - val_val_loss: 5.7514 - val_val_recon_loss: 0.0025 - val_val_KL loss: 3.1430 - val_beta: 0.0307\n",
      "Epoch 4639/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7429 - recon_loss: 0.0024 - KL loss: 3.1731 - beta: 0.0307 - val_val_loss: 5.7277 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1775 - val_beta: 0.0307\n",
      "Epoch 4640/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7328 - recon_loss: 0.0024 - KL loss: 3.1832 - beta: 0.0307 - val_val_loss: 5.7374 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1850 - val_beta: 0.0307\n",
      "Epoch 4641/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7214 - recon_loss: 0.0024 - KL loss: 3.1801 - beta: 0.0307 - val_val_loss: 5.7408 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1796 - val_beta: 0.0307\n",
      "Epoch 4642/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7367 - recon_loss: 0.0024 - KL loss: 3.1748 - beta: 0.0307 - val_val_loss: 5.7494 - val_val_recon_loss: 0.0025 - val_val_KL loss: 3.1395 - val_beta: 0.0307\n",
      "Epoch 4643/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7345 - recon_loss: 0.0024 - KL loss: 3.1813 - beta: 0.0307 - val_val_loss: 5.7384 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1460 - val_beta: 0.0307\n",
      "Epoch 4644/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.7472 - recon_loss: 0.0024 - KL loss: 3.1733 - beta: 0.0307\n",
      "Epoch 04644: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7472 - recon_loss: 0.0024 - KL loss: 3.1733 - beta: 0.0307 - val_val_loss: 5.7366 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.2038 - val_beta: 0.0307\n",
      "Epoch 4645/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7312 - recon_loss: 0.0024 - KL loss: 3.1847 - beta: 0.0307 - val_val_loss: 5.7401 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1739 - val_beta: 0.0307\n",
      "Epoch 4646/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7250 - recon_loss: 0.0024 - KL loss: 3.1764 - beta: 0.0307 - val_val_loss: 5.7338 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1625 - val_beta: 0.0307\n",
      "Epoch 4647/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7288 - recon_loss: 0.0024 - KL loss: 3.1747 - beta: 0.0307 - val_val_loss: 5.7412 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1698 - val_beta: 0.0307\n",
      "Epoch 4648/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7522 - recon_loss: 0.0024 - KL loss: 3.1801 - beta: 0.0307 - val_val_loss: 5.7172 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.2043 - val_beta: 0.0307\n",
      "Epoch 4649/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7224 - recon_loss: 0.0024 - KL loss: 3.1838 - beta: 0.0307 - val_val_loss: 5.7444 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1897 - val_beta: 0.0307\n",
      "Epoch 4650/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7343 - recon_loss: 0.0024 - KL loss: 3.1784 - beta: 0.0307 - val_val_loss: 5.7412 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.2061 - val_beta: 0.0307\n",
      "Epoch 4651/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7181 - recon_loss: 0.0024 - KL loss: 3.1772 - beta: 0.0307 - val_val_loss: 5.7289 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1821 - val_beta: 0.0307\n",
      "Epoch 4652/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7195 - recon_loss: 0.0024 - KL loss: 3.1826 - beta: 0.0307 - val_val_loss: 5.7455 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1692 - val_beta: 0.0307\n",
      "Epoch 4653/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.7190 - recon_loss: 0.0024 - KL loss: 3.1694 - beta: 0.0307\n",
      "Epoch 04653: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7190 - recon_loss: 0.0024 - KL loss: 3.1694 - beta: 0.0307 - val_val_loss: 5.7320 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1909 - val_beta: 0.0307\n",
      "Epoch 4654/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7398 - recon_loss: 0.0024 - KL loss: 3.1854 - beta: 0.0307 - val_val_loss: 5.7364 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1681 - val_beta: 0.0307\n",
      "Epoch 4655/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7190 - recon_loss: 0.0024 - KL loss: 3.1786 - beta: 0.0307 - val_val_loss: 5.7172 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1776 - val_beta: 0.0307\n",
      "Epoch 4656/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7259 - recon_loss: 0.0024 - KL loss: 3.1859 - beta: 0.0307 - val_val_loss: 5.7197 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1751 - val_beta: 0.0307\n",
      "Epoch 4657/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7212 - recon_loss: 0.0024 - KL loss: 3.1760 - beta: 0.0307 - val_val_loss: 5.7217 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1801 - val_beta: 0.0307\n",
      "Epoch 4658/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.7253 - recon_loss: 0.0024 - KL loss: 3.1820 - beta: 0.0307\n",
      "Epoch 04658: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7253 - recon_loss: 0.0024 - KL loss: 3.1820 - beta: 0.0307 - val_val_loss: 5.7292 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1604 - val_beta: 0.0307\n",
      "Epoch 4659/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7188 - recon_loss: 0.0024 - KL loss: 3.1702 - beta: 0.0307 - val_val_loss: 5.7255 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1797 - val_beta: 0.0307\n",
      "Epoch 4660/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7250 - recon_loss: 0.0024 - KL loss: 3.1811 - beta: 0.0307 - val_val_loss: 5.7116 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1820 - val_beta: 0.0307\n",
      "Epoch 4661/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7319 - recon_loss: 0.0024 - KL loss: 3.1790 - beta: 0.0307 - val_val_loss: 5.7274 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1788 - val_beta: 0.0307\n",
      "Epoch 4662/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7132 - recon_loss: 0.0024 - KL loss: 3.1826 - beta: 0.0307 - val_val_loss: 5.7232 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1807 - val_beta: 0.0307\n",
      "Epoch 4663/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7310 - recon_loss: 0.0024 - KL loss: 3.1796 - beta: 0.0307 - val_val_loss: 5.7142 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1784 - val_beta: 0.0307\n",
      "Epoch 4664/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7216 - recon_loss: 0.0024 - KL loss: 3.1767 - beta: 0.0307 - val_val_loss: 5.7247 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1804 - val_beta: 0.0307\n",
      "Epoch 4665/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.7215 - recon_loss: 0.0024 - KL loss: 3.1821 - beta: 0.0307\n",
      "Epoch 04665: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7215 - recon_loss: 0.0024 - KL loss: 3.1821 - beta: 0.0307 - val_val_loss: 5.7247 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1836 - val_beta: 0.0307\n",
      "Epoch 4666/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7314 - recon_loss: 0.0024 - KL loss: 3.1796 - beta: 0.0307 - val_val_loss: 5.7136 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1819 - val_beta: 0.0307\n",
      "Epoch 4667/10000\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7331 - recon_loss: 0.0024 - KL loss: 3.1802 - beta: 0.0307 - val_val_loss: 5.7253 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1806 - val_beta: 0.0307\n",
      "Epoch 4668/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7226 - recon_loss: 0.0024 - KL loss: 3.1806 - beta: 0.0307 - val_val_loss: 5.7154 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1812 - val_beta: 0.0307\n",
      "Epoch 4669/10000\n",
      "1000/1000 [==============================] - 146s 146ms/step - loss: 5.7161 - recon_loss: 0.0024 - KL loss: 3.1826 - beta: 0.0307 - val_val_loss: 5.7233 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1807 - val_beta: 0.0307\n",
      "Epoch 4670/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.7133 - recon_loss: 0.0024 - KL loss: 3.1795 - beta: 0.0307\n",
      "Epoch 04670: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 147s 147ms/step - loss: 5.7133 - recon_loss: 0.0024 - KL loss: 3.1796 - beta: 0.0307 - val_val_loss: 5.7217 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.1811 - val_beta: 0.0307\n",
      "Epoch 4670/10000\n",
      "1000/1000 [==============================] - 142s 142ms/step - loss: 4.5912 - recon_loss: 0.0032 - KL loss: 2.5764 - beta: 0.0400 - val_val_loss: 4.5725 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.5254 - val_beta: 0.0400\n",
      "Epoch 4671/10000\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5809 - recon_loss: 0.0033 - KL loss: 2.5088 - beta: 0.0400 - val_val_loss: 4.5795 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.4911 - val_beta: 0.0400\n",
      "Epoch 4672/10000\n",
      "1000/1000 [==============================] - 141s 141ms/step - loss: 4.5968 - recon_loss: 0.0034 - KL loss: 2.5011 - beta: 0.0400 - val_val_loss: 4.5914 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.4460 - val_beta: 0.0400\n",
      "Epoch 4673/10000\n",
      "1000/1000 [==============================] - 139s 139ms/step - loss: 4.6000 - recon_loss: 0.0034 - KL loss: 2.4893 - beta: 0.0400 - val_val_loss: 4.5730 - val_val_recon_loss: 0.0035 - val_val_KL loss: 2.4104 - val_beta: 0.0400\n",
      "Epoch 4674/10000\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5969 - recon_loss: 0.0034 - KL loss: 2.4958 - beta: 0.0400 - val_val_loss: 4.5718 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.5067 - val_beta: 0.0400\n",
      "Epoch 4675/10000\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5756 - recon_loss: 0.0034 - KL loss: 2.4781 - beta: 0.0400 - val_val_loss: 4.5926 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.4857 - val_beta: 0.0400\n",
      "Epoch 4676/10000\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5757 - recon_loss: 0.0034 - KL loss: 2.4744 - beta: 0.0400 - val_val_loss: 4.5796 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.5138 - val_beta: 0.0400\n",
      "Epoch 4677/10000\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5746 - recon_loss: 0.0034 - KL loss: 2.4650 - beta: 0.0400 - val_val_loss: 4.5952 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.4444 - val_beta: 0.0400\n",
      "Epoch 4678/10000\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5769 - recon_loss: 0.0034 - KL loss: 2.4526 - beta: 0.0400 - val_val_loss: 4.5733 - val_val_recon_loss: 0.0032 - val_val_KL loss: 2.5612 - val_beta: 0.0400\n",
      "Epoch 4679/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.5596 - recon_loss: 0.0034 - KL loss: 2.4585 - beta: 0.0400\n",
      "Epoch 04679: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5596 - recon_loss: 0.0034 - KL loss: 2.4585 - beta: 0.0400 - val_val_loss: 4.5773 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.4413 - val_beta: 0.0400\n",
      "Epoch 4680/10000\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5567 - recon_loss: 0.0033 - KL loss: 2.4637 - beta: 0.0400 - val_val_loss: 4.5563 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.4781 - val_beta: 0.0400\n",
      "Epoch 4681/10000\n",
      "1000/1000 [==============================] - 141s 141ms/step - loss: 4.5575 - recon_loss: 0.0034 - KL loss: 2.4635 - beta: 0.0400 - val_val_loss: 4.5489 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.4764 - val_beta: 0.0400\n",
      "Epoch 4682/10000\n",
      "1000/1000 [==============================] - 141s 141ms/step - loss: 4.5480 - recon_loss: 0.0033 - KL loss: 2.4640 - beta: 0.0400 - val_val_loss: 4.5367 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.4725 - val_beta: 0.0400\n",
      "Epoch 4683/10000\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5452 - recon_loss: 0.0033 - KL loss: 2.4577 - beta: 0.0400 - val_val_loss: 4.5581 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.4423 - val_beta: 0.0400\n",
      "Epoch 4684/10000\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5564 - recon_loss: 0.0034 - KL loss: 2.4624 - beta: 0.0400 - val_val_loss: 4.5592 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.4621 - val_beta: 0.0400\n",
      "Epoch 4685/10000\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5573 - recon_loss: 0.0034 - KL loss: 2.4590 - beta: 0.0400 - val_val_loss: 4.5398 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.4897 - val_beta: 0.0400\n",
      "Epoch 4686/10000\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5544 - recon_loss: 0.0033 - KL loss: 2.4650 - beta: 0.0400 - val_val_loss: 4.5613 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.4509 - val_beta: 0.0400\n",
      "Epoch 4687/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.5486 - recon_loss: 0.0033 - KL loss: 2.4620 - beta: 0.0400\n",
      "Epoch 04687: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 141s 141ms/step - loss: 4.5486 - recon_loss: 0.0033 - KL loss: 2.4620 - beta: 0.0400 - val_val_loss: 4.5369 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.4508 - val_beta: 0.0400\n",
      "Epoch 4688/10000\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5533 - recon_loss: 0.0033 - KL loss: 2.4609 - beta: 0.0400 - val_val_loss: 4.5478 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.4429 - val_beta: 0.0400\n",
      "Epoch 4689/10000\n",
      "1000/1000 [==============================] - 141s 141ms/step - loss: 4.5487 - recon_loss: 0.0033 - KL loss: 2.4614 - beta: 0.0400 - val_val_loss: 4.5489 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.4693 - val_beta: 0.0400\n",
      "Epoch 4690/10000\n",
      "1000/1000 [==============================] - 140s 140ms/step - loss: 4.5477 - recon_loss: 0.0033 - KL loss: 2.4600 - beta: 0.0400 - val_val_loss: 4.5531 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.4374 - val_beta: 0.0400\n",
      "Epoch 4691/10000\n",
      "1000/1000 [==============================] - 141s 141ms/step - loss: 4.5479 - recon_loss: 0.0033 - KL loss: 2.4546 - beta: 0.0400 - val_val_loss: 4.5520 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.4600 - val_beta: 0.0400\n",
      "Epoch 4692/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.5603 - recon_loss: 0.0034 - KL loss: 2.4623 - beta: 0.0400\n",
      "Epoch 04692: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 141s 141ms/step - loss: 4.5603 - recon_loss: 0.0034 - KL loss: 2.4623 - beta: 0.0400 - val_val_loss: 4.5531 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.4520 - val_beta: 0.0400\n"
     ]
    }
   ],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0., patience=10, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "\n",
    "for beta in np.logspace(-3,np.log10(4e-2),15):\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,3e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3229/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 6.9833 - recon_loss: 0.0088 - KL loss: 0.6476 - beta: 0.0373 - val_val_loss: 5.5028 - val_val_recon_loss: 0.0047 - val_val_KL loss: 2.0897 - val_beta: 0.0373\n",
      "Epoch 3230/10000\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 5.3901 - recon_loss: 0.0043 - KL loss: 2.2608 - beta: 0.0373 - val_val_loss: 5.1368 - val_val_recon_loss: 0.0037 - val_val_KL loss: 2.4528 - val_beta: 0.0373\n",
      "Epoch 3231/10000\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 5.0955 - recon_loss: 0.0036 - KL loss: 2.4881 - beta: 0.0373 - val_val_loss: 5.0536 - val_val_recon_loss: 0.0035 - val_val_KL loss: 2.5608 - val_beta: 0.0373\n",
      "Epoch 3232/10000\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 5.0007 - recon_loss: 0.0034 - KL loss: 2.5638 - beta: 0.0373 - val_val_loss: 4.9813 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.4994 - val_beta: 0.0373\n",
      "Epoch 3233/10000\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 4.9556 - recon_loss: 0.0033 - KL loss: 2.5833 - beta: 0.0373 - val_val_loss: 4.9148 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.5639 - val_beta: 0.0373\n",
      "Epoch 3234/10000\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 4.9358 - recon_loss: 0.0033 - KL loss: 2.5914 - beta: 0.0373 - val_val_loss: 4.9771 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.6285 - val_beta: 0.0373\n",
      "Epoch 3235/10000\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 4.9379 - recon_loss: 0.0033 - KL loss: 2.5938 - beta: 0.0373 - val_val_loss: 4.9083 - val_val_recon_loss: 0.0032 - val_val_KL loss: 2.6317 - val_beta: 0.0373\n",
      "Epoch 3236/10000\n",
      "1000/1000 [==============================] - 106s 106ms/step - loss: 4.9093 - recon_loss: 0.0032 - KL loss: 2.6191 - beta: 0.0373 - val_val_loss: 4.8807 - val_val_recon_loss: 0.0032 - val_val_KL loss: 2.5746 - val_beta: 0.0373\n",
      "Epoch 3237/10000\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 4.8955 - recon_loss: 0.0032 - KL loss: 2.6262 - beta: 0.0373 - val_val_loss: 4.8832 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6537 - val_beta: 0.0373\n",
      "Epoch 3238/10000\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 4.8956 - recon_loss: 0.0032 - KL loss: 2.6277 - beta: 0.0373 - val_val_loss: 4.8960 - val_val_recon_loss: 0.0032 - val_val_KL loss: 2.6125 - val_beta: 0.0373\n",
      "Epoch 3239/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 4.8840 - recon_loss: 0.0031 - KL loss: 2.6326 - beta: 0.0373 - val_val_loss: 4.9200 - val_val_recon_loss: 0.0032 - val_val_KL loss: 2.6100 - val_beta: 0.0373\n",
      "Epoch 3240/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 4.8865 - recon_loss: 0.0031 - KL loss: 2.6212 - beta: 0.0373 - val_val_loss: 4.8862 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6458 - val_beta: 0.0373\n",
      "Epoch 3241/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 4.8910 - recon_loss: 0.0031 - KL loss: 2.6277 - beta: 0.0373 - val_val_loss: 4.8766 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6273 - val_beta: 0.0373\n",
      "Epoch 3242/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 4.8633 - recon_loss: 0.0031 - KL loss: 2.6444 - beta: 0.0373 - val_val_loss: 4.8526 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6213 - val_beta: 0.0373\n",
      "Epoch 3243/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8530 - recon_loss: 0.0031 - KL loss: 2.6471 - beta: 0.0373 - val_val_loss: 4.8642 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6542 - val_beta: 0.0373\n",
      "Epoch 3244/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8643 - recon_loss: 0.0031 - KL loss: 2.6548 - beta: 0.0373 - val_val_loss: 4.8368 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6840 - val_beta: 0.0373\n",
      "Epoch 3245/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8628 - recon_loss: 0.0031 - KL loss: 2.6429 - beta: 0.0373 - val_val_loss: 4.8513 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6139 - val_beta: 0.0373\n",
      "Epoch 3246/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8796 - recon_loss: 0.0031 - KL loss: 2.6469 - beta: 0.0373 - val_val_loss: 4.8779 - val_val_recon_loss: 0.0032 - val_val_KL loss: 2.6002 - val_beta: 0.0373\n",
      "Epoch 3247/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8635 - recon_loss: 0.0031 - KL loss: 2.6540 - beta: 0.0373 - val_val_loss: 4.8544 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6798 - val_beta: 0.0373\n",
      "Epoch 3248/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8533 - recon_loss: 0.0031 - KL loss: 2.6458 - beta: 0.0373 - val_val_loss: 4.8333 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6365 - val_beta: 0.0373\n",
      "Epoch 3249/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8615 - recon_loss: 0.0031 - KL loss: 2.6631 - beta: 0.0373 - val_val_loss: 4.8365 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6110 - val_beta: 0.0373\n",
      "Epoch 3250/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8485 - recon_loss: 0.0031 - KL loss: 2.6506 - beta: 0.0373 - val_val_loss: 4.8205 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6105 - val_beta: 0.0373\n",
      "Epoch 3251/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8420 - recon_loss: 0.0031 - KL loss: 2.6392 - beta: 0.0373 - val_val_loss: 4.8491 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6974 - val_beta: 0.0373\n",
      "Epoch 3252/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8505 - recon_loss: 0.0031 - KL loss: 2.6459 - beta: 0.0373 - val_val_loss: 4.8347 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6568 - val_beta: 0.0373\n",
      "Epoch 3253/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8450 - recon_loss: 0.0030 - KL loss: 2.6589 - beta: 0.0373 - val_val_loss: 4.8229 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6426 - val_beta: 0.0373\n",
      "Epoch 3254/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8414 - recon_loss: 0.0030 - KL loss: 2.6647 - beta: 0.0373 - val_val_loss: 4.8320 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.7180 - val_beta: 0.0373\n",
      "Epoch 3255/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8327 - recon_loss: 0.0030 - KL loss: 2.6709 - beta: 0.0373 - val_val_loss: 4.8110 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6478 - val_beta: 0.0373\n",
      "Epoch 3256/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 4.8408 - recon_loss: 0.0030 - KL loss: 2.6644 - beta: 0.0373 - val_val_loss: 4.8547 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6095 - val_beta: 0.0373\n",
      "Epoch 3257/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8380 - recon_loss: 0.0030 - KL loss: 2.6662 - beta: 0.0373 - val_val_loss: 4.8298 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6265 - val_beta: 0.0373\n",
      "Epoch 3258/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8454 - recon_loss: 0.0030 - KL loss: 2.6573 - beta: 0.0373 - val_val_loss: 4.7974 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6354 - val_beta: 0.0373\n",
      "Epoch 3259/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8333 - recon_loss: 0.0030 - KL loss: 2.6761 - beta: 0.0373 - val_val_loss: 4.8694 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6291 - val_beta: 0.0373\n",
      "Epoch 3260/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8291 - recon_loss: 0.0030 - KL loss: 2.6571 - beta: 0.0373 - val_val_loss: 4.8476 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6537 - val_beta: 0.0373\n",
      "Epoch 3261/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8092 - recon_loss: 0.0030 - KL loss: 2.6539 - beta: 0.0373 - val_val_loss: 4.8372 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6359 - val_beta: 0.0373\n",
      "Epoch 3262/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8171 - recon_loss: 0.0030 - KL loss: 2.6488 - beta: 0.0373 - val_val_loss: 4.8047 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6823 - val_beta: 0.0373\n",
      "Epoch 3263/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.8231 - recon_loss: 0.0030 - KL loss: 2.6745 - beta: 0.0373\n",
      "Epoch 03263: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8231 - recon_loss: 0.0030 - KL loss: 2.6745 - beta: 0.0373 - val_val_loss: 4.8269 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6437 - val_beta: 0.0373\n",
      "Epoch 3264/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.8028 - recon_loss: 0.0030 - KL loss: 2.6698 - beta: 0.0373 - val_val_loss: 4.7902 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6900 - val_beta: 0.0373\n",
      "Epoch 3265/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7951 - recon_loss: 0.0029 - KL loss: 2.6766 - beta: 0.0373 - val_val_loss: 4.7895 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6900 - val_beta: 0.0373\n",
      "Epoch 3266/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.8021 - recon_loss: 0.0030 - KL loss: 2.6765 - beta: 0.0373 - val_val_loss: 4.7815 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6891 - val_beta: 0.0373\n",
      "Epoch 3267/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7978 - recon_loss: 0.0029 - KL loss: 2.6779 - beta: 0.0373 - val_val_loss: 4.7883 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.7232 - val_beta: 0.0373\n",
      "Epoch 3268/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.8003 - recon_loss: 0.0029 - KL loss: 2.6778 - beta: 0.0373 - val_val_loss: 4.7824 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6628 - val_beta: 0.0373\n",
      "Epoch 3269/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7824 - recon_loss: 0.0029 - KL loss: 2.6729 - beta: 0.0373 - val_val_loss: 4.8019 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6792 - val_beta: 0.0373\n",
      "Epoch 3270/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4.7896 - recon_loss: 0.0029 - KL loss: 2.6681 - beta: 0.0373 - val_val_loss: 4.7687 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6804 - val_beta: 0.0373\n",
      "Epoch 3271/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7903 - recon_loss: 0.0029 - KL loss: 2.6765 - beta: 0.0373 - val_val_loss: 4.7810 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6807 - val_beta: 0.0373\n",
      "Epoch 3272/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7896 - recon_loss: 0.0029 - KL loss: 2.6686 - beta: 0.0373 - val_val_loss: 4.7687 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6704 - val_beta: 0.0373\n",
      "Epoch 3273/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.7830 - recon_loss: 0.0029 - KL loss: 2.6724 - beta: 0.0373 - val_val_loss: 4.7763 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6826 - val_beta: 0.0373\n",
      "Epoch 3274/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7993 - recon_loss: 0.0030 - KL loss: 2.6751 - beta: 0.0373 - val_val_loss: 4.7719 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6805 - val_beta: 0.0373\n",
      "Epoch 3275/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.7901 - recon_loss: 0.0029 - KL loss: 2.6787 - beta: 0.0373\n",
      "Epoch 03275: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7901 - recon_loss: 0.0029 - KL loss: 2.6787 - beta: 0.0373 - val_val_loss: 4.7835 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6670 - val_beta: 0.0373\n",
      "Epoch 3276/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7820 - recon_loss: 0.0029 - KL loss: 2.6773 - beta: 0.0373 - val_val_loss: 4.7747 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6743 - val_beta: 0.0373\n",
      "Epoch 3277/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7809 - recon_loss: 0.0029 - KL loss: 2.6720 - beta: 0.0373 - val_val_loss: 4.7807 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6888 - val_beta: 0.0373\n",
      "Epoch 3278/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7850 - recon_loss: 0.0029 - KL loss: 2.6785 - beta: 0.0373 - val_val_loss: 4.7792 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6804 - val_beta: 0.0373\n",
      "Epoch 3279/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7867 - recon_loss: 0.0029 - KL loss: 2.6794 - beta: 0.0373 - val_val_loss: 4.7845 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6685 - val_beta: 0.0373\n",
      "Epoch 3280/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.7844 - recon_loss: 0.0029 - KL loss: 2.6805 - beta: 0.0373\n",
      "Epoch 03280: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7845 - recon_loss: 0.0029 - KL loss: 2.6805 - beta: 0.0373 - val_val_loss: 4.7833 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6615 - val_beta: 0.0373\n",
      "Epoch 3280/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.6474 - recon_loss: 0.0020 - KL loss: 3.7323 - beta: 0.0228 - val_val_loss: 7.5248 - val_val_recon_loss: 0.0020 - val_val_KL loss: 3.6746 - val_beta: 0.0228\n",
      "Epoch 3281/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5561 - recon_loss: 0.0019 - KL loss: 3.7960 - beta: 0.0228 - val_val_loss: 7.4929 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8287 - val_beta: 0.0228\n",
      "Epoch 3282/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4918 - recon_loss: 0.0019 - KL loss: 3.8090 - beta: 0.0228 - val_val_loss: 7.5087 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7904 - val_beta: 0.0228\n",
      "Epoch 3283/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5180 - recon_loss: 0.0019 - KL loss: 3.8029 - beta: 0.0228 - val_val_loss: 7.4741 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7481 - val_beta: 0.0228\n",
      "Epoch 3284/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.4853 - recon_loss: 0.0019 - KL loss: 3.8139 - beta: 0.0228 - val_val_loss: 7.5199 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7829 - val_beta: 0.0228\n",
      "Epoch 3285/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5431 - recon_loss: 0.0019 - KL loss: 3.8161 - beta: 0.0228 - val_val_loss: 7.5142 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8182 - val_beta: 0.0228\n",
      "Epoch 3286/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5198 - recon_loss: 0.0019 - KL loss: 3.8134 - beta: 0.0228 - val_val_loss: 7.4672 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8331 - val_beta: 0.0228\n",
      "Epoch 3287/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.4946 - recon_loss: 0.0019 - KL loss: 3.8164 - beta: 0.0228 - val_val_loss: 7.5025 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8227 - val_beta: 0.0228\n",
      "Epoch 3288/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5109 - recon_loss: 0.0019 - KL loss: 3.8166 - beta: 0.0228 - val_val_loss: 7.5360 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7818 - val_beta: 0.0228\n",
      "Epoch 3289/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5833 - recon_loss: 0.0019 - KL loss: 3.8238 - beta: 0.0228 - val_val_loss: 7.5180 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8272 - val_beta: 0.0228\n",
      "Epoch 3290/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5553 - recon_loss: 0.0019 - KL loss: 3.8157 - beta: 0.0228 - val_val_loss: 7.4836 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7960 - val_beta: 0.0228\n",
      "Epoch 3291/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5121 - recon_loss: 0.0019 - KL loss: 3.8117 - beta: 0.0228 - val_val_loss: 7.4642 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7812 - val_beta: 0.0228\n",
      "Epoch 3292/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5183 - recon_loss: 0.0019 - KL loss: 3.8158 - beta: 0.0228 - val_val_loss: 7.4768 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8621 - val_beta: 0.0228\n",
      "Epoch 3293/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5367 - recon_loss: 0.0019 - KL loss: 3.8202 - beta: 0.0228 - val_val_loss: 7.4715 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7930 - val_beta: 0.0228\n",
      "Epoch 3294/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4983 - recon_loss: 0.0019 - KL loss: 3.8216 - beta: 0.0228 - val_val_loss: 7.5366 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8061 - val_beta: 0.0228\n",
      "Epoch 3295/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4732 - recon_loss: 0.0019 - KL loss: 3.8207 - beta: 0.0228 - val_val_loss: 7.4388 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8227 - val_beta: 0.0228\n",
      "Epoch 3296/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4605 - recon_loss: 0.0019 - KL loss: 3.8224 - beta: 0.0228 - val_val_loss: 7.5139 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7961 - val_beta: 0.0228\n",
      "Epoch 3297/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5846 - recon_loss: 0.0020 - KL loss: 3.8132 - beta: 0.0228 - val_val_loss: 7.6175 - val_val_recon_loss: 0.0020 - val_val_KL loss: 3.7718 - val_beta: 0.0228\n",
      "Epoch 3298/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5090 - recon_loss: 0.0019 - KL loss: 3.8148 - beta: 0.0228 - val_val_loss: 7.4433 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7718 - val_beta: 0.0228\n",
      "Epoch 3299/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4857 - recon_loss: 0.0019 - KL loss: 3.8251 - beta: 0.0228 - val_val_loss: 7.5251 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8544 - val_beta: 0.0228\n",
      "Epoch 3300/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.5325 - recon_loss: 0.0019 - KL loss: 3.8342 - beta: 0.0228\n",
      "Epoch 03300: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5325 - recon_loss: 0.0019 - KL loss: 3.8342 - beta: 0.0228 - val_val_loss: 7.6474 - val_val_recon_loss: 0.0020 - val_val_KL loss: 3.8131 - val_beta: 0.0228\n",
      "Epoch 3301/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5969 - recon_loss: 0.0020 - KL loss: 3.8283 - beta: 0.0228 - val_val_loss: 7.5475 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8645 - val_beta: 0.0228\n",
      "Epoch 3302/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 7.6060 - recon_loss: 0.0020 - KL loss: 3.8368 - beta: 0.0228 - val_val_loss: 7.4901 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8284 - val_beta: 0.0228\n",
      "Epoch 3303/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4678 - recon_loss: 0.0019 - KL loss: 3.8161 - beta: 0.0228 - val_val_loss: 7.4645 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8452 - val_beta: 0.0228\n",
      "Epoch 3304/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4673 - recon_loss: 0.0019 - KL loss: 3.8177 - beta: 0.0228 - val_val_loss: 7.4174 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7976 - val_beta: 0.0228\n",
      "Epoch 3305/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4606 - recon_loss: 0.0019 - KL loss: 3.8231 - beta: 0.0228 - val_val_loss: 7.4303 - val_val_recon_loss: 0.0018 - val_val_KL loss: 3.8596 - val_beta: 0.0228\n",
      "Epoch 3306/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.4498 - recon_loss: 0.0019 - KL loss: 3.8331 - beta: 0.0228 - val_val_loss: 7.4355 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8319 - val_beta: 0.0228\n",
      "Epoch 3307/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4522 - recon_loss: 0.0019 - KL loss: 3.8357 - beta: 0.0228 - val_val_loss: 7.4087 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8066 - val_beta: 0.0228\n",
      "Epoch 3308/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4287 - recon_loss: 0.0019 - KL loss: 3.8221 - beta: 0.0228 - val_val_loss: 7.4235 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8062 - val_beta: 0.0228\n",
      "Epoch 3309/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4591 - recon_loss: 0.0019 - KL loss: 3.8184 - beta: 0.0228 - val_val_loss: 7.4534 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8201 - val_beta: 0.0228\n",
      "Epoch 3310/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.4531 - recon_loss: 0.0019 - KL loss: 3.8281 - beta: 0.0228 - val_val_loss: 7.4320 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8060 - val_beta: 0.0228\n",
      "Epoch 3311/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4265 - recon_loss: 0.0019 - KL loss: 3.8297 - beta: 0.0228 - val_val_loss: 7.4112 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8295 - val_beta: 0.0228\n",
      "Epoch 3312/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.4488 - recon_loss: 0.0019 - KL loss: 3.8363 - beta: 0.0228\n",
      "Epoch 03312: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4488 - recon_loss: 0.0019 - KL loss: 3.8363 - beta: 0.0228 - val_val_loss: 7.4167 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7867 - val_beta: 0.0228\n",
      "Epoch 3313/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 7.4047 - recon_loss: 0.0019 - KL loss: 3.8306 - beta: 0.0228 - val_val_loss: 7.3920 - val_val_recon_loss: 0.0018 - val_val_KL loss: 3.8420 - val_beta: 0.0228\n",
      "Epoch 3314/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 7.3897 - recon_loss: 0.0018 - KL loss: 3.8331 - beta: 0.0228 - val_val_loss: 7.4023 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8008 - val_beta: 0.0228\n",
      "Epoch 3315/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 7.4020 - recon_loss: 0.0019 - KL loss: 3.8228 - beta: 0.0228 - val_val_loss: 7.3775 - val_val_recon_loss: 0.0018 - val_val_KL loss: 3.8417 - val_beta: 0.0228\n",
      "Epoch 3316/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 7.4209 - recon_loss: 0.0019 - KL loss: 3.8372 - beta: 0.0228 - val_val_loss: 7.4354 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8118 - val_beta: 0.0228\n",
      "Epoch 3317/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 7.4476 - recon_loss: 0.0019 - KL loss: 3.8273 - beta: 0.0228 - val_val_loss: 7.4466 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8257 - val_beta: 0.0228\n",
      "Epoch 3318/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 7.4427 - recon_loss: 0.0019 - KL loss: 3.8277 - beta: 0.0228 - val_val_loss: 7.4153 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8220 - val_beta: 0.0228\n",
      "Epoch 3319/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 7.4198 - recon_loss: 0.0019 - KL loss: 3.8341 - beta: 0.0228 - val_val_loss: 7.3777 - val_val_recon_loss: 0.0018 - val_val_KL loss: 3.8094 - val_beta: 0.0228\n",
      "Epoch 3320/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.3657 - recon_loss: 0.0018 - KL loss: 3.8276 - beta: 0.0228\n",
      "Epoch 03320: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 7.3658 - recon_loss: 0.0018 - KL loss: 3.8276 - beta: 0.0228 - val_val_loss: 7.4075 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8133 - val_beta: 0.0228\n",
      "Epoch 3321/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 7.3928 - recon_loss: 0.0018 - KL loss: 3.8351 - beta: 0.0228 - val_val_loss: 7.3949 - val_val_recon_loss: 0.0018 - val_val_KL loss: 3.8394 - val_beta: 0.0228\n",
      "Epoch 3322/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 7.3723 - recon_loss: 0.0018 - KL loss: 3.8395 - beta: 0.0228 - val_val_loss: 7.4098 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8221 - val_beta: 0.0228\n",
      "Epoch 3323/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 115s 115ms/step - loss: 7.4104 - recon_loss: 0.0019 - KL loss: 3.8273 - beta: 0.0228 - val_val_loss: 7.4115 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8205 - val_beta: 0.0228\n",
      "Epoch 3324/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.4197 - recon_loss: 0.0019 - KL loss: 3.8308 - beta: 0.0228 - val_val_loss: 7.4003 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8080 - val_beta: 0.0228\n",
      "Epoch 3325/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.4259 - recon_loss: 0.0019 - KL loss: 3.8290 - beta: 0.0228\n",
      "Epoch 03325: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.4259 - recon_loss: 0.0019 - KL loss: 3.8290 - beta: 0.0228 - val_val_loss: 7.4075 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8258 - val_beta: 0.0228\n",
      "Epoch 3325/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.1246 - recon_loss: 0.0016 - KL loss: 4.8315 - beta: 0.0139 - val_val_loss: 13.1643 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.9256 - val_beta: 0.0139\n",
      "Epoch 3326/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.1790 - recon_loss: 0.0016 - KL loss: 4.9015 - beta: 0.0139 - val_val_loss: 13.2404 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.9835 - val_beta: 0.0139\n",
      "Epoch 3327/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.1226 - recon_loss: 0.0016 - KL loss: 4.9116 - beta: 0.0139 - val_val_loss: 13.6545 - val_val_recon_loss: 0.0017 - val_val_KL loss: 5.0103 - val_beta: 0.0139\n",
      "Epoch 3328/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.2901 - recon_loss: 0.0016 - KL loss: 4.9036 - beta: 0.0139 - val_val_loss: 13.1691 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.9338 - val_beta: 0.0139\n",
      "Epoch 3329/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.1359 - recon_loss: 0.0016 - KL loss: 4.9007 - beta: 0.0139 - val_val_loss: 13.0532 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.9309 - val_beta: 0.0139\n",
      "Epoch 3330/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.0273 - recon_loss: 0.0016 - KL loss: 4.8956 - beta: 0.0139 - val_val_loss: 13.0750 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.9030 - val_beta: 0.0139\n",
      "Epoch 3331/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.0574 - recon_loss: 0.0016 - KL loss: 4.9103 - beta: 0.0139 - val_val_loss: 13.2631 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.8982 - val_beta: 0.0139\n",
      "Epoch 3332/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.1795 - recon_loss: 0.0016 - KL loss: 4.9141 - beta: 0.0139 - val_val_loss: 13.1751 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.9150 - val_beta: 0.0139\n",
      "Epoch 3333/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.0807 - recon_loss: 0.0016 - KL loss: 4.9003 - beta: 0.0139 - val_val_loss: 13.0407 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.8900 - val_beta: 0.0139\n",
      "Epoch 3334/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.9800 - recon_loss: 0.0016 - KL loss: 4.8959 - beta: 0.0139 - val_val_loss: 12.9454 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.8519 - val_beta: 0.0139\n",
      "Epoch 3335/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.9419 - recon_loss: 0.0016 - KL loss: 4.8902 - beta: 0.0139 - val_val_loss: 12.8743 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9525 - val_beta: 0.0139\n",
      "Epoch 3336/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.8846 - recon_loss: 0.0015 - KL loss: 4.8909 - beta: 0.0139 - val_val_loss: 12.8551 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9742 - val_beta: 0.0139\n",
      "Epoch 3337/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.8103 - recon_loss: 0.0015 - KL loss: 4.9008 - beta: 0.0139 - val_val_loss: 12.9115 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9199 - val_beta: 0.0139\n",
      "Epoch 3338/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.9707 - recon_loss: 0.0016 - KL loss: 4.9048 - beta: 0.0139 - val_val_loss: 12.8292 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9166 - val_beta: 0.0139\n",
      "Epoch 3339/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.8784 - recon_loss: 0.0015 - KL loss: 4.8966 - beta: 0.0139 - val_val_loss: 12.8718 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.8375 - val_beta: 0.0139\n",
      "Epoch 3340/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.9470 - recon_loss: 0.0016 - KL loss: 4.9022 - beta: 0.0139 - val_val_loss: 12.9071 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.8660 - val_beta: 0.0139\n",
      "Epoch 3341/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.8258 - recon_loss: 0.0015 - KL loss: 4.8980 - beta: 0.0139 - val_val_loss: 12.9190 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8911 - val_beta: 0.0139\n",
      "Epoch 3342/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.0337 - recon_loss: 0.0016 - KL loss: 4.9198 - beta: 0.0139 - val_val_loss: 12.9095 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9085 - val_beta: 0.0139\n",
      "Epoch 3343/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.8605 - recon_loss: 0.0015 - KL loss: 4.9029 - beta: 0.0139\n",
      "Epoch 03343: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.8605 - recon_loss: 0.0015 - KL loss: 4.9029 - beta: 0.0139 - val_val_loss: 12.8572 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8902 - val_beta: 0.0139\n",
      "Epoch 3344/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.8102 - recon_loss: 0.0015 - KL loss: 4.9153 - beta: 0.0139 - val_val_loss: 12.7787 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9023 - val_beta: 0.0139\n",
      "Epoch 3345/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.7641 - recon_loss: 0.0015 - KL loss: 4.9142 - beta: 0.0139 - val_val_loss: 12.6892 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8884 - val_beta: 0.0139\n",
      "Epoch 3346/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6818 - recon_loss: 0.0015 - KL loss: 4.9008 - beta: 0.0139 - val_val_loss: 12.6479 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9095 - val_beta: 0.0139\n",
      "Epoch 3347/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6541 - recon_loss: 0.0015 - KL loss: 4.8980 - beta: 0.0139 - val_val_loss: 12.6481 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9208 - val_beta: 0.0139\n",
      "Epoch 3348/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6926 - recon_loss: 0.0015 - KL loss: 4.9194 - beta: 0.0139 - val_val_loss: 12.6365 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8731 - val_beta: 0.0139\n",
      "Epoch 3349/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.6031 - recon_loss: 0.0015 - KL loss: 4.9158 - beta: 0.0139 - val_val_loss: 12.6674 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8949 - val_beta: 0.0139\n",
      "Epoch 3350/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.7572 - recon_loss: 0.0015 - KL loss: 4.9180 - beta: 0.0139 - val_val_loss: 12.6583 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8927 - val_beta: 0.0139\n",
      "Epoch 3351/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6166 - recon_loss: 0.0015 - KL loss: 4.9062 - beta: 0.0139 - val_val_loss: 12.6374 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9160 - val_beta: 0.0139\n",
      "Epoch 3352/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6355 - recon_loss: 0.0015 - KL loss: 4.9158 - beta: 0.0139 - val_val_loss: 12.6923 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9250 - val_beta: 0.0139\n",
      "Epoch 3353/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 12.7113 - recon_loss: 0.0015 - KL loss: 4.9308 - beta: 0.0139\n",
      "Epoch 03353: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.7113 - recon_loss: 0.0015 - KL loss: 4.9308 - beta: 0.0139 - val_val_loss: 12.6825 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9008 - val_beta: 0.0139\n",
      "Epoch 3354/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.6537 - recon_loss: 0.0015 - KL loss: 4.9187 - beta: 0.0139 - val_val_loss: 12.6300 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9325 - val_beta: 0.0139\n",
      "Epoch 3355/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5900 - recon_loss: 0.0015 - KL loss: 4.9256 - beta: 0.0139 - val_val_loss: 12.6536 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9219 - val_beta: 0.0139\n",
      "Epoch 3356/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.6502 - recon_loss: 0.0015 - KL loss: 4.9277 - beta: 0.0139 - val_val_loss: 12.6222 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9129 - val_beta: 0.0139\n",
      "Epoch 3357/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6254 - recon_loss: 0.0015 - KL loss: 4.9106 - beta: 0.0139 - val_val_loss: 12.6395 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8994 - val_beta: 0.0139\n",
      "Epoch 3358/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6450 - recon_loss: 0.0015 - KL loss: 4.9230 - beta: 0.0139 - val_val_loss: 12.6193 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9106 - val_beta: 0.0139\n",
      "Epoch 3359/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6767 - recon_loss: 0.0015 - KL loss: 4.9197 - beta: 0.0139 - val_val_loss: 12.6028 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9002 - val_beta: 0.0139\n",
      "Epoch 3360/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6668 - recon_loss: 0.0015 - KL loss: 4.9102 - beta: 0.0139 - val_val_loss: 12.5874 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9170 - val_beta: 0.0139\n",
      "Epoch 3361/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5724 - recon_loss: 0.0015 - KL loss: 4.9232 - beta: 0.0139 - val_val_loss: 12.5807 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9219 - val_beta: 0.0139\n",
      "Epoch 3362/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5458 - recon_loss: 0.0015 - KL loss: 4.9229 - beta: 0.0139 - val_val_loss: 12.6100 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9024 - val_beta: 0.0139\n",
      "Epoch 3363/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5843 - recon_loss: 0.0015 - KL loss: 4.9118 - beta: 0.0139 - val_val_loss: 12.5710 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9269 - val_beta: 0.0139\n",
      "Epoch 3364/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5574 - recon_loss: 0.0015 - KL loss: 4.9134 - beta: 0.0139 - val_val_loss: 12.6013 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9186 - val_beta: 0.0139\n",
      "Epoch 3365/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5854 - recon_loss: 0.0015 - KL loss: 4.9166 - beta: 0.0139 - val_val_loss: 12.5835 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9011 - val_beta: 0.0139\n",
      "Epoch 3366/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.6061 - recon_loss: 0.0015 - KL loss: 4.9170 - beta: 0.0139 - val_val_loss: 12.5917 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9052 - val_beta: 0.0139\n",
      "Epoch 3367/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5067 - recon_loss: 0.0015 - KL loss: 4.9151 - beta: 0.0139 - val_val_loss: 12.5942 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9119 - val_beta: 0.0139\n",
      "Epoch 3368/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.5657 - recon_loss: 0.0015 - KL loss: 4.9115 - beta: 0.0139\n",
      "Epoch 03368: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5657 - recon_loss: 0.0015 - KL loss: 4.9115 - beta: 0.0139 - val_val_loss: 12.5936 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9280 - val_beta: 0.0139\n",
      "Epoch 3369/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5906 - recon_loss: 0.0015 - KL loss: 4.9231 - beta: 0.0139 - val_val_loss: 12.5949 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9198 - val_beta: 0.0139\n",
      "Epoch 3370/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6025 - recon_loss: 0.0015 - KL loss: 4.9158 - beta: 0.0139 - val_val_loss: 12.5816 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9104 - val_beta: 0.0139\n",
      "Epoch 3371/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5657 - recon_loss: 0.0015 - KL loss: 4.9173 - beta: 0.0139 - val_val_loss: 12.6459 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9066 - val_beta: 0.0139\n",
      "Epoch 3372/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5799 - recon_loss: 0.0015 - KL loss: 4.9111 - beta: 0.0139 - val_val_loss: 12.6020 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8988 - val_beta: 0.0139\n",
      "Epoch 3373/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5494 - recon_loss: 0.0015 - KL loss: 4.9037 - beta: 0.0139 - val_val_loss: 12.5601 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8968 - val_beta: 0.0139\n",
      "Epoch 3374/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5455 - recon_loss: 0.0015 - KL loss: 4.9044 - beta: 0.0139 - val_val_loss: 12.5290 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9192 - val_beta: 0.0139\n",
      "Epoch 3375/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5963 - recon_loss: 0.0015 - KL loss: 4.9136 - beta: 0.0139 - val_val_loss: 12.5670 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9032 - val_beta: 0.0139\n",
      "Epoch 3376/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 12.5308 - recon_loss: 0.0015 - KL loss: 4.9087 - beta: 0.0139 - val_val_loss: 12.5876 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9004 - val_beta: 0.0139\n",
      "Epoch 3377/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5240 - recon_loss: 0.0015 - KL loss: 4.9112 - beta: 0.0139 - val_val_loss: 12.5854 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9162 - val_beta: 0.0139\n",
      "Epoch 3378/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6386 - recon_loss: 0.0015 - KL loss: 4.9129 - beta: 0.0139 - val_val_loss: 12.5863 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9011 - val_beta: 0.0139\n",
      "Epoch 3379/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.4717 - recon_loss: 0.0015 - KL loss: 4.9091 - beta: 0.0139\n",
      "Epoch 03379: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.4718 - recon_loss: 0.0015 - KL loss: 4.9091 - beta: 0.0139 - val_val_loss: 12.5619 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9153 - val_beta: 0.0139\n",
      "Epoch 3380/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5075 - recon_loss: 0.0015 - KL loss: 4.9182 - beta: 0.0139 - val_val_loss: 12.5503 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9142 - val_beta: 0.0139\n",
      "Epoch 3381/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5600 - recon_loss: 0.0015 - KL loss: 4.9156 - beta: 0.0139 - val_val_loss: 12.5593 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9133 - val_beta: 0.0139\n",
      "Epoch 3382/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5477 - recon_loss: 0.0015 - KL loss: 4.9147 - beta: 0.0139 - val_val_loss: 12.5471 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9124 - val_beta: 0.0139\n",
      "Epoch 3383/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6113 - recon_loss: 0.0015 - KL loss: 4.9110 - beta: 0.0139 - val_val_loss: 12.5533 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9149 - val_beta: 0.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3384/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.5575 - recon_loss: 0.0015 - KL loss: 4.9212 - beta: 0.0139\n",
      "Epoch 03384: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5575 - recon_loss: 0.0015 - KL loss: 4.9212 - beta: 0.0139 - val_val_loss: 12.5345 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9148 - val_beta: 0.0139\n",
      "Epoch 3384/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.2867 - recon_loss: 0.0014 - KL loss: 5.8802 - beta: 0.0085 - val_val_loss: 25.5553 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.9241 - val_beta: 0.0085\n",
      "Epoch 3385/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.4701 - recon_loss: 0.0014 - KL loss: 5.9655 - beta: 0.0085 - val_val_loss: 25.4412 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.9231 - val_beta: 0.0085\n",
      "Epoch 3386/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 24.9942 - recon_loss: 0.0014 - KL loss: 5.9998 - beta: 0.0085 - val_val_loss: 25.0165 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0614 - val_beta: 0.0085\n",
      "Epoch 3387/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.2043 - recon_loss: 0.0014 - KL loss: 5.9996 - beta: 0.0085 - val_val_loss: 25.2364 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.9715 - val_beta: 0.0085\n",
      "Epoch 3388/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 24.8963 - recon_loss: 0.0014 - KL loss: 5.9947 - beta: 0.0085 - val_val_loss: 24.8369 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0450 - val_beta: 0.0085\n",
      "Epoch 3389/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.4457 - recon_loss: 0.0014 - KL loss: 6.0267 - beta: 0.0085 - val_val_loss: 25.2241 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0922 - val_beta: 0.0085\n",
      "Epoch 3390/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.6584 - recon_loss: 0.0014 - KL loss: 6.0177 - beta: 0.0085 - val_val_loss: 25.3647 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0893 - val_beta: 0.0085\n",
      "Epoch 3391/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 26.0279 - recon_loss: 0.0014 - KL loss: 6.0329 - beta: 0.0085 - val_val_loss: 26.7736 - val_val_recon_loss: 0.0015 - val_val_KL loss: 6.0723 - val_beta: 0.0085\n",
      "Epoch 3392/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 26.6986 - recon_loss: 0.0015 - KL loss: 6.0819 - beta: 0.0085 - val_val_loss: 26.5819 - val_val_recon_loss: 0.0015 - val_val_KL loss: 6.1555 - val_beta: 0.0085\n",
      "Epoch 3393/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 26.4520 - recon_loss: 0.0015 - KL loss: 6.0765 - beta: 0.0085\n",
      "Epoch 03393: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 26.4518 - recon_loss: 0.0015 - KL loss: 6.0765 - beta: 0.0085 - val_val_loss: 25.7757 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0985 - val_beta: 0.0085\n",
      "Epoch 3394/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.6292 - recon_loss: 0.0014 - KL loss: 6.0312 - beta: 0.0085 - val_val_loss: 25.3888 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0047 - val_beta: 0.0085\n",
      "Epoch 3395/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.4530 - recon_loss: 0.0014 - KL loss: 5.9870 - beta: 0.0085 - val_val_loss: 25.5601 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.9791 - val_beta: 0.0085\n",
      "Epoch 3396/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.6082 - recon_loss: 0.0014 - KL loss: 6.0104 - beta: 0.0085 - val_val_loss: 25.3848 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0308 - val_beta: 0.0085\n",
      "Epoch 3397/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 25.4286 - recon_loss: 0.0014 - KL loss: 6.0185 - beta: 0.0085 - val_val_loss: 25.4760 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.9961 - val_beta: 0.0085\n",
      "Epoch 3398/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 25.5173 - recon_loss: 0.0014 - KL loss: 6.0032 - beta: 0.0085\n",
      "Epoch 03398: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.5171 - recon_loss: 0.0014 - KL loss: 6.0032 - beta: 0.0085 - val_val_loss: 25.2545 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0520 - val_beta: 0.0085\n",
      "Epoch 3398/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 59.4270 - recon_loss: 0.0014 - KL loss: 7.0027 - beta: 0.0052 - val_val_loss: 58.6708 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.1279 - val_beta: 0.0052\n",
      "Epoch 3399/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 58.9463 - recon_loss: 0.0014 - KL loss: 7.1264 - beta: 0.0052 - val_val_loss: 57.6729 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.2927 - val_beta: 0.0052\n",
      "Epoch 3400/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 57.6500 - recon_loss: 0.0014 - KL loss: 7.1477 - beta: 0.0052 - val_val_loss: 57.1366 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.0952 - val_beta: 0.0052\n",
      "Epoch 3401/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 56.7000 - recon_loss: 0.0013 - KL loss: 7.0652 - beta: 0.0052 - val_val_loss: 56.5030 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2526 - val_beta: 0.0052\n",
      "Epoch 3402/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 56.5153 - recon_loss: 0.0013 - KL loss: 7.1168 - beta: 0.0052 - val_val_loss: 56.5566 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.1404 - val_beta: 0.0052\n",
      "Epoch 3403/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 56.6256 - recon_loss: 0.0013 - KL loss: 7.0759 - beta: 0.0052 - val_val_loss: 56.0388 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.0306 - val_beta: 0.0052\n",
      "Epoch 3404/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 56.2409 - recon_loss: 0.0013 - KL loss: 7.0815 - beta: 0.0052 - val_val_loss: 58.5218 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.1422 - val_beta: 0.0052\n",
      "Epoch 3405/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 57.7491 - recon_loss: 0.0014 - KL loss: 7.1957 - beta: 0.0052 - val_val_loss: 59.9867 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.2332 - val_beta: 0.0052\n",
      "Epoch 3406/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 58.6558 - recon_loss: 0.0014 - KL loss: 7.2323 - beta: 0.0052 - val_val_loss: 58.1630 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.3529 - val_beta: 0.0052\n",
      "Epoch 3407/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 57.4079 - recon_loss: 0.0013 - KL loss: 7.2746 - beta: 0.0052 - val_val_loss: 57.1006 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2802 - val_beta: 0.0052\n",
      "Epoch 3408/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 57.4824 - recon_loss: 0.0013 - KL loss: 7.1834 - beta: 0.0052\n",
      "Epoch 03408: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 57.4823 - recon_loss: 0.0013 - KL loss: 7.1834 - beta: 0.0052 - val_val_loss: 56.4063 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.1672 - val_beta: 0.0052\n",
      "Epoch 3409/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 56.4650 - recon_loss: 0.0013 - KL loss: 7.1338 - beta: 0.0052 - val_val_loss: 56.1593 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.1692 - val_beta: 0.0052\n",
      "Epoch 3410/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 56.8075 - recon_loss: 0.0013 - KL loss: 7.1690 - beta: 0.0052 - val_val_loss: 56.3604 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.1926 - val_beta: 0.0052\n",
      "Epoch 3411/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 56.2188 - recon_loss: 0.0013 - KL loss: 7.1803 - beta: 0.0052 - val_val_loss: 55.7044 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.1444 - val_beta: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3412/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 56.1721 - recon_loss: 0.0013 - KL loss: 7.1531 - beta: 0.0052 - val_val_loss: 57.6387 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.1492 - val_beta: 0.0052\n",
      "Epoch 3413/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 56.6391 - recon_loss: 0.0013 - KL loss: 7.2086 - beta: 0.0052 - val_val_loss: 57.4025 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.1867 - val_beta: 0.0052\n",
      "Epoch 3414/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 57.5593 - recon_loss: 0.0014 - KL loss: 7.2190 - beta: 0.0052 - val_val_loss: 58.0413 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.2896 - val_beta: 0.0052\n",
      "Epoch 3415/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 57.9997 - recon_loss: 0.0014 - KL loss: 7.2179 - beta: 0.0052 - val_val_loss: 59.1839 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.3018 - val_beta: 0.0052\n",
      "Epoch 3416/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 58.8892 - recon_loss: 0.0014 - KL loss: 7.2997 - beta: 0.0052\n",
      "Epoch 03416: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 58.8888 - recon_loss: 0.0014 - KL loss: 7.2997 - beta: 0.0052 - val_val_loss: 57.3502 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.3105 - val_beta: 0.0052\n",
      "Epoch 3417/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 57.2820 - recon_loss: 0.0013 - KL loss: 7.3062 - beta: 0.0052 - val_val_loss: 57.8503 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.2606 - val_beta: 0.0052\n",
      "Epoch 3418/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 57.5502 - recon_loss: 0.0013 - KL loss: 7.2373 - beta: 0.0052 - val_val_loss: 57.5055 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2550 - val_beta: 0.0052\n",
      "Epoch 3419/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 57.1987 - recon_loss: 0.0013 - KL loss: 7.2670 - beta: 0.0052 - val_val_loss: 57.1450 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2979 - val_beta: 0.0052\n",
      "Epoch 3420/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 56.4881 - recon_loss: 0.0013 - KL loss: 7.2910 - beta: 0.0052 - val_val_loss: 57.0191 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2521 - val_beta: 0.0052\n",
      "Epoch 3421/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 56.8802 - recon_loss: 0.0013 - KL loss: 7.2531 - beta: 0.0052\n",
      "Epoch 03421: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 56.8803 - recon_loss: 0.0013 - KL loss: 7.2531 - beta: 0.0052 - val_val_loss: 57.3271 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2185 - val_beta: 0.0052\n",
      "Epoch 3421/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 147.2177 - recon_loss: 0.0014 - KL loss: 8.1457 - beta: 0.0032 - val_val_loss: 141.0450 - val_val_recon_loss: 0.0013 - val_val_KL loss: 8.2686 - val_beta: 0.0032\n",
      "Epoch 3422/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 140.6397 - recon_loss: 0.0013 - KL loss: 8.3472 - beta: 0.0032 - val_val_loss: 140.3017 - val_val_recon_loss: 0.0013 - val_val_KL loss: 8.2077 - val_beta: 0.0032\n",
      "Epoch 3423/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 138.0632 - recon_loss: 0.0013 - KL loss: 8.1595 - beta: 0.0032 - val_val_loss: 139.1128 - val_val_recon_loss: 0.0013 - val_val_KL loss: 8.2820 - val_beta: 0.0032\n",
      "Epoch 3424/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 138.6866 - recon_loss: 0.0013 - KL loss: 8.2641 - beta: 0.0032 - val_val_loss: 143.3583 - val_val_recon_loss: 0.0013 - val_val_KL loss: 8.5080 - val_beta: 0.0032\n",
      "Epoch 3425/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 146.9553 - recon_loss: 0.0014 - KL loss: 8.4989 - beta: 0.0032 - val_val_loss: 144.8592 - val_val_recon_loss: 0.0014 - val_val_KL loss: 8.7062 - val_beta: 0.0032\n",
      "Epoch 3426/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 146.1299 - recon_loss: 0.0014 - KL loss: 8.7831 - beta: 0.0032 - val_val_loss: 143.5051 - val_val_recon_loss: 0.0013 - val_val_KL loss: 8.6315 - val_beta: 0.0032\n",
      "Epoch 3427/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 143.8764 - recon_loss: 0.0013 - KL loss: 8.9556 - beta: 0.0032 - val_val_loss: 148.6463 - val_val_recon_loss: 0.0014 - val_val_KL loss: 9.7857 - val_beta: 0.0032\n",
      "Epoch 3428/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 143.8496 - recon_loss: 0.0013 - KL loss: 10.0790 - beta: 0.0032\n",
      "Epoch 03428: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 143.8474 - recon_loss: 0.0013 - KL loss: 10.0793 - beta: 0.0032 - val_val_loss: 139.1210 - val_val_recon_loss: 0.0013 - val_val_KL loss: 11.0682 - val_beta: 0.0032\n",
      "Epoch 3429/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 136.4204 - recon_loss: 0.0013 - KL loss: 10.9484 - beta: 0.0032 - val_val_loss: 135.6033 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.2619 - val_beta: 0.0032\n",
      "Epoch 3430/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 134.9727 - recon_loss: 0.0012 - KL loss: 11.2366 - beta: 0.0032 - val_val_loss: 133.8284 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.2129 - val_beta: 0.0032\n",
      "Epoch 3431/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 134.2440 - recon_loss: 0.0012 - KL loss: 11.3091 - beta: 0.0032 - val_val_loss: 131.0860 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.2652 - val_beta: 0.0032\n",
      "Epoch 3432/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 132.4570 - recon_loss: 0.0012 - KL loss: 11.2679 - beta: 0.0032 - val_val_loss: 131.5077 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.4892 - val_beta: 0.0032\n",
      "Epoch 3433/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 130.5378 - recon_loss: 0.0012 - KL loss: 11.3271 - beta: 0.0032 - val_val_loss: 128.1512 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.2945 - val_beta: 0.0032\n",
      "Epoch 3434/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 128.2637 - recon_loss: 0.0012 - KL loss: 11.2772 - beta: 0.0032 - val_val_loss: 128.8490 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.2782 - val_beta: 0.0032\n",
      "Epoch 3435/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 127.5568 - recon_loss: 0.0012 - KL loss: 11.3282 - beta: 0.0032 - val_val_loss: 130.3728 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.8156 - val_beta: 0.0032\n",
      "Epoch 3436/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 129.6619 - recon_loss: 0.0012 - KL loss: 11.7972 - beta: 0.0032 - val_val_loss: 129.5359 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.8919 - val_beta: 0.0032\n",
      "Epoch 3437/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 129.0074 - recon_loss: 0.0012 - KL loss: 11.9613 - beta: 0.0032 - val_val_loss: 128.8930 - val_val_recon_loss: 0.0012 - val_val_KL loss: 12.2293 - val_beta: 0.0032\n",
      "Epoch 3438/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 128.4864 - recon_loss: 0.0012 - KL loss: 11.9489 - beta: 0.0032 - val_val_loss: 126.4020 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.6485 - val_beta: 0.0032\n",
      "Epoch 3439/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 125.3830 - recon_loss: 0.0011 - KL loss: 11.5957 - beta: 0.0032 - val_val_loss: 124.9555 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.5022 - val_beta: 0.0032\n",
      "Epoch 3440/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 124.6662 - recon_loss: 0.0011 - KL loss: 11.5359 - beta: 0.0032 - val_val_loss: 124.7718 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.4932 - val_beta: 0.0032\n",
      "Epoch 3441/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 124.6035 - recon_loss: 0.0011 - KL loss: 11.3632 - beta: 0.0032 - val_val_loss: 123.3791 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.7199 - val_beta: 0.0032\n",
      "Epoch 3442/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 121.9436 - recon_loss: 0.0011 - KL loss: 11.5229 - beta: 0.0032 - val_val_loss: 121.4238 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.3993 - val_beta: 0.0032\n",
      "Epoch 3443/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 121.8248 - recon_loss: 0.0011 - KL loss: 11.4395 - beta: 0.0032 - val_val_loss: 121.4511 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.6106 - val_beta: 0.0032\n",
      "Epoch 3444/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 120.6986 - recon_loss: 0.0011 - KL loss: 11.5882 - beta: 0.0032 - val_val_loss: 121.2995 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.7032 - val_beta: 0.0032\n",
      "Epoch 3445/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 121.6328 - recon_loss: 0.0011 - KL loss: 11.6547 - beta: 0.0032 - val_val_loss: 120.6014 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.7980 - val_beta: 0.0032\n",
      "Epoch 3446/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.2297 - recon_loss: 0.0011 - KL loss: 11.7090 - beta: 0.0032 - val_val_loss: 119.8358 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.7896 - val_beta: 0.0032\n",
      "Epoch 3447/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 119.2147 - recon_loss: 0.0011 - KL loss: 11.7615 - beta: 0.0032 - val_val_loss: 120.9678 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.9081 - val_beta: 0.0032\n",
      "Epoch 3448/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.5835 - recon_loss: 0.0011 - KL loss: 11.8856 - beta: 0.0032 - val_val_loss: 121.2702 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.9674 - val_beta: 0.0032\n",
      "Epoch 3449/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.2607 - recon_loss: 0.0011 - KL loss: 11.8819 - beta: 0.0032 - val_val_loss: 121.9831 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.8390 - val_beta: 0.0032\n",
      "Epoch 3450/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.5278 - recon_loss: 0.0011 - KL loss: 11.8661 - beta: 0.0032 - val_val_loss: 119.2624 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.8467 - val_beta: 0.0032\n",
      "Epoch 3451/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.4548 - recon_loss: 0.0011 - KL loss: 11.8459 - beta: 0.0032 - val_val_loss: 119.1767 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.8169 - val_beta: 0.0032\n",
      "Epoch 3452/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.9800 - recon_loss: 0.0011 - KL loss: 12.0158 - beta: 0.0032 - val_val_loss: 122.3100 - val_val_recon_loss: 0.0011 - val_val_KL loss: 12.1172 - val_beta: 0.0032\n",
      "Epoch 3453/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.5893 - recon_loss: 0.0011 - KL loss: 12.1252 - beta: 0.0032 - val_val_loss: 121.0097 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.9783 - val_beta: 0.0032\n",
      "Epoch 3454/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 122.7140 - recon_loss: 0.0011 - KL loss: 12.0121 - beta: 0.0032 - val_val_loss: 120.6001 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.9752 - val_beta: 0.0032\n",
      "Epoch 3455/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 119.9809 - recon_loss: 0.0011 - KL loss: 12.0193 - beta: 0.0032 - val_val_loss: 120.4930 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.9760 - val_beta: 0.0032\n",
      "Epoch 3456/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 121.1008 - recon_loss: 0.0011 - KL loss: 12.0124 - beta: 0.0032\n",
      "Epoch 03456: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 121.0999 - recon_loss: 0.0011 - KL loss: 12.0124 - beta: 0.0032 - val_val_loss: 120.6186 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.9297 - val_beta: 0.0032\n",
      "Epoch 3457/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 121.0598 - recon_loss: 0.0011 - KL loss: 12.0571 - beta: 0.0032 - val_val_loss: 119.8642 - val_val_recon_loss: 0.0011 - val_val_KL loss: 12.1514 - val_beta: 0.0032\n",
      "Epoch 3458/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 119.1310 - recon_loss: 0.0011 - KL loss: 12.1312 - beta: 0.0032 - val_val_loss: 120.5394 - val_val_recon_loss: 0.0011 - val_val_KL loss: 12.2162 - val_beta: 0.0032\n",
      "Epoch 3459/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 120.5750 - recon_loss: 0.0011 - KL loss: 12.1924 - beta: 0.0032 - val_val_loss: 120.5201 - val_val_recon_loss: 0.0011 - val_val_KL loss: 12.2176 - val_beta: 0.0032\n",
      "Epoch 3460/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 120.7321 - recon_loss: 0.0011 - KL loss: 12.2143 - beta: 0.0032 - val_val_loss: 119.3991 - val_val_recon_loss: 0.0011 - val_val_KL loss: 12.1719 - val_beta: 0.0032\n",
      "Epoch 3461/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 120.7489 - recon_loss: 0.0011 - KL loss: 12.2163 - beta: 0.0032\n",
      "Epoch 03461: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 120.7487 - recon_loss: 0.0011 - KL loss: 12.2163 - beta: 0.0032 - val_val_loss: 119.9794 - val_val_recon_loss: 0.0011 - val_val_KL loss: 12.1708 - val_beta: 0.0032\n",
      "Epoch 3461/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 314.7493 - recon_loss: 0.0011 - KL loss: 14.8120 - beta: 0.0019 - val_val_loss: 310.0626 - val_val_recon_loss: 0.0011 - val_val_KL loss: 16.3244 - val_beta: 0.0019\n",
      "Epoch 3462/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 307.3261 - recon_loss: 0.0011 - KL loss: 16.5442 - beta: 0.0019 - val_val_loss: 307.1768 - val_val_recon_loss: 0.0011 - val_val_KL loss: 16.9640 - val_beta: 0.0019\n",
      "Epoch 3463/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 303.2117 - recon_loss: 0.0011 - KL loss: 16.1469 - beta: 0.0019 - val_val_loss: 296.0112 - val_val_recon_loss: 0.0010 - val_val_KL loss: 15.9363 - val_beta: 0.0019\n",
      "Epoch 3464/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 296.7651 - recon_loss: 0.0010 - KL loss: 16.3662 - beta: 0.0019 - val_val_loss: 307.4694 - val_val_recon_loss: 0.0011 - val_val_KL loss: 17.0531 - val_beta: 0.0019\n",
      "Epoch 3465/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 310.2494 - recon_loss: 0.0011 - KL loss: 17.1850 - beta: 0.0019 - val_val_loss: 312.6570 - val_val_recon_loss: 0.0011 - val_val_KL loss: 18.7749 - val_beta: 0.0019\n",
      "Epoch 3466/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 310.5964 - recon_loss: 0.0011 - KL loss: 17.5706 - beta: 0.0019 - val_val_loss: 305.1532 - val_val_recon_loss: 0.0011 - val_val_KL loss: 17.8765 - val_beta: 0.0019\n",
      "Epoch 3467/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 305.5029 - recon_loss: 0.0011 - KL loss: 17.9711 - beta: 0.0019 - val_val_loss: 316.0296 - val_val_recon_loss: 0.0011 - val_val_KL loss: 18.7766 - val_beta: 0.0019\n",
      "Epoch 3468/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 309.0551 - recon_loss: 0.0011 - KL loss: 18.8004 - beta: 0.0019\n",
      "Epoch 03468: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 309.0540 - recon_loss: 0.0011 - KL loss: 18.8004 - beta: 0.0019 - val_val_loss: 306.8905 - val_val_recon_loss: 0.0011 - val_val_KL loss: 18.8707 - val_beta: 0.0019\n",
      "Epoch 3469/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 302.0248 - recon_loss: 0.0011 - KL loss: 18.5872 - beta: 0.0019 - val_val_loss: 298.4450 - val_val_recon_loss: 0.0010 - val_val_KL loss: 18.4077 - val_beta: 0.0019\n",
      "Epoch 3470/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 299.7363 - recon_loss: 0.0010 - KL loss: 18.3057 - beta: 0.0019 - val_val_loss: 293.3787 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.9454 - val_beta: 0.0019\n",
      "Epoch 3471/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 294.6204 - recon_loss: 0.0010 - KL loss: 17.8711 - beta: 0.0019 - val_val_loss: 293.7485 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.8666 - val_beta: 0.0019\n",
      "Epoch 3472/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 290.9760 - recon_loss: 0.0010 - KL loss: 17.7414 - beta: 0.0019 - val_val_loss: 292.3014 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.5055 - val_beta: 0.0019\n",
      "Epoch 3473/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 289.4732 - recon_loss: 0.0010 - KL loss: 17.4951 - beta: 0.0019 - val_val_loss: 288.3490 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.4851 - val_beta: 0.0019\n",
      "Epoch 3474/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 285.7910 - recon_loss: 0.0010 - KL loss: 17.3547 - beta: 0.0019 - val_val_loss: 286.7814 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.0843 - val_beta: 0.0019\n",
      "Epoch 3475/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 285.0678 - recon_loss: 9.9886e-04 - KL loss: 17.1032 - beta: 0.0019 - val_val_loss: 285.6054 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.0111 - val_beta: 0.0019\n",
      "Epoch 3476/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 285.0781 - recon_loss: 9.9981e-04 - KL loss: 16.8591 - beta: 0.0019 - val_val_loss: 286.0237 - val_val_recon_loss: 0.0010 - val_val_KL loss: 16.7450 - val_beta: 0.0019\n",
      "Epoch 3477/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 287.2605 - recon_loss: 0.0010 - KL loss: 16.6021 - beta: 0.0019 - val_val_loss: 283.6970 - val_val_recon_loss: 9.9551e-04 - val_val_KL loss: 16.6330 - val_beta: 0.0019\n",
      "Epoch 3478/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 283.5180 - recon_loss: 9.9425e-04 - KL loss: 16.7901 - beta: 0.0019 - val_val_loss: 282.0058 - val_val_recon_loss: 9.8943e-04 - val_val_KL loss: 16.5713 - val_beta: 0.0019\n",
      "Epoch 3479/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 282.8401 - recon_loss: 9.9328e-04 - KL loss: 16.3738 - beta: 0.0019 - val_val_loss: 282.7943 - val_val_recon_loss: 9.9439e-04 - val_val_KL loss: 16.0304 - val_beta: 0.0019\n",
      "Epoch 3480/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 281.2365 - recon_loss: 9.8848e-04 - KL loss: 16.0562 - beta: 0.0019 - val_val_loss: 288.2583 - val_val_recon_loss: 0.0010 - val_val_KL loss: 16.3094 - val_beta: 0.0019\n",
      "Epoch 3481/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 282.3771 - recon_loss: 9.9226e-04 - KL loss: 16.1853 - beta: 0.0019 - val_val_loss: 282.1797 - val_val_recon_loss: 9.9201e-04 - val_val_KL loss: 16.0534 - val_beta: 0.0019\n",
      "Epoch 3482/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 281.4171 - recon_loss: 9.8943e-04 - KL loss: 15.9827 - beta: 0.0019 - val_val_loss: 281.1472 - val_val_recon_loss: 9.8801e-04 - val_val_KL loss: 16.0951 - val_beta: 0.0019\n",
      "Epoch 3483/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 278.2643 - recon_loss: 9.7824e-04 - KL loss: 15.8330 - beta: 0.0019 - val_val_loss: 278.5416 - val_val_recon_loss: 9.7886e-04 - val_val_KL loss: 15.9427 - val_beta: 0.0019\n",
      "Epoch 3484/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 279.9469 - recon_loss: 9.8457e-04 - KL loss: 15.8168 - beta: 0.0019 - val_val_loss: 278.1648 - val_val_recon_loss: 9.7875e-04 - val_val_KL loss: 15.5966 - val_beta: 0.0019\n",
      "Epoch 3485/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 278.1447 - recon_loss: 9.7887e-04 - KL loss: 15.5440 - beta: 0.0019 - val_val_loss: 277.3176 - val_val_recon_loss: 9.7620e-04 - val_val_KL loss: 15.4321 - val_beta: 0.0019\n",
      "Epoch 3486/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 276.0290 - recon_loss: 9.7143e-04 - KL loss: 15.4252 - beta: 0.0019 - val_val_loss: 278.1014 - val_val_recon_loss: 9.8006e-04 - val_val_KL loss: 15.1820 - val_beta: 0.0019\n",
      "Epoch 3487/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 276.9858 - recon_loss: 9.7571e-04 - KL loss: 15.2336 - beta: 0.0019 - val_val_loss: 275.4843 - val_val_recon_loss: 9.7034e-04 - val_val_KL loss: 15.1711 - val_beta: 0.0019\n",
      "Epoch 3488/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 277.2073 - recon_loss: 9.7647e-04 - KL loss: 15.2508 - beta: 0.0019 - val_val_loss: 275.4694 - val_val_recon_loss: 9.7034e-04 - val_val_KL loss: 15.1578 - val_beta: 0.0019\n",
      "Epoch 3489/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 276.4178 - recon_loss: 9.7425e-04 - KL loss: 15.0556 - beta: 0.0019 - val_val_loss: 275.2845 - val_val_recon_loss: 9.7047e-04 - val_val_KL loss: 14.9366 - val_beta: 0.0019\n",
      "Epoch 3490/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 277.0936 - recon_loss: 9.7734e-04 - KL loss: 14.9022 - beta: 0.0019 - val_val_loss: 274.4264 - val_val_recon_loss: 9.6708e-04 - val_val_KL loss: 14.9887 - val_beta: 0.0019\n",
      "Epoch 3491/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 273.9903 - recon_loss: 9.6529e-04 - KL loss: 15.0317 - beta: 0.0019 - val_val_loss: 273.8430 - val_val_recon_loss: 9.6539e-04 - val_val_KL loss: 14.8581 - val_beta: 0.0019\n",
      "Epoch 3492/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 273.8635 - recon_loss: 9.6543e-04 - KL loss: 14.8673 - beta: 0.0019 - val_val_loss: 273.4226 - val_val_recon_loss: 9.6486e-04 - val_val_KL loss: 14.5792 - val_beta: 0.0019\n",
      "Epoch 3493/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 272.4270 - recon_loss: 9.6128e-04 - KL loss: 14.5439 - beta: 0.0019 - val_val_loss: 273.6830 - val_val_recon_loss: 9.6532e-04 - val_val_KL loss: 14.7160 - val_beta: 0.0019\n",
      "Epoch 3494/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 273.7967 - recon_loss: 9.6600e-04 - KL loss: 14.6481 - beta: 0.0019 - val_val_loss: 274.0755 - val_val_recon_loss: 9.6704e-04 - val_val_KL loss: 14.6468 - val_beta: 0.0019\n",
      "Epoch 3495/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 271.3061 - recon_loss: 9.5743e-04 - KL loss: 14.4556 - beta: 0.0019 - val_val_loss: 273.8907 - val_val_recon_loss: 9.6692e-04 - val_val_KL loss: 14.4957 - val_beta: 0.0019\n",
      "Epoch 3496/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 270.7386 - recon_loss: 9.5469e-04 - KL loss: 14.6247 - beta: 0.0019 - val_val_loss: 271.5711 - val_val_recon_loss: 9.5767e-04 - val_val_KL loss: 14.6568 - val_beta: 0.0019\n",
      "Epoch 3497/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 270.4015 - recon_loss: 9.5336e-04 - KL loss: 14.6438 - beta: 0.0019 - val_val_loss: 270.3541 - val_val_recon_loss: 9.5299e-04 - val_val_KL loss: 14.6967 - val_beta: 0.0019\n",
      "Epoch 3498/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 270.0610 - recon_loss: 9.5178e-04 - KL loss: 14.7284 - beta: 0.0019 - val_val_loss: 270.8148 - val_val_recon_loss: 9.5504e-04 - val_val_KL loss: 14.6069 - val_beta: 0.0019\n",
      "Epoch 3499/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 272.0606 - recon_loss: 9.5963e-04 - KL loss: 14.6210 - beta: 0.0019 - val_val_loss: 270.3254 - val_val_recon_loss: 9.5294e-04 - val_val_KL loss: 14.6813 - val_beta: 0.0019\n",
      "Epoch 3500/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 268.0955 - recon_loss: 9.4467e-04 - KL loss: 14.6686 - beta: 0.0019 - val_val_loss: 269.8042 - val_val_recon_loss: 9.5071e-04 - val_val_KL loss: 14.7573 - val_beta: 0.0019\n",
      "Epoch 3501/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 269.9587 - recon_loss: 9.5105e-04 - KL loss: 14.8197 - beta: 0.0019 - val_val_loss: 270.0655 - val_val_recon_loss: 9.5134e-04 - val_val_KL loss: 14.8493 - val_beta: 0.0019\n",
      "Epoch 3502/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266.7442 - recon_loss: 9.3894e-04 - KL loss: 14.8544 - beta: 0.0019 - val_val_loss: 268.4309 - val_val_recon_loss: 9.4606e-04 - val_val_KL loss: 14.6308 - val_beta: 0.0019\n",
      "Epoch 3503/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266.4415 - recon_loss: 9.3806e-04 - KL loss: 14.7882 - beta: 0.0019 - val_val_loss: 266.9958 - val_val_recon_loss: 9.3972e-04 - val_val_KL loss: 14.8976 - val_beta: 0.0019\n",
      "Epoch 3504/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 266.6794 - recon_loss: 9.3862e-04 - KL loss: 14.8765 - beta: 0.0019 - val_val_loss: 266.9639 - val_val_recon_loss: 9.3961e-04 - val_val_KL loss: 14.8962 - val_beta: 0.0019\n",
      "Epoch 3505/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265.2013 - recon_loss: 9.3281e-04 - KL loss: 14.9555 - beta: 0.0019 - val_val_loss: 265.8748 - val_val_recon_loss: 9.3561e-04 - val_val_KL loss: 14.8787 - val_beta: 0.0019\n",
      "Epoch 3506/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 265.8786 - recon_loss: 9.3558e-04 - KL loss: 14.8911 - beta: 0.0019 - val_val_loss: 266.3352 - val_val_recon_loss: 9.3665e-04 - val_val_KL loss: 15.0599 - val_beta: 0.0019\n",
      "Epoch 3507/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265.8415 - recon_loss: 9.3472e-04 - KL loss: 15.0839 - beta: 0.0019 - val_val_loss: 267.1937 - val_val_recon_loss: 9.3827e-04 - val_val_KL loss: 15.4847 - val_beta: 0.0019\n",
      "Epoch 3508/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265.1799 - recon_loss: 9.3134e-04 - KL loss: 15.3283 - beta: 0.0019 - val_val_loss: 265.6052 - val_val_recon_loss: 9.3221e-04 - val_val_KL loss: 15.5219 - val_beta: 0.0019\n",
      "Epoch 3509/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 265.6240 - recon_loss: 9.3245e-04 - KL loss: 15.4770 - beta: 0.0019 - val_val_loss: 268.0314 - val_val_recon_loss: 9.4026e-04 - val_val_KL loss: 15.7878 - val_beta: 0.0019\n",
      "Epoch 3510/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 266.2081 - recon_loss: 9.3346e-04 - KL loss: 15.7898 - beta: 0.0019 - val_val_loss: 263.4619 - val_val_recon_loss: 9.2498e-04 - val_val_KL loss: 15.3190 - val_beta: 0.0019\n",
      "Epoch 3511/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 259.2703 - recon_loss: 9.0910e-04 - KL loss: 15.3869 - beta: 0.0019 - val_val_loss: 261.6110 - val_val_recon_loss: 9.1756e-04 - val_val_KL loss: 15.4587 - val_beta: 0.0019\n",
      "Epoch 3512/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 259.2913 - recon_loss: 9.0896e-04 - KL loss: 15.4462 - beta: 0.0019 - val_val_loss: 260.4565 - val_val_recon_loss: 9.1310e-04 - val_val_KL loss: 15.4987 - val_beta: 0.0019\n",
      "Epoch 3513/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 259.1397 - recon_loss: 9.0796e-04 - KL loss: 15.5605 - beta: 0.0019 - val_val_loss: 259.1143 - val_val_recon_loss: 9.0792e-04 - val_val_KL loss: 15.5474 - val_beta: 0.0019\n",
      "Epoch 3514/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 259.3075 - recon_loss: 9.0873e-04 - KL loss: 15.5238 - beta: 0.0019 - val_val_loss: 260.5548 - val_val_recon_loss: 9.1140e-04 - val_val_KL loss: 16.0538 - val_beta: 0.0019\n",
      "Epoch 3515/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 261.3293 - recon_loss: 9.1480e-04 - KL loss: 15.9162 - beta: 0.0019 - val_val_loss: 259.4322 - val_val_recon_loss: 9.0812e-04 - val_val_KL loss: 15.8114 - val_beta: 0.0019\n",
      "Epoch 3516/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 258.6029 - recon_loss: 9.0425e-04 - KL loss: 16.0214 - beta: 0.0019 - val_val_loss: 257.0977 - val_val_recon_loss: 8.9764e-04 - val_val_KL loss: 16.2891 - val_beta: 0.0019\n",
      "Epoch 3517/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 253.6366 - recon_loss: 8.8512e-04 - KL loss: 16.1849 - beta: 0.0019 - val_val_loss: 258.1169 - val_val_recon_loss: 9.0214e-04 - val_val_KL loss: 16.1014 - val_beta: 0.0019\n",
      "Epoch 3518/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 256.6085 - recon_loss: 8.9600e-04 - KL loss: 16.2393 - beta: 0.0019 - val_val_loss: 255.2909 - val_val_recon_loss: 8.9210e-04 - val_val_KL loss: 15.9677 - val_beta: 0.0019\n",
      "Epoch 3519/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 253.0666 - recon_loss: 8.8381e-04 - KL loss: 15.9683 - beta: 0.0019 - val_val_loss: 255.4325 - val_val_recon_loss: 8.9148e-04 - val_val_KL loss: 16.2761 - val_beta: 0.0019\n",
      "Epoch 3520/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 253.6392 - recon_loss: 8.8576e-04 - KL loss: 16.0166 - beta: 0.0019 - val_val_loss: 253.2388 - val_val_recon_loss: 8.8453e-04 - val_val_KL loss: 15.9473 - val_beta: 0.0019\n",
      "Epoch 3521/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 252.2599 - recon_loss: 8.8116e-04 - KL loss: 15.8728 - beta: 0.0019 - val_val_loss: 253.1278 - val_val_recon_loss: 8.8350e-04 - val_val_KL loss: 16.1115 - val_beta: 0.0019\n",
      "Epoch 3522/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 251.7867 - recon_loss: 8.7933e-04 - KL loss: 15.8888 - beta: 0.0019 - val_val_loss: 252.6158 - val_val_recon_loss: 8.8260e-04 - val_val_KL loss: 15.8422 - val_beta: 0.0019\n",
      "Epoch 3523/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 249.6895 - recon_loss: 8.7068e-04 - KL loss: 16.1137 - beta: 0.0019 - val_val_loss: 249.7642 - val_val_recon_loss: 8.6920e-04 - val_val_KL loss: 16.5837 - val_beta: 0.0019\n",
      "Epoch 3524/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 248.5051 - recon_loss: 8.6458e-04 - KL loss: 16.5636 - beta: 0.0019 - val_val_loss: 249.2495 - val_val_recon_loss: 8.6777e-04 - val_val_KL loss: 16.4541 - val_beta: 0.0019\n",
      "Epoch 3525/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 247.3373 - recon_loss: 8.6088e-04 - KL loss: 16.3902 - beta: 0.0019 - val_val_loss: 248.1235 - val_val_recon_loss: 8.6319e-04 - val_val_KL loss: 16.5565 - val_beta: 0.0019\n",
      "Epoch 3526/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 246.3301 - recon_loss: 8.5672e-04 - KL loss: 16.4987 - beta: 0.0019 - val_val_loss: 247.9286 - val_val_recon_loss: 8.6304e-04 - val_val_KL loss: 16.4006 - val_beta: 0.0019\n",
      "Epoch 3527/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 244.8490 - recon_loss: 8.5155e-04 - KL loss: 16.4049 - beta: 0.0019 - val_val_loss: 246.1194 - val_val_recon_loss: 8.5515e-04 - val_val_KL loss: 16.7074 - val_beta: 0.0019\n",
      "Epoch 3528/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 244.7750 - recon_loss: 8.5002e-04 - KL loss: 16.7415 - beta: 0.0019 - val_val_loss: 247.0917 - val_val_recon_loss: 8.5773e-04 - val_val_KL loss: 16.9890 - val_beta: 0.0019\n",
      "Epoch 3529/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 245.6739 - recon_loss: 8.5224e-04 - KL loss: 17.0444 - beta: 0.0019 - val_val_loss: 244.5934 - val_val_recon_loss: 8.4724e-04 - val_val_KL loss: 17.3040 - val_beta: 0.0019\n",
      "Epoch 3530/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 245.2499 - recon_loss: 8.5005e-04 - KL loss: 17.2061 - beta: 0.0019 - val_val_loss: 244.0965 - val_val_recon_loss: 8.4578e-04 - val_val_KL loss: 17.1993 - val_beta: 0.0019\n",
      "Epoch 3531/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 241.5080 - recon_loss: 8.3614e-04 - KL loss: 17.1963 - beta: 0.0019 - val_val_loss: 241.8740 - val_val_recon_loss: 8.3646e-04 - val_val_KL loss: 17.4772 - val_beta: 0.0019\n",
      "Epoch 3532/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 236.1624 - recon_loss: 8.1555e-04 - KL loss: 17.3753 - beta: 0.0019 - val_val_loss: 240.4067 - val_val_recon_loss: 8.3181e-04 - val_val_KL loss: 17.2587 - val_beta: 0.0019\n",
      "Epoch 3533/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 239.8366 - recon_loss: 8.2947e-04 - KL loss: 17.3140 - beta: 0.0019 - val_val_loss: 240.4171 - val_val_recon_loss: 8.3090e-04 - val_val_KL loss: 17.5129 - val_beta: 0.0019\n",
      "Epoch 3534/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 240.3591 - recon_loss: 8.3098e-04 - KL loss: 17.4328 - beta: 0.0019 - val_val_loss: 241.3821 - val_val_recon_loss: 8.3491e-04 - val_val_KL loss: 17.4011 - val_beta: 0.0019\n",
      "Epoch 3535/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 239.7497 - recon_loss: 8.2903e-04 - KL loss: 17.3455 - beta: 0.0019 - val_val_loss: 238.3393 - val_val_recon_loss: 8.2330e-04 - val_val_KL loss: 17.4731 - val_beta: 0.0019\n",
      "Epoch 3536/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 235.4520 - recon_loss: 8.1257e-04 - KL loss: 17.4627 - beta: 0.0019 - val_val_loss: 235.9418 - val_val_recon_loss: 8.1363e-04 - val_val_KL loss: 17.6684 - val_beta: 0.0019\n",
      "Epoch 3537/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 235.4793 - recon_loss: 8.1129e-04 - KL loss: 17.8345 - beta: 0.0019 - val_val_loss: 237.7800 - val_val_recon_loss: 8.1703e-04 - val_val_KL loss: 18.5949 - val_beta: 0.0019\n",
      "Epoch 3538/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 235.8668 - recon_loss: 8.1062e-04 - KL loss: 18.4013 - beta: 0.0019 - val_val_loss: 235.3074 - val_val_recon_loss: 8.0942e-04 - val_val_KL loss: 18.1661 - val_beta: 0.0019\n",
      "Epoch 3539/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 234.9588 - recon_loss: 8.0752e-04 - KL loss: 18.3245 - beta: 0.0019 - val_val_loss: 233.3687 - val_val_recon_loss: 8.0064e-04 - val_val_KL loss: 18.5814 - val_beta: 0.0019\n",
      "Epoch 3540/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 233.2269 - recon_loss: 8.0042e-04 - KL loss: 18.4983 - beta: 0.0019 - val_val_loss: 231.9596 - val_val_recon_loss: 7.9672e-04 - val_val_KL loss: 18.2233 - val_beta: 0.0019\n",
      "Epoch 3541/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 228.8909 - recon_loss: 7.8523e-04 - KL loss: 18.2386 - beta: 0.0019 - val_val_loss: 230.7866 - val_val_recon_loss: 7.9304e-04 - val_val_KL loss: 18.0379 - val_beta: 0.0019\n",
      "Epoch 3542/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 230.7993 - recon_loss: 7.9172e-04 - KL loss: 18.4038 - beta: 0.0019 - val_val_loss: 231.0009 - val_val_recon_loss: 7.9296e-04 - val_val_KL loss: 18.2743 - val_beta: 0.0019\n",
      "Epoch 3543/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 231.1339 - recon_loss: 7.9263e-04 - KL loss: 18.4958 - beta: 0.0019 - val_val_loss: 230.4152 - val_val_recon_loss: 7.9010e-04 - val_val_KL loss: 18.4558 - val_beta: 0.0019\n",
      "Epoch 3544/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 226.6062 - recon_loss: 7.7610e-04 - KL loss: 18.4012 - beta: 0.0019 - val_val_loss: 227.1824 - val_val_recon_loss: 7.7768e-04 - val_val_KL loss: 18.5557 - val_beta: 0.0019\n",
      "Epoch 3545/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 227.8548 - recon_loss: 7.8000e-04 - KL loss: 18.6037 - beta: 0.0019 - val_val_loss: 228.1485 - val_val_recon_loss: 7.8115e-04 - val_val_KL loss: 18.5889 - val_beta: 0.0019\n",
      "Epoch 3546/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 229.6627 - recon_loss: 7.8646e-04 - KL loss: 18.6793 - beta: 0.0019 - val_val_loss: 231.2833 - val_val_recon_loss: 7.9244e-04 - val_val_KL loss: 18.6963 - val_beta: 0.0019\n",
      "Epoch 3547/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 227.8056 - recon_loss: 7.7955e-04 - KL loss: 18.6767 - beta: 0.0019 - val_val_loss: 228.5541 - val_val_recon_loss: 7.8121e-04 - val_val_KL loss: 18.9806 - val_beta: 0.0019\n",
      "Epoch 3548/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 225.2379 - recon_loss: 7.6879e-04 - KL loss: 18.9951 - beta: 0.0019 - val_val_loss: 226.9739 - val_val_recon_loss: 7.7599e-04 - val_val_KL loss: 18.7995 - val_beta: 0.0019\n",
      "Epoch 3549/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 224.6858 - recon_loss: 7.6771e-04 - KL loss: 18.7327 - beta: 0.0019 - val_val_loss: 225.0540 - val_val_recon_loss: 7.6908e-04 - val_val_KL loss: 18.7339 - val_beta: 0.0019\n",
      "Epoch 3550/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 222.5650 - recon_loss: 7.5958e-04 - KL loss: 18.7915 - beta: 0.0019 - val_val_loss: 224.1610 - val_val_recon_loss: 7.6526e-04 - val_val_KL loss: 18.8655 - val_beta: 0.0019\n",
      "Epoch 3551/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 221.3042 - recon_loss: 7.5492e-04 - KL loss: 18.7812 - beta: 0.0019 - val_val_loss: 223.4532 - val_val_recon_loss: 7.6425e-04 - val_val_KL loss: 18.4283 - val_beta: 0.0019\n",
      "Epoch 3552/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 219.6521 - recon_loss: 7.4922e-04 - KL loss: 18.6601 - beta: 0.0019 - val_val_loss: 219.8588 - val_val_recon_loss: 7.5010e-04 - val_val_KL loss: 18.6290 - val_beta: 0.0019\n",
      "Epoch 3553/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 218.3193 - recon_loss: 7.4328e-04 - KL loss: 18.9201 - beta: 0.0019 - val_val_loss: 219.4355 - val_val_recon_loss: 7.4771e-04 - val_val_KL loss: 18.8478 - val_beta: 0.0019\n",
      "Epoch 3554/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 216.2082 - recon_loss: 7.3564e-04 - KL loss: 18.8596 - beta: 0.0019 - val_val_loss: 218.3576 - val_val_recon_loss: 7.4400e-04 - val_val_KL loss: 18.7663 - val_beta: 0.0019\n",
      "Epoch 3555/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 218.8395 - recon_loss: 7.4495e-04 - KL loss: 18.9925 - beta: 0.0019 - val_val_loss: 217.0430 - val_val_recon_loss: 7.3778e-04 - val_val_KL loss: 19.1183 - val_beta: 0.0019\n",
      "Epoch 3556/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 216.1212 - recon_loss: 7.3431e-04 - KL loss: 19.1293 - beta: 0.0019 - val_val_loss: 217.5102 - val_val_recon_loss: 7.3955e-04 - val_val_KL loss: 19.1123 - val_beta: 0.0019\n",
      "Epoch 3557/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 215.9960 - recon_loss: 7.3417e-04 - KL loss: 19.0419 - beta: 0.0019 - val_val_loss: 215.2197 - val_val_recon_loss: 7.3196e-04 - val_val_KL loss: 18.8573 - val_beta: 0.0019\n",
      "Epoch 3558/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 215.4179 - recon_loss: 7.3188e-04 - KL loss: 19.0767 - beta: 0.0019 - val_val_loss: 214.6148 - val_val_recon_loss: 7.2868e-04 - val_val_KL loss: 19.1320 - val_beta: 0.0019\n",
      "Epoch 3559/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 212.5790 - recon_loss: 7.2108e-04 - KL loss: 19.1362 - beta: 0.0019 - val_val_loss: 213.8929 - val_val_recon_loss: 7.2636e-04 - val_val_KL loss: 19.0331 - val_beta: 0.0019\n",
      "Epoch 3560/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 212.8095 - recon_loss: 7.2170e-04 - KL loss: 19.1999 - beta: 0.0019 - val_val_loss: 212.2972 - val_val_recon_loss: 7.1996e-04 - val_val_KL loss: 19.1538 - val_beta: 0.0019\n",
      "Epoch 3561/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 212.3207 - recon_loss: 7.1982e-04 - KL loss: 19.2143 - beta: 0.0019 - val_val_loss: 212.6801 - val_val_recon_loss: 7.2031e-04 - val_val_KL loss: 19.4436 - val_beta: 0.0019\n",
      "Epoch 3562/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 211.7412 - recon_loss: 7.1703e-04 - KL loss: 19.3837 - beta: 0.0019 - val_val_loss: 213.5877 - val_val_recon_loss: 7.2328e-04 - val_val_KL loss: 19.5533 - val_beta: 0.0019\n",
      "Epoch 3563/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 210.0322 - recon_loss: 7.1010e-04 - KL loss: 19.5332 - beta: 0.0019 - val_val_loss: 209.3561 - val_val_recon_loss: 7.0770e-04 - val_val_KL loss: 19.5021 - val_beta: 0.0019\n",
      "Epoch 3564/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 209.7519 - recon_loss: 7.0896e-04 - KL loss: 19.5600 - beta: 0.0019 - val_val_loss: 210.0097 - val_val_recon_loss: 7.1099e-04 - val_val_KL loss: 19.2715 - val_beta: 0.0019\n",
      "Epoch 3565/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 207.4512 - recon_loss: 7.0071e-04 - KL loss: 19.4710 - beta: 0.0019 - val_val_loss: 208.9757 - val_val_recon_loss: 7.0607e-04 - val_val_KL loss: 19.5578 - val_beta: 0.0019\n",
      "Epoch 3566/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 207.9744 - recon_loss: 7.0227e-04 - KL loss: 19.5755 - beta: 0.0019 - val_val_loss: 207.8357 - val_val_recon_loss: 7.0244e-04 - val_val_KL loss: 19.3922 - val_beta: 0.0019\n",
      "Epoch 3567/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 206.8838 - recon_loss: 6.9849e-04 - KL loss: 19.5004 - beta: 0.0019 - val_val_loss: 208.8089 - val_val_recon_loss: 7.0623e-04 - val_val_KL loss: 19.3490 - val_beta: 0.0019\n",
      "Epoch 3568/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 208.6287 - recon_loss: 7.0414e-04 - KL loss: 19.7305 - beta: 0.0019 - val_val_loss: 208.5613 - val_val_recon_loss: 7.0364e-04 - val_val_KL loss: 19.7960 - val_beta: 0.0019\n",
      "Epoch 3569/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 203.8913 - recon_loss: 6.8638e-04 - KL loss: 19.7574 - beta: 0.0019 - val_val_loss: 206.8852 - val_val_recon_loss: 6.9670e-04 - val_val_KL loss: 19.9811 - val_beta: 0.0019\n",
      "Epoch 3570/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 207.5472 - recon_loss: 6.9953e-04 - KL loss: 19.8854 - beta: 0.0019 - val_val_loss: 204.7211 - val_val_recon_loss: 6.9035e-04 - val_val_KL loss: 19.5225 - val_beta: 0.0019\n",
      "Epoch 3571/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 203.1986 - recon_loss: 6.8390e-04 - KL loss: 19.7279 - beta: 0.0019 - val_val_loss: 204.1850 - val_val_recon_loss: 6.8781e-04 - val_val_KL loss: 19.6652 - val_beta: 0.0019\n",
      "Epoch 3572/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 204.8120 - recon_loss: 6.8985e-04 - KL loss: 19.7463 - beta: 0.0019 - val_val_loss: 203.8212 - val_val_recon_loss: 6.8552e-04 - val_val_KL loss: 19.9172 - val_beta: 0.0019\n",
      "Epoch 3573/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 204.2880 - recon_loss: 6.8681e-04 - KL loss: 20.0366 - beta: 0.0019 - val_val_loss: 204.2472 - val_val_recon_loss: 6.8697e-04 - val_val_KL loss: 19.9553 - val_beta: 0.0019\n",
      "Epoch 3574/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 203.5422 - recon_loss: 6.8405e-04 - KL loss: 20.0313 - beta: 0.0019 - val_val_loss: 202.7929 - val_val_recon_loss: 6.8175e-04 - val_val_KL loss: 19.9001 - val_beta: 0.0019\n",
      "Epoch 3575/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 204.5776 - recon_loss: 6.8773e-04 - KL loss: 20.0811 - beta: 0.0019 - val_val_loss: 204.3219 - val_val_recon_loss: 6.8635e-04 - val_val_KL loss: 20.1939 - val_beta: 0.0019\n",
      "Epoch 3576/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 204.0261 - recon_loss: 6.8498e-04 - KL loss: 20.2676 - beta: 0.0019 - val_val_loss: 202.6543 - val_val_recon_loss: 6.8108e-04 - val_val_KL loss: 19.9410 - val_beta: 0.0019\n",
      "Epoch 3577/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 203.2866 - recon_loss: 6.8278e-04 - KL loss: 20.1185 - beta: 0.0019 - val_val_loss: 202.9504 - val_val_recon_loss: 6.8099e-04 - val_val_KL loss: 20.2627 - val_beta: 0.0019\n",
      "Epoch 3578/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 203.1066 - recon_loss: 6.8148e-04 - KL loss: 20.2867 - beta: 0.0019 - val_val_loss: 201.3579 - val_val_recon_loss: 6.7598e-04 - val_val_KL loss: 20.0126 - val_beta: 0.0019\n",
      "Epoch 3579/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 198.6131 - recon_loss: 6.6542e-04 - KL loss: 20.1002 - beta: 0.0019 - val_val_loss: 200.1915 - val_val_recon_loss: 6.7183e-04 - val_val_KL loss: 19.9608 - val_beta: 0.0019\n",
      "Epoch 3580/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 199.0714 - recon_loss: 6.6664e-04 - KL loss: 20.2316 - beta: 0.0019 - val_val_loss: 199.7034 - val_val_recon_loss: 6.6958e-04 - val_val_KL loss: 20.0747 - val_beta: 0.0019\n",
      "Epoch 3581/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 199.1808 - recon_loss: 6.6742e-04 - KL loss: 20.1313 - beta: 0.0019 - val_val_loss: 199.5386 - val_val_recon_loss: 6.6927e-04 - val_val_KL loss: 19.9936 - val_beta: 0.0019\n",
      "Epoch 3582/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 198.9990 - recon_loss: 6.6650e-04 - KL loss: 20.1978 - beta: 0.0019 - val_val_loss: 200.4924 - val_val_recon_loss: 6.7265e-04 - val_val_KL loss: 20.0408 - val_beta: 0.0019\n",
      "Epoch 3583/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 201.9532 - recon_loss: 6.7774e-04 - KL loss: 20.1368 - beta: 0.0019 - val_val_loss: 199.2718 - val_val_recon_loss: 6.6555e-04 - val_val_KL loss: 20.7256 - val_beta: 0.0019\n",
      "Epoch 3584/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 195.9602 - recon_loss: 6.5391e-04 - KL loss: 20.5368 - beta: 0.0019 - val_val_loss: 198.3179 - val_val_recon_loss: 6.6380e-04 - val_val_KL loss: 20.2396 - val_beta: 0.0019\n",
      "Epoch 3585/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 197.6099 - recon_loss: 6.6045e-04 - KL loss: 20.4303 - beta: 0.0019 - val_val_loss: 196.4772 - val_val_recon_loss: 6.5694e-04 - val_val_KL loss: 20.2389 - val_beta: 0.0019\n",
      "Epoch 3586/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 195.6516 - recon_loss: 6.5313e-04 - KL loss: 20.4374 - beta: 0.0019 - val_val_loss: 198.2440 - val_val_recon_loss: 6.6471e-04 - val_val_KL loss: 19.9231 - val_beta: 0.0019\n",
      "Epoch 3587/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 198.2812 - recon_loss: 6.6358e-04 - KL loss: 20.2638 - beta: 0.0019 - val_val_loss: 195.9603 - val_val_recon_loss: 6.5556e-04 - val_val_KL loss: 20.0923 - val_beta: 0.0019\n",
      "Epoch 3588/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 198.1699 - recon_loss: 6.6335e-04 - KL loss: 20.2143 - beta: 0.0019 - val_val_loss: 195.5031 - val_val_recon_loss: 6.5456e-04 - val_val_KL loss: 19.9045 - val_beta: 0.0019\n",
      "Epoch 3589/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 195.6368 - recon_loss: 6.5345e-04 - KL loss: 20.3366 - beta: 0.0019 - val_val_loss: 194.6865 - val_val_recon_loss: 6.5023e-04 - val_val_KL loss: 20.2491 - val_beta: 0.0019\n",
      "Epoch 3590/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 193.2327 - recon_loss: 6.4416e-04 - KL loss: 20.4248 - beta: 0.0019 - val_val_loss: 194.5706 - val_val_recon_loss: 6.5010e-04 - val_val_KL loss: 20.1694 - val_beta: 0.0019\n",
      "Epoch 3591/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 193.6023 - recon_loss: 6.4595e-04 - KL loss: 20.3142 - beta: 0.0019 - val_val_loss: 197.4237 - val_val_recon_loss: 6.6164e-04 - val_val_KL loss: 19.9247 - val_beta: 0.0019\n",
      "Epoch 3592/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 193.4602 - recon_loss: 6.4585e-04 - KL loss: 20.1975 - beta: 0.0019 - val_val_loss: 194.8249 - val_val_recon_loss: 6.5115e-04 - val_val_KL loss: 20.1420 - val_beta: 0.0019\n",
      "Epoch 3593/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 195.6522 - recon_loss: 6.5384e-04 - KL loss: 20.2466 - beta: 0.0019 - val_val_loss: 194.8734 - val_val_recon_loss: 6.5096e-04 - val_val_KL loss: 20.2408 - val_beta: 0.0019\n",
      "Epoch 3594/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 194.5379 - recon_loss: 6.4885e-04 - KL loss: 20.4725 - beta: 0.0019 - val_val_loss: 193.0632 - val_val_recon_loss: 6.4336e-04 - val_val_KL loss: 20.4695 - val_beta: 0.0019\n",
      "Epoch 3595/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 192.6282 - recon_loss: 6.4220e-04 - KL loss: 20.3447 - beta: 0.0019 - val_val_loss: 191.0499 - val_val_recon_loss: 6.3596e-04 - val_val_KL loss: 20.4410 - val_beta: 0.0019\n",
      "Epoch 3596/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 190.3845 - recon_loss: 6.3358e-04 - KL loss: 20.4143 - beta: 0.0019 - val_val_loss: 191.8931 - val_val_recon_loss: 6.3998e-04 - val_val_KL loss: 20.2061 - val_beta: 0.0019\n",
      "Epoch 3597/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 189.7863 - recon_loss: 6.3130e-04 - KL loss: 20.4285 - beta: 0.0019 - val_val_loss: 191.0049 - val_val_recon_loss: 6.3563e-04 - val_val_KL loss: 20.4859 - val_beta: 0.0019\n",
      "Epoch 3598/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 192.0317 - recon_loss: 6.3880e-04 - KL loss: 20.6617 - beta: 0.0019 - val_val_loss: 189.5082 - val_val_recon_loss: 6.3007e-04 - val_val_KL loss: 20.4805 - val_beta: 0.0019\n",
      "Epoch 3599/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 190.0442 - recon_loss: 6.3185e-04 - KL loss: 20.5372 - beta: 0.0019 - val_val_loss: 188.4212 - val_val_recon_loss: 6.2588e-04 - val_val_KL loss: 20.5177 - val_beta: 0.0019\n",
      "Epoch 3600/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 188.5530 - recon_loss: 6.2599e-04 - KL loss: 20.6181 - beta: 0.0019 - val_val_loss: 188.1302 - val_val_recon_loss: 6.2433e-04 - val_val_KL loss: 20.6420 - val_beta: 0.0019\n",
      "Epoch 3601/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 188.7472 - recon_loss: 6.2706e-04 - KL loss: 20.5262 - beta: 0.0019 - val_val_loss: 188.3676 - val_val_recon_loss: 6.2622e-04 - val_val_KL loss: 20.3727 - val_beta: 0.0019\n",
      "Epoch 3602/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 186.3251 - recon_loss: 6.1780e-04 - KL loss: 20.5876 - beta: 0.0019 - val_val_loss: 189.7141 - val_val_recon_loss: 6.3132e-04 - val_val_KL loss: 20.3496 - val_beta: 0.0019\n",
      "Epoch 3603/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 188.6975 - recon_loss: 6.2682e-04 - KL loss: 20.5401 - beta: 0.0019 - val_val_loss: 187.0140 - val_val_recon_loss: 6.2083e-04 - val_val_KL loss: 20.4634 - val_beta: 0.0019\n",
      "Epoch 3604/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 188.3763 - recon_loss: 6.2538e-04 - KL loss: 20.6060 - beta: 0.0019 - val_val_loss: 190.9588 - val_val_recon_loss: 6.3506e-04 - val_val_KL loss: 20.5914 - val_beta: 0.0019\n",
      "Epoch 3605/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 192.4983 - recon_loss: 6.4113e-04 - KL loss: 20.5016 - beta: 0.0019 - val_val_loss: 191.6557 - val_val_recon_loss: 6.3827e-04 - val_val_KL loss: 20.4265 - val_beta: 0.0019\n",
      "Epoch 3606/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 189.0803 - recon_loss: 6.2861e-04 - KL loss: 20.4433 - beta: 0.0019 - val_val_loss: 186.1082 - val_val_recon_loss: 6.1768e-04 - val_val_KL loss: 20.4041 - val_beta: 0.0019\n",
      "Epoch 3607/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 184.5261 - recon_loss: 6.1160e-04 - KL loss: 20.4512 - beta: 0.0019 - val_val_loss: 184.6509 - val_val_recon_loss: 6.1201e-04 - val_val_KL loss: 20.4665 - val_beta: 0.0019\n",
      "Epoch 3608/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 184.4525 - recon_loss: 6.1063e-04 - KL loss: 20.6385 - beta: 0.0019 - val_val_loss: 185.5499 - val_val_recon_loss: 6.1450e-04 - val_val_KL loss: 20.6970 - val_beta: 0.0019\n",
      "Epoch 3609/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 184.5001 - recon_loss: 6.1000e-04 - KL loss: 20.8555 - beta: 0.0019 - val_val_loss: 183.4258 - val_val_recon_loss: 6.0593e-04 - val_val_KL loss: 20.8726 - val_beta: 0.0019\n",
      "Epoch 3610/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 182.5711 - recon_loss: 6.0212e-04 - KL loss: 21.0396 - beta: 0.0019 - val_val_loss: 185.1293 - val_val_recon_loss: 6.1275e-04 - val_val_KL loss: 20.7485 - val_beta: 0.0019\n",
      "Epoch 3611/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 183.8502 - recon_loss: 6.0780e-04 - KL loss: 20.7950 - beta: 0.0019 - val_val_loss: 186.9890 - val_val_recon_loss: 6.1981e-04 - val_val_KL loss: 20.7139 - val_beta: 0.0019\n",
      "Epoch 3612/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 185.6449 - recon_loss: 6.1393e-04 - KL loss: 20.9454 - beta: 0.0019 - val_val_loss: 184.0263 - val_val_recon_loss: 6.0773e-04 - val_val_KL loss: 20.9920 - val_beta: 0.0019\n",
      "Epoch 3613/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 184.4953 - recon_loss: 6.0921e-04 - KL loss: 21.0622 - beta: 0.0019 - val_val_loss: 192.4620 - val_val_recon_loss: 6.3903e-04 - val_val_KL loss: 21.0294 - val_beta: 0.0019\n",
      "Epoch 3614/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 189.4145 - recon_loss: 6.2829e-04 - KL loss: 20.8629 - beta: 0.0019\n",
      "Epoch 03614: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 189.4150 - recon_loss: 6.2829e-04 - KL loss: 20.8629 - beta: 0.0019 - val_val_loss: 189.0879 - val_val_recon_loss: 6.2694e-04 - val_val_KL loss: 20.8977 - val_beta: 0.0019\n",
      "Epoch 3615/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 185.8945 - recon_loss: 6.1531e-04 - KL loss: 20.8256 - beta: 0.0019 - val_val_loss: 185.8803 - val_val_recon_loss: 6.1553e-04 - val_val_KL loss: 20.7518 - val_beta: 0.0019\n",
      "Epoch 3616/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 185.4926 - recon_loss: 6.1323e-04 - KL loss: 20.9822 - beta: 0.0019 - val_val_loss: 184.7111 - val_val_recon_loss: 6.1035e-04 - val_val_KL loss: 20.9714 - val_beta: 0.0019\n",
      "Epoch 3617/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 183.4000 - recon_loss: 6.0501e-04 - KL loss: 21.0937 - beta: 0.0019 - val_val_loss: 184.1964 - val_val_recon_loss: 6.0840e-04 - val_val_KL loss: 20.9797 - val_beta: 0.0019\n",
      "Epoch 3618/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 182.6134 - recon_loss: 6.0204e-04 - KL loss: 21.1051 - beta: 0.0019 - val_val_loss: 183.5799 - val_val_recon_loss: 6.0560e-04 - val_val_KL loss: 21.1161 - val_beta: 0.0019\n",
      "Epoch 3619/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 181.9379 - recon_loss: 5.9932e-04 - KL loss: 21.1593 - beta: 0.0019\n",
      "Epoch 03619: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 181.9375 - recon_loss: 5.9932e-04 - KL loss: 21.1593 - beta: 0.0019 - val_val_loss: 184.1830 - val_val_recon_loss: 6.0780e-04 - val_val_KL loss: 21.1294 - val_beta: 0.0019\n",
      "Epoch 3619/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 480.7974 - recon_loss: 6.3409e-04 - KL loss: 24.4483 - beta: 0.0012 - val_val_loss: 454.3910 - val_val_recon_loss: 5.9395e-04 - val_val_KL loss: 26.9342 - val_beta: 0.0012\n",
      "Epoch 3620/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 454.0660 - recon_loss: 5.9312e-04 - KL loss: 27.2074 - beta: 0.0012 - val_val_loss: 439.7726 - val_val_recon_loss: 5.7274e-04 - val_val_KL loss: 27.5801 - val_beta: 0.0012\n",
      "Epoch 3621/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 451.0234 - recon_loss: 5.8835e-04 - KL loss: 27.5959 - beta: 0.0012 - val_val_loss: 455.7516 - val_val_recon_loss: 5.9421e-04 - val_val_KL loss: 28.1075 - val_beta: 0.0012\n",
      "Epoch 3622/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 450.9466 - recon_loss: 5.8806e-04 - KL loss: 27.7298 - beta: 0.0012 - val_val_loss: 437.0865 - val_val_recon_loss: 5.6839e-04 - val_val_KL loss: 28.0228 - val_beta: 0.0012\n",
      "Epoch 3623/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 433.2348 - recon_loss: 5.6235e-04 - KL loss: 28.5181 - beta: 0.0012 - val_val_loss: 440.1449 - val_val_recon_loss: 5.7334e-04 - val_val_KL loss: 27.5188 - val_beta: 0.0012\n",
      "Epoch 3624/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 436.2988 - recon_loss: 5.6667e-04 - KL loss: 28.4711 - beta: 0.0012 - val_val_loss: 452.9181 - val_val_recon_loss: 5.8999e-04 - val_val_KL loss: 28.3082 - val_beta: 0.0012\n",
      "Epoch 3625/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 444.5879 - recon_loss: 5.7791e-04 - KL loss: 28.6749 - beta: 0.0012 - val_val_loss: 423.7817 - val_val_recon_loss: 5.4897e-04 - val_val_KL loss: 28.6982 - val_beta: 0.0012\n",
      "Epoch 3626/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 420.2714 - recon_loss: 5.4345e-04 - KL loss: 29.1580 - beta: 0.0012 - val_val_loss: 410.2273 - val_val_recon_loss: 5.2973e-04 - val_val_KL loss: 28.9887 - val_beta: 0.0012\n",
      "Epoch 3627/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 414.6327 - recon_loss: 5.3541e-04 - KL loss: 29.3058 - beta: 0.0012 - val_val_loss: 405.7836 - val_val_recon_loss: 5.2268e-04 - val_val_KL loss: 29.6163 - val_beta: 0.0012\n",
      "Epoch 3628/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 405.0416 - recon_loss: 5.2208e-04 - KL loss: 29.3049 - beta: 0.0012 - val_val_loss: 410.0157 - val_val_recon_loss: 5.2906e-04 - val_val_KL loss: 29.2596 - val_beta: 0.0012\n",
      "Epoch 3629/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 407.6348 - recon_loss: 5.2521e-04 - KL loss: 29.6513 - beta: 0.0012 - val_val_loss: 388.3619 - val_val_recon_loss: 4.9946e-04 - val_val_KL loss: 28.9068 - val_beta: 0.0012\n",
      "Epoch 3630/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 391.4607 - recon_loss: 5.0370e-04 - KL loss: 28.9560 - beta: 0.0012 - val_val_loss: 396.5891 - val_val_recon_loss: 5.1138e-04 - val_val_KL loss: 28.5567 - val_beta: 0.0012\n",
      "Epoch 3631/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 392.9484 - recon_loss: 5.0558e-04 - KL loss: 29.0877 - beta: 0.0012 - val_val_loss: 386.2798 - val_val_recon_loss: 4.9656e-04 - val_val_KL loss: 28.9128 - val_beta: 0.0012\n",
      "Epoch 3632/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 391.2581 - recon_loss: 5.0327e-04 - KL loss: 29.0640 - beta: 0.0012 - val_val_loss: 387.0138 - val_val_recon_loss: 4.9705e-04 - val_val_KL loss: 29.2925 - val_beta: 0.0012\n",
      "Epoch 3633/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 378.7876 - recon_loss: 4.8625e-04 - KL loss: 28.8408 - beta: 0.0012 - val_val_loss: 370.4948 - val_val_recon_loss: 4.7480e-04 - val_val_KL loss: 28.7885 - val_beta: 0.0012\n",
      "Epoch 3634/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 389.0625 - recon_loss: 4.9985e-04 - KL loss: 29.3269 - beta: 0.0012 - val_val_loss: 393.2380 - val_val_recon_loss: 5.0603e-04 - val_val_KL loss: 29.0562 - val_beta: 0.0012\n",
      "Epoch 3635/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 389.6556 - recon_loss: 5.0078e-04 - KL loss: 29.2486 - beta: 0.0012 - val_val_loss: 373.1623 - val_val_recon_loss: 4.7944e-04 - val_val_KL loss: 28.1140 - val_beta: 0.0012\n",
      "Epoch 3636/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 380.3323 - recon_loss: 4.8874e-04 - KL loss: 28.5916 - beta: 0.0012 - val_val_loss: 474.0561 - val_val_recon_loss: 6.1697e-04 - val_val_KL loss: 30.0339 - val_beta: 0.0012\n",
      "Epoch 3637/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 413.3398 - recon_loss: 5.3402e-04 - KL loss: 29.0123 - beta: 0.0012 - val_val_loss: 369.0154 - val_val_recon_loss: 4.7340e-04 - val_val_KL loss: 28.3178 - val_beta: 0.0012\n",
      "Epoch 3638/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 365.9159 - recon_loss: 4.6910e-04 - KL loss: 28.3108 - beta: 0.0012 - val_val_loss: 358.2495 - val_val_recon_loss: 4.5854e-04 - val_val_KL loss: 28.2466 - val_beta: 0.0012\n",
      "Epoch 3639/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 360.0356 - recon_loss: 4.6093e-04 - KL loss: 28.3123 - beta: 0.0012 - val_val_loss: 363.4671 - val_val_recon_loss: 4.6678e-04 - val_val_KL loss: 27.5285 - val_beta: 0.0012\n",
      "Epoch 3640/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 357.6503 - recon_loss: 4.5813e-04 - KL loss: 27.9437 - beta: 0.0012 - val_val_loss: 353.7366 - val_val_recon_loss: 4.5253e-04 - val_val_KL loss: 28.0586 - val_beta: 0.0012\n",
      "Epoch 3641/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 358.2810 - recon_loss: 4.5847e-04 - KL loss: 28.3296 - beta: 0.0012 - val_val_loss: 354.1697 - val_val_recon_loss: 4.5297e-04 - val_val_KL loss: 28.1730 - val_beta: 0.0012\n",
      "Epoch 3642/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 352.3405 - recon_loss: 4.5048e-04 - KL loss: 28.1344 - beta: 0.0012 - val_val_loss: 352.4354 - val_val_recon_loss: 4.5082e-04 - val_val_KL loss: 27.9855 - val_beta: 0.0012\n",
      "Epoch 3643/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 352.5485 - recon_loss: 4.5091e-04 - KL loss: 28.0364 - beta: 0.0012 - val_val_loss: 362.1417 - val_val_recon_loss: 4.6479e-04 - val_val_KL loss: 27.6378 - val_beta: 0.0012\n",
      "Epoch 3644/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 359.2680 - recon_loss: 4.6073e-04 - KL loss: 27.6893 - beta: 0.0012 - val_val_loss: 357.9365 - val_val_recon_loss: 4.5933e-04 - val_val_KL loss: 27.3665 - val_beta: 0.0012\n",
      "Epoch 3645/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 349.2553 - recon_loss: 4.4709e-04 - KL loss: 27.4907 - beta: 0.0012 - val_val_loss: 349.4797 - val_val_recon_loss: 4.4741e-04 - val_val_KL loss: 27.4833 - val_beta: 0.0012\n",
      "Epoch 3646/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 350.0584 - recon_loss: 4.4792e-04 - KL loss: 27.6991 - beta: 0.0012 - val_val_loss: 343.5258 - val_val_recon_loss: 4.3888e-04 - val_val_KL loss: 27.6700 - val_beta: 0.0012\n",
      "Epoch 3647/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 348.6501 - recon_loss: 4.4565e-04 - KL loss: 27.9191 - beta: 0.0012 - val_val_loss: 369.4307 - val_val_recon_loss: 4.7426e-04 - val_val_KL loss: 28.1094 - val_beta: 0.0012\n",
      "Epoch 3648/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 359.8441 - recon_loss: 4.6085e-04 - KL loss: 28.1751 - beta: 0.0012 - val_val_loss: 362.1812 - val_val_recon_loss: 4.6410e-04 - val_val_KL loss: 28.1719 - val_beta: 0.0012\n",
      "Epoch 3649/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 355.1193 - recon_loss: 4.5455e-04 - KL loss: 27.9864 - beta: 0.0012 - val_val_loss: 353.7771 - val_val_recon_loss: 4.5213e-04 - val_val_KL loss: 28.3879 - val_beta: 0.0012\n",
      "Epoch 3650/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 369.9422 - recon_loss: 4.7392e-04 - KL loss: 28.8709 - beta: 0.0012 - val_val_loss: 343.7177 - val_val_recon_loss: 4.3870e-04 - val_val_KL loss: 27.9928 - val_beta: 0.0012\n",
      "Epoch 3651/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 339.9333 - recon_loss: 4.3373e-04 - KL loss: 27.7856 - beta: 0.0012\n",
      "Epoch 03651: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 339.9384 - recon_loss: 4.3374e-04 - KL loss: 27.7856 - beta: 0.0012 - val_val_loss: 383.1608 - val_val_recon_loss: 4.9302e-04 - val_val_KL loss: 28.3431 - val_beta: 0.0012\n",
      "Epoch 3652/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 361.8331 - recon_loss: 4.6406e-04 - KL loss: 27.8588 - beta: 0.0012 - val_val_loss: 337.2065 - val_val_recon_loss: 4.3001e-04 - val_val_KL loss: 27.7376 - val_beta: 0.0012\n",
      "Epoch 3653/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 337.2111 - recon_loss: 4.3003e-04 - KL loss: 27.7260 - beta: 0.0012 - val_val_loss: 332.1464 - val_val_recon_loss: 4.2313e-04 - val_val_KL loss: 27.6227 - val_beta: 0.0012\n",
      "Epoch 3654/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 331.8858 - recon_loss: 4.2262e-04 - KL loss: 27.7293 - beta: 0.0012 - val_val_loss: 332.8234 - val_val_recon_loss: 4.2484e-04 - val_val_KL loss: 27.0724 - val_beta: 0.0012\n",
      "Epoch 3655/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 330.2342 - recon_loss: 4.2096e-04 - KL loss: 27.2726 - beta: 0.0012 - val_val_loss: 334.0750 - val_val_recon_loss: 4.2606e-04 - val_val_KL loss: 27.4460 - val_beta: 0.0012\n",
      "Epoch 3656/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 331.2367 - recon_loss: 4.2226e-04 - KL loss: 27.3417 - beta: 0.0012 - val_val_loss: 329.7284 - val_val_recon_loss: 4.2063e-04 - val_val_KL loss: 27.0071 - val_beta: 0.0012\n",
      "Epoch 3657/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 326.3361 - recon_loss: 4.1574e-04 - KL loss: 27.1332 - beta: 0.0012 - val_val_loss: 335.7654 - val_val_recon_loss: 4.2841e-04 - val_val_KL loss: 27.4427 - val_beta: 0.0012\n",
      "Epoch 3658/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 331.1308 - recon_loss: 4.2214e-04 - KL loss: 27.3260 - beta: 0.0012 - val_val_loss: 324.0004 - val_val_recon_loss: 4.1225e-04 - val_val_KL loss: 27.3112 - val_beta: 0.0012\n",
      "Epoch 3659/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 323.6914 - recon_loss: 4.1170e-04 - KL loss: 27.3967 - beta: 0.0012 - val_val_loss: 321.9484 - val_val_recon_loss: 4.0934e-04 - val_val_KL loss: 27.3503 - val_beta: 0.0012\n",
      "Epoch 3660/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 320.4594 - recon_loss: 4.0730e-04 - KL loss: 27.3300 - beta: 0.0012 - val_val_loss: 321.7909 - val_val_recon_loss: 4.0923e-04 - val_val_KL loss: 27.2770 - val_beta: 0.0012\n",
      "Epoch 3661/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 320.2053 - recon_loss: 4.0683e-04 - KL loss: 27.4159 - beta: 0.0012 - val_val_loss: 321.9643 - val_val_recon_loss: 4.0946e-04 - val_val_KL loss: 27.2848 - val_beta: 0.0012\n",
      "Epoch 3662/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 322.2395 - recon_loss: 4.0965e-04 - KL loss: 27.4189 - beta: 0.0012 - val_val_loss: 319.4113 - val_val_recon_loss: 4.0584e-04 - val_val_KL loss: 27.3348 - val_beta: 0.0012\n",
      "Epoch 3663/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 317.4287 - recon_loss: 4.0317e-04 - KL loss: 27.2733 - beta: 0.0012 - val_val_loss: 319.6057 - val_val_recon_loss: 4.0651e-04 - val_val_KL loss: 27.0443 - val_beta: 0.0012\n",
      "Epoch 3664/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 321.3925 - recon_loss: 4.0885e-04 - KL loss: 27.1456 - beta: 0.0012 - val_val_loss: 319.1735 - val_val_recon_loss: 4.0573e-04 - val_val_KL loss: 27.1724 - val_beta: 0.0012\n",
      "Epoch 3665/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 314.9231 - recon_loss: 3.9988e-04 - KL loss: 27.1316 - beta: 0.0012 - val_val_loss: 318.2271 - val_val_recon_loss: 4.0463e-04 - val_val_KL loss: 27.0217 - val_beta: 0.0012\n",
      "Epoch 3666/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 316.6202 - recon_loss: 4.0214e-04 - KL loss: 27.2089 - beta: 0.0012 - val_val_loss: 316.6226 - val_val_recon_loss: 4.0201e-04 - val_val_KL loss: 27.3042 - val_beta: 0.0012\n",
      "Epoch 3667/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 310.6397 - recon_loss: 3.9378e-04 - KL loss: 27.2418 - beta: 0.0012 - val_val_loss: 315.9978 - val_val_recon_loss: 4.0116e-04 - val_val_KL loss: 27.2917 - val_beta: 0.0012\n",
      "Epoch 3668/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 320.5425 - recon_loss: 4.0738e-04 - KL loss: 27.3552 - beta: 0.0012 - val_val_loss: 314.9402 - val_val_recon_loss: 3.9965e-04 - val_val_KL loss: 27.3162 - val_beta: 0.0012\n",
      "Epoch 3669/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 315.3764 - recon_loss: 4.0027e-04 - KL loss: 27.3050 - beta: 0.0012 - val_val_loss: 315.5038 - val_val_recon_loss: 4.0055e-04 - val_val_KL loss: 27.2315 - val_beta: 0.0012\n",
      "Epoch 3670/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 317.3110 - recon_loss: 4.0314e-04 - KL loss: 27.1762 - beta: 0.0012 - val_val_loss: 318.7054 - val_val_recon_loss: 4.0542e-04 - val_val_KL loss: 26.9315 - val_beta: 0.0012\n",
      "Epoch 3671/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 316.7515 - recon_loss: 4.0253e-04 - KL loss: 27.0573 - beta: 0.0012 - val_val_loss: 315.0099 - val_val_recon_loss: 4.0005e-04 - val_val_KL loss: 27.1017 - val_beta: 0.0012\n",
      "Epoch 3672/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 313.1299 - recon_loss: 3.9743e-04 - KL loss: 27.1052 - beta: 0.0012 - val_val_loss: 316.5587 - val_val_recon_loss: 4.0249e-04 - val_val_KL loss: 26.8959 - val_beta: 0.0012\n",
      "Epoch 3673/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 314.0495 - recon_loss: 3.9881e-04 - KL loss: 27.0291 - beta: 0.0012\n",
      "Epoch 03673: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 314.0487 - recon_loss: 3.9881e-04 - KL loss: 27.0291 - beta: 0.0012 - val_val_loss: 315.7579 - val_val_recon_loss: 4.0083e-04 - val_val_KL loss: 27.2870 - val_beta: 0.0012\n",
      "Epoch 3674/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 307.0416 - recon_loss: 3.8897e-04 - KL loss: 27.1031 - beta: 0.0012 - val_val_loss: 311.2898 - val_val_recon_loss: 3.9494e-04 - val_val_KL loss: 27.0568 - val_beta: 0.0012\n",
      "Epoch 3675/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 311.4028 - recon_loss: 3.9507e-04 - KL loss: 27.0796 - beta: 0.0012 - val_val_loss: 313.2206 - val_val_recon_loss: 3.9746e-04 - val_val_KL loss: 27.1743 - val_beta: 0.0012\n",
      "Epoch 3676/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 309.8520 - recon_loss: 3.9286e-04 - KL loss: 27.1172 - beta: 0.0012 - val_val_loss: 313.6280 - val_val_recon_loss: 3.9824e-04 - val_val_KL loss: 27.0208 - val_beta: 0.0012\n",
      "Epoch 3677/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 310.8904 - recon_loss: 3.9441e-04 - KL loss: 27.0402 - beta: 0.0012 - val_val_loss: 313.8107 - val_val_recon_loss: 3.9830e-04 - val_val_KL loss: 27.1581 - val_beta: 0.0012\n",
      "Epoch 3678/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 312.9917 - recon_loss: 3.9707e-04 - KL loss: 27.2255 - beta: 0.0012 - val_val_loss: 313.4954 - val_val_recon_loss: 3.9796e-04 - val_val_KL loss: 27.0882 - val_beta: 0.0012\n",
      "Epoch 3679/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 305.4920 - recon_loss: 3.8689e-04 - KL loss: 27.0545 - beta: 0.0012\n",
      "Epoch 03679: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.4926 - recon_loss: 3.8689e-04 - KL loss: 27.0545 - beta: 0.0012 - val_val_loss: 313.2631 - val_val_recon_loss: 3.9762e-04 - val_val_KL loss: 27.1044 - val_beta: 0.0012\n",
      "Epoch 3680/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.6712 - recon_loss: 3.9114e-04 - KL loss: 27.1740 - beta: 0.0012 - val_val_loss: 313.3683 - val_val_recon_loss: 3.9776e-04 - val_val_KL loss: 27.1033 - val_beta: 0.0012\n",
      "Epoch 3681/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 309.4685 - recon_loss: 3.9235e-04 - KL loss: 27.1024 - beta: 0.0012 - val_val_loss: 312.1892 - val_val_recon_loss: 3.9604e-04 - val_val_KL loss: 27.1664 - val_beta: 0.0012\n",
      "Epoch 3682/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 312.9110 - recon_loss: 3.9701e-04 - KL loss: 27.1916 - beta: 0.0012 - val_val_loss: 311.9126 - val_val_recon_loss: 3.9565e-04 - val_val_KL loss: 27.1708 - val_beta: 0.0012\n",
      "Epoch 3683/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.6414 - recon_loss: 3.9114e-04 - KL loss: 27.1412 - beta: 0.0012 - val_val_loss: 311.4148 - val_val_recon_loss: 3.9500e-04 - val_val_KL loss: 27.1387 - val_beta: 0.0012\n",
      "Epoch 3684/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.3931 - recon_loss: 3.9078e-04 - KL loss: 27.1564 - beta: 0.0012 - val_val_loss: 310.9689 - val_val_recon_loss: 3.9432e-04 - val_val_KL loss: 27.1820 - val_beta: 0.0012\n",
      "Epoch 3685/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 311.4179 - recon_loss: 3.9495e-04 - KL loss: 27.1765 - beta: 0.0012 - val_val_loss: 311.6553 - val_val_recon_loss: 3.9526e-04 - val_val_KL loss: 27.1953 - val_beta: 0.0012\n",
      "Epoch 3686/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 310.0728 - recon_loss: 3.9305e-04 - KL loss: 27.2022 - beta: 0.0012 - val_val_loss: 311.4607 - val_val_recon_loss: 3.9497e-04 - val_val_KL loss: 27.2067 - val_beta: 0.0012\n",
      "Epoch 3687/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.7716 - recon_loss: 3.8710e-04 - KL loss: 27.1841 - beta: 0.0012 - val_val_loss: 311.1211 - val_val_recon_loss: 3.9452e-04 - val_val_KL loss: 27.1939 - val_beta: 0.0012\n",
      "Epoch 3688/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.3714 - recon_loss: 3.9073e-04 - KL loss: 27.1651 - beta: 0.0012 - val_val_loss: 311.8962 - val_val_recon_loss: 3.9563e-04 - val_val_KL loss: 27.1668 - val_beta: 0.0012\n",
      "Epoch 3689/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 306.5574 - recon_loss: 3.8820e-04 - KL loss: 27.1759 - beta: 0.0012\n",
      "Epoch 03689: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.5575 - recon_loss: 3.8820e-04 - KL loss: 27.1759 - beta: 0.0012 - val_val_loss: 311.0369 - val_val_recon_loss: 3.9438e-04 - val_val_KL loss: 27.2057 - val_beta: 0.0012\n",
      "Epoch 3690/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 311.8361 - recon_loss: 3.9545e-04 - KL loss: 27.2358 - beta: 0.0012 - val_val_loss: 311.1736 - val_val_recon_loss: 3.9458e-04 - val_val_KL loss: 27.2004 - val_beta: 0.0012\n",
      "Epoch 3691/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.8969 - recon_loss: 3.9142e-04 - KL loss: 27.1963 - beta: 0.0012 - val_val_loss: 311.5076 - val_val_recon_loss: 3.9502e-04 - val_val_KL loss: 27.2171 - val_beta: 0.0012\n",
      "Epoch 3692/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 307.5233 - recon_loss: 3.8950e-04 - KL loss: 27.2066 - beta: 0.0012 - val_val_loss: 311.5873 - val_val_recon_loss: 3.9516e-04 - val_val_KL loss: 27.1930 - val_beta: 0.0012\n",
      "Epoch 3693/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 304.7164 - recon_loss: 3.8576e-04 - KL loss: 27.0925 - beta: 0.0012 - val_val_loss: 310.8820 - val_val_recon_loss: 3.9418e-04 - val_val_KL loss: 27.1996 - val_beta: 0.0012\n",
      "Epoch 3694/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 307.6879 - recon_loss: 3.8969e-04 - KL loss: 27.2309 - beta: 0.0012 - val_val_loss: 310.9481 - val_val_recon_loss: 3.9426e-04 - val_val_KL loss: 27.2074 - val_beta: 0.0012\n",
      "Epoch 3695/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 308.6688 - recon_loss: 3.9114e-04 - KL loss: 27.1718 - beta: 0.0012 - val_val_loss: 311.2772 - val_val_recon_loss: 3.9473e-04 - val_val_KL loss: 27.1938 - val_beta: 0.0012\n",
      "Epoch 3696/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.6881 - recon_loss: 3.8841e-04 - KL loss: 27.1534 - beta: 0.0012 - val_val_loss: 310.6691 - val_val_recon_loss: 3.9382e-04 - val_val_KL loss: 27.2399 - val_beta: 0.0012\n",
      "Epoch 3697/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.1582 - recon_loss: 3.8763e-04 - KL loss: 27.1890 - beta: 0.0012 - val_val_loss: 311.0175 - val_val_recon_loss: 3.9437e-04 - val_val_KL loss: 27.1941 - val_beta: 0.0012\n",
      "Epoch 3698/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 303.1933 - recon_loss: 3.8354e-04 - KL loss: 27.1617 - beta: 0.0012 - val_val_loss: 311.2554 - val_val_recon_loss: 3.9466e-04 - val_val_KL loss: 27.2206 - val_beta: 0.0012\n",
      "Epoch 3699/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.1233 - recon_loss: 3.8760e-04 - KL loss: 27.1764 - beta: 0.0012 - val_val_loss: 311.0306 - val_val_recon_loss: 3.9438e-04 - val_val_KL loss: 27.2019 - val_beta: 0.0012\n",
      "Epoch 3700/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.9239 - recon_loss: 3.8729e-04 - KL loss: 27.1947 - beta: 0.0012 - val_val_loss: 310.5955 - val_val_recon_loss: 3.9375e-04 - val_val_KL loss: 27.2170 - val_beta: 0.0012\n",
      "Epoch 3701/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 309.7240 - recon_loss: 3.9251e-04 - KL loss: 27.2384 - beta: 0.0012 - val_val_loss: 311.5630 - val_val_recon_loss: 3.9507e-04 - val_val_KL loss: 27.2349 - val_beta: 0.0012\n",
      "Epoch 3702/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.3752 - recon_loss: 3.9065e-04 - KL loss: 27.2322 - beta: 0.0012 - val_val_loss: 311.1992 - val_val_recon_loss: 3.9454e-04 - val_val_KL loss: 27.2511 - val_beta: 0.0012\n",
      "Epoch 3703/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 307.9187 - recon_loss: 3.9007e-04 - KL loss: 27.1935 - beta: 0.0012 - val_val_loss: 311.2375 - val_val_recon_loss: 3.9463e-04 - val_val_KL loss: 27.2244 - val_beta: 0.0012\n",
      "Epoch 3704/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.6280 - recon_loss: 3.8683e-04 - KL loss: 27.2349 - beta: 0.0012 - val_val_loss: 311.2039 - val_val_recon_loss: 3.9456e-04 - val_val_KL loss: 27.2469 - val_beta: 0.0012\n",
      "Epoch 3705/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 306.1003 - recon_loss: 3.8750e-04 - KL loss: 27.2227 - beta: 0.0012\n",
      "Epoch 03705: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.1011 - recon_loss: 3.8750e-04 - KL loss: 27.2227 - beta: 0.0012 - val_val_loss: 310.8796 - val_val_recon_loss: 3.9415e-04 - val_val_KL loss: 27.2182 - val_beta: 0.0012\n",
      "Epoch 3706/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.2428 - recon_loss: 3.9055e-04 - KL loss: 27.1681 - beta: 0.0012 - val_val_loss: 310.9733 - val_val_recon_loss: 3.9429e-04 - val_val_KL loss: 27.2106 - val_beta: 0.0012\n",
      "Epoch 3707/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.8712 - recon_loss: 3.8863e-04 - KL loss: 27.1775 - beta: 0.0012 - val_val_loss: 311.4512 - val_val_recon_loss: 3.9495e-04 - val_val_KL loss: 27.2100 - val_beta: 0.0012\n",
      "Epoch 3708/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.9951 - recon_loss: 3.8731e-04 - KL loss: 27.2536 - beta: 0.0012 - val_val_loss: 310.5055 - val_val_recon_loss: 3.9364e-04 - val_val_KL loss: 27.2064 - val_beta: 0.0012\n",
      "Epoch 3709/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.1813 - recon_loss: 3.8630e-04 - KL loss: 27.1639 - beta: 0.0012 - val_val_loss: 310.6494 - val_val_recon_loss: 3.9383e-04 - val_val_KL loss: 27.2131 - val_beta: 0.0012\n",
      "Epoch 3710/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.9554 - recon_loss: 3.8736e-04 - KL loss: 27.1778 - beta: 0.0012 - val_val_loss: 310.6654 - val_val_recon_loss: 3.9384e-04 - val_val_KL loss: 27.2279 - val_beta: 0.0012\n",
      "Epoch 3711/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.7204 - recon_loss: 3.8696e-04 - KL loss: 27.2318 - beta: 0.0012 - val_val_loss: 310.8090 - val_val_recon_loss: 3.9404e-04 - val_val_KL loss: 27.2237 - val_beta: 0.0012\n",
      "Epoch 3712/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.6665 - recon_loss: 3.8699e-04 - KL loss: 27.1548 - beta: 0.0012 - val_val_loss: 311.0736 - val_val_recon_loss: 3.9443e-04 - val_val_KL loss: 27.2092 - val_beta: 0.0012\n",
      "Epoch 3713/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 307.9612 - recon_loss: 3.9005e-04 - KL loss: 27.2475 - beta: 0.0012\n",
      "Epoch 03713: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 307.9600 - recon_loss: 3.9005e-04 - KL loss: 27.2475 - beta: 0.0012 - val_val_loss: 310.8926 - val_val_recon_loss: 3.9417e-04 - val_val_KL loss: 27.2135 - val_beta: 0.0012\n",
      "Epoch 3714/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 307.0184 - recon_loss: 3.8881e-04 - KL loss: 27.1952 - beta: 0.0012 - val_val_loss: 310.8022 - val_val_recon_loss: 3.9405e-04 - val_val_KL loss: 27.2112 - val_beta: 0.0012\n",
      "Epoch 3715/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.5533 - recon_loss: 3.8815e-04 - KL loss: 27.2047 - beta: 0.0012 - val_val_loss: 310.7710 - val_val_recon_loss: 3.9401e-04 - val_val_KL loss: 27.2105 - val_beta: 0.0012\n",
      "Epoch 3716/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.8748 - recon_loss: 3.8727e-04 - KL loss: 27.1634 - beta: 0.0012 - val_val_loss: 310.5399 - val_val_recon_loss: 3.9368e-04 - val_val_KL loss: 27.2117 - val_beta: 0.0012\n",
      "Epoch 3717/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.5248 - recon_loss: 3.8808e-04 - KL loss: 27.2285 - beta: 0.0012 - val_val_loss: 310.5396 - val_val_recon_loss: 3.9368e-04 - val_val_KL loss: 27.2142 - val_beta: 0.0012\n",
      "Epoch 3718/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 307.3927 - recon_loss: 3.8933e-04 - KL loss: 27.1948 - beta: 0.0012\n",
      "Epoch 03718: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 307.3929 - recon_loss: 3.8933e-04 - KL loss: 27.1948 - beta: 0.0012 - val_val_loss: 310.9605 - val_val_recon_loss: 3.9427e-04 - val_val_KL loss: 27.2107 - val_beta: 0.0012\n",
      "Epoch 3718/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 868.1012 - recon_loss: 4.3386e-04 - KL loss: 30.4398 - beta: 7.1969e-04 - val_val_loss: 864.9519 - val_val_recon_loss: 4.3199e-04 - val_val_KL loss: 30.9080 - val_beta: 7.1969e-04\n",
      "Epoch 3719/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 887.6436 - recon_loss: 4.4311e-04 - KL loss: 32.1409 - beta: 7.1969e-04 - val_val_loss: 831.4099 - val_val_recon_loss: 4.1403e-04 - val_val_KL loss: 32.0480 - val_beta: 7.1969e-04\n",
      "Epoch 3720/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 834.5264 - recon_loss: 4.1557e-04 - KL loss: 32.1866 - beta: 7.1969e-04 - val_val_loss: 887.8501 - val_val_recon_loss: 4.4267e-04 - val_val_KL loss: 33.1790 - val_beta: 7.1969e-04\n",
      "Epoch 3721/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 874.0301 - recon_loss: 4.3580e-04 - KL loss: 32.6258 - beta: 7.1969e-04 - val_val_loss: 885.2258 - val_val_recon_loss: 4.4151e-04 - val_val_KL loss: 32.8098 - val_beta: 7.1969e-04\n",
      "Epoch 3722/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 862.8944 - recon_loss: 4.3016e-04 - KL loss: 32.3912 - beta: 7.1969e-04 - val_val_loss: 867.3298 - val_val_recon_loss: 4.3228e-04 - val_val_KL loss: 32.7311 - val_beta: 7.1969e-04\n",
      "Epoch 3723/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 913.2093 - recon_loss: 4.5557e-04 - KL loss: 33.6433 - beta: 7.1969e-04 - val_val_loss: 869.5153 - val_val_recon_loss: 4.3338e-04 - val_val_KL loss: 32.7869 - val_beta: 7.1969e-04\n",
      "Epoch 3724/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 841.6465 - recon_loss: 4.1893e-04 - KL loss: 32.8182 - beta: 7.1969e-04 - val_val_loss: 829.8849 - val_val_recon_loss: 4.1338e-04 - val_val_KL loss: 31.7718 - val_beta: 7.1969e-04\n",
      "Epoch 3725/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 821.7475 - recon_loss: 4.0878e-04 - KL loss: 32.5176 - beta: 7.1969e-04 - val_val_loss: 887.5670 - val_val_recon_loss: 4.4260e-04 - val_val_KL loss: 33.0333 - val_beta: 7.1969e-04\n",
      "Epoch 3726/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 883.0881 - recon_loss: 4.4008e-04 - KL loss: 33.4178 - beta: 7.1969e-04 - val_val_loss: 857.1797 - val_val_recon_loss: 4.2682e-04 - val_val_KL loss: 33.1176 - val_beta: 7.1969e-04\n",
      "Epoch 3727/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 854.0324 - recon_loss: 4.2512e-04 - KL loss: 33.2447 - beta: 7.1969e-04 - val_val_loss: 849.4355 - val_val_recon_loss: 4.2262e-04 - val_val_KL loss: 33.4810 - val_beta: 7.1969e-04\n",
      "Epoch 3728/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 839.4712 - recon_loss: 4.1771e-04 - KL loss: 32.9983 - beta: 7.1969e-04 - val_val_loss: 842.7960 - val_val_recon_loss: 4.1993e-04 - val_val_KL loss: 32.0468 - val_beta: 7.1969e-04\n",
      "Epoch 3729/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 826.4788 - recon_loss: 4.1093e-04 - KL loss: 33.0896 - beta: 7.1969e-04 - val_val_loss: 818.9263 - val_val_recon_loss: 4.0713e-04 - val_val_KL loss: 32.8787 - val_beta: 7.1969e-04\n",
      "Epoch 3730/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 798.3005 - recon_loss: 3.9657e-04 - KL loss: 32.6494 - beta: 7.1969e-04 - val_val_loss: 812.1474 - val_val_recon_loss: 4.0398e-04 - val_val_KL loss: 32.1870 - val_beta: 7.1969e-04\n",
      "Epoch 3731/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 814.6006 - recon_loss: 4.0509e-04 - KL loss: 32.4934 - beta: 7.1969e-04 - val_val_loss: 838.2397 - val_val_recon_loss: 4.1737e-04 - val_val_KL loss: 32.4338 - val_beta: 7.1969e-04\n",
      "Epoch 3732/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 812.9598 - recon_loss: 4.0427e-04 - KL loss: 32.4397 - beta: 7.1969e-04 - val_val_loss: 799.1629 - val_val_recon_loss: 3.9715e-04 - val_val_KL loss: 32.3860 - val_beta: 7.1969e-04\n",
      "Epoch 3733/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 806.1807 - recon_loss: 4.0066e-04 - KL loss: 32.6225 - beta: 7.1969e-04 - val_val_loss: 790.9919 - val_val_recon_loss: 3.9281e-04 - val_val_KL loss: 32.6004 - val_beta: 7.1969e-04\n",
      "Epoch 3734/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 790.7383 - recon_loss: 3.9262e-04 - KL loss: 32.7057 - beta: 7.1969e-04 - val_val_loss: 825.6520 - val_val_recon_loss: 4.1044e-04 - val_val_KL loss: 33.2262 - val_beta: 7.1969e-04\n",
      "Epoch 3735/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 813.5735 - recon_loss: 4.0418e-04 - KL loss: 33.2179 - beta: 7.1969e-04 - val_val_loss: 798.0532 - val_val_recon_loss: 3.9638e-04 - val_val_KL loss: 32.7637 - val_beta: 7.1969e-04\n",
      "Epoch 3736/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 815.4722 - recon_loss: 4.0530e-04 - KL loss: 32.9596 - beta: 7.1969e-04 - val_val_loss: 809.3430 - val_val_recon_loss: 4.0204e-04 - val_val_KL loss: 33.1228 - val_beta: 7.1969e-04\n",
      "Epoch 3737/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 788.9202 - recon_loss: 3.9162e-04 - KL loss: 32.8283 - beta: 7.1969e-04 - val_val_loss: 804.2258 - val_val_recon_loss: 3.9998e-04 - val_val_KL loss: 31.9878 - val_beta: 7.1969e-04\n",
      "Epoch 3738/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 790.3975 - recon_loss: 3.9260e-04 - KL loss: 32.4152 - beta: 7.1969e-04 - val_val_loss: 790.7656 - val_val_recon_loss: 3.9294e-04 - val_val_KL loss: 32.1157 - val_beta: 7.1969e-04\n",
      "Epoch 3739/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 785.6901 - recon_loss: 3.9017e-04 - KL loss: 32.3809 - beta: 7.1969e-04 - val_val_loss: 874.4512 - val_val_recon_loss: 4.3560e-04 - val_val_KL loss: 33.4319 - val_beta: 7.1969e-04\n",
      "Epoch 3740/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 821.4035 - recon_loss: 4.0832e-04 - KL loss: 33.0606 - beta: 7.1969e-04 - val_val_loss: 789.0617 - val_val_recon_loss: 3.9201e-04 - val_val_KL loss: 32.2162 - val_beta: 7.1969e-04\n",
      "Epoch 3741/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 794.2814 - recon_loss: 3.9444e-04 - KL loss: 32.7294 - beta: 7.1969e-04 - val_val_loss: 804.7687 - val_val_recon_loss: 4.0007e-04 - val_val_KL loss: 32.3561 - val_beta: 7.1969e-04\n",
      "Epoch 3742/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 825.0197 - recon_loss: 4.1040e-04 - KL loss: 32.6676 - beta: 7.1969e-04 - val_val_loss: 793.0643 - val_val_recon_loss: 3.9374e-04 - val_val_KL loss: 32.8714 - val_beta: 7.1969e-04\n",
      "Epoch 3743/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 805.1108 - recon_loss: 3.9995e-04 - KL loss: 32.9226 - beta: 7.1969e-04 - val_val_loss: 792.9857 - val_val_recon_loss: 3.9406e-04 - val_val_KL loss: 32.1819 - val_beta: 7.1969e-04\n",
      "Epoch 3744/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 812.7198 - recon_loss: 4.0386e-04 - KL loss: 32.9956 - beta: 7.1969e-04 - val_val_loss: 779.7332 - val_val_recon_loss: 3.8691e-04 - val_val_KL loss: 32.7311 - val_beta: 7.1969e-04\n",
      "Epoch 3745/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 772.6064 - recon_loss: 3.8324e-04 - KL loss: 32.6816 - beta: 7.1969e-04 - val_val_loss: 786.2261 - val_val_recon_loss: 3.9022e-04 - val_val_KL loss: 32.8232 - val_beta: 7.1969e-04\n",
      "Epoch 3746/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 787.8721 - recon_loss: 3.9102e-04 - KL loss: 32.9209 - beta: 7.1969e-04 - val_val_loss: 834.8402 - val_val_recon_loss: 4.1590e-04 - val_val_KL loss: 31.8602 - val_beta: 7.1969e-04\n",
      "Epoch 3747/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 799.7434 - recon_loss: 3.9733e-04 - KL loss: 32.6182 - beta: 7.1969e-04 - val_val_loss: 833.3265 - val_val_recon_loss: 4.1433e-04 - val_val_KL loss: 33.3896 - val_beta: 7.1969e-04\n",
      "Epoch 3748/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 787.5970 - recon_loss: 3.9088e-04 - KL loss: 32.9332 - beta: 7.1969e-04 - val_val_loss: 786.3754 - val_val_recon_loss: 3.9043e-04 - val_val_KL loss: 32.5689 - val_beta: 7.1969e-04\n",
      "Epoch 3749/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 790.0178 - recon_loss: 3.9221e-04 - KL loss: 32.7815 - beta: 7.1969e-04\n",
      "Epoch 03749: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 790.0247 - recon_loss: 3.9221e-04 - KL loss: 32.7817 - beta: 7.1969e-04 - val_val_loss: 796.1434 - val_val_recon_loss: 3.9551e-04 - val_val_KL loss: 32.5245 - val_beta: 7.1969e-04\n",
      "Epoch 3750/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 767.8164 - recon_loss: 3.8073e-04 - KL loss: 32.7394 - beta: 7.1969e-04 - val_val_loss: 763.1516 - val_val_recon_loss: 3.7837e-04 - val_val_KL loss: 32.6408 - val_beta: 7.1969e-04\n",
      "Epoch 3751/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 747.8816 - recon_loss: 3.7040e-04 - KL loss: 32.7528 - beta: 7.1969e-04 - val_val_loss: 765.8412 - val_val_recon_loss: 3.7961e-04 - val_val_KL loss: 32.9333 - val_beta: 7.1969e-04\n",
      "Epoch 3752/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 766.4173 - recon_loss: 3.7981e-04 - KL loss: 33.1176 - beta: 7.1969e-04 - val_val_loss: 777.3973 - val_val_recon_loss: 3.8543e-04 - val_val_KL loss: 33.2486 - val_beta: 7.1969e-04\n",
      "Epoch 3753/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 756.8336 - recon_loss: 3.7491e-04 - KL loss: 33.0040 - beta: 7.1969e-04 - val_val_loss: 772.5164 - val_val_recon_loss: 3.8287e-04 - val_val_KL loss: 33.3131 - val_beta: 7.1969e-04\n",
      "Epoch 3754/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 765.3477 - recon_loss: 3.7911e-04 - KL loss: 33.3989 - beta: 7.1969e-04 - val_val_loss: 765.2363 - val_val_recon_loss: 3.7911e-04 - val_val_KL loss: 33.2950 - val_beta: 7.1969e-04\n",
      "Epoch 3755/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 745.6399 - recon_loss: 3.6900e-04 - KL loss: 33.2148 - beta: 7.1969e-04 - val_val_loss: 760.3499 - val_val_recon_loss: 3.7676e-04 - val_val_KL loss: 32.9457 - val_beta: 7.1969e-04\n",
      "Epoch 3756/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 751.2555 - recon_loss: 3.7187e-04 - KL loss: 33.2871 - beta: 7.1969e-04 - val_val_loss: 762.8419 - val_val_recon_loss: 3.7782e-04 - val_val_KL loss: 33.3849 - val_beta: 7.1969e-04\n",
      "Epoch 3757/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 754.1528 - recon_loss: 3.7336e-04 - KL loss: 33.3004 - beta: 7.1969e-04 - val_val_loss: 761.3471 - val_val_recon_loss: 3.7709e-04 - val_val_KL loss: 33.2917 - val_beta: 7.1969e-04\n",
      "Epoch 3758/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 751.3188 - recon_loss: 3.7187e-04 - KL loss: 33.3545 - beta: 7.1969e-04 - val_val_loss: 764.4962 - val_val_recon_loss: 3.7867e-04 - val_val_KL loss: 33.3920 - val_beta: 7.1969e-04\n",
      "Epoch 3759/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 746.2085 - recon_loss: 3.6924e-04 - KL loss: 33.3134 - beta: 7.1969e-04 - val_val_loss: 765.0483 - val_val_recon_loss: 3.7916e-04 - val_val_KL loss: 32.9962 - val_beta: 7.1969e-04\n",
      "Epoch 3760/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 740.9059 - recon_loss: 3.6668e-04 - KL loss: 32.9604 - beta: 7.1969e-04 - val_val_loss: 747.9709 - val_val_recon_loss: 3.7030e-04 - val_val_KL loss: 33.0238 - val_beta: 7.1969e-04\n",
      "Epoch 3761/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 738.8968 - recon_loss: 3.6562e-04 - KL loss: 32.9950 - beta: 7.1969e-04 - val_val_loss: 747.5349 - val_val_recon_loss: 3.7023e-04 - val_val_KL loss: 32.7347 - val_beta: 7.1969e-04\n",
      "Epoch 3762/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 738.2625 - recon_loss: 3.6538e-04 - KL loss: 32.8225 - beta: 7.1969e-04 - val_val_loss: 747.7606 - val_val_recon_loss: 3.7022e-04 - val_val_KL loss: 32.9848 - val_beta: 7.1969e-04\n",
      "Epoch 3763/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 737.4582 - recon_loss: 3.6486e-04 - KL loss: 33.0271 - beta: 7.1969e-04 - val_val_loss: 747.5309 - val_val_recon_loss: 3.7020e-04 - val_val_KL loss: 32.7795 - val_beta: 7.1969e-04\n",
      "Epoch 3764/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 733.1265 - recon_loss: 3.6266e-04 - KL loss: 32.9361 - beta: 7.1969e-04 - val_val_loss: 753.7513 - val_val_recon_loss: 3.7330e-04 - val_val_KL loss: 33.0287 - val_beta: 7.1969e-04\n",
      "Epoch 3765/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 736.4048 - recon_loss: 3.6431e-04 - KL loss: 33.0395 - beta: 7.1969e-04 - val_val_loss: 744.7301 - val_val_recon_loss: 3.6859e-04 - val_val_KL loss: 33.1005 - val_beta: 7.1969e-04\n",
      "Epoch 3766/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 732.4424 - recon_loss: 3.6223e-04 - KL loss: 33.0852 - beta: 7.1969e-04 - val_val_loss: 748.3847 - val_val_recon_loss: 3.7046e-04 - val_val_KL loss: 33.1292 - val_beta: 7.1969e-04\n",
      "Epoch 3767/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 740.9127 - recon_loss: 3.6671e-04 - KL loss: 32.9070 - beta: 7.1969e-04 - val_val_loss: 740.6096 - val_val_recon_loss: 3.6675e-04 - val_val_KL loss: 32.5228 - val_beta: 7.1969e-04\n",
      "Epoch 3768/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 730.6667 - recon_loss: 3.6152e-04 - KL loss: 32.6721 - beta: 7.1969e-04 - val_val_loss: 730.0394 - val_val_recon_loss: 3.6125e-04 - val_val_KL loss: 32.5689 - val_beta: 7.1969e-04\n",
      "Epoch 3769/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 733.7966 - recon_loss: 3.6302e-04 - KL loss: 32.9121 - beta: 7.1969e-04 - val_val_loss: 740.4504 - val_val_recon_loss: 3.6631e-04 - val_val_KL loss: 33.2139 - val_beta: 7.1969e-04\n",
      "Epoch 3770/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 721.0308 - recon_loss: 3.5635e-04 - KL loss: 33.0215 - beta: 7.1969e-04 - val_val_loss: 737.2411 - val_val_recon_loss: 3.6490e-04 - val_val_KL loss: 32.7360 - val_beta: 7.1969e-04\n",
      "Epoch 3771/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 727.6975 - recon_loss: 3.5992e-04 - KL loss: 32.8101 - beta: 7.1969e-04 - val_val_loss: 735.8454 - val_val_recon_loss: 3.6412e-04 - val_val_KL loss: 32.8402 - val_beta: 7.1969e-04\n",
      "Epoch 3772/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 726.4259 - recon_loss: 3.5912e-04 - KL loss: 33.0671 - beta: 7.1969e-04 - val_val_loss: 743.8602 - val_val_recon_loss: 3.6816e-04 - val_val_KL loss: 33.0480 - val_beta: 7.1969e-04\n",
      "Epoch 3773/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 726.9489 - recon_loss: 3.5941e-04 - KL loss: 33.0315 - beta: 7.1969e-04\n",
      "Epoch 03773: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 726.9502 - recon_loss: 3.5941e-04 - KL loss: 33.0315 - beta: 7.1969e-04 - val_val_loss: 746.6393 - val_val_recon_loss: 3.6962e-04 - val_val_KL loss: 33.0219 - val_beta: 7.1969e-04\n",
      "Epoch 3774/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 721.9355 - recon_loss: 3.5676e-04 - KL loss: 33.1465 - beta: 7.1969e-04 - val_val_loss: 732.9366 - val_val_recon_loss: 3.6240e-04 - val_val_KL loss: 33.2481 - val_beta: 7.1969e-04\n",
      "Epoch 3775/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 729.1888 - recon_loss: 3.6043e-04 - KL loss: 33.2975 - beta: 7.1969e-04 - val_val_loss: 730.9398 - val_val_recon_loss: 3.6136e-04 - val_val_KL loss: 33.2588 - val_beta: 7.1969e-04\n",
      "Epoch 3776/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 718.7610 - recon_loss: 3.5505e-04 - KL loss: 33.2597 - beta: 7.1969e-04 - val_val_loss: 731.3557 - val_val_recon_loss: 3.6158e-04 - val_val_KL loss: 33.2607 - val_beta: 7.1969e-04\n",
      "Epoch 3777/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 721.7224 - recon_loss: 3.5662e-04 - KL loss: 33.1943 - beta: 7.1969e-04 - val_val_loss: 730.0623 - val_val_recon_loss: 3.6096e-04 - val_val_KL loss: 33.1489 - val_beta: 7.1969e-04\n",
      "Epoch 3778/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 715.3465 - recon_loss: 3.5335e-04 - KL loss: 33.1313 - beta: 7.1969e-04 - val_val_loss: 726.8011 - val_val_recon_loss: 3.5932e-04 - val_val_KL loss: 33.0640 - val_beta: 7.1969e-04\n",
      "Epoch 3779/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 720.6362 - recon_loss: 3.5608e-04 - KL loss: 33.1519 - beta: 7.1969e-04 - val_val_loss: 728.4952 - val_val_recon_loss: 3.6018e-04 - val_val_KL loss: 33.1029 - val_beta: 7.1969e-04\n",
      "Epoch 3780/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 715.1060 - recon_loss: 3.5320e-04 - KL loss: 33.1799 - beta: 7.1969e-04 - val_val_loss: 730.6178 - val_val_recon_loss: 3.6116e-04 - val_val_KL loss: 33.3287 - val_beta: 7.1969e-04\n",
      "Epoch 3781/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 720.3392 - recon_loss: 3.5589e-04 - KL loss: 33.2150 - beta: 7.1969e-04 - val_val_loss: 728.6431 - val_val_recon_loss: 3.6028e-04 - val_val_KL loss: 33.0490 - val_beta: 7.1969e-04\n",
      "Epoch 3782/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 719.9163 - recon_loss: 3.5574e-04 - KL loss: 33.0937 - beta: 7.1969e-04 - val_val_loss: 728.1019 - val_val_recon_loss: 3.5994e-04 - val_val_KL loss: 33.1609 - val_beta: 7.1969e-04\n",
      "Epoch 3783/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 716.7053 - recon_loss: 3.5397e-04 - KL loss: 33.2998 - beta: 7.1969e-04\n",
      "Epoch 03783: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 716.7041 - recon_loss: 3.5397e-04 - KL loss: 33.2997 - beta: 7.1969e-04 - val_val_loss: 727.3652 - val_val_recon_loss: 3.5960e-04 - val_val_KL loss: 33.0882 - val_beta: 7.1969e-04\n",
      "Epoch 3784/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 714.3475 - recon_loss: 3.5282e-04 - KL loss: 33.1665 - beta: 7.1969e-04 - val_val_loss: 725.3968 - val_val_recon_loss: 3.5856e-04 - val_val_KL loss: 33.1249 - val_beta: 7.1969e-04\n",
      "Epoch 3785/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 718.7979 - recon_loss: 3.5512e-04 - KL loss: 33.1644 - beta: 7.1969e-04 - val_val_loss: 724.3145 - val_val_recon_loss: 3.5803e-04 - val_val_KL loss: 33.0650 - val_beta: 7.1969e-04\n",
      "Epoch 3786/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 714.4288 - recon_loss: 3.5286e-04 - KL loss: 33.1687 - beta: 7.1969e-04 - val_val_loss: 724.4500 - val_val_recon_loss: 3.5808e-04 - val_val_KL loss: 33.1153 - val_beta: 7.1969e-04\n",
      "Epoch 3787/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 707.4767 - recon_loss: 3.4922e-04 - KL loss: 33.2348 - beta: 7.1969e-04 - val_val_loss: 724.0590 - val_val_recon_loss: 3.5784e-04 - val_val_KL loss: 33.1693 - val_beta: 7.1969e-04\n",
      "Epoch 3788/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 712.7117 - recon_loss: 3.5191e-04 - KL loss: 33.2780 - beta: 7.1969e-04 - val_val_loss: 725.3960 - val_val_recon_loss: 3.5850e-04 - val_val_KL loss: 33.2377 - val_beta: 7.1969e-04\n",
      "Epoch 3789/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 718.2359 - recon_loss: 3.5476e-04 - KL loss: 33.3092 - beta: 7.1969e-04 - val_val_loss: 725.0622 - val_val_recon_loss: 3.5831e-04 - val_val_KL loss: 33.2728 - val_beta: 7.1969e-04\n",
      "Epoch 3790/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 712.4593 - recon_loss: 3.5173e-04 - KL loss: 33.3819 - beta: 7.1969e-04 - val_val_loss: 726.9959 - val_val_recon_loss: 3.5931e-04 - val_val_KL loss: 33.2731 - val_beta: 7.1969e-04\n",
      "Epoch 3791/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 709.7913 - recon_loss: 3.5035e-04 - KL loss: 33.3705 - beta: 7.1969e-04 - val_val_loss: 725.7377 - val_val_recon_loss: 3.5864e-04 - val_val_KL loss: 33.3115 - val_beta: 7.1969e-04\n",
      "Epoch 3792/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 711.1307 - recon_loss: 3.5106e-04 - KL loss: 33.3319 - beta: 7.1969e-04\n",
      "Epoch 03792: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 711.1342 - recon_loss: 3.5107e-04 - KL loss: 33.3319 - beta: 7.1969e-04 - val_val_loss: 726.3954 - val_val_recon_loss: 3.5898e-04 - val_val_KL loss: 33.3042 - val_beta: 7.1969e-04\n",
      "Epoch 3793/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 713.2019 - recon_loss: 3.5213e-04 - KL loss: 33.3478 - beta: 7.1969e-04 - val_val_loss: 723.1409 - val_val_recon_loss: 3.5729e-04 - val_val_KL loss: 33.3134 - val_beta: 7.1969e-04\n",
      "Epoch 3794/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 710.8542 - recon_loss: 3.5088e-04 - KL loss: 33.4037 - beta: 7.1969e-04 - val_val_loss: 724.9453 - val_val_recon_loss: 3.5822e-04 - val_val_KL loss: 33.3222 - val_beta: 7.1969e-04\n",
      "Epoch 3795/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 714.0240 - recon_loss: 3.5258e-04 - KL loss: 33.2943 - beta: 7.1969e-04 - val_val_loss: 725.2606 - val_val_recon_loss: 3.5841e-04 - val_val_KL loss: 33.2717 - val_beta: 7.1969e-04\n",
      "Epoch 3796/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 711.6771 - recon_loss: 3.5136e-04 - KL loss: 33.3073 - beta: 7.1969e-04 - val_val_loss: 724.5005 - val_val_recon_loss: 3.5801e-04 - val_val_KL loss: 33.2986 - val_beta: 7.1969e-04\n",
      "Epoch 3797/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 709.5682 - recon_loss: 3.5025e-04 - KL loss: 33.3377 - beta: 7.1969e-04 - val_val_loss: 724.7199 - val_val_recon_loss: 3.5811e-04 - val_val_KL loss: 33.3199 - val_beta: 7.1969e-04\n",
      "Epoch 3798/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 711.1572 - recon_loss: 3.5111e-04 - KL loss: 33.2781 - beta: 7.1969e-04\n",
      "Epoch 03798: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 711.1561 - recon_loss: 3.5111e-04 - KL loss: 33.2781 - beta: 7.1969e-04 - val_val_loss: 724.1309 - val_val_recon_loss: 3.5782e-04 - val_val_KL loss: 33.2920 - val_beta: 7.1969e-04\n",
      "Epoch 3799/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 720.6605 - recon_loss: 3.5599e-04 - KL loss: 33.3427 - beta: 7.1969e-04 - val_val_loss: 723.4920 - val_val_recon_loss: 3.5749e-04 - val_val_KL loss: 33.2844 - val_beta: 7.1969e-04\n",
      "Epoch 3800/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 709.9339 - recon_loss: 3.5043e-04 - KL loss: 33.3587 - beta: 7.1969e-04 - val_val_loss: 724.5520 - val_val_recon_loss: 3.5803e-04 - val_val_KL loss: 33.2980 - val_beta: 7.1969e-04\n",
      "Epoch 3801/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 710.9394 - recon_loss: 3.5099e-04 - KL loss: 33.2780 - beta: 7.1969e-04 - val_val_loss: 724.0447 - val_val_recon_loss: 3.5777e-04 - val_val_KL loss: 33.3072 - val_beta: 7.1969e-04\n",
      "Epoch 3802/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 712.3801 - recon_loss: 3.5170e-04 - KL loss: 33.3627 - beta: 7.1969e-04 - val_val_loss: 724.7810 - val_val_recon_loss: 3.5816e-04 - val_val_KL loss: 33.2887 - val_beta: 7.1969e-04\n",
      "Epoch 3803/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 702.9329 - recon_loss: 3.4689e-04 - KL loss: 33.1889 - beta: 7.1969e-04\n",
      "Epoch 03803: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 702.9375 - recon_loss: 3.4689e-04 - KL loss: 33.1889 - beta: 7.1969e-04 - val_val_loss: 724.5074 - val_val_recon_loss: 3.5801e-04 - val_val_KL loss: 33.3044 - val_beta: 7.1969e-04\n",
      "Epoch 3803/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2075.4177 - recon_loss: 3.9357e-04 - KL loss: 36.9548 - beta: 4.3940e-04 - val_val_loss: 2046.7961 - val_val_recon_loss: 3.8778e-04 - val_val_KL loss: 38.2825 - val_beta: 4.3940e-04\n",
      "Epoch 3804/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2083.4217 - recon_loss: 3.9454e-04 - KL loss: 39.9051 - beta: 4.3940e-04 - val_val_loss: 2004.8981 - val_val_recon_loss: 3.7963e-04 - val_val_KL loss: 38.6376 - val_beta: 4.3940e-04\n",
      "Epoch 3805/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1993.8098 - recon_loss: 3.7734e-04 - KL loss: 39.3966 - beta: 4.3940e-04 - val_val_loss: 1972.5205 - val_val_recon_loss: 3.7331e-04 - val_val_KL loss: 38.9644 - val_beta: 4.3940e-04\n",
      "Epoch 3806/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1954.6950 - recon_loss: 3.6984e-04 - KL loss: 39.0962 - beta: 4.3940e-04 - val_val_loss: 1970.7699 - val_val_recon_loss: 3.7296e-04 - val_val_KL loss: 39.0566 - val_beta: 4.3940e-04\n",
      "Epoch 3807/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1960.0880 - recon_loss: 3.7096e-04 - KL loss: 38.6862 - beta: 4.3940e-04 - val_val_loss: 1990.4681 - val_val_recon_loss: 3.7663e-04 - val_val_KL loss: 39.7158 - val_beta: 4.3940e-04\n",
      "Epoch 3808/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1947.0114 - recon_loss: 3.6837e-04 - KL loss: 39.0539 - beta: 4.3940e-04 - val_val_loss: 1950.6713 - val_val_recon_loss: 3.6914e-04 - val_val_KL loss: 38.7260 - val_beta: 4.3940e-04\n",
      "Epoch 3809/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1969.8364 - recon_loss: 3.7277e-04 - KL loss: 39.0727 - beta: 4.3940e-04 - val_val_loss: 2170.9277 - val_val_recon_loss: 4.1115e-04 - val_val_KL loss: 41.3705 - val_beta: 4.3940e-04\n",
      "Epoch 3810/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2038.4736 - recon_loss: 3.8579e-04 - KL loss: 40.3038 - beta: 4.3940e-04 - val_val_loss: 1963.0989 - val_val_recon_loss: 3.7141e-04 - val_val_KL loss: 39.3751 - val_beta: 4.3940e-04\n",
      "Epoch 3811/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1935.4665 - recon_loss: 3.6603e-04 - KL loss: 39.6181 - beta: 4.3940e-04 - val_val_loss: 1937.6385 - val_val_recon_loss: 3.6647e-04 - val_val_KL loss: 39.5120 - val_beta: 4.3940e-04\n",
      "Epoch 3812/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1909.7614 - recon_loss: 3.6115e-04 - KL loss: 39.2048 - beta: 4.3940e-04 - val_val_loss: 1931.1765 - val_val_recon_loss: 3.6523e-04 - val_val_KL loss: 39.4765 - val_beta: 4.3940e-04\n",
      "Epoch 3813/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1910.8149 - recon_loss: 3.6134e-04 - KL loss: 39.2798 - beta: 4.3940e-04 - val_val_loss: 1905.3875 - val_val_recon_loss: 3.6032e-04 - val_val_KL loss: 39.1016 - val_beta: 4.3940e-04\n",
      "Epoch 3814/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1962.7465 - recon_loss: 3.7126e-04 - KL loss: 39.7902 - beta: 4.3940e-04 - val_val_loss: 2004.7332 - val_val_recon_loss: 3.7942e-04 - val_val_KL loss: 39.5330 - val_beta: 4.3940e-04\n",
      "Epoch 3815/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1990.8539 - recon_loss: 3.7656e-04 - KL loss: 40.4457 - beta: 4.3940e-04 - val_val_loss: 1954.6039 - val_val_recon_loss: 3.6949e-04 - val_val_KL loss: 40.8295 - val_beta: 4.3940e-04\n",
      "Epoch 3816/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1959.5036 - recon_loss: 3.7044e-04 - KL loss: 40.8053 - beta: 4.3940e-04 - val_val_loss: 2087.4817 - val_val_recon_loss: 3.9520e-04 - val_val_KL loss: 40.5580 - val_beta: 4.3940e-04\n",
      "Epoch 3817/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1957.8419 - recon_loss: 3.7016e-04 - KL loss: 40.5949 - beta: 4.3940e-04 - val_val_loss: 1927.6318 - val_val_recon_loss: 3.6431e-04 - val_val_KL loss: 40.6913 - val_beta: 4.3940e-04\n",
      "Epoch 3818/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1926.2494 - recon_loss: 3.6407e-04 - KL loss: 40.5733 - beta: 4.3940e-04\n",
      "Epoch 03818: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1926.2635 - recon_loss: 3.6407e-04 - KL loss: 40.5732 - beta: 4.3940e-04 - val_val_loss: 1953.9269 - val_val_recon_loss: 3.6954e-04 - val_val_KL loss: 39.8938 - val_beta: 4.3940e-04\n",
      "Epoch 3819/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1885.7773 - recon_loss: 3.5627e-04 - KL loss: 40.4796 - beta: 4.3940e-04 - val_val_loss: 1872.4237 - val_val_recon_loss: 3.5370e-04 - val_val_KL loss: 40.4527 - val_beta: 4.3940e-04\n",
      "Epoch 3820/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1830.1596 - recon_loss: 3.4555e-04 - KL loss: 40.3714 - beta: 4.3940e-04 - val_val_loss: 1857.3306 - val_val_recon_loss: 3.5083e-04 - val_val_KL loss: 40.1984 - val_beta: 4.3940e-04\n",
      "Epoch 3821/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1841.7856 - recon_loss: 3.4783e-04 - KL loss: 40.2282 - beta: 4.3940e-04 - val_val_loss: 1844.3801 - val_val_recon_loss: 3.4833e-04 - val_val_KL loss: 40.2229 - val_beta: 4.3940e-04\n",
      "Epoch 3822/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1840.7107 - recon_loss: 3.4760e-04 - KL loss: 40.3469 - beta: 4.3940e-04 - val_val_loss: 1844.7197 - val_val_recon_loss: 3.4845e-04 - val_val_KL loss: 39.9269 - val_beta: 4.3940e-04\n",
      "Epoch 3823/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1832.2130 - recon_loss: 3.4596e-04 - KL loss: 40.2971 - beta: 4.3940e-04 - val_val_loss: 1836.8398 - val_val_recon_loss: 3.4682e-04 - val_val_KL loss: 40.4927 - val_beta: 4.3940e-04\n",
      "Epoch 3824/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1833.3902 - recon_loss: 3.4616e-04 - KL loss: 40.4719 - beta: 4.3940e-04 - val_val_loss: 1837.2303 - val_val_recon_loss: 3.4694e-04 - val_val_KL loss: 40.2460 - val_beta: 4.3940e-04\n",
      "Epoch 3825/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1831.0432 - recon_loss: 3.4567e-04 - KL loss: 40.6672 - beta: 4.3940e-04 - val_val_loss: 1848.7657 - val_val_recon_loss: 3.4903e-04 - val_val_KL loss: 40.9690 - val_beta: 4.3940e-04\n",
      "Epoch 3826/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 1811.9572 - recon_loss: 3.4201e-04 - KL loss: 40.5307 - beta: 4.3940e-04 - val_val_loss: 1841.5553 - val_val_recon_loss: 3.4768e-04 - val_val_KL loss: 40.7770 - val_beta: 4.3940e-04\n",
      "Epoch 3827/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1835.6690 - recon_loss: 3.4651e-04 - KL loss: 40.9143 - beta: 4.3940e-04 - val_val_loss: 1854.3085 - val_val_recon_loss: 3.5011e-04 - val_val_KL loss: 40.9033 - val_beta: 4.3940e-04\n",
      "Epoch 3828/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 1832.0073 - recon_loss: 3.4579e-04 - KL loss: 41.0020 - beta: 4.3940e-04\n",
      "Epoch 03828: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1832.0055 - recon_loss: 3.4579e-04 - KL loss: 41.0019 - beta: 4.3940e-04 - val_val_loss: 1850.9347 - val_val_recon_loss: 3.4945e-04 - val_val_KL loss: 40.9762 - val_beta: 4.3940e-04\n",
      "Epoch 3829/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1814.5579 - recon_loss: 3.4244e-04 - KL loss: 40.8834 - beta: 4.3940e-04 - val_val_loss: 1831.7223 - val_val_recon_loss: 3.4576e-04 - val_val_KL loss: 40.8699 - val_beta: 4.3940e-04\n",
      "Epoch 3830/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1808.8221 - recon_loss: 3.4131e-04 - KL loss: 41.0029 - beta: 4.3940e-04 - val_val_loss: 1829.5024 - val_val_recon_loss: 3.4535e-04 - val_val_KL loss: 40.7509 - val_beta: 4.3940e-04\n",
      "Epoch 3831/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1826.6188 - recon_loss: 3.4477e-04 - KL loss: 40.8851 - beta: 4.3940e-04 - val_val_loss: 1825.9659 - val_val_recon_loss: 3.4467e-04 - val_val_KL loss: 40.7391 - val_beta: 4.3940e-04\n",
      "Epoch 3832/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1785.9029 - recon_loss: 3.3696e-04 - KL loss: 40.6426 - beta: 4.3940e-04 - val_val_loss: 1818.4425 - val_val_recon_loss: 3.4323e-04 - val_val_KL loss: 40.6690 - val_beta: 4.3940e-04\n",
      "Epoch 3833/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1780.3156 - recon_loss: 3.3584e-04 - KL loss: 40.8351 - beta: 4.3940e-04 - val_val_loss: 1822.7770 - val_val_recon_loss: 3.4406e-04 - val_val_KL loss: 40.7106 - val_beta: 4.3940e-04\n",
      "Epoch 3834/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1800.1235 - recon_loss: 3.3966e-04 - KL loss: 40.8794 - beta: 4.3940e-04 - val_val_loss: 1822.1444 - val_val_recon_loss: 3.4396e-04 - val_val_KL loss: 40.6139 - val_beta: 4.3940e-04\n",
      "Epoch 3835/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1788.5989 - recon_loss: 3.3745e-04 - KL loss: 40.7886 - beta: 4.3940e-04 - val_val_loss: 1823.8046 - val_val_recon_loss: 3.4425e-04 - val_val_KL loss: 40.7880 - val_beta: 4.3940e-04\n",
      "Epoch 3836/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1790.0744 - recon_loss: 3.3774e-04 - KL loss: 40.7363 - beta: 4.3940e-04 - val_val_loss: 1817.7150 - val_val_recon_loss: 3.4310e-04 - val_val_KL loss: 40.6410 - val_beta: 4.3940e-04\n",
      "Epoch 3837/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 1785.4629 - recon_loss: 3.3682e-04 - KL loss: 40.9059 - beta: 4.3940e-04 - val_val_loss: 1834.7053 - val_val_recon_loss: 3.4628e-04 - val_val_KL loss: 41.1447 - val_beta: 4.3940e-04\n",
      "Epoch 3838/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1815.2109 - recon_loss: 3.4250e-04 - KL loss: 41.2481 - beta: 4.3940e-04 - val_val_loss: 1831.3894 - val_val_recon_loss: 3.4566e-04 - val_val_KL loss: 41.0528 - val_beta: 4.3940e-04\n",
      "Epoch 3839/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1826.6573 - recon_loss: 3.4471e-04 - KL loss: 41.2175 - beta: 4.3940e-04 - val_val_loss: 1813.1216 - val_val_recon_loss: 3.4219e-04 - val_val_KL loss: 40.7645 - val_beta: 4.3940e-04\n",
      "Epoch 3840/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1798.5552 - recon_loss: 3.3935e-04 - KL loss: 40.8866 - beta: 4.3940e-04 - val_val_loss: 1813.2701 - val_val_recon_loss: 3.4218e-04 - val_val_KL loss: 40.9704 - val_beta: 4.3940e-04\n",
      "Epoch 3841/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1786.8874 - recon_loss: 3.3712e-04 - KL loss: 40.7944 - beta: 4.3940e-04 - val_val_loss: 1811.1344 - val_val_recon_loss: 3.4180e-04 - val_val_KL loss: 40.7719 - val_beta: 4.3940e-04\n",
      "Epoch 3842/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1797.0174 - recon_loss: 3.3907e-04 - KL loss: 40.8174 - beta: 4.3940e-04 - val_val_loss: 1813.1388 - val_val_recon_loss: 3.4217e-04 - val_val_KL loss: 40.8687 - val_beta: 4.3940e-04\n",
      "Epoch 3843/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1786.5991 - recon_loss: 3.3704e-04 - KL loss: 40.9050 - beta: 4.3940e-04 - val_val_loss: 1816.5624 - val_val_recon_loss: 3.4281e-04 - val_val_KL loss: 40.9724 - val_beta: 4.3940e-04\n",
      "Epoch 3844/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1791.3156 - recon_loss: 3.3792e-04 - KL loss: 41.0687 - beta: 4.3940e-04 - val_val_loss: 1812.5663 - val_val_recon_loss: 3.4207e-04 - val_val_KL loss: 40.8322 - val_beta: 4.3940e-04\n",
      "Epoch 3845/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1784.9993 - recon_loss: 3.3675e-04 - KL loss: 40.7908 - beta: 4.3940e-04 - val_val_loss: 1806.5118 - val_val_recon_loss: 3.4088e-04 - val_val_KL loss: 40.9473 - val_beta: 4.3940e-04\n",
      "Epoch 3846/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1786.3843 - recon_loss: 3.3701e-04 - KL loss: 40.8551 - beta: 4.3940e-04 - val_val_loss: 1802.8707 - val_val_recon_loss: 3.4023e-04 - val_val_KL loss: 40.6699 - val_beta: 4.3940e-04\n",
      "Epoch 3847/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1778.3881 - recon_loss: 3.3552e-04 - KL loss: 40.5524 - beta: 4.3940e-04 - val_val_loss: 1800.0933 - val_val_recon_loss: 3.3969e-04 - val_val_KL loss: 40.6553 - val_beta: 4.3940e-04\n",
      "Epoch 3848/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1777.0157 - recon_loss: 3.3522e-04 - KL loss: 40.7287 - beta: 4.3940e-04 - val_val_loss: 1804.9539 - val_val_recon_loss: 3.4065e-04 - val_val_KL loss: 40.5920 - val_beta: 4.3940e-04\n",
      "Epoch 3849/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1784.6794 - recon_loss: 3.3672e-04 - KL loss: 40.6599 - beta: 4.3940e-04 - val_val_loss: 1802.9335 - val_val_recon_loss: 3.4023e-04 - val_val_KL loss: 40.7444 - val_beta: 4.3940e-04\n",
      "Epoch 3850/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1785.4934 - recon_loss: 3.3686e-04 - KL loss: 40.7424 - beta: 4.3940e-04 - val_val_loss: 1793.5178 - val_val_recon_loss: 3.3839e-04 - val_val_KL loss: 40.8529 - val_beta: 4.3940e-04\n",
      "Epoch 3851/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1792.1793 - recon_loss: 3.3815e-04 - KL loss: 40.7648 - beta: 4.3940e-04 - val_val_loss: 1796.3539 - val_val_recon_loss: 3.3899e-04 - val_val_KL loss: 40.5478 - val_beta: 4.3940e-04\n",
      "Epoch 3852/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1764.1688 - recon_loss: 3.3276e-04 - KL loss: 40.6246 - beta: 4.3940e-04 - val_val_loss: 1795.3584 - val_val_recon_loss: 3.3876e-04 - val_val_KL loss: 40.7653 - val_beta: 4.3940e-04\n",
      "Epoch 3853/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1783.4449 - recon_loss: 3.3642e-04 - KL loss: 40.9525 - beta: 4.3940e-04 - val_val_loss: 1807.7611 - val_val_recon_loss: 3.4112e-04 - val_val_KL loss: 40.9593 - val_beta: 4.3940e-04\n",
      "Epoch 3854/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1783.2927 - recon_loss: 3.3636e-04 - KL loss: 41.1293 - beta: 4.3940e-04 - val_val_loss: 1807.7114 - val_val_recon_loss: 3.4107e-04 - val_val_KL loss: 41.1255 - val_beta: 4.3940e-04\n",
      "Epoch 3855/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1787.8877 - recon_loss: 3.3726e-04 - KL loss: 41.0352 - beta: 4.3940e-04\n",
      "Epoch 03855: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1787.8863 - recon_loss: 3.3726e-04 - KL loss: 41.0353 - beta: 4.3940e-04 - val_val_loss: 1799.1472 - val_val_recon_loss: 3.3946e-04 - val_val_KL loss: 40.9444 - val_beta: 4.3940e-04\n",
      "Epoch 3856/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1795.6443 - recon_loss: 3.3875e-04 - KL loss: 41.0724 - beta: 4.3940e-04 - val_val_loss: 1793.8961 - val_val_recon_loss: 3.3844e-04 - val_val_KL loss: 40.9575 - val_beta: 4.3940e-04\n",
      "Epoch 3857/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1753.9829 - recon_loss: 3.3073e-04 - KL loss: 40.9908 - beta: 4.3940e-04 - val_val_loss: 1795.6282 - val_val_recon_loss: 3.3874e-04 - val_val_KL loss: 41.1418 - val_beta: 4.3940e-04\n",
      "Epoch 3858/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1770.9705 - recon_loss: 3.3395e-04 - KL loss: 41.2679 - beta: 4.3940e-04 - val_val_loss: 1795.0028 - val_val_recon_loss: 3.3863e-04 - val_val_KL loss: 41.0801 - val_beta: 4.3940e-04\n",
      "Epoch 3859/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1764.8484 - recon_loss: 3.3279e-04 - KL loss: 41.1676 - beta: 4.3940e-04 - val_val_loss: 1796.6000 - val_val_recon_loss: 3.3891e-04 - val_val_KL loss: 41.2012 - val_beta: 4.3940e-04\n",
      "Epoch 3860/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1775.3569 - recon_loss: 3.3479e-04 - KL loss: 41.3077 - beta: 4.3940e-04\n",
      "Epoch 03860: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1775.3576 - recon_loss: 3.3479e-04 - KL loss: 41.3077 - beta: 4.3940e-04 - val_val_loss: 1795.5688 - val_val_recon_loss: 3.3872e-04 - val_val_KL loss: 41.1559 - val_beta: 4.3940e-04\n",
      "Epoch 3860/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 5202.5782 - recon_loss: 3.7101e-04 - KL loss: 47.3970 - beta: 2.6827e-04 - val_val_loss: 5029.7695 - val_val_recon_loss: 3.5817e-04 - val_val_KL loss: 53.0051 - val_beta: 2.6827e-04\n",
      "Epoch 3861/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5061.4289 - recon_loss: 3.6055e-04 - KL loss: 51.5333 - beta: 2.6827e-04 - val_val_loss: 5132.0645 - val_val_recon_loss: 3.6556e-04 - val_val_KL loss: 52.5974 - val_beta: 2.6827e-04\n",
      "Epoch 3862/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5034.8612 - recon_loss: 3.5861e-04 - KL loss: 51.9858 - beta: 2.6827e-04 - val_val_loss: 5041.2202 - val_val_recon_loss: 3.5910e-04 - val_val_KL loss: 51.5857 - val_beta: 2.6827e-04\n",
      "Epoch 3863/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4951.9575 - recon_loss: 3.5264e-04 - KL loss: 52.0579 - beta: 2.6827e-04 - val_val_loss: 5013.9668 - val_val_recon_loss: 3.5715e-04 - val_val_KL loss: 51.3632 - val_beta: 2.6827e-04\n",
      "Epoch 3864/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5013.9948 - recon_loss: 3.5717e-04 - KL loss: 51.1845 - beta: 2.6827e-04 - val_val_loss: 5039.9736 - val_val_recon_loss: 3.5894e-04 - val_val_KL loss: 52.5239 - val_beta: 2.6827e-04\n",
      "Epoch 3865/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4929.1180 - recon_loss: 3.5098e-04 - KL loss: 52.2247 - beta: 2.6827e-04 - val_val_loss: 4962.0269 - val_val_recon_loss: 3.5336e-04 - val_val_KL loss: 52.0702 - val_beta: 2.6827e-04\n",
      "Epoch 3866/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4965.9190 - recon_loss: 3.5361e-04 - KL loss: 52.5317 - beta: 2.6827e-04 - val_val_loss: 4951.4658 - val_val_recon_loss: 3.5264e-04 - val_val_KL loss: 51.6150 - val_beta: 2.6827e-04\n",
      "Epoch 3867/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5038.7036 - recon_loss: 3.5879e-04 - KL loss: 53.3143 - beta: 2.6827e-04 - val_val_loss: 5078.8022 - val_val_recon_loss: 3.6156e-04 - val_val_KL loss: 54.9893 - val_beta: 2.6827e-04\n",
      "Epoch 3868/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4999.1084 - recon_loss: 3.5583e-04 - KL loss: 54.9253 - beta: 2.6827e-04 - val_val_loss: 4829.5000 - val_val_recon_loss: 3.4378e-04 - val_val_KL loss: 52.6524 - val_beta: 2.6827e-04\n",
      "Epoch 3869/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4932.1644 - recon_loss: 3.5108e-04 - KL loss: 53.9456 - beta: 2.6827e-04 - val_val_loss: 5547.5806 - val_val_recon_loss: 3.9487e-04 - val_val_KL loss: 60.8148 - val_beta: 2.6827e-04\n",
      "Epoch 3870/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5356.4868 - recon_loss: 3.8128e-04 - KL loss: 58.5788 - beta: 2.6827e-04 - val_val_loss: 5159.3374 - val_val_recon_loss: 3.6729e-04 - val_val_KL loss: 55.8736 - val_beta: 2.6827e-04\n",
      "Epoch 3871/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5099.9623 - recon_loss: 3.6298e-04 - KL loss: 56.4326 - beta: 2.6827e-04 - val_val_loss: 5019.4004 - val_val_recon_loss: 3.5731e-04 - val_val_KL loss: 54.5459 - val_beta: 2.6827e-04\n",
      "Epoch 3872/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 4928.9415 - recon_loss: 3.5079e-04 - KL loss: 54.7848 - beta: 2.6827e-04 - val_val_loss: 5002.2539 - val_val_recon_loss: 3.5589e-04 - val_val_KL loss: 57.2071 - val_beta: 2.6827e-04\n",
      "Epoch 3873/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4993.5086 - recon_loss: 3.5534e-04 - KL loss: 56.0945 - beta: 2.6827e-04\n",
      "Epoch 03873: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4993.4842 - recon_loss: 3.5534e-04 - KL loss: 56.0939 - beta: 2.6827e-04 - val_val_loss: 5185.8325 - val_val_recon_loss: 3.6938e-04 - val_val_KL loss: 53.3014 - val_beta: 2.6827e-04\n",
      "Epoch 3874/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4825.9325 - recon_loss: 3.4344e-04 - KL loss: 53.9078 - beta: 2.6827e-04 - val_val_loss: 4778.1997 - val_val_recon_loss: 3.4002e-04 - val_val_KL loss: 53.5717 - val_beta: 2.6827e-04\n",
      "Epoch 3875/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 4709.5585 - recon_loss: 3.3507e-04 - KL loss: 53.7783 - beta: 2.6827e-04 - val_val_loss: 4719.6260 - val_val_recon_loss: 3.3573e-04 - val_val_KL loss: 54.7238 - val_beta: 2.6827e-04\n",
      "Epoch 3876/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4677.8048 - recon_loss: 3.3274e-04 - KL loss: 54.3977 - beta: 2.6827e-04 - val_val_loss: 4758.6538 - val_val_recon_loss: 3.3848e-04 - val_val_KL loss: 55.4974 - val_beta: 2.6827e-04\n",
      "Epoch 3877/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4689.2741 - recon_loss: 3.3353e-04 - KL loss: 54.8255 - beta: 2.6827e-04 - val_val_loss: 4769.0293 - val_val_recon_loss: 3.3929e-04 - val_val_KL loss: 54.6661 - val_beta: 2.6827e-04\n",
      "Epoch 3878/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 4825.8292 - recon_loss: 3.4332e-04 - KL loss: 55.3524 - beta: 2.6827e-04 - val_val_loss: 4898.6001 - val_val_recon_loss: 3.4853e-04 - val_val_KL loss: 55.8374 - val_beta: 2.6827e-04\n",
      "Epoch 3879/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4877.6257 - recon_loss: 3.4700e-04 - KL loss: 56.0246 - beta: 2.6827e-04 - val_val_loss: 4764.6367 - val_val_recon_loss: 3.3897e-04 - val_val_KL loss: 54.6764 - val_beta: 2.6827e-04\n",
      "Epoch 3880/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4695.3630 - recon_loss: 3.3400e-04 - KL loss: 54.4989 - beta: 2.6827e-04 - val_val_loss: 4712.1787 - val_val_recon_loss: 3.3522e-04 - val_val_KL loss: 54.3730 - val_beta: 2.6827e-04\n",
      "Epoch 3881/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4660.7700 - recon_loss: 3.3149e-04 - KL loss: 54.6967 - beta: 2.6827e-04 - val_val_loss: 4738.0620 - val_val_recon_loss: 3.3705e-04 - val_val_KL loss: 54.8115 - val_beta: 2.6827e-04\n",
      "Epoch 3882/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4676.7509 - recon_loss: 3.3262e-04 - KL loss: 54.9425 - beta: 2.6827e-04 - val_val_loss: 4730.1699 - val_val_recon_loss: 3.3645e-04 - val_val_KL loss: 55.1672 - val_beta: 2.6827e-04\n",
      "Epoch 3883/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4635.4890 - recon_loss: 3.2964e-04 - KL loss: 55.1323 - beta: 2.6827e-04 - val_val_loss: 4657.8813 - val_val_recon_loss: 3.3128e-04 - val_val_KL loss: 54.8250 - val_beta: 2.6827e-04\n",
      "Epoch 3884/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4588.9262 - recon_loss: 3.2635e-04 - KL loss: 54.3483 - beta: 2.6827e-04 - val_val_loss: 4653.7871 - val_val_recon_loss: 3.3100e-04 - val_val_KL loss: 54.6018 - val_beta: 2.6827e-04\n",
      "Epoch 3885/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4705.3954 - recon_loss: 3.3466e-04 - KL loss: 55.2629 - beta: 2.6827e-04 - val_val_loss: 4699.2827 - val_val_recon_loss: 3.3419e-04 - val_val_KL loss: 55.6797 - val_beta: 2.6827e-04\n",
      "Epoch 3886/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4687.9967 - recon_loss: 3.3337e-04 - KL loss: 55.8566 - beta: 2.6827e-04 - val_val_loss: 4717.8364 - val_val_recon_loss: 3.3560e-04 - val_val_KL loss: 54.6650 - val_beta: 2.6827e-04\n",
      "Epoch 3887/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4604.8329 - recon_loss: 3.2742e-04 - KL loss: 55.2849 - beta: 2.6827e-04 - val_val_loss: 4666.8184 - val_val_recon_loss: 3.3191e-04 - val_val_KL loss: 54.9979 - val_beta: 2.6827e-04\n",
      "Epoch 3888/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4579.1522 - recon_loss: 3.2559e-04 - KL loss: 55.1322 - beta: 2.6827e-04 - val_val_loss: 4669.4854 - val_val_recon_loss: 3.3213e-04 - val_val_KL loss: 54.4982 - val_beta: 2.6827e-04\n",
      "Epoch 3889/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 4604.7454 - recon_loss: 3.2745e-04 - KL loss: 54.7976 - beta: 2.6827e-04 - val_val_loss: 4648.3823 - val_val_recon_loss: 3.3063e-04 - val_val_KL loss: 54.2843 - val_beta: 2.6827e-04\n",
      "Epoch 3890/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4590.9061 - recon_loss: 3.2643e-04 - KL loss: 55.1749 - beta: 2.6827e-04 - val_val_loss: 4676.9004 - val_val_recon_loss: 3.3264e-04 - val_val_KL loss: 54.9274 - val_beta: 2.6827e-04\n",
      "Epoch 3891/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4605.7398 - recon_loss: 3.2752e-04 - KL loss: 54.9078 - beta: 2.6827e-04 - val_val_loss: 4653.0293 - val_val_recon_loss: 3.3085e-04 - val_val_KL loss: 55.9513 - val_beta: 2.6827e-04\n",
      "Epoch 3892/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4592.5970 - recon_loss: 3.2655e-04 - KL loss: 55.2466 - beta: 2.6827e-04 - val_val_loss: 4632.6748 - val_val_recon_loss: 3.2943e-04 - val_val_KL loss: 55.1989 - val_beta: 2.6827e-04\n",
      "Epoch 3893/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4544.0083 - recon_loss: 3.2304e-04 - KL loss: 55.3764 - beta: 2.6827e-04 - val_val_loss: 4608.8765 - val_val_recon_loss: 3.2775e-04 - val_val_KL loss: 54.8371 - val_beta: 2.6827e-04\n",
      "Epoch 3894/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4613.9264 - recon_loss: 3.2809e-04 - KL loss: 55.1583 - beta: 2.6827e-04 - val_val_loss: 4749.3760 - val_val_recon_loss: 3.3780e-04 - val_val_KL loss: 55.6739 - val_beta: 2.6827e-04\n",
      "Epoch 3895/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4622.3889 - recon_loss: 3.2867e-04 - KL loss: 55.5857 - beta: 2.6827e-04 - val_val_loss: 4669.8516 - val_val_recon_loss: 3.3214e-04 - val_val_KL loss: 54.8027 - val_beta: 2.6827e-04\n",
      "Epoch 3896/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4567.3539 - recon_loss: 3.2472e-04 - KL loss: 55.3570 - beta: 2.6827e-04 - val_val_loss: 4616.2661 - val_val_recon_loss: 3.2823e-04 - val_val_KL loss: 55.4997 - val_beta: 2.6827e-04\n",
      "Epoch 3897/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4525.5938 - recon_loss: 3.2168e-04 - KL loss: 55.8786 - beta: 2.6827e-04 - val_val_loss: 4637.9160 - val_val_recon_loss: 3.2984e-04 - val_val_KL loss: 54.7912 - val_beta: 2.6827e-04\n",
      "Epoch 3898/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4495.2091 - recon_loss: 3.1953e-04 - KL loss: 55.4046 - beta: 2.6827e-04 - val_val_loss: 4582.6045 - val_val_recon_loss: 3.2578e-04 - val_val_KL loss: 55.9430 - val_beta: 2.6827e-04\n",
      "Epoch 3899/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4579.4937 - recon_loss: 3.2558e-04 - KL loss: 55.5797 - beta: 2.6827e-04 - val_val_loss: 4565.4121 - val_val_recon_loss: 3.2458e-04 - val_val_KL loss: 55.4123 - val_beta: 2.6827e-04\n",
      "Epoch 3900/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4525.7759 - recon_loss: 3.2171e-04 - KL loss: 55.5813 - beta: 2.6827e-04 - val_val_loss: 4574.8267 - val_val_recon_loss: 3.2516e-04 - val_val_KL loss: 56.7644 - val_beta: 2.6827e-04\n",
      "Epoch 3901/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4537.8585 - recon_loss: 3.2256e-04 - KL loss: 55.9081 - beta: 2.6827e-04 - val_val_loss: 4574.2036 - val_val_recon_loss: 3.2517e-04 - val_val_KL loss: 56.0199 - val_beta: 2.6827e-04\n",
      "Epoch 3902/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4500.6902 - recon_loss: 3.1992e-04 - KL loss: 55.4533 - beta: 2.6827e-04 - val_val_loss: 4580.3750 - val_val_recon_loss: 3.2569e-04 - val_val_KL loss: 54.8597 - val_beta: 2.6827e-04\n",
      "Epoch 3903/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4522.6898 - recon_loss: 3.2152e-04 - KL loss: 55.1396 - beta: 2.6827e-04 - val_val_loss: 4547.5103 - val_val_recon_loss: 3.2331e-04 - val_val_KL loss: 55.1274 - val_beta: 2.6827e-04\n",
      "Epoch 3904/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4474.1934 - recon_loss: 3.1802e-04 - KL loss: 55.2907 - beta: 2.6827e-04 - val_val_loss: 4603.5474 - val_val_recon_loss: 3.2737e-04 - val_val_KL loss: 54.7354 - val_beta: 2.6827e-04\n",
      "Epoch 3905/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4508.3300 - recon_loss: 3.2051e-04 - KL loss: 54.8969 - beta: 2.6827e-04 - val_val_loss: 4543.2251 - val_val_recon_loss: 3.2293e-04 - val_val_KL loss: 56.1395 - val_beta: 2.6827e-04\n",
      "Epoch 3906/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4487.7872 - recon_loss: 3.1894e-04 - KL loss: 56.0917 - beta: 2.6827e-04 - val_val_loss: 4533.9731 - val_val_recon_loss: 3.2227e-04 - val_val_KL loss: 56.0035 - val_beta: 2.6827e-04\n",
      "Epoch 3907/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4497.4121 - recon_loss: 3.1962e-04 - KL loss: 56.3285 - beta: 2.6827e-04 - val_val_loss: 4608.9536 - val_val_recon_loss: 3.2754e-04 - val_val_KL loss: 57.7769 - val_beta: 2.6827e-04\n",
      "Epoch 3908/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4508.9035 - recon_loss: 3.2039e-04 - KL loss: 57.1353 - beta: 2.6827e-04 - val_val_loss: 4521.7271 - val_val_recon_loss: 3.2139e-04 - val_val_KL loss: 56.0065 - val_beta: 2.6827e-04\n",
      "Epoch 3909/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4435.7329 - recon_loss: 3.1521e-04 - KL loss: 55.9221 - beta: 2.6827e-04 - val_val_loss: 4529.4785 - val_val_recon_loss: 3.2195e-04 - val_val_KL loss: 56.0636 - val_beta: 2.6827e-04\n",
      "Epoch 3910/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4489.9590 - recon_loss: 3.1912e-04 - KL loss: 55.7877 - beta: 2.6827e-04 - val_val_loss: 4505.9609 - val_val_recon_loss: 3.2028e-04 - val_val_KL loss: 55.7354 - val_beta: 2.6827e-04\n",
      "Epoch 3911/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4435.4936 - recon_loss: 3.1518e-04 - KL loss: 56.1117 - beta: 2.6827e-04 - val_val_loss: 4505.0713 - val_val_recon_loss: 3.2015e-04 - val_val_KL loss: 56.6186 - val_beta: 2.6827e-04\n",
      "Epoch 3912/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4441.2710 - recon_loss: 3.1555e-04 - KL loss: 56.7350 - beta: 2.6827e-04 - val_val_loss: 4560.4243 - val_val_recon_loss: 3.2413e-04 - val_val_KL loss: 56.6414 - val_beta: 2.6827e-04\n",
      "Epoch 3913/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4534.1823 - recon_loss: 3.2221e-04 - KL loss: 57.1135 - beta: 2.6827e-04 - val_val_loss: 4594.3237 - val_val_recon_loss: 3.2644e-04 - val_val_KL loss: 58.4427 - val_beta: 2.6827e-04\n",
      "Epoch 3914/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4508.9311 - recon_loss: 3.2033e-04 - KL loss: 57.9644 - beta: 2.6827e-04 - val_val_loss: 4528.0439 - val_val_recon_loss: 3.2179e-04 - val_val_KL loss: 56.7963 - val_beta: 2.6827e-04\n",
      "Epoch 3915/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4451.6397 - recon_loss: 3.1626e-04 - KL loss: 57.1668 - beta: 2.6827e-04 - val_val_loss: 4569.8027 - val_val_recon_loss: 3.2482e-04 - val_val_KL loss: 56.4225 - val_beta: 2.6827e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3916/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4508.4755 - recon_loss: 3.2037e-04 - KL loss: 56.9530 - beta: 2.6827e-04\n",
      "Epoch 03916: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4508.4614 - recon_loss: 3.2037e-04 - KL loss: 56.9536 - beta: 2.6827e-04 - val_val_loss: 4636.9932 - val_val_recon_loss: 3.2955e-04 - val_val_KL loss: 57.9397 - val_beta: 2.6827e-04\n",
      "Epoch 3917/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4504.0267 - recon_loss: 3.1997e-04 - KL loss: 58.0904 - beta: 2.6827e-04 - val_val_loss: 4534.7139 - val_val_recon_loss: 3.2223e-04 - val_val_KL loss: 57.3796 - val_beta: 2.6827e-04\n",
      "Epoch 3918/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4471.4365 - recon_loss: 3.1766e-04 - KL loss: 57.6089 - beta: 2.6827e-04 - val_val_loss: 4536.2520 - val_val_recon_loss: 3.2228e-04 - val_val_KL loss: 58.1983 - val_beta: 2.6827e-04\n",
      "Epoch 3919/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 4438.2705 - recon_loss: 3.1524e-04 - KL loss: 58.0377 - beta: 2.6827e-04 - val_val_loss: 4515.8755 - val_val_recon_loss: 3.2083e-04 - val_val_KL loss: 57.8937 - val_beta: 2.6827e-04\n",
      "Epoch 3920/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4454.8824 - recon_loss: 3.1646e-04 - KL loss: 57.6386 - beta: 2.6827e-04 - val_val_loss: 4513.3013 - val_val_recon_loss: 3.2067e-04 - val_val_KL loss: 57.6659 - val_beta: 2.6827e-04\n",
      "Epoch 3921/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4497.8269 - recon_loss: 3.1954e-04 - KL loss: 57.8161 - beta: 2.6827e-04\n",
      "Epoch 03921: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4497.8062 - recon_loss: 3.1954e-04 - KL loss: 57.8163 - beta: 2.6827e-04 - val_val_loss: 4512.6992 - val_val_recon_loss: 3.2058e-04 - val_val_KL loss: 58.2720 - val_beta: 2.6827e-04\n",
      "Epoch 3921/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 13410.8213 - recon_loss: 3.5789e-04 - KL loss: 69.9844 - beta: 1.6379e-04 - val_val_loss: 13263.7305 - val_val_recon_loss: 3.5365e-04 - val_val_KL loss: 81.1264 - val_beta: 1.6379e-04\n",
      "Epoch 3922/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 13095.3044 - recon_loss: 3.4911e-04 - KL loss: 82.0800 - beta: 1.6379e-04 - val_val_loss: 13052.6963 - val_val_recon_loss: 3.4792e-04 - val_val_KL loss: 83.7978 - val_beta: 1.6379e-04\n",
      "Epoch 3923/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 13127.9789 - recon_loss: 3.4995e-04 - KL loss: 83.0894 - beta: 1.6379e-04 - val_val_loss: 12720.7266 - val_val_recon_loss: 3.3904e-04 - val_val_KL loss: 82.5489 - val_beta: 1.6379e-04\n",
      "Epoch 3924/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 12600.2673 - recon_loss: 3.3580e-04 - KL loss: 82.8993 - beta: 1.6379e-04 - val_val_loss: 12558.9092 - val_val_recon_loss: 3.3470e-04 - val_val_KL loss: 82.7743 - val_beta: 1.6379e-04\n",
      "Epoch 3925/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12463.1790 - recon_loss: 3.3209e-04 - KL loss: 84.0706 - beta: 1.6379e-04 - val_val_loss: 12375.6523 - val_val_recon_loss: 3.2973e-04 - val_val_KL loss: 84.8325 - val_beta: 1.6379e-04\n",
      "Epoch 3926/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12377.9501 - recon_loss: 3.2980e-04 - KL loss: 84.4308 - beta: 1.6379e-04 - val_val_loss: 12234.4658 - val_val_recon_loss: 3.2597e-04 - val_val_KL loss: 83.5975 - val_beta: 1.6379e-04\n",
      "Epoch 3927/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12342.8318 - recon_loss: 3.2886e-04 - KL loss: 84.4128 - beta: 1.6379e-04 - val_val_loss: 12918.3779 - val_val_recon_loss: 3.4429e-04 - val_val_KL loss: 84.7943 - val_beta: 1.6379e-04\n",
      "Epoch 3928/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12804.8590 - recon_loss: 3.4119e-04 - KL loss: 86.7785 - beta: 1.6379e-04 - val_val_loss: 12839.5771 - val_val_recon_loss: 3.4209e-04 - val_val_KL loss: 87.9714 - val_beta: 1.6379e-04\n",
      "Epoch 3929/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13018.9863 - recon_loss: 3.4687e-04 - KL loss: 89.0751 - beta: 1.6379e-04 - val_val_loss: 12377.8320 - val_val_recon_loss: 3.2977e-04 - val_val_KL loss: 85.4192 - val_beta: 1.6379e-04\n",
      "Epoch 3930/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12289.0315 - recon_loss: 3.2738e-04 - KL loss: 85.7856 - beta: 1.6379e-04 - val_val_loss: 12509.8340 - val_val_recon_loss: 3.3330e-04 - val_val_KL loss: 85.7239 - val_beta: 1.6379e-04\n",
      "Epoch 3931/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12162.1160 - recon_loss: 3.2396e-04 - KL loss: 86.2323 - beta: 1.6379e-04\n",
      "Epoch 03931: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12162.1815 - recon_loss: 3.2396e-04 - KL loss: 86.2327 - beta: 1.6379e-04 - val_val_loss: 12676.2178 - val_val_recon_loss: 3.3764e-04 - val_val_KL loss: 90.3207 - val_beta: 1.6379e-04\n",
      "Epoch 3932/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11940.7275 - recon_loss: 3.1798e-04 - KL loss: 87.9020 - beta: 1.6379e-04 - val_val_loss: 12064.7314 - val_val_recon_loss: 3.2128e-04 - val_val_KL loss: 88.7514 - val_beta: 1.6379e-04\n",
      "Epoch 3933/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 11776.1131 - recon_loss: 3.1357e-04 - KL loss: 87.3679 - beta: 1.6379e-04 - val_val_loss: 12049.1191 - val_val_recon_loss: 3.2099e-04 - val_val_KL loss: 83.8265 - val_beta: 1.6379e-04\n",
      "Epoch 3934/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11743.7278 - recon_loss: 3.1277e-04 - KL loss: 84.7744 - beta: 1.6379e-04 - val_val_loss: 11792.1641 - val_val_recon_loss: 3.1408e-04 - val_val_KL loss: 84.5593 - val_beta: 1.6379e-04\n",
      "Epoch 3935/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11616.3955 - recon_loss: 3.0940e-04 - KL loss: 83.1857 - beta: 1.6379e-04 - val_val_loss: 11776.5225 - val_val_recon_loss: 3.1367e-04 - val_val_KL loss: 84.1789 - val_beta: 1.6379e-04\n",
      "Epoch 3936/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11706.8348 - recon_loss: 3.1183e-04 - KL loss: 83.2479 - beta: 1.6379e-04 - val_val_loss: 11724.0576 - val_val_recon_loss: 3.1228e-04 - val_val_KL loss: 83.3766 - val_beta: 1.6379e-04\n",
      "Epoch 3937/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11666.9618 - recon_loss: 3.1071e-04 - KL loss: 84.7876 - beta: 1.6379e-04 - val_val_loss: 11724.9688 - val_val_recon_loss: 3.1227e-04 - val_val_KL loss: 84.6643 - val_beta: 1.6379e-04\n",
      "Epoch 3938/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11514.6711 - recon_loss: 3.0662e-04 - KL loss: 84.9458 - beta: 1.6379e-04 - val_val_loss: 11832.2305 - val_val_recon_loss: 3.1516e-04 - val_val_KL loss: 84.4362 - val_beta: 1.6379e-04\n",
      "Epoch 3939/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11605.7198 - recon_loss: 3.0905e-04 - KL loss: 85.4179 - beta: 1.6379e-04 - val_val_loss: 11826.9424 - val_val_recon_loss: 3.1495e-04 - val_val_KL loss: 86.7402 - val_beta: 1.6379e-04\n",
      "Epoch 3940/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11549.5137 - recon_loss: 3.0753e-04 - KL loss: 86.0086 - beta: 1.6379e-04 - val_val_loss: 11705.3887 - val_val_recon_loss: 3.1172e-04 - val_val_KL loss: 85.8196 - val_beta: 1.6379e-04\n",
      "Epoch 3941/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 11708.6960 - recon_loss: 3.1179e-04 - KL loss: 86.4845 - beta: 1.6379e-04 - val_val_loss: 11774.3564 - val_val_recon_loss: 3.1355e-04 - val_val_KL loss: 86.3291 - val_beta: 1.6379e-04\n",
      "Epoch 3942/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11507.9838 - recon_loss: 3.0642e-04 - KL loss: 85.9849 - beta: 1.6379e-04 - val_val_loss: 11698.5771 - val_val_recon_loss: 3.1156e-04 - val_val_KL loss: 84.8580 - val_beta: 1.6379e-04\n",
      "Epoch 3943/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11530.8748 - recon_loss: 3.0706e-04 - KL loss: 84.8613 - beta: 1.6379e-04 - val_val_loss: 11546.8740 - val_val_recon_loss: 3.0748e-04 - val_val_KL loss: 85.3773 - val_beta: 1.6379e-04\n",
      "Epoch 3944/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11568.6758 - recon_loss: 3.0808e-04 - KL loss: 84.6969 - beta: 1.6379e-04 - val_val_loss: 11655.3301 - val_val_recon_loss: 3.1038e-04 - val_val_KL loss: 85.4456 - val_beta: 1.6379e-04\n",
      "Epoch 3945/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11510.8236 - recon_loss: 3.0651e-04 - KL loss: 85.3547 - beta: 1.6379e-04 - val_val_loss: 11606.6748 - val_val_recon_loss: 3.0910e-04 - val_val_KL loss: 84.7797 - val_beta: 1.6379e-04\n",
      "Epoch 3946/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11353.9372 - recon_loss: 3.0232e-04 - KL loss: 84.5914 - beta: 1.6379e-04 - val_val_loss: 11530.3799 - val_val_recon_loss: 3.0701e-04 - val_val_KL loss: 86.2264 - val_beta: 1.6379e-04\n",
      "Epoch 3947/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11493.6336 - recon_loss: 3.0604e-04 - KL loss: 85.8095 - beta: 1.6379e-04 - val_val_loss: 11610.6992 - val_val_recon_loss: 3.0915e-04 - val_val_KL loss: 86.9282 - val_beta: 1.6379e-04\n",
      "Epoch 3948/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11441.7024 - recon_loss: 3.0464e-04 - KL loss: 85.8315 - beta: 1.6379e-04 - val_val_loss: 11521.7139 - val_val_recon_loss: 3.0681e-04 - val_val_KL loss: 85.0235 - val_beta: 1.6379e-04\n",
      "Epoch 3949/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11448.3261 - recon_loss: 3.0483e-04 - KL loss: 85.3953 - beta: 1.6379e-04 - val_val_loss: 11632.9961 - val_val_recon_loss: 3.0977e-04 - val_val_KL loss: 85.9496 - val_beta: 1.6379e-04\n",
      "Epoch 3950/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11327.5877 - recon_loss: 3.0157e-04 - KL loss: 86.3764 - beta: 1.6379e-04 - val_val_loss: 11796.6729 - val_val_recon_loss: 3.1411e-04 - val_val_KL loss: 88.0644 - val_beta: 1.6379e-04\n",
      "Epoch 3951/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11643.5909 - recon_loss: 3.1002e-04 - KL loss: 87.4605 - beta: 1.6379e-04 - val_val_loss: 12173.9424 - val_val_recon_loss: 3.2412e-04 - val_val_KL loss: 92.2049 - val_beta: 1.6379e-04\n",
      "Epoch 3952/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11712.8087 - recon_loss: 3.1182e-04 - KL loss: 89.2556 - beta: 1.6379e-04 - val_val_loss: 11863.1729 - val_val_recon_loss: 3.1585e-04 - val_val_KL loss: 89.7395 - val_beta: 1.6379e-04\n",
      "Epoch 3953/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11676.0885 - recon_loss: 3.1084e-04 - KL loss: 89.1806 - beta: 1.6379e-04\n",
      "Epoch 03953: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11676.1194 - recon_loss: 3.1084e-04 - KL loss: 89.1809 - beta: 1.6379e-04 - val_val_loss: 11999.5186 - val_val_recon_loss: 3.1947e-04 - val_val_KL loss: 90.9781 - val_beta: 1.6379e-04\n",
      "Epoch 3954/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11841.3280 - recon_loss: 3.1525e-04 - KL loss: 90.2244 - beta: 1.6379e-04 - val_val_loss: 11785.5967 - val_val_recon_loss: 3.1376e-04 - val_val_KL loss: 89.9073 - val_beta: 1.6379e-04\n",
      "Epoch 3955/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11677.7060 - recon_loss: 3.1085e-04 - KL loss: 90.3263 - beta: 1.6379e-04 - val_val_loss: 11699.4746 - val_val_recon_loss: 3.1147e-04 - val_val_KL loss: 89.2484 - val_beta: 1.6379e-04\n",
      "Epoch 3956/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11456.7279 - recon_loss: 3.0497e-04 - KL loss: 88.5282 - beta: 1.6379e-04 - val_val_loss: 11623.5166 - val_val_recon_loss: 3.0945e-04 - val_val_KL loss: 88.5588 - val_beta: 1.6379e-04\n",
      "Epoch 3957/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11404.6971 - recon_loss: 3.0358e-04 - KL loss: 88.2992 - beta: 1.6379e-04 - val_val_loss: 11631.8799 - val_val_recon_loss: 3.0964e-04 - val_val_KL loss: 89.7402 - val_beta: 1.6379e-04\n",
      "Epoch 3958/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11384.4686 - recon_loss: 3.0302e-04 - KL loss: 89.0349 - beta: 1.6379e-04\n",
      "Epoch 03958: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11384.5087 - recon_loss: 3.0302e-04 - KL loss: 89.0349 - beta: 1.6379e-04 - val_val_loss: 11617.3301 - val_val_recon_loss: 3.0926e-04 - val_val_KL loss: 89.2033 - val_beta: 1.6379e-04\n",
      "Epoch 3958/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 33591.1860 - recon_loss: 3.3490e-04 - KL loss: 101.1153 - beta: 1.0000e-04 - val_val_loss: 31878.3477 - val_val_recon_loss: 3.1756e-04 - val_val_KL loss: 121.9791 - val_beta: 1.0000e-04\n",
      "Epoch 3959/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31504.7809 - recon_loss: 3.1380e-04 - KL loss: 124.4661 - beta: 1.0000e-04 - val_val_loss: 34380.3516 - val_val_recon_loss: 3.4247e-04 - val_val_KL loss: 133.6364 - val_beta: 1.0000e-04\n",
      "Epoch 3960/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32631.6794 - recon_loss: 3.2497e-04 - KL loss: 135.1191 - beta: 1.0000e-04 - val_val_loss: 35284.6836 - val_val_recon_loss: 3.5153e-04 - val_val_KL loss: 131.8408 - val_beta: 1.0000e-04\n",
      "Epoch 3961/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32839.6479 - recon_loss: 3.2702e-04 - KL loss: 137.6690 - beta: 1.0000e-04 - val_val_loss: 32849.1875 - val_val_recon_loss: 3.2706e-04 - val_val_KL loss: 143.5226 - val_beta: 1.0000e-04\n",
      "Epoch 3962/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32844.1530 - recon_loss: 3.2701e-04 - KL loss: 143.0631 - beta: 1.0000e-04 - val_val_loss: 32377.6992 - val_val_recon_loss: 3.2237e-04 - val_val_KL loss: 141.0420 - val_beta: 1.0000e-04\n",
      "Epoch 3963/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31949.6686 - recon_loss: 3.1808e-04 - KL loss: 142.1374 - beta: 1.0000e-04\n",
      "Epoch 03963: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31949.7732 - recon_loss: 3.1808e-04 - KL loss: 142.1366 - beta: 1.0000e-04 - val_val_loss: 32385.7773 - val_val_recon_loss: 3.2249e-04 - val_val_KL loss: 136.7717 - val_beta: 1.0000e-04\n",
      "Epoch 3964/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30904.4594 - recon_loss: 3.0766e-04 - KL loss: 138.0263 - beta: 1.0000e-04 - val_val_loss: 30814.3750 - val_val_recon_loss: 3.0674e-04 - val_val_KL loss: 140.7479 - val_beta: 1.0000e-04\n",
      "Epoch 3965/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30178.0746 - recon_loss: 3.0038e-04 - KL loss: 140.4137 - beta: 1.0000e-04 - val_val_loss: 30790.3672 - val_val_recon_loss: 3.0650e-04 - val_val_KL loss: 140.2811 - val_beta: 1.0000e-04\n",
      "Epoch 3966/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30725.3792 - recon_loss: 3.0586e-04 - KL loss: 139.7794 - beta: 1.0000e-04 - val_val_loss: 30460.1152 - val_val_recon_loss: 3.0322e-04 - val_val_KL loss: 138.3659 - val_beta: 1.0000e-04\n",
      "Epoch 3967/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30192.4470 - recon_loss: 3.0053e-04 - KL loss: 139.1493 - beta: 1.0000e-04 - val_val_loss: 30653.1934 - val_val_recon_loss: 3.0512e-04 - val_val_KL loss: 141.1413 - val_beta: 1.0000e-04\n",
      "Epoch 3968/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30437.4002 - recon_loss: 3.0296e-04 - KL loss: 141.3003 - beta: 1.0000e-04 - val_val_loss: 31480.7930 - val_val_recon_loss: 3.1337e-04 - val_val_KL loss: 143.4957 - val_beta: 1.0000e-04\n",
      "Epoch 3969/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30972.1692 - recon_loss: 3.0828e-04 - KL loss: 144.3750 - beta: 1.0000e-04 - val_val_loss: 30693.4980 - val_val_recon_loss: 3.0550e-04 - val_val_KL loss: 143.6693 - val_beta: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3970/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30390.7032 - recon_loss: 3.0246e-04 - KL loss: 144.4160 - beta: 1.0000e-04 - val_val_loss: 31465.9316 - val_val_recon_loss: 3.1319e-04 - val_val_KL loss: 147.2839 - val_beta: 1.0000e-04\n",
      "Epoch 3971/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 30605.4073 - recon_loss: 3.0460e-04 - KL loss: 145.3790 - beta: 1.0000e-04\n",
      "Epoch 03971: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30605.1529 - recon_loss: 3.0460e-04 - KL loss: 145.3785 - beta: 1.0000e-04 - val_val_loss: 30703.7969 - val_val_recon_loss: 3.0558e-04 - val_val_KL loss: 145.9330 - val_beta: 1.0000e-04\n",
      "Epoch 3972/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30368.4104 - recon_loss: 3.0222e-04 - KL loss: 145.9436 - beta: 1.0000e-04 - val_val_loss: 30479.6797 - val_val_recon_loss: 3.0333e-04 - val_val_KL loss: 146.2202 - val_beta: 1.0000e-04\n",
      "Epoch 3973/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30086.1813 - recon_loss: 2.9940e-04 - KL loss: 145.8219 - beta: 1.0000e-04 - val_val_loss: 30348.9707 - val_val_recon_loss: 3.0203e-04 - val_val_KL loss: 145.6610 - val_beta: 1.0000e-04\n",
      "Epoch 3974/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 29719.3657 - recon_loss: 2.9574e-04 - KL loss: 145.0256 - beta: 1.0000e-04 - val_val_loss: 30371.5469 - val_val_recon_loss: 3.0227e-04 - val_val_KL loss: 144.4561 - val_beta: 1.0000e-04\n",
      "Epoch 3975/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30021.3970 - recon_loss: 2.9877e-04 - KL loss: 144.6451 - beta: 1.0000e-04 - val_val_loss: 30501.0645 - val_val_recon_loss: 3.0356e-04 - val_val_KL loss: 145.3878 - val_beta: 1.0000e-04\n",
      "Epoch 3976/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29938.3206 - recon_loss: 2.9793e-04 - KL loss: 144.8317 - beta: 1.0000e-04 - val_val_loss: 30387.0918 - val_val_recon_loss: 3.0242e-04 - val_val_KL loss: 144.8084 - val_beta: 1.0000e-04\n",
      "Epoch 3977/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 29888.4303 - recon_loss: 2.9744e-04 - KL loss: 144.7985 - beta: 1.0000e-04 - val_val_loss: 30277.0625 - val_val_recon_loss: 3.0133e-04 - val_val_KL loss: 144.5319 - val_beta: 1.0000e-04\n",
      "Epoch 3978/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29757.3348 - recon_loss: 2.9613e-04 - KL loss: 144.1090 - beta: 1.0000e-04 - val_val_loss: 30406.0566 - val_val_recon_loss: 3.0260e-04 - val_val_KL loss: 146.0853 - val_beta: 1.0000e-04\n",
      "Epoch 3979/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29590.2329 - recon_loss: 2.9445e-04 - KL loss: 145.3345 - beta: 1.0000e-04 - val_val_loss: 30290.5801 - val_val_recon_loss: 3.0146e-04 - val_val_KL loss: 144.4080 - val_beta: 1.0000e-04\n",
      "Epoch 3980/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29952.2645 - recon_loss: 2.9807e-04 - KL loss: 144.8683 - beta: 1.0000e-04 - val_val_loss: 30123.9492 - val_val_recon_loss: 2.9980e-04 - val_val_KL loss: 144.2715 - val_beta: 1.0000e-04\n",
      "Epoch 3981/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29571.3622 - recon_loss: 2.9428e-04 - KL loss: 143.6043 - beta: 1.0000e-04 - val_val_loss: 30140.1250 - val_val_recon_loss: 2.9996e-04 - val_val_KL loss: 144.2843 - val_beta: 1.0000e-04\n",
      "Epoch 3982/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29877.5939 - recon_loss: 2.9734e-04 - KL loss: 143.9974 - beta: 1.0000e-04 - val_val_loss: 30109.0117 - val_val_recon_loss: 2.9963e-04 - val_val_KL loss: 145.6407 - val_beta: 1.0000e-04\n",
      "Epoch 3983/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 29746.5156 - recon_loss: 2.9601e-04 - KL loss: 145.4140 - beta: 1.0000e-04 - val_val_loss: 30105.7344 - val_val_recon_loss: 2.9961e-04 - val_val_KL loss: 145.1327 - val_beta: 1.0000e-04\n",
      "Epoch 3984/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29694.5624 - recon_loss: 2.9549e-04 - KL loss: 145.4023 - beta: 1.0000e-04 - val_val_loss: 30023.1426 - val_val_recon_loss: 2.9878e-04 - val_val_KL loss: 144.9992 - val_beta: 1.0000e-04\n",
      "Epoch 3985/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29529.2633 - recon_loss: 2.9385e-04 - KL loss: 144.5594 - beta: 1.0000e-04 - val_val_loss: 29900.1074 - val_val_recon_loss: 2.9756e-04 - val_val_KL loss: 144.4674 - val_beta: 1.0000e-04\n",
      "Epoch 3986/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29474.6358 - recon_loss: 2.9330e-04 - KL loss: 144.3885 - beta: 1.0000e-04 - val_val_loss: 29907.5547 - val_val_recon_loss: 2.9762e-04 - val_val_KL loss: 145.2069 - val_beta: 1.0000e-04\n",
      "Epoch 3987/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29494.2591 - recon_loss: 2.9349e-04 - KL loss: 145.1190 - beta: 1.0000e-04 - val_val_loss: 29954.4648 - val_val_recon_loss: 2.9810e-04 - val_val_KL loss: 144.3628 - val_beta: 1.0000e-04\n",
      "Epoch 3988/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29469.7998 - recon_loss: 2.9326e-04 - KL loss: 144.2208 - beta: 1.0000e-04 - val_val_loss: 29822.7402 - val_val_recon_loss: 2.9679e-04 - val_val_KL loss: 144.1563 - val_beta: 1.0000e-04\n",
      "Epoch 3989/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29200.5170 - recon_loss: 2.9057e-04 - KL loss: 143.5524 - beta: 1.0000e-04 - val_val_loss: 29840.7949 - val_val_recon_loss: 2.9697e-04 - val_val_KL loss: 144.0605 - val_beta: 1.0000e-04\n",
      "Epoch 3990/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29438.9004 - recon_loss: 2.9294e-04 - KL loss: 144.6139 - beta: 1.0000e-04 - val_val_loss: 29923.0645 - val_val_recon_loss: 2.9778e-04 - val_val_KL loss: 145.2921 - val_beta: 1.0000e-04\n",
      "Epoch 3991/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29457.5554 - recon_loss: 2.9312e-04 - KL loss: 145.7500 - beta: 1.0000e-04 - val_val_loss: 29939.0977 - val_val_recon_loss: 2.9793e-04 - val_val_KL loss: 146.2998 - val_beta: 1.0000e-04\n",
      "Epoch 3992/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29559.9953 - recon_loss: 2.9415e-04 - KL loss: 145.0640 - beta: 1.0000e-04 - val_val_loss: 29844.3926 - val_val_recon_loss: 2.9699e-04 - val_val_KL loss: 145.7102 - val_beta: 1.0000e-04\n",
      "Epoch 3993/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29060.0321 - recon_loss: 2.8915e-04 - KL loss: 145.2239 - beta: 1.0000e-04 - val_val_loss: 29774.1426 - val_val_recon_loss: 2.9629e-04 - val_val_KL loss: 145.4624 - val_beta: 1.0000e-04\n",
      "Epoch 3994/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29270.8104 - recon_loss: 2.9125e-04 - KL loss: 145.3674 - beta: 1.0000e-04 - val_val_loss: 29777.3301 - val_val_recon_loss: 2.9631e-04 - val_val_KL loss: 145.9894 - val_beta: 1.0000e-04\n",
      "Epoch 3995/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29463.3730 - recon_loss: 2.9318e-04 - KL loss: 145.7462 - beta: 1.0000e-04 - val_val_loss: 29743.4199 - val_val_recon_loss: 2.9598e-04 - val_val_KL loss: 145.4037 - val_beta: 1.0000e-04\n",
      "Epoch 3996/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29181.9782 - recon_loss: 2.9036e-04 - KL loss: 145.6605 - beta: 1.0000e-04 - val_val_loss: 29720.5020 - val_val_recon_loss: 2.9575e-04 - val_val_KL loss: 145.6998 - val_beta: 1.0000e-04\n",
      "Epoch 3997/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29354.4619 - recon_loss: 2.9209e-04 - KL loss: 145.0604 - beta: 1.0000e-04 - val_val_loss: 29749.3203 - val_val_recon_loss: 2.9603e-04 - val_val_KL loss: 146.0604 - val_beta: 1.0000e-04\n",
      "Epoch 3998/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29441.1094 - recon_loss: 2.9295e-04 - KL loss: 146.2769 - beta: 1.0000e-04 - val_val_loss: 29886.9824 - val_val_recon_loss: 2.9740e-04 - val_val_KL loss: 147.2907 - val_beta: 1.0000e-04\n",
      "Epoch 3999/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29507.2187 - recon_loss: 2.9360e-04 - KL loss: 147.2308 - beta: 1.0000e-04 - val_val_loss: 29870.1191 - val_val_recon_loss: 2.9723e-04 - val_val_KL loss: 147.3313 - val_beta: 1.0000e-04\n",
      "Epoch 4000/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29181.1937 - recon_loss: 2.9034e-04 - KL loss: 146.8915 - beta: 1.0000e-04 - val_val_loss: 29768.0801 - val_val_recon_loss: 2.9621e-04 - val_val_KL loss: 147.2242 - val_beta: 1.0000e-04\n",
      "Epoch 4001/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29209.7714 - recon_loss: 2.9064e-04 - KL loss: 145.6180 - beta: 1.0000e-04 - val_val_loss: 29666.2266 - val_val_recon_loss: 2.9520e-04 - val_val_KL loss: 146.5338 - val_beta: 1.0000e-04\n",
      "Epoch 4002/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29174.4734 - recon_loss: 2.9028e-04 - KL loss: 146.6573 - beta: 1.0000e-04 - val_val_loss: 29675.6953 - val_val_recon_loss: 2.9529e-04 - val_val_KL loss: 146.6197 - val_beta: 1.0000e-04\n",
      "Epoch 4003/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 29082.1036 - recon_loss: 2.8935e-04 - KL loss: 147.0450 - beta: 1.0000e-04 - val_val_loss: 29775.8867 - val_val_recon_loss: 2.9629e-04 - val_val_KL loss: 147.3519 - val_beta: 1.0000e-04\n",
      "Epoch 4004/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29234.6926 - recon_loss: 2.9086e-04 - KL loss: 148.2389 - beta: 1.0000e-04 - val_val_loss: 29846.4141 - val_val_recon_loss: 2.9697e-04 - val_val_KL loss: 149.2150 - val_beta: 1.0000e-04\n",
      "Epoch 4005/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29202.0907 - recon_loss: 2.9053e-04 - KL loss: 149.1003 - beta: 1.0000e-04 - val_val_loss: 29875.1641 - val_val_recon_loss: 2.9726e-04 - val_val_KL loss: 148.7558 - val_beta: 1.0000e-04\n",
      "Epoch 4006/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 29112.5966 - recon_loss: 2.8964e-04 - KL loss: 148.2225 - beta: 1.0000e-04\n",
      "Epoch 04006: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29112.6181 - recon_loss: 2.8964e-04 - KL loss: 148.2222 - beta: 1.0000e-04 - val_val_loss: 29736.4199 - val_val_recon_loss: 2.9589e-04 - val_val_KL loss: 147.4700 - val_beta: 1.0000e-04\n",
      "Epoch 4007/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29072.2788 - recon_loss: 2.8925e-04 - KL loss: 147.5855 - beta: 1.0000e-04 - val_val_loss: 29576.7598 - val_val_recon_loss: 2.9429e-04 - val_val_KL loss: 148.1689 - val_beta: 1.0000e-04\n",
      "Epoch 4008/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29078.9905 - recon_loss: 2.8931e-04 - KL loss: 147.4804 - beta: 1.0000e-04 - val_val_loss: 29667.0195 - val_val_recon_loss: 2.9519e-04 - val_val_KL loss: 148.4227 - val_beta: 1.0000e-04\n",
      "Epoch 4009/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29050.4541 - recon_loss: 2.8902e-04 - KL loss: 148.1752 - beta: 1.0000e-04 - val_val_loss: 29609.6094 - val_val_recon_loss: 2.9461e-04 - val_val_KL loss: 148.6277 - val_beta: 1.0000e-04\n",
      "Epoch 4010/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29160.0024 - recon_loss: 2.9011e-04 - KL loss: 149.0536 - beta: 1.0000e-04 - val_val_loss: 29564.3809 - val_val_recon_loss: 2.9416e-04 - val_val_KL loss: 148.8518 - val_beta: 1.0000e-04\n",
      "Epoch 4011/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 28796.7285 - recon_loss: 2.8648e-04 - KL loss: 148.9595 - beta: 1.0000e-04 - val_val_loss: 29579.1250 - val_val_recon_loss: 2.9430e-04 - val_val_KL loss: 148.8053 - val_beta: 1.0000e-04\n",
      "Epoch 4012/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29200.7881 - recon_loss: 2.9052e-04 - KL loss: 148.6037 - beta: 1.0000e-04 - val_val_loss: 29580.8574 - val_val_recon_loss: 2.9432e-04 - val_val_KL loss: 149.2177 - val_beta: 1.0000e-04\n",
      "Epoch 4013/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 28992.6611 - recon_loss: 2.8844e-04 - KL loss: 149.0465 - beta: 1.0000e-04 - val_val_loss: 29523.0195 - val_val_recon_loss: 2.9374e-04 - val_val_KL loss: 148.8427 - val_beta: 1.0000e-04\n",
      "Epoch 4014/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29284.0891 - recon_loss: 2.9135e-04 - KL loss: 148.8763 - beta: 1.0000e-04 - val_val_loss: 29553.3672 - val_val_recon_loss: 2.9404e-04 - val_val_KL loss: 149.4171 - val_beta: 1.0000e-04\n",
      "Epoch 4015/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 28880.2255 - recon_loss: 2.8731e-04 - KL loss: 149.4343 - beta: 1.0000e-04 - val_val_loss: 29561.3984 - val_val_recon_loss: 2.9412e-04 - val_val_KL loss: 149.0214 - val_beta: 1.0000e-04\n",
      "Epoch 4016/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29131.6187 - recon_loss: 2.8982e-04 - KL loss: 149.1417 - beta: 1.0000e-04 - val_val_loss: 29559.4902 - val_val_recon_loss: 2.9410e-04 - val_val_KL loss: 149.4195 - val_beta: 1.0000e-04\n",
      "Epoch 4017/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 28849.6088 - recon_loss: 2.8700e-04 - KL loss: 149.3499 - beta: 1.0000e-04 - val_val_loss: 29540.0430 - val_val_recon_loss: 2.9392e-04 - val_val_KL loss: 148.5454 - val_beta: 1.0000e-04\n",
      "Epoch 4018/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 29002.0594 - recon_loss: 2.8853e-04 - KL loss: 148.5937 - beta: 1.0000e-04\n",
      "Epoch 04018: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29001.9939 - recon_loss: 2.8853e-04 - KL loss: 148.5937 - beta: 1.0000e-04 - val_val_loss: 29552.5605 - val_val_recon_loss: 2.9404e-04 - val_val_KL loss: 148.8103 - val_beta: 1.0000e-04\n",
      "Epoch 4019/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 28781.6352 - recon_loss: 2.8633e-04 - KL loss: 148.7379 - beta: 1.0000e-04 - val_val_loss: 29503.9199 - val_val_recon_loss: 2.9355e-04 - val_val_KL loss: 148.8492 - val_beta: 1.0000e-04\n",
      "Epoch 4020/10000\n",
      "1000/1000 [==============================] - 124s 124ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4021/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4022/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4023/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4024/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04\n",
      "Epoch 04024: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4025/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4026/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4027/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4028/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4029/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04\n",
      "Epoch 04029: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_val_loss', min_delta=0., patience=10, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "\n",
    "for beta in np.logspace(-1,-4,15)[2:]:\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,3e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 756/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 31734.9253 - recon_loss: 3.1504e-04 - KL loss: 231.1730 - beta: 1.0000e-04 - val_val_loss: 32552.8555 - val_val_recon_loss: 3.2328e-04 - val_val_KL loss: 224.8359 - val_beta: 1.0000e-04\n",
      "Epoch 757/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 31422.9057 - recon_loss: 3.1198e-04 - KL loss: 225.1942 - beta: 1.0000e-04 - val_val_loss: 32635.0020 - val_val_recon_loss: 3.2409e-04 - val_val_KL loss: 225.6331 - val_beta: 1.0000e-04\n",
      "Epoch 758/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 32146.5800 - recon_loss: 3.1916e-04 - KL loss: 230.2496 - beta: 1.0000e-04 - val_val_loss: 34566.9961 - val_val_recon_loss: 3.4329e-04 - val_val_KL loss: 237.7053 - val_beta: 1.0000e-04\n",
      "Epoch 759/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 34457.7641 - recon_loss: 3.4222e-04 - KL loss: 235.7530 - beta: 1.0000e-04 - val_val_loss: 33953.9844 - val_val_recon_loss: 3.3723e-04 - val_val_KL loss: 230.8280 - val_beta: 1.0000e-04\n",
      "Epoch 760/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 33973.7853 - recon_loss: 3.3739e-04 - KL loss: 234.4306 - beta: 1.0000e-04 - val_val_loss: 33504.1016 - val_val_recon_loss: 3.3269e-04 - val_val_KL loss: 235.2220 - val_beta: 1.0000e-04\n",
      "Epoch 761/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 33148.8028 - recon_loss: 3.2916e-04 - KL loss: 232.4198 - beta: 1.0000e-04\n",
      "Epoch 00761: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 33148.5909 - recon_loss: 3.2916e-04 - KL loss: 232.4179 - beta: 1.0000e-04 - val_val_loss: 33597.3906 - val_val_recon_loss: 3.3367e-04 - val_val_KL loss: 230.8152 - val_beta: 1.0000e-04\n",
      "Epoch 762/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 32748.2018 - recon_loss: 3.2515e-04 - KL loss: 232.7624 - beta: 1.0000e-04 - val_val_loss: 32675.5820 - val_val_recon_loss: 3.2444e-04 - val_val_KL loss: 231.4207 - val_beta: 1.0000e-04\n",
      "Epoch 763/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32084.4247 - recon_loss: 3.1850e-04 - KL loss: 233.9477 - beta: 1.0000e-04 - val_val_loss: 33216.9258 - val_val_recon_loss: 3.2975e-04 - val_val_KL loss: 241.4691 - val_beta: 1.0000e-04\n",
      "Epoch 764/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32980.4050 - recon_loss: 3.2738e-04 - KL loss: 242.5221 - beta: 1.0000e-04 - val_val_loss: 32560.9824 - val_val_recon_loss: 3.2322e-04 - val_val_KL loss: 239.3627 - val_beta: 1.0000e-04\n",
      "Epoch 765/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32125.8578 - recon_loss: 3.1886e-04 - KL loss: 239.4620 - beta: 1.0000e-04 - val_val_loss: 32372.7109 - val_val_recon_loss: 3.2139e-04 - val_val_KL loss: 233.8444 - val_beta: 1.0000e-04\n",
      "Epoch 766/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 31508.4112 - recon_loss: 3.1272e-04 - KL loss: 236.7888 - beta: 1.0000e-04 - val_val_loss: 32161.9297 - val_val_recon_loss: 3.1923e-04 - val_val_KL loss: 239.4142 - val_beta: 1.0000e-04\n",
      "Epoch 767/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 31453.0612 - recon_loss: 3.1214e-04 - KL loss: 239.3167 - beta: 1.0000e-04 - val_val_loss: 32460.1953 - val_val_recon_loss: 3.2222e-04 - val_val_KL loss: 237.9905 - val_beta: 1.0000e-04\n",
      "Epoch 768/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 32416.1813 - recon_loss: 3.2175e-04 - KL loss: 241.3270 - beta: 1.0000e-04 - val_val_loss: 32403.3848 - val_val_recon_loss: 3.2163e-04 - val_val_KL loss: 239.9623 - val_beta: 1.0000e-04\n",
      "Epoch 769/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 32062.8120 - recon_loss: 3.1820e-04 - KL loss: 242.7523 - beta: 1.0000e-04 - val_val_loss: 31870.1621 - val_val_recon_loss: 3.1633e-04 - val_val_KL loss: 237.1737 - val_beta: 1.0000e-04\n",
      "Epoch 770/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31758.2375 - recon_loss: 3.1520e-04 - KL loss: 238.6980 - beta: 1.0000e-04 - val_val_loss: 31717.4180 - val_val_recon_loss: 3.1479e-04 - val_val_KL loss: 238.1461 - val_beta: 1.0000e-04\n",
      "Epoch 771/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 30949.9720 - recon_loss: 3.0712e-04 - KL loss: 237.5664 - beta: 1.0000e-04 - val_val_loss: 31445.7305 - val_val_recon_loss: 3.1207e-04 - val_val_KL loss: 238.8710 - val_beta: 1.0000e-04\n",
      "Epoch 772/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31135.9858 - recon_loss: 3.0898e-04 - KL loss: 238.0942 - beta: 1.0000e-04 - val_val_loss: 31617.3379 - val_val_recon_loss: 3.1378e-04 - val_val_KL loss: 239.1307 - val_beta: 1.0000e-04\n",
      "Epoch 773/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31102.3219 - recon_loss: 3.0863e-04 - KL loss: 239.6461 - beta: 1.0000e-04 - val_val_loss: 31689.9805 - val_val_recon_loss: 3.1451e-04 - val_val_KL loss: 238.9722 - val_beta: 1.0000e-04\n",
      "Epoch 774/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31162.3538 - recon_loss: 3.0922e-04 - KL loss: 240.4582 - beta: 1.0000e-04 - val_val_loss: 31920.4609 - val_val_recon_loss: 3.1677e-04 - val_val_KL loss: 243.7856 - val_beta: 1.0000e-04\n",
      "Epoch 775/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31809.6359 - recon_loss: 3.1566e-04 - KL loss: 243.5698 - beta: 1.0000e-04 - val_val_loss: 32361.6523 - val_val_recon_loss: 3.2113e-04 - val_val_KL loss: 249.0607 - val_beta: 1.0000e-04\n",
      "Epoch 776/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 32028.7363 - recon_loss: 3.1779e-04 - KL loss: 249.9569 - beta: 1.0000e-04- ETA: 5s - loss: 32029.3446 - recon_loss\n",
      "Epoch 00776: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 32028.7376 - recon_loss: 3.1779e-04 - KL loss: 249.9555 - beta: 1.0000e-04 - val_val_loss: 32466.6250 - val_val_recon_loss: 3.2221e-04 - val_val_KL loss: 246.0588 - val_beta: 1.0000e-04\n",
      "Epoch 777/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31993.3283 - recon_loss: 3.1745e-04 - KL loss: 248.0733 - beta: 1.0000e-04 - val_val_loss: 32325.2559 - val_val_recon_loss: 3.2075e-04 - val_val_KL loss: 250.3663 - val_beta: 1.0000e-04\n",
      "Epoch 778/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31863.4494 - recon_loss: 3.1613e-04 - KL loss: 250.3737 - beta: 1.0000e-04 - val_val_loss: 32090.9746 - val_val_recon_loss: 3.1841e-04 - val_val_KL loss: 250.0829 - val_beta: 1.0000e-04\n",
      "Epoch 779/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31787.1841 - recon_loss: 3.1537e-04 - KL loss: 250.0444 - beta: 1.0000e-04 - val_val_loss: 31917.4824 - val_val_recon_loss: 3.1669e-04 - val_val_KL loss: 248.8754 - val_beta: 1.0000e-04\n",
      "Epoch 780/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 31573.9766 - recon_loss: 3.1324e-04 - KL loss: 250.2026 - beta: 1.0000e-04 - val_val_loss: 31871.2559 - val_val_recon_loss: 3.1623e-04 - val_val_KL loss: 248.6668 - val_beta: 1.0000e-04\n",
      "Epoch 781/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31369.9170 - recon_loss: 3.1121e-04 - KL loss: 249.3442 - beta: 1.0000e-04\n",
      "Epoch 00781: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 31370.0124 - recon_loss: 3.1121e-04 - KL loss: 249.3450 - beta: 1.0000e-04 - val_val_loss: 31931.5078 - val_val_recon_loss: 3.1681e-04 - val_val_KL loss: 250.7457 - val_beta: 1.0000e-04\n",
      "Epoch 781/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 9120.9496 - recon_loss: 3.1488e-04 - KL loss: 232.1327 - beta: 1.8821e-04 - val_val_loss: 9433.7383 - val_val_recon_loss: 3.2735e-04 - val_val_KL loss: 192.9590 - val_beta: 1.8821e-04\n",
      "Epoch 782/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 9294.5237 - recon_loss: 3.2265e-04 - KL loss: 186.2035 - beta: 1.8821e-04 - val_val_loss: 10041.1953 - val_val_recon_loss: 3.4922e-04 - val_val_KL loss: 183.0658 - val_beta: 1.8821e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 783/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 9695.9676 - recon_loss: 3.3708e-04 - KL loss: 180.3865 - beta: 1.8821e-04 - val_val_loss: 9603.8359 - val_val_recon_loss: 3.3405e-04 - val_val_KL loss: 173.7154 - val_beta: 1.8821e-04\n",
      "Epoch 784/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 9490.7684 - recon_loss: 3.3011e-04 - KL loss: 172.1215 - beta: 1.8821e-04 - val_val_loss: 9527.5752 - val_val_recon_loss: 3.3166e-04 - val_val_KL loss: 165.1717 - val_beta: 1.8821e-04\n",
      "Epoch 785/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 9402.9572 - recon_loss: 3.2723e-04 - KL loss: 165.3779 - beta: 1.8821e-04 - val_val_loss: 9534.2842 - val_val_recon_loss: 3.3178e-04 - val_val_KL loss: 168.4199 - val_beta: 1.8821e-04\n",
      "Epoch 786/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 9340.7008 - recon_loss: 3.2503e-04 - KL loss: 165.3658 - beta: 1.8821e-04 - val_val_loss: 9195.4521 - val_val_recon_loss: 3.2021e-04 - val_val_KL loss: 156.0148 - val_beta: 1.8821e-04\n",
      "Epoch 787/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 9055.9824 - recon_loss: 3.1520e-04 - KL loss: 158.2086 - beta: 1.8821e-04 - val_val_loss: 9287.2285 - val_val_recon_loss: 3.2335e-04 - val_val_KL loss: 159.3331 - val_beta: 1.8821e-04\n",
      "Epoch 788/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 9268.3444 - recon_loss: 3.2263e-04 - KL loss: 160.7528 - beta: 1.8821e-04 - val_val_loss: 10014.8652 - val_val_recon_loss: 3.4858e-04 - val_val_KL loss: 174.5871 - val_beta: 1.8821e-04\n",
      "Epoch 789/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 9562.0885 - recon_loss: 3.3287e-04 - KL loss: 165.3954 - beta: 1.8821e-04 - val_val_loss: 9440.2617 - val_val_recon_loss: 3.2891e-04 - val_val_KL loss: 155.4210 - val_beta: 1.8821e-04\n",
      "Epoch 790/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 9229.0630 - recon_loss: 3.2151e-04 - KL loss: 153.1188 - beta: 1.8821e-04 - val_val_loss: 9168.3447 - val_val_recon_loss: 3.1945e-04 - val_val_KL loss: 150.6188 - val_beta: 1.8821e-04\n",
      "Epoch 791/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 8964.7566 - recon_loss: 3.1230e-04 - KL loss: 148.7679 - beta: 1.8821e-04 - val_val_loss: 9144.7852 - val_val_recon_loss: 3.1864e-04 - val_val_KL loss: 149.6818 - val_beta: 1.8821e-04\n",
      "Epoch 792/10000\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 8993.3632 - recon_loss: 3.1328e-04 - KL loss: 149.8152 - beta: 1.8821e-04 - val_val_loss: 9121.7041 - val_val_recon_loss: 3.1798e-04 - val_val_KL loss: 145.2145 - val_beta: 1.8821e-04\n",
      "Epoch 793/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 8935.8022 - recon_loss: 3.1131e-04 - KL loss: 147.7187 - beta: 1.8821e-04 - val_val_loss: 8981.2383 - val_val_recon_loss: 3.1280e-04 - val_val_KL loss: 151.1387 - val_beta: 1.8821e-04\n",
      "Epoch 794/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 8958.7546 - recon_loss: 3.1200e-04 - KL loss: 151.2540 - beta: 1.8821e-04 - val_val_loss: 9037.2734 - val_val_recon_loss: 3.1476e-04 - val_val_KL loss: 151.8327 - val_beta: 1.8821e-04\n",
      "Epoch 795/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 8916.5986 - recon_loss: 3.1057e-04 - KL loss: 149.3989 - beta: 1.8821e-04 - val_val_loss: 8831.5811 - val_val_recon_loss: 3.0769e-04 - val_val_KL loss: 145.8178 - val_beta: 1.8821e-04\n",
      "Epoch 796/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 8857.5242 - recon_loss: 3.0849e-04 - KL loss: 148.9430 - beta: 1.8821e-04 - val_val_loss: 8859.4102 - val_val_recon_loss: 3.0865e-04 - val_val_KL loss: 146.5707 - val_beta: 1.8821e-04\n",
      "Epoch 797/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 8851.8109 - recon_loss: 3.0843e-04 - KL loss: 145.0381 - beta: 1.8821e-04 - val_val_loss: 8873.1660 - val_val_recon_loss: 3.0907e-04 - val_val_KL loss: 148.3136 - val_beta: 1.8821e-04\n",
      "Epoch 798/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 8888.7785 - recon_loss: 3.0963e-04 - KL loss: 148.1650 - beta: 1.8821e-04 - val_val_loss: 8932.6055 - val_val_recon_loss: 3.1114e-04 - val_val_KL loss: 149.4586 - val_beta: 1.8821e-04\n",
      "Epoch 799/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 8780.1541 - recon_loss: 3.0585e-04 - KL loss: 146.2955 - beta: 1.8821e-04 - val_val_loss: 8839.6191 - val_val_recon_loss: 3.0802e-04 - val_val_KL loss: 144.4619 - val_beta: 1.8821e-04\n",
      "Epoch 800/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8715.2011 - recon_loss: 3.0361e-04 - KL loss: 144.6166 - beta: 1.8821e-04 - val_val_loss: 8829.5801 - val_val_recon_loss: 3.0781e-04 - val_val_KL loss: 140.4396 - val_beta: 1.8821e-04\n",
      "Epoch 801/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8932.1605 - recon_loss: 3.1129e-04 - KL loss: 144.7607 - beta: 1.8821e-04 - val_val_loss: 8950.7109 - val_val_recon_loss: 3.1187e-04 - val_val_KL loss: 146.8484 - val_beta: 1.8821e-04\n",
      "Epoch 802/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8819.8925 - recon_loss: 3.0728e-04 - KL loss: 145.7075 - beta: 1.8821e-04 - val_val_loss: 8780.6768 - val_val_recon_loss: 3.0599e-04 - val_val_KL loss: 142.8170 - val_beta: 1.8821e-04\n",
      "Epoch 803/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8734.5982 - recon_loss: 3.0430e-04 - KL loss: 144.4035 - beta: 1.8821e-04 - val_val_loss: 9080.6855 - val_val_recon_loss: 3.1632e-04 - val_val_KL loss: 151.3258 - val_beta: 1.8821e-04\n",
      "Epoch 804/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8786.1809 - recon_loss: 3.0609e-04 - KL loss: 145.5030 - beta: 1.8821e-04 - val_val_loss: 8714.9746 - val_val_recon_loss: 3.0369e-04 - val_val_KL loss: 141.9438 - val_beta: 1.8821e-04\n",
      "Epoch 805/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8660.7822 - recon_loss: 3.0176e-04 - KL loss: 142.3120 - beta: 1.8821e-04 - val_val_loss: 8881.0205 - val_val_recon_loss: 3.0938e-04 - val_val_KL loss: 147.3856 - val_beta: 1.8821e-04\n",
      "Epoch 806/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8644.6820 - recon_loss: 3.0111e-04 - KL loss: 144.4958 - beta: 1.8821e-04 - val_val_loss: 8970.0752 - val_val_recon_loss: 3.1250e-04 - val_val_KL loss: 148.2917 - val_beta: 1.8821e-04\n",
      "Epoch 807/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8783.1169 - recon_loss: 3.0589e-04 - KL loss: 147.9910 - beta: 1.8821e-04 - val_val_loss: 9020.8740 - val_val_recon_loss: 3.1440e-04 - val_val_KL loss: 145.7129 - val_beta: 1.8821e-04\n",
      "Epoch 808/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 9153.7325 - recon_loss: 3.1894e-04 - KL loss: 150.2759 - beta: 1.8821e-04 - val_val_loss: 9606.5527 - val_val_recon_loss: 3.3464e-04 - val_val_KL loss: 159.9084 - val_beta: 1.8821e-04\n",
      "Epoch 809/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9474.2537 - recon_loss: 3.3006e-04 - KL loss: 156.9918 - beta: 1.8821e-04\n",
      "Epoch 00809: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 9474.2864 - recon_loss: 3.3006e-04 - KL loss: 156.9934 - beta: 1.8821e-04 - val_val_loss: 9490.1865 - val_val_recon_loss: 3.3052e-04 - val_val_KL loss: 159.7274 - val_beta: 1.8821e-04\n",
      "Epoch 810/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 9313.6948 - recon_loss: 3.2429e-04 - KL loss: 159.1545 - beta: 1.8821e-04 - val_val_loss: 9012.1953 - val_val_recon_loss: 3.1384e-04 - val_val_KL loss: 152.6553 - val_beta: 1.8821e-04\n",
      "Epoch 811/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 8900.5738 - recon_loss: 3.0983e-04 - KL loss: 154.3698 - beta: 1.8821e-04 - val_val_loss: 8958.0479 - val_val_recon_loss: 3.1171e-04 - val_val_KL loss: 158.7372 - val_beta: 1.8821e-04\n",
      "Epoch 812/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 118s 118ms/step - loss: 8960.3873 - recon_loss: 3.1175e-04 - KL loss: 159.8263 - beta: 1.8821e-04 - val_val_loss: 9002.4404 - val_val_recon_loss: 3.1317e-04 - val_val_KL loss: 161.8598 - val_beta: 1.8821e-04\n",
      "Epoch 813/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 8987.7007 - recon_loss: 3.1270e-04 - KL loss: 160.2957 - beta: 1.8821e-04 - val_val_loss: 9065.2637 - val_val_recon_loss: 3.1541e-04 - val_val_KL loss: 161.4455 - val_beta: 1.8821e-04\n",
      "Epoch 814/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9032.8043 - recon_loss: 3.1419e-04 - KL loss: 163.3644 - beta: 1.8821e-04\n",
      "Epoch 00814: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 9032.8269 - recon_loss: 3.1419e-04 - KL loss: 163.3644 - beta: 1.8821e-04 - val_val_loss: 9055.6562 - val_val_recon_loss: 3.1505e-04 - val_val_KL loss: 161.8716 - val_beta: 1.8821e-04\n",
      "Epoch 814/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2671.1607 - recon_loss: 3.1767e-04 - KL loss: 139.6631 - beta: 3.5424e-04 - val_val_loss: 2647.0181 - val_val_recon_loss: 3.1810e-04 - val_val_KL loss: 112.0914 - val_beta: 3.5424e-04\n",
      "Epoch 815/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2674.1779 - recon_loss: 3.2168e-04 - KL loss: 110.6967 - beta: 3.5424e-04 - val_val_loss: 2592.7842 - val_val_recon_loss: 3.1261e-04 - val_val_KL loss: 101.5751 - val_beta: 3.5424e-04\n",
      "Epoch 816/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2563.1162 - recon_loss: 3.0898e-04 - KL loss: 100.8492 - beta: 3.5424e-04 - val_val_loss: 2552.3596 - val_val_recon_loss: 3.0812e-04 - val_val_KL loss: 96.9504 - val_beta: 3.5424e-04\n",
      "Epoch 817/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2542.2832 - recon_loss: 3.0673e-04 - KL loss: 98.0097 - beta: 3.5424e-04 - val_val_loss: 2560.9094 - val_val_recon_loss: 3.0929e-04 - val_val_KL loss: 96.2304 - val_beta: 3.5424e-04\n",
      "Epoch 818/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2544.3519 - recon_loss: 3.0725e-04 - KL loss: 95.9130 - beta: 3.5424e-04 - val_val_loss: 2538.5266 - val_val_recon_loss: 3.0691e-04 - val_val_KL loss: 92.8125 - val_beta: 3.5424e-04\n",
      "Epoch 819/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2534.1573 - recon_loss: 3.0643e-04 - KL loss: 92.2312 - beta: 3.5424e-04 - val_val_loss: 2551.2197 - val_val_recon_loss: 3.0857e-04 - val_val_KL loss: 92.2178 - val_beta: 3.5424e-04\n",
      "Epoch 820/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2563.2699 - recon_loss: 3.1009e-04 - KL loss: 92.1890 - beta: 3.5424e-04 - val_val_loss: 2594.2832 - val_val_recon_loss: 3.1389e-04 - val_val_KL loss: 92.9342 - val_beta: 3.5424e-04\n",
      "Epoch 821/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2567.9216 - recon_loss: 3.1065e-04 - KL loss: 92.3614 - beta: 3.5424e-04 - val_val_loss: 2597.7798 - val_val_recon_loss: 3.1462e-04 - val_val_KL loss: 90.6049 - val_beta: 3.5424e-04\n",
      "Epoch 822/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2570.6575 - recon_loss: 3.1121e-04 - KL loss: 90.6154 - beta: 3.5424e-04 - val_val_loss: 2571.7642 - val_val_recon_loss: 3.1133e-04 - val_val_KL loss: 90.7621 - val_beta: 3.5424e-04\n",
      "Epoch 823/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2534.3025 - recon_loss: 3.0664e-04 - KL loss: 90.7306 - beta: 3.5424e-04\n",
      "Epoch 00823: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2534.3093 - recon_loss: 3.0664e-04 - KL loss: 90.7293 - beta: 3.5424e-04 - val_val_loss: 2547.3083 - val_val_recon_loss: 3.0871e-04 - val_val_KL loss: 87.2509 - val_beta: 3.5424e-04\n",
      "Epoch 824/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2483.0640 - recon_loss: 3.0049e-04 - KL loss: 88.4429 - beta: 3.5424e-04 - val_val_loss: 2529.3894 - val_val_recon_loss: 3.0633e-04 - val_val_KL loss: 88.2790 - val_beta: 3.5424e-04\n",
      "Epoch 825/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2465.7338 - recon_loss: 2.9822e-04 - KL loss: 89.2184 - beta: 3.5424e-04 - val_val_loss: 2474.5244 - val_val_recon_loss: 2.9957e-04 - val_val_KL loss: 87.2819 - val_beta: 3.5424e-04\n",
      "Epoch 826/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2445.0972 - recon_loss: 2.9572e-04 - KL loss: 88.4850 - beta: 3.5424e-04 - val_val_loss: 2450.6003 - val_val_recon_loss: 2.9653e-04 - val_val_KL loss: 87.6040 - val_beta: 3.5424e-04\n",
      "Epoch 827/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2421.8533 - recon_loss: 2.9290e-04 - KL loss: 87.7475 - beta: 3.5424e-04 - val_val_loss: 2451.1577 - val_val_recon_loss: 2.9672e-04 - val_val_KL loss: 86.6308 - val_beta: 3.5424e-04\n",
      "Epoch 828/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2421.6208 - recon_loss: 2.9291e-04 - KL loss: 87.4040 - beta: 3.5424e-04 - val_val_loss: 2481.9998 - val_val_recon_loss: 3.0053e-04 - val_val_KL loss: 87.0848 - val_beta: 3.5424e-04\n",
      "Epoch 829/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2459.1649 - recon_loss: 2.9756e-04 - KL loss: 87.8888 - beta: 3.5424e-04 - val_val_loss: 2465.0979 - val_val_recon_loss: 2.9834e-04 - val_val_KL loss: 87.6434 - val_beta: 3.5424e-04\n",
      "Epoch 830/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2429.4955 - recon_loss: 2.9389e-04 - KL loss: 87.5017 - beta: 3.5424e-04 - val_val_loss: 2482.7322 - val_val_recon_loss: 3.0041e-04 - val_val_KL loss: 88.7801 - val_beta: 3.5424e-04\n",
      "Epoch 831/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2448.4575 - recon_loss: 2.9611e-04 - KL loss: 88.7575 - beta: 3.5424e-04\n",
      "Epoch 00831: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2448.4378 - recon_loss: 2.9611e-04 - KL loss: 88.7571 - beta: 3.5424e-04 - val_val_loss: 2492.1348 - val_val_recon_loss: 3.0171e-04 - val_val_KL loss: 87.8416 - val_beta: 3.5424e-04\n",
      "Epoch 832/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2458.6369 - recon_loss: 2.9745e-04 - KL loss: 88.2765 - beta: 3.5424e-04 - val_val_loss: 2459.0728 - val_val_recon_loss: 2.9757e-04 - val_val_KL loss: 87.7156 - val_beta: 3.5424e-04\n",
      "Epoch 833/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2425.3032 - recon_loss: 2.9332e-04 - KL loss: 87.8401 - beta: 3.5424e-04 - val_val_loss: 2459.3491 - val_val_recon_loss: 2.9750e-04 - val_val_KL loss: 88.5678 - val_beta: 3.5424e-04\n",
      "Epoch 834/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2421.7421 - recon_loss: 2.9283e-04 - KL loss: 88.1630 - beta: 3.5424e-04 - val_val_loss: 2440.0146 - val_val_recon_loss: 2.9516e-04 - val_val_KL loss: 87.9085 - val_beta: 3.5424e-04\n",
      "Epoch 835/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2397.9272 - recon_loss: 2.8991e-04 - KL loss: 87.6698 - beta: 3.5424e-04 - val_val_loss: 2439.5969 - val_val_recon_loss: 2.9513e-04 - val_val_KL loss: 87.7506 - val_beta: 3.5424e-04\n",
      "Epoch 836/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2409.6742 - recon_loss: 2.9131e-04 - KL loss: 88.2096 - beta: 3.5424e-04 - val_val_loss: 2430.7358 - val_val_recon_loss: 2.9397e-04 - val_val_KL loss: 88.1280 - val_beta: 3.5424e-04\n",
      "Epoch 837/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2392.5366 - recon_loss: 2.8918e-04 - KL loss: 88.0868 - beta: 3.5424e-04 - val_val_loss: 2428.9443 - val_val_recon_loss: 2.9373e-04 - val_val_KL loss: 88.2589 - val_beta: 3.5424e-04\n",
      "Epoch 838/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2372.6026 - recon_loss: 2.8672e-04 - KL loss: 87.7748 - beta: 3.5424e-04 - val_val_loss: 2421.1257 - val_val_recon_loss: 2.9281e-04 - val_val_KL loss: 87.7471 - val_beta: 3.5424e-04\n",
      "Epoch 839/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2377.9861 - recon_loss: 2.8740e-04 - KL loss: 87.7404 - beta: 3.5424e-04 - val_val_loss: 2414.1265 - val_val_recon_loss: 2.9189e-04 - val_val_KL loss: 88.0672 - val_beta: 3.5424e-04\n",
      "Epoch 840/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2384.8154 - recon_loss: 2.8822e-04 - KL loss: 87.9728 - beta: 3.5424e-04 - val_val_loss: 2418.5300 - val_val_recon_loss: 2.9241e-04 - val_val_KL loss: 88.3051 - val_beta: 3.5424e-04\n",
      "Epoch 841/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2394.0915 - recon_loss: 2.8941e-04 - KL loss: 87.8014 - beta: 3.5424e-04 - val_val_loss: 2402.1157 - val_val_recon_loss: 2.9049e-04 - val_val_KL loss: 87.2023 - val_beta: 3.5424e-04\n",
      "Epoch 842/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2357.0481 - recon_loss: 2.8485e-04 - KL loss: 87.1211 - beta: 3.5424e-04 - val_val_loss: 2399.1523 - val_val_recon_loss: 2.9011e-04 - val_val_KL loss: 87.2614 - val_beta: 3.5424e-04\n",
      "Epoch 843/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2386.6119 - recon_loss: 2.8855e-04 - KL loss: 87.1759 - beta: 3.5424e-04 - val_val_loss: 2409.4646 - val_val_recon_loss: 2.9149e-04 - val_val_KL loss: 86.5634 - val_beta: 3.5424e-04\n",
      "Epoch 844/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2363.4540 - recon_loss: 2.8567e-04 - KL loss: 86.9620 - beta: 3.5424e-04 - val_val_loss: 2398.7700 - val_val_recon_loss: 2.9012e-04 - val_val_KL loss: 86.8167 - val_beta: 3.5424e-04\n",
      "Epoch 845/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2339.6671 - recon_loss: 2.8280e-04 - KL loss: 86.0905 - beta: 3.5424e-04 - val_val_loss: 2397.2698 - val_val_recon_loss: 2.8985e-04 - val_val_KL loss: 87.5062 - val_beta: 3.5424e-04\n",
      "Epoch 846/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2366.0219 - recon_loss: 2.8598e-04 - KL loss: 87.0712 - beta: 3.5424e-04 - val_val_loss: 2391.2214 - val_val_recon_loss: 2.8921e-04 - val_val_KL loss: 86.5069 - val_beta: 3.5424e-04\n",
      "Epoch 847/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2353.5599 - recon_loss: 2.8443e-04 - KL loss: 86.9204 - beta: 3.5424e-04 - val_val_loss: 2388.1860 - val_val_recon_loss: 2.8870e-04 - val_val_KL loss: 87.5783 - val_beta: 3.5424e-04\n",
      "Epoch 848/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2366.4228 - recon_loss: 2.8598e-04 - KL loss: 87.4272 - beta: 3.5424e-04 - val_val_loss: 2395.9680 - val_val_recon_loss: 2.8973e-04 - val_val_KL loss: 87.1620 - val_beta: 3.5424e-04\n",
      "Epoch 849/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2376.7562 - recon_loss: 2.8728e-04 - KL loss: 87.4244 - beta: 3.5424e-04 - val_val_loss: 2390.8701 - val_val_recon_loss: 2.8918e-04 - val_val_KL loss: 86.4151 - val_beta: 3.5424e-04\n",
      "Epoch 850/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2357.0765 - recon_loss: 2.8489e-04 - KL loss: 86.8127 - beta: 3.5424e-04 - val_val_loss: 2394.6973 - val_val_recon_loss: 2.8961e-04 - val_val_KL loss: 86.8397 - val_beta: 3.5424e-04\n",
      "Epoch 851/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2335.3009 - recon_loss: 2.8219e-04 - KL loss: 86.5331 - beta: 3.5424e-04 - val_val_loss: 2382.6167 - val_val_recon_loss: 2.8805e-04 - val_val_KL loss: 87.1356 - val_beta: 3.5424e-04\n",
      "Epoch 852/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2348.7810 - recon_loss: 2.8381e-04 - KL loss: 87.1033 - beta: 3.5424e-04 - val_val_loss: 2386.8049 - val_val_recon_loss: 2.8861e-04 - val_val_KL loss: 86.8660 - val_beta: 3.5424e-04\n",
      "Epoch 853/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2351.0511 - recon_loss: 2.8411e-04 - KL loss: 86.9927 - beta: 3.5424e-04 - val_val_loss: 2383.0454 - val_val_recon_loss: 2.8810e-04 - val_val_KL loss: 87.1881 - val_beta: 3.5424e-04\n",
      "Epoch 854/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2330.9636 - recon_loss: 2.8155e-04 - KL loss: 87.2758 - beta: 3.5424e-04 - val_val_loss: 2379.8889 - val_val_recon_loss: 2.8777e-04 - val_val_KL loss: 86.6921 - val_beta: 3.5424e-04\n",
      "Epoch 855/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2355.8078 - recon_loss: 2.8477e-04 - KL loss: 86.4900 - beta: 3.5424e-04 - val_val_loss: 2376.5945 - val_val_recon_loss: 2.8727e-04 - val_val_KL loss: 87.3621 - val_beta: 3.5424e-04\n",
      "Epoch 856/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2357.4793 - recon_loss: 2.8484e-04 - KL loss: 87.5795 - beta: 3.5424e-04 - val_val_loss: 2368.6392 - val_val_recon_loss: 2.8638e-04 - val_val_KL loss: 86.4713 - val_beta: 3.5424e-04\n",
      "Epoch 857/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2344.7898 - recon_loss: 2.8342e-04 - KL loss: 86.2208 - beta: 3.5424e-04 - val_val_loss: 2364.8730 - val_val_recon_loss: 2.8591e-04 - val_val_KL loss: 86.4903 - val_beta: 3.5424e-04\n",
      "Epoch 858/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2362.9388 - recon_loss: 2.8563e-04 - KL loss: 86.7693 - beta: 3.5424e-04 - val_val_loss: 2367.0544 - val_val_recon_loss: 2.8620e-04 - val_val_KL loss: 86.3501 - val_beta: 3.5424e-04\n",
      "Epoch 859/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2341.1269 - recon_loss: 2.8293e-04 - KL loss: 86.4730 - beta: 3.5424e-04 - val_val_loss: 2360.0168 - val_val_recon_loss: 2.8532e-04 - val_val_KL loss: 86.3359 - val_beta: 3.5424e-04\n",
      "Epoch 860/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2331.3244 - recon_loss: 2.8172e-04 - KL loss: 86.3533 - beta: 3.5424e-04 - val_val_loss: 2364.5601 - val_val_recon_loss: 2.8582e-04 - val_val_KL loss: 86.8813 - val_beta: 3.5424e-04\n",
      "Epoch 861/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2335.8178 - recon_loss: 2.8220e-04 - KL loss: 86.9942 - beta: 3.5424e-04 - val_val_loss: 2361.4863 - val_val_recon_loss: 2.8545e-04 - val_val_KL loss: 86.7186 - val_beta: 3.5424e-04\n",
      "Epoch 862/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2327.7069 - recon_loss: 2.8124e-04 - KL loss: 86.4858 - beta: 3.5424e-04 - val_val_loss: 2368.6323 - val_val_recon_loss: 2.8632e-04 - val_val_KL loss: 87.0042 - val_beta: 3.5424e-04\n",
      "Epoch 863/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2335.1988 - recon_loss: 2.8211e-04 - KL loss: 87.0850 - beta: 3.5424e-04 - val_val_loss: 2360.8235 - val_val_recon_loss: 2.8546e-04 - val_val_KL loss: 86.0206 - val_beta: 3.5424e-04\n",
      "Epoch 864/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2329.1875 - recon_loss: 2.8142e-04 - KL loss: 86.5281 - beta: 3.5424e-04 - val_val_loss: 2358.8474 - val_val_recon_loss: 2.8516e-04 - val_val_KL loss: 86.3860 - val_beta: 3.5424e-04\n",
      "Epoch 865/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2331.6838 - recon_loss: 2.8170e-04 - KL loss: 86.8206 - beta: 3.5424e-04 - val_val_loss: 2363.8406 - val_val_recon_loss: 2.8579e-04 - val_val_KL loss: 86.3713 - val_beta: 3.5424e-04\n",
      "Epoch 866/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2335.6829 - recon_loss: 2.8223e-04 - KL loss: 86.6303 - beta: 3.5424e-04 - val_val_loss: 2367.7600 - val_val_recon_loss: 2.8632e-04 - val_val_KL loss: 86.1247 - val_beta: 3.5424e-04\n",
      "Epoch 867/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2329.9298 - recon_loss: 2.8153e-04 - KL loss: 86.4244 - beta: 3.5424e-04 - val_val_loss: 2359.7085 - val_val_recon_loss: 2.8529e-04 - val_val_KL loss: 86.2355 - val_beta: 3.5424e-04\n",
      "Epoch 868/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2307.1230 - recon_loss: 2.7875e-04 - KL loss: 85.8089 - beta: 3.5424e-04 - val_val_loss: 2354.4312 - val_val_recon_loss: 2.8467e-04 - val_val_KL loss: 85.9310 - val_beta: 3.5424e-04\n",
      "Epoch 869/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2331.7553 - recon_loss: 2.8178e-04 - KL loss: 86.2391 - beta: 3.5424e-04 - val_val_loss: 2359.2542 - val_val_recon_loss: 2.8522e-04 - val_val_KL loss: 86.3842 - val_beta: 3.5424e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 870/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2332.3216 - recon_loss: 2.8177e-04 - KL loss: 86.9308 - beta: 3.5424e-04 - val_val_loss: 2361.6855 - val_val_recon_loss: 2.8556e-04 - val_val_KL loss: 86.0360 - val_beta: 3.5424e-04\n",
      "Epoch 871/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2319.6263 - recon_loss: 2.8028e-04 - KL loss: 86.0771 - beta: 3.5424e-04 - val_val_loss: 2358.6091 - val_val_recon_loss: 2.8514e-04 - val_val_KL loss: 86.3215 - val_beta: 3.5424e-04\n",
      "Epoch 872/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2324.0502 - recon_loss: 2.8078e-04 - KL loss: 86.5661 - beta: 3.5424e-04 - val_val_loss: 2358.6531 - val_val_recon_loss: 2.8506e-04 - val_val_KL loss: 86.9938 - val_beta: 3.5424e-04\n",
      "Epoch 873/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2331.8936 - recon_loss: 2.8173e-04 - KL loss: 86.7872 - beta: 3.5424e-04\n",
      "Epoch 00873: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2331.8907 - recon_loss: 2.8173e-04 - KL loss: 86.7873 - beta: 3.5424e-04 - val_val_loss: 2360.2681 - val_val_recon_loss: 2.8538e-04 - val_val_KL loss: 86.0843 - val_beta: 3.5424e-04\n",
      "Epoch 874/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2299.9712 - recon_loss: 2.7780e-04 - KL loss: 86.2036 - beta: 3.5424e-04 - val_val_loss: 2353.1663 - val_val_recon_loss: 2.8444e-04 - val_val_KL loss: 86.4907 - val_beta: 3.5424e-04\n",
      "Epoch 875/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2335.6769 - recon_loss: 2.8219e-04 - KL loss: 86.9556 - beta: 3.5424e-04 - val_val_loss: 2349.8425 - val_val_recon_loss: 2.8402e-04 - val_val_KL loss: 86.5271 - val_beta: 3.5424e-04\n",
      "Epoch 876/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2332.4705 - recon_loss: 2.8177e-04 - KL loss: 87.0940 - beta: 3.5424e-04 - val_val_loss: 2348.8218 - val_val_recon_loss: 2.8387e-04 - val_val_KL loss: 86.6440 - val_beta: 3.5424e-04\n",
      "Epoch 877/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2310.6819 - recon_loss: 2.7907e-04 - KL loss: 86.8005 - beta: 3.5424e-04 - val_val_loss: 2358.0439 - val_val_recon_loss: 2.8502e-04 - val_val_KL loss: 86.7041 - val_beta: 3.5424e-04\n",
      "Epoch 878/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2320.1942 - recon_loss: 2.8024e-04 - KL loss: 86.9743 - beta: 3.5424e-04 - val_val_loss: 2357.9236 - val_val_recon_loss: 2.8500e-04 - val_val_KL loss: 86.8090 - val_beta: 3.5424e-04\n",
      "Epoch 879/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2328.3351 - recon_loss: 2.8124e-04 - KL loss: 87.1297 - beta: 3.5424e-04 - val_val_loss: 2355.1152 - val_val_recon_loss: 2.8465e-04 - val_val_KL loss: 86.7935 - val_beta: 3.5424e-04\n",
      "Epoch 880/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2298.3385 - recon_loss: 2.7754e-04 - KL loss: 86.6119 - beta: 3.5424e-04 - val_val_loss: 2354.8269 - val_val_recon_loss: 2.8461e-04 - val_val_KL loss: 86.7986 - val_beta: 3.5424e-04\n",
      "Epoch 881/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2324.8699 - recon_loss: 2.8085e-04 - KL loss: 86.7852 - beta: 3.5424e-04\n",
      "Epoch 00881: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2324.8711 - recon_loss: 2.8085e-04 - KL loss: 86.7854 - beta: 3.5424e-04 - val_val_loss: 2357.9707 - val_val_recon_loss: 2.8504e-04 - val_val_KL loss: 86.5352 - val_beta: 3.5424e-04\n",
      "Epoch 882/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2300.1724 - recon_loss: 2.7777e-04 - KL loss: 86.6208 - beta: 3.5424e-04 - val_val_loss: 2356.1804 - val_val_recon_loss: 2.8478e-04 - val_val_KL loss: 86.7643 - val_beta: 3.5424e-04\n",
      "Epoch 883/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2317.3035 - recon_loss: 2.7990e-04 - KL loss: 86.8207 - beta: 3.5424e-04 - val_val_loss: 2356.3674 - val_val_recon_loss: 2.8480e-04 - val_val_KL loss: 86.8400 - val_beta: 3.5424e-04\n",
      "Epoch 884/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2308.8723 - recon_loss: 2.7884e-04 - KL loss: 86.8022 - beta: 3.5424e-04 - val_val_loss: 2355.0422 - val_val_recon_loss: 2.8463e-04 - val_val_KL loss: 86.8474 - val_beta: 3.5424e-04\n",
      "Epoch 885/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2296.2479 - recon_loss: 2.7725e-04 - KL loss: 86.8329 - beta: 3.5424e-04 - val_val_loss: 2354.1375 - val_val_recon_loss: 2.8453e-04 - val_val_KL loss: 86.7716 - val_beta: 3.5424e-04\n",
      "Epoch 886/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2310.5669 - recon_loss: 2.7908e-04 - KL loss: 86.5801 - beta: 3.5424e-04\n",
      "Epoch 00886: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2310.5663 - recon_loss: 2.7908e-04 - KL loss: 86.5802 - beta: 3.5424e-04 - val_val_loss: 2352.9355 - val_val_recon_loss: 2.8438e-04 - val_val_KL loss: 86.7297 - val_beta: 3.5424e-04\n",
      "Epoch 886/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 715.9178 - recon_loss: 2.8617e-04 - KL loss: 72.1642 - beta: 6.6673e-04 - val_val_loss: 742.3240 - val_val_recon_loss: 3.0180e-04 - val_val_KL loss: 63.4119 - val_beta: 6.6673e-04\n",
      "Epoch 887/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 722.2794 - recon_loss: 2.9308e-04 - KL loss: 62.9667 - beta: 6.6673e-04 - val_val_loss: 734.4524 - val_val_recon_loss: 2.9953e-04 - val_val_KL loss: 60.6342 - val_beta: 6.6673e-04\n",
      "Epoch 888/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 721.3537 - recon_loss: 2.9414e-04 - KL loss: 59.6723 - beta: 6.6673e-04 - val_val_loss: 727.4402 - val_val_recon_loss: 2.9742e-04 - val_val_KL loss: 58.3781 - val_beta: 6.6673e-04\n",
      "Epoch 889/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 725.0393 - recon_loss: 2.9652e-04 - KL loss: 57.9840 - beta: 6.6673e-04 - val_val_loss: 752.6011 - val_val_recon_loss: 3.0949e-04 - val_val_KL loss: 56.3808 - val_beta: 6.6673e-04\n",
      "Epoch 890/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 736.7233 - recon_loss: 3.0223e-04 - KL loss: 56.8302 - beta: 6.6673e-04 - val_val_loss: 759.3339 - val_val_recon_loss: 3.1303e-04 - val_val_KL loss: 55.1577 - val_beta: 6.6673e-04\n",
      "Epoch 891/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 737.7542 - recon_loss: 3.0304e-04 - KL loss: 56.0397 - beta: 6.6673e-04 - val_val_loss: 737.5136 - val_val_recon_loss: 3.0317e-04 - val_val_KL loss: 55.5188 - val_beta: 6.6673e-04\n",
      "Epoch 892/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 726.2503 - recon_loss: 2.9835e-04 - KL loss: 55.0909 - beta: 6.6673e-04 - val_val_loss: 733.8825 - val_val_recon_loss: 3.0160e-04 - val_val_KL loss: 55.4003 - val_beta: 6.6673e-04\n",
      "Epoch 893/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 719.0835 - recon_loss: 2.9539e-04 - KL loss: 54.5843 - beta: 6.6673e-04\n",
      "Epoch 00893: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 719.0808 - recon_loss: 2.9539e-04 - KL loss: 54.5837 - beta: 6.6673e-04 - val_val_loss: 727.4455 - val_val_recon_loss: 2.9946e-04 - val_val_KL loss: 53.7769 - val_beta: 6.6673e-04\n",
      "Epoch 894/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 708.2153 - recon_loss: 2.9101e-04 - KL loss: 53.5606 - beta: 6.6673e-04 - val_val_loss: 706.9704 - val_val_recon_loss: 2.9036e-04 - val_val_KL loss: 53.7862 - val_beta: 6.6673e-04\n",
      "Epoch 895/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 707.1851 - recon_loss: 2.9042e-04 - KL loss: 53.8534 - beta: 6.6673e-04 - val_val_loss: 707.4611 - val_val_recon_loss: 2.9090e-04 - val_val_KL loss: 53.0627 - val_beta: 6.6673e-04\n",
      "Epoch 896/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 704.9109 - recon_loss: 2.8940e-04 - KL loss: 53.8760 - beta: 6.6673e-04 - val_val_loss: 709.2504 - val_val_recon_loss: 2.9171e-04 - val_val_KL loss: 53.0215 - val_beta: 6.6673e-04\n",
      "Epoch 897/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 695.8292 - recon_loss: 2.8572e-04 - KL loss: 53.0836 - beta: 6.6673e-04 - val_val_loss: 705.1111 - val_val_recon_loss: 2.8997e-04 - val_val_KL loss: 52.8032 - val_beta: 6.6673e-04\n",
      "Epoch 898/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 696.9754 - recon_loss: 2.8632e-04 - KL loss: 52.8795 - beta: 6.6673e-04 - val_val_loss: 702.9266 - val_val_recon_loss: 2.8907e-04 - val_val_KL loss: 52.6333 - val_beta: 6.6673e-04\n",
      "Epoch 899/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 695.8745 - recon_loss: 2.8590e-04 - KL loss: 52.7123 - beta: 6.6673e-04 - val_val_loss: 713.1071 - val_val_recon_loss: 2.9374e-04 - val_val_KL loss: 52.3062 - val_beta: 6.6673e-04\n",
      "Epoch 900/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 697.7516 - recon_loss: 2.8680e-04 - KL loss: 52.5733 - beta: 6.6673e-04 - val_val_loss: 705.8062 - val_val_recon_loss: 2.9022e-04 - val_val_KL loss: 52.9311 - val_beta: 6.6673e-04\n",
      "Epoch 901/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 697.7219 - recon_loss: 2.8660e-04 - KL loss: 52.9953 - beta: 6.6673e-04 - val_val_loss: 705.6599 - val_val_recon_loss: 2.9020e-04 - val_val_KL loss: 52.8309 - val_beta: 6.6673e-04\n",
      "Epoch 902/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 701.4650 - recon_loss: 2.8822e-04 - KL loss: 53.0961 - beta: 6.6673e-04 - val_val_loss: 703.7980 - val_val_recon_loss: 2.8929e-04 - val_val_KL loss: 53.0138 - val_beta: 6.6673e-04\n",
      "Epoch 903/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 698.7612 - recon_loss: 2.8692e-04 - KL loss: 53.3086 - beta: 6.6673e-04\n",
      "Epoch 00903: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 698.7587 - recon_loss: 2.8692e-04 - KL loss: 53.3083 - beta: 6.6673e-04 - val_val_loss: 705.3010 - val_val_recon_loss: 2.9004e-04 - val_val_KL loss: 52.8436 - val_beta: 6.6673e-04\n",
      "Epoch 904/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 694.8902 - recon_loss: 2.8542e-04 - KL loss: 52.8265 - beta: 6.6673e-04 - val_val_loss: 698.1407 - val_val_recon_loss: 2.8683e-04 - val_val_KL loss: 52.8894 - val_beta: 6.6673e-04\n",
      "Epoch 905/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 685.9371 - recon_loss: 2.8147e-04 - KL loss: 52.7435 - beta: 6.6673e-04 - val_val_loss: 696.4523 - val_val_recon_loss: 2.8632e-04 - val_val_KL loss: 52.3634 - val_beta: 6.6673e-04\n",
      "Epoch 906/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 686.7743 - recon_loss: 2.8191e-04 - KL loss: 52.5956 - beta: 6.6673e-04 - val_val_loss: 695.7240 - val_val_recon_loss: 2.8609e-04 - val_val_KL loss: 52.1324 - val_beta: 6.6673e-04\n",
      "Epoch 907/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 689.1829 - recon_loss: 2.8304e-04 - KL loss: 52.4575 - beta: 6.6673e-04 - val_val_loss: 696.3543 - val_val_recon_loss: 2.8634e-04 - val_val_KL loss: 52.2012 - val_beta: 6.6673e-04\n",
      "Epoch 908/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 693.1333 - recon_loss: 2.8466e-04 - KL loss: 52.7590 - beta: 6.6673e-04 - val_val_loss: 695.9769 - val_val_recon_loss: 2.8614e-04 - val_val_KL loss: 52.2896 - val_beta: 6.6673e-04\n",
      "Epoch 909/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 685.4716 - recon_loss: 2.8142e-04 - KL loss: 52.3953 - beta: 6.6673e-04 - val_val_loss: 694.3415 - val_val_recon_loss: 2.8538e-04 - val_val_KL loss: 52.3667 - val_beta: 6.6673e-04\n",
      "Epoch 910/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 687.3507 - recon_loss: 2.8225e-04 - KL loss: 52.4160 - beta: 6.6673e-04 - val_val_loss: 693.6912 - val_val_recon_loss: 2.8506e-04 - val_val_KL loss: 52.4362 - val_beta: 6.6673e-04\n",
      "Epoch 911/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 685.5660 - recon_loss: 2.8144e-04 - KL loss: 52.4491 - beta: 6.6673e-04 - val_val_loss: 693.7411 - val_val_recon_loss: 2.8524e-04 - val_val_KL loss: 52.0671 - val_beta: 6.6673e-04\n",
      "Epoch 912/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 680.9584 - recon_loss: 2.7942e-04 - KL loss: 52.3867 - beta: 6.6673e-04 - val_val_loss: 694.6353 - val_val_recon_loss: 2.8547e-04 - val_val_KL loss: 52.4501 - val_beta: 6.6673e-04\n",
      "Epoch 913/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 679.3100 - recon_loss: 2.7873e-04 - KL loss: 52.2744 - beta: 6.6673e-04 - val_val_loss: 694.3795 - val_val_recon_loss: 2.8544e-04 - val_val_KL loss: 52.2698 - val_beta: 6.6673e-04\n",
      "Epoch 914/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 690.1779 - recon_loss: 2.8341e-04 - KL loss: 52.6195 - beta: 6.6673e-04 - val_val_loss: 696.8678 - val_val_recon_loss: 2.8653e-04 - val_val_KL loss: 52.2940 - val_beta: 6.6673e-04\n",
      "Epoch 915/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 686.6936 - recon_loss: 2.8199e-04 - KL loss: 52.3314 - beta: 6.6673e-04\n",
      "Epoch 00915: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 686.6927 - recon_loss: 2.8199e-04 - KL loss: 52.3314 - beta: 6.6673e-04 - val_val_loss: 696.7360 - val_val_recon_loss: 2.8647e-04 - val_val_KL loss: 52.2943 - val_beta: 6.6673e-04\n",
      "Epoch 916/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 684.8313 - recon_loss: 2.8117e-04 - KL loss: 52.3077 - beta: 6.6673e-04 - val_val_loss: 694.6080 - val_val_recon_loss: 2.8552e-04 - val_val_KL loss: 52.3117 - val_beta: 6.6673e-04\n",
      "Epoch 917/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 686.9765 - recon_loss: 2.8203e-04 - KL loss: 52.5301 - beta: 6.6673e-04 - val_val_loss: 694.9662 - val_val_recon_loss: 2.8561e-04 - val_val_KL loss: 52.4583 - val_beta: 6.6673e-04\n",
      "Epoch 918/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 684.6950 - recon_loss: 2.8099e-04 - KL loss: 52.5790 - beta: 6.6673e-04 - val_val_loss: 696.0246 - val_val_recon_loss: 2.8613e-04 - val_val_KL loss: 52.3497 - val_beta: 6.6673e-04\n",
      "Epoch 919/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 686.7847 - recon_loss: 2.8206e-04 - KL loss: 52.2716 - beta: 6.6673e-04 - val_val_loss: 694.5257 - val_val_recon_loss: 2.8557e-04 - val_val_KL loss: 52.1199 - val_beta: 6.6673e-04\n",
      "Epoch 920/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 684.7459 - recon_loss: 2.8112e-04 - KL loss: 52.3447 - beta: 6.6673e-04\n",
      "Epoch 00920: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 684.7464 - recon_loss: 2.8112e-04 - KL loss: 52.3447 - beta: 6.6673e-04 - val_val_loss: 694.5232 - val_val_recon_loss: 2.8543e-04 - val_val_KL loss: 52.4222 - val_beta: 6.6673e-04\n",
      "Epoch 920/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 228.1611 - recon_loss: 2.8923e-04 - KL loss: 44.4889 - beta: 0.0013 - val_val_loss: 229.7703 - val_val_recon_loss: 2.9896e-04 - val_val_KL loss: 39.9220 - val_beta: 0.0013\n",
      "Epoch 921/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 227.9769 - recon_loss: 2.9625e-04 - KL loss: 39.8438 - beta: 0.0013 - val_val_loss: 230.0675 - val_val_recon_loss: 3.0367e-04 - val_val_KL loss: 37.2242 - val_beta: 0.0013\n",
      "Epoch 922/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 228.7908 - recon_loss: 3.0161e-04 - KL loss: 37.2546 - beta: 0.0013 - val_val_loss: 230.7031 - val_val_recon_loss: 3.0599e-04 - val_val_KL loss: 36.3870 - val_beta: 0.0013\n",
      "Epoch 923/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 225.6735 - recon_loss: 2.9861e-04 - KL loss: 36.0428 - beta: 0.0013 - val_val_loss: 227.1661 - val_val_recon_loss: 3.0204e-04 - val_val_KL loss: 35.3595 - val_beta: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 924/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 227.9508 - recon_loss: 3.0360e-04 - KL loss: 35.1542 - beta: 0.0013 - val_val_loss: 226.2829 - val_val_recon_loss: 3.0218e-04 - val_val_KL loss: 34.3893 - val_beta: 0.0013\n",
      "Epoch 925/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 231.6893 - recon_loss: 3.0988e-04 - KL loss: 34.9044 - beta: 0.0013 - val_val_loss: 230.6033 - val_val_recon_loss: 3.0943e-04 - val_val_KL loss: 34.1046 - val_beta: 0.0013\n",
      "Epoch 926/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 230.2135 - recon_loss: 3.0852e-04 - KL loss: 34.2909 - beta: 0.0013 - val_val_loss: 235.5328 - val_val_recon_loss: 3.1849e-04 - val_val_KL loss: 33.2770 - val_beta: 0.0013\n",
      "Epoch 927/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 225.6491 - recon_loss: 3.0229e-04 - KL loss: 33.6803 - beta: 0.0013 - val_val_loss: 227.6791 - val_val_recon_loss: 3.0565e-04 - val_val_KL loss: 33.5798 - val_beta: 0.0013\n",
      "Epoch 928/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 223.7753 - recon_loss: 2.9977e-04 - KL loss: 33.4102 - beta: 0.0013 - val_val_loss: 224.9149 - val_val_recon_loss: 3.0224e-04 - val_val_KL loss: 32.9812 - val_beta: 0.0013\n",
      "Epoch 929/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 229.6028 - recon_loss: 3.0970e-04 - KL loss: 32.9314 - beta: 0.0013 - val_val_loss: 227.1497 - val_val_recon_loss: 3.0596e-04 - val_val_KL loss: 32.8509 - val_beta: 0.0013\n",
      "Epoch 930/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 222.8938 - recon_loss: 2.9962e-04 - KL loss: 32.6256 - beta: 0.0013 - val_val_loss: 226.0332 - val_val_recon_loss: 3.0512e-04 - val_val_KL loss: 32.2684 - val_beta: 0.0013\n",
      "Epoch 931/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 223.7367 - recon_loss: 3.0121e-04 - KL loss: 32.4548 - beta: 0.0013 - val_val_loss: 232.0871 - val_val_recon_loss: 3.1398e-04 - val_val_KL loss: 32.6987 - val_beta: 0.0013\n",
      "Epoch 932/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 233.7385 - recon_loss: 3.1618e-04 - KL loss: 32.9502 - beta: 0.0013 - val_val_loss: 245.5828 - val_val_recon_loss: 3.3446e-04 - val_val_KL loss: 33.1847 - val_beta: 0.0013\n",
      "Epoch 933/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 239.8349 - recon_loss: 3.2551e-04 - KL loss: 33.1258 - beta: 0.0013\n",
      "Epoch 00933: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 239.8335 - recon_loss: 3.2550e-04 - KL loss: 33.1256 - beta: 0.0013 - val_val_loss: 237.3039 - val_val_recon_loss: 3.2262e-04 - val_val_KL loss: 32.4290 - val_beta: 0.0013\n",
      "Epoch 934/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 230.2299 - recon_loss: 3.1093e-04 - KL loss: 32.7752 - beta: 0.0013 - val_val_loss: 232.1465 - val_val_recon_loss: 3.1370e-04 - val_val_KL loss: 32.9372 - val_beta: 0.0013\n",
      "Epoch 935/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 229.0024 - recon_loss: 3.0894e-04 - KL loss: 32.8117 - beta: 0.0013 - val_val_loss: 233.7412 - val_val_recon_loss: 3.1619e-04 - val_val_KL loss: 32.9460 - val_beta: 0.0013\n",
      "Epoch 936/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 231.1023 - recon_loss: 3.1206e-04 - KL loss: 32.9291 - beta: 0.0013 - val_val_loss: 229.8429 - val_val_recon_loss: 3.1010e-04 - val_val_KL loss: 32.9150 - val_beta: 0.0013\n",
      "Epoch 937/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 229.1739 - recon_loss: 3.0921e-04 - KL loss: 32.8115 - beta: 0.0013 - val_val_loss: 228.8979 - val_val_recon_loss: 3.0936e-04 - val_val_KL loss: 32.4413 - val_beta: 0.0013\n",
      "Epoch 938/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 225.6819 - recon_loss: 3.0459e-04 - KL loss: 32.2537 - beta: 0.0013\n",
      "Epoch 00938: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 225.6808 - recon_loss: 3.0459e-04 - KL loss: 32.2537 - beta: 0.0013 - val_val_loss: 226.6530 - val_val_recon_loss: 3.0617e-04 - val_val_KL loss: 32.2257 - val_beta: 0.0013\n",
      "Epoch 938/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 84.1915 - recon_loss: 3.1828e-04 - KL loss: 27.1337 - beta: 0.0024 - val_val_loss: 83.5073 - val_val_recon_loss: 3.2637e-04 - val_val_KL loss: 24.9992 - val_beta: 0.0024\n",
      "Epoch 939/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 82.5744 - recon_loss: 3.2154e-04 - KL loss: 24.9320 - beta: 0.0024 - val_val_loss: 83.4404 - val_val_recon_loss: 3.3015e-04 - val_val_KL loss: 24.2554 - val_beta: 0.0024\n",
      "Epoch 940/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83.1828 - recon_loss: 3.2883e-04 - KL loss: 24.2349 - beta: 0.0024 - val_val_loss: 84.1479 - val_val_recon_loss: 3.3651e-04 - val_val_KL loss: 23.8225 - val_beta: 0.0024\n",
      "Epoch 941/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 82.5168 - recon_loss: 3.2833e-04 - KL loss: 23.6571 - beta: 0.0024 - val_val_loss: 84.2472 - val_val_recon_loss: 3.3810e-04 - val_val_KL loss: 23.6374 - val_beta: 0.0024\n",
      "Epoch 942/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83.7830 - recon_loss: 3.3648e-04 - KL loss: 23.4629 - beta: 0.0024 - val_val_loss: 83.3915 - val_val_recon_loss: 3.3592e-04 - val_val_KL loss: 23.1714 - val_beta: 0.0024\n",
      "Epoch 943/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83.0746 - recon_loss: 3.3449e-04 - KL loss: 23.1109 - beta: 0.0024 - val_val_loss: 83.0524 - val_val_recon_loss: 3.3600e-04 - val_val_KL loss: 22.8179 - val_beta: 0.0024\n",
      "Epoch 944/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83.3967 - recon_loss: 3.3730e-04 - KL loss: 22.9292 - beta: 0.0024 - val_val_loss: 83.9561 - val_val_recon_loss: 3.4279e-04 - val_val_KL loss: 22.5047 - val_beta: 0.0024\n",
      "Epoch 945/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 82.8413 - recon_loss: 3.3607e-04 - KL loss: 22.5952 - beta: 0.0024 - val_val_loss: 83.9339 - val_val_recon_loss: 3.4256e-04 - val_val_KL loss: 22.5241 - val_beta: 0.0024\n",
      "Epoch 946/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83.7385 - recon_loss: 3.4133e-04 - KL loss: 22.5487 - beta: 0.0024 - val_val_loss: 83.7744 - val_val_recon_loss: 3.4289e-04 - val_val_KL loss: 22.3045 - val_beta: 0.0024\n",
      "Epoch 947/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83.2806 - recon_loss: 3.3953e-04 - KL loss: 22.4143 - beta: 0.0024 - val_val_loss: 82.7921 - val_val_recon_loss: 3.3815e-04 - val_val_KL loss: 22.1724 - val_beta: 0.0024\n",
      "Epoch 948/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 82.5678 - recon_loss: 3.3625e-04 - KL loss: 22.2899 - beta: 0.0024 - val_val_loss: 84.5265 - val_val_recon_loss: 3.4810e-04 - val_val_KL loss: 22.1234 - val_beta: 0.0024\n",
      "Epoch 949/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81.8050 - recon_loss: 3.3331e-04 - KL loss: 22.0540 - beta: 0.0024 - val_val_loss: 82.9227 - val_val_recon_loss: 3.3940e-04 - val_val_KL loss: 22.0795 - val_beta: 0.0024\n",
      "Epoch 950/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81.9319 - recon_loss: 3.3409e-04 - KL loss: 22.0397 - beta: 0.0024 - val_val_loss: 82.6405 - val_val_recon_loss: 3.3847e-04 - val_val_KL loss: 21.9631 - val_beta: 0.0024\n",
      "Epoch 951/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 82.2357 - recon_loss: 3.3421e-04 - KL loss: 22.3225 - beta: 0.0024 - val_val_loss: 82.7133 - val_val_recon_loss: 3.3780e-04 - val_val_KL loss: 22.1570 - val_beta: 0.0024\n",
      "Epoch 952/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 81.9324 - recon_loss: 3.3320e-04 - KL loss: 22.2012 - beta: 0.0024 - val_val_loss: 82.2035 - val_val_recon_loss: 3.3548e-04 - val_val_KL loss: 22.0622 - val_beta: 0.0024\n",
      "Epoch 953/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81.5174 - recon_loss: 3.3246e-04 - KL loss: 21.9189 - beta: 0.0024 - val_val_loss: 81.6732 - val_val_recon_loss: 3.3371e-04 - val_val_KL loss: 21.8493 - val_beta: 0.0024\n",
      "Epoch 954/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.6288 - recon_loss: 3.2765e-04 - KL loss: 21.8918 - beta: 0.0024 - val_val_loss: 80.4265 - val_val_recon_loss: 3.2621e-04 - val_val_KL loss: 21.9486 - val_beta: 0.0024\n",
      "Epoch 955/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.6313 - recon_loss: 3.2784e-04 - KL loss: 21.8606 - beta: 0.0024 - val_val_loss: 80.8029 - val_val_recon_loss: 3.2776e-04 - val_val_KL loss: 22.0465 - val_beta: 0.0024\n",
      "Epoch 956/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.2387 - recon_loss: 3.2641e-04 - KL loss: 21.7250 - beta: 0.0024 - val_val_loss: 80.4581 - val_val_recon_loss: 3.2749e-04 - val_val_KL loss: 21.7493 - val_beta: 0.0024\n",
      "Epoch 957/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81.0763 - recon_loss: 3.3117e-04 - KL loss: 21.7088 - beta: 0.0024 - val_val_loss: 81.0441 - val_val_recon_loss: 3.2961e-04 - val_val_KL loss: 21.9559 - val_beta: 0.0024\n",
      "Epoch 958/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.4641 - recon_loss: 3.2710e-04 - KL loss: 21.8258 - beta: 0.0024 - val_val_loss: 79.6327 - val_val_recon_loss: 3.2231e-04 - val_val_KL loss: 21.8537 - val_beta: 0.0024\n",
      "Epoch 959/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79.2368 - recon_loss: 3.2081e-04 - KL loss: 21.7266 - beta: 0.0024 - val_val_loss: 80.8490 - val_val_recon_loss: 3.2774e-04 - val_val_KL loss: 22.0951 - val_beta: 0.0024\n",
      "Epoch 960/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.6992 - recon_loss: 3.2868e-04 - KL loss: 21.7783 - beta: 0.0024 - val_val_loss: 80.1884 - val_val_recon_loss: 3.2632e-04 - val_val_KL loss: 21.6898 - val_beta: 0.0024\n",
      "Epoch 961/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79.6188 - recon_loss: 3.2336e-04 - KL loss: 21.6514 - beta: 0.0024 - val_val_loss: 79.5009 - val_val_recon_loss: 3.2290e-04 - val_val_KL loss: 21.6150 - val_beta: 0.0024\n",
      "Epoch 962/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78.7738 - recon_loss: 3.1849e-04 - KL loss: 21.6796 - beta: 0.0024 - val_val_loss: 80.5079 - val_val_recon_loss: 3.2855e-04 - val_val_KL loss: 21.6102 - val_beta: 0.0024\n",
      "Epoch 963/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 79.0878 - recon_loss: 3.2065e-04 - KL loss: 21.6058 - beta: 0.0024 - val_val_loss: 80.0961 - val_val_recon_loss: 3.2595e-04 - val_val_KL loss: 21.6636 - val_beta: 0.0024\n",
      "Epoch 964/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.0841 - recon_loss: 3.2602e-04 - KL loss: 21.6394 - beta: 0.0024 - val_val_loss: 79.6458 - val_val_recon_loss: 3.2327e-04 - val_val_KL loss: 21.6943 - val_beta: 0.0024\n",
      "Epoch 965/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79.3461 - recon_loss: 3.2212e-04 - KL loss: 21.6013 - beta: 0.0024 - val_val_loss: 80.7482 - val_val_recon_loss: 3.3105e-04 - val_val_KL loss: 21.4024 - val_beta: 0.0024\n",
      "Epoch 966/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78.9388 - recon_loss: 3.2033e-04 - KL loss: 21.5146 - beta: 0.0024 - val_val_loss: 78.7953 - val_val_recon_loss: 3.1970e-04 - val_val_KL loss: 21.4835 - val_beta: 0.0024\n",
      "Epoch 967/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79.9699 - recon_loss: 3.2559e-04 - KL loss: 21.6027 - beta: 0.0024 - val_val_loss: 81.8386 - val_val_recon_loss: 3.3649e-04 - val_val_KL loss: 21.5176 - val_beta: 0.0024\n",
      "Epoch 968/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.4011 - recon_loss: 3.2787e-04 - KL loss: 21.6250 - beta: 0.0024 - val_val_loss: 83.3156 - val_val_recon_loss: 3.4805e-04 - val_val_KL loss: 20.9213 - val_beta: 0.0024\n",
      "Epoch 969/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79.4864 - recon_loss: 3.2353e-04 - KL loss: 21.4888 - beta: 0.0024 - val_val_loss: 79.4290 - val_val_recon_loss: 3.2314e-04 - val_val_KL loss: 21.5006 - val_beta: 0.0024\n",
      "Epoch 970/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.5435 - recon_loss: 3.2879e-04 - KL loss: 21.6027 - beta: 0.0024 - val_val_loss: 79.6409 - val_val_recon_loss: 3.2334e-04 - val_val_KL loss: 21.6766 - val_beta: 0.0024\n",
      "Epoch 971/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 79.3035 - recon_loss: 3.2200e-04 - KL loss: 21.5797 - beta: 0.0024\n",
      "Epoch 00971: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79.3036 - recon_loss: 3.2200e-04 - KL loss: 21.5797 - beta: 0.0024 - val_val_loss: 80.1811 - val_val_recon_loss: 3.2820e-04 - val_val_KL loss: 21.3448 - val_beta: 0.0024\n",
      "Epoch 972/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78.1254 - recon_loss: 3.1546e-04 - KL loss: 21.5732 - beta: 0.0024 - val_val_loss: 78.3573 - val_val_recon_loss: 3.1696e-04 - val_val_KL loss: 21.5360 - val_beta: 0.0024\n",
      "Epoch 973/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77.5546 - recon_loss: 3.1164e-04 - KL loss: 21.6870 - beta: 0.0024 - val_val_loss: 78.3505 - val_val_recon_loss: 3.1600e-04 - val_val_KL loss: 21.7028 - val_beta: 0.0024\n",
      "Epoch 974/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 77.8825 - recon_loss: 3.1350e-04 - KL loss: 21.6817 - beta: 0.0024 - val_val_loss: 77.9149 - val_val_recon_loss: 3.1395e-04 - val_val_KL loss: 21.6337 - val_beta: 0.0024\n",
      "Epoch 975/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77.7414 - recon_loss: 3.1262e-04 - KL loss: 21.6984 - beta: 0.0024 - val_val_loss: 78.2411 - val_val_recon_loss: 3.1478e-04 - val_val_KL loss: 21.8117 - val_beta: 0.0024\n",
      "Epoch 976/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77.6114 - recon_loss: 3.1188e-04 - KL loss: 21.7011 - beta: 0.0024 - val_val_loss: 78.6104 - val_val_recon_loss: 3.1692e-04 - val_val_KL loss: 21.7961 - val_beta: 0.0024\n",
      "Epoch 977/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77.8030 - recon_loss: 3.1279e-04 - KL loss: 21.7305 - beta: 0.0024 - val_val_loss: 79.2475 - val_val_recon_loss: 3.1939e-04 - val_val_KL loss: 21.9909 - val_beta: 0.0024\n",
      "Epoch 978/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78.0888 - recon_loss: 3.1437e-04 - KL loss: 21.7332 - beta: 0.0024 - val_val_loss: 78.1699 - val_val_recon_loss: 3.1519e-04 - val_val_KL loss: 21.6660 - val_beta: 0.0024\n",
      "Epoch 979/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 77.6397 - recon_loss: 3.1220e-04 - KL loss: 21.6731 - beta: 0.0024\n",
      "Epoch 00979: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77.6400 - recon_loss: 3.1220e-04 - KL loss: 21.6731 - beta: 0.0024 - val_val_loss: 78.8084 - val_val_recon_loss: 3.1848e-04 - val_val_KL loss: 21.7158 - val_beta: 0.0024\n",
      "Epoch 980/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78.6071 - recon_loss: 3.1711e-04 - KL loss: 21.7593 - beta: 0.0024 - val_val_loss: 78.5219 - val_val_recon_loss: 3.1684e-04 - val_val_KL loss: 21.7226 - val_beta: 0.0024\n",
      "Epoch 981/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77.5220 - recon_loss: 3.1153e-04 - KL loss: 21.6743 - beta: 0.0024 - val_val_loss: 79.1969 - val_val_recon_loss: 3.2011e-04 - val_val_KL loss: 21.8118 - val_beta: 0.0024\n",
      "Epoch 982/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 78.3166 - recon_loss: 3.1555e-04 - KL loss: 21.7484 - beta: 0.0024 - val_val_loss: 78.3560 - val_val_recon_loss: 3.1567e-04 - val_val_KL loss: 21.7674 - val_beta: 0.0024\n",
      "Epoch 983/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 78.2462 - recon_loss: 3.1493e-04 - KL loss: 21.7902 - beta: 0.0024 - val_val_loss: 78.6724 - val_val_recon_loss: 3.1762e-04 - val_val_KL loss: 21.7330 - val_beta: 0.0024\n",
      "Epoch 984/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 78.0206 - recon_loss: 3.1383e-04 - KL loss: 21.7613 - beta: 0.0024- ETA: 2s - loss: 78.0232 - recon_loss: 3.1384e-04 - KL loss: \n",
      "Epoch 00984: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78.0205 - recon_loss: 3.1383e-04 - KL loss: 21.7613 - beta: 0.0024 - val_val_loss: 78.4990 - val_val_recon_loss: 3.1672e-04 - val_val_KL loss: 21.7220 - val_beta: 0.0024\n",
      "Epoch 984/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.8631 - recon_loss: 3.7114e-04 - KL loss: 17.0813 - beta: 0.0044 - val_val_loss: 35.6457 - val_val_recon_loss: 3.8449e-04 - val_val_KL loss: 16.1883 - val_beta: 0.0044\n",
      "Epoch 985/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.7908 - recon_loss: 3.8736e-04 - KL loss: 16.1880 - beta: 0.0044 - val_val_loss: 36.2678 - val_val_recon_loss: 3.9783e-04 - val_val_KL loss: 16.1354 - val_beta: 0.0044\n",
      "Epoch 986/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35.9739 - recon_loss: 3.9629e-04 - KL loss: 15.9192 - beta: 0.0044 - val_val_loss: 36.1041 - val_val_recon_loss: 4.0423e-04 - val_val_KL loss: 15.6475 - val_beta: 0.0044\n",
      "Epoch 987/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35.9122 - recon_loss: 4.0033e-04 - KL loss: 15.6529 - beta: 0.0044 - val_val_loss: 35.7915 - val_val_recon_loss: 3.9815e-04 - val_val_KL loss: 15.6427 - val_beta: 0.0044\n",
      "Epoch 988/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.4248 - recon_loss: 3.9259e-04 - KL loss: 15.5576 - beta: 0.0044 - val_val_loss: 35.4701 - val_val_recon_loss: 3.9971e-04 - val_val_KL loss: 15.2423 - val_beta: 0.0044\n",
      "Epoch 989/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35.3714 - recon_loss: 3.9275e-04 - KL loss: 15.4961 - beta: 0.0044 - val_val_loss: 35.3759 - val_val_recon_loss: 3.9536e-04 - val_val_KL loss: 15.3682 - val_beta: 0.0044\n",
      "Epoch 990/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.2319 - recon_loss: 3.9155e-04 - KL loss: 15.4172 - beta: 0.0044 - val_val_loss: 35.5402 - val_val_recon_loss: 3.9843e-04 - val_val_KL loss: 15.3770 - val_beta: 0.0044\n",
      "Epoch 991/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.2926 - recon_loss: 3.9349e-04 - KL loss: 15.3794 - beta: 0.0044 - val_val_loss: 36.2813 - val_val_recon_loss: 4.1613e-04 - val_val_KL loss: 15.2228 - val_beta: 0.0044\n",
      "Epoch 992/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.7832 - recon_loss: 4.0408e-04 - KL loss: 15.3343 - beta: 0.0044 - val_val_loss: 35.6158 - val_val_recon_loss: 4.0175e-04 - val_val_KL loss: 15.2851 - val_beta: 0.0044\n",
      "Epoch 993/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35.4086 - recon_loss: 3.9768e-04 - KL loss: 15.2835 - beta: 0.0044 - val_val_loss: 35.5857 - val_val_recon_loss: 4.0019e-04 - val_val_KL loss: 15.3337 - val_beta: 0.0044\n",
      "Epoch 994/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 35.6631 - recon_loss: 4.0303e-04 - KL loss: 15.2674 - beta: 0.0044\n",
      "Epoch 00994: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35.6632 - recon_loss: 4.0303e-04 - KL loss: 15.2674 - beta: 0.0044 - val_val_loss: 36.3956 - val_val_recon_loss: 4.1364e-04 - val_val_KL loss: 15.4632 - val_beta: 0.0044\n",
      "Epoch 995/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.6664 - recon_loss: 4.0229e-04 - KL loss: 15.3080 - beta: 0.0044 - val_val_loss: 36.2427 - val_val_recon_loss: 4.1497e-04 - val_val_KL loss: 15.2426 - val_beta: 0.0044\n",
      "Epoch 996/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.0632 - recon_loss: 4.1040e-04 - KL loss: 15.2947 - beta: 0.0044 - val_val_loss: 35.4906 - val_val_recon_loss: 3.9928e-04 - val_val_KL loss: 15.2847 - val_beta: 0.0044\n",
      "Epoch 997/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.2798 - recon_loss: 3.9519e-04 - KL loss: 15.2808 - beta: 0.0044 - val_val_loss: 35.4051 - val_val_recon_loss: 3.9762e-04 - val_val_KL loss: 15.2834 - val_beta: 0.0044\n",
      "Epoch 998/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35.3081 - recon_loss: 3.9563e-04 - KL loss: 15.2867 - beta: 0.0044 - val_val_loss: 35.4152 - val_val_recon_loss: 3.9723e-04 - val_val_KL loss: 15.3128 - val_beta: 0.0044\n",
      "Epoch 999/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 35.0767 - recon_loss: 3.9166e-04 - KL loss: 15.2563 - beta: 0.0044\n",
      "Epoch 00999: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 35.0770 - recon_loss: 3.9167e-04 - KL loss: 15.2563 - beta: 0.0044 - val_val_loss: 35.4798 - val_val_recon_loss: 3.9883e-04 - val_val_KL loss: 15.2966 - val_beta: 0.0044\n",
      "Epoch 999/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 19.2205 - recon_loss: 5.5309e-04 - KL loss: 11.3193 - beta: 0.0084 - val_val_loss: 18.8930 - val_val_recon_loss: 5.7338e-04 - val_val_KL loss: 10.7019 - val_beta: 0.0084\n",
      "Epoch 1000/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.8251 - recon_loss: 5.7465e-04 - KL loss: 10.6158 - beta: 0.0084 - val_val_loss: 18.7202 - val_val_recon_loss: 5.8626e-04 - val_val_KL loss: 10.3451 - val_beta: 0.0084\n",
      "Epoch 1001/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.7627 - recon_loss: 5.8258e-04 - KL loss: 10.4401 - beta: 0.0084 - val_val_loss: 18.8025 - val_val_recon_loss: 5.8561e-04 - val_val_KL loss: 10.4366 - val_beta: 0.0084\n",
      "Epoch 1002/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.7726 - recon_loss: 5.9094e-04 - KL loss: 10.3306 - beta: 0.0084 - val_val_loss: 18.7345 - val_val_recon_loss: 5.9019e-04 - val_val_KL loss: 10.3032 - val_beta: 0.0084\n",
      "Epoch 1003/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.6461 - recon_loss: 5.8867e-04 - KL loss: 10.2365 - beta: 0.0084 - val_val_loss: 18.6062 - val_val_recon_loss: 5.8939e-04 - val_val_KL loss: 10.1864 - val_beta: 0.0084\n",
      "Epoch 1004/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.5592 - recon_loss: 5.8767e-04 - KL loss: 10.1640 - beta: 0.0084 - val_val_loss: 18.5815 - val_val_recon_loss: 6.0183e-04 - val_val_KL loss: 9.9839 - val_beta: 0.0084\n",
      "Epoch 1005/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.5225 - recon_loss: 5.9072e-04 - KL loss: 10.0837 - beta: 0.0084 - val_val_loss: 18.5216 - val_val_recon_loss: 5.9508e-04 - val_val_KL loss: 10.0204 - val_beta: 0.0084\n",
      "Epoch 1006/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.4100 - recon_loss: 5.8501e-04 - KL loss: 10.0528 - beta: 0.0084 - val_val_loss: 18.5587 - val_val_recon_loss: 6.0544e-04 - val_val_KL loss: 9.9096 - val_beta: 0.0084\n",
      "Epoch 1007/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.5061 - recon_loss: 5.9698e-04 - KL loss: 9.9779 - beta: 0.0084 - val_val_loss: 18.5933 - val_val_recon_loss: 6.0172e-04 - val_val_KL loss: 9.9973 - val_beta: 0.0084\n",
      "Epoch 1008/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.6100 - recon_loss: 6.0339e-04 - KL loss: 9.9901 - beta: 0.0084 - val_val_loss: 18.5070 - val_val_recon_loss: 6.0547e-04 - val_val_KL loss: 9.8573 - val_beta: 0.0084\n",
      "Epoch 1009/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.5343 - recon_loss: 6.0004e-04 - KL loss: 9.9623 - beta: 0.0084 - val_val_loss: 18.4855 - val_val_recon_loss: 6.0005e-04 - val_val_KL loss: 9.9134 - val_beta: 0.0084\n",
      "Epoch 1010/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.5339 - recon_loss: 6.0098e-04 - KL loss: 9.9485 - beta: 0.0084 - val_val_loss: 18.3901 - val_val_recon_loss: 5.9444e-04 - val_val_KL loss: 9.8981 - val_beta: 0.0084\n",
      "Epoch 1011/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.6841 - recon_loss: 6.1133e-04 - KL loss: 9.9509 - beta: 0.0084 - val_val_loss: 18.4289 - val_val_recon_loss: 5.9941e-04 - val_val_KL loss: 9.8660 - val_beta: 0.0084\n",
      "Epoch 1012/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.4152 - recon_loss: 5.9801e-04 - KL loss: 9.8722 - beta: 0.0084 - val_val_loss: 18.3426 - val_val_recon_loss: 5.9472e-04 - val_val_KL loss: 9.8466 - val_beta: 0.0084\n",
      "Epoch 1013/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.3029 - recon_loss: 5.9467e-04 - KL loss: 9.8077 - beta: 0.0084 - val_val_loss: 18.3486 - val_val_recon_loss: 5.9262e-04 - val_val_KL loss: 9.8826 - val_beta: 0.0084\n",
      "Epoch 1014/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.3977 - recon_loss: 5.9902e-04 - KL loss: 9.8403 - beta: 0.0084 - val_val_loss: 18.2848 - val_val_recon_loss: 5.9376e-04 - val_val_KL loss: 9.8025 - val_beta: 0.0084\n",
      "Epoch 1015/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.2710 - recon_loss: 5.9428e-04 - KL loss: 9.7813 - beta: 0.0084 - val_val_loss: 18.3565 - val_val_recon_loss: 6.0142e-04 - val_val_KL loss: 9.7649 - val_beta: 0.0084\n",
      "Epoch 1016/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.4373 - recon_loss: 6.0381e-04 - KL loss: 9.8115 - beta: 0.0084 - val_val_loss: 18.3930 - val_val_recon_loss: 6.0853e-04 - val_val_KL loss: 9.6996 - val_beta: 0.0084\n",
      "Epoch 1017/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.3028 - recon_loss: 5.9698e-04 - KL loss: 9.7745 - beta: 0.0084 - val_val_loss: 18.2242 - val_val_recon_loss: 5.8418e-04 - val_val_KL loss: 9.8788 - val_beta: 0.0084\n",
      "Epoch 1018/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.3817 - recon_loss: 6.0550e-04 - KL loss: 9.7317 - beta: 0.0084 - val_val_loss: 18.4485 - val_val_recon_loss: 6.0591e-04 - val_val_KL loss: 9.7927 - val_beta: 0.0084\n",
      "Epoch 1019/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.3001 - recon_loss: 5.9958e-04 - KL loss: 9.7347 - beta: 0.0084 - val_val_loss: 18.4300 - val_val_recon_loss: 6.0579e-04 - val_val_KL loss: 9.7759 - val_beta: 0.0084\n",
      "Epoch 1020/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.4066 - recon_loss: 6.0697e-04 - KL loss: 9.7356 - beta: 0.0084 - val_val_loss: 18.7082 - val_val_recon_loss: 6.1843e-04 - val_val_KL loss: 9.8735 - val_beta: 0.0084\n",
      "Epoch 1021/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.6784 - recon_loss: 6.2609e-04 - KL loss: 9.7343 - beta: 0.0084 - val_val_loss: 18.4864 - val_val_recon_loss: 6.1329e-04 - val_val_KL loss: 9.7250 - val_beta: 0.0084\n",
      "Epoch 1022/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18.4064 - recon_loss: 6.0983e-04 - KL loss: 9.6946 - beta: 0.0084\n",
      "Epoch 01022: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.4064 - recon_loss: 6.0983e-04 - KL loss: 9.6946 - beta: 0.0084 - val_val_loss: 18.4343 - val_val_recon_loss: 6.1377e-04 - val_val_KL loss: 9.6661 - val_beta: 0.0084\n",
      "Epoch 1023/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.3285 - recon_loss: 6.0180e-04 - KL loss: 9.7314 - beta: 0.0084 - val_val_loss: 18.4398 - val_val_recon_loss: 6.1100e-04 - val_val_KL loss: 9.7113 - val_beta: 0.0084\n",
      "Epoch 1024/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.3442 - recon_loss: 6.0496e-04 - KL loss: 9.7019 - beta: 0.0084 - val_val_loss: 18.1760 - val_val_recon_loss: 5.9399e-04 - val_val_KL loss: 9.6904 - val_beta: 0.0084\n",
      "Epoch 1025/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.1379 - recon_loss: 5.9062e-04 - KL loss: 9.7005 - beta: 0.0084 - val_val_loss: 18.1378 - val_val_recon_loss: 5.9283e-04 - val_val_KL loss: 9.6687 - val_beta: 0.0084\n",
      "Epoch 1026/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0812 - recon_loss: 5.8676e-04 - KL loss: 9.6990 - beta: 0.0084 - val_val_loss: 18.1450 - val_val_recon_loss: 5.9055e-04 - val_val_KL loss: 9.7086 - val_beta: 0.0084\n",
      "Epoch 1027/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0875 - recon_loss: 5.8799e-04 - KL loss: 9.6876 - beta: 0.0084 - val_val_loss: 18.1862 - val_val_recon_loss: 5.9771e-04 - val_val_KL loss: 9.6475 - val_beta: 0.0084\n",
      "Epoch 1028/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0496 - recon_loss: 5.8446e-04 - KL loss: 9.7001 - beta: 0.0084 - val_val_loss: 18.0578 - val_val_recon_loss: 5.8565e-04 - val_val_KL loss: 9.6913 - val_beta: 0.0084\n",
      "Epoch 1029/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0269 - recon_loss: 5.8449e-04 - KL loss: 9.6771 - beta: 0.0084 - val_val_loss: 18.1201 - val_val_recon_loss: 5.9283e-04 - val_val_KL loss: 9.6511 - val_beta: 0.0084\n",
      "Epoch 1030/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0715 - recon_loss: 5.8534e-04 - KL loss: 9.7095 - beta: 0.0084 - val_val_loss: 18.0231 - val_val_recon_loss: 5.8261e-04 - val_val_KL loss: 9.7000 - val_beta: 0.0084\n",
      "Epoch 1031/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9423 - recon_loss: 5.8025e-04 - KL loss: 9.6530 - beta: 0.0084 - val_val_loss: 18.0529 - val_val_recon_loss: 5.8421e-04 - val_val_KL loss: 9.7071 - val_beta: 0.0084\n",
      "Epoch 1032/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.0085 - recon_loss: 5.8508e-04 - KL loss: 9.6502 - beta: 0.0084 - val_val_loss: 18.0286 - val_val_recon_loss: 5.9033e-04 - val_val_KL loss: 9.5952 - val_beta: 0.0084\n",
      "Epoch 1033/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.1323 - recon_loss: 5.9114e-04 - KL loss: 9.6875 - beta: 0.0084 - val_val_loss: 18.0445 - val_val_recon_loss: 5.8587e-04 - val_val_KL loss: 9.6749 - val_beta: 0.0084\n",
      "Epoch 1034/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0527 - recon_loss: 5.8388e-04 - KL loss: 9.7116 - beta: 0.0084 - val_val_loss: 18.0364 - val_val_recon_loss: 5.8352e-04 - val_val_KL loss: 9.7004 - val_beta: 0.0084\n",
      "Epoch 1035/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18.0267 - recon_loss: 5.8589e-04 - KL loss: 9.6569 - beta: 0.0084\n",
      "Epoch 01035: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0266 - recon_loss: 5.8589e-04 - KL loss: 9.6569 - beta: 0.0084 - val_val_loss: 18.0826 - val_val_recon_loss: 5.9186e-04 - val_val_KL loss: 9.6274 - val_beta: 0.0084\n",
      "Epoch 1036/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.0373 - recon_loss: 5.8634e-04 - KL loss: 9.6610 - beta: 0.0084 - val_val_loss: 17.9900 - val_val_recon_loss: 5.8300e-04 - val_val_KL loss: 9.6615 - val_beta: 0.0084\n",
      "Epoch 1037/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.9621 - recon_loss: 5.8071e-04 - KL loss: 9.6664 - beta: 0.0084 - val_val_loss: 17.9776 - val_val_recon_loss: 5.8145e-04 - val_val_KL loss: 9.6712 - val_beta: 0.0084\n",
      "Epoch 1038/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.9400 - recon_loss: 5.7978e-04 - KL loss: 9.6574 - beta: 0.0084 - val_val_loss: 17.9715 - val_val_recon_loss: 5.8039e-04 - val_val_KL loss: 9.6802 - val_beta: 0.0084\n",
      "Epoch 1039/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.8813 - recon_loss: 5.7684e-04 - KL loss: 9.6407 - beta: 0.0084 - val_val_loss: 17.9857 - val_val_recon_loss: 5.8513e-04 - val_val_KL loss: 9.6267 - val_beta: 0.0084\n",
      "Epoch 1040/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.8829 - recon_loss: 5.7597e-04 - KL loss: 9.6548 - beta: 0.0084 - val_val_loss: 17.9269 - val_val_recon_loss: 5.7811e-04 - val_val_KL loss: 9.6682 - val_beta: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1041/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.9606 - recon_loss: 5.8067e-04 - KL loss: 9.6653 - beta: 0.0084 - val_val_loss: 17.9650 - val_val_recon_loss: 5.8208e-04 - val_val_KL loss: 9.6496 - val_beta: 0.0084\n",
      "Epoch 1042/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0140 - recon_loss: 5.8185e-04 - KL loss: 9.7018 - beta: 0.0084 - val_val_loss: 17.9448 - val_val_recon_loss: 5.8365e-04 - val_val_KL loss: 9.6069 - val_beta: 0.0084\n",
      "Epoch 1043/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9691 - recon_loss: 5.8126e-04 - KL loss: 9.6655 - beta: 0.0084 - val_val_loss: 17.9723 - val_val_recon_loss: 5.8214e-04 - val_val_KL loss: 9.6560 - val_beta: 0.0084\n",
      "Epoch 1044/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9808 - recon_loss: 5.8037e-04 - KL loss: 9.6897 - beta: 0.0084 - val_val_loss: 17.9806 - val_val_recon_loss: 5.8503e-04 - val_val_KL loss: 9.6231 - val_beta: 0.0084\n",
      "Epoch 1045/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17.8799 - recon_loss: 5.7570e-04 - KL loss: 9.6556 - beta: 0.0084\n",
      "Epoch 01045: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.8799 - recon_loss: 5.7571e-04 - KL loss: 9.6556 - beta: 0.0084 - val_val_loss: 17.9767 - val_val_recon_loss: 5.8287e-04 - val_val_KL loss: 9.6499 - val_beta: 0.0084\n",
      "Epoch 1046/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9198 - recon_loss: 5.7790e-04 - KL loss: 9.6641 - beta: 0.0084 - val_val_loss: 17.9294 - val_val_recon_loss: 5.7836e-04 - val_val_KL loss: 9.6670 - val_beta: 0.0084\n",
      "Epoch 1047/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9309 - recon_loss: 5.7859e-04 - KL loss: 9.6653 - beta: 0.0084 - val_val_loss: 17.9538 - val_val_recon_loss: 5.8119e-04 - val_val_KL loss: 9.6511 - val_beta: 0.0084\n",
      "Epoch 1048/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9192 - recon_loss: 5.7756e-04 - KL loss: 9.6684 - beta: 0.0084 - val_val_loss: 17.9279 - val_val_recon_loss: 5.7956e-04 - val_val_KL loss: 9.6484 - val_beta: 0.0084\n",
      "Epoch 1049/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.9215 - recon_loss: 5.7786e-04 - KL loss: 9.6664 - beta: 0.0084 - val_val_loss: 17.9001 - val_val_recon_loss: 5.7592e-04 - val_val_KL loss: 9.6726 - val_beta: 0.0084\n",
      "Epoch 1050/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9490 - recon_loss: 5.7971e-04 - KL loss: 9.6674 - beta: 0.0084 - val_val_loss: 17.9526 - val_val_recon_loss: 5.8088e-04 - val_val_KL loss: 9.6543 - val_beta: 0.0084\n",
      "Epoch 1051/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9074 - recon_loss: 5.7694e-04 - KL loss: 9.6654 - beta: 0.0084 - val_val_loss: 17.9333 - val_val_recon_loss: 5.7911e-04 - val_val_KL loss: 9.6603 - val_beta: 0.0084\n",
      "Epoch 1052/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.8920 - recon_loss: 5.7681e-04 - KL loss: 9.6519 - beta: 0.0084 - val_val_loss: 17.8983 - val_val_recon_loss: 5.7703e-04 - val_val_KL loss: 9.6550 - val_beta: 0.0084\n",
      "Epoch 1053/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9212 - recon_loss: 5.7853e-04 - KL loss: 9.6565 - beta: 0.0084 - val_val_loss: 17.9151 - val_val_recon_loss: 5.7855e-04 - val_val_KL loss: 9.6501 - val_beta: 0.0084\n",
      "Epoch 1054/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9172 - recon_loss: 5.7797e-04 - KL loss: 9.6605 - beta: 0.0084 - val_val_loss: 17.9328 - val_val_recon_loss: 5.8132e-04 - val_val_KL loss: 9.6282 - val_beta: 0.0084\n",
      "Epoch 1055/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9159 - recon_loss: 5.7837e-04 - KL loss: 9.6536 - beta: 0.0084 - val_val_loss: 17.9611 - val_val_recon_loss: 5.8203e-04 - val_val_KL loss: 9.6464 - val_beta: 0.0084\n",
      "Epoch 1056/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.9021 - recon_loss: 5.7701e-04 - KL loss: 9.6591 - beta: 0.0084 - val_val_loss: 17.9365 - val_val_recon_loss: 5.8140e-04 - val_val_KL loss: 9.6308 - val_beta: 0.0084\n",
      "Epoch 1057/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17.9240 - recon_loss: 5.8050e-04 - KL loss: 9.6312 - beta: 0.0084\n",
      "Epoch 01057: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9240 - recon_loss: 5.8049e-04 - KL loss: 9.6312 - beta: 0.0084 - val_val_loss: 17.9413 - val_val_recon_loss: 5.8109e-04 - val_val_KL loss: 9.6400 - val_beta: 0.0084\n",
      "Epoch 1058/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.9415 - recon_loss: 5.8018e-04 - KL loss: 9.6532 - beta: 0.0084 - val_val_loss: 17.9196 - val_val_recon_loss: 5.8018e-04 - val_val_KL loss: 9.6314 - val_beta: 0.0084\n",
      "Epoch 1059/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.8618 - recon_loss: 5.7698e-04 - KL loss: 9.6192 - beta: 0.0084 - val_val_loss: 17.9640 - val_val_recon_loss: 5.8208e-04 - val_val_KL loss: 9.6486 - val_beta: 0.0084\n",
      "Epoch 1060/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9500 - recon_loss: 5.8024e-04 - KL loss: 9.6610 - beta: 0.0084 - val_val_loss: 17.9060 - val_val_recon_loss: 5.7838e-04 - val_val_KL loss: 9.6435 - val_beta: 0.0084\n",
      "Epoch 1061/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.8608 - recon_loss: 5.7575e-04 - KL loss: 9.6358 - beta: 0.0084 - val_val_loss: 17.9134 - val_val_recon_loss: 5.7898e-04 - val_val_KL loss: 9.6422 - val_beta: 0.0084\n",
      "Epoch 1062/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17.8842 - recon_loss: 5.7639e-04 - KL loss: 9.6501 - beta: 0.0084\n",
      "Epoch 01062: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.8842 - recon_loss: 5.7639e-04 - KL loss: 9.6501 - beta: 0.0084 - val_val_loss: 17.9004 - val_val_recon_loss: 5.7787e-04 - val_val_KL loss: 9.6451 - val_beta: 0.0084\n",
      "Epoch 1062/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.6750 - recon_loss: 9.6505e-04 - KL loss: 6.7832 - beta: 0.0157 - val_val_loss: 10.5136 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.2552 - val_beta: 0.0157\n",
      "Epoch 1063/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.5136 - recon_loss: 0.0010 - KL loss: 6.2907 - beta: 0.0157 - val_val_loss: 10.4784 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.1347 - val_beta: 0.0157\n",
      "Epoch 1064/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.5235 - recon_loss: 0.0011 - KL loss: 6.1829 - beta: 0.0157 - val_val_loss: 10.4784 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.0259 - val_beta: 0.0157\n",
      "Epoch 1065/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.5117 - recon_loss: 0.0011 - KL loss: 6.0966 - beta: 0.0157 - val_val_loss: 10.4234 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.0287 - val_beta: 0.0157\n",
      "Epoch 1066/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.4231 - recon_loss: 0.0011 - KL loss: 6.0093 - beta: 0.0157 - val_val_loss: 10.4117 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.9283 - val_beta: 0.0157\n",
      "Epoch 1067/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.4043 - recon_loss: 0.0011 - KL loss: 5.9577 - beta: 0.0157 - val_val_loss: 10.3830 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.9745 - val_beta: 0.0157\n",
      "Epoch 1068/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.4236 - recon_loss: 0.0011 - KL loss: 5.9393 - beta: 0.0157 - val_val_loss: 10.3703 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8350 - val_beta: 0.0157\n",
      "Epoch 1069/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.4152 - recon_loss: 0.0011 - KL loss: 5.9044 - beta: 0.0157 - val_val_loss: 10.3382 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.9118 - val_beta: 0.0157\n",
      "Epoch 1070/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3777 - recon_loss: 0.0011 - KL loss: 5.8551 - beta: 0.0157 - val_val_loss: 10.3631 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8589 - val_beta: 0.0157\n",
      "Epoch 1071/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.3570 - recon_loss: 0.0011 - KL loss: 5.8656 - beta: 0.0157 - val_val_loss: 10.3292 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.9158 - val_beta: 0.0157\n",
      "Epoch 1072/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3651 - recon_loss: 0.0011 - KL loss: 5.8624 - beta: 0.0157 - val_val_loss: 10.3296 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8922 - val_beta: 0.0157\n",
      "Epoch 1073/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.3082 - recon_loss: 0.0011 - KL loss: 5.8305 - beta: 0.0157 - val_val_loss: 10.3686 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8233 - val_beta: 0.0157\n",
      "Epoch 1074/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.3631 - recon_loss: 0.0011 - KL loss: 5.8184 - beta: 0.0157 - val_val_loss: 10.3216 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8198 - val_beta: 0.0157\n",
      "Epoch 1075/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3537 - recon_loss: 0.0011 - KL loss: 5.8098 - beta: 0.0157 - val_val_loss: 10.2657 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7662 - val_beta: 0.0157\n",
      "Epoch 1076/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.2569 - recon_loss: 0.0011 - KL loss: 5.7808 - beta: 0.0157 - val_val_loss: 10.2721 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8395 - val_beta: 0.0157\n",
      "Epoch 1077/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3268 - recon_loss: 0.0011 - KL loss: 5.7940 - beta: 0.0157 - val_val_loss: 10.3405 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8007 - val_beta: 0.0157\n",
      "Epoch 1078/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3039 - recon_loss: 0.0011 - KL loss: 5.8067 - beta: 0.0157 - val_val_loss: 10.4008 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7993 - val_beta: 0.0157\n",
      "Epoch 1079/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3955 - recon_loss: 0.0011 - KL loss: 5.7700 - beta: 0.0157 - val_val_loss: 10.3348 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7618 - val_beta: 0.0157\n",
      "Epoch 1080/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.3082 - recon_loss: 0.0011 - KL loss: 5.7609 - beta: 0.0157\n",
      "Epoch 01080: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3082 - recon_loss: 0.0011 - KL loss: 5.7609 - beta: 0.0157 - val_val_loss: 10.3746 - val_val_recon_loss: 0.0012 - val_val_KL loss: 5.7253 - val_beta: 0.0157\n",
      "Epoch 1081/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2854 - recon_loss: 0.0011 - KL loss: 5.7439 - beta: 0.0157 - val_val_loss: 10.2681 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.6965 - val_beta: 0.0157\n",
      "Epoch 1082/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2607 - recon_loss: 0.0011 - KL loss: 5.7536 - beta: 0.0157 - val_val_loss: 10.2566 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7715 - val_beta: 0.0157\n",
      "Epoch 1083/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2656 - recon_loss: 0.0011 - KL loss: 5.7863 - beta: 0.0157 - val_val_loss: 10.2433 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7403 - val_beta: 0.0157\n",
      "Epoch 1084/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2455 - recon_loss: 0.0011 - KL loss: 5.7487 - beta: 0.0157 - val_val_loss: 10.2338 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7879 - val_beta: 0.0157\n",
      "Epoch 1085/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2700 - recon_loss: 0.0011 - KL loss: 5.7554 - beta: 0.0157 - val_val_loss: 10.2473 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7287 - val_beta: 0.0157\n",
      "Epoch 1086/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2406 - recon_loss: 0.0011 - KL loss: 5.7578 - beta: 0.0157 - val_val_loss: 10.2281 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7521 - val_beta: 0.0157\n",
      "Epoch 1087/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2516 - recon_loss: 0.0011 - KL loss: 5.7622 - beta: 0.0157 - val_val_loss: 10.2330 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7069 - val_beta: 0.0157\n",
      "Epoch 1088/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.2378 - recon_loss: 0.0011 - KL loss: 5.7492 - beta: 0.0157 - val_val_loss: 10.2036 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7730 - val_beta: 0.0157\n",
      "Epoch 1089/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1963 - recon_loss: 0.0011 - KL loss: 5.7428 - beta: 0.0157 - val_val_loss: 10.2094 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7304 - val_beta: 0.0157\n",
      "Epoch 1090/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1844 - recon_loss: 0.0011 - KL loss: 5.7361 - beta: 0.0157 - val_val_loss: 10.2254 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7073 - val_beta: 0.0157\n",
      "Epoch 1091/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.2147 - recon_loss: 0.0011 - KL loss: 5.7434 - beta: 0.0157 - val_val_loss: 10.2136 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7720 - val_beta: 0.0157\n",
      "Epoch 1092/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.2285 - recon_loss: 0.0011 - KL loss: 5.7496 - beta: 0.0157 - val_val_loss: 10.2122 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7675 - val_beta: 0.0157\n",
      "Epoch 1093/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.2075 - recon_loss: 0.0011 - KL loss: 5.7292 - beta: 0.0157\n",
      "Epoch 01093: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.2075 - recon_loss: 0.0011 - KL loss: 5.7292 - beta: 0.0157 - val_val_loss: 10.2334 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8103 - val_beta: 0.0157\n",
      "Epoch 1094/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2417 - recon_loss: 0.0011 - KL loss: 5.7753 - beta: 0.0157 - val_val_loss: 10.1907 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7707 - val_beta: 0.0157\n",
      "Epoch 1095/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.1951 - recon_loss: 0.0011 - KL loss: 5.7517 - beta: 0.0157 - val_val_loss: 10.1902 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7590 - val_beta: 0.0157\n",
      "Epoch 1096/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2059 - recon_loss: 0.0011 - KL loss: 5.7497 - beta: 0.0157 - val_val_loss: 10.1765 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7450 - val_beta: 0.0157\n",
      "Epoch 1097/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1855 - recon_loss: 0.0011 - KL loss: 5.7412 - beta: 0.0157 - val_val_loss: 10.1726 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7246 - val_beta: 0.0157\n",
      "Epoch 1098/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1560 - recon_loss: 0.0011 - KL loss: 5.7248 - beta: 0.0157 - val_val_loss: 10.1753 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7448 - val_beta: 0.0157\n",
      "Epoch 1099/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2197 - recon_loss: 0.0011 - KL loss: 5.7601 - beta: 0.0157 - val_val_loss: 10.1811 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7340 - val_beta: 0.0157\n",
      "Epoch 1100/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.1793 - recon_loss: 0.0011 - KL loss: 5.7440 - beta: 0.0157 - val_val_loss: 10.1584 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7411 - val_beta: 0.0157\n",
      "Epoch 1101/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2172 - recon_loss: 0.0011 - KL loss: 5.7634 - beta: 0.0157 - val_val_loss: 10.1792 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7533 - val_beta: 0.0157\n",
      "Epoch 1102/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1940 - recon_loss: 0.0011 - KL loss: 5.7560 - beta: 0.0157 - val_val_loss: 10.1755 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7252 - val_beta: 0.0157\n",
      "Epoch 1103/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2009 - recon_loss: 0.0011 - KL loss: 5.7645 - beta: 0.0157 - val_val_loss: 10.1877 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7644 - val_beta: 0.0157\n",
      "Epoch 1104/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.1461 - recon_loss: 0.0011 - KL loss: 5.7474 - beta: 0.0157 - val_val_loss: 10.1879 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7408 - val_beta: 0.0157\n",
      "Epoch 1105/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.1661 - recon_loss: 0.0011 - KL loss: 5.7451 - beta: 0.0157\n",
      "Epoch 01105: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.1661 - recon_loss: 0.0011 - KL loss: 5.7451 - beta: 0.0157 - val_val_loss: 10.1944 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7573 - val_beta: 0.0157\n",
      "Epoch 1106/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1794 - recon_loss: 0.0011 - KL loss: 5.7459 - beta: 0.0157 - val_val_loss: 10.1838 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7212 - val_beta: 0.0157\n",
      "Epoch 1107/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1934 - recon_loss: 0.0011 - KL loss: 5.7428 - beta: 0.0157 - val_val_loss: 10.1728 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7254 - val_beta: 0.0157\n",
      "Epoch 1108/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.1570 - recon_loss: 0.0011 - KL loss: 5.7351 - beta: 0.0157 - val_val_loss: 10.1654 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7542 - val_beta: 0.0157\n",
      "Epoch 1109/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1858 - recon_loss: 0.0011 - KL loss: 5.7579 - beta: 0.0157 - val_val_loss: 10.1679 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7538 - val_beta: 0.0157\n",
      "Epoch 1110/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.1801 - recon_loss: 0.0011 - KL loss: 5.7605 - beta: 0.0157\n",
      "Epoch 01110: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1801 - recon_loss: 0.0011 - KL loss: 5.7605 - beta: 0.0157 - val_val_loss: 10.1817 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7651 - val_beta: 0.0157\n",
      "Epoch 1110/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 6.1320 - recon_loss: 0.0020 - KL loss: 3.8088 - beta: 0.0296 - val_val_loss: 5.9858 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.5274 - val_beta: 0.0296\n",
      "Epoch 1111/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.9788 - recon_loss: 0.0022 - KL loss: 3.4214 - beta: 0.0296 - val_val_loss: 5.9426 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.3886 - val_beta: 0.0296\n",
      "Epoch 1112/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.9359 - recon_loss: 0.0023 - KL loss: 3.3500 - beta: 0.0296 - val_val_loss: 5.9142 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.3092 - val_beta: 0.0296\n",
      "Epoch 1113/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.9282 - recon_loss: 0.0023 - KL loss: 3.3156 - beta: 0.0296 - val_val_loss: 5.8860 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2845 - val_beta: 0.0296\n",
      "Epoch 1114/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8867 - recon_loss: 0.0023 - KL loss: 3.2782 - beta: 0.0296 - val_val_loss: 5.8935 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2820 - val_beta: 0.0296\n",
      "Epoch 1115/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5.8864 - recon_loss: 0.0023 - KL loss: 3.2761 - beta: 0.0296 - val_val_loss: 5.8968 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2324 - val_beta: 0.0296\n",
      "Epoch 1116/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.8876 - recon_loss: 0.0023 - KL loss: 3.2569 - beta: 0.0296 - val_val_loss: 5.8578 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2590 - val_beta: 0.0296\n",
      "Epoch 1117/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8545 - recon_loss: 0.0023 - KL loss: 3.2472 - beta: 0.0296 - val_val_loss: 5.8519 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2000 - val_beta: 0.0296\n",
      "Epoch 1118/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8461 - recon_loss: 0.0023 - KL loss: 3.2478 - beta: 0.0296 - val_val_loss: 5.8446 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2186 - val_beta: 0.0296\n",
      "Epoch 1119/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8567 - recon_loss: 0.0023 - KL loss: 3.2542 - beta: 0.0296 - val_val_loss: 5.8637 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2201 - val_beta: 0.0296\n",
      "Epoch 1120/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8911 - recon_loss: 0.0023 - KL loss: 3.2710 - beta: 0.0296 - val_val_loss: 5.8964 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2881 - val_beta: 0.0296\n",
      "Epoch 1121/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.8685 - recon_loss: 0.0023 - KL loss: 3.2708 - beta: 0.0296 - val_val_loss: 5.8684 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2160 - val_beta: 0.0296\n",
      "Epoch 1122/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8779 - recon_loss: 0.0023 - KL loss: 3.2671 - beta: 0.0296 - val_val_loss: 5.9439 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.2234 - val_beta: 0.0296\n",
      "Epoch 1123/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.9210 - recon_loss: 0.0023 - KL loss: 3.2593 - beta: 0.0296\n",
      "Epoch 01123: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.9210 - recon_loss: 0.0023 - KL loss: 3.2593 - beta: 0.0296 - val_val_loss: 5.8969 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2354 - val_beta: 0.0296\n",
      "Epoch 1124/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8572 - recon_loss: 0.0023 - KL loss: 3.2724 - beta: 0.0296 - val_val_loss: 5.8397 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2697 - val_beta: 0.0296\n",
      "Epoch 1125/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8433 - recon_loss: 0.0022 - KL loss: 3.2826 - beta: 0.0296 - val_val_loss: 5.8264 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.2844 - val_beta: 0.0296\n",
      "Epoch 1126/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8401 - recon_loss: 0.0023 - KL loss: 3.2706 - beta: 0.0296 - val_val_loss: 5.8501 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2776 - val_beta: 0.0296\n",
      "Epoch 1127/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8414 - recon_loss: 0.0023 - KL loss: 3.2748 - beta: 0.0296 - val_val_loss: 5.8437 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2593 - val_beta: 0.0296\n",
      "Epoch 1128/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8399 - recon_loss: 0.0023 - KL loss: 3.2658 - beta: 0.0296 - val_val_loss: 5.8432 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2563 - val_beta: 0.0296\n",
      "Epoch 1129/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8254 - recon_loss: 0.0022 - KL loss: 3.2702 - beta: 0.0296 - val_val_loss: 5.8330 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.2845 - val_beta: 0.0296\n",
      "Epoch 1130/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8209 - recon_loss: 0.0022 - KL loss: 3.2641 - beta: 0.0296 - val_val_loss: 5.8206 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2472 - val_beta: 0.0296\n",
      "Epoch 1131/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8372 - recon_loss: 0.0023 - KL loss: 3.2654 - beta: 0.0296 - val_val_loss: 5.8258 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2438 - val_beta: 0.0296\n",
      "Epoch 1132/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5.8400 - recon_loss: 0.0023 - KL loss: 3.2708 - beta: 0.0296 - val_val_loss: 5.8273 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.2875 - val_beta: 0.0296\n",
      "Epoch 1133/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8428 - recon_loss: 0.0023 - KL loss: 3.2722 - beta: 0.0296 - val_val_loss: 5.8261 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.2656 - val_beta: 0.0296\n",
      "Epoch 1134/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8413 - recon_loss: 0.0023 - KL loss: 3.2790 - beta: 0.0296 - val_val_loss: 5.8252 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.3059 - val_beta: 0.0296\n",
      "Epoch 1135/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.8188 - recon_loss: 0.0022 - KL loss: 3.2723 - beta: 0.0296- ETA: 7s -\n",
      "Epoch 01135: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8188 - recon_loss: 0.0022 - KL loss: 3.2723 - beta: 0.0296 - val_val_loss: 5.8607 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2833 - val_beta: 0.0296\n",
      "Epoch 1136/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8553 - recon_loss: 0.0023 - KL loss: 3.2751 - beta: 0.0296 - val_val_loss: 5.8330 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.2851 - val_beta: 0.0296\n",
      "Epoch 1137/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8349 - recon_loss: 0.0023 - KL loss: 3.2654 - beta: 0.0296 - val_val_loss: 5.8435 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2708 - val_beta: 0.0296\n",
      "Epoch 1138/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8473 - recon_loss: 0.0023 - KL loss: 3.2686 - beta: 0.0296 - val_val_loss: 5.8391 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2577 - val_beta: 0.0296\n",
      "Epoch 1139/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5.8286 - recon_loss: 0.0023 - KL loss: 3.2625 - beta: 0.0296 - val_val_loss: 5.8508 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2701 - val_beta: 0.0296\n",
      "Epoch 1140/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.8405 - recon_loss: 0.0023 - KL loss: 3.2716 - beta: 0.0296\n",
      "Epoch 01140: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8405 - recon_loss: 0.0023 - KL loss: 3.2716 - beta: 0.0296 - val_val_loss: 5.8417 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2773 - val_beta: 0.0296\n",
      "Epoch 1140/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 3.3939 - recon_loss: 0.0050 - KL loss: 1.7893 - beta: 0.0558 - val_val_loss: 3.3057 - val_val_recon_loss: 0.0059 - val_val_KL loss: 1.4041 - val_beta: 0.0558\n",
      "Epoch 1141/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 3.3140 - recon_loss: 0.0059 - KL loss: 1.4062 - beta: 0.0558 - val_val_loss: 3.2986 - val_val_recon_loss: 0.0060 - val_val_KL loss: 1.3574 - val_beta: 0.0558\n",
      "Epoch 1142/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2971 - recon_loss: 0.0062 - KL loss: 1.2898 - beta: 0.0558 - val_val_loss: 3.2919 - val_val_recon_loss: 0.0065 - val_val_KL loss: 1.2163 - val_beta: 0.0558\n",
      "Epoch 1143/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2872 - recon_loss: 0.0065 - KL loss: 1.2024 - beta: 0.0558 - val_val_loss: 3.2975 - val_val_recon_loss: 0.0067 - val_val_KL loss: 1.1597 - val_beta: 0.0558\n",
      "Epoch 1144/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2824 - recon_loss: 0.0067 - KL loss: 1.1303 - beta: 0.0558 - val_val_loss: 3.2864 - val_val_recon_loss: 0.0068 - val_val_KL loss: 1.1024 - val_beta: 0.0558\n",
      "Epoch 1145/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2817 - recon_loss: 0.0069 - KL loss: 1.0621 - beta: 0.0558 - val_val_loss: 3.2921 - val_val_recon_loss: 0.0070 - val_val_KL loss: 1.0371 - val_beta: 0.0558\n",
      "Epoch 1146/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2927 - recon_loss: 0.0071 - KL loss: 1.0209 - beta: 0.0558 - val_val_loss: 3.2713 - val_val_recon_loss: 0.0068 - val_val_KL loss: 1.0840 - val_beta: 0.0558\n",
      "Epoch 1147/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2783 - recon_loss: 0.0070 - KL loss: 1.0336 - beta: 0.0558 - val_val_loss: 3.2769 - val_val_recon_loss: 0.0070 - val_val_KL loss: 1.0408 - val_beta: 0.0558\n",
      "Epoch 1148/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2764 - recon_loss: 0.0071 - KL loss: 0.9977 - beta: 0.0558 - val_val_loss: 3.2837 - val_val_recon_loss: 0.0072 - val_val_KL loss: 0.9594 - val_beta: 0.0558\n",
      "Epoch 1149/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2811 - recon_loss: 0.0072 - KL loss: 0.9668 - beta: 0.0558 - val_val_loss: 3.2675 - val_val_recon_loss: 0.0073 - val_val_KL loss: 0.9373 - val_beta: 0.0558\n",
      "Epoch 1150/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2729 - recon_loss: 0.0072 - KL loss: 0.9435 - beta: 0.0558 - val_val_loss: 3.2491 - val_val_recon_loss: 0.0072 - val_val_KL loss: 0.9401 - val_beta: 0.0558\n",
      "Epoch 1151/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2726 - recon_loss: 0.0073 - KL loss: 0.9246 - beta: 0.0558 - val_val_loss: 3.2789 - val_val_recon_loss: 0.0073 - val_val_KL loss: 0.9387 - val_beta: 0.0558\n",
      "Epoch 1152/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2708 - recon_loss: 0.0073 - KL loss: 0.9309 - beta: 0.0558 - val_val_loss: 3.2620 - val_val_recon_loss: 0.0073 - val_val_KL loss: 0.9052 - val_beta: 0.0558\n",
      "Epoch 1153/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2652 - recon_loss: 0.0074 - KL loss: 0.8921 - beta: 0.0558 - val_val_loss: 3.2707 - val_val_recon_loss: 0.0075 - val_val_KL loss: 0.8484 - val_beta: 0.0558\n",
      "Epoch 1154/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2724 - recon_loss: 0.0075 - KL loss: 0.8650 - beta: 0.0558 - val_val_loss: 3.2729 - val_val_recon_loss: 0.0075 - val_val_KL loss: 0.8783 - val_beta: 0.0558\n",
      "Epoch 1155/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3.2673 - recon_loss: 0.0075 - KL loss: 0.8624 - beta: 0.0558\n",
      "Epoch 01155: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2673 - recon_loss: 0.0075 - KL loss: 0.8624 - beta: 0.0558 - val_val_loss: 3.2740 - val_val_recon_loss: 0.0076 - val_val_KL loss: 0.8459 - val_beta: 0.0558\n",
      "Epoch 1156/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2594 - recon_loss: 0.0076 - KL loss: 0.8259 - beta: 0.0558 - val_val_loss: 3.2503 - val_val_recon_loss: 0.0075 - val_val_KL loss: 0.8274 - val_beta: 0.0558\n",
      "Epoch 1157/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2698 - recon_loss: 0.0076 - KL loss: 0.8305 - beta: 0.0558 - val_val_loss: 3.2673 - val_val_recon_loss: 0.0076 - val_val_KL loss: 0.8184 - val_beta: 0.0558\n",
      "Epoch 1158/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2638 - recon_loss: 0.0076 - KL loss: 0.8157 - beta: 0.0558 - val_val_loss: 3.2659 - val_val_recon_loss: 0.0077 - val_val_KL loss: 0.7892 - val_beta: 0.0558\n",
      "Epoch 1159/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2752 - recon_loss: 0.0077 - KL loss: 0.7914 - beta: 0.0558 - val_val_loss: 3.2587 - val_val_recon_loss: 0.0077 - val_val_KL loss: 0.7859 - val_beta: 0.0558\n",
      "Epoch 1160/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3.2595 - recon_loss: 0.0077 - KL loss: 0.7907 - beta: 0.0558\n",
      "Epoch 01160: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 3.2595 - recon_loss: 0.0077 - KL loss: 0.7907 - beta: 0.0558 - val_val_loss: 3.2576 - val_val_recon_loss: 0.0078 - val_val_KL loss: 0.7635 - val_beta: 0.0558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1160/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 1.0724 - recon_loss: 0.0105 - KL loss: 0.1192 - beta: 0.1050 - val_val_loss: 0.9804 - val_val_recon_loss: 0.0107 - val_val_KL loss: 0.0054 - val_beta: 0.1050\n",
      "Epoch 1161/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9781 - recon_loss: 0.0107 - KL loss: 0.0041 - beta: 0.1050 - val_val_loss: 0.9728 - val_val_recon_loss: 0.0107 - val_val_KL loss: 0.0018 - val_beta: 0.1050\n",
      "Epoch 1162/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9739 - recon_loss: 0.0107 - KL loss: 0.0015 - beta: 0.1050 - val_val_loss: 0.9705 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.0647e-04 - val_beta: 0.1050\n",
      "Epoch 1163/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9680 - recon_loss: 0.0107 - KL loss: 8.4354e-04 - beta: 0.1050 - val_val_loss: 0.9689 - val_val_recon_loss: 0.0107 - val_val_KL loss: 6.7246e-04 - val_beta: 0.1050\n",
      "Epoch 1164/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9696 - recon_loss: 0.0107 - KL loss: 5.8475e-04 - beta: 0.1050 - val_val_loss: 0.9672 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.4991e-04 - val_beta: 0.1050\n",
      "Epoch 1165/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9690 - recon_loss: 0.0107 - KL loss: 3.9937e-04 - beta: 0.1050 - val_val_loss: 0.9684 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.0935e-04 - val_beta: 0.1050\n",
      "Epoch 1166/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9676 - recon_loss: 0.0107 - KL loss: 3.3296e-04 - beta: 0.1050 - val_val_loss: 0.9678 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.5092e-04 - val_beta: 0.1050\n",
      "Epoch 1167/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9676 - recon_loss: 0.0107 - KL loss: 2.5869e-04 - beta: 0.1050 - val_val_loss: 0.9682 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.4904e-04 - val_beta: 0.1050\n",
      "Epoch 1168/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9690 - recon_loss: 0.0107 - KL loss: 2.3597e-04 - beta: 0.1050 - val_val_loss: 0.9683 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.9338e-04 - val_beta: 0.1050\n",
      "Epoch 1169/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.9697 - recon_loss: 0.0107 - KL loss: 2.0757e-04 - beta: 0.1050\n",
      "Epoch 01169: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9697 - recon_loss: 0.0107 - KL loss: 2.0755e-04 - beta: 0.1050 - val_val_loss: 0.9683 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5272e-04 - val_beta: 0.1050\n",
      "Epoch 1170/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9682 - recon_loss: 0.0107 - KL loss: 1.3385e-04 - beta: 0.1050 - val_val_loss: 0.9686 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2216e-04 - val_beta: 0.1050\n",
      "Epoch 1171/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9681 - recon_loss: 0.0107 - KL loss: 1.2354e-04 - beta: 0.1050 - val_val_loss: 0.9690 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1060e-04 - val_beta: 0.1050\n",
      "Epoch 1172/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9700 - recon_loss: 0.0107 - KL loss: 1.1279e-04 - beta: 0.1050 - val_val_loss: 0.9685 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.8526e-05 - val_beta: 0.1050\n",
      "Epoch 1173/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9689 - recon_loss: 0.0107 - KL loss: 1.0120e-04 - beta: 0.1050 - val_val_loss: 0.9687 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.0294e-04 - val_beta: 0.1050\n",
      "Epoch 1174/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.9688 - recon_loss: 0.0107 - KL loss: 1.0269e-04 - beta: 0.1050\n",
      "Epoch 01174: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9688 - recon_loss: 0.0107 - KL loss: 1.0269e-04 - beta: 0.1050 - val_val_loss: 0.9687 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.5336e-05 - val_beta: 0.1050\n",
      "Epoch 1174/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2738 - recon_loss: 0.0107 - KL loss: 1.0398e-04 - beta: 0.1976 - val_val_loss: 0.2738 - val_val_recon_loss: 0.0107 - val_val_KL loss: 7.3149e-05 - val_beta: 0.1976\n",
      "Epoch 1175/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2737 - recon_loss: 0.0107 - KL loss: 8.4015e-05 - beta: 0.1976 - val_val_loss: 0.2738 - val_val_recon_loss: 0.0107 - val_val_KL loss: 6.4769e-05 - val_beta: 0.1976\n",
      "Epoch 1176/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2730 - recon_loss: 0.0107 - KL loss: 7.0936e-05 - beta: 0.1976 - val_val_loss: 0.2737 - val_val_recon_loss: 0.0107 - val_val_KL loss: 5.5335e-05 - val_beta: 0.1976\n",
      "Epoch 1177/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2737 - recon_loss: 0.0107 - KL loss: 6.9050e-05 - beta: 0.1976 - val_val_loss: 0.2739 - val_val_recon_loss: 0.0107 - val_val_KL loss: 5.2594e-05 - val_beta: 0.1976\n",
      "Epoch 1178/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2738 - recon_loss: 0.0107 - KL loss: 6.1996e-05 - beta: 0.1976 - val_val_loss: 0.2742 - val_val_recon_loss: 0.0107 - val_val_KL loss: 6.1241e-05 - val_beta: 0.1976\n",
      "Epoch 1179/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2740 - recon_loss: 0.0107 - KL loss: 5.9786e-05 - beta: 0.1976 - val_val_loss: 0.2742 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.7351e-05 - val_beta: 0.1976\n",
      "Epoch 1180/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2738 - recon_loss: 0.0107 - KL loss: 5.1337e-05 - beta: 0.1976 - val_val_loss: 0.2739 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.6334e-05 - val_beta: 0.1976\n",
      "Epoch 1181/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2741 - recon_loss: 0.0107 - KL loss: 4.9327e-05 - beta: 0.1976\n",
      "Epoch 01181: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2741 - recon_loss: 0.0107 - KL loss: 4.9326e-05 - beta: 0.1976 - val_val_loss: 0.2741 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.6366e-05 - val_beta: 0.1976\n",
      "Epoch 1182/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2739 - recon_loss: 0.0107 - KL loss: 3.4492e-05 - beta: 0.1976 - val_val_loss: 0.2739 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.1854e-05 - val_beta: 0.1976\n",
      "Epoch 1183/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2739 - recon_loss: 0.0107 - KL loss: 3.3053e-05 - beta: 0.1976 - val_val_loss: 0.2739 - val_val_recon_loss: 0.0107 - val_val_KL loss: 5.0288e-05 - val_beta: 0.1976\n",
      "Epoch 1184/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2736 - recon_loss: 0.0107 - KL loss: 3.3154e-05 - beta: 0.1976 - val_val_loss: 0.2738 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.0855e-05 - val_beta: 0.1976\n",
      "Epoch 1185/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2742 - recon_loss: 0.0107 - KL loss: 3.1979e-05 - beta: 0.1976 - val_val_loss: 0.2739 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.9075e-05 - val_beta: 0.1976\n",
      "Epoch 1186/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2737 - recon_loss: 0.0107 - KL loss: 3.0977e-05 - beta: 0.1976\n",
      "Epoch 01186: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2737 - recon_loss: 0.0107 - KL loss: 3.0977e-05 - beta: 0.1976 - val_val_loss: 0.2739 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.0412e-05 - val_beta: 0.1976\n",
      "Epoch 1186/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0774 - recon_loss: 0.0107 - KL loss: 8.6226e-05 - beta: 0.3719 - val_val_loss: 0.0773 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.1069e-05 - val_beta: 0.3719\n",
      "Epoch 1187/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0774 - recon_loss: 0.0107 - KL loss: 3.7595e-05 - beta: 0.3719 - val_val_loss: 0.0774 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.1261e-05 - val_beta: 0.3719\n",
      "Epoch 1188/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0773 - recon_loss: 0.0107 - KL loss: 3.3656e-05 - beta: 0.3719 - val_val_loss: 0.0773 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.7614e-05 - val_beta: 0.3719\n",
      "Epoch 1189/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0774 - recon_loss: 0.0107 - KL loss: 3.5244e-05 - beta: 0.3719 - val_val_loss: 0.0775 - val_val_recon_loss: 0.0107 - val_val_KL loss: 6.1094e-05 - val_beta: 0.3719\n",
      "Epoch 1190/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0773 - recon_loss: 0.0107 - KL loss: 3.4352e-05 - beta: 0.3719 - val_val_loss: 0.0774 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.2841e-05 - val_beta: 0.3719\n",
      "Epoch 1191/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0775 - recon_loss: 0.0107 - KL loss: 2.8957e-05 - beta: 0.3719\n",
      "Epoch 01191: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0775 - recon_loss: 0.0107 - KL loss: 2.8957e-05 - beta: 0.3719 - val_val_loss: 0.0774 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.8948e-05 - val_beta: 0.3719\n",
      "Epoch 1192/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0772 - recon_loss: 0.0107 - KL loss: 2.1164e-05 - beta: 0.3719 - val_val_loss: 0.0773 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0285e-05 - val_beta: 0.3719\n",
      "Epoch 1193/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0773 - recon_loss: 0.0107 - KL loss: 2.1301e-05 - beta: 0.3719 - val_val_loss: 0.0773 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1767e-05 - val_beta: 0.3719\n",
      "Epoch 1194/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0774 - recon_loss: 0.0107 - KL loss: 2.1768e-05 - beta: 0.3719 - val_val_loss: 0.0774 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.9993e-05 - val_beta: 0.3719\n",
      "Epoch 1195/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0773 - recon_loss: 0.0107 - KL loss: 2.1022e-05 - beta: 0.3719 - val_val_loss: 0.0775 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.8939e-05 - val_beta: 0.3719\n",
      "Epoch 1196/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0774 - recon_loss: 0.0107 - KL loss: 2.0428e-05 - beta: 0.3719\n",
      "Epoch 01196: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.0774 - recon_loss: 0.0107 - KL loss: 2.0428e-05 - beta: 0.3719 - val_val_loss: 0.0773 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1251e-05 - val_beta: 0.3719\n",
      "Epoch 1196/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 8.4871e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.5977e-05 - val_beta: 0.7000\n",
      "Epoch 1197/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 2.7097e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.4572e-05 - val_beta: 0.7000\n",
      "Epoch 1198/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 2.6423e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.3737e-05 - val_beta: 0.7000\n",
      "Epoch 1199/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 2.4308e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.3668e-05 - val_beta: 0.7000\n",
      "Epoch 1200/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 2.6565e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0410e-05 - val_beta: 0.7000\n",
      "Epoch 1201/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 2.8620e-05 - beta: 0.7000\n",
      "Epoch 01201: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 2.8617e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.9878e-05 - val_beta: 0.7000\n",
      "Epoch 1202/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.5692e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.4945e-05 - val_beta: 0.7000\n",
      "Epoch 1203/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.5547e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5634e-05 - val_beta: 0.7000\n",
      "Epoch 1204/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.6113e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5711e-05 - val_beta: 0.7000\n",
      "Epoch 1205/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.6735e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.4885e-05 - val_beta: 0.7000\n",
      "Epoch 1206/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.5445e-05 - beta: 0.7000\n",
      "Epoch 01206: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.5445e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.7365e-05 - val_beta: 0.7000\n",
      "Epoch 1207/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.3410e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.4495e-05 - val_beta: 0.7000\n",
      "Epoch 1208/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.3521e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3531e-05 - val_beta: 0.7000\n",
      "Epoch 1209/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.3497e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.4649e-05 - val_beta: 0.7000\n",
      "Epoch 1210/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.3446e-05 - beta: 0.7000 - val_val_loss: 0.0218 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3544e-05 - val_beta: 0.7000\n",
      "Epoch 1211/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.3360e-05 - beta: 0.7000\n",
      "Epoch 01211: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.3360e-05 - beta: 0.7000 - val_val_loss: 0.0218 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5016e-05 - val_beta: 0.7000\n",
      "Epoch 1212/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.2704e-05 - beta: 0.7000 - val_val_loss: 0.0218 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3137e-05 - val_beta: 0.7000\n",
      "Epoch 1213/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.2557e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2970e-05 - val_beta: 0.7000\n",
      "Epoch 1214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.2622e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3086e-05 - val_beta: 0.7000\n",
      "Epoch 1215/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.2377e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2989e-05 - val_beta: 0.7000\n",
      "Epoch 1216/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.2421e-05 - beta: 0.7000\n",
      "Epoch 01216: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.2421e-05 - beta: 0.7000 - val_val_loss: 0.0218 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3196e-05 - val_beta: 0.7000\n",
      "Epoch 1217/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.2326e-05 - beta: 0.7000 - val_val_loss: 0.0218 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2818e-05 - val_beta: 0.7000\n",
      "Epoch 1218/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.2223e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2869e-05 - val_beta: 0.7000\n",
      "Epoch 1219/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.2146e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2741e-05 - val_beta: 0.7000\n",
      "Epoch 1220/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.2133e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2882e-05 - val_beta: 0.7000\n",
      "Epoch 1220/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.0714 - recon_loss: 0.0107 - KL loss: 5.7062e-04 - beta: 0.3891 - val_val_loss: 0.0708 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.9985e-05 - val_beta: 0.3891\n",
      "Epoch 1221/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 2.4089e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1467e-05 - val_beta: 0.3891\n",
      "Epoch 1222/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 2.3124e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.3620e-05 - val_beta: 0.3891\n",
      "Epoch 1223/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 2.7530e-05 - beta: 0.3891 - val_val_loss: 0.0708 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0977e-05 - val_beta: 0.3891\n",
      "Epoch 1224/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 2.4069e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.8568e-05 - val_beta: 0.3891\n",
      "Epoch 1225/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0705 - recon_loss: 0.0107 - KL loss: 2.2495e-05 - beta: 0.3891- ETA: 2s - loss: 0.0705 - recon_loss: 0.0107 - KL los\n",
      "Epoch 01225: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0705 - recon_loss: 0.0107 - KL loss: 2.2496e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5914e-05 - val_beta: 0.3891\n",
      "Epoch 1226/10000\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.4477e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3991e-05 - val_beta: 0.3891\n",
      "Epoch 1227/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.0706 - recon_loss: 0.0107 - KL loss: 1.4853e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3613e-05 - val_beta: 0.3891\n",
      "Epoch 1228/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0709 - recon_loss: 0.0107 - KL loss: 1.4667e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.6663e-05 - val_beta: 0.3891\n",
      "Epoch 1229/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.4519e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.4093e-05 - val_beta: 0.3891\n",
      "Epoch 1230/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.5263e-05 - beta: 0.3891\n",
      "Epoch 01230: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.5262e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.3918e-05 - val_beta: 0.3891\n",
      "Epoch 1231/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.2617e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2343e-05 - val_beta: 0.3891\n",
      "Epoch 1232/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0706 - recon_loss: 0.0107 - KL loss: 1.2256e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2477e-05 - val_beta: 0.3891\n",
      "Epoch 1233/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.2288e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2286e-05 - val_beta: 0.3891\n",
      "Epoch 1234/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.2397e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3648e-05 - val_beta: 0.3891\n",
      "Epoch 1235/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.2078e-05 - beta: 0.3891\n",
      "Epoch 01235: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.2078e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2116e-05 - val_beta: 0.3891\n",
      "Epoch 1236/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.1467e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1921e-05 - val_beta: 0.3891\n",
      "Epoch 1237/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0709 - recon_loss: 0.0107 - KL loss: 1.1415e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1855e-05 - val_beta: 0.3891\n",
      "Epoch 1238/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0706 - recon_loss: 0.0107 - KL loss: 1.1277e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1670e-05 - val_beta: 0.3891\n",
      "Epoch 1239/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.1178e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1725e-05 - val_beta: 0.3891\n",
      "Epoch 1240/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.1233e-05 - beta: 0.3891\n",
      "Epoch 01240: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.1233e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1704e-05 - val_beta: 0.3891\n",
      "Epoch 1241/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.1078e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1514e-05 - val_beta: 0.3891\n",
      "Epoch 1242/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.1141e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1543e-05 - val_beta: 0.3891\n",
      "Epoch 1243/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0706 - recon_loss: 0.0107 - KL loss: 1.0982e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1468e-05 - val_beta: 0.3891\n",
      "Epoch 1244/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.0979e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1542e-05 - val_beta: 0.3891\n",
      "Epoch 1245/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.0964e-05 - beta: 0.3891\n",
      "Epoch 01245: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.0964e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1605e-05 - val_beta: 0.3891\n",
      "Epoch 1245/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2298 - recon_loss: 0.0107 - KL loss: 6.5802e-04 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.4916e-05 - val_beta: 0.2163\n",
      "Epoch 1246/10000\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 0.2289 - recon_loss: 0.0107 - KL loss: 1.5416e-05 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1048e-05 - val_beta: 0.2163\n",
      "Epoch 1247/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2293 - recon_loss: 0.0107 - KL loss: 1.7010e-05 - beta: 0.2163 - val_val_loss: 0.2290 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3957e-05 - val_beta: 0.2163\n",
      "Epoch 1248/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2286 - recon_loss: 0.0107 - KL loss: 1.9039e-05 - beta: 0.2163 - val_val_loss: 0.2289 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.6883e-05 - val_beta: 0.2163\n",
      "Epoch 1249/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2289 - recon_loss: 0.0107 - KL loss: 1.9555e-05 - beta: 0.2163 - val_val_loss: 0.2290 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.8509e-05 - val_beta: 0.2163\n",
      "Epoch 1250/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 2.0597e-05 - beta: 0.2163\n",
      "Epoch 01250: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 2.0597e-05 - beta: 0.2163 - val_val_loss: 0.2292 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3787e-05 - val_beta: 0.2163\n",
      "Epoch 1251/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2291 - recon_loss: 0.0107 - KL loss: 1.1869e-05 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2223e-05 - val_beta: 0.2163\n",
      "Epoch 1252/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 1.1568e-05 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5733e-05 - val_beta: 0.2163\n",
      "Epoch 1253/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2291 - recon_loss: 0.0107 - KL loss: 1.2020e-05 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.0678e-05 - val_beta: 0.2163\n",
      "Epoch 1254/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2289 - recon_loss: 0.0107 - KL loss: 1.1506e-05 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.0942e-05 - val_beta: 0.2163\n",
      "Epoch 1255/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2291 - recon_loss: 0.0107 - KL loss: 1.1429e-05 - beta: 0.2163\n",
      "Epoch 01255: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2291 - recon_loss: 0.0107 - KL loss: 1.1429e-05 - beta: 0.2163 - val_val_loss: 0.2289 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5800e-05 - val_beta: 0.2163\n",
      "Epoch 1256/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2288 - recon_loss: 0.0107 - KL loss: 9.8782e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.0458e-05 - val_beta: 0.2163\n",
      "Epoch 1257/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2289 - recon_loss: 0.0107 - KL loss: 9.8803e-06 - beta: 0.2163 - val_val_loss: 0.2289 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1336e-05 - val_beta: 0.2163\n",
      "Epoch 1258/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2286 - recon_loss: 0.0107 - KL loss: 9.9605e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.0549e-05 - val_beta: 0.2163\n",
      "Epoch 1259/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.2292 - recon_loss: 0.0107 - KL loss: 1.0003e-05 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.0278e-05 - val_beta: 0.2163\n",
      "Epoch 1260/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 9.7770e-06 - beta: 0.2163\n",
      "Epoch 01260: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 9.7770e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.6292e-06 - val_beta: 0.2163\n",
      "Epoch 1261/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2290 - recon_loss: 0.0107 - KL loss: 9.0995e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.4013e-06 - val_beta: 0.2163\n",
      "Epoch 1262/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2286 - recon_loss: 0.0107 - KL loss: 8.9239e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.4938e-06 - val_beta: 0.2163\n",
      "Epoch 1263/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2292 - recon_loss: 0.0107 - KL loss: 9.1761e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.6133e-06 - val_beta: 0.2163\n",
      "Epoch 1264/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 9.1579e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.6179e-06 - val_beta: 0.2163\n",
      "Epoch 1265/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2286 - recon_loss: 0.0107 - KL loss: 9.0127e-06 - beta: 0.2163\n",
      "Epoch 01265: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2286 - recon_loss: 0.0107 - KL loss: 9.0127e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.5240e-06 - val_beta: 0.2163\n",
      "Epoch 1266/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.2291 - recon_loss: 0.0107 - KL loss: 8.9679e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.4269e-06 - val_beta: 0.2163\n",
      "Epoch 1267/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 8.7311e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.1976e-06 - val_beta: 0.2163\n",
      "Epoch 1268/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 8.7403e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.4195e-06 - val_beta: 0.2163\n",
      "Epoch 1269/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2288 - recon_loss: 0.0107 - KL loss: 8.7867e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.2464e-06 - val_beta: 0.2163\n",
      "Epoch 1269/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.7418 - recon_loss: 0.0107 - KL loss: 4.2233e-04 - beta: 0.1202 - val_val_loss: 0.7410 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.7473e-05 - val_beta: 0.1202\n",
      "Epoch 1270/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7415 - recon_loss: 0.0107 - KL loss: 1.8820e-05 - beta: 0.1202 - val_val_loss: 0.7410 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.8231e-05 - val_beta: 0.1202\n",
      "Epoch 1271/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7405 - recon_loss: 0.0107 - KL loss: 2.6889e-05 - beta: 0.1202 - val_val_loss: 0.7413 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.5231e-05 - val_beta: 0.1202\n",
      "Epoch 1272/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7406 - recon_loss: 0.0107 - KL loss: 2.4183e-05 - beta: 0.1202 - val_val_loss: 0.7407 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0926e-05 - val_beta: 0.1202\n",
      "Epoch 1273/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7394 - recon_loss: 0.0107 - KL loss: 2.1270e-05 - beta: 0.1202 - val_val_loss: 0.7416 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.8719e-05 - val_beta: 0.1202\n",
      "Epoch 1274/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7417 - recon_loss: 0.0107 - KL loss: 2.0348e-05 - beta: 0.1202 - val_val_loss: 0.7408 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.9484e-05 - val_beta: 0.1202\n",
      "Epoch 1275/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7419 - recon_loss: 0.0107 - KL loss: 2.3545e-05 - beta: 0.1202 - val_val_loss: 0.7410 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3313e-05 - val_beta: 0.1202\n",
      "Epoch 1276/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7404 - recon_loss: 0.0107 - KL loss: 1.7642e-05 - beta: 0.1202 - val_val_loss: 0.7406 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1395e-05 - val_beta: 0.1202\n",
      "Epoch 1277/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7414 - recon_loss: 0.0107 - KL loss: 1.8292e-05 - beta: 0.1202 - val_val_loss: 0.7407 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2830e-05 - val_beta: 0.1202\n",
      "Epoch 1278/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7418 - recon_loss: 0.0107 - KL loss: 1.8740e-05 - beta: 0.1202 - val_val_loss: 0.7410 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.6114e-05 - val_beta: 0.1202\n",
      "Epoch 1279/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7410 - recon_loss: 0.0107 - KL loss: 1.9377e-05 - beta: 0.1202 - val_val_loss: 0.7406 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2102e-05 - val_beta: 0.1202\n",
      "Epoch 1280/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7412 - recon_loss: 0.0107 - KL loss: 1.9101e-05 - beta: 0.1202 - val_val_loss: 0.7408 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.5704e-05 - val_beta: 0.1202\n",
      "Epoch 1281/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.7408 - recon_loss: 0.0107 - KL loss: 2.1044e-05 - beta: 0.1202\n",
      "Epoch 01281: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7408 - recon_loss: 0.0107 - KL loss: 2.1041e-05 - beta: 0.1202 - val_val_loss: 0.7407 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.2890e-05 - val_beta: 0.1202\n",
      "Epoch 1282/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7399 - recon_loss: 0.0107 - KL loss: 9.7539e-06 - beta: 0.1202 - val_val_loss: 0.7403 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.6372e-06 - val_beta: 0.1202\n",
      "Epoch 1283/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7400 - recon_loss: 0.0107 - KL loss: 9.9953e-06 - beta: 0.1202 - val_val_loss: 0.7406 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.6812e-05 - val_beta: 0.1202\n",
      "Epoch 1284/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.7401 - recon_loss: 0.0107 - KL loss: 1.0698e-05 - beta: 0.1202 - val_val_loss: 0.7406 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.7874e-06 - val_beta: 0.1202\n",
      "Epoch 1285/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.7411 - recon_loss: 0.0107 - KL loss: 1.0271e-05 - beta: 0.1202 - val_val_loss: 0.7410 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.7019e-06 - val_beta: 0.1202\n",
      "Epoch 1286/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7409 - recon_loss: 0.0107 - KL loss: 1.0201e-05 - beta: 0.1202 - val_val_loss: 0.7407 - val_val_recon_loss: 0.0107 - val_val_KL loss: 8.5999e-06 - val_beta: 0.1202\n",
      "Epoch 1287/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.7400 - recon_loss: 0.0107 - KL loss: 1.0379e-05 - beta: 0.1202\n",
      "Epoch 01287: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7400 - recon_loss: 0.0107 - KL loss: 1.0379e-05 - beta: 0.1202 - val_val_loss: 0.7404 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1818e-05 - val_beta: 0.1202\n",
      "Epoch 1288/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7418 - recon_loss: 0.0107 - KL loss: 8.4252e-06 - beta: 0.1202 - val_val_loss: 0.7408 - val_val_recon_loss: 0.0107 - val_val_KL loss: 8.7936e-06 - val_beta: 0.1202\n",
      "Epoch 1289/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7419 - recon_loss: 0.0107 - KL loss: 8.2905e-06 - beta: 0.1202 - val_val_loss: 0.7406 - val_val_recon_loss: 0.0107 - val_val_KL loss: 8.7806e-06 - val_beta: 0.1202\n",
      "Epoch 1290/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7407 - recon_loss: 0.0107 - KL loss: 8.3667e-06 - beta: 0.1202 - val_val_loss: 0.7407 - val_val_recon_loss: 0.0107 - val_val_KL loss: 8.9313e-06 - val_beta: 0.1202\n",
      "Epoch 1291/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7394 - recon_loss: 0.0107 - KL loss: 8.0475e-06 - beta: 0.1202 - val_val_loss: 0.7407 - val_val_recon_loss: 0.0107 - val_val_KL loss: 8.0432e-06 - val_beta: 0.1202\n",
      "Epoch 1292/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.7408 - recon_loss: 0.0107 - KL loss: 8.0126e-06 - beta: 0.1202\n",
      "Epoch 01292: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7408 - recon_loss: 0.0107 - KL loss: 8.0126e-06 - beta: 0.1202 - val_val_loss: 0.7405 - val_val_recon_loss: 0.0107 - val_val_KL loss: 8.1798e-06 - val_beta: 0.1202\n",
      "Epoch 1292/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.4024 - recon_loss: 0.0107 - KL loss: 3.0339e-04 - beta: 0.0668 - val_val_loss: 2.3975 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.7230e-05 - val_beta: 0.0668\n",
      "Epoch 1293/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3998 - recon_loss: 0.0107 - KL loss: 3.4130e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.0635e-05 - val_beta: 0.0668\n",
      "Epoch 1294/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3961 - recon_loss: 0.0107 - KL loss: 3.9056e-05 - beta: 0.0668 - val_val_loss: 2.3975 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.2400e-05 - val_beta: 0.0668\n",
      "Epoch 1295/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3954 - recon_loss: 0.0107 - KL loss: 4.4523e-05 - beta: 0.0668 - val_val_loss: 2.3977 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.0206e-05 - val_beta: 0.0668\n",
      "Epoch 1296/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3925 - recon_loss: 0.0107 - KL loss: 4.3809e-05 - beta: 0.0668 - val_val_loss: 2.3976 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.2491e-05 - val_beta: 0.0668\n",
      "Epoch 1297/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3988 - recon_loss: 0.0107 - KL loss: 3.6366e-05 - beta: 0.0668 - val_val_loss: 2.3978 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.1875e-05 - val_beta: 0.0668\n",
      "Epoch 1298/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3966 - recon_loss: 0.0107 - KL loss: 3.7380e-05 - beta: 0.0668\n",
      "Epoch 01298: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3966 - recon_loss: 0.0107 - KL loss: 3.7379e-05 - beta: 0.0668 - val_val_loss: 2.3987 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.6891e-05 - val_beta: 0.0668\n",
      "Epoch 1299/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3958 - recon_loss: 0.0107 - KL loss: 2.4628e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.2876e-05 - val_beta: 0.0668\n",
      "Epoch 1300/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3997 - recon_loss: 0.0107 - KL loss: 2.4388e-05 - beta: 0.0668 - val_val_loss: 2.3972 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.4449e-05 - val_beta: 0.0668\n",
      "Epoch 1301/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 2.3952 - recon_loss: 0.0107 - KL loss: 2.5899e-05 - beta: 0.0668 - val_val_loss: 2.3969 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.7180e-05 - val_beta: 0.0668\n",
      "Epoch 1302/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3978 - recon_loss: 0.0107 - KL loss: 3.1433e-05 - beta: 0.0668 - val_val_loss: 2.3981 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.2397e-05 - val_beta: 0.0668\n",
      "Epoch 1303/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3971 - recon_loss: 0.0107 - KL loss: 2.8572e-05 - beta: 0.0668\n",
      "Epoch 01303: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3971 - recon_loss: 0.0107 - KL loss: 2.8572e-05 - beta: 0.0668 - val_val_loss: 2.3975 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.9705e-05 - val_beta: 0.0668\n",
      "Epoch 1304/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3963 - recon_loss: 0.0107 - KL loss: 2.6669e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.7164e-05 - val_beta: 0.0668\n",
      "Epoch 1305/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3988 - recon_loss: 0.0107 - KL loss: 2.5648e-05 - beta: 0.0668 - val_val_loss: 2.3969 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.7510e-05 - val_beta: 0.0668\n",
      "Epoch 1306/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3978 - recon_loss: 0.0107 - KL loss: 2.4891e-05 - beta: 0.0668 - val_val_loss: 2.3965 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.4334e-05 - val_beta: 0.0668\n",
      "Epoch 1307/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3957 - recon_loss: 0.0107 - KL loss: 2.4283e-05 - beta: 0.0668 - val_val_loss: 2.3969 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.4837e-05 - val_beta: 0.0668\n",
      "Epoch 1308/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3995 - recon_loss: 0.0107 - KL loss: 2.4707e-05 - beta: 0.0668 - val_val_loss: 2.3969 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.4334e-05 - val_beta: 0.0668\n",
      "Epoch 1309/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3956 - recon_loss: 0.0107 - KL loss: 2.4802e-05 - beta: 0.0668 - val_val_loss: 2.3968 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.4485e-05 - val_beta: 0.0668\n",
      "Epoch 1310/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3957 - recon_loss: 0.0107 - KL loss: 2.4209e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.3198e-05 - val_beta: 0.0668\n",
      "Epoch 1311/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3952 - recon_loss: 0.0107 - KL loss: 2.3082e-05 - beta: 0.0668\n",
      "Epoch 01311: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 2.3952 - recon_loss: 0.0107 - KL loss: 2.3082e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.2030e-05 - val_beta: 0.0668\n",
      "Epoch 1312/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3992 - recon_loss: 0.0107 - KL loss: 2.1543e-05 - beta: 0.0668 - val_val_loss: 2.3969 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.2127e-05 - val_beta: 0.0668\n",
      "Epoch 1313/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3949 - recon_loss: 0.0107 - KL loss: 2.1146e-05 - beta: 0.0668 - val_val_loss: 2.3968 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.2296e-05 - val_beta: 0.0668\n",
      "Epoch 1314/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3963 - recon_loss: 0.0107 - KL loss: 2.1317e-05 - beta: 0.0668 - val_val_loss: 2.3971 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1555e-05 - val_beta: 0.0668\n",
      "Epoch 1315/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3993 - recon_loss: 0.0107 - KL loss: 2.1307e-05 - beta: 0.0668 - val_val_loss: 2.3966 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.2474e-05 - val_beta: 0.0668\n",
      "Epoch 1316/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3969 - recon_loss: 0.0107 - KL loss: 2.1274e-05 - beta: 0.0668\n",
      "Epoch 01316: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3969 - recon_loss: 0.0107 - KL loss: 2.1274e-05 - beta: 0.0668 - val_val_loss: 2.3965 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1263e-05 - val_beta: 0.0668\n",
      "Epoch 1317/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3946 - recon_loss: 0.0107 - KL loss: 2.0922e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0708e-05 - val_beta: 0.0668\n",
      "Epoch 1318/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3993 - recon_loss: 0.0107 - KL loss: 2.0648e-05 - beta: 0.0668 - val_val_loss: 2.3965 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1054e-05 - val_beta: 0.0668\n",
      "Epoch 1319/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3959 - recon_loss: 0.0107 - KL loss: 2.0539e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0931e-05 - val_beta: 0.0668\n",
      "Epoch 1320/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3980 - recon_loss: 0.0107 - KL loss: 2.0698e-05 - beta: 0.0668 - val_val_loss: 2.3968 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1310e-05 - val_beta: 0.0668\n",
      "Epoch 1321/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3961 - recon_loss: 0.0107 - KL loss: 2.0739e-05 - beta: 0.0668\n",
      "Epoch 01321: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3961 - recon_loss: 0.0107 - KL loss: 2.0739e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1056e-05 - val_beta: 0.0668\n",
      "Epoch 1322/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3979 - recon_loss: 0.0107 - KL loss: 2.0488e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0976e-05 - val_beta: 0.0668\n",
      "Epoch 1323/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3939 - recon_loss: 0.0107 - KL loss: 2.0528e-05 - beta: 0.0668 - val_val_loss: 2.3968 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1172e-05 - val_beta: 0.0668\n",
      "Epoch 1324/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3969 - recon_loss: 0.0107 - KL loss: 2.0752e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1028e-05 - val_beta: 0.0668\n",
      "Epoch 1325/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3940 - recon_loss: 0.0107 - KL loss: 2.0642e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1333e-05 - val_beta: 0.0668\n",
      "Epoch 1326/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3990 - recon_loss: 0.0107 - KL loss: 2.0727e-05 - beta: 0.0668\n",
      "Epoch 01326: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3990 - recon_loss: 0.0107 - KL loss: 2.0727e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1031e-05 - val_beta: 0.0668\n",
      "Epoch 1327/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3943 - recon_loss: 0.0107 - KL loss: 2.0567e-05 - beta: 0.0668 - val_val_loss: 2.3968 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1091e-05 - val_beta: 0.0668\n",
      "Epoch 1328/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3926 - recon_loss: 0.0107 - KL loss: 2.0467e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1035e-05 - val_beta: 0.0668\n",
      "Epoch 1328/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 7.7431 - recon_loss: 0.0107 - KL loss: 0.0186 - beta: 0.0372 - val_val_loss: 6.8101 - val_val_recon_loss: 0.0082 - val_val_KL loss: 0.8371 - val_beta: 0.0372\n",
      "Epoch 1329/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 6.6419 - recon_loss: 0.0078 - KL loss: 0.9870 - beta: 0.0372 - val_val_loss: 6.3076 - val_val_recon_loss: 0.0068 - val_val_KL loss: 1.3570 - val_beta: 0.0372\n",
      "Epoch 1330/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 6.1945 - recon_loss: 0.0065 - KL loss: 1.4735 - beta: 0.0372 - val_val_loss: 6.0255 - val_val_recon_loss: 0.0059 - val_val_KL loss: 1.7354 - val_beta: 0.0372\n",
      "Epoch 1331/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 5.8901 - recon_loss: 0.0056 - KL loss: 1.8077 - beta: 0.0372 - val_val_loss: 5.7455 - val_val_recon_loss: 0.0052 - val_val_KL loss: 1.9610 - val_beta: 0.0372\n",
      "Epoch 1332/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.7031 - recon_loss: 0.0051 - KL loss: 1.9936 - beta: 0.0372 - val_val_loss: 5.5774 - val_val_recon_loss: 0.0047 - val_val_KL loss: 2.1434 - val_beta: 0.0372\n",
      "Epoch 1333/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.5829 - recon_loss: 0.0047 - KL loss: 2.1482 - beta: 0.0372 - val_val_loss: 5.5326 - val_val_recon_loss: 0.0046 - val_val_KL loss: 2.1796 - val_beta: 0.0372\n",
      "Epoch 1334/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.5247 - recon_loss: 0.0046 - KL loss: 2.2074 - beta: 0.0372 - val_val_loss: 5.4990 - val_val_recon_loss: 0.0045 - val_val_KL loss: 2.2217 - val_beta: 0.0372\n",
      "Epoch 1335/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.4724 - recon_loss: 0.0045 - KL loss: 2.2100 - beta: 0.0372 - val_val_loss: 5.4506 - val_val_recon_loss: 0.0044 - val_val_KL loss: 2.2616 - val_beta: 0.0372\n",
      "Epoch 1336/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.4560 - recon_loss: 0.0044 - KL loss: 2.2684 - beta: 0.0372 - val_val_loss: 5.4563 - val_val_recon_loss: 0.0043 - val_val_KL loss: 2.3073 - val_beta: 0.0372\n",
      "Epoch 1337/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.4197 - recon_loss: 0.0043 - KL loss: 2.3073 - beta: 0.0372 - val_val_loss: 5.3829 - val_val_recon_loss: 0.0042 - val_val_KL loss: 2.3324 - val_beta: 0.0372\n",
      "Epoch 1338/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.3882 - recon_loss: 0.0042 - KL loss: 2.3503 - beta: 0.0372 - val_val_loss: 5.3872 - val_val_recon_loss: 0.0042 - val_val_KL loss: 2.3640 - val_beta: 0.0372\n",
      "Epoch 1339/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.3453 - recon_loss: 0.0041 - KL loss: 2.3817 - beta: 0.0372 - val_val_loss: 5.3080 - val_val_recon_loss: 0.0040 - val_val_KL loss: 2.4197 - val_beta: 0.0372\n",
      "Epoch 1340/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.3267 - recon_loss: 0.0040 - KL loss: 2.4094 - beta: 0.0372 - val_val_loss: 5.3390 - val_val_recon_loss: 0.0040 - val_val_KL loss: 2.4222 - val_beta: 0.0372\n",
      "Epoch 1341/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.3320 - recon_loss: 0.0040 - KL loss: 2.4244 - beta: 0.0372 - val_val_loss: 5.2935 - val_val_recon_loss: 0.0040 - val_val_KL loss: 2.4183 - val_beta: 0.0372\n",
      "Epoch 1342/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.3109 - recon_loss: 0.0040 - KL loss: 2.4338 - beta: 0.0372 - val_val_loss: 5.2702 - val_val_recon_loss: 0.0039 - val_val_KL loss: 2.4319 - val_beta: 0.0372\n",
      "Epoch 1343/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2940 - recon_loss: 0.0039 - KL loss: 2.4429 - beta: 0.0372 - val_val_loss: 5.2925 - val_val_recon_loss: 0.0040 - val_val_KL loss: 2.4011 - val_beta: 0.0372\n",
      "Epoch 1344/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.2877 - recon_loss: 0.0039 - KL loss: 2.4420 - beta: 0.0372 - val_val_loss: 5.2661 - val_val_recon_loss: 0.0038 - val_val_KL loss: 2.4891 - val_beta: 0.0372\n",
      "Epoch 1345/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.2865 - recon_loss: 0.0039 - KL loss: 2.4614 - beta: 0.0372 - val_val_loss: 5.2682 - val_val_recon_loss: 0.0039 - val_val_KL loss: 2.4561 - val_beta: 0.0372\n",
      "Epoch 1346/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2407 - recon_loss: 0.0038 - KL loss: 2.4542 - beta: 0.0372 - val_val_loss: 5.2670 - val_val_recon_loss: 0.0039 - val_val_KL loss: 2.4188 - val_beta: 0.0372\n",
      "Epoch 1347/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2646 - recon_loss: 0.0039 - KL loss: 2.4466 - beta: 0.0372 - val_val_loss: 5.2447 - val_val_recon_loss: 0.0038 - val_val_KL loss: 2.4868 - val_beta: 0.0372\n",
      "Epoch 1348/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2571 - recon_loss: 0.0039 - KL loss: 2.4642 - beta: 0.0372 - val_val_loss: 5.2413 - val_val_recon_loss: 0.0039 - val_val_KL loss: 2.4453 - val_beta: 0.0372\n",
      "Epoch 1349/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2445 - recon_loss: 0.0039 - KL loss: 2.4537 - beta: 0.0372 - val_val_loss: 5.2256 - val_val_recon_loss: 0.0038 - val_val_KL loss: 2.5054 - val_beta: 0.0372\n",
      "Epoch 1350/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2233 - recon_loss: 0.0038 - KL loss: 2.4820 - beta: 0.0372 - val_val_loss: 5.1883 - val_val_recon_loss: 0.0037 - val_val_KL loss: 2.5371 - val_beta: 0.0372\n",
      "Epoch 1351/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2306 - recon_loss: 0.0038 - KL loss: 2.5066 - beta: 0.0372 - val_val_loss: 5.1637 - val_val_recon_loss: 0.0037 - val_val_KL loss: 2.4898 - val_beta: 0.0372\n",
      "Epoch 1352/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.1549 - recon_loss: 0.0036 - KL loss: 2.5475 - beta: 0.0372 - val_val_loss: 5.0403 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.6091 - val_beta: 0.0372\n",
      "Epoch 1353/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.0200 - recon_loss: 0.0033 - KL loss: 2.6363 - beta: 0.0372 - val_val_loss: 5.0117 - val_val_recon_loss: 0.0032 - val_val_KL loss: 2.6706 - val_beta: 0.0372\n",
      "Epoch 1354/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9951 - recon_loss: 0.0032 - KL loss: 2.6783 - beta: 0.0372 - val_val_loss: 5.0085 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.6452 - val_beta: 0.0372\n",
      "Epoch 1355/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.9747 - recon_loss: 0.0032 - KL loss: 2.6832 - beta: 0.0372 - val_val_loss: 4.9916 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7168 - val_beta: 0.0372\n",
      "Epoch 1356/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.0294 - recon_loss: 0.0032 - KL loss: 2.6928 - beta: 0.0372 - val_val_loss: 4.9808 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7134 - val_beta: 0.0372\n",
      "Epoch 1357/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9692 - recon_loss: 0.0031 - KL loss: 2.7141 - beta: 0.0372 - val_val_loss: 4.9531 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7413 - val_beta: 0.0372\n",
      "Epoch 1358/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9815 - recon_loss: 0.0031 - KL loss: 2.7056 - beta: 0.0372 - val_val_loss: 4.9483 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7227 - val_beta: 0.0372\n",
      "Epoch 1359/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9686 - recon_loss: 0.0031 - KL loss: 2.6986 - beta: 0.0372 - val_val_loss: 5.0261 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7951 - val_beta: 0.0372\n",
      "Epoch 1360/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.0117 - recon_loss: 0.0032 - KL loss: 2.7242 - beta: 0.0372 - val_val_loss: 4.9445 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7257 - val_beta: 0.0372\n",
      "Epoch 1361/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9586 - recon_loss: 0.0031 - KL loss: 2.7220 - beta: 0.0372 - val_val_loss: 4.9663 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7370 - val_beta: 0.0372\n",
      "Epoch 1362/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9697 - recon_loss: 0.0031 - KL loss: 2.7204 - beta: 0.0372 - val_val_loss: 4.9849 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7346 - val_beta: 0.0372\n",
      "Epoch 1363/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.9797 - recon_loss: 0.0031 - KL loss: 2.7213 - beta: 0.0372 - val_val_loss: 4.9596 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7183 - val_beta: 0.0372\n",
      "Epoch 1364/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9678 - recon_loss: 0.0031 - KL loss: 2.7202 - beta: 0.0372 - val_val_loss: 4.9600 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7132 - val_beta: 0.0372\n",
      "Epoch 1365/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.0064 - recon_loss: 0.0032 - KL loss: 2.7219 - beta: 0.0372\n",
      "Epoch 01365: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.0064 - recon_loss: 0.0032 - KL loss: 2.7219 - beta: 0.0372 - val_val_loss: 5.0040 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7346 - val_beta: 0.0372\n",
      "Epoch 1366/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9751 - recon_loss: 0.0031 - KL loss: 2.7445 - beta: 0.0372 - val_val_loss: 4.9265 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7394 - val_beta: 0.0372\n",
      "Epoch 1367/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9503 - recon_loss: 0.0030 - KL loss: 2.7442 - beta: 0.0372 - val_val_loss: 4.9199 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7751 - val_beta: 0.0372\n",
      "Epoch 1368/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.9283 - recon_loss: 0.0030 - KL loss: 2.7496 - beta: 0.0372 - val_val_loss: 4.9286 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7260 - val_beta: 0.0372\n",
      "Epoch 1369/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9187 - recon_loss: 0.0030 - KL loss: 2.7351 - beta: 0.0372 - val_val_loss: 4.9205 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7345 - val_beta: 0.0372\n",
      "Epoch 1370/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.9187 - recon_loss: 0.0030 - KL loss: 2.7382 - beta: 0.0372 - val_val_loss: 4.9063 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7502 - val_beta: 0.0372\n",
      "Epoch 1371/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9162 - recon_loss: 0.0030 - KL loss: 2.7432 - beta: 0.0372 - val_val_loss: 4.9139 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7388 - val_beta: 0.0372\n",
      "Epoch 1372/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9243 - recon_loss: 0.0030 - KL loss: 2.7414 - beta: 0.0372 - val_val_loss: 4.9181 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7377 - val_beta: 0.0372\n",
      "Epoch 1373/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9159 - recon_loss: 0.0030 - KL loss: 2.7402 - beta: 0.0372 - val_val_loss: 4.9125 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7181 - val_beta: 0.0372\n",
      "Epoch 1374/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9239 - recon_loss: 0.0030 - KL loss: 2.7347 - beta: 0.0372 - val_val_loss: 4.9171 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7378 - val_beta: 0.0372\n",
      "Epoch 1375/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.9270 - recon_loss: 0.0030 - KL loss: 2.7453 - beta: 0.0372\n",
      "Epoch 01375: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9270 - recon_loss: 0.0030 - KL loss: 2.7453 - beta: 0.0372 - val_val_loss: 4.9149 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7640 - val_beta: 0.0372\n",
      "Epoch 1376/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9108 - recon_loss: 0.0030 - KL loss: 2.7409 - beta: 0.0372 - val_val_loss: 4.9072 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7576 - val_beta: 0.0372\n",
      "Epoch 1377/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9191 - recon_loss: 0.0030 - KL loss: 2.7476 - beta: 0.0372 - val_val_loss: 4.9151 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7316 - val_beta: 0.0372\n",
      "Epoch 1378/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.9183 - recon_loss: 0.0030 - KL loss: 2.7492 - beta: 0.0372 - val_val_loss: 4.9079 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7415 - val_beta: 0.0372\n",
      "Epoch 1379/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9058 - recon_loss: 0.0030 - KL loss: 2.7488 - beta: 0.0372 - val_val_loss: 4.8931 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7539 - val_beta: 0.0372\n",
      "Epoch 1380/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9147 - recon_loss: 0.0030 - KL loss: 2.7511 - beta: 0.0372 - val_val_loss: 4.9100 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7622 - val_beta: 0.0372\n",
      "Epoch 1381/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8991 - recon_loss: 0.0030 - KL loss: 2.7494 - beta: 0.0372 - val_val_loss: 4.8948 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7226 - val_beta: 0.0372\n",
      "Epoch 1382/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8976 - recon_loss: 0.0030 - KL loss: 2.7401 - beta: 0.0372 - val_val_loss: 4.8926 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7356 - val_beta: 0.0372\n",
      "Epoch 1383/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8884 - recon_loss: 0.0030 - KL loss: 2.7395 - beta: 0.0372 - val_val_loss: 4.9025 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7368 - val_beta: 0.0372\n",
      "Epoch 1384/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9018 - recon_loss: 0.0030 - KL loss: 2.7432 - beta: 0.0372 - val_val_loss: 4.9049 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7581 - val_beta: 0.0372\n",
      "Epoch 1385/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8935 - recon_loss: 0.0030 - KL loss: 2.7420 - beta: 0.0372 - val_val_loss: 4.8895 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.7547 - val_beta: 0.0372\n",
      "Epoch 1386/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8892 - recon_loss: 0.0030 - KL loss: 2.7457 - beta: 0.0372 - val_val_loss: 4.8942 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7433 - val_beta: 0.0372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1387/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9167 - recon_loss: 0.0030 - KL loss: 2.7492 - beta: 0.0372 - val_val_loss: 4.9016 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7471 - val_beta: 0.0372\n",
      "Epoch 1388/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9128 - recon_loss: 0.0030 - KL loss: 2.7544 - beta: 0.0372 - val_val_loss: 4.9178 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7637 - val_beta: 0.0372\n",
      "Epoch 1389/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9191 - recon_loss: 0.0030 - KL loss: 2.7537 - beta: 0.0372 - val_val_loss: 4.9192 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7591 - val_beta: 0.0372\n",
      "Epoch 1390/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.9132 - recon_loss: 0.0030 - KL loss: 2.7534 - beta: 0.0372\n",
      "Epoch 01390: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.9132 - recon_loss: 0.0030 - KL loss: 2.7534 - beta: 0.0372 - val_val_loss: 4.9095 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7626 - val_beta: 0.0372\n",
      "Epoch 1391/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8993 - recon_loss: 0.0030 - KL loss: 2.7526 - beta: 0.0372 - val_val_loss: 4.9032 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7478 - val_beta: 0.0372\n",
      "Epoch 1392/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.8894 - recon_loss: 0.0029 - KL loss: 2.7556 - beta: 0.0372 - val_val_loss: 4.9005 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7602 - val_beta: 0.0372\n",
      "Epoch 1393/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9054 - recon_loss: 0.0030 - KL loss: 2.7575 - beta: 0.0372 - val_val_loss: 4.9021 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7636 - val_beta: 0.0372\n",
      "Epoch 1394/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9056 - recon_loss: 0.0030 - KL loss: 2.7583 - beta: 0.0372 - val_val_loss: 4.9049 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7509 - val_beta: 0.0372\n",
      "Epoch 1395/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.8947 - recon_loss: 0.0030 - KL loss: 2.7517 - beta: 0.0372\n",
      "Epoch 01395: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8947 - recon_loss: 0.0030 - KL loss: 2.7517 - beta: 0.0372 - val_val_loss: 4.9057 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7518 - val_beta: 0.0372\n",
      "Epoch 1395/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 8.8156 - recon_loss: 0.0021 - KL loss: 3.9430 - beta: 0.0207 - val_val_loss: 8.4819 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0767 - val_beta: 0.0207\n",
      "Epoch 1396/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.5526 - recon_loss: 0.0019 - KL loss: 4.0502 - beta: 0.0207 - val_val_loss: 8.4795 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0295 - val_beta: 0.0207\n",
      "Epoch 1397/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4695 - recon_loss: 0.0019 - KL loss: 4.0426 - beta: 0.0207 - val_val_loss: 8.4788 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0636 - val_beta: 0.0207\n",
      "Epoch 1398/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4762 - recon_loss: 0.0019 - KL loss: 4.0576 - beta: 0.0207 - val_val_loss: 8.5377 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0603 - val_beta: 0.0207\n",
      "Epoch 1399/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.5091 - recon_loss: 0.0019 - KL loss: 4.0646 - beta: 0.0207 - val_val_loss: 8.4728 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0569 - val_beta: 0.0207\n",
      "Epoch 1400/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4376 - recon_loss: 0.0019 - KL loss: 4.0707 - beta: 0.0207 - val_val_loss: 8.5245 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0771 - val_beta: 0.0207\n",
      "Epoch 1401/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4476 - recon_loss: 0.0019 - KL loss: 4.0872 - beta: 0.0207 - val_val_loss: 8.3656 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0588 - val_beta: 0.0207\n",
      "Epoch 1402/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3875 - recon_loss: 0.0018 - KL loss: 4.0822 - beta: 0.0207 - val_val_loss: 8.3794 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0566 - val_beta: 0.0207\n",
      "Epoch 1403/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4143 - recon_loss: 0.0018 - KL loss: 4.0805 - beta: 0.0207 - val_val_loss: 8.3725 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1002 - val_beta: 0.0207\n",
      "Epoch 1404/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4173 - recon_loss: 0.0018 - KL loss: 4.0894 - beta: 0.0207 - val_val_loss: 8.3750 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0819 - val_beta: 0.0207\n",
      "Epoch 1405/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4152 - recon_loss: 0.0018 - KL loss: 4.0816 - beta: 0.0207 - val_val_loss: 8.3713 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0323 - val_beta: 0.0207\n",
      "Epoch 1406/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3741 - recon_loss: 0.0018 - KL loss: 4.0744 - beta: 0.0207 - val_val_loss: 8.3576 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0458 - val_beta: 0.0207\n",
      "Epoch 1407/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 8.3913 - recon_loss: 0.0018 - KL loss: 4.0875 - beta: 0.0207 - val_val_loss: 8.4156 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1541 - val_beta: 0.0207\n",
      "Epoch 1408/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3866 - recon_loss: 0.0018 - KL loss: 4.1112 - beta: 0.0207 - val_val_loss: 8.4218 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0096 - val_beta: 0.0207\n",
      "Epoch 1409/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3783 - recon_loss: 0.0018 - KL loss: 4.0888 - beta: 0.0207 - val_val_loss: 8.4153 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1164 - val_beta: 0.0207\n",
      "Epoch 1410/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4010 - recon_loss: 0.0018 - KL loss: 4.0781 - beta: 0.0207 - val_val_loss: 8.4644 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0435 - val_beta: 0.0207\n",
      "Epoch 1411/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4356 - recon_loss: 0.0019 - KL loss: 4.0555 - beta: 0.0207 - val_val_loss: 8.3228 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0513 - val_beta: 0.0207\n",
      "Epoch 1412/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3764 - recon_loss: 0.0018 - KL loss: 4.0725 - beta: 0.0207 - val_val_loss: 8.3544 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0787 - val_beta: 0.0207\n",
      "Epoch 1413/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3975 - recon_loss: 0.0018 - KL loss: 4.0714 - beta: 0.0207 - val_val_loss: 8.2985 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1169 - val_beta: 0.0207\n",
      "Epoch 1414/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 8.3480 - recon_loss: 0.0018 - KL loss: 4.0855 - beta: 0.0207 - val_val_loss: 8.3583 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0558 - val_beta: 0.0207\n",
      "Epoch 1415/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3226 - recon_loss: 0.0018 - KL loss: 4.0734 - beta: 0.0207 - val_val_loss: 8.3260 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1981 - val_beta: 0.0207\n",
      "Epoch 1416/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3698 - recon_loss: 0.0018 - KL loss: 4.0919 - beta: 0.0207 - val_val_loss: 8.3664 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1278 - val_beta: 0.0207\n",
      "Epoch 1417/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 8.3141 - recon_loss: 0.0018 - KL loss: 4.1021 - beta: 0.0207 - val_val_loss: 8.3547 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1076 - val_beta: 0.0207\n",
      "Epoch 1418/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.3671 - recon_loss: 0.0018 - KL loss: 4.1125 - beta: 0.0207\n",
      "Epoch 01418: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3672 - recon_loss: 0.0018 - KL loss: 4.1125 - beta: 0.0207 - val_val_loss: 8.4245 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0932 - val_beta: 0.0207\n",
      "Epoch 1419/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3485 - recon_loss: 0.0018 - KL loss: 4.1119 - beta: 0.0207 - val_val_loss: 8.3115 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0951 - val_beta: 0.0207\n",
      "Epoch 1420/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2961 - recon_loss: 0.0018 - KL loss: 4.0972 - beta: 0.0207 - val_val_loss: 8.3241 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0718 - val_beta: 0.0207\n",
      "Epoch 1421/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3031 - recon_loss: 0.0018 - KL loss: 4.0746 - beta: 0.0207 - val_val_loss: 8.3338 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0666 - val_beta: 0.0207\n",
      "Epoch 1422/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2976 - recon_loss: 0.0018 - KL loss: 4.0725 - beta: 0.0207 - val_val_loss: 8.3049 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1011 - val_beta: 0.0207\n",
      "Epoch 1423/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2910 - recon_loss: 0.0018 - KL loss: 4.0898 - beta: 0.0207 - val_val_loss: 8.2729 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0764 - val_beta: 0.0207\n",
      "Epoch 1424/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2712 - recon_loss: 0.0018 - KL loss: 4.0886 - beta: 0.0207 - val_val_loss: 8.2586 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1449 - val_beta: 0.0207\n",
      "Epoch 1425/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2396 - recon_loss: 0.0018 - KL loss: 4.0922 - beta: 0.0207 - val_val_loss: 8.2659 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0998 - val_beta: 0.0207\n",
      "Epoch 1426/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2015 - recon_loss: 0.0018 - KL loss: 4.0968 - beta: 0.0207 - val_val_loss: 8.2596 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0997 - val_beta: 0.0207\n",
      "Epoch 1427/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2802 - recon_loss: 0.0018 - KL loss: 4.0925 - beta: 0.0207 - val_val_loss: 8.2482 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1226 - val_beta: 0.0207\n",
      "Epoch 1428/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2320 - recon_loss: 0.0018 - KL loss: 4.0875 - beta: 0.0207 - val_val_loss: 8.2300 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0955 - val_beta: 0.0207\n",
      "Epoch 1429/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2341 - recon_loss: 0.0018 - KL loss: 4.0840 - beta: 0.0207 - val_val_loss: 8.2230 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0660 - val_beta: 0.0207\n",
      "Epoch 1430/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2360 - recon_loss: 0.0018 - KL loss: 4.0967 - beta: 0.0207 - val_val_loss: 8.2410 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1252 - val_beta: 0.0207\n",
      "Epoch 1431/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2093 - recon_loss: 0.0018 - KL loss: 4.0989 - beta: 0.0207 - val_val_loss: 8.2496 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0957 - val_beta: 0.0207\n",
      "Epoch 1432/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2214 - recon_loss: 0.0018 - KL loss: 4.0988 - beta: 0.0207 - val_val_loss: 8.2224 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1050 - val_beta: 0.0207\n",
      "Epoch 1433/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2609 - recon_loss: 0.0018 - KL loss: 4.1055 - beta: 0.0207 - val_val_loss: 8.2785 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1010 - val_beta: 0.0207\n",
      "Epoch 1434/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2339 - recon_loss: 0.0018 - KL loss: 4.0998 - beta: 0.0207 - val_val_loss: 8.2224 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0925 - val_beta: 0.0207\n",
      "Epoch 1435/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2330 - recon_loss: 0.0018 - KL loss: 4.0925 - beta: 0.0207 - val_val_loss: 8.2269 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0577 - val_beta: 0.0207\n",
      "Epoch 1436/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2303 - recon_loss: 0.0018 - KL loss: 4.0838 - beta: 0.0207 - val_val_loss: 8.2514 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0772 - val_beta: 0.0207\n",
      "Epoch 1437/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.2155 - recon_loss: 0.0018 - KL loss: 4.0713 - beta: 0.0207\n",
      "Epoch 01437: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2155 - recon_loss: 0.0018 - KL loss: 4.0713 - beta: 0.0207 - val_val_loss: 8.2427 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1301 - val_beta: 0.0207\n",
      "Epoch 1438/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2236 - recon_loss: 0.0018 - KL loss: 4.0976 - beta: 0.0207 - val_val_loss: 8.1978 - val_val_recon_loss: 0.0017 - val_val_KL loss: 4.0998 - val_beta: 0.0207\n",
      "Epoch 1439/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.1718 - recon_loss: 0.0017 - KL loss: 4.0833 - beta: 0.0207 - val_val_loss: 8.1858 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0832 - val_beta: 0.0207\n",
      "Epoch 1440/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.1927 - recon_loss: 0.0018 - KL loss: 4.0848 - beta: 0.0207 - val_val_loss: 8.1893 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0761 - val_beta: 0.0207\n",
      "Epoch 1441/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2246 - recon_loss: 0.0018 - KL loss: 4.0842 - beta: 0.0207 - val_val_loss: 8.2174 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0869 - val_beta: 0.0207\n",
      "Epoch 1442/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.1947 - recon_loss: 0.0018 - KL loss: 4.0927 - beta: 0.0207 - val_val_loss: 8.1889 - val_val_recon_loss: 0.0017 - val_val_KL loss: 4.1185 - val_beta: 0.0207\n",
      "Epoch 1443/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2035 - recon_loss: 0.0018 - KL loss: 4.0868 - beta: 0.0207 - val_val_loss: 8.2072 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0870 - val_beta: 0.0207\n",
      "Epoch 1444/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.2088 - recon_loss: 0.0018 - KL loss: 4.0821 - beta: 0.0207\n",
      "Epoch 01444: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2087 - recon_loss: 0.0018 - KL loss: 4.0821 - beta: 0.0207 - val_val_loss: 8.2039 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0714 - val_beta: 0.0207\n",
      "Epoch 1445/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.1884 - recon_loss: 0.0018 - KL loss: 4.0782 - beta: 0.0207 - val_val_loss: 8.2001 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0794 - val_beta: 0.0207\n",
      "Epoch 1446/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2212 - recon_loss: 0.0018 - KL loss: 4.0836 - beta: 0.0207 - val_val_loss: 8.1988 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0893 - val_beta: 0.0207\n",
      "Epoch 1447/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2254 - recon_loss: 0.0018 - KL loss: 4.0878 - beta: 0.0207 - val_val_loss: 8.2043 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0884 - val_beta: 0.0207\n",
      "Epoch 1448/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2018 - recon_loss: 0.0018 - KL loss: 4.0912 - beta: 0.0207 - val_val_loss: 8.2059 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0853 - val_beta: 0.0207\n",
      "Epoch 1449/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.1722 - recon_loss: 0.0017 - KL loss: 4.0841 - beta: 0.0207\n",
      "Epoch 01449: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.1722 - recon_loss: 0.0017 - KL loss: 4.0841 - beta: 0.0207 - val_val_loss: 8.2017 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0861 - val_beta: 0.0207\n",
      "Epoch 1449/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.7959 - recon_loss: 0.0015 - KL loss: 5.2486 - beta: 0.0115 - val_val_loss: 16.5466 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.2983 - val_beta: 0.0115\n",
      "Epoch 1450/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.6173 - recon_loss: 0.0015 - KL loss: 5.3202 - beta: 0.0115 - val_val_loss: 16.5288 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3581 - val_beta: 0.0115\n",
      "Epoch 1451/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.4849 - recon_loss: 0.0015 - KL loss: 5.3521 - beta: 0.0115 - val_val_loss: 16.8190 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4194 - val_beta: 0.0115\n",
      "Epoch 1452/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 16.8882 - recon_loss: 0.0015 - KL loss: 5.3984 - beta: 0.0115 - val_val_loss: 16.5676 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3369 - val_beta: 0.0115\n",
      "Epoch 1453/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 16.7157 - recon_loss: 0.0015 - KL loss: 5.3790 - beta: 0.0115 - val_val_loss: 16.5150 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3658 - val_beta: 0.0115\n",
      "Epoch 1454/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.4322 - recon_loss: 0.0015 - KL loss: 5.3910 - beta: 0.0115 - val_val_loss: 16.4319 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4115 - val_beta: 0.0115\n",
      "Epoch 1455/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.3948 - recon_loss: 0.0015 - KL loss: 5.3696 - beta: 0.0115 - val_val_loss: 16.5048 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3043 - val_beta: 0.0115\n",
      "Epoch 1456/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.3973 - recon_loss: 0.0015 - KL loss: 5.3487 - beta: 0.0115 - val_val_loss: 16.6187 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4017 - val_beta: 0.0115\n",
      "Epoch 1457/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.7326 - recon_loss: 0.0015 - KL loss: 5.3766 - beta: 0.0115 - val_val_loss: 16.5360 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3011 - val_beta: 0.0115\n",
      "Epoch 1458/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 16.6434 - recon_loss: 0.0015 - KL loss: 5.3951 - beta: 0.0115 - val_val_loss: 16.7561 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3852 - val_beta: 0.0115\n",
      "Epoch 1459/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 16.6135 - recon_loss: 0.0015 - KL loss: 5.3990 - beta: 0.0115\n",
      "Epoch 01459: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.6136 - recon_loss: 0.0015 - KL loss: 5.3990 - beta: 0.0115 - val_val_loss: 16.6986 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.1347 - val_beta: 0.0115\n",
      "Epoch 1460/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.5206 - recon_loss: 0.0015 - KL loss: 5.3660 - beta: 0.0115 - val_val_loss: 16.5294 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4174 - val_beta: 0.0115\n",
      "Epoch 1461/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 16.5814 - recon_loss: 0.0015 - KL loss: 5.4088 - beta: 0.0115 - val_val_loss: 16.6161 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4008 - val_beta: 0.0115\n",
      "Epoch 1462/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.6155 - recon_loss: 0.0015 - KL loss: 5.4323 - beta: 0.0115 - val_val_loss: 16.7461 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4347 - val_beta: 0.0115\n",
      "Epoch 1463/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 16.7827 - recon_loss: 0.0015 - KL loss: 5.4522 - beta: 0.0115 - val_val_loss: 16.7082 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4487 - val_beta: 0.0115\n",
      "Epoch 1464/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 16.6373 - recon_loss: 0.0015 - KL loss: 5.4391 - beta: 0.0115\n",
      "Epoch 01464: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.6372 - recon_loss: 0.0015 - KL loss: 5.4391 - beta: 0.0115 - val_val_loss: 16.6299 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3994 - val_beta: 0.0115\n",
      "Epoch 1464/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 43.4451 - recon_loss: 0.0015 - KL loss: 6.6631 - beta: 0.0064 - val_val_loss: 43.4661 - val_val_recon_loss: 0.0015 - val_val_KL loss: 6.8600 - val_beta: 0.0064\n",
      "Epoch 1465/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 43.5024 - recon_loss: 0.0015 - KL loss: 7.0650 - beta: 0.0064 - val_val_loss: 41.4834 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.0630 - val_beta: 0.0064\n",
      "Epoch 1466/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 41.1016 - recon_loss: 0.0014 - KL loss: 6.9958 - beta: 0.0064 - val_val_loss: 40.2988 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.9980 - val_beta: 0.0064\n",
      "Epoch 1467/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 39.9393 - recon_loss: 0.0013 - KL loss: 7.0424 - beta: 0.0064 - val_val_loss: 39.6466 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.0555 - val_beta: 0.0064\n",
      "Epoch 1468/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 39.5393 - recon_loss: 0.0013 - KL loss: 7.0886 - beta: 0.0064 - val_val_loss: 39.1513 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.0914 - val_beta: 0.0064\n",
      "Epoch 1469/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 38.8692 - recon_loss: 0.0013 - KL loss: 7.1359 - beta: 0.0064 - val_val_loss: 38.9814 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2462 - val_beta: 0.0064\n",
      "Epoch 1470/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 38.7484 - recon_loss: 0.0013 - KL loss: 7.2765 - beta: 0.0064 - val_val_loss: 38.4193 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.3144 - val_beta: 0.0064\n",
      "Epoch 1471/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 38.0956 - recon_loss: 0.0013 - KL loss: 7.4078 - beta: 0.0064 - val_val_loss: 37.7369 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.5097 - val_beta: 0.0064\n",
      "Epoch 1472/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.6566 - recon_loss: 0.0012 - KL loss: 7.5325 - beta: 0.0064 - val_val_loss: 37.5145 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.6461 - val_beta: 0.0064\n",
      "Epoch 1473/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 37.3646 - recon_loss: 0.0012 - KL loss: 7.6162 - beta: 0.0064 - val_val_loss: 37.2573 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.6781 - val_beta: 0.0064\n",
      "Epoch 1474/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.1692 - recon_loss: 0.0012 - KL loss: 7.6846 - beta: 0.0064 - val_val_loss: 37.3692 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.7382 - val_beta: 0.0064\n",
      "Epoch 1475/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.0459 - recon_loss: 0.0012 - KL loss: 7.7395 - beta: 0.0064 - val_val_loss: 37.0905 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.7912 - val_beta: 0.0064\n",
      "Epoch 1476/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.0687 - recon_loss: 0.0012 - KL loss: 7.7843 - beta: 0.0064 - val_val_loss: 37.1483 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.8462 - val_beta: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1477/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.7504 - recon_loss: 0.0012 - KL loss: 7.8116 - beta: 0.0064 - val_val_loss: 36.7887 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.8921 - val_beta: 0.0064\n",
      "Epoch 1478/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 37.1083 - recon_loss: 0.0012 - KL loss: 7.8956 - beta: 0.0064 - val_val_loss: 37.3102 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.8383 - val_beta: 0.0064\n",
      "Epoch 1479/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 37.3692 - recon_loss: 0.0012 - KL loss: 7.8789 - beta: 0.0064 - val_val_loss: 37.3554 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.8499 - val_beta: 0.0064\n",
      "Epoch 1480/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.7914 - recon_loss: 0.0012 - KL loss: 7.9704 - beta: 0.0064 - val_val_loss: 38.6289 - val_val_recon_loss: 0.0012 - val_val_KL loss: 8.0926 - val_beta: 0.0064\n",
      "Epoch 1481/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 38.5164 - recon_loss: 0.0012 - KL loss: 8.1194 - beta: 0.0064 - val_val_loss: 37.7122 - val_val_recon_loss: 0.0012 - val_val_KL loss: 8.0000 - val_beta: 0.0064\n",
      "Epoch 1482/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 38.1963 - recon_loss: 0.0012 - KL loss: 8.1140 - beta: 0.0064\n",
      "Epoch 01482: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 38.1964 - recon_loss: 0.0012 - KL loss: 8.1140 - beta: 0.0064 - val_val_loss: 37.3442 - val_val_recon_loss: 0.0012 - val_val_KL loss: 8.0923 - val_beta: 0.0064\n",
      "Epoch 1483/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.0914 - recon_loss: 0.0012 - KL loss: 8.0378 - beta: 0.0064 - val_val_loss: 37.1502 - val_val_recon_loss: 0.0012 - val_val_KL loss: 8.0133 - val_beta: 0.0064\n",
      "Epoch 1484/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.1835 - recon_loss: 0.0012 - KL loss: 8.0005 - beta: 0.0064 - val_val_loss: 36.7332 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.9238 - val_beta: 0.0064\n",
      "Epoch 1485/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.4513 - recon_loss: 0.0012 - KL loss: 7.9339 - beta: 0.0064 - val_val_loss: 36.6175 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.9753 - val_beta: 0.0064\n",
      "Epoch 1486/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.4827 - recon_loss: 0.0012 - KL loss: 7.9592 - beta: 0.0064 - val_val_loss: 36.3193 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.9361 - val_beta: 0.0064\n",
      "Epoch 1487/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.4873 - recon_loss: 0.0012 - KL loss: 7.9616 - beta: 0.0064 - val_val_loss: 36.2884 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.9710 - val_beta: 0.0064\n",
      "Epoch 1488/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.5366 - recon_loss: 0.0012 - KL loss: 8.0035 - beta: 0.0064 - val_val_loss: 36.1557 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0000 - val_beta: 0.0064\n",
      "Epoch 1489/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.3069 - recon_loss: 0.0012 - KL loss: 8.0142 - beta: 0.0064 - val_val_loss: 35.9920 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0338 - val_beta: 0.0064\n",
      "Epoch 1490/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.0002 - recon_loss: 0.0011 - KL loss: 7.9860 - beta: 0.0064 - val_val_loss: 36.0027 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0458 - val_beta: 0.0064\n",
      "Epoch 1491/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.0153 - recon_loss: 0.0011 - KL loss: 7.9882 - beta: 0.0064 - val_val_loss: 35.9980 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0047 - val_beta: 0.0064\n",
      "Epoch 1492/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.0476 - recon_loss: 0.0011 - KL loss: 7.9944 - beta: 0.0064 - val_val_loss: 36.1147 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0058 - val_beta: 0.0064\n",
      "Epoch 1493/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.1262 - recon_loss: 0.0011 - KL loss: 8.0250 - beta: 0.0064 - val_val_loss: 36.2331 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0545 - val_beta: 0.0064\n",
      "Epoch 1494/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 36.2605 - recon_loss: 0.0012 - KL loss: 8.0352 - beta: 0.0064\n",
      "Epoch 01494: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.2606 - recon_loss: 0.0012 - KL loss: 8.0352 - beta: 0.0064 - val_val_loss: 36.1824 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0373 - val_beta: 0.0064\n",
      "Epoch 1495/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.0706 - recon_loss: 0.0011 - KL loss: 8.0279 - beta: 0.0064 - val_val_loss: 36.1839 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0550 - val_beta: 0.0064\n",
      "Epoch 1496/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.9865 - recon_loss: 0.0011 - KL loss: 8.0494 - beta: 0.0064 - val_val_loss: 36.0517 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0462 - val_beta: 0.0064\n",
      "Epoch 1497/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.2049 - recon_loss: 0.0011 - KL loss: 8.0349 - beta: 0.0064 - val_val_loss: 36.0466 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0265 - val_beta: 0.0064\n",
      "Epoch 1498/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.9828 - recon_loss: 0.0011 - KL loss: 8.0214 - beta: 0.0064 - val_val_loss: 36.2212 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0941 - val_beta: 0.0064\n",
      "Epoch 1499/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 36.1930 - recon_loss: 0.0011 - KL loss: 8.0532 - beta: 0.0064\n",
      "Epoch 01499: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.1929 - recon_loss: 0.0011 - KL loss: 8.0532 - beta: 0.0064 - val_val_loss: 36.0086 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0204 - val_beta: 0.0064\n",
      "Epoch 1499/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 101.4232 - recon_loss: 0.0012 - KL loss: 10.0793 - beta: 0.0035 - val_val_loss: 99.3053 - val_val_recon_loss: 0.0011 - val_val_KL loss: 10.8861 - val_beta: 0.0035\n",
      "Epoch 1500/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 98.2342 - recon_loss: 0.0011 - KL loss: 10.7456 - beta: 0.0035 - val_val_loss: 99.2486 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1345 - val_beta: 0.0035\n",
      "Epoch 1501/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 97.0721 - recon_loss: 0.0011 - KL loss: 10.8606 - beta: 0.0035 - val_val_loss: 97.1952 - val_val_recon_loss: 0.0011 - val_val_KL loss: 10.9631 - val_beta: 0.0035\n",
      "Epoch 1502/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 98.2356 - recon_loss: 0.0011 - KL loss: 11.0364 - beta: 0.0035 - val_val_loss: 99.3442 - val_val_recon_loss: 0.0011 - val_val_KL loss: 10.8573 - val_beta: 0.0035\n",
      "Epoch 1503/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 99.2517 - recon_loss: 0.0011 - KL loss: 10.8979 - beta: 0.0035 - val_val_loss: 99.9083 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.0939 - val_beta: 0.0035\n",
      "Epoch 1504/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 99.4769 - recon_loss: 0.0011 - KL loss: 11.0955 - beta: 0.0035 - val_val_loss: 98.3639 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.0114 - val_beta: 0.0035\n",
      "Epoch 1505/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 97.5536 - recon_loss: 0.0011 - KL loss: 11.0337 - beta: 0.0035 - val_val_loss: 97.6781 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.0513 - val_beta: 0.0035\n",
      "Epoch 1506/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 98.4462 - recon_loss: 0.0011 - KL loss: 11.1638 - beta: 0.0035\n",
      "Epoch 01506: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 98.4458 - recon_loss: 0.0011 - KL loss: 11.1638 - beta: 0.0035 - val_val_loss: 98.2264 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.2340 - val_beta: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1507/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96.7840 - recon_loss: 0.0011 - KL loss: 11.2413 - beta: 0.0035 - val_val_loss: 96.0201 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.0768 - val_beta: 0.0035\n",
      "Epoch 1508/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 96.4098 - recon_loss: 0.0011 - KL loss: 11.1753 - beta: 0.0035 - val_val_loss: 95.8321 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1602 - val_beta: 0.0035\n",
      "Epoch 1509/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96.1042 - recon_loss: 0.0011 - KL loss: 11.2770 - beta: 0.0035 - val_val_loss: 95.9999 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.2522 - val_beta: 0.0035\n",
      "Epoch 1510/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96.3479 - recon_loss: 0.0011 - KL loss: 11.2213 - beta: 0.0035 - val_val_loss: 96.0295 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1817 - val_beta: 0.0035\n",
      "Epoch 1511/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96.0333 - recon_loss: 0.0011 - KL loss: 11.2547 - beta: 0.0035 - val_val_loss: 96.7696 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.2617 - val_beta: 0.0035\n",
      "Epoch 1512/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 96.6433 - recon_loss: 0.0011 - KL loss: 11.2311 - beta: 0.0035 - val_val_loss: 96.4477 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.0958 - val_beta: 0.0035\n",
      "Epoch 1513/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 95.1655 - recon_loss: 0.0011 - KL loss: 11.1503 - beta: 0.0035- ETA: 6s - loss: 95.\n",
      "Epoch 01513: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95.1662 - recon_loss: 0.0011 - KL loss: 11.1503 - beta: 0.0035 - val_val_loss: 96.0767 - val_val_recon_loss: 0.0011 - val_val_KL loss: 10.9789 - val_beta: 0.0035\n",
      "Epoch 1514/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95.6147 - recon_loss: 0.0011 - KL loss: 11.0407 - beta: 0.0035 - val_val_loss: 95.3901 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.2146 - val_beta: 0.0035\n",
      "Epoch 1515/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 95.0459 - recon_loss: 0.0011 - KL loss: 11.1707 - beta: 0.0035 - val_val_loss: 95.2015 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1143 - val_beta: 0.0035\n",
      "Epoch 1516/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 95.2665 - recon_loss: 0.0011 - KL loss: 11.1438 - beta: 0.0035 - val_val_loss: 94.9986 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1086 - val_beta: 0.0035\n",
      "Epoch 1517/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 95.0635 - recon_loss: 0.0011 - KL loss: 11.1371 - beta: 0.0035 - val_val_loss: 95.1969 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1160 - val_beta: 0.0035\n",
      "Epoch 1518/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 93.8258 - recon_loss: 0.0010 - KL loss: 11.1803 - beta: 0.0035 - val_val_loss: 95.0389 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1554 - val_beta: 0.0035\n",
      "Epoch 1519/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.8899 - recon_loss: 0.0011 - KL loss: 11.2094 - beta: 0.0035 - val_val_loss: 95.1811 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1820 - val_beta: 0.0035\n",
      "Epoch 1520/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95.7542 - recon_loss: 0.0011 - KL loss: 11.1798 - beta: 0.0035 - val_val_loss: 95.1580 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.2714 - val_beta: 0.0035\n",
      "Epoch 1521/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 94.7550 - recon_loss: 0.0011 - KL loss: 11.2267 - beta: 0.0035\n",
      "Epoch 01521: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.7554 - recon_loss: 0.0011 - KL loss: 11.2267 - beta: 0.0035 - val_val_loss: 95.0153 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1494 - val_beta: 0.0035\n",
      "Epoch 1522/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.9222 - recon_loss: 0.0011 - KL loss: 11.1800 - beta: 0.0035 - val_val_loss: 94.9318 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1278 - val_beta: 0.0035\n",
      "Epoch 1523/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95.0487 - recon_loss: 0.0011 - KL loss: 11.1787 - beta: 0.0035 - val_val_loss: 95.2249 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1032 - val_beta: 0.0035\n",
      "Epoch 1524/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.7152 - recon_loss: 0.0011 - KL loss: 11.1529 - beta: 0.0035 - val_val_loss: 94.8842 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1219 - val_beta: 0.0035\n",
      "Epoch 1525/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.6145 - recon_loss: 0.0011 - KL loss: 11.1421 - beta: 0.0035 - val_val_loss: 94.8069 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1471 - val_beta: 0.0035\n",
      "Epoch 1526/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.6337 - recon_loss: 0.0011 - KL loss: 11.1457 - beta: 0.0035 - val_val_loss: 94.6058 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1363 - val_beta: 0.0035\n",
      "Epoch 1527/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.3245 - recon_loss: 0.0010 - KL loss: 11.1798 - beta: 0.0035 - val_val_loss: 94.6676 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1395 - val_beta: 0.0035\n",
      "Epoch 1528/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 95.4231 - recon_loss: 0.0011 - KL loss: 11.1820 - beta: 0.0035 - val_val_loss: 94.6624 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.0987 - val_beta: 0.0035\n",
      "Epoch 1529/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.5686 - recon_loss: 0.0011 - KL loss: 11.0645 - beta: 0.0035 - val_val_loss: 94.4290 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.0927 - val_beta: 0.0035\n",
      "Epoch 1530/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.6492 - recon_loss: 0.0011 - KL loss: 11.1599 - beta: 0.0035 - val_val_loss: 95.0016 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1131 - val_beta: 0.0035\n",
      "Epoch 1531/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.0452 - recon_loss: 0.0010 - KL loss: 11.1656 - beta: 0.0035 - val_val_loss: 94.5463 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1358 - val_beta: 0.0035\n",
      "Epoch 1532/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.4251 - recon_loss: 0.0010 - KL loss: 11.1634 - beta: 0.0035 - val_val_loss: 94.5570 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1451 - val_beta: 0.0035\n",
      "Epoch 1533/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.5301 - recon_loss: 0.0010 - KL loss: 11.1690 - beta: 0.0035 - val_val_loss: 94.5919 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1215 - val_beta: 0.0035\n",
      "Epoch 1534/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 94.9622 - recon_loss: 0.0011 - KL loss: 11.1699 - beta: 0.0035\n",
      "Epoch 01534: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.9621 - recon_loss: 0.0011 - KL loss: 11.1699 - beta: 0.0035 - val_val_loss: 94.4426 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1535 - val_beta: 0.0035\n",
      "Epoch 1535/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 95.5393 - recon_loss: 0.0011 - KL loss: 11.2184 - beta: 0.0035 - val_val_loss: 94.4062 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1611 - val_beta: 0.0035\n",
      "Epoch 1536/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.5648 - recon_loss: 0.0010 - KL loss: 11.2057 - beta: 0.0035 - val_val_loss: 94.1751 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1516 - val_beta: 0.0035\n",
      "Epoch 1537/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93.5676 - recon_loss: 0.0010 - KL loss: 11.1611 - beta: 0.0035 - val_val_loss: 94.3405 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1468 - val_beta: 0.0035\n",
      "Epoch 1538/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.5359 - recon_loss: 0.0010 - KL loss: 11.1990 - beta: 0.0035 - val_val_loss: 94.0098 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1401 - val_beta: 0.0035\n",
      "Epoch 1539/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 93.6817 - recon_loss: 0.0010 - KL loss: 11.1720 - beta: 0.0035 - val_val_loss: 94.1401 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1459 - val_beta: 0.0035\n",
      "Epoch 1540/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 93.6590 - recon_loss: 0.0010 - KL loss: 11.1485 - beta: 0.0035 - val_val_loss: 94.0221 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1476 - val_beta: 0.0035\n",
      "Epoch 1541/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.3355 - recon_loss: 0.0010 - KL loss: 11.1815 - beta: 0.0035 - val_val_loss: 93.9829 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1558 - val_beta: 0.0035\n",
      "Epoch 1542/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.8288 - recon_loss: 0.0011 - KL loss: 11.1830 - beta: 0.0035 - val_val_loss: 94.1466 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1458 - val_beta: 0.0035\n",
      "Epoch 1543/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.7254 - recon_loss: 0.0011 - KL loss: 11.2042 - beta: 0.0035 - val_val_loss: 94.1122 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1434 - val_beta: 0.0035\n",
      "Epoch 1544/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.0183 - recon_loss: 0.0010 - KL loss: 11.1736 - beta: 0.0035 - val_val_loss: 94.2011 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1608 - val_beta: 0.0035\n",
      "Epoch 1545/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.8680 - recon_loss: 0.0011 - KL loss: 11.1795 - beta: 0.0035 - val_val_loss: 94.1536 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1399 - val_beta: 0.0035\n",
      "Epoch 1546/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.2093 - recon_loss: 0.0010 - KL loss: 11.1959 - beta: 0.0035 - val_val_loss: 93.9588 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1384 - val_beta: 0.0035\n",
      "Epoch 1547/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.7413 - recon_loss: 0.0011 - KL loss: 11.2110 - beta: 0.0035 - val_val_loss: 94.2316 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1461 - val_beta: 0.0035\n",
      "Epoch 1548/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.7124 - recon_loss: 0.0011 - KL loss: 11.1764 - beta: 0.0035 - val_val_loss: 94.3055 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1398 - val_beta: 0.0035\n",
      "Epoch 1549/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 93.4873 - recon_loss: 0.0010 - KL loss: 11.1242 - beta: 0.0035 - val_val_loss: 94.0277 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1485 - val_beta: 0.0035\n",
      "Epoch 1550/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.4608 - recon_loss: 0.0010 - KL loss: 11.1562 - beta: 0.0035 - val_val_loss: 94.1589 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1423 - val_beta: 0.0035\n",
      "Epoch 1551/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 93.8594 - recon_loss: 0.0010 - KL loss: 11.1738 - beta: 0.0035\n",
      "Epoch 01551: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93.8601 - recon_loss: 0.0010 - KL loss: 11.1738 - beta: 0.0035 - val_val_loss: 94.1127 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1359 - val_beta: 0.0035\n",
      "Epoch 1552/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.3349 - recon_loss: 0.0010 - KL loss: 11.1892 - beta: 0.0035 - val_val_loss: 94.2445 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1377 - val_beta: 0.0035\n",
      "Epoch 1553/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95.0994 - recon_loss: 0.0011 - KL loss: 11.1764 - beta: 0.0035 - val_val_loss: 94.2144 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1418 - val_beta: 0.0035\n",
      "Epoch 1554/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.3670 - recon_loss: 0.0010 - KL loss: 11.1456 - beta: 0.0035 - val_val_loss: 94.1848 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1429 - val_beta: 0.0035\n",
      "Epoch 1555/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.2639 - recon_loss: 0.0010 - KL loss: 11.1804 - beta: 0.0035 - val_val_loss: 94.1461 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1496 - val_beta: 0.0035\n",
      "Epoch 1556/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 94.8266 - recon_loss: 0.0011 - KL loss: 11.2005 - beta: 0.0035\n",
      "Epoch 01556: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.8266 - recon_loss: 0.0011 - KL loss: 11.2005 - beta: 0.0035 - val_val_loss: 94.0143 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1514 - val_beta: 0.0035\n",
      "Epoch 1556/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 294.6963 - recon_loss: 0.0011 - KL loss: 14.1943 - beta: 0.0020 - val_val_loss: 284.2715 - val_val_recon_loss: 0.0010 - val_val_KL loss: 15.0328 - val_beta: 0.0020\n",
      "Epoch 1557/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 287.2007 - recon_loss: 0.0011 - KL loss: 15.3142 - beta: 0.0020 - val_val_loss: 289.1927 - val_val_recon_loss: 0.0011 - val_val_KL loss: 16.0566 - val_beta: 0.0020\n",
      "Epoch 1558/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 287.3280 - recon_loss: 0.0011 - KL loss: 16.0424 - beta: 0.0020 - val_val_loss: 279.5905 - val_val_recon_loss: 0.0010 - val_val_KL loss: 15.8194 - val_beta: 0.0020\n",
      "Epoch 1559/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 278.2480 - recon_loss: 0.0010 - KL loss: 15.8241 - beta: 0.0020 - val_val_loss: 282.2134 - val_val_recon_loss: 0.0010 - val_val_KL loss: 16.1074 - val_beta: 0.0020\n",
      "Epoch 1560/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 282.7798 - recon_loss: 0.0010 - KL loss: 16.1638 - beta: 0.0020 - val_val_loss: 288.4546 - val_val_recon_loss: 0.0011 - val_val_KL loss: 16.6217 - val_beta: 0.0020\n",
      "Epoch 1561/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 288.3847 - recon_loss: 0.0011 - KL loss: 16.6875 - beta: 0.0020 - val_val_loss: 290.4715 - val_val_recon_loss: 0.0011 - val_val_KL loss: 17.1163 - val_beta: 0.0020\n",
      "Epoch 1562/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 291.3066 - recon_loss: 0.0011 - KL loss: 17.1934 - beta: 0.0020 - val_val_loss: 284.6950 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.0293 - val_beta: 0.0020\n",
      "Epoch 1563/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 290.0777 - recon_loss: 0.0011 - KL loss: 17.2118 - beta: 0.0020\n",
      "Epoch 01563: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 290.0767 - recon_loss: 0.0011 - KL loss: 17.2117 - beta: 0.0020 - val_val_loss: 286.5746 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.0086 - val_beta: 0.0020\n",
      "Epoch 1564/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 283.3914 - recon_loss: 0.0010 - KL loss: 17.0412 - beta: 0.0020 - val_val_loss: 277.3213 - val_val_recon_loss: 0.0010 - val_val_KL loss: 16.8457 - val_beta: 0.0020\n",
      "Epoch 1565/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 276.3371 - recon_loss: 0.0010 - KL loss: 16.9066 - beta: 0.0020 - val_val_loss: 276.0626 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.1856 - val_beta: 0.0020\n",
      "Epoch 1566/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 276.3639 - recon_loss: 0.0010 - KL loss: 16.9384 - beta: 0.0020 - val_val_loss: 272.1277 - val_val_recon_loss: 9.9458e-04 - val_val_KL loss: 16.5352 - val_beta: 0.0020\n",
      "Epoch 1567/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 274.1410 - recon_loss: 0.0010 - KL loss: 16.5997 - beta: 0.0020 - val_val_loss: 271.4066 - val_val_recon_loss: 9.9242e-04 - val_val_KL loss: 16.3703 - val_beta: 0.0020\n",
      "Epoch 1568/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 272.2842 - recon_loss: 9.9583e-04 - KL loss: 16.3716 - beta: 0.0020 - val_val_loss: 270.2649 - val_val_recon_loss: 9.8803e-04 - val_val_KL loss: 16.3565 - val_beta: 0.0020\n",
      "Epoch 1569/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 271.5099 - recon_loss: 9.9317e-04 - KL loss: 16.2807 - beta: 0.0020 - val_val_loss: 271.0623 - val_val_recon_loss: 9.9200e-04 - val_val_KL loss: 16.1341 - val_beta: 0.0020\n",
      "Epoch 1570/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 273.3565 - recon_loss: 0.0010 - KL loss: 16.1831 - beta: 0.0020 - val_val_loss: 271.9944 - val_val_recon_loss: 9.9582e-04 - val_val_KL loss: 16.0828 - val_beta: 0.0020\n",
      "Epoch 1571/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 271.5908 - recon_loss: 9.9488e-04 - KL loss: 15.9211 - beta: 0.0020 - val_val_loss: 270.0796 - val_val_recon_loss: 9.9083e-04 - val_val_KL loss: 15.4506 - val_beta: 0.0020\n",
      "Epoch 1572/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 268.7325 - recon_loss: 9.8569e-04 - KL loss: 15.4264 - beta: 0.0020 - val_val_loss: 265.6221 - val_val_recon_loss: 9.7394e-04 - val_val_KL loss: 15.3336 - val_beta: 0.0020\n",
      "Epoch 1573/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 265.6074 - recon_loss: 9.7415e-04 - KL loss: 15.2647 - beta: 0.0020 - val_val_loss: 263.4286 - val_val_recon_loss: 9.6596e-04 - val_val_KL loss: 15.1916 - val_beta: 0.0020\n",
      "Epoch 1574/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 263.2589 - recon_loss: 9.6552e-04 - KL loss: 15.1340 - beta: 0.0020 - val_val_loss: 266.4163 - val_val_recon_loss: 9.7833e-04 - val_val_KL loss: 15.0006 - val_beta: 0.0020\n",
      "Epoch 1575/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265.1146 - recon_loss: 9.7372e-04 - KL loss: 14.8828 - beta: 0.0020 - val_val_loss: 264.1250 - val_val_recon_loss: 9.7014e-04 - val_val_KL loss: 14.8142 - val_beta: 0.0020\n",
      "Epoch 1576/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 262.3132 - recon_loss: 9.6358e-04 - KL loss: 14.6889 - beta: 0.0020 - val_val_loss: 262.6974 - val_val_recon_loss: 9.6508e-04 - val_val_KL loss: 14.6856 - val_beta: 0.0020\n",
      "Epoch 1577/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 262.2276 - recon_loss: 9.6359e-04 - KL loss: 14.6006 - beta: 0.0020 - val_val_loss: 263.8901 - val_val_recon_loss: 9.7014e-04 - val_val_KL loss: 14.5799 - val_beta: 0.0020\n",
      "Epoch 1578/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264.4946 - recon_loss: 9.7241e-04 - KL loss: 14.6013 - beta: 0.0020 - val_val_loss: 263.9162 - val_val_recon_loss: 9.7010e-04 - val_val_KL loss: 14.6164 - val_beta: 0.0020\n",
      "Epoch 1579/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 263.7164 - recon_loss: 9.7004e-04 - KL loss: 14.4305 - beta: 0.0020 - val_val_loss: 263.0760 - val_val_recon_loss: 9.6835e-04 - val_val_KL loss: 14.2245 - val_beta: 0.0020\n",
      "Epoch 1580/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 262.9643 - recon_loss: 9.6771e-04 - KL loss: 14.2790 - beta: 0.0020 - val_val_loss: 263.3329 - val_val_recon_loss: 9.6955e-04 - val_val_KL loss: 14.1743 - val_beta: 0.0020\n",
      "Epoch 1581/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265.1524 - recon_loss: 9.7671e-04 - KL loss: 14.1527 - beta: 0.0020 - val_val_loss: 261.6140 - val_val_recon_loss: 9.6344e-04 - val_val_KL loss: 14.0247 - val_beta: 0.0020\n",
      "Epoch 1582/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264.8464 - recon_loss: 9.7595e-04 - KL loss: 14.0420 - beta: 0.0020 - val_val_loss: 259.2641 - val_val_recon_loss: 9.5422e-04 - val_val_KL loss: 14.0444 - val_beta: 0.0020\n",
      "Epoch 1583/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 260.0304 - recon_loss: 9.5722e-04 - KL loss: 14.0384 - beta: 0.0020 - val_val_loss: 259.7224 - val_val_recon_loss: 9.5600e-04 - val_val_KL loss: 14.0441 - val_beta: 0.0020\n",
      "Epoch 1584/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 259.1359 - recon_loss: 9.5370e-04 - KL loss: 14.0493 - beta: 0.0020 - val_val_loss: 260.2354 - val_val_recon_loss: 9.5839e-04 - val_val_KL loss: 13.9434 - val_beta: 0.0020\n",
      "Epoch 1585/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 258.9052 - recon_loss: 9.5325e-04 - KL loss: 13.9334 - beta: 0.0020 - val_val_loss: 259.9172 - val_val_recon_loss: 9.5686e-04 - val_val_KL loss: 14.0186 - val_beta: 0.0020\n",
      "Epoch 1586/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 261.3130 - recon_loss: 9.6269e-04 - KL loss: 13.9160 - beta: 0.0020 - val_val_loss: 259.4178 - val_val_recon_loss: 9.5583e-04 - val_val_KL loss: 13.7854 - val_beta: 0.0020\n",
      "Epoch 1587/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 259.3152 - recon_loss: 9.5516e-04 - KL loss: 13.8527 - beta: 0.0020 - val_val_loss: 257.2420 - val_val_recon_loss: 9.4763e-04 - val_val_KL loss: 13.7151 - val_beta: 0.0020\n",
      "Epoch 1588/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 257.7460 - recon_loss: 9.4931e-04 - KL loss: 13.7883 - beta: 0.0020 - val_val_loss: 257.5017 - val_val_recon_loss: 9.4860e-04 - val_val_KL loss: 13.7272 - val_beta: 0.0020\n",
      "Epoch 1589/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 257.2435 - recon_loss: 9.4740e-04 - KL loss: 13.7751 - beta: 0.0020 - val_val_loss: 257.6917 - val_val_recon_loss: 9.4935e-04 - val_val_KL loss: 13.7234 - val_beta: 0.0020\n",
      "Epoch 1590/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 257.0986 - recon_loss: 9.4686e-04 - KL loss: 13.7710 - beta: 0.0020 - val_val_loss: 256.7947 - val_val_recon_loss: 9.4537e-04 - val_val_KL loss: 13.8500 - val_beta: 0.0020\n",
      "Epoch 1591/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 256.7740 - recon_loss: 9.4543e-04 - KL loss: 13.8132 - beta: 0.0020 - val_val_loss: 257.7301 - val_val_recon_loss: 9.4895e-04 - val_val_KL loss: 13.8634 - val_beta: 0.0020\n",
      "Epoch 1592/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 256.4252 - recon_loss: 9.4390e-04 - KL loss: 13.8565 - beta: 0.0020 - val_val_loss: 259.3503 - val_val_recon_loss: 9.5549e-04 - val_val_KL loss: 13.8038 - val_beta: 0.0020\n",
      "Epoch 1593/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 258.0012 - recon_loss: 9.4995e-04 - KL loss: 13.8798 - beta: 0.0020 - val_val_loss: 258.1379 - val_val_recon_loss: 9.5079e-04 - val_val_KL loss: 13.7991 - val_beta: 0.0020\n",
      "Epoch 1594/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 256.0505 - recon_loss: 9.4252e-04 - KL loss: 13.8380 - beta: 0.0020 - val_val_loss: 257.5441 - val_val_recon_loss: 9.4818e-04 - val_val_KL loss: 13.8768 - val_beta: 0.0020\n",
      "Epoch 1595/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 259.0228 - recon_loss: 9.5363e-04 - KL loss: 13.9541 - beta: 0.0020\n",
      "Epoch 01595: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 259.0221 - recon_loss: 9.5363e-04 - KL loss: 13.9541 - beta: 0.0020 - val_val_loss: 257.6218 - val_val_recon_loss: 9.4811e-04 - val_val_KL loss: 13.9729 - val_beta: 0.0020\n",
      "Epoch 1596/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 256.6522 - recon_loss: 9.4447e-04 - KL loss: 13.9373 - beta: 0.0020 - val_val_loss: 255.5041 - val_val_recon_loss: 9.3995e-04 - val_val_KL loss: 13.9514 - val_beta: 0.0020\n",
      "Epoch 1597/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 256.9466 - recon_loss: 9.4537e-04 - KL loss: 13.9999 - beta: 0.0020 - val_val_loss: 254.5704 - val_val_recon_loss: 9.3620e-04 - val_val_KL loss: 13.9804 - val_beta: 0.0020\n",
      "Epoch 1598/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 254.4854 - recon_loss: 9.3565e-04 - KL loss: 14.0384 - beta: 0.0020 - val_val_loss: 254.3285 - val_val_recon_loss: 9.3504e-04 - val_val_KL loss: 14.0383 - val_beta: 0.0020\n",
      "Epoch 1599/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 254.5176 - recon_loss: 9.3583e-04 - KL loss: 14.0241 - beta: 0.0020 - val_val_loss: 254.6265 - val_val_recon_loss: 9.3617e-04 - val_val_KL loss: 14.0441 - val_beta: 0.0020\n",
      "Epoch 1600/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 251.3876 - recon_loss: 9.2358e-04 - KL loss: 14.0412 - beta: 0.0020 - val_val_loss: 253.6315 - val_val_recon_loss: 9.3253e-04 - val_val_KL loss: 13.9851 - val_beta: 0.0020\n",
      "Epoch 1601/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 254.9989 - recon_loss: 9.3769e-04 - KL loss: 14.0275 - beta: 0.0020 - val_val_loss: 253.8636 - val_val_recon_loss: 9.3328e-04 - val_val_KL loss: 14.0259 - val_beta: 0.0020\n",
      "Epoch 1602/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 252.1221 - recon_loss: 9.2653e-04 - KL loss: 14.0177 - beta: 0.0020 - val_val_loss: 253.7916 - val_val_recon_loss: 9.3323e-04 - val_val_KL loss: 13.9669 - val_beta: 0.0020\n",
      "Epoch 1603/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 252.7088 - recon_loss: 9.2871e-04 - KL loss: 14.0448 - beta: 0.0020 - val_val_loss: 254.4710 - val_val_recon_loss: 9.3548e-04 - val_val_KL loss: 14.0670 - val_beta: 0.0020\n",
      "Epoch 1604/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 254.1042 - recon_loss: 9.3415e-04 - KL loss: 14.0414 - beta: 0.0020 - val_val_loss: 253.5023 - val_val_recon_loss: 9.3201e-04 - val_val_KL loss: 13.9892 - val_beta: 0.0020\n",
      "Epoch 1605/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 254.1722 - recon_loss: 9.3456e-04 - KL loss: 14.0043 - beta: 0.0020 - val_val_loss: 253.7865 - val_val_recon_loss: 9.3287e-04 - val_val_KL loss: 14.0523 - val_beta: 0.0020\n",
      "Epoch 1606/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 252.9883 - recon_loss: 9.2984e-04 - KL loss: 14.0332 - beta: 0.0020 - val_val_loss: 254.0349 - val_val_recon_loss: 9.3406e-04 - val_val_KL loss: 13.9964 - val_beta: 0.0020\n",
      "Epoch 1607/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 254.7881 - recon_loss: 9.3680e-04 - KL loss: 14.0438 - beta: 0.0020 - val_val_loss: 254.1943 - val_val_recon_loss: 9.3463e-04 - val_val_KL loss: 14.0086 - val_beta: 0.0020\n",
      "Epoch 1608/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 253.9416 - recon_loss: 9.3342e-04 - KL loss: 14.0659 - beta: 0.0020 - val_val_loss: 254.9288 - val_val_recon_loss: 9.3741e-04 - val_val_KL loss: 14.0297 - val_beta: 0.0020\n",
      "Epoch 1609/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 252.7359 - recon_loss: 9.2865e-04 - KL loss: 14.0876 - beta: 0.0020\n",
      "Epoch 01609: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 252.7363 - recon_loss: 9.2865e-04 - KL loss: 14.0876 - beta: 0.0020 - val_val_loss: 254.8295 - val_val_recon_loss: 9.3691e-04 - val_val_KL loss: 14.0584 - val_beta: 0.0020\n",
      "Epoch 1610/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 257.3530 - recon_loss: 9.4665e-04 - KL loss: 14.0782 - beta: 0.0020 - val_val_loss: 254.4655 - val_val_recon_loss: 9.3535e-04 - val_val_KL loss: 14.0940 - val_beta: 0.0020\n",
      "Epoch 1611/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 251.8343 - recon_loss: 9.2506e-04 - KL loss: 14.1077 - beta: 0.0020 - val_val_loss: 254.9639 - val_val_recon_loss: 9.3730e-04 - val_val_KL loss: 14.0927 - val_beta: 0.0020\n",
      "Epoch 1612/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 253.4770 - recon_loss: 9.3131e-04 - KL loss: 14.1435 - beta: 0.0020 - val_val_loss: 254.1640 - val_val_recon_loss: 9.3428e-04 - val_val_KL loss: 14.0685 - val_beta: 0.0020\n",
      "Epoch 1613/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 254.2472 - recon_loss: 9.3452e-04 - KL loss: 14.0896 - beta: 0.0020 - val_val_loss: 254.2812 - val_val_recon_loss: 9.3478e-04 - val_val_KL loss: 14.0570 - val_beta: 0.0020\n",
      "Epoch 1614/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 252.5868 - recon_loss: 9.2799e-04 - KL loss: 14.1072 - beta: 0.0020\n",
      "Epoch 01614: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 252.5867 - recon_loss: 9.2799e-04 - KL loss: 14.1072 - beta: 0.0020 - val_val_loss: 254.6856 - val_val_recon_loss: 9.3633e-04 - val_val_KL loss: 14.0636 - val_beta: 0.0020\n",
      "Epoch 1614/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 835.9469 - recon_loss: 9.8543e-04 - KL loss: 16.4586 - beta: 0.0011 - val_val_loss: 815.3420 - val_val_recon_loss: 9.6045e-04 - val_val_KL loss: 16.6264 - val_beta: 0.0011\n",
      "Epoch 1615/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 814.8295 - recon_loss: 9.5908e-04 - KL loss: 17.2564 - beta: 0.0011 - val_val_loss: 821.2053 - val_val_recon_loss: 9.6546e-04 - val_val_KL loss: 18.3265 - val_beta: 0.0011\n",
      "Epoch 1616/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 819.2088 - recon_loss: 9.6318e-04 - KL loss: 18.2235 - beta: 0.0011 - val_val_loss: 803.8745 - val_val_recon_loss: 9.4554e-04 - val_val_KL loss: 17.5567 - val_beta: 0.0011\n",
      "Epoch 1617/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 783.6957 - recon_loss: 9.2127e-04 - KL loss: 17.5627 - beta: 0.0011 - val_val_loss: 779.6004 - val_val_recon_loss: 9.1642e-04 - val_val_KL loss: 17.5018 - val_beta: 0.0011\n",
      "Epoch 1618/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 794.7201 - recon_loss: 9.3457e-04 - KL loss: 17.5300 - beta: 0.0011 - val_val_loss: 788.5203 - val_val_recon_loss: 9.2732e-04 - val_val_KL loss: 17.3595 - val_beta: 0.0011\n",
      "Epoch 1619/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 783.5730 - recon_loss: 9.2121e-04 - KL loss: 17.4857 - beta: 0.0011 - val_val_loss: 787.6068 - val_val_recon_loss: 9.2637e-04 - val_val_KL loss: 17.2347 - val_beta: 0.0011\n",
      "Epoch 1620/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 780.0765 - recon_loss: 9.1707e-04 - KL loss: 17.4333 - beta: 0.0011 - val_val_loss: 768.6177 - val_val_recon_loss: 9.0296e-04 - val_val_KL loss: 17.7072 - val_beta: 0.0011\n",
      "Epoch 1621/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 776.7040 - recon_loss: 9.1251e-04 - KL loss: 17.8533 - beta: 0.0011 - val_val_loss: 765.7119 - val_val_recon_loss: 8.9907e-04 - val_val_KL loss: 18.0440 - val_beta: 0.0011\n",
      "Epoch 1622/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 766.7344 - recon_loss: 9.0024e-04 - KL loss: 18.0938 - beta: 0.0011 - val_val_loss: 776.0240 - val_val_recon_loss: 9.1196e-04 - val_val_KL loss: 17.6342 - val_beta: 0.0011\n",
      "Epoch 1623/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 761.3336 - recon_loss: 8.9386e-04 - KL loss: 17.9974 - beta: 0.0011 - val_val_loss: 770.9543 - val_val_recon_loss: 9.0494e-04 - val_val_KL loss: 18.4025 - val_beta: 0.0011\n",
      "Epoch 1624/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 769.0716 - recon_loss: 9.0213e-04 - KL loss: 18.8565 - beta: 0.0011 - val_val_loss: 766.0119 - val_val_recon_loss: 8.9807e-04 - val_val_KL loss: 19.1727 - val_beta: 0.0011\n",
      "Epoch 1625/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 756.9323 - recon_loss: 8.8696e-04 - KL loss: 19.3322 - beta: 0.0011 - val_val_loss: 751.4730 - val_val_recon_loss: 8.8130e-04 - val_val_KL loss: 18.5790 - val_beta: 0.0011\n",
      "Epoch 1626/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 758.6018 - recon_loss: 8.8922e-04 - KL loss: 19.1209 - beta: 0.0011 - val_val_loss: 763.1834 - val_val_recon_loss: 8.9484e-04 - val_val_KL loss: 19.0311 - val_beta: 0.0011\n",
      "Epoch 1627/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 763.6077 - recon_loss: 8.9512e-04 - KL loss: 19.2212 - beta: 0.0011 - val_val_loss: 759.2870 - val_val_recon_loss: 8.8993e-04 - val_val_KL loss: 19.2166 - val_beta: 0.0011\n",
      "Epoch 1628/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 751.4255 - recon_loss: 8.8037e-04 - KL loss: 19.3080 - beta: 0.0011 - val_val_loss: 748.0732 - val_val_recon_loss: 8.7650e-04 - val_val_KL loss: 19.1712 - val_beta: 0.0011\n",
      "Epoch 1629/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 751.0672 - recon_loss: 8.7986e-04 - KL loss: 19.3708 - beta: 0.0011 - val_val_loss: 760.5078 - val_val_recon_loss: 8.9028e-04 - val_val_KL loss: 20.1422 - val_beta: 0.0011\n",
      "Epoch 1630/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 762.0158 - recon_loss: 8.9166e-04 - KL loss: 20.5052 - beta: 0.0011 - val_val_loss: 802.2679 - val_val_recon_loss: 9.3756e-04 - val_val_KL loss: 22.5905 - val_beta: 0.0011\n",
      "Epoch 1631/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 804.1535 - recon_loss: 9.3970e-04 - KL loss: 22.6920 - beta: 0.0011 - val_val_loss: 754.0341 - val_val_recon_loss: 8.8060e-04 - val_val_KL loss: 21.7219 - val_beta: 0.0011\n",
      "Epoch 1632/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 750.1702 - recon_loss: 8.7593e-04 - KL loss: 21.7384 - beta: 0.0011 - val_val_loss: 750.6075 - val_val_recon_loss: 8.7618e-04 - val_val_KL loss: 21.9701 - val_beta: 0.0011\n",
      "Epoch 1633/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 752.2823 - recon_loss: 8.7832e-04 - KL loss: 21.8639 - beta: 0.0011\n",
      "Epoch 01633: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 752.2844 - recon_loss: 8.7833e-04 - KL loss: 21.8644 - beta: 0.0011 - val_val_loss: 752.8289 - val_val_recon_loss: 8.7813e-04 - val_val_KL loss: 22.5737 - val_beta: 0.0011\n",
      "Epoch 1634/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 738.3443 - recon_loss: 8.6090e-04 - KL loss: 22.4131 - beta: 0.0011 - val_val_loss: 729.5279 - val_val_recon_loss: 8.5088e-04 - val_val_KL loss: 21.9347 - val_beta: 0.0011\n",
      "Epoch 1635/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 729.0186 - recon_loss: 8.5008e-04 - KL loss: 22.0881 - beta: 0.0011 - val_val_loss: 723.5016 - val_val_recon_loss: 8.4402e-04 - val_val_KL loss: 21.6085 - val_beta: 0.0011\n",
      "Epoch 1636/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 718.7290 - recon_loss: 8.3802e-04 - KL loss: 21.8292 - beta: 0.0011 - val_val_loss: 716.4914 - val_val_recon_loss: 8.3532e-04 - val_val_KL loss: 21.8385 - val_beta: 0.0011\n",
      "Epoch 1637/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 712.0658 - recon_loss: 8.2986e-04 - KL loss: 21.9498 - beta: 0.0011 - val_val_loss: 715.8054 - val_val_recon_loss: 8.3431e-04 - val_val_KL loss: 21.9906 - val_beta: 0.0011\n",
      "Epoch 1638/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 716.1115 - recon_loss: 8.3483e-04 - KL loss: 21.8582 - beta: 0.0011 - val_val_loss: 716.8420 - val_val_recon_loss: 8.3589e-04 - val_val_KL loss: 21.7147 - val_beta: 0.0011\n",
      "Epoch 1639/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 709.0688 - recon_loss: 8.2668e-04 - KL loss: 21.6004 - beta: 0.0011 - val_val_loss: 714.3251 - val_val_recon_loss: 8.3292e-04 - val_val_KL loss: 21.6614 - val_beta: 0.0011\n",
      "Epoch 1640/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 708.7456 - recon_loss: 8.2602e-04 - KL loss: 21.8208 - beta: 0.0011 - val_val_loss: 713.1715 - val_val_recon_loss: 8.3126e-04 - val_val_KL loss: 21.8884 - val_beta: 0.0011\n",
      "Epoch 1641/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 711.2100 - recon_loss: 8.2883e-04 - KL loss: 21.9460 - beta: 0.0011 - val_val_loss: 710.5932 - val_val_recon_loss: 8.2826e-04 - val_val_KL loss: 21.8077 - val_beta: 0.0011\n",
      "Epoch 1642/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 705.5420 - recon_loss: 8.2202e-04 - KL loss: 21.9491 - beta: 0.0011 - val_val_loss: 706.4683 - val_val_recon_loss: 8.2330e-04 - val_val_KL loss: 21.8035 - val_beta: 0.0011\n",
      "Epoch 1643/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 714.2500 - recon_loss: 8.3233e-04 - KL loss: 22.0829 - beta: 0.0011 - val_val_loss: 707.1428 - val_val_recon_loss: 8.2409e-04 - val_val_KL loss: 21.8277 - val_beta: 0.0011\n",
      "Epoch 1644/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 706.2355 - recon_loss: 8.2271e-04 - KL loss: 22.0683 - beta: 0.0011 - val_val_loss: 706.0074 - val_val_recon_loss: 8.2284e-04 - val_val_KL loss: 21.7294 - val_beta: 0.0011\n",
      "Epoch 1645/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 700.1099 - recon_loss: 8.1552e-04 - KL loss: 21.9215 - beta: 0.0011 - val_val_loss: 705.8359 - val_val_recon_loss: 8.2225e-04 - val_val_KL loss: 22.0455 - val_beta: 0.0011\n",
      "Epoch 1646/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 706.1820 - recon_loss: 8.2243e-04 - KL loss: 22.2486 - beta: 0.0011 - val_val_loss: 703.5526 - val_val_recon_loss: 8.1939e-04 - val_val_KL loss: 22.1459 - val_beta: 0.0011\n",
      "Epoch 1647/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 700.5872 - recon_loss: 8.1555e-04 - KL loss: 22.3697 - beta: 0.0011 - val_val_loss: 701.4130 - val_val_recon_loss: 8.1661e-04 - val_val_KL loss: 22.3146 - val_beta: 0.0011\n",
      "Epoch 1648/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 698.6120 - recon_loss: 8.1318e-04 - KL loss: 22.3659 - beta: 0.0011 - val_val_loss: 706.8513 - val_val_recon_loss: 8.2287e-04 - val_val_KL loss: 22.5455 - val_beta: 0.0011\n",
      "Epoch 1649/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 697.1945 - recon_loss: 8.1129e-04 - KL loss: 22.5203 - beta: 0.0011 - val_val_loss: 705.9481 - val_val_recon_loss: 8.2179e-04 - val_val_KL loss: 22.5437 - val_beta: 0.0011\n",
      "Epoch 1650/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 707.9942 - recon_loss: 8.2389e-04 - KL loss: 22.8381 - beta: 0.0011 - val_val_loss: 704.4314 - val_val_recon_loss: 8.1959e-04 - val_val_KL loss: 22.8585 - val_beta: 0.0011\n",
      "Epoch 1651/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 708.6058 - recon_loss: 8.2417e-04 - KL loss: 23.2230 - beta: 0.0011 - val_val_loss: 708.4532 - val_val_recon_loss: 8.2406e-04 - val_val_KL loss: 23.1634 - val_beta: 0.0011\n",
      "Epoch 1652/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 703.9025 - recon_loss: 8.1872e-04 - KL loss: 23.0511 - beta: 0.0011\n",
      "Epoch 01652: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 703.8979 - recon_loss: 8.1871e-04 - KL loss: 23.0511 - beta: 0.0011 - val_val_loss: 706.4995 - val_val_recon_loss: 8.2157e-04 - val_val_KL loss: 23.2766 - val_beta: 0.0011\n",
      "Epoch 1653/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 704.5577 - recon_loss: 8.1915e-04 - KL loss: 23.3444 - beta: 0.0011 - val_val_loss: 706.0739 - val_val_recon_loss: 8.2090e-04 - val_val_KL loss: 23.4059 - val_beta: 0.0011\n",
      "Epoch 1654/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 697.8438 - recon_loss: 8.1098e-04 - KL loss: 23.4306 - beta: 0.0011 - val_val_loss: 701.5933 - val_val_recon_loss: 8.1571e-04 - val_val_KL loss: 23.2437 - val_beta: 0.0011\n",
      "Epoch 1655/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 706.7415 - recon_loss: 8.2158e-04 - KL loss: 23.5131 - beta: 0.0011 - val_val_loss: 698.7149 - val_val_recon_loss: 8.1225e-04 - val_val_KL loss: 23.2446 - val_beta: 0.0011\n",
      "Epoch 1656/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 694.0353 - recon_loss: 8.0640e-04 - KL loss: 23.4280 - beta: 0.0011 - val_val_loss: 695.9814 - val_val_recon_loss: 8.0896e-04 - val_val_KL loss: 23.2464 - val_beta: 0.0011\n",
      "Epoch 1657/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 693.8276 - recon_loss: 8.0603e-04 - KL loss: 23.5294 - beta: 0.0011 - val_val_loss: 697.6355 - val_val_recon_loss: 8.1077e-04 - val_val_KL loss: 23.3904 - val_beta: 0.0011\n",
      "Epoch 1658/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 696.1085 - recon_loss: 8.0880e-04 - KL loss: 23.5027 - beta: 0.0011 - val_val_loss: 697.1534 - val_val_recon_loss: 8.1015e-04 - val_val_KL loss: 23.4251 - val_beta: 0.0011\n",
      "Epoch 1659/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 691.9333 - recon_loss: 8.0374e-04 - KL loss: 23.5410 - beta: 0.0011 - val_val_loss: 695.0499 - val_val_recon_loss: 8.0780e-04 - val_val_KL loss: 23.2785 - val_beta: 0.0011\n",
      "Epoch 1660/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 690.9695 - recon_loss: 8.0276e-04 - KL loss: 23.3923 - beta: 0.0011 - val_val_loss: 693.1733 - val_val_recon_loss: 8.0547e-04 - val_val_KL loss: 23.3440 - val_beta: 0.0011\n",
      "Epoch 1661/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 692.3152 - recon_loss: 8.0432e-04 - KL loss: 23.4408 - beta: 0.0011 - val_val_loss: 693.4396 - val_val_recon_loss: 8.0597e-04 - val_val_KL loss: 23.1879 - val_beta: 0.0011\n",
      "Epoch 1662/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 686.6062 - recon_loss: 7.9764e-04 - KL loss: 23.2879 - beta: 0.0011 - val_val_loss: 693.9955 - val_val_recon_loss: 8.0677e-04 - val_val_KL loss: 23.0794 - val_beta: 0.0011\n",
      "Epoch 1663/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 687.0097 - recon_loss: 7.9821e-04 - KL loss: 23.2170 - beta: 0.0011 - val_val_loss: 691.6865 - val_val_recon_loss: 8.0396e-04 - val_val_KL loss: 23.1125 - val_beta: 0.0011\n",
      "Epoch 1664/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 688.4851 - recon_loss: 7.9989e-04 - KL loss: 23.2879 - beta: 0.0011 - val_val_loss: 690.5345 - val_val_recon_loss: 8.0264e-04 - val_val_KL loss: 23.0521 - val_beta: 0.0011\n",
      "Epoch 1665/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 684.1678 - recon_loss: 7.9483e-04 - KL loss: 23.1826 - beta: 0.0011 - val_val_loss: 690.4040 - val_val_recon_loss: 8.0255e-04 - val_val_KL loss: 23.0033 - val_beta: 0.0011\n",
      "Epoch 1666/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 691.7114 - recon_loss: 8.0396e-04 - KL loss: 23.1369 - beta: 0.0011 - val_val_loss: 689.1689 - val_val_recon_loss: 8.0118e-04 - val_val_KL loss: 22.9061 - val_beta: 0.0011\n",
      "Epoch 1667/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 692.5383 - recon_loss: 8.0504e-04 - KL loss: 23.0631 - beta: 0.0011 - val_val_loss: 688.4843 - val_val_recon_loss: 8.0010e-04 - val_val_KL loss: 23.1150 - val_beta: 0.0011\n",
      "Epoch 1668/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 684.8506 - recon_loss: 7.9551e-04 - KL loss: 23.2981 - beta: 0.0011 - val_val_loss: 687.5109 - val_val_recon_loss: 7.9896e-04 - val_val_KL loss: 23.0888 - val_beta: 0.0011\n",
      "Epoch 1669/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 679.5609 - recon_loss: 7.8928e-04 - KL loss: 23.1928 - beta: 0.0011 - val_val_loss: 687.1417 - val_val_recon_loss: 7.9856e-04 - val_val_KL loss: 23.0555 - val_beta: 0.0011\n",
      "Epoch 1670/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 688.8916 - recon_loss: 8.0050e-04 - KL loss: 23.1900 - beta: 0.0011 - val_val_loss: 685.4658 - val_val_recon_loss: 7.9635e-04 - val_val_KL loss: 23.2162 - val_beta: 0.0011\n",
      "Epoch 1671/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 683.0277 - recon_loss: 7.9336e-04 - KL loss: 23.2660 - beta: 0.0011 - val_val_loss: 685.8694 - val_val_recon_loss: 7.9716e-04 - val_val_KL loss: 22.9476 - val_beta: 0.0011\n",
      "Epoch 1672/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 687.2119 - recon_loss: 7.9851e-04 - KL loss: 23.1636 - beta: 0.0011 - val_val_loss: 686.1038 - val_val_recon_loss: 7.9744e-04 - val_val_KL loss: 22.9447 - val_beta: 0.0011\n",
      "Epoch 1673/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 677.3520 - recon_loss: 7.8674e-04 - KL loss: 23.0966 - beta: 0.0011 - val_val_loss: 685.7820 - val_val_recon_loss: 7.9678e-04 - val_val_KL loss: 23.1792 - val_beta: 0.0011\n",
      "Epoch 1674/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 681.4421 - recon_loss: 7.9145e-04 - KL loss: 23.2655 - beta: 0.0011 - val_val_loss: 685.6281 - val_val_recon_loss: 7.9661e-04 - val_val_KL loss: 23.1641 - val_beta: 0.0011\n",
      "Epoch 1675/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 687.8803 - recon_loss: 7.9921e-04 - KL loss: 23.2548 - beta: 0.0011 - val_val_loss: 684.3836 - val_val_recon_loss: 7.9507e-04 - val_val_KL loss: 23.1972 - val_beta: 0.0011\n",
      "Epoch 1676/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 675.6329 - recon_loss: 7.8455e-04 - KL loss: 23.1936 - beta: 0.0011 - val_val_loss: 685.1590 - val_val_recon_loss: 7.9639e-04 - val_val_KL loss: 22.8753 - val_beta: 0.0011\n",
      "Epoch 1677/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 687.6157 - recon_loss: 7.9906e-04 - KL loss: 23.1126 - beta: 0.0011 - val_val_loss: 685.1852 - val_val_recon_loss: 7.9636e-04 - val_val_KL loss: 22.9247 - val_beta: 0.0011\n",
      "Epoch 1678/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 681.3077 - recon_loss: 7.9165e-04 - KL loss: 22.9641 - beta: 0.0011 - val_val_loss: 684.7581 - val_val_recon_loss: 7.9584e-04 - val_val_KL loss: 22.9359 - val_beta: 0.0011\n",
      "Epoch 1679/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 676.8401 - recon_loss: 7.8616e-04 - KL loss: 23.0644 - beta: 0.0011 - val_val_loss: 683.7397 - val_val_recon_loss: 7.9456e-04 - val_val_KL loss: 22.9775 - val_beta: 0.0011\n",
      "Epoch 1680/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 688.6983 - recon_loss: 8.0047e-04 - KL loss: 23.0269 - beta: 0.0011 - val_val_loss: 683.4498 - val_val_recon_loss: 7.9413e-04 - val_val_KL loss: 23.0475 - val_beta: 0.0011\n",
      "Epoch 1681/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 676.2397 - recon_loss: 7.8547e-04 - KL loss: 23.0389 - beta: 0.0011 - val_val_loss: 681.9539 - val_val_recon_loss: 7.9215e-04 - val_val_KL loss: 23.2004 - val_beta: 0.0011\n",
      "Epoch 1682/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 677.5733 - recon_loss: 7.8679e-04 - KL loss: 23.2704 - beta: 0.0011 - val_val_loss: 683.5206 - val_val_recon_loss: 7.9420e-04 - val_val_KL loss: 23.0590 - val_beta: 0.0011\n",
      "Epoch 1683/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 683.3933 - recon_loss: 7.9374e-04 - KL loss: 23.3182 - beta: 0.0011 - val_val_loss: 683.5894 - val_val_recon_loss: 7.9412e-04 - val_val_KL loss: 23.1986 - val_beta: 0.0011\n",
      "Epoch 1684/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 678.9436 - recon_loss: 7.8848e-04 - KL loss: 23.2365 - beta: 0.0011 - val_val_loss: 680.0818 - val_val_recon_loss: 7.8999e-04 - val_val_KL loss: 23.1253 - val_beta: 0.0011\n",
      "Epoch 1685/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 674.7662 - recon_loss: 7.8357e-04 - KL loss: 23.1474 - beta: 0.0011 - val_val_loss: 682.7277 - val_val_recon_loss: 7.9332e-04 - val_val_KL loss: 22.9998 - val_beta: 0.0011\n",
      "Epoch 1686/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 679.6140 - recon_loss: 7.8929e-04 - KL loss: 23.2319 - beta: 0.0011 - val_val_loss: 681.1002 - val_val_recon_loss: 7.9125e-04 - val_val_KL loss: 23.0901 - val_beta: 0.0011\n",
      "Epoch 1687/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 680.1645 - recon_loss: 7.8983e-04 - KL loss: 23.3369 - beta: 0.0011 - val_val_loss: 679.5798 - val_val_recon_loss: 7.8935e-04 - val_val_KL loss: 23.1484 - val_beta: 0.0011\n",
      "Epoch 1688/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 676.3957 - recon_loss: 7.8547e-04 - KL loss: 23.1937 - beta: 0.0011 - val_val_loss: 679.4469 - val_val_recon_loss: 7.8907e-04 - val_val_KL loss: 23.2523 - val_beta: 0.0011\n",
      "Epoch 1689/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 681.0183 - recon_loss: 7.9092e-04 - KL loss: 23.2815 - beta: 0.0011 - val_val_loss: 679.6406 - val_val_recon_loss: 7.8944e-04 - val_val_KL loss: 23.1337 - val_beta: 0.0011\n",
      "Epoch 1690/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 670.6944 - recon_loss: 7.7867e-04 - KL loss: 23.1459 - beta: 0.0011 - val_val_loss: 678.6266 - val_val_recon_loss: 7.8807e-04 - val_val_KL loss: 23.2631 - val_beta: 0.0011\n",
      "Epoch 1691/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 676.8434 - recon_loss: 7.8568e-04 - KL loss: 23.4641 - beta: 0.0011 - val_val_loss: 680.3977 - val_val_recon_loss: 7.9038e-04 - val_val_KL loss: 23.1136 - val_beta: 0.0011\n",
      "Epoch 1692/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 679.0368 - recon_loss: 7.8860e-04 - KL loss: 23.2355 - beta: 0.0011 - val_val_loss: 680.5416 - val_val_recon_loss: 7.9062e-04 - val_val_KL loss: 23.0557 - val_beta: 0.0011\n",
      "Epoch 1693/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 677.6650 - recon_loss: 7.8694e-04 - KL loss: 23.2410 - beta: 0.0011 - val_val_loss: 681.1808 - val_val_recon_loss: 7.9144e-04 - val_val_KL loss: 23.0164 - val_beta: 0.0011\n",
      "Epoch 1694/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 673.2929 - recon_loss: 7.8179e-04 - KL loss: 23.1497 - beta: 0.0011 - val_val_loss: 679.1357 - val_val_recon_loss: 7.8888e-04 - val_val_KL loss: 23.0999 - val_beta: 0.0011\n",
      "Epoch 1695/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 674.1304 - recon_loss: 7.8276e-04 - KL loss: 23.1840 - beta: 0.0011 - val_val_loss: 677.4131 - val_val_recon_loss: 7.8667e-04 - val_val_KL loss: 23.2174 - val_beta: 0.0011\n",
      "Epoch 1696/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 675.3543 - recon_loss: 7.8407e-04 - KL loss: 23.3140 - beta: 0.0011 - val_val_loss: 677.5703 - val_val_recon_loss: 7.8677e-04 - val_val_KL loss: 23.2844 - val_beta: 0.0011\n",
      "Epoch 1697/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 675.1985 - recon_loss: 7.8397e-04 - KL loss: 23.2412 - beta: 0.0011 - val_val_loss: 678.4183 - val_val_recon_loss: 7.8796e-04 - val_val_KL loss: 23.1493 - val_beta: 0.0011\n",
      "Epoch 1698/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 679.7901 - recon_loss: 7.8942e-04 - KL loss: 23.3064 - beta: 0.0011 - val_val_loss: 678.2449 - val_val_recon_loss: 7.8785e-04 - val_val_KL loss: 23.0639 - val_beta: 0.0011\n",
      "Epoch 1699/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 676.8182 - recon_loss: 7.8595e-04 - KL loss: 23.2219 - beta: 0.0011 - val_val_loss: 677.6689 - val_val_recon_loss: 7.8728e-04 - val_val_KL loss: 22.9594 - val_beta: 0.0011\n",
      "Epoch 1700/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 670.2691 - recon_loss: 7.7805e-04 - KL loss: 23.2423 - beta: 0.0011 - val_val_loss: 677.4104 - val_val_recon_loss: 7.8664e-04 - val_val_KL loss: 23.2376 - val_beta: 0.0011\n",
      "Epoch 1701/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 680.0389 - recon_loss: 7.8978e-04 - KL loss: 23.2563 - beta: 0.0011 - val_val_loss: 677.5576 - val_val_recon_loss: 7.8682e-04 - val_val_KL loss: 23.2360 - val_beta: 0.0011\n",
      "Epoch 1702/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 681.5668 - recon_loss: 7.9143e-04 - KL loss: 23.4092 - beta: 0.0011 - val_val_loss: 677.3703 - val_val_recon_loss: 7.8660e-04 - val_val_KL loss: 23.2286 - val_beta: 0.0011\n",
      "Epoch 1703/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 674.0559 - recon_loss: 7.8238e-04 - KL loss: 23.4224 - beta: 0.0011 - val_val_loss: 676.5923 - val_val_recon_loss: 7.8550e-04 - val_val_KL loss: 23.3636 - val_beta: 0.0011\n",
      "Epoch 1704/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 667.2695 - recon_loss: 7.7428e-04 - KL loss: 23.3712 - beta: 0.0011 - val_val_loss: 676.2756 - val_val_recon_loss: 7.8488e-04 - val_val_KL loss: 23.5613 - val_beta: 0.0011\n",
      "Epoch 1705/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 673.5994 - recon_loss: 7.8165e-04 - KL loss: 23.5739 - beta: 0.0011 - val_val_loss: 678.0891 - val_val_recon_loss: 7.8722e-04 - val_val_KL loss: 23.4340 - val_beta: 0.0011\n",
      "Epoch 1706/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 674.6640 - recon_loss: 7.8313e-04 - KL loss: 23.4046 - beta: 0.0011 - val_val_loss: 676.1256 - val_val_recon_loss: 7.8503e-04 - val_val_KL loss: 23.2870 - val_beta: 0.0011\n",
      "Epoch 1707/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 672.5620 - recon_loss: 7.8030e-04 - KL loss: 23.6575 - beta: 0.0011 - val_val_loss: 675.1490 - val_val_recon_loss: 7.8364e-04 - val_val_KL loss: 23.4692 - val_beta: 0.0011\n",
      "Epoch 1708/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 675.3865 - recon_loss: 7.8368e-04 - KL loss: 23.6765 - beta: 0.0011 - val_val_loss: 674.3608 - val_val_recon_loss: 7.8287e-04 - val_val_KL loss: 23.3243 - val_beta: 0.0011\n",
      "Epoch 1709/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 672.2102 - recon_loss: 7.8001e-04 - KL loss: 23.5462 - beta: 0.0011 - val_val_loss: 675.1978 - val_val_recon_loss: 7.8364e-04 - val_val_KL loss: 23.5203 - val_beta: 0.0011\n",
      "Epoch 1710/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 671.8935 - recon_loss: 7.7935e-04 - KL loss: 23.7794 - beta: 0.0011 - val_val_loss: 675.0291 - val_val_recon_loss: 7.8297e-04 - val_val_KL loss: 23.9095 - val_beta: 0.0011\n",
      "Epoch 1711/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 671.2860 - recon_loss: 7.7837e-04 - KL loss: 23.9929 - beta: 0.0011 - val_val_loss: 672.0334 - val_val_recon_loss: 7.7963e-04 - val_val_KL loss: 23.6868 - val_beta: 0.0011\n",
      "Epoch 1712/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 665.8866 - recon_loss: 7.7213e-04 - KL loss: 23.7825 - beta: 0.0011 - val_val_loss: 673.3184 - val_val_recon_loss: 7.8121e-04 - val_val_KL loss: 23.6635 - val_beta: 0.0011\n",
      "Epoch 1713/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 665.7879 - recon_loss: 7.7186e-04 - KL loss: 23.9075 - beta: 0.0011 - val_val_loss: 673.8437 - val_val_recon_loss: 7.8157e-04 - val_val_KL loss: 23.8894 - val_beta: 0.0011\n",
      "Epoch 1714/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 675.4367 - recon_loss: 7.8325e-04 - KL loss: 24.0848 - beta: 0.0011 - val_val_loss: 674.5388 - val_val_recon_loss: 7.8247e-04 - val_val_KL loss: 23.8288 - val_beta: 0.0011\n",
      "Epoch 1715/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 667.5762 - recon_loss: 7.7406e-04 - KL loss: 23.8656 - beta: 0.0011 - val_val_loss: 672.1584 - val_val_recon_loss: 7.7959e-04 - val_val_KL loss: 23.8465 - val_beta: 0.0011\n",
      "Epoch 1716/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 669.2952 - recon_loss: 7.7599e-04 - KL loss: 23.9793 - beta: 0.0011\n",
      "Epoch 01716: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 669.2953 - recon_loss: 7.7599e-04 - KL loss: 23.9794 - beta: 0.0011 - val_val_loss: 672.7455 - val_val_recon_loss: 7.8005e-04 - val_val_KL loss: 24.0488 - val_beta: 0.0011\n",
      "Epoch 1717/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 669.9084 - recon_loss: 7.7648e-04 - KL loss: 24.1793 - beta: 0.0011 - val_val_loss: 671.3940 - val_val_recon_loss: 7.7850e-04 - val_val_KL loss: 23.9912 - val_beta: 0.0011\n",
      "Epoch 1718/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 664.0636 - recon_loss: 7.6949e-04 - KL loss: 24.1530 - beta: 0.0011 - val_val_loss: 671.4457 - val_val_recon_loss: 7.7863e-04 - val_val_KL loss: 23.9328 - val_beta: 0.0011\n",
      "Epoch 1719/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 663.3224 - recon_loss: 7.6878e-04 - KL loss: 24.0017 - beta: 0.0011 - val_val_loss: 670.0535 - val_val_recon_loss: 7.7687e-04 - val_val_KL loss: 24.0004 - val_beta: 0.0011\n",
      "Epoch 1720/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 661.5059 - recon_loss: 7.6659e-04 - KL loss: 24.0038 - beta: 0.0011 - val_val_loss: 670.2449 - val_val_recon_loss: 7.7719e-04 - val_val_KL loss: 23.9308 - val_beta: 0.0011\n",
      "Epoch 1721/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 674.1592 - recon_loss: 7.8161e-04 - KL loss: 24.1655 - beta: 0.0011 - val_val_loss: 670.0578 - val_val_recon_loss: 7.7698e-04 - val_val_KL loss: 23.9195 - val_beta: 0.0011\n",
      "Epoch 1722/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 665.8742 - recon_loss: 7.7167e-04 - KL loss: 24.1455 - beta: 0.0011 - val_val_loss: 669.5120 - val_val_recon_loss: 7.7620e-04 - val_val_KL loss: 24.0189 - val_beta: 0.0011\n",
      "Epoch 1723/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 663.7704 - recon_loss: 7.6907e-04 - KL loss: 24.2051 - beta: 0.0011 - val_val_loss: 669.5929 - val_val_recon_loss: 7.7639e-04 - val_val_KL loss: 23.9458 - val_beta: 0.0011\n",
      "Epoch 1724/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 666.9292 - recon_loss: 7.7311e-04 - KL loss: 24.0041 - beta: 0.0011 - val_val_loss: 669.7618 - val_val_recon_loss: 7.7660e-04 - val_val_KL loss: 23.9375 - val_beta: 0.0011\n",
      "Epoch 1725/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 667.8289 - recon_loss: 7.7421e-04 - KL loss: 23.9873 - beta: 0.0011 - val_val_loss: 669.8651 - val_val_recon_loss: 7.7674e-04 - val_val_KL loss: 23.9247 - val_beta: 0.0011\n",
      "Epoch 1726/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 669.4388 - recon_loss: 7.7598e-04 - KL loss: 24.1323 - beta: 0.0011 - val_val_loss: 668.4611 - val_val_recon_loss: 7.7499e-04 - val_val_KL loss: 23.9736 - val_beta: 0.0011\n",
      "Epoch 1727/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 662.2119 - recon_loss: 7.6730e-04 - KL loss: 24.1199 - beta: 0.0011 - val_val_loss: 669.9645 - val_val_recon_loss: 7.7663e-04 - val_val_KL loss: 24.1163 - val_beta: 0.0011\n",
      "Epoch 1728/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 663.0101 - recon_loss: 7.6826e-04 - KL loss: 24.1214 - beta: 0.0011 - val_val_loss: 669.5107 - val_val_recon_loss: 7.7616e-04 - val_val_KL loss: 24.0504 - val_beta: 0.0011\n",
      "Epoch 1729/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 665.4340 - recon_loss: 7.7109e-04 - KL loss: 24.1883 - beta: 0.0011 - val_val_loss: 669.7910 - val_val_recon_loss: 7.7653e-04 - val_val_KL loss: 24.0234 - val_beta: 0.0011\n",
      "Epoch 1730/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 659.9862 - recon_loss: 7.6461e-04 - KL loss: 24.1351 - beta: 0.0011 - val_val_loss: 669.9354 - val_val_recon_loss: 7.7665e-04 - val_val_KL loss: 24.0668 - val_beta: 0.0011\n",
      "Epoch 1731/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 664.6472 - recon_loss: 7.7019e-04 - KL loss: 24.1496 - beta: 0.0011\n",
      "Epoch 01731: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 664.6495 - recon_loss: 7.7020e-04 - KL loss: 24.1496 - beta: 0.0011 - val_val_loss: 670.7155 - val_val_recon_loss: 7.7760e-04 - val_val_KL loss: 24.0567 - val_beta: 0.0011\n",
      "Epoch 1732/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 668.2946 - recon_loss: 7.7463e-04 - KL loss: 24.1068 - beta: 0.0011 - val_val_loss: 669.5067 - val_val_recon_loss: 7.7622e-04 - val_val_KL loss: 24.0002 - val_beta: 0.0011\n",
      "Epoch 1733/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 661.0788 - recon_loss: 7.6587e-04 - KL loss: 24.1760 - beta: 0.0011 - val_val_loss: 668.4888 - val_val_recon_loss: 7.7498e-04 - val_val_KL loss: 24.0125 - val_beta: 0.0011\n",
      "Epoch 1734/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 663.7294 - recon_loss: 7.6909e-04 - KL loss: 24.1507 - beta: 0.0011 - val_val_loss: 668.1513 - val_val_recon_loss: 7.7454e-04 - val_val_KL loss: 24.0388 - val_beta: 0.0011\n",
      "Epoch 1735/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 669.6449 - recon_loss: 7.7614e-04 - KL loss: 24.1996 - beta: 0.0011 - val_val_loss: 668.0457 - val_val_recon_loss: 7.7442e-04 - val_val_KL loss: 24.0364 - val_beta: 0.0011\n",
      "Epoch 1736/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 665.2920 - recon_loss: 7.7089e-04 - KL loss: 24.2196 - beta: 0.0011 - val_val_loss: 668.9473 - val_val_recon_loss: 7.7552e-04 - val_val_KL loss: 24.0181 - val_beta: 0.0011\n",
      "Epoch 1737/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 661.8333 - recon_loss: 7.6690e-04 - KL loss: 24.0744 - beta: 0.0011 - val_val_loss: 668.1985 - val_val_recon_loss: 7.7457e-04 - val_val_KL loss: 24.0626 - val_beta: 0.0011\n",
      "Epoch 1738/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 666.5363 - recon_loss: 7.7243e-04 - KL loss: 24.1754 - beta: 0.0011 - val_val_loss: 669.5623 - val_val_recon_loss: 7.7615e-04 - val_val_KL loss: 24.1141 - val_beta: 0.0011\n",
      "Epoch 1739/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 664.7131 - recon_loss: 7.7040e-04 - KL loss: 24.0453 - beta: 0.0011 - val_val_loss: 668.3781 - val_val_recon_loss: 7.7477e-04 - val_val_KL loss: 24.0775 - val_beta: 0.0011\n",
      "Epoch 1740/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 666.3579 - recon_loss: 7.7224e-04 - KL loss: 24.1583 - beta: 0.0011\n",
      "Epoch 01740: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 666.3572 - recon_loss: 7.7224e-04 - KL loss: 24.1583 - beta: 0.0011 - val_val_loss: 668.4744 - val_val_recon_loss: 7.7490e-04 - val_val_KL loss: 24.0642 - val_beta: 0.0011\n",
      "Epoch 1741/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 665.2038 - recon_loss: 7.7072e-04 - KL loss: 24.2661 - beta: 0.0011 - val_val_loss: 668.3668 - val_val_recon_loss: 7.7476e-04 - val_val_KL loss: 24.0712 - val_beta: 0.0011\n",
      "Epoch 1742/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 670.4721 - recon_loss: 7.7705e-04 - KL loss: 24.2755 - beta: 0.0011 - val_val_loss: 669.2821 - val_val_recon_loss: 7.7586e-04 - val_val_KL loss: 24.0769 - val_beta: 0.0011\n",
      "Epoch 1743/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 666.5343 - recon_loss: 7.7229e-04 - KL loss: 24.2914 - beta: 0.0011 - val_val_loss: 668.1531 - val_val_recon_loss: 7.7448e-04 - val_val_KL loss: 24.0943 - val_beta: 0.0011\n",
      "Epoch 1744/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 666.5231 - recon_loss: 7.7256e-04 - KL loss: 24.0574 - beta: 0.0011 - val_val_loss: 669.1108 - val_val_recon_loss: 7.7566e-04 - val_val_KL loss: 24.0681 - val_beta: 0.0011\n",
      "Epoch 1745/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 671.9252 - recon_loss: 7.7888e-04 - KL loss: 24.2036 - beta: 0.0011\n",
      "Epoch 01745: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 671.9224 - recon_loss: 7.7888e-04 - KL loss: 24.2036 - beta: 0.0011 - val_val_loss: 668.5771 - val_val_recon_loss: 7.7500e-04 - val_val_KL loss: 24.0838 - val_beta: 0.0011\n",
      "Epoch 1745/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2268.5999 - recon_loss: 8.3183e-04 - KL loss: 30.0683 - beta: 6.0959e-04 - val_val_loss: 2236.0552 - val_val_recon_loss: 8.1913e-04 - val_val_KL loss: 31.6993 - val_beta: 6.0959e-04\n",
      "Epoch 1746/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2263.9401 - recon_loss: 8.2948e-04 - KL loss: 31.7369 - beta: 6.0959e-04 - val_val_loss: 2189.4712 - val_val_recon_loss: 8.0175e-04 - val_val_KL loss: 31.8903 - val_beta: 6.0959e-04\n",
      "Epoch 1747/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2214.4434 - recon_loss: 8.1082e-04 - KL loss: 32.4557 - beta: 6.0959e-04 - val_val_loss: 2177.6416 - val_val_recon_loss: 7.9693e-04 - val_val_KL loss: 33.0398 - val_beta: 6.0959e-04\n",
      "Epoch 1748/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2147.7940 - recon_loss: 7.8565e-04 - KL loss: 33.5436 - beta: 6.0959e-04 - val_val_loss: 2124.8743 - val_val_recon_loss: 7.7699e-04 - val_val_KL loss: 33.9361 - val_beta: 6.0959e-04\n",
      "Epoch 1749/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2120.4855 - recon_loss: 7.7517e-04 - KL loss: 34.4227 - beta: 6.0959e-04 - val_val_loss: 2106.3660 - val_val_recon_loss: 7.7017e-04 - val_val_KL loss: 33.7651 - val_beta: 6.0959e-04\n",
      "Epoch 1750/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2108.1808 - recon_loss: 7.7047e-04 - KL loss: 34.7739 - beta: 6.0959e-04 - val_val_loss: 2103.1260 - val_val_recon_loss: 7.6821e-04 - val_val_KL loss: 35.8161 - val_beta: 6.0959e-04\n",
      "Epoch 1751/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2109.1289 - recon_loss: 7.7035e-04 - KL loss: 36.0529 - beta: 6.0959e-04 - val_val_loss: 2135.4768 - val_val_recon_loss: 7.8056e-04 - val_val_KL loss: 34.9306 - val_beta: 6.0959e-04\n",
      "Epoch 1752/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2126.0068 - recon_loss: 7.7707e-04 - KL loss: 34.8540 - beta: 6.0959e-04 - val_val_loss: 2138.8452 - val_val_recon_loss: 7.8177e-04 - val_val_KL loss: 35.0236 - val_beta: 6.0959e-04\n",
      "Epoch 1753/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2141.6716 - recon_loss: 7.8256e-04 - KL loss: 35.7242 - beta: 6.0959e-04 - val_val_loss: 2099.5723 - val_val_recon_loss: 7.6667e-04 - val_val_KL loss: 36.4097 - val_beta: 6.0959e-04\n",
      "Epoch 1754/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2095.5979 - recon_loss: 7.6478e-04 - KL loss: 37.5098 - beta: 6.0959e-04 - val_val_loss: 2085.6462 - val_val_recon_loss: 7.6048e-04 - val_val_KL loss: 39.1266 - val_beta: 6.0959e-04\n",
      "Epoch 1755/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2029.1920 - recon_loss: 7.3909e-04 - KL loss: 40.2461 - beta: 6.0959e-04 - val_val_loss: 2044.3805 - val_val_recon_loss: 7.4484e-04 - val_val_KL loss: 39.9508 - val_beta: 6.0959e-04\n",
      "Epoch 1756/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2045.6001 - recon_loss: 7.4512e-04 - KL loss: 40.4057 - beta: 6.0959e-04 - val_val_loss: 2022.2484 - val_val_recon_loss: 7.3632e-04 - val_val_KL loss: 40.7523 - val_beta: 6.0959e-04\n",
      "Epoch 1757/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1994.7658 - recon_loss: 7.2570e-04 - KL loss: 41.8469 - beta: 6.0959e-04 - val_val_loss: 1993.5189 - val_val_recon_loss: 7.2547e-04 - val_val_KL loss: 41.2206 - val_beta: 6.0959e-04\n",
      "Epoch 1758/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2006.1204 - recon_loss: 7.2984e-04 - KL loss: 42.0613 - beta: 6.0959e-04 - val_val_loss: 2072.5532 - val_val_recon_loss: 7.5484e-04 - val_val_KL loss: 41.2143 - val_beta: 6.0959e-04\n",
      "Epoch 1759/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2029.3900 - recon_loss: 7.3831e-04 - KL loss: 42.5336 - beta: 6.0959e-04 - val_val_loss: 2102.3906 - val_val_recon_loss: 7.6574e-04 - val_val_KL loss: 41.7283 - val_beta: 6.0959e-04\n",
      "Epoch 1760/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2032.5821 - recon_loss: 7.3983e-04 - KL loss: 41.6418 - beta: 6.0959e-04 - val_val_loss: 1975.5881 - val_val_recon_loss: 7.1824e-04 - val_val_KL loss: 42.7366 - val_beta: 6.0959e-04\n",
      "Epoch 1761/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1957.9065 - recon_loss: 7.1157e-04 - KL loss: 42.9994 - beta: 6.0959e-04 - val_val_loss: 1932.8232 - val_val_recon_loss: 7.0200e-04 - val_val_KL loss: 43.6831 - val_beta: 6.0959e-04\n",
      "Epoch 1762/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1897.1927 - recon_loss: 6.8835e-04 - KL loss: 44.7736 - beta: 6.0959e-04 - val_val_loss: 1861.1450 - val_val_recon_loss: 6.7416e-04 - val_val_KL loss: 46.9111 - val_beta: 6.0959e-04\n",
      "Epoch 1763/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1850.7940 - recon_loss: 6.7038e-04 - KL loss: 46.7509 - beta: 6.0959e-04 - val_val_loss: 1924.9766 - val_val_recon_loss: 6.9861e-04 - val_val_KL loss: 44.9701 - val_beta: 6.0959e-04\n",
      "Epoch 1764/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1868.0530 - recon_loss: 6.7678e-04 - KL loss: 46.7801 - beta: 6.0959e-04 - val_val_loss: 1893.4922 - val_val_recon_loss: 6.8410e-04 - val_val_KL loss: 52.5126 - val_beta: 6.0959e-04\n",
      "Epoch 1765/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1855.7243 - recon_loss: 6.7052e-04 - KL loss: 51.3066 - beta: 6.0959e-04 - val_val_loss: 1800.4106 - val_val_recon_loss: 6.4965e-04 - val_val_KL loss: 52.1366 - val_beta: 6.0959e-04\n",
      "Epoch 1766/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1785.2596 - recon_loss: 6.4428e-04 - KL loss: 51.4419 - beta: 6.0959e-04 - val_val_loss: 1827.5093 - val_val_recon_loss: 6.5828e-04 - val_val_KL loss: 56.0117 - val_beta: 6.0959e-04\n",
      "Epoch 1767/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1757.1834 - recon_loss: 6.3298e-04 - KL loss: 53.7821 - beta: 6.0959e-04 - val_val_loss: 1728.1168 - val_val_recon_loss: 6.2219e-04 - val_val_KL loss: 53.7363 - val_beta: 6.0959e-04\n",
      "Epoch 1768/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1679.7552 - recon_loss: 6.0472e-04 - KL loss: 52.4092 - beta: 6.0959e-04 - val_val_loss: 1722.1194 - val_val_recon_loss: 6.2095e-04 - val_val_KL loss: 51.1018 - val_beta: 6.0959e-04\n",
      "Epoch 1769/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1713.6927 - recon_loss: 6.1788e-04 - KL loss: 50.9336 - beta: 6.0959e-04 - val_val_loss: 1724.0659 - val_val_recon_loss: 6.2290e-04 - val_val_KL loss: 47.7794 - val_beta: 6.0959e-04\n",
      "Epoch 1770/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1721.8853 - recon_loss: 6.2215e-04 - KL loss: 47.6237 - beta: 6.0959e-04 - val_val_loss: 1674.7780 - val_val_recon_loss: 6.0445e-04 - val_val_KL loss: 48.1418 - val_beta: 6.0959e-04\n",
      "Epoch 1771/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1677.8244 - recon_loss: 6.0544e-04 - KL loss: 48.5312 - beta: 6.0959e-04 - val_val_loss: 1727.9750 - val_val_recon_loss: 6.2496e-04 - val_val_KL loss: 46.1472 - val_beta: 6.0959e-04\n",
      "Epoch 1772/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1722.0135 - recon_loss: 6.2250e-04 - KL loss: 46.8195 - beta: 6.0959e-04 - val_val_loss: 1720.8341 - val_val_recon_loss: 6.2230e-04 - val_val_KL loss: 46.1815 - val_beta: 6.0959e-04\n",
      "Epoch 1773/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1718.1445 - recon_loss: 6.2108e-04 - KL loss: 46.7561 - beta: 6.0959e-04 - val_val_loss: 1685.1814 - val_val_recon_loss: 6.0877e-04 - val_val_KL loss: 46.9329 - val_beta: 6.0959e-04\n",
      "Epoch 1774/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1731.5667 - recon_loss: 6.2602e-04 - KL loss: 46.8878 - beta: 6.0959e-04 - val_val_loss: 1794.4259 - val_val_recon_loss: 6.4995e-04 - val_val_KL loss: 45.3450 - val_beta: 6.0959e-04\n",
      "Epoch 1775/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1788.9577 - recon_loss: 6.4790e-04 - KL loss: 45.3957 - beta: 6.0959e-04\n",
      "Epoch 01775: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1788.9303 - recon_loss: 6.4789e-04 - KL loss: 45.3963 - beta: 6.0959e-04 - val_val_loss: 1688.5848 - val_val_recon_loss: 6.1016e-04 - val_val_KL loss: 46.5872 - val_beta: 6.0959e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1776/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1675.0297 - recon_loss: 6.0501e-04 - KL loss: 46.8984 - beta: 6.0959e-04 - val_val_loss: 1659.2410 - val_val_recon_loss: 5.9906e-04 - val_val_KL loss: 47.1180 - val_beta: 6.0959e-04\n",
      "Epoch 1777/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1680.6158 - recon_loss: 6.0700e-04 - KL loss: 47.1157 - beta: 6.0959e-04 - val_val_loss: 1654.1508 - val_val_recon_loss: 5.9710e-04 - val_val_KL loss: 47.3130 - val_beta: 6.0959e-04\n",
      "Epoch 1778/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1654.5388 - recon_loss: 5.9710e-04 - KL loss: 47.6863 - beta: 6.0959e-04 - val_val_loss: 1632.4280 - val_val_recon_loss: 5.8830e-04 - val_val_KL loss: 49.2548 - val_beta: 6.0959e-04\n",
      "Epoch 1779/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1609.8727 - recon_loss: 5.8024e-04 - KL loss: 48.3873 - beta: 6.0959e-04 - val_val_loss: 1602.5542 - val_val_recon_loss: 5.7758e-04 - val_val_KL loss: 48.2259 - val_beta: 6.0959e-04\n",
      "Epoch 1780/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1589.0372 - recon_loss: 5.7244e-04 - KL loss: 48.5606 - beta: 6.0959e-04 - val_val_loss: 1602.5962 - val_val_recon_loss: 5.7767e-04 - val_val_KL loss: 48.0390 - val_beta: 6.0959e-04\n",
      "Epoch 1781/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1599.7816 - recon_loss: 5.7665e-04 - KL loss: 47.9719 - beta: 6.0959e-04 - val_val_loss: 1593.2740 - val_val_recon_loss: 5.7389e-04 - val_val_KL loss: 48.8738 - val_beta: 6.0959e-04\n",
      "Epoch 1782/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1570.1426 - recon_loss: 5.6536e-04 - KL loss: 48.7044 - beta: 6.0959e-04 - val_val_loss: 1573.8374 - val_val_recon_loss: 5.6664e-04 - val_val_KL loss: 48.9720 - val_beta: 6.0959e-04\n",
      "Epoch 1783/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1572.9307 - recon_loss: 5.6616e-04 - KL loss: 49.3374 - beta: 6.0959e-04 - val_val_loss: 1568.7241 - val_val_recon_loss: 5.6494e-04 - val_val_KL loss: 48.4342 - val_beta: 6.0959e-04\n",
      "Epoch 1784/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1566.9689 - recon_loss: 5.6434e-04 - KL loss: 48.2867 - beta: 6.0959e-04 - val_val_loss: 1568.1914 - val_val_recon_loss: 5.6482e-04 - val_val_KL loss: 48.1996 - val_beta: 6.0959e-04\n",
      "Epoch 1785/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1571.1530 - recon_loss: 5.6588e-04 - KL loss: 48.3308 - beta: 6.0959e-04 - val_val_loss: 1568.6267 - val_val_recon_loss: 5.6467e-04 - val_val_KL loss: 49.0564 - val_beta: 6.0959e-04\n",
      "Epoch 1786/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1554.7230 - recon_loss: 5.5979e-04 - KL loss: 48.2671 - beta: 6.0959e-04 - val_val_loss: 1589.4189 - val_val_recon_loss: 5.7286e-04 - val_val_KL loss: 47.8061 - val_beta: 6.0959e-04\n",
      "Epoch 1787/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1587.5546 - recon_loss: 5.7205e-04 - KL loss: 48.1078 - beta: 6.0959e-04 - val_val_loss: 1583.2405 - val_val_recon_loss: 5.7020e-04 - val_val_KL loss: 48.7818 - val_beta: 6.0959e-04\n",
      "Epoch 1788/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1610.6356 - recon_loss: 5.8054e-04 - KL loss: 48.3625 - beta: 6.0959e-04 - val_val_loss: 1618.9067 - val_val_recon_loss: 5.8384e-04 - val_val_KL loss: 47.7467 - val_beta: 6.0959e-04\n",
      "Epoch 1789/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1623.2955 - recon_loss: 5.8540e-04 - KL loss: 47.9319 - beta: 6.0959e-04\n",
      "Epoch 01789: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1623.3007 - recon_loss: 5.8540e-04 - KL loss: 47.9317 - beta: 6.0959e-04 - val_val_loss: 1625.7775 - val_val_recon_loss: 5.8643e-04 - val_val_KL loss: 47.6397 - val_beta: 6.0959e-04\n",
      "Epoch 1790/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1623.8335 - recon_loss: 5.8568e-04 - KL loss: 47.7257 - beta: 6.0959e-04 - val_val_loss: 1616.5166 - val_val_recon_loss: 5.8292e-04 - val_val_KL loss: 47.8274 - val_beta: 6.0959e-04\n",
      "Epoch 1791/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1604.3046 - recon_loss: 5.7835e-04 - KL loss: 47.9270 - beta: 6.0959e-04 - val_val_loss: 1597.4258 - val_val_recon_loss: 5.7564e-04 - val_val_KL loss: 48.3404 - val_beta: 6.0959e-04\n",
      "Epoch 1792/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1590.5939 - recon_loss: 5.7317e-04 - KL loss: 48.1378 - beta: 6.0959e-04 - val_val_loss: 1592.9399 - val_val_recon_loss: 5.7405e-04 - val_val_KL loss: 48.1325 - val_beta: 6.0959e-04\n",
      "Epoch 1793/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1598.1111 - recon_loss: 5.7592e-04 - KL loss: 48.2691 - beta: 6.0959e-04 - val_val_loss: 1577.6586 - val_val_recon_loss: 5.6813e-04 - val_val_KL loss: 48.7678 - val_beta: 6.0959e-04\n",
      "Epoch 1794/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1590.7812 - recon_loss: 5.7312e-04 - KL loss: 48.4778 - beta: 6.0959e-04\n",
      "Epoch 01794: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1590.7720 - recon_loss: 5.7311e-04 - KL loss: 48.4777 - beta: 6.0959e-04 - val_val_loss: 1594.6128 - val_val_recon_loss: 5.7459e-04 - val_val_KL loss: 48.3444 - val_beta: 6.0959e-04\n",
      "Epoch 1794/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5739.3930 - recon_loss: 6.5243e-04 - KL loss: 57.7527 - beta: 3.3887e-04 - val_val_loss: 5338.3687 - val_val_recon_loss: 6.0523e-04 - val_val_KL loss: 67.8215 - val_beta: 3.3887e-04\n",
      "Epoch 1795/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5229.2899 - recon_loss: 5.9256e-04 - KL loss: 69.0238 - beta: 3.3887e-04 - val_val_loss: 4997.3765 - val_val_recon_loss: 5.6553e-04 - val_val_KL loss: 72.5428 - val_beta: 3.3887e-04\n",
      "Epoch 1796/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4988.5889 - recon_loss: 5.6450e-04 - KL loss: 72.7329 - beta: 3.3887e-04 - val_val_loss: 5011.1245 - val_val_recon_loss: 5.6709e-04 - val_val_KL loss: 72.6982 - val_beta: 3.3887e-04\n",
      "Epoch 1797/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5049.7402 - recon_loss: 5.7142e-04 - KL loss: 73.6199 - beta: 3.3887e-04 - val_val_loss: 4972.6968 - val_val_recon_loss: 5.6234e-04 - val_val_KL loss: 75.5971 - val_beta: 3.3887e-04\n",
      "Epoch 1798/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5014.5174 - recon_loss: 5.6703e-04 - KL loss: 76.6332 - beta: 3.3887e-04 - val_val_loss: 4922.0435 - val_val_recon_loss: 5.5624e-04 - val_val_KL loss: 78.0627 - val_beta: 3.3887e-04\n",
      "Epoch 1799/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4824.9038 - recon_loss: 5.4501e-04 - KL loss: 78.7566 - beta: 3.3887e-04 - val_val_loss: 4805.0645 - val_val_recon_loss: 5.4301e-04 - val_val_KL loss: 76.3542 - val_beta: 3.3887e-04\n",
      "Epoch 1800/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4674.2562 - recon_loss: 5.2770e-04 - KL loss: 78.8271 - beta: 3.3887e-04 - val_val_loss: 4734.3350 - val_val_recon_loss: 5.3420e-04 - val_val_KL loss: 82.3017 - val_beta: 3.3887e-04\n",
      "Epoch 1801/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4684.7971 - recon_loss: 5.2858e-04 - KL loss: 81.7443 - beta: 3.3887e-04 - val_val_loss: 4629.8555 - val_val_recon_loss: 5.2249e-04 - val_val_KL loss: 79.7914 - val_beta: 3.3887e-04\n",
      "Epoch 1802/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4573.1699 - recon_loss: 5.1587e-04 - KL loss: 80.7773 - beta: 3.3887e-04 - val_val_loss: 4521.5537 - val_val_recon_loss: 5.0997e-04 - val_val_KL loss: 80.5054 - val_beta: 3.3887e-04\n",
      "Epoch 1803/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4541.2363 - recon_loss: 5.1206e-04 - KL loss: 82.0148 - beta: 3.3887e-04 - val_val_loss: 4625.2056 - val_val_recon_loss: 5.2152e-04 - val_val_KL loss: 83.5657 - val_beta: 3.3887e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1804/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4530.7971 - recon_loss: 5.1065e-04 - KL loss: 83.8858 - beta: 3.3887e-04 - val_val_loss: 4493.0298 - val_val_recon_loss: 5.0608e-04 - val_val_KL loss: 85.8438 - val_beta: 3.3887e-04\n",
      "Epoch 1805/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4495.4664 - recon_loss: 5.0626e-04 - KL loss: 86.7485 - beta: 3.3887e-04 - val_val_loss: 4428.8652 - val_val_recon_loss: 4.9853e-04 - val_val_KL loss: 87.5033 - val_beta: 3.3887e-04\n",
      "Epoch 1806/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4350.8940 - recon_loss: 4.8981e-04 - KL loss: 85.4543 - beta: 3.3887e-04 - val_val_loss: 4411.5142 - val_val_recon_loss: 4.9685e-04 - val_val_KL loss: 84.7273 - val_beta: 3.3887e-04\n",
      "Epoch 1807/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4345.6407 - recon_loss: 4.8920e-04 - KL loss: 85.4986 - beta: 3.3887e-04 - val_val_loss: 4432.4668 - val_val_recon_loss: 4.9916e-04 - val_val_KL loss: 85.6144 - val_beta: 3.3887e-04\n",
      "Epoch 1808/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4339.8776 - recon_loss: 4.8878e-04 - KL loss: 83.4042 - beta: 3.3887e-04 - val_val_loss: 4368.3276 - val_val_recon_loss: 4.9228e-04 - val_val_KL loss: 81.3941 - val_beta: 3.3887e-04\n",
      "Epoch 1809/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4262.3087 - recon_loss: 4.7993e-04 - KL loss: 82.9038 - beta: 3.3887e-04 - val_val_loss: 4272.9004 - val_val_recon_loss: 4.8073e-04 - val_val_KL loss: 86.5194 - val_beta: 3.3887e-04\n",
      "Epoch 1810/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4271.3027 - recon_loss: 4.8067e-04 - KL loss: 85.4649 - beta: 3.3887e-04 - val_val_loss: 4688.6733 - val_val_recon_loss: 5.2776e-04 - val_val_KL loss: 92.7666 - val_beta: 3.3887e-04\n",
      "Epoch 1811/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4457.9692 - recon_loss: 5.0169e-04 - KL loss: 89.0450 - beta: 3.3887e-04 - val_val_loss: 4176.5293 - val_val_recon_loss: 4.6979e-04 - val_val_KL loss: 85.4325 - val_beta: 3.3887e-04\n",
      "Epoch 1812/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4189.8126 - recon_loss: 4.7111e-04 - KL loss: 87.2360 - beta: 3.3887e-04 - val_val_loss: 4263.2104 - val_val_recon_loss: 4.7975e-04 - val_val_KL loss: 85.3912 - val_beta: 3.3887e-04\n",
      "Epoch 1813/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4279.9904 - recon_loss: 4.8141e-04 - KL loss: 87.6792 - beta: 3.3887e-04 - val_val_loss: 4159.2568 - val_val_recon_loss: 4.6814e-04 - val_val_KL loss: 82.5458 - val_beta: 3.3887e-04\n",
      "Epoch 1814/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4145.4719 - recon_loss: 4.6634e-04 - KL loss: 84.4199 - beta: 3.3887e-04 - val_val_loss: 4149.9253 - val_val_recon_loss: 4.6696e-04 - val_val_KL loss: 83.4919 - val_beta: 3.3887e-04\n",
      "Epoch 1815/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4087.2239 - recon_loss: 4.5980e-04 - KL loss: 83.1235 - beta: 3.3887e-04 - val_val_loss: 4066.5271 - val_val_recon_loss: 4.5747e-04 - val_val_KL loss: 82.6770 - val_beta: 3.3887e-04\n",
      "Epoch 1816/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4076.6319 - recon_loss: 4.5871e-04 - KL loss: 82.0111 - beta: 3.3887e-04 - val_val_loss: 4087.9282 - val_val_recon_loss: 4.6009e-04 - val_val_KL loss: 81.3192 - val_beta: 3.3887e-04\n",
      "Epoch 1817/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4234.7969 - recon_loss: 4.7688e-04 - KL loss: 81.9642 - beta: 3.3887e-04 - val_val_loss: 4118.5752 - val_val_recon_loss: 4.6348e-04 - val_val_KL loss: 82.3829 - val_beta: 3.3887e-04\n",
      "Epoch 1818/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4062.2868 - recon_loss: 4.5695e-04 - KL loss: 82.9902 - beta: 3.3887e-04 - val_val_loss: 4148.2705 - val_val_recon_loss: 4.6685e-04 - val_val_KL loss: 82.7507 - val_beta: 3.3887e-04\n",
      "Epoch 1819/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4057.1632 - recon_loss: 4.5641e-04 - KL loss: 82.5861 - beta: 3.3887e-04 - val_val_loss: 3977.1841 - val_val_recon_loss: 4.4713e-04 - val_val_KL loss: 83.4182 - val_beta: 3.3887e-04\n",
      "Epoch 1820/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3932.5052 - recon_loss: 4.4201e-04 - KL loss: 83.3350 - beta: 3.3887e-04 - val_val_loss: 3972.8284 - val_val_recon_loss: 4.4656e-04 - val_val_KL loss: 84.0495 - val_beta: 3.3887e-04\n",
      "Epoch 1821/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3932.3824 - recon_loss: 4.4192e-04 - KL loss: 83.9659 - beta: 3.3887e-04 - val_val_loss: 3915.0649 - val_val_recon_loss: 4.4023e-04 - val_val_KL loss: 81.3790 - val_beta: 3.3887e-04\n",
      "Epoch 1822/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3910.9394 - recon_loss: 4.3963e-04 - KL loss: 82.5029 - beta: 3.3887e-04 - val_val_loss: 3940.6108 - val_val_recon_loss: 4.4278e-04 - val_val_KL loss: 84.7319 - val_beta: 3.3887e-04\n",
      "Epoch 1823/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3884.5689 - recon_loss: 4.3660e-04 - KL loss: 82.5239 - beta: 3.3887e-04 - val_val_loss: 3888.7959 - val_val_recon_loss: 4.3699e-04 - val_val_KL loss: 83.2866 - val_beta: 3.3887e-04\n",
      "Epoch 1824/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4074.8013 - recon_loss: 4.5799e-04 - KL loss: 86.4578 - beta: 3.3887e-04 - val_val_loss: 4021.0127 - val_val_recon_loss: 4.5213e-04 - val_val_KL loss: 83.7184 - val_beta: 3.3887e-04\n",
      "Epoch 1825/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3943.0701 - recon_loss: 4.4302e-04 - KL loss: 85.0368 - beta: 3.3887e-04 - val_val_loss: 3934.4802 - val_val_recon_loss: 4.4186e-04 - val_val_KL loss: 86.6099 - val_beta: 3.3887e-04\n",
      "Epoch 1826/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3977.8068 - recon_loss: 4.4666e-04 - KL loss: 88.1209 - beta: 3.3887e-04 - val_val_loss: 4179.4678 - val_val_recon_loss: 4.6953e-04 - val_val_KL loss: 90.6498 - val_beta: 3.3887e-04\n",
      "Epoch 1827/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4110.3751 - recon_loss: 4.6135e-04 - KL loss: 92.7603 - beta: 3.3887e-04 - val_val_loss: 4074.6436 - val_val_recon_loss: 4.5856e-04 - val_val_KL loss: 81.3125 - val_beta: 3.3887e-04\n",
      "Epoch 1828/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3918.8917 - recon_loss: 4.4033e-04 - KL loss: 84.3417 - beta: 3.3887e-04 - val_val_loss: 3856.7415 - val_val_recon_loss: 4.3312e-04 - val_val_KL loss: 84.9887 - val_beta: 3.3887e-04\n",
      "Epoch 1829/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3784.5746 - recon_loss: 4.2476e-04 - KL loss: 85.5791 - beta: 3.3887e-04 - val_val_loss: 3852.6738 - val_val_recon_loss: 4.3276e-04 - val_val_KL loss: 84.0314 - val_beta: 3.3887e-04\n",
      "Epoch 1830/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3888.4244 - recon_loss: 4.3699e-04 - KL loss: 82.9273 - beta: 3.3887e-04 - val_val_loss: 4097.6050 - val_val_recon_loss: 4.6089e-04 - val_val_KL loss: 83.9800 - val_beta: 3.3887e-04\n",
      "Epoch 1831/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3882.8700 - recon_loss: 4.3624e-04 - KL loss: 83.8859 - beta: 3.3887e-04 - val_val_loss: 3877.1140 - val_val_recon_loss: 4.3597e-04 - val_val_KL loss: 80.4815 - val_beta: 3.3887e-04\n",
      "Epoch 1832/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3887.2780 - recon_loss: 4.3708e-04 - KL loss: 81.0271 - beta: 3.3887e-04 - val_val_loss: 3847.3943 - val_val_recon_loss: 4.3240e-04 - val_val_KL loss: 81.8984 - val_beta: 3.3887e-04\n",
      "Epoch 1833/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3787.8441 - recon_loss: 4.2560e-04 - KL loss: 81.5282 - beta: 3.3887e-04 - val_val_loss: 3801.8950 - val_val_recon_loss: 4.2677e-04 - val_val_KL loss: 85.3750 - val_beta: 3.3887e-04\n",
      "Epoch 1834/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3764.4693 - recon_loss: 4.2268e-04 - KL loss: 83.6089 - beta: 3.3887e-04 - val_val_loss: 3779.3850 - val_val_recon_loss: 4.2461e-04 - val_val_KL loss: 81.7143 - val_beta: 3.3887e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1835/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3715.1573 - recon_loss: 4.1719e-04 - KL loss: 82.1329 - beta: 3.3887e-04 - val_val_loss: 3790.7910 - val_val_recon_loss: 4.2584e-04 - val_val_KL loss: 82.4490 - val_beta: 3.3887e-04\n",
      "Epoch 1836/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3836.7094 - recon_loss: 4.3107e-04 - KL loss: 82.7789 - beta: 3.3887e-04 - val_val_loss: 3899.6777 - val_val_recon_loss: 4.3793e-04 - val_val_KL loss: 85.9931 - val_beta: 3.3887e-04\n",
      "Epoch 1837/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3768.7500 - recon_loss: 4.2305e-04 - KL loss: 84.6398 - beta: 3.3887e-04 - val_val_loss: 3820.0437 - val_val_recon_loss: 4.2929e-04 - val_val_KL loss: 81.5918 - val_beta: 3.3887e-04\n",
      "Epoch 1838/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3718.5053 - recon_loss: 4.1764e-04 - KL loss: 81.5279 - beta: 3.3887e-04 - val_val_loss: 3679.4932 - val_val_recon_loss: 4.1320e-04 - val_val_KL loss: 81.2256 - val_beta: 3.3887e-04\n",
      "Epoch 1839/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3660.9505 - recon_loss: 4.1096e-04 - KL loss: 82.1529 - beta: 3.3887e-04 - val_val_loss: 3750.1670 - val_val_recon_loss: 4.2108e-04 - val_val_KL loss: 83.2232 - val_beta: 3.3887e-04\n",
      "Epoch 1840/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3752.5256 - recon_loss: 4.2132e-04 - KL loss: 83.4697 - beta: 3.3887e-04 - val_val_loss: 3701.1436 - val_val_recon_loss: 4.1510e-04 - val_val_KL loss: 86.3103 - val_beta: 3.3887e-04\n",
      "Epoch 1841/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3678.6144 - recon_loss: 4.1256e-04 - KL loss: 85.9159 - beta: 3.3887e-04 - val_val_loss: 3639.8071 - val_val_recon_loss: 4.0814e-04 - val_val_KL loss: 85.5957 - val_beta: 3.3887e-04\n",
      "Epoch 1842/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3628.4604 - recon_loss: 4.0714e-04 - KL loss: 82.9099 - beta: 3.3887e-04 - val_val_loss: 3605.7258 - val_val_recon_loss: 4.0467e-04 - val_val_KL loss: 81.7403 - val_beta: 3.3887e-04\n",
      "Epoch 1843/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3681.4049 - recon_loss: 4.1311e-04 - KL loss: 83.8627 - beta: 3.3887e-04 - val_val_loss: 3739.9844 - val_val_recon_loss: 4.1937e-04 - val_val_KL loss: 87.9698 - val_beta: 3.3887e-04\n",
      "Epoch 1844/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3782.9781 - recon_loss: 4.2418e-04 - KL loss: 89.0698 - beta: 3.3887e-04 - val_val_loss: 3780.3560 - val_val_recon_loss: 4.2445e-04 - val_val_KL loss: 84.1048 - val_beta: 3.3887e-04\n",
      "Epoch 1845/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3648.7240 - recon_loss: 4.0931e-04 - KL loss: 84.3231 - beta: 3.3887e-04 - val_val_loss: 3652.2854 - val_val_recon_loss: 4.0960e-04 - val_val_KL loss: 85.2934 - val_beta: 3.3887e-04\n",
      "Epoch 1846/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3733.8203 - recon_loss: 4.1860e-04 - KL loss: 88.4763 - beta: 3.3887e-04 - val_val_loss: 3681.7542 - val_val_recon_loss: 4.1266e-04 - val_val_KL loss: 88.1472 - val_beta: 3.3887e-04\n",
      "Epoch 1847/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3667.7186 - recon_loss: 4.1104e-04 - KL loss: 88.2298 - beta: 3.3887e-04\n",
      "Epoch 01847: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3667.7114 - recon_loss: 4.1104e-04 - KL loss: 88.2287 - beta: 3.3887e-04 - val_val_loss: 3626.4043 - val_val_recon_loss: 4.0668e-04 - val_val_KL loss: 84.8358 - val_beta: 3.3887e-04\n",
      "Epoch 1848/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3509.4056 - recon_loss: 3.9319e-04 - KL loss: 85.3358 - beta: 3.3887e-04 - val_val_loss: 3506.0840 - val_val_recon_loss: 3.9252e-04 - val_val_KL loss: 87.8309 - val_beta: 3.3887e-04\n",
      "Epoch 1849/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3439.3738 - recon_loss: 3.8489e-04 - KL loss: 87.5660 - beta: 3.3887e-04 - val_val_loss: 3504.1357 - val_val_recon_loss: 3.9230e-04 - val_val_KL loss: 87.8009 - val_beta: 3.3887e-04\n",
      "Epoch 1850/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3466.3163 - recon_loss: 3.8794e-04 - KL loss: 87.9844 - beta: 3.3887e-04 - val_val_loss: 3485.3472 - val_val_recon_loss: 3.9015e-04 - val_val_KL loss: 87.7953 - val_beta: 3.3887e-04\n",
      "Epoch 1851/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3447.8629 - recon_loss: 3.8589e-04 - KL loss: 87.3862 - beta: 3.3887e-04 - val_val_loss: 3503.3315 - val_val_recon_loss: 3.9216e-04 - val_val_KL loss: 88.2365 - val_beta: 3.3887e-04\n",
      "Epoch 1852/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3441.6846 - recon_loss: 3.8514e-04 - KL loss: 87.7080 - beta: 3.3887e-04 - val_val_loss: 3510.0125 - val_val_recon_loss: 3.9281e-04 - val_val_KL loss: 89.2558 - val_beta: 3.3887e-04\n",
      "Epoch 1853/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3457.9707 - recon_loss: 3.8686e-04 - KL loss: 89.0196 - beta: 3.3887e-04 - val_val_loss: 3499.4077 - val_val_recon_loss: 3.9173e-04 - val_val_KL loss: 88.0795 - val_beta: 3.3887e-04\n",
      "Epoch 1854/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3430.8306 - recon_loss: 3.8387e-04 - KL loss: 87.9460 - beta: 3.3887e-04 - val_val_loss: 3490.2949 - val_val_recon_loss: 3.9081e-04 - val_val_KL loss: 86.9752 - val_beta: 3.3887e-04\n",
      "Epoch 1855/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3422.9962 - recon_loss: 3.8299e-04 - KL loss: 87.8076 - beta: 3.3887e-04 - val_val_loss: 3459.9688 - val_val_recon_loss: 3.8719e-04 - val_val_KL loss: 88.1257 - val_beta: 3.3887e-04\n",
      "Epoch 1856/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3414.6657 - recon_loss: 3.8203e-04 - KL loss: 87.8219 - beta: 3.3887e-04 - val_val_loss: 3458.5969 - val_val_recon_loss: 3.8724e-04 - val_val_KL loss: 86.3950 - val_beta: 3.3887e-04\n",
      "Epoch 1857/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3392.2261 - recon_loss: 3.7965e-04 - KL loss: 86.0428 - beta: 3.3887e-04 - val_val_loss: 3446.1299 - val_val_recon_loss: 3.8584e-04 - val_val_KL loss: 86.0540 - val_beta: 3.3887e-04\n",
      "Epoch 1858/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3403.8914 - recon_loss: 3.8096e-04 - KL loss: 86.3316 - beta: 3.3887e-04 - val_val_loss: 3430.4937 - val_val_recon_loss: 3.8406e-04 - val_val_KL loss: 85.9796 - val_beta: 3.3887e-04\n",
      "Epoch 1859/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3405.3462 - recon_loss: 3.8103e-04 - KL loss: 87.2068 - beta: 3.3887e-04 - val_val_loss: 3422.1904 - val_val_recon_loss: 3.8314e-04 - val_val_KL loss: 85.6154 - val_beta: 3.3887e-04\n",
      "Epoch 1860/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3378.1673 - recon_loss: 3.7808e-04 - KL loss: 85.7401 - beta: 3.3887e-04 - val_val_loss: 3476.8784 - val_val_recon_loss: 3.8942e-04 - val_val_KL loss: 85.6177 - val_beta: 3.3887e-04\n",
      "Epoch 1861/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3424.2097 - recon_loss: 3.8337e-04 - KL loss: 85.6410 - beta: 3.3887e-04 - val_val_loss: 3425.3743 - val_val_recon_loss: 3.8334e-04 - val_val_KL loss: 87.0556 - val_beta: 3.3887e-04\n",
      "Epoch 1862/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3369.0969 - recon_loss: 3.7685e-04 - KL loss: 87.3790 - beta: 3.3887e-04 - val_val_loss: 3415.3091 - val_val_recon_loss: 3.8238e-04 - val_val_KL loss: 85.3865 - val_beta: 3.3887e-04\n",
      "Epoch 1863/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3374.2395 - recon_loss: 3.7770e-04 - KL loss: 85.0667 - beta: 3.3887e-04 - val_val_loss: 3441.8738 - val_val_recon_loss: 3.8562e-04 - val_val_KL loss: 83.7787 - val_beta: 3.3887e-04\n",
      "Epoch 1864/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3374.9355 - recon_loss: 3.7793e-04 - KL loss: 83.7901 - beta: 3.3887e-04 - val_val_loss: 3457.4653 - val_val_recon_loss: 3.8752e-04 - val_val_KL loss: 82.8084 - val_beta: 3.3887e-04\n",
      "Epoch 1865/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3423.8348 - recon_loss: 3.8369e-04 - KL loss: 82.5199 - beta: 3.3887e-04 - val_val_loss: 3413.5042 - val_val_recon_loss: 3.8250e-04 - val_val_KL loss: 82.5233 - val_beta: 3.3887e-04\n",
      "Epoch 1866/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3377.6561 - recon_loss: 3.7837e-04 - KL loss: 82.6871 - beta: 3.3887e-04 - val_val_loss: 3458.0806 - val_val_recon_loss: 3.8770e-04 - val_val_KL loss: 81.8557 - val_beta: 3.3887e-04\n",
      "Epoch 1867/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3396.3570 - recon_loss: 3.8057e-04 - KL loss: 82.2238 - beta: 3.3887e-04 - val_val_loss: 3395.9319 - val_val_recon_loss: 3.8048e-04 - val_val_KL loss: 82.5891 - val_beta: 3.3887e-04\n",
      "Epoch 1868/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3391.3522 - recon_loss: 3.7996e-04 - KL loss: 82.4726 - beta: 3.3887e-04 - val_val_loss: 3427.1965 - val_val_recon_loss: 3.8397e-04 - val_val_KL loss: 83.4276 - val_beta: 3.3887e-04\n",
      "Epoch 1869/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3369.5535 - recon_loss: 3.7737e-04 - KL loss: 83.2721 - beta: 3.3887e-04 - val_val_loss: 3403.4556 - val_val_recon_loss: 3.8133e-04 - val_val_KL loss: 82.6499 - val_beta: 3.3887e-04\n",
      "Epoch 1870/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3426.4639 - recon_loss: 3.8401e-04 - KL loss: 82.3556 - beta: 3.3887e-04 - val_val_loss: 3410.0212 - val_val_recon_loss: 3.8209e-04 - val_val_KL loss: 82.6060 - val_beta: 3.3887e-04\n",
      "Epoch 1871/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3387.4062 - recon_loss: 3.7945e-04 - KL loss: 83.0142 - beta: 3.3887e-04 - val_val_loss: 3442.8347 - val_val_recon_loss: 3.8569e-04 - val_val_KL loss: 84.0725 - val_beta: 3.3887e-04\n",
      "Epoch 1872/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3430.5604 - recon_loss: 3.8435e-04 - KL loss: 83.5015 - beta: 3.3887e-04\n",
      "Epoch 01872: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3430.5446 - recon_loss: 3.8435e-04 - KL loss: 83.5011 - beta: 3.3887e-04 - val_val_loss: 3444.7434 - val_val_recon_loss: 3.8611e-04 - val_val_KL loss: 82.3660 - val_beta: 3.3887e-04\n",
      "Epoch 1873/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3364.2693 - recon_loss: 3.7680e-04 - KL loss: 82.9599 - beta: 3.3887e-04 - val_val_loss: 3374.7075 - val_val_recon_loss: 3.7800e-04 - val_val_KL loss: 82.9375 - val_beta: 3.3887e-04\n",
      "Epoch 1874/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3346.2019 - recon_loss: 3.7470e-04 - KL loss: 83.1686 - beta: 3.3887e-04 - val_val_loss: 3383.3484 - val_val_recon_loss: 3.7895e-04 - val_val_KL loss: 83.3321 - val_beta: 3.3887e-04\n",
      "Epoch 1875/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 3341.9696 - recon_loss: 3.7419e-04 - KL loss: 83.3711 - beta: 3.3887e-04 - val_val_loss: 3376.9382 - val_val_recon_loss: 3.7822e-04 - val_val_KL loss: 83.2368 - val_beta: 3.3887e-04\n",
      "Epoch 1876/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3332.0885 - recon_loss: 3.7310e-04 - KL loss: 82.9887 - beta: 3.3887e-04 - val_val_loss: 3367.4751 - val_val_recon_loss: 3.7716e-04 - val_val_KL loss: 83.0385 - val_beta: 3.3887e-04\n",
      "Epoch 1877/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3327.6288 - recon_loss: 3.7259e-04 - KL loss: 82.9696 - beta: 3.3887e-04 - val_val_loss: 3378.9719 - val_val_recon_loss: 3.7848e-04 - val_val_KL loss: 83.0504 - val_beta: 3.3887e-04\n",
      "Epoch 1878/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3335.9093 - recon_loss: 3.7352e-04 - KL loss: 83.1230 - beta: 3.3887e-04 - val_val_loss: 3385.6094 - val_val_recon_loss: 3.7927e-04 - val_val_KL loss: 82.7873 - val_beta: 3.3887e-04\n",
      "Epoch 1879/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3334.4720 - recon_loss: 3.7340e-04 - KL loss: 82.7751 - beta: 3.3887e-04 - val_val_loss: 3367.7151 - val_val_recon_loss: 3.7718e-04 - val_val_KL loss: 83.0826 - val_beta: 3.3887e-04\n",
      "Epoch 1880/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3329.9787 - recon_loss: 3.7283e-04 - KL loss: 83.2231 - beta: 3.3887e-04 - val_val_loss: 3360.6790 - val_val_recon_loss: 3.7638e-04 - val_val_KL loss: 83.0475 - val_beta: 3.3887e-04\n",
      "Epoch 1881/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3314.4237 - recon_loss: 3.7105e-04 - KL loss: 83.1329 - beta: 3.3887e-04 - val_val_loss: 3353.0715 - val_val_recon_loss: 3.7552e-04 - val_val_KL loss: 82.8652 - val_beta: 3.3887e-04\n",
      "Epoch 1882/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3332.1288 - recon_loss: 3.7313e-04 - KL loss: 82.7714 - beta: 3.3887e-04 - val_val_loss: 3346.3562 - val_val_recon_loss: 3.7475e-04 - val_val_KL loss: 82.9026 - val_beta: 3.3887e-04\n",
      "Epoch 1883/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3320.4289 - recon_loss: 3.7178e-04 - KL loss: 82.8415 - beta: 3.3887e-04 - val_val_loss: 3344.8293 - val_val_recon_loss: 3.7456e-04 - val_val_KL loss: 82.9868 - val_beta: 3.3887e-04\n",
      "Epoch 1884/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3297.8564 - recon_loss: 3.6910e-04 - KL loss: 83.6061 - beta: 3.3887e-04 - val_val_loss: 3331.0234 - val_val_recon_loss: 3.7291e-04 - val_val_KL loss: 83.5616 - val_beta: 3.3887e-04\n",
      "Epoch 1885/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3293.6553 - recon_loss: 3.6863e-04 - KL loss: 83.4612 - beta: 3.3887e-04 - val_val_loss: 3338.8413 - val_val_recon_loss: 3.7380e-04 - val_val_KL loss: 83.6006 - val_beta: 3.3887e-04\n",
      "Epoch 1886/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3315.9650 - recon_loss: 3.7116e-04 - KL loss: 83.7994 - beta: 3.3887e-04 - val_val_loss: 3340.3806 - val_val_recon_loss: 3.7402e-04 - val_val_KL loss: 83.2469 - val_beta: 3.3887e-04\n",
      "Epoch 1887/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3278.9088 - recon_loss: 3.6700e-04 - KL loss: 82.9406 - beta: 3.3887e-04 - val_val_loss: 3346.3110 - val_val_recon_loss: 3.7472e-04 - val_val_KL loss: 83.0910 - val_beta: 3.3887e-04\n",
      "Epoch 1888/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3309.1712 - recon_loss: 3.7045e-04 - KL loss: 83.1840 - beta: 3.3887e-04 - val_val_loss: 3348.1064 - val_val_recon_loss: 3.7490e-04 - val_val_KL loss: 83.3407 - val_beta: 3.3887e-04\n",
      "Epoch 1889/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3298.7559 - recon_loss: 3.6922e-04 - KL loss: 83.4447 - beta: 3.3887e-04\n",
      "Epoch 01889: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3298.7593 - recon_loss: 3.6922e-04 - KL loss: 83.4448 - beta: 3.3887e-04 - val_val_loss: 3338.6101 - val_val_recon_loss: 3.7380e-04 - val_val_KL loss: 83.3902 - val_beta: 3.3887e-04\n",
      "Epoch 1890/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3279.2752 - recon_loss: 3.6702e-04 - KL loss: 83.0978 - beta: 3.3887e-04 - val_val_loss: 3325.9456 - val_val_recon_loss: 3.7234e-04 - val_val_KL loss: 83.4571 - val_beta: 3.3887e-04\n",
      "Epoch 1891/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3305.1523 - recon_loss: 3.6997e-04 - KL loss: 83.2900 - beta: 3.3887e-04 - val_val_loss: 3323.1584 - val_val_recon_loss: 3.7201e-04 - val_val_KL loss: 83.5485 - val_beta: 3.3887e-04\n",
      "Epoch 1892/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3263.7764 - recon_loss: 3.6519e-04 - KL loss: 83.5168 - beta: 3.3887e-04 - val_val_loss: 3319.0713 - val_val_recon_loss: 3.7151e-04 - val_val_KL loss: 83.7855 - val_beta: 3.3887e-04\n",
      "Epoch 1893/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3246.9073 - recon_loss: 3.6328e-04 - KL loss: 83.2814 - beta: 3.3887e-04 - val_val_loss: 3314.1484 - val_val_recon_loss: 3.7095e-04 - val_val_KL loss: 83.7763 - val_beta: 3.3887e-04\n",
      "Epoch 1894/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3258.3916 - recon_loss: 3.6460e-04 - KL loss: 83.2736 - beta: 3.3887e-04 - val_val_loss: 3317.8450 - val_val_recon_loss: 3.7137e-04 - val_val_KL loss: 83.8509 - val_beta: 3.3887e-04\n",
      "Epoch 1895/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3276.0029 - recon_loss: 3.6657e-04 - KL loss: 83.7507 - beta: 3.3887e-04 - val_val_loss: 3312.2102 - val_val_recon_loss: 3.7071e-04 - val_val_KL loss: 83.9516 - val_beta: 3.3887e-04\n",
      "Epoch 1896/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3263.9141 - recon_loss: 3.6515e-04 - KL loss: 84.0828 - beta: 3.3887e-04 - val_val_loss: 3314.0125 - val_val_recon_loss: 3.7092e-04 - val_val_KL loss: 83.9001 - val_beta: 3.3887e-04\n",
      "Epoch 1897/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3278.3485 - recon_loss: 3.6683e-04 - KL loss: 83.8074 - beta: 3.3887e-04 - val_val_loss: 3314.9009 - val_val_recon_loss: 3.7101e-04 - val_val_KL loss: 84.0324 - val_beta: 3.3887e-04\n",
      "Epoch 1898/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3264.3051 - recon_loss: 3.6519e-04 - KL loss: 84.0779 - beta: 3.3887e-04 - val_val_loss: 3316.4187 - val_val_recon_loss: 3.7118e-04 - val_val_KL loss: 84.0551 - val_beta: 3.3887e-04\n",
      "Epoch 1899/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3290.5298 - recon_loss: 3.6820e-04 - KL loss: 84.0641 - beta: 3.3887e-04 - val_val_loss: 3303.4707 - val_val_recon_loss: 3.6968e-04 - val_val_KL loss: 84.1167 - val_beta: 3.3887e-04\n",
      "Epoch 1900/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3235.7128 - recon_loss: 3.6195e-04 - KL loss: 83.7428 - beta: 3.3887e-04 - val_val_loss: 3299.1526 - val_val_recon_loss: 3.6921e-04 - val_val_KL loss: 83.9654 - val_beta: 3.3887e-04\n",
      "Epoch 1901/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3274.5809 - recon_loss: 3.6635e-04 - KL loss: 84.2896 - beta: 3.3887e-04 - val_val_loss: 3304.5356 - val_val_recon_loss: 3.6977e-04 - val_val_KL loss: 84.3928 - val_beta: 3.3887e-04\n",
      "Epoch 1902/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3252.5927 - recon_loss: 3.6383e-04 - KL loss: 84.1994 - beta: 3.3887e-04 - val_val_loss: 3311.2961 - val_val_recon_loss: 3.7060e-04 - val_val_KL loss: 83.9401 - val_beta: 3.3887e-04\n",
      "Epoch 1903/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3282.4149 - recon_loss: 3.6727e-04 - KL loss: 84.0567 - beta: 3.3887e-04 - val_val_loss: 3308.3381 - val_val_recon_loss: 3.7025e-04 - val_val_KL loss: 84.0732 - val_beta: 3.3887e-04\n",
      "Epoch 1904/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3267.3515 - recon_loss: 3.6554e-04 - KL loss: 84.0960 - beta: 3.3887e-04 - val_val_loss: 3315.1094 - val_val_recon_loss: 3.7105e-04 - val_val_KL loss: 83.8590 - val_beta: 3.3887e-04\n",
      "Epoch 1905/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3269.1115 - recon_loss: 3.6579e-04 - KL loss: 83.6695 - beta: 3.3887e-04\n",
      "Epoch 01905: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3269.1158 - recon_loss: 3.6579e-04 - KL loss: 83.6697 - beta: 3.3887e-04 - val_val_loss: 3314.2285 - val_val_recon_loss: 3.7096e-04 - val_val_KL loss: 83.7756 - val_beta: 3.3887e-04\n",
      "Epoch 1906/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3299.4164 - recon_loss: 3.6928e-04 - KL loss: 83.6187 - beta: 3.3887e-04 - val_val_loss: 3307.9343 - val_val_recon_loss: 3.7023e-04 - val_val_KL loss: 83.8018 - val_beta: 3.3887e-04\n",
      "Epoch 1907/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3275.9201 - recon_loss: 3.6655e-04 - KL loss: 83.8941 - beta: 3.3887e-04 - val_val_loss: 3308.6130 - val_val_recon_loss: 3.7031e-04 - val_val_KL loss: 83.8305 - val_beta: 3.3887e-04\n",
      "Epoch 1908/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3260.6219 - recon_loss: 3.6482e-04 - KL loss: 83.6447 - beta: 3.3887e-04 - val_val_loss: 3313.2881 - val_val_recon_loss: 3.7084e-04 - val_val_KL loss: 83.8640 - val_beta: 3.3887e-04\n",
      "Epoch 1909/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3254.4809 - recon_loss: 3.6412e-04 - KL loss: 83.6027 - beta: 3.3887e-04 - val_val_loss: 3312.2671 - val_val_recon_loss: 3.7073e-04 - val_val_KL loss: 83.8348 - val_beta: 3.3887e-04\n",
      "Epoch 1910/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3256.0841 - recon_loss: 3.6427e-04 - KL loss: 83.8483 - beta: 3.3887e-04\n",
      "Epoch 01910: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3256.0954 - recon_loss: 3.6427e-04 - KL loss: 83.8483 - beta: 3.3887e-04 - val_val_loss: 3308.8779 - val_val_recon_loss: 3.7034e-04 - val_val_KL loss: 83.8034 - val_beta: 3.3887e-04\n",
      "Epoch 1910/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12926.9833 - recon_loss: 4.5521e-04 - KL loss: 98.9758 - beta: 1.8838e-04 - val_val_loss: 11766.3223 - val_val_recon_loss: 4.1364e-04 - val_val_KL loss: 109.7642 - val_beta: 1.8838e-04\n",
      "Epoch 1911/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11666.0816 - recon_loss: 4.1003e-04 - KL loss: 111.1646 - beta: 1.8838e-04 - val_val_loss: 11550.7695 - val_val_recon_loss: 4.0585e-04 - val_val_KL loss: 113.7249 - val_beta: 1.8838e-04\n",
      "Epoch 1912/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 11402.2317 - recon_loss: 4.0053e-04 - KL loss: 115.1092 - beta: 1.8838e-04 - val_val_loss: 11170.0908 - val_val_recon_loss: 3.9212e-04 - val_val_KL loss: 120.0324 - val_beta: 1.8838e-04\n",
      "Epoch 1913/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11185.0348 - recon_loss: 3.9264e-04 - KL loss: 120.2260 - beta: 1.8838e-04 - val_val_loss: 11821.0479 - val_val_recon_loss: 4.1498e-04 - val_val_KL loss: 126.6432 - val_beta: 1.8838e-04\n",
      "Epoch 1914/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 11374.1418 - recon_loss: 3.9933e-04 - KL loss: 120.7363 - beta: 1.8838e-04 - val_val_loss: 11321.8652 - val_val_recon_loss: 3.9765e-04 - val_val_KL loss: 115.8471 - val_beta: 1.8838e-04\n",
      "Epoch 1915/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11054.1513 - recon_loss: 3.8811e-04 - KL loss: 116.9364 - beta: 1.8838e-04 - val_val_loss: 11501.2676 - val_val_recon_loss: 4.0368e-04 - val_val_KL loss: 125.2664 - val_beta: 1.8838e-04\n",
      "Epoch 1916/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11175.4909 - recon_loss: 3.9214e-04 - KL loss: 124.7064 - beta: 1.8838e-04 - val_val_loss: 11262.0049 - val_val_recon_loss: 3.9532e-04 - val_val_KL loss: 121.7876 - val_beta: 1.8838e-04\n",
      "Epoch 1917/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11082.5358 - recon_loss: 3.8895e-04 - KL loss: 121.7897 - beta: 1.8838e-04 - val_val_loss: 11039.8184 - val_val_recon_loss: 3.8745e-04 - val_val_KL loss: 121.2449 - val_beta: 1.8838e-04\n",
      "Epoch 1918/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11182.3905 - recon_loss: 3.9249e-04 - KL loss: 121.9132 - beta: 1.8838e-04 - val_val_loss: 11585.0371 - val_val_recon_loss: 4.0661e-04 - val_val_KL loss: 126.5166 - val_beta: 1.8838e-04\n",
      "Epoch 1919/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11296.5098 - recon_loss: 3.9642e-04 - KL loss: 125.2554 - beta: 1.8838e-04 - val_val_loss: 11240.1914 - val_val_recon_loss: 3.9452e-04 - val_val_KL loss: 122.5299 - val_beta: 1.8838e-04\n",
      "Epoch 1920/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11220.9828 - recon_loss: 3.9372e-04 - KL loss: 125.7640 - beta: 1.8838e-04 - val_val_loss: 11303.8076 - val_val_recon_loss: 3.9648e-04 - val_val_KL loss: 130.8015 - val_beta: 1.8838e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1921/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11847.9969 - recon_loss: 4.1557e-04 - KL loss: 137.1712 - beta: 1.8838e-04 - val_val_loss: 11486.1260 - val_val_recon_loss: 4.0285e-04 - val_val_KL loss: 133.6739 - val_beta: 1.8838e-04\n",
      "Epoch 1922/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11351.4788 - recon_loss: 3.9801e-04 - KL loss: 135.3007 - beta: 1.8838e-04\n",
      "Epoch 01922: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11351.4847 - recon_loss: 3.9801e-04 - KL loss: 135.3015 - beta: 1.8838e-04 - val_val_loss: 11350.3662 - val_val_recon_loss: 3.9805e-04 - val_val_KL loss: 133.0941 - val_beta: 1.8838e-04\n",
      "Epoch 1923/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10874.4420 - recon_loss: 3.8117e-04 - KL loss: 133.0091 - beta: 1.8838e-04 - val_val_loss: 10799.3242 - val_val_recon_loss: 3.7852e-04 - val_val_KL loss: 132.3400 - val_beta: 1.8838e-04\n",
      "Epoch 1924/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10653.0530 - recon_loss: 3.7323e-04 - KL loss: 135.2595 - beta: 1.8838e-04 - val_val_loss: 10840.5137 - val_val_recon_loss: 3.7978e-04 - val_val_KL loss: 138.0131 - val_beta: 1.8838e-04\n",
      "Epoch 1925/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10651.4011 - recon_loss: 3.7308e-04 - KL loss: 137.9165 - beta: 1.8838e-04 - val_val_loss: 10634.1201 - val_val_recon_loss: 3.7257e-04 - val_val_KL loss: 134.8661 - val_beta: 1.8838e-04\n",
      "Epoch 1926/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10583.5889 - recon_loss: 3.7076e-04 - KL loss: 135.3753 - beta: 1.8838e-04 - val_val_loss: 10639.1289 - val_val_recon_loss: 3.7282e-04 - val_val_KL loss: 132.7832 - val_beta: 1.8838e-04\n",
      "Epoch 1927/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10527.8654 - recon_loss: 3.6884e-04 - KL loss: 133.8624 - beta: 1.8838e-04 - val_val_loss: 10655.5527 - val_val_recon_loss: 3.7319e-04 - val_val_KL loss: 138.8546 - val_beta: 1.8838e-04\n",
      "Epoch 1928/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10578.8950 - recon_loss: 3.7041e-04 - KL loss: 140.4686 - beta: 1.8838e-04 - val_val_loss: 11469.2178 - val_val_recon_loss: 4.0162e-04 - val_val_KL loss: 151.3233 - val_beta: 1.8838e-04\n",
      "Epoch 1929/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11250.9973 - recon_loss: 3.9390e-04 - KL loss: 150.7924 - beta: 1.8838e-04 - val_val_loss: 11026.0000 - val_val_recon_loss: 3.8603e-04 - val_val_KL loss: 147.5301 - val_beta: 1.8838e-04\n",
      "Epoch 1930/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10803.0551 - recon_loss: 3.7821e-04 - KL loss: 145.0329 - beta: 1.8838e-04\n",
      "Epoch 01930: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10803.0304 - recon_loss: 3.7820e-04 - KL loss: 145.0324 - beta: 1.8838e-04 - val_val_loss: 10929.1152 - val_val_recon_loss: 3.8267e-04 - val_val_KL loss: 145.3797 - val_beta: 1.8838e-04\n",
      "Epoch 1931/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10708.3599 - recon_loss: 3.7479e-04 - KL loss: 146.5668 - beta: 1.8838e-04 - val_val_loss: 10766.5059 - val_val_recon_loss: 3.7688e-04 - val_val_KL loss: 145.8800 - val_beta: 1.8838e-04\n",
      "Epoch 1932/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10639.3019 - recon_loss: 3.7239e-04 - KL loss: 145.3051 - beta: 1.8838e-04 - val_val_loss: 10701.8311 - val_val_recon_loss: 3.7464e-04 - val_val_KL loss: 144.2867 - val_beta: 1.8838e-04\n",
      "Epoch 1933/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10459.8393 - recon_loss: 3.6602e-04 - KL loss: 145.2306 - beta: 1.8838e-04 - val_val_loss: 10684.2334 - val_val_recon_loss: 3.7394e-04 - val_val_KL loss: 146.5394 - val_beta: 1.8838e-04\n",
      "Epoch 1934/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 10655.2765 - recon_loss: 3.7289e-04 - KL loss: 147.1858 - beta: 1.8838e-04 - val_val_loss: 10773.0342 - val_val_recon_loss: 3.7696e-04 - val_val_KL loss: 150.2037 - val_beta: 1.8838e-04\n",
      "Epoch 1935/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10601.1652 - recon_loss: 3.7088e-04 - KL loss: 149.5094 - beta: 1.8838e-04\n",
      "Epoch 01935: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 10601.1237 - recon_loss: 3.7088e-04 - KL loss: 149.5084 - beta: 1.8838e-04 - val_val_loss: 10642.1562 - val_val_recon_loss: 3.7249e-04 - val_val_KL loss: 145.2283 - val_beta: 1.8838e-04\n",
      "Epoch 1935/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 38565.3932 - recon_loss: 4.2103e-04 - KL loss: 170.9710 - beta: 1.0472e-04 - val_val_loss: 36004.0469 - val_val_recon_loss: 3.9280e-04 - val_val_KL loss: 183.9176 - val_beta: 1.0472e-04\n",
      "Epoch 1936/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35885.7042 - recon_loss: 3.9138e-04 - KL loss: 195.2031 - beta: 1.0472e-04 - val_val_loss: 35691.4531 - val_val_recon_loss: 3.8907e-04 - val_val_KL loss: 211.1354 - val_beta: 1.0472e-04\n",
      "Epoch 1937/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35175.3726 - recon_loss: 3.8348e-04 - KL loss: 205.0735 - beta: 1.0472e-04 - val_val_loss: 35813.7344 - val_val_recon_loss: 3.9059e-04 - val_val_KL loss: 194.5182 - val_beta: 1.0472e-04\n",
      "Epoch 1938/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35219.9747 - recon_loss: 3.8401e-04 - KL loss: 201.5699 - beta: 1.0472e-04 - val_val_loss: 34391.6094 - val_val_recon_loss: 3.7481e-04 - val_val_KL loss: 211.7545 - val_beta: 1.0472e-04\n",
      "Epoch 1939/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 34024.1449 - recon_loss: 3.7078e-04 - KL loss: 211.4980 - beta: 1.0472e-04 - val_val_loss: 34899.8555 - val_val_recon_loss: 3.8051e-04 - val_val_KL loss: 200.4304 - val_beta: 1.0472e-04\n",
      "Epoch 1940/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 34267.2442 - recon_loss: 3.7348e-04 - KL loss: 208.9093 - beta: 1.0472e-04 - val_val_loss: 34118.7148 - val_val_recon_loss: 3.7193e-04 - val_val_KL loss: 201.1625 - val_beta: 1.0472e-04\n",
      "Epoch 1941/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35064.1810 - recon_loss: 3.8222e-04 - KL loss: 208.3522 - beta: 1.0472e-04 - val_val_loss: 35041.4023 - val_val_recon_loss: 3.8180e-04 - val_val_KL loss: 223.7919 - val_beta: 1.0472e-04\n",
      "Epoch 1942/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 34703.8410 - recon_loss: 3.7821e-04 - KL loss: 214.3364 - beta: 1.0472e-04 - val_val_loss: 34021.3906 - val_val_recon_loss: 3.7075e-04 - val_val_KL loss: 211.4742 - val_beta: 1.0472e-04\n",
      "Epoch 1943/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 35257.9396 - recon_loss: 3.8419e-04 - KL loss: 223.1425 - beta: 1.0472e-04 - val_val_loss: 42164.2734 - val_val_recon_loss: 4.5941e-04 - val_val_KL loss: 269.8879 - val_beta: 1.0472e-04\n",
      "Epoch 1944/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 39590.6398 - recon_loss: 4.3123e-04 - KL loss: 265.9643 - beta: 1.0472e-04 - val_val_loss: 36006.8750 - val_val_recon_loss: 3.9223e-04 - val_val_KL loss: 238.3408 - val_beta: 1.0472e-04\n",
      "Epoch 1945/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 36163.6814 - recon_loss: 3.9406e-04 - KL loss: 228.4842 - beta: 1.0472e-04 - val_val_loss: 36245.6562 - val_val_recon_loss: 3.9491e-04 - val_val_KL loss: 232.5460 - val_beta: 1.0472e-04\n",
      "Epoch 1946/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 40160.3048 - recon_loss: 4.3756e-04 - KL loss: 257.7382 - beta: 1.0472e-04 - val_val_loss: 35729.3164 - val_val_recon_loss: 3.8916e-04 - val_val_KL loss: 240.4613 - val_beta: 1.0472e-04\n",
      "Epoch 1947/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 34788.0751 - recon_loss: 3.7877e-04 - KL loss: 247.1917 - beta: 1.0472e-04\n",
      "Epoch 01947: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 34788.0758 - recon_loss: 3.7877e-04 - KL loss: 247.1960 - beta: 1.0472e-04 - val_val_loss: 35241.6133 - val_val_recon_loss: 3.8366e-04 - val_val_KL loss: 254.8901 - val_beta: 1.0472e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1948/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 33829.5249 - recon_loss: 3.6810e-04 - KL loss: 261.9456 - beta: 1.0472e-04 - val_val_loss: 33534.0234 - val_val_recon_loss: 3.6489e-04 - val_val_KL loss: 259.2631 - val_beta: 1.0472e-04\n",
      "Epoch 1949/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 33132.7133 - recon_loss: 3.6047e-04 - KL loss: 260.5226 - beta: 1.0472e-04 - val_val_loss: 33508.8008 - val_val_recon_loss: 3.6475e-04 - val_val_KL loss: 246.3950 - val_beta: 1.0472e-04\n",
      "Epoch 1950/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32838.2955 - recon_loss: 3.5738e-04 - KL loss: 247.9837 - beta: 1.0472e-04 - val_val_loss: 32906.3594 - val_val_recon_loss: 3.5811e-04 - val_val_KL loss: 249.4379 - val_beta: 1.0472e-04\n",
      "Epoch 1951/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32748.6559 - recon_loss: 3.5634e-04 - KL loss: 253.1429 - beta: 1.0472e-04 - val_val_loss: 32692.6641 - val_val_recon_loss: 3.5571e-04 - val_val_KL loss: 254.4685 - val_beta: 1.0472e-04\n",
      "Epoch 1952/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32461.3059 - recon_loss: 3.5319e-04 - KL loss: 252.9346 - beta: 1.0472e-04 - val_val_loss: 32783.5234 - val_val_recon_loss: 3.5678e-04 - val_val_KL loss: 248.3179 - val_beta: 1.0472e-04\n",
      "Epoch 1953/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32665.2798 - recon_loss: 3.5539e-04 - KL loss: 256.7566 - beta: 1.0472e-04 - val_val_loss: 33208.9375 - val_val_recon_loss: 3.6122e-04 - val_val_KL loss: 268.1165 - val_beta: 1.0472e-04\n",
      "Epoch 1954/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32931.9228 - recon_loss: 3.5820e-04 - KL loss: 266.6546 - beta: 1.0472e-04 - val_val_loss: 32972.4297 - val_val_recon_loss: 3.5875e-04 - val_val_KL loss: 257.0733 - val_beta: 1.0472e-04\n",
      "Epoch 1955/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32404.2370 - recon_loss: 3.5250e-04 - KL loss: 258.5632 - beta: 1.0472e-04 - val_val_loss: 32382.2422 - val_val_recon_loss: 3.5228e-04 - val_val_KL loss: 257.1192 - val_beta: 1.0472e-04\n",
      "Epoch 1956/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31851.8044 - recon_loss: 3.4645e-04 - KL loss: 258.1344 - beta: 1.0472e-04 - val_val_loss: 32405.7949 - val_val_recon_loss: 3.5251e-04 - val_val_KL loss: 259.8823 - val_beta: 1.0472e-04\n",
      "Epoch 1957/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 32108.3196 - recon_loss: 3.4927e-04 - KL loss: 257.3521 - beta: 1.0472e-04 - val_val_loss: 33162.8281 - val_val_recon_loss: 3.6084e-04 - val_val_KL loss: 257.3220 - val_beta: 1.0472e-04\n",
      "Epoch 1958/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32220.1593 - recon_loss: 3.5049e-04 - KL loss: 258.4786 - beta: 1.0472e-04 - val_val_loss: 32061.8203 - val_val_recon_loss: 3.4874e-04 - val_val_KL loss: 259.3027 - val_beta: 1.0472e-04\n",
      "Epoch 1959/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 31546.0536 - recon_loss: 3.4310e-04 - KL loss: 257.7240 - beta: 1.0472e-04 - val_val_loss: 31926.7598 - val_val_recon_loss: 3.4730e-04 - val_val_KL loss: 255.3885 - val_beta: 1.0472e-04\n",
      "Epoch 1960/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32178.2215 - recon_loss: 3.5010e-04 - KL loss: 251.7041 - beta: 1.0472e-04 - val_val_loss: 32171.9707 - val_val_recon_loss: 3.5004e-04 - val_val_KL loss: 251.3265 - val_beta: 1.0472e-04\n",
      "Epoch 1961/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 31577.0592 - recon_loss: 3.4350e-04 - KL loss: 252.1392 - beta: 1.0472e-04 - val_val_loss: 32119.4668 - val_val_recon_loss: 3.4949e-04 - val_val_KL loss: 248.8904 - val_beta: 1.0472e-04\n",
      "Epoch 1962/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 31903.1050 - recon_loss: 3.4711e-04 - KL loss: 248.9202 - beta: 1.0472e-04 - val_val_loss: 31884.2051 - val_val_recon_loss: 3.4690e-04 - val_val_KL loss: 249.6753 - val_beta: 1.0472e-04\n",
      "Epoch 1963/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31447.7339 - recon_loss: 3.4211e-04 - KL loss: 249.8283 - beta: 1.0472e-04 - val_val_loss: 32307.9121 - val_val_recon_loss: 3.5156e-04 - val_val_KL loss: 248.6487 - val_beta: 1.0472e-04\n",
      "Epoch 1964/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 31918.5868 - recon_loss: 3.4727e-04 - KL loss: 249.8058 - beta: 1.0472e-04 - val_val_loss: 32001.6582 - val_val_recon_loss: 3.4813e-04 - val_val_KL loss: 254.8090 - val_beta: 1.0472e-04\n",
      "Epoch 1965/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31584.5910 - recon_loss: 3.4354e-04 - KL loss: 256.1353 - beta: 1.0472e-04 - val_val_loss: 31759.3730 - val_val_recon_loss: 3.4552e-04 - val_val_KL loss: 251.0221 - val_beta: 1.0472e-04\n",
      "Epoch 1966/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31359.7792 - recon_loss: 3.4110e-04 - KL loss: 253.6824 - beta: 1.0472e-04 - val_val_loss: 31691.5684 - val_val_recon_loss: 3.4475e-04 - val_val_KL loss: 253.1748 - val_beta: 1.0472e-04\n",
      "Epoch 1967/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31552.9413 - recon_loss: 3.4323e-04 - KL loss: 252.6282 - beta: 1.0472e-04 - val_val_loss: 31702.7656 - val_val_recon_loss: 3.4487e-04 - val_val_KL loss: 253.1664 - val_beta: 1.0472e-04\n",
      "Epoch 1968/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31356.8461 - recon_loss: 3.4102e-04 - KL loss: 258.2143 - beta: 1.0472e-04 - val_val_loss: 32043.3691 - val_val_recon_loss: 3.4849e-04 - val_val_KL loss: 263.9974 - val_beta: 1.0472e-04\n",
      "Epoch 1969/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31878.1599 - recon_loss: 3.4668e-04 - KL loss: 263.9821 - beta: 1.0472e-04 - val_val_loss: 31786.2832 - val_val_recon_loss: 3.4567e-04 - val_val_KL loss: 263.7391 - val_beta: 1.0472e-04\n",
      "Epoch 1970/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31265.4760 - recon_loss: 3.3992e-04 - KL loss: 267.4326 - beta: 1.0472e-04 - val_val_loss: 31915.5879 - val_val_recon_loss: 3.4705e-04 - val_val_KL loss: 267.6566 - val_beta: 1.0472e-04\n",
      "Epoch 1971/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31692.5002 - recon_loss: 3.4460e-04 - KL loss: 268.0193 - beta: 1.0472e-04\n",
      "Epoch 01971: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31692.5953 - recon_loss: 3.4460e-04 - KL loss: 268.0202 - beta: 1.0472e-04 - val_val_loss: 31748.0977 - val_val_recon_loss: 3.4521e-04 - val_val_KL loss: 267.9886 - val_beta: 1.0472e-04\n",
      "Epoch 1972/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31193.2959 - recon_loss: 3.3913e-04 - KL loss: 267.2754 - beta: 1.0472e-04 - val_val_loss: 31437.1992 - val_val_recon_loss: 3.4180e-04 - val_val_KL loss: 268.0531 - val_beta: 1.0472e-04\n",
      "Epoch 1973/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31121.9921 - recon_loss: 3.3835e-04 - KL loss: 266.7564 - beta: 1.0472e-04 - val_val_loss: 31410.6641 - val_val_recon_loss: 3.4151e-04 - val_val_KL loss: 267.2878 - val_beta: 1.0472e-04\n",
      "Epoch 1974/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 31150.3709 - recon_loss: 3.3864e-04 - KL loss: 268.8010 - beta: 1.0472e-04 - val_val_loss: 31373.2070 - val_val_recon_loss: 3.4104e-04 - val_val_KL loss: 272.9287 - val_beta: 1.0472e-04\n",
      "Epoch 1975/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31191.2782 - recon_loss: 3.3904e-04 - KL loss: 273.1855 - beta: 1.0472e-04 - val_val_loss: 31574.0332 - val_val_recon_loss: 3.4330e-04 - val_val_KL loss: 267.3471 - val_beta: 1.0472e-04\n",
      "Epoch 1976/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31150.8334 - recon_loss: 3.3866e-04 - KL loss: 267.1803 - beta: 1.0472e-04 - val_val_loss: 31091.0703 - val_val_recon_loss: 3.3804e-04 - val_val_KL loss: 264.3107 - val_beta: 1.0472e-04\n",
      "Epoch 1977/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30761.8107 - recon_loss: 3.3443e-04 - KL loss: 264.6445 - beta: 1.0472e-04 - val_val_loss: 31184.0859 - val_val_recon_loss: 3.3902e-04 - val_val_KL loss: 268.3842 - val_beta: 1.0472e-04\n",
      "Epoch 1978/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30759.3954 - recon_loss: 3.3435e-04 - KL loss: 269.1639 - beta: 1.0472e-04 - val_val_loss: 31135.5898 - val_val_recon_loss: 3.3851e-04 - val_val_KL loss: 265.8579 - val_beta: 1.0472e-04\n",
      "Epoch 1979/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30529.2964 - recon_loss: 3.3187e-04 - KL loss: 265.6665 - beta: 1.0472e-04 - val_val_loss: 31059.1250 - val_val_recon_loss: 3.3765e-04 - val_val_KL loss: 267.6901 - val_beta: 1.0472e-04\n",
      "Epoch 1980/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30856.8626 - recon_loss: 3.3541e-04 - KL loss: 269.9672 - beta: 1.0472e-04 - val_val_loss: 31373.8320 - val_val_recon_loss: 3.4104e-04 - val_val_KL loss: 273.6424 - val_beta: 1.0472e-04\n",
      "Epoch 1981/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30995.0204 - recon_loss: 3.3689e-04 - KL loss: 273.0525 - beta: 1.0472e-04 - val_val_loss: 31122.6875 - val_val_recon_loss: 3.3833e-04 - val_val_KL loss: 269.9547 - val_beta: 1.0472e-04\n",
      "Epoch 1982/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30515.2721 - recon_loss: 3.3165e-04 - KL loss: 270.9696 - beta: 1.0472e-04 - val_val_loss: 31145.6152 - val_val_recon_loss: 3.3853e-04 - val_val_KL loss: 274.3388 - val_beta: 1.0472e-04\n",
      "Epoch 1983/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30892.3693 - recon_loss: 3.3576e-04 - KL loss: 274.0327 - beta: 1.0472e-04 - val_val_loss: 31276.1895 - val_val_recon_loss: 3.3991e-04 - val_val_KL loss: 278.6480 - val_beta: 1.0472e-04\n",
      "Epoch 1984/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31019.0087 - recon_loss: 3.3709e-04 - KL loss: 278.6771 - beta: 1.0472e-04- ETA: 5s - loss: 31024.4792 - recon_loss: \n",
      "Epoch 01984: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31018.8984 - recon_loss: 3.3709e-04 - KL loss: 278.6779 - beta: 1.0472e-04 - val_val_loss: 31319.6445 - val_val_recon_loss: 3.4037e-04 - val_val_KL loss: 280.7059 - val_beta: 1.0472e-04\n",
      "Epoch 1985/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30772.6635 - recon_loss: 3.3438e-04 - KL loss: 280.1420 - beta: 1.0472e-04 - val_val_loss: 31146.0449 - val_val_recon_loss: 3.3848e-04 - val_val_KL loss: 278.8440 - val_beta: 1.0472e-04\n",
      "Epoch 1986/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30876.0032 - recon_loss: 3.3552e-04 - KL loss: 279.1381 - beta: 1.0472e-04 - val_val_loss: 31084.1992 - val_val_recon_loss: 3.3781e-04 - val_val_KL loss: 278.7748 - val_beta: 1.0472e-04\n",
      "Epoch 1987/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30750.6311 - recon_loss: 3.3416e-04 - KL loss: 277.8421 - beta: 1.0472e-04 - val_val_loss: 31071.1523 - val_val_recon_loss: 3.3766e-04 - val_val_KL loss: 278.6717 - val_beta: 1.0472e-04\n",
      "Epoch 1988/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30464.8337 - recon_loss: 3.3102e-04 - KL loss: 278.4083 - beta: 1.0472e-04 - val_val_loss: 31053.3457 - val_val_recon_loss: 3.3747e-04 - val_val_KL loss: 278.7924 - val_beta: 1.0472e-04\n",
      "Epoch 1989/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30965.1597 - recon_loss: 3.3650e-04 - KL loss: 279.2505 - beta: 1.0472e-04 - val_val_loss: 31101.0117 - val_val_recon_loss: 3.3797e-04 - val_val_KL loss: 280.9991 - val_beta: 1.0472e-04\n",
      "Epoch 1990/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30546.4817 - recon_loss: 3.3189e-04 - KL loss: 280.3904 - beta: 1.0472e-04 - val_val_loss: 31117.0059 - val_val_recon_loss: 3.3814e-04 - val_val_KL loss: 281.4272 - val_beta: 1.0472e-04\n",
      "Epoch 1991/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30647.7334 - recon_loss: 3.3299e-04 - KL loss: 281.8502 - beta: 1.0472e-04 - val_val_loss: 31026.4121 - val_val_recon_loss: 3.3715e-04 - val_val_KL loss: 281.0699 - val_beta: 1.0472e-04\n",
      "Epoch 1992/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30683.7827 - recon_loss: 3.3338e-04 - KL loss: 282.4885 - beta: 1.0472e-04 - val_val_loss: 31028.8105 - val_val_recon_loss: 3.3717e-04 - val_val_KL loss: 281.7570 - val_beta: 1.0472e-04\n",
      "Epoch 1993/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30835.4603 - recon_loss: 3.3505e-04 - KL loss: 281.7055 - beta: 1.0472e-04 - val_val_loss: 31011.4199 - val_val_recon_loss: 3.3699e-04 - val_val_KL loss: 280.7350 - val_beta: 1.0472e-04\n",
      "Epoch 1994/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30541.4028 - recon_loss: 3.3184e-04 - KL loss: 279.8997 - beta: 1.0472e-04 - val_val_loss: 30991.5020 - val_val_recon_loss: 3.3677e-04 - val_val_KL loss: 280.4916 - val_beta: 1.0472e-04\n",
      "Epoch 1995/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30708.4286 - recon_loss: 3.3366e-04 - KL loss: 280.9500 - beta: 1.0472e-04 - val_val_loss: 30978.4375 - val_val_recon_loss: 3.3663e-04 - val_val_KL loss: 280.5966 - val_beta: 1.0472e-04\n",
      "Epoch 1996/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30489.2697 - recon_loss: 3.3126e-04 - KL loss: 280.8319 - beta: 1.0472e-04 - val_val_loss: 31014.8906 - val_val_recon_loss: 3.3702e-04 - val_val_KL loss: 281.5975 - val_beta: 1.0472e-04\n",
      "Epoch 1997/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30871.2331 - recon_loss: 3.3543e-04 - KL loss: 282.4176 - beta: 1.0472e-04 - val_val_loss: 30983.6641 - val_val_recon_loss: 3.3669e-04 - val_val_KL loss: 280.3763 - val_beta: 1.0472e-04\n",
      "Epoch 1998/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30736.8365 - recon_loss: 3.3397e-04 - KL loss: 281.1522 - beta: 1.0472e-04 - val_val_loss: 30979.7129 - val_val_recon_loss: 3.3663e-04 - val_val_KL loss: 281.7362 - val_beta: 1.0472e-04\n",
      "Epoch 1999/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30625.4447 - recon_loss: 3.3275e-04 - KL loss: 280.7829 - beta: 1.0472e-04 - val_val_loss: 30924.7344 - val_val_recon_loss: 3.3604e-04 - val_val_KL loss: 280.2626 - val_beta: 1.0472e-04\n",
      "Epoch 2000/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30428.5801 - recon_loss: 3.3059e-04 - KL loss: 281.3391 - beta: 1.0472e-04 - val_val_loss: 30977.2344 - val_val_recon_loss: 3.3660e-04 - val_val_KL loss: 281.7056 - val_beta: 1.0472e-04\n",
      "Epoch 2001/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30761.0995 - recon_loss: 3.3423e-04 - KL loss: 282.3206 - beta: 1.0472e-04 - val_val_loss: 31005.3008 - val_val_recon_loss: 3.3690e-04 - val_val_KL loss: 282.3332 - val_beta: 1.0472e-04\n",
      "Epoch 2002/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30706.9137 - recon_loss: 3.3363e-04 - KL loss: 282.6858 - beta: 1.0472e-04 - val_val_loss: 30919.4922 - val_val_recon_loss: 3.3598e-04 - val_val_KL loss: 280.8941 - val_beta: 1.0472e-04\n",
      "Epoch 2003/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30265.9477 - recon_loss: 3.2881e-04 - KL loss: 281.0663 - beta: 1.0472e-04 - val_val_loss: 30950.2695 - val_val_recon_loss: 3.3631e-04 - val_val_KL loss: 281.5605 - val_beta: 1.0472e-04\n",
      "Epoch 2004/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30621.6082 - recon_loss: 3.3271e-04 - KL loss: 281.3062 - beta: 1.0472e-04 - val_val_loss: 31041.2168 - val_val_recon_loss: 3.3729e-04 - val_val_KL loss: 283.3168 - val_beta: 1.0472e-04\n",
      "Epoch 2005/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30536.0201 - recon_loss: 3.3175e-04 - KL loss: 282.6812 - beta: 1.0472e-04 - val_val_loss: 30953.2480 - val_val_recon_loss: 3.3633e-04 - val_val_KL loss: 282.5082 - val_beta: 1.0472e-04\n",
      "Epoch 2006/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30442.9943 - recon_loss: 3.3074e-04 - KL loss: 281.9721 - beta: 1.0472e-04 - val_val_loss: 30911.8691 - val_val_recon_loss: 3.3589e-04 - val_val_KL loss: 281.4202 - val_beta: 1.0472e-04\n",
      "Epoch 2007/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30420.2287 - recon_loss: 3.3050e-04 - KL loss: 281.3499 - beta: 1.0472e-04 - val_val_loss: 30865.1055 - val_val_recon_loss: 3.3538e-04 - val_val_KL loss: 281.0238 - val_beta: 1.0472e-04\n",
      "Epoch 2008/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30469.9662 - recon_loss: 3.3105e-04 - KL loss: 280.4010 - beta: 1.0472e-04 - val_val_loss: 30819.7676 - val_val_recon_loss: 3.3489e-04 - val_val_KL loss: 280.1097 - val_beta: 1.0472e-04\n",
      "Epoch 2009/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30363.1544 - recon_loss: 3.2990e-04 - KL loss: 279.2161 - beta: 1.0472e-04 - val_val_loss: 30836.5801 - val_val_recon_loss: 3.3507e-04 - val_val_KL loss: 280.6500 - val_beta: 1.0472e-04\n",
      "Epoch 2010/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30567.2159 - recon_loss: 3.3212e-04 - KL loss: 280.4078 - beta: 1.0472e-04 - val_val_loss: 30881.8320 - val_val_recon_loss: 3.3556e-04 - val_val_KL loss: 281.0027 - val_beta: 1.0472e-04\n",
      "Epoch 2011/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30374.6151 - recon_loss: 3.3000e-04 - KL loss: 281.4505 - beta: 1.0472e-04 - val_val_loss: 30922.1348 - val_val_recon_loss: 3.3598e-04 - val_val_KL loss: 282.8903 - val_beta: 1.0472e-04\n",
      "Epoch 2012/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30238.2304 - recon_loss: 3.2848e-04 - KL loss: 282.8969 - beta: 1.0472e-04 - val_val_loss: 30868.6641 - val_val_recon_loss: 3.3540e-04 - val_val_KL loss: 282.3518 - val_beta: 1.0472e-04\n",
      "Epoch 2013/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 29978.3449 - recon_loss: 3.2565e-04 - KL loss: 281.3503 - beta: 1.0472e-04\n",
      "Epoch 02013: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29978.6074 - recon_loss: 3.2565e-04 - KL loss: 281.3509 - beta: 1.0472e-04 - val_val_loss: 30860.0391 - val_val_recon_loss: 3.3532e-04 - val_val_KL loss: 281.7741 - val_beta: 1.0472e-04\n",
      "Epoch 2014/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30123.0363 - recon_loss: 3.2723e-04 - KL loss: 281.9258 - beta: 1.0472e-04 - val_val_loss: 30818.0469 - val_val_recon_loss: 3.3485e-04 - val_val_KL loss: 281.9654 - val_beta: 1.0472e-04\n",
      "Epoch 2015/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30183.1342 - recon_loss: 3.2789e-04 - KL loss: 282.0001 - beta: 1.0472e-04 - val_val_loss: 30802.2852 - val_val_recon_loss: 3.3468e-04 - val_val_KL loss: 281.8605 - val_beta: 1.0472e-04\n",
      "Epoch 2016/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30330.9425 - recon_loss: 3.2952e-04 - KL loss: 281.4012 - beta: 1.0472e-04 - val_val_loss: 30806.0293 - val_val_recon_loss: 3.3472e-04 - val_val_KL loss: 282.5323 - val_beta: 1.0472e-04\n",
      "Epoch 2017/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30397.3624 - recon_loss: 3.3023e-04 - KL loss: 282.5546 - beta: 1.0472e-04 - val_val_loss: 30795.5703 - val_val_recon_loss: 3.3461e-04 - val_val_KL loss: 281.8658 - val_beta: 1.0472e-04\n",
      "Epoch 2018/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30285.9178 - recon_loss: 3.2902e-04 - KL loss: 281.9128 - beta: 1.0472e-04 - val_val_loss: 30798.3145 - val_val_recon_loss: 3.3464e-04 - val_val_KL loss: 281.6091 - val_beta: 1.0472e-04\n",
      "Epoch 2019/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30159.3351 - recon_loss: 3.2762e-04 - KL loss: 282.5175 - beta: 1.0472e-04 - val_val_loss: 30795.1367 - val_val_recon_loss: 3.3460e-04 - val_val_KL loss: 281.9528 - val_beta: 1.0472e-04\n",
      "Epoch 2020/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30470.7225 - recon_loss: 3.3104e-04 - KL loss: 282.4417 - beta: 1.0472e-04 - val_val_loss: 30785.3945 - val_val_recon_loss: 3.3450e-04 - val_val_KL loss: 281.3453 - val_beta: 1.0472e-04\n",
      "Epoch 2021/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30256.1261 - recon_loss: 3.2870e-04 - KL loss: 281.6350 - beta: 1.0472e-04 - val_val_loss: 30736.4004 - val_val_recon_loss: 3.3396e-04 - val_val_KL loss: 281.4624 - val_beta: 1.0472e-04\n",
      "Epoch 2022/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30468.0531 - recon_loss: 3.3102e-04 - KL loss: 281.8930 - beta: 1.0472e-04 - val_val_loss: 30737.0332 - val_val_recon_loss: 3.3397e-04 - val_val_KL loss: 281.5047 - val_beta: 1.0472e-04\n",
      "Epoch 2023/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30410.9859 - recon_loss: 3.3040e-04 - KL loss: 281.3301 - beta: 1.0472e-04 - val_val_loss: 30727.3418 - val_val_recon_loss: 3.3387e-04 - val_val_KL loss: 281.1176 - val_beta: 1.0472e-04\n",
      "Epoch 2024/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30240.6402 - recon_loss: 3.2853e-04 - KL loss: 281.4720 - beta: 1.0472e-04 - val_val_loss: 30711.1641 - val_val_recon_loss: 3.3369e-04 - val_val_KL loss: 281.5170 - val_beta: 1.0472e-04\n",
      "Epoch 2025/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29931.1257 - recon_loss: 3.2514e-04 - KL loss: 281.2402 - beta: 1.0472e-04 - val_val_loss: 30719.8926 - val_val_recon_loss: 3.3378e-04 - val_val_KL loss: 281.4244 - val_beta: 1.0472e-04\n",
      "Epoch 2026/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30388.8413 - recon_loss: 3.3015e-04 - KL loss: 281.5996 - beta: 1.0472e-04 - val_val_loss: 30710.4258 - val_val_recon_loss: 3.3368e-04 - val_val_KL loss: 281.1454 - val_beta: 1.0472e-04\n",
      "Epoch 2027/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30213.7894 - recon_loss: 3.2824e-04 - KL loss: 280.4906 - beta: 1.0472e-04 - val_val_loss: 30741.3496 - val_val_recon_loss: 3.3402e-04 - val_val_KL loss: 280.8349 - val_beta: 1.0472e-04\n",
      "Epoch 2028/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30361.9745 - recon_loss: 3.2986e-04 - KL loss: 281.4177 - beta: 1.0472e-04 - val_val_loss: 30713.7832 - val_val_recon_loss: 3.3372e-04 - val_val_KL loss: 281.0781 - val_beta: 1.0472e-04\n",
      "Epoch 2029/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30244.0940 - recon_loss: 3.2858e-04 - KL loss: 280.2974 - beta: 1.0472e-04 - val_val_loss: 30755.1895 - val_val_recon_loss: 3.3417e-04 - val_val_KL loss: 281.1469 - val_beta: 1.0472e-04\n",
      "Epoch 2030/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30230.8789 - recon_loss: 3.2843e-04 - KL loss: 280.7885 - beta: 1.0472e-04 - val_val_loss: 30712.8418 - val_val_recon_loss: 3.3371e-04 - val_val_KL loss: 281.4853 - val_beta: 1.0472e-04\n",
      "Epoch 2031/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30615.5444 - recon_loss: 3.3264e-04 - KL loss: 281.7653 - beta: 1.0472e-04 - val_val_loss: 30698.9082 - val_val_recon_loss: 3.3356e-04 - val_val_KL loss: 281.0430 - val_beta: 1.0472e-04\n",
      "Epoch 2032/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30227.3993 - recon_loss: 3.2838e-04 - KL loss: 281.6156 - beta: 1.0472e-04 - val_val_loss: 30691.9727 - val_val_recon_loss: 3.3348e-04 - val_val_KL loss: 281.3565 - val_beta: 1.0472e-04\n",
      "Epoch 2033/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30323.1545 - recon_loss: 3.2944e-04 - KL loss: 280.9787 - beta: 1.0472e-04 - val_val_loss: 30687.7832 - val_val_recon_loss: 3.3343e-04 - val_val_KL loss: 281.0982 - val_beta: 1.0472e-04\n",
      "Epoch 2034/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30200.0385 - recon_loss: 3.2809e-04 - KL loss: 280.7688 - beta: 1.0472e-04 - val_val_loss: 30696.6230 - val_val_recon_loss: 3.3353e-04 - val_val_KL loss: 281.0844 - val_beta: 1.0472e-04\n",
      "Epoch 2035/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30041.7765 - recon_loss: 3.2636e-04 - KL loss: 280.5259 - beta: 1.0472e-04 - val_val_loss: 30696.2676 - val_val_recon_loss: 3.3353e-04 - val_val_KL loss: 280.4068 - val_beta: 1.0472e-04\n",
      "Epoch 2036/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30052.6203 - recon_loss: 3.2648e-04 - KL loss: 280.0686 - beta: 1.0472e-04 - val_val_loss: 30708.3516 - val_val_recon_loss: 3.3367e-04 - val_val_KL loss: 280.0273 - val_beta: 1.0472e-04\n",
      "Epoch 2037/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30126.3566 - recon_loss: 3.2729e-04 - KL loss: 280.2464 - beta: 1.0472e-04 - val_val_loss: 30671.3691 - val_val_recon_loss: 3.3327e-04 - val_val_KL loss: 279.7681 - val_beta: 1.0472e-04\n",
      "Epoch 2038/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30507.6116 - recon_loss: 3.3147e-04 - KL loss: 279.7065 - beta: 1.0472e-04 - val_val_loss: 30659.0176 - val_val_recon_loss: 3.3314e-04 - val_val_KL loss: 279.2246 - val_beta: 1.0472e-04\n",
      "Epoch 2039/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30386.4118 - recon_loss: 3.3014e-04 - KL loss: 279.9459 - beta: 1.0472e-04 - val_val_loss: 30675.1699 - val_val_recon_loss: 3.3331e-04 - val_val_KL loss: 279.5468 - val_beta: 1.0472e-04\n",
      "Epoch 2040/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30210.6584 - recon_loss: 3.2822e-04 - KL loss: 279.3938 - beta: 1.0472e-04 - val_val_loss: 30688.6016 - val_val_recon_loss: 3.3346e-04 - val_val_KL loss: 279.8803 - val_beta: 1.0472e-04\n",
      "Epoch 2041/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30180.2259 - recon_loss: 3.2788e-04 - KL loss: 279.8752 - beta: 1.0472e-04 - val_val_loss: 30647.6250 - val_val_recon_loss: 3.3301e-04 - val_val_KL loss: 279.4230 - val_beta: 1.0472e-04\n",
      "Epoch 2042/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30008.6162 - recon_loss: 3.2601e-04 - KL loss: 279.2830 - beta: 1.0472e-04 - val_val_loss: 30652.5195 - val_val_recon_loss: 3.3307e-04 - val_val_KL loss: 279.0798 - val_beta: 1.0472e-04\n",
      "Epoch 2043/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30251.7430 - recon_loss: 3.2868e-04 - KL loss: 279.0654 - beta: 1.0472e-04 - val_val_loss: 30638.4102 - val_val_recon_loss: 3.3291e-04 - val_val_KL loss: 279.3189 - val_beta: 1.0472e-04\n",
      "Epoch 2044/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30133.8568 - recon_loss: 3.2737e-04 - KL loss: 280.4951 - beta: 1.0472e-04 - val_val_loss: 30625.8477 - val_val_recon_loss: 3.3277e-04 - val_val_KL loss: 279.5839 - val_beta: 1.0472e-04\n",
      "Epoch 2045/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30208.5183 - recon_loss: 3.2820e-04 - KL loss: 279.3369 - beta: 1.0472e-04 - val_val_loss: 30632.5898 - val_val_recon_loss: 3.3285e-04 - val_val_KL loss: 279.4845 - val_beta: 1.0472e-04\n",
      "Epoch 2046/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30203.0517 - recon_loss: 3.2812e-04 - KL loss: 280.5846 - beta: 1.0472e-04 - val_val_loss: 30657.1758 - val_val_recon_loss: 3.3311e-04 - val_val_KL loss: 279.9133 - val_beta: 1.0472e-04\n",
      "Epoch 2047/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30079.4911 - recon_loss: 3.2678e-04 - KL loss: 279.7265 - beta: 1.0472e-04 - val_val_loss: 30637.1895 - val_val_recon_loss: 3.3290e-04 - val_val_KL loss: 279.3924 - val_beta: 1.0472e-04\n",
      "Epoch 2048/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30275.7652 - recon_loss: 3.2893e-04 - KL loss: 279.4392 - beta: 1.0472e-04 - val_val_loss: 30616.4258 - val_val_recon_loss: 3.3267e-04 - val_val_KL loss: 279.7211 - val_beta: 1.0472e-04\n",
      "Epoch 2049/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30125.5210 - recon_loss: 3.2728e-04 - KL loss: 279.8270 - beta: 1.0472e-04 - val_val_loss: 30612.3691 - val_val_recon_loss: 3.3262e-04 - val_val_KL loss: 280.0695 - val_beta: 1.0472e-04\n",
      "Epoch 2050/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30060.8874 - recon_loss: 3.2658e-04 - KL loss: 279.6822 - beta: 1.0472e-04 - val_val_loss: 30649.7773 - val_val_recon_loss: 3.3303e-04 - val_val_KL loss: 279.5310 - val_beta: 1.0472e-04\n",
      "Epoch 2051/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30233.2036 - recon_loss: 3.2846e-04 - KL loss: 279.8579 - beta: 1.0472e-04 - val_val_loss: 30653.1250 - val_val_recon_loss: 3.3307e-04 - val_val_KL loss: 280.0855 - val_beta: 1.0472e-04\n",
      "Epoch 2052/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30199.3286 - recon_loss: 3.2809e-04 - KL loss: 280.4157 - beta: 1.0472e-04 - val_val_loss: 30608.9980 - val_val_recon_loss: 3.3259e-04 - val_val_KL loss: 279.7028 - val_beta: 1.0472e-04\n",
      "Epoch 2053/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30247.3515 - recon_loss: 3.2861e-04 - KL loss: 280.5092 - beta: 1.0472e-04 - val_val_loss: 30611.9824 - val_val_recon_loss: 3.3262e-04 - val_val_KL loss: 279.8826 - val_beta: 1.0472e-04\n",
      "Epoch 2054/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30097.0217 - recon_loss: 3.2697e-04 - KL loss: 279.6577 - beta: 1.0472e-04 - val_val_loss: 30584.1016 - val_val_recon_loss: 3.3232e-04 - val_val_KL loss: 279.3199 - val_beta: 1.0472e-04\n",
      "Epoch 2055/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30075.2650 - recon_loss: 3.2674e-04 - KL loss: 279.2801 - beta: 1.0472e-04 - val_val_loss: 30609.0273 - val_val_recon_loss: 3.3258e-04 - val_val_KL loss: 280.0982 - val_beta: 1.0472e-04\n",
      "Epoch 2056/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30437.0559 - recon_loss: 3.3069e-04 - KL loss: 281.0004 - beta: 1.0472e-04 - val_val_loss: 30640.9297 - val_val_recon_loss: 3.3293e-04 - val_val_KL loss: 280.4686 - val_beta: 1.0472e-04\n",
      "Epoch 2057/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30304.9803 - recon_loss: 3.2924e-04 - KL loss: 281.0593 - beta: 1.0472e-04 - val_val_loss: 30623.5332 - val_val_recon_loss: 3.3274e-04 - val_val_KL loss: 280.0894 - val_beta: 1.0472e-04\n",
      "Epoch 2058/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29981.4387 - recon_loss: 3.2570e-04 - KL loss: 279.7988 - beta: 1.0472e-04 - val_val_loss: 30631.8906 - val_val_recon_loss: 3.3283e-04 - val_val_KL loss: 280.6956 - val_beta: 1.0472e-04\n",
      "Epoch 2059/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 30119.0008 - recon_loss: 3.2720e-04 - KL loss: 280.9396 - beta: 1.0472e-04\n",
      "Epoch 02059: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30119.0742 - recon_loss: 3.2720e-04 - KL loss: 280.9399 - beta: 1.0472e-04 - val_val_loss: 30649.1309 - val_val_recon_loss: 3.3301e-04 - val_val_KL loss: 281.1491 - val_beta: 1.0472e-04\n",
      "Epoch 2060/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30328.9740 - recon_loss: 3.2950e-04 - KL loss: 281.1010 - beta: 1.0472e-04 - val_val_loss: 30659.6230 - val_val_recon_loss: 3.3313e-04 - val_val_KL loss: 280.9799 - val_beta: 1.0472e-04\n",
      "Epoch 2061/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30435.8036 - recon_loss: 3.3066e-04 - KL loss: 282.2059 - beta: 1.0472e-04 - val_val_loss: 30643.2383 - val_val_recon_loss: 3.3295e-04 - val_val_KL loss: 281.0012 - val_beta: 1.0472e-04\n",
      "Epoch 2062/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30303.5752 - recon_loss: 3.2921e-04 - KL loss: 281.9794 - beta: 1.0472e-04 - val_val_loss: 30635.5918 - val_val_recon_loss: 3.3286e-04 - val_val_KL loss: 281.0115 - val_beta: 1.0472e-04\n",
      "Epoch 2063/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30243.4717 - recon_loss: 3.2856e-04 - KL loss: 281.2760 - beta: 1.0472e-04 - val_val_loss: 30621.4043 - val_val_recon_loss: 3.3270e-04 - val_val_KL loss: 281.3950 - val_beta: 1.0472e-04\n",
      "Epoch 2064/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 30256.4536 - recon_loss: 3.2869e-04 - KL loss: 282.1476 - beta: 1.0472e-04\n",
      "Epoch 02064: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30256.4372 - recon_loss: 3.2869e-04 - KL loss: 282.1475 - beta: 1.0472e-04 - val_val_loss: 30618.6172 - val_val_recon_loss: 3.3267e-04 - val_val_KL loss: 281.1997 - val_beta: 1.0472e-04\n",
      "Epoch 2064/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 117191.2508 - recon_loss: 3.9610e-04 - KL loss: 301.6840 - beta: 5.8212e-05 - val_val_loss: 107085.6562 - val_val_recon_loss: 3.6177e-04 - val_val_KL loss: 327.9785 - val_beta: 5.8212e-05\n",
      "Epoch 2065/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 115231.0799 - recon_loss: 3.8929e-04 - KL loss: 351.3969 - beta: 5.8212e-05 - val_val_loss: 113293.8828 - val_val_recon_loss: 3.8263e-04 - val_val_KL loss: 380.0471 - val_beta: 5.8212e-05\n",
      "Epoch 2066/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 113387.5322 - recon_loss: 3.8294e-04 - KL loss: 382.3175 - beta: 5.8212e-05 - val_val_loss: 123392.6328 - val_val_recon_loss: 4.1677e-04 - val_val_KL loss: 404.6392 - val_beta: 5.8212e-05\n",
      "Epoch 2067/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 116484.8163 - recon_loss: 3.9341e-04 - KL loss: 388.9782 - beta: 5.8212e-05 - val_val_loss: 108313.1484 - val_val_recon_loss: 3.6591e-04 - val_val_KL loss: 332.5073 - val_beta: 5.8212e-05\n",
      "Epoch 2068/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 105935.9633 - recon_loss: 3.5786e-04 - KL loss: 330.5623 - beta: 5.8212e-05 - val_val_loss: 104567.5000 - val_val_recon_loss: 3.5321e-04 - val_val_KL loss: 334.6327 - val_beta: 5.8212e-05\n",
      "Epoch 2069/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 106011.7347 - recon_loss: 3.5812e-04 - KL loss: 330.3150 - beta: 5.8212e-05 - val_val_loss: 104636.9688 - val_val_recon_loss: 3.5344e-04 - val_val_KL loss: 337.4868 - val_beta: 5.8212e-05\n",
      "Epoch 2070/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 104215.0578 - recon_loss: 3.5200e-04 - KL loss: 339.7224 - beta: 5.8212e-05 - val_val_loss: 103714.7422 - val_val_recon_loss: 3.5030e-04 - val_val_KL loss: 340.9005 - val_beta: 5.8212e-05\n",
      "Epoch 2071/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 102999.2770 - recon_loss: 3.4787e-04 - KL loss: 342.0382 - beta: 5.8212e-05 - val_val_loss: 108187.3203 - val_val_recon_loss: 3.6538e-04 - val_val_KL loss: 362.4333 - val_beta: 5.8212e-05\n",
      "Epoch 2072/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 104690.4011 - recon_loss: 3.5354e-04 - KL loss: 359.6862 - beta: 5.8212e-05 - val_val_loss: 104852.5469 - val_val_recon_loss: 3.5416e-04 - val_val_KL loss: 339.5587 - val_beta: 5.8212e-05\n",
      "Epoch 2073/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 104934.0096 - recon_loss: 3.5440e-04 - KL loss: 349.6069 - beta: 5.8212e-05 - val_val_loss: 108650.1719 - val_val_recon_loss: 3.6689e-04 - val_val_KL loss: 379.7261 - val_beta: 5.8212e-05\n",
      "Epoch 2074/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 107086.6757 - recon_loss: 3.6164e-04 - KL loss: 368.0233 - beta: 5.8212e-05 - val_val_loss: 105983.9062 - val_val_recon_loss: 3.5794e-04 - val_val_KL loss: 356.2934 - val_beta: 5.8212e-05\n",
      "Epoch 2075/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 103620.0116 - recon_loss: 3.4996e-04 - KL loss: 347.3042 - beta: 5.8212e-05\n",
      "Epoch 02075: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 103621.4483 - recon_loss: 3.4996e-04 - KL loss: 347.2959 - beta: 5.8212e-05 - val_val_loss: 104581.1719 - val_val_recon_loss: 3.5329e-04 - val_val_KL loss: 323.9913 - val_beta: 5.8212e-05\n",
      "Epoch 2076/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 101539.3109 - recon_loss: 3.4296e-04 - KL loss: 330.4445 - beta: 5.8212e-05 - val_val_loss: 100439.7031 - val_val_recon_loss: 3.3919e-04 - val_val_KL loss: 345.4132 - val_beta: 5.8212e-05\n",
      "Epoch 2077/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 100458.6609 - recon_loss: 3.3927e-04 - KL loss: 341.3004 - beta: 5.8212e-05 - val_val_loss: 99405.2734 - val_val_recon_loss: 3.3568e-04 - val_val_KL loss: 344.7122 - val_beta: 5.8212e-05\n",
      "Epoch 2078/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 98533.4833 - recon_loss: 3.3272e-04 - KL loss: 346.4122 - beta: 5.8212e-05 - val_val_loss: 99841.8438 - val_val_recon_loss: 3.3716e-04 - val_val_KL loss: 346.8337 - val_beta: 5.8212e-05\n",
      "Epoch 2079/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 98222.5516 - recon_loss: 3.3166e-04 - KL loss: 349.3576 - beta: 5.8212e-05 - val_val_loss: 98394.5078 - val_val_recon_loss: 3.3224e-04 - val_val_KL loss: 351.3491 - val_beta: 5.8212e-05\n",
      "Epoch 2080/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 97841.6462 - recon_loss: 3.3036e-04 - KL loss: 353.0097 - beta: 5.8212e-05 - val_val_loss: 99898.2266 - val_val_recon_loss: 3.3732e-04 - val_val_KL loss: 355.8976 - val_beta: 5.8212e-05\n",
      "Epoch 2081/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 98214.5719 - recon_loss: 3.3163e-04 - KL loss: 349.9220 - beta: 5.8212e-05 - val_val_loss: 100141.5781 - val_val_recon_loss: 3.3816e-04 - val_val_KL loss: 350.5659 - val_beta: 5.8212e-05\n",
      "Epoch 2082/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 98105.5182 - recon_loss: 3.3125e-04 - KL loss: 352.7501 - beta: 5.8212e-05 - val_val_loss: 97863.4766 - val_val_recon_loss: 3.3042e-04 - val_val_KL loss: 355.4557 - val_beta: 5.8212e-05\n",
      "Epoch 2083/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96845.3386 - recon_loss: 3.2697e-04 - KL loss: 355.1516 - beta: 5.8212e-05 - val_val_loss: 98102.4922 - val_val_recon_loss: 3.3123e-04 - val_val_KL loss: 357.6984 - val_beta: 5.8212e-05\n",
      "Epoch 2084/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95757.7939 - recon_loss: 3.2328e-04 - KL loss: 357.9194 - beta: 5.8212e-05 - val_val_loss: 97901.5781 - val_val_recon_loss: 3.3053e-04 - val_val_KL loss: 363.0564 - val_beta: 5.8212e-05\n",
      "Epoch 2085/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96241.9193 - recon_loss: 3.2491e-04 - KL loss: 360.0428 - beta: 5.8212e-05 - val_val_loss: 97864.0078 - val_val_recon_loss: 3.3041e-04 - val_val_KL loss: 359.5671 - val_beta: 5.8212e-05\n",
      "Epoch 2086/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95588.4044 - recon_loss: 3.2270e-04 - KL loss: 359.9775 - beta: 5.8212e-05 - val_val_loss: 98231.1484 - val_val_recon_loss: 3.3166e-04 - val_val_KL loss: 358.3243 - val_beta: 5.8212e-05\n",
      "Epoch 2087/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 98181.9058 - recon_loss: 3.3149e-04 - KL loss: 360.7615 - beta: 5.8212e-05\n",
      "Epoch 02087: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 98182.0149 - recon_loss: 3.3149e-04 - KL loss: 360.7610 - beta: 5.8212e-05 - val_val_loss: 99801.8516 - val_val_recon_loss: 3.3699e-04 - val_val_KL loss: 355.2203 - val_beta: 5.8212e-05\n",
      "Epoch 2088/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96895.2116 - recon_loss: 3.2714e-04 - KL loss: 355.0887 - beta: 5.8212e-05 - val_val_loss: 97163.9531 - val_val_recon_loss: 3.2805e-04 - val_val_KL loss: 357.4428 - val_beta: 5.8212e-05\n",
      "Epoch 2089/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96117.5057 - recon_loss: 3.2450e-04 - KL loss: 356.5558 - beta: 5.8212e-05 - val_val_loss: 97031.2109 - val_val_recon_loss: 3.2759e-04 - val_val_KL loss: 360.8096 - val_beta: 5.8212e-05\n",
      "Epoch 2090/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95080.2107 - recon_loss: 3.2097e-04 - KL loss: 360.6213 - beta: 5.8212e-05 - val_val_loss: 96506.7891 - val_val_recon_loss: 3.2581e-04 - val_val_KL loss: 359.1034 - val_beta: 5.8212e-05\n",
      "Epoch 2091/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95351.1382 - recon_loss: 3.2190e-04 - KL loss: 359.4056 - beta: 5.8212e-05 - val_val_loss: 96822.2109 - val_val_recon_loss: 3.2688e-04 - val_val_KL loss: 359.6653 - val_beta: 5.8212e-05\n",
      "Epoch 2092/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95664.7272 - recon_loss: 3.2295e-04 - KL loss: 361.3065 - beta: 5.8212e-05 - val_val_loss: 96564.1484 - val_val_recon_loss: 3.2601e-04 - val_val_KL loss: 358.1995 - val_beta: 5.8212e-05\n",
      "Epoch 2093/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94379.0335 - recon_loss: 3.1860e-04 - KL loss: 358.7517 - beta: 5.8212e-05 - val_val_loss: 96222.3125 - val_val_recon_loss: 3.2484e-04 - val_val_KL loss: 362.3177 - val_beta: 5.8212e-05\n",
      "Epoch 2094/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94213.8730 - recon_loss: 3.1804e-04 - KL loss: 359.6091 - beta: 5.8212e-05 - val_val_loss: 96293.0938 - val_val_recon_loss: 3.2508e-04 - val_val_KL loss: 362.2961 - val_beta: 5.8212e-05\n",
      "Epoch 2095/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94120.7945 - recon_loss: 3.1772e-04 - KL loss: 362.1273 - beta: 5.8212e-05 - val_val_loss: 95912.5000 - val_val_recon_loss: 3.2379e-04 - val_val_KL loss: 363.2479 - val_beta: 5.8212e-05\n",
      "Epoch 2096/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93972.8679 - recon_loss: 3.1721e-04 - KL loss: 364.0043 - beta: 5.8212e-05 - val_val_loss: 95745.7891 - val_val_recon_loss: 3.2321e-04 - val_val_KL loss: 365.3469 - val_beta: 5.8212e-05\n",
      "Epoch 2097/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94568.5972 - recon_loss: 3.1922e-04 - KL loss: 365.5043 - beta: 5.8212e-05 - val_val_loss: 95653.6719 - val_val_recon_loss: 3.2290e-04 - val_val_KL loss: 366.3509 - val_beta: 5.8212e-05\n",
      "Epoch 2098/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93961.7348 - recon_loss: 3.1717e-04 - KL loss: 366.3301 - beta: 5.8212e-05 - val_val_loss: 95531.7188 - val_val_recon_loss: 3.2249e-04 - val_val_KL loss: 366.1293 - val_beta: 5.8212e-05\n",
      "Epoch 2099/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93968.3360 - recon_loss: 3.1718e-04 - KL loss: 367.2312 - beta: 5.8212e-05 - val_val_loss: 95558.2109 - val_val_recon_loss: 3.2256e-04 - val_val_KL loss: 371.7963 - val_beta: 5.8212e-05\n",
      "Epoch 2100/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94154.0719 - recon_loss: 3.1781e-04 - KL loss: 368.3839 - beta: 5.8212e-05 - val_val_loss: 95374.4922 - val_val_recon_loss: 3.2194e-04 - val_val_KL loss: 369.2604 - val_beta: 5.8212e-05\n",
      "Epoch 2101/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 93879.4662 - recon_loss: 3.1688e-04 - KL loss: 368.1820 - beta: 5.8212e-05 - val_val_loss: 95500.3906 - val_val_recon_loss: 3.2238e-04 - val_val_KL loss: 366.4634 - val_beta: 5.8212e-05\n",
      "Epoch 2102/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 93643.2865 - recon_loss: 3.1608e-04 - KL loss: 367.4324 - beta: 5.8212e-05 - val_val_loss: 95376.8516 - val_val_recon_loss: 3.2196e-04 - val_val_KL loss: 367.1841 - val_beta: 5.8212e-05\n",
      "Epoch 2103/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93894.8141 - recon_loss: 3.1694e-04 - KL loss: 367.0508 - beta: 5.8212e-05 - val_val_loss: 95643.7578 - val_val_recon_loss: 3.2287e-04 - val_val_KL loss: 364.1941 - val_beta: 5.8212e-05\n",
      "Epoch 2104/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 93937.7119 - recon_loss: 3.1709e-04 - KL loss: 365.5708 - beta: 5.8212e-05 - val_val_loss: 95338.1797 - val_val_recon_loss: 3.2183e-04 - val_val_KL loss: 365.2115 - val_beta: 5.8212e-05\n",
      "Epoch 2105/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 94415.6579 - recon_loss: 3.1871e-04 - KL loss: 364.6873 - beta: 5.8212e-05 - val_val_loss: 95644.6172 - val_val_recon_loss: 3.2287e-04 - val_val_KL loss: 365.0780 - val_beta: 5.8212e-05\n",
      "Epoch 2106/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94287.5554 - recon_loss: 3.1827e-04 - KL loss: 365.1880 - beta: 5.8212e-05 - val_val_loss: 95548.2969 - val_val_recon_loss: 3.2255e-04 - val_val_KL loss: 364.2859 - val_beta: 5.8212e-05\n",
      "Epoch 2107/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 93873.7091 - recon_loss: 3.1687e-04 - KL loss: 365.2401 - beta: 5.8212e-05 - val_val_loss: 95444.2891 - val_val_recon_loss: 3.2219e-04 - val_val_KL loss: 366.5944 - val_beta: 5.8212e-05\n",
      "Epoch 2108/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93718.7757 - recon_loss: 3.1635e-04 - KL loss: 365.4692 - beta: 5.8212e-05 - val_val_loss: 96129.1562 - val_val_recon_loss: 3.2451e-04 - val_val_KL loss: 366.3144 - val_beta: 5.8212e-05\n",
      "Epoch 2109/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 93978.0038 - recon_loss: 3.1722e-04 - KL loss: 365.2729 - beta: 5.8212e-05\n",
      "Epoch 02109: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93978.5206 - recon_loss: 3.1723e-04 - KL loss: 365.2728 - beta: 5.8212e-05 - val_val_loss: 96864.3672 - val_val_recon_loss: 3.2702e-04 - val_val_KL loss: 362.2935 - val_beta: 5.8212e-05\n",
      "Epoch 2110/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94807.9126 - recon_loss: 3.2004e-04 - KL loss: 363.0920 - beta: 5.8212e-05 - val_val_loss: 96303.4375 - val_val_recon_loss: 3.2511e-04 - val_val_KL loss: 362.9567 - val_beta: 5.8212e-05\n",
      "Epoch 2111/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93434.1252 - recon_loss: 3.1539e-04 - KL loss: 361.8322 - beta: 5.8212e-05 - val_val_loss: 95727.7891 - val_val_recon_loss: 3.2315e-04 - val_val_KL loss: 365.0109 - val_beta: 5.8212e-05\n",
      "Epoch 2112/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 93621.0426 - recon_loss: 3.1602e-04 - KL loss: 364.6498 - beta: 5.8212e-05 - val_val_loss: 95841.4375 - val_val_recon_loss: 3.2354e-04 - val_val_KL loss: 365.0339 - val_beta: 5.8212e-05\n",
      "Epoch 2113/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93951.9629 - recon_loss: 3.1714e-04 - KL loss: 365.3975 - beta: 5.8212e-05 - val_val_loss: 95515.9062 - val_val_recon_loss: 3.2243e-04 - val_val_KL loss: 366.5185 - val_beta: 5.8212e-05\n",
      "Epoch 2114/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 93452.7316 - recon_loss: 3.1544e-04 - KL loss: 366.2046 - beta: 5.8212e-05\n",
      "Epoch 02114: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93452.6945 - recon_loss: 3.1544e-04 - KL loss: 366.2043 - beta: 5.8212e-05 - val_val_loss: 95923.7812 - val_val_recon_loss: 3.2381e-04 - val_val_KL loss: 366.0274 - val_beta: 5.8212e-05\n",
      "Epoch 2114/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 359066.6520 - recon_loss: 3.7564e-04 - KL loss: 353.0956 - beta: 3.2360e-05 - val_val_loss: 346066.2500 - val_val_recon_loss: 3.6200e-04 - val_val_KL loss: 379.4404 - val_beta: 3.2360e-05\n",
      "Epoch 2115/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 335783.7946 - recon_loss: 3.5122e-04 - KL loss: 386.6663 - beta: 3.2360e-05 - val_val_loss: 325084.6875 - val_val_recon_loss: 3.4000e-04 - val_val_KL loss: 407.1968 - val_beta: 3.2360e-05\n",
      "Epoch 2116/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 322015.2351 - recon_loss: 3.3678e-04 - KL loss: 411.1287 - beta: 3.2360e-05 - val_val_loss: 327860.9062 - val_val_recon_loss: 3.4290e-04 - val_val_KL loss: 409.5703 - val_beta: 3.2360e-05\n",
      "Epoch 2117/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 329984.9904 - recon_loss: 3.4512e-04 - KL loss: 413.2307 - beta: 3.2360e-05 - val_val_loss: 332707.9062 - val_val_recon_loss: 3.4798e-04 - val_val_KL loss: 408.0019 - val_beta: 3.2360e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2118/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 329646.6682 - recon_loss: 3.4476e-04 - KL loss: 415.2349 - beta: 3.2360e-05 - val_val_loss: 328472.2812 - val_val_recon_loss: 3.4352e-04 - val_val_KL loss: 431.0194 - val_beta: 3.2360e-05\n",
      "Epoch 2119/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 326351.4215 - recon_loss: 3.4129e-04 - KL loss: 434.4423 - beta: 3.2360e-05 - val_val_loss: 341316.8438 - val_val_recon_loss: 3.5696e-04 - val_val_KL loss: 435.2529 - val_beta: 3.2360e-05\n",
      "Epoch 2120/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 350956.3407 - recon_loss: 3.6706e-04 - KL loss: 435.5558 - beta: 3.2360e-05\n",
      "Epoch 02120: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 350951.4731 - recon_loss: 3.6705e-04 - KL loss: 435.5540 - beta: 3.2360e-05 - val_val_loss: 333202.9062 - val_val_recon_loss: 3.4848e-04 - val_val_KL loss: 420.1148 - val_beta: 3.2360e-05\n",
      "Epoch 2121/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 319534.5661 - recon_loss: 3.3416e-04 - KL loss: 425.5896 - beta: 3.2360e-05 - val_val_loss: 317853.5938 - val_val_recon_loss: 3.3239e-04 - val_val_KL loss: 437.0301 - val_beta: 3.2360e-05\n",
      "Epoch 2122/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 315846.4285 - recon_loss: 3.3029e-04 - KL loss: 438.4383 - beta: 3.2360e-05 - val_val_loss: 318231.6250 - val_val_recon_loss: 3.3278e-04 - val_val_KL loss: 443.1169 - val_beta: 3.2360e-05\n",
      "Epoch 2123/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 314334.7643 - recon_loss: 3.2870e-04 - KL loss: 443.6060 - beta: 3.2360e-05 - val_val_loss: 319442.5312 - val_val_recon_loss: 3.3405e-04 - val_val_KL loss: 443.5701 - val_beta: 3.2360e-05\n",
      "Epoch 2124/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 316917.0635 - recon_loss: 3.3140e-04 - KL loss: 446.3227 - beta: 3.2360e-05 - val_val_loss: 315125.4062 - val_val_recon_loss: 3.2952e-04 - val_val_KL loss: 447.5217 - val_beta: 3.2360e-05\n",
      "Epoch 2125/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 312534.1966 - recon_loss: 3.2681e-04 - KL loss: 448.0160 - beta: 3.2360e-05 - val_val_loss: 312835.3438 - val_val_recon_loss: 3.2712e-04 - val_val_KL loss: 454.2769 - val_beta: 3.2360e-05\n",
      "Epoch 2126/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 309362.9093 - recon_loss: 3.2349e-04 - KL loss: 451.0533 - beta: 3.2360e-05 - val_val_loss: 316684.5000 - val_val_recon_loss: 3.3116e-04 - val_val_KL loss: 448.0499 - val_beta: 3.2360e-05\n",
      "Epoch 2127/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 311949.3590 - recon_loss: 3.2619e-04 - KL loss: 450.7587 - beta: 3.2360e-05 - val_val_loss: 313112.5625 - val_val_recon_loss: 3.2741e-04 - val_val_KL loss: 454.9582 - val_beta: 3.2360e-05\n",
      "Epoch 2128/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 309654.1173 - recon_loss: 3.2379e-04 - KL loss: 455.9985 - beta: 3.2360e-05 - val_val_loss: 313726.1875 - val_val_recon_loss: 3.2805e-04 - val_val_KL loss: 458.6643 - val_beta: 3.2360e-05\n",
      "Epoch 2129/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308700.1123 - recon_loss: 3.2279e-04 - KL loss: 455.9555 - beta: 3.2360e-05 - val_val_loss: 313896.6875 - val_val_recon_loss: 3.2823e-04 - val_val_KL loss: 454.0961 - val_beta: 3.2360e-05\n",
      "Epoch 2130/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 304946.6540 - recon_loss: 3.1886e-04 - KL loss: 454.4910 - beta: 3.2360e-05 - val_val_loss: 311579.3125 - val_val_recon_loss: 3.2580e-04 - val_val_KL loss: 457.8214 - val_beta: 3.2360e-05\n",
      "Epoch 2131/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308059.3123 - recon_loss: 3.2212e-04 - KL loss: 456.2400 - beta: 3.2360e-05 - val_val_loss: 312390.6875 - val_val_recon_loss: 3.2665e-04 - val_val_KL loss: 453.7733 - val_beta: 3.2360e-05\n",
      "Epoch 2132/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306893.2302 - recon_loss: 3.2090e-04 - KL loss: 454.2789 - beta: 3.2360e-05 - val_val_loss: 309820.9688 - val_val_recon_loss: 3.2396e-04 - val_val_KL loss: 455.8039 - val_beta: 3.2360e-05\n",
      "Epoch 2133/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308477.2076 - recon_loss: 3.2255e-04 - KL loss: 458.5766 - beta: 3.2360e-05 - val_val_loss: 312890.4062 - val_val_recon_loss: 3.2717e-04 - val_val_KL loss: 458.4325 - val_beta: 3.2360e-05\n",
      "Epoch 2134/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 309485.2606 - recon_loss: 3.2361e-04 - KL loss: 459.1542 - beta: 3.2360e-05 - val_val_loss: 313361.7188 - val_val_recon_loss: 3.2767e-04 - val_val_KL loss: 457.4814 - val_beta: 3.2360e-05\n",
      "Epoch 2135/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 306699.9852 - recon_loss: 3.2069e-04 - KL loss: 458.1481 - beta: 3.2360e-05 - val_val_loss: 312307.0625 - val_val_recon_loss: 3.2655e-04 - val_val_KL loss: 466.4692 - val_beta: 3.2360e-05\n",
      "Epoch 2136/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 304557.8867 - recon_loss: 3.1844e-04 - KL loss: 462.1513 - beta: 3.2360e-05 - val_val_loss: 311292.2812 - val_val_recon_loss: 3.2549e-04 - val_val_KL loss: 462.6033 - val_beta: 3.2360e-05\n",
      "Epoch 2137/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305650.1842 - recon_loss: 3.1959e-04 - KL loss: 460.7531 - beta: 3.2360e-05 - val_val_loss: 308733.1562 - val_val_recon_loss: 3.2282e-04 - val_val_KL loss: 461.6325 - val_beta: 3.2360e-05\n",
      "Epoch 2138/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 308831.3779 - recon_loss: 3.2292e-04 - KL loss: 460.4637 - beta: 3.2360e-05 - val_val_loss: 308103.8125 - val_val_recon_loss: 3.2216e-04 - val_val_KL loss: 460.0796 - val_beta: 3.2360e-05\n",
      "Epoch 2139/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306930.3075 - recon_loss: 3.2093e-04 - KL loss: 460.9153 - beta: 3.2360e-05 - val_val_loss: 314656.8750 - val_val_recon_loss: 3.2902e-04 - val_val_KL loss: 464.6577 - val_beta: 3.2360e-05\n",
      "Epoch 2140/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 309170.6118 - recon_loss: 3.2327e-04 - KL loss: 464.7685 - beta: 3.2360e-05 - val_val_loss: 317187.1250 - val_val_recon_loss: 3.3166e-04 - val_val_KL loss: 470.9457 - val_beta: 3.2360e-05\n",
      "Epoch 2141/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 308678.4134 - recon_loss: 3.2275e-04 - KL loss: 468.0801 - beta: 3.2360e-05 - val_val_loss: 311541.6250 - val_val_recon_loss: 3.2575e-04 - val_val_KL loss: 468.1915 - val_beta: 3.2360e-05\n",
      "Epoch 2142/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 309435.5923 - recon_loss: 3.2354e-04 - KL loss: 468.8155 - beta: 3.2360e-05 - val_val_loss: 307110.0625 - val_val_recon_loss: 3.2111e-04 - val_val_KL loss: 470.5109 - val_beta: 3.2360e-05\n",
      "Epoch 2143/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 302322.0251 - recon_loss: 3.1609e-04 - KL loss: 470.2942 - beta: 3.2360e-05 - val_val_loss: 307346.8125 - val_val_recon_loss: 3.2135e-04 - val_val_KL loss: 471.8997 - val_beta: 3.2360e-05\n",
      "Epoch 2144/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 296519.8915 - recon_loss: 3.1001e-04 - KL loss: 472.2515 - beta: 3.2360e-05 - val_val_loss: 305886.4062 - val_val_recon_loss: 3.1982e-04 - val_val_KL loss: 474.8055 - val_beta: 3.2360e-05\n",
      "Epoch 2145/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 299130.8713 - recon_loss: 3.1275e-04 - KL loss: 471.8163 - beta: 3.2360e-05 - val_val_loss: 304282.6562 - val_val_recon_loss: 3.1814e-04 - val_val_KL loss: 471.1151 - val_beta: 3.2360e-05\n",
      "Epoch 2146/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 302804.2816 - recon_loss: 3.1660e-04 - KL loss: 472.3894 - beta: 3.2360e-05 - val_val_loss: 303944.4688 - val_val_recon_loss: 3.1779e-04 - val_val_KL loss: 470.3246 - val_beta: 3.2360e-05\n",
      "Epoch 2147/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 300034.0145 - recon_loss: 3.1370e-04 - KL loss: 468.5246 - beta: 3.2360e-05 - val_val_loss: 306491.4062 - val_val_recon_loss: 3.2046e-04 - val_val_KL loss: 467.8434 - val_beta: 3.2360e-05\n",
      "Epoch 2148/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 304325.5089 - recon_loss: 3.1819e-04 - KL loss: 469.1834 - beta: 3.2360e-05 - val_val_loss: 303078.4062 - val_val_recon_loss: 3.1688e-04 - val_val_KL loss: 476.2138 - val_beta: 3.2360e-05\n",
      "Epoch 2149/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 300217.4650 - recon_loss: 3.1388e-04 - KL loss: 476.1687 - beta: 3.2360e-05 - val_val_loss: 303820.5938 - val_val_recon_loss: 3.1766e-04 - val_val_KL loss: 474.5779 - val_beta: 3.2360e-05\n",
      "Epoch 2150/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 298283.6833 - recon_loss: 3.1186e-04 - KL loss: 476.1240 - beta: 3.2360e-05 - val_val_loss: 304747.0312 - val_val_recon_loss: 3.1863e-04 - val_val_KL loss: 475.5521 - val_beta: 3.2360e-05\n",
      "Epoch 2151/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 297538.4938 - recon_loss: 3.1108e-04 - KL loss: 476.2750 - beta: 3.2360e-05 - val_val_loss: 301440.6250 - val_val_recon_loss: 3.1516e-04 - val_val_KL loss: 482.5945 - val_beta: 3.2360e-05\n",
      "Epoch 2152/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 299427.6125 - recon_loss: 3.1305e-04 - KL loss: 481.2788 - beta: 3.2360e-05 - val_val_loss: 301448.8125 - val_val_recon_loss: 3.1517e-04 - val_val_KL loss: 480.4847 - val_beta: 3.2360e-05\n",
      "Epoch 2153/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 300971.4201 - recon_loss: 3.1467e-04 - KL loss: 482.6352 - beta: 3.2360e-05 - val_val_loss: 301102.1875 - val_val_recon_loss: 3.1480e-04 - val_val_KL loss: 483.6618 - val_beta: 3.2360e-05\n",
      "Epoch 2154/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 297233.3657 - recon_loss: 3.1075e-04 - KL loss: 484.0570 - beta: 3.2360e-05 - val_val_loss: 306558.4062 - val_val_recon_loss: 3.2050e-04 - val_val_KL loss: 495.8857 - val_beta: 3.2360e-05\n",
      "Epoch 2155/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 302912.6332 - recon_loss: 3.1669e-04 - KL loss: 493.3605 - beta: 3.2360e-05 - val_val_loss: 302358.8125 - val_val_recon_loss: 3.1611e-04 - val_val_KL loss: 487.3717 - val_beta: 3.2360e-05\n",
      "Epoch 2156/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 300680.8961 - recon_loss: 3.1435e-04 - KL loss: 490.1477 - beta: 3.2360e-05 - val_val_loss: 301089.3125 - val_val_recon_loss: 3.1478e-04 - val_val_KL loss: 490.3997 - val_beta: 3.2360e-05\n",
      "Epoch 2157/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 300208.0649 - recon_loss: 3.1385e-04 - KL loss: 493.7203 - beta: 3.2360e-05 - val_val_loss: 301933.6875 - val_val_recon_loss: 3.1566e-04 - val_val_KL loss: 491.9537 - val_beta: 3.2360e-05\n",
      "Epoch 2158/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 298797.1099 - recon_loss: 3.1238e-04 - KL loss: 490.9947 - beta: 3.2360e-05 - val_val_loss: 304201.0312 - val_val_recon_loss: 3.1805e-04 - val_val_KL loss: 479.9368 - val_beta: 3.2360e-05\n",
      "Epoch 2159/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 297846.6230 - recon_loss: 3.1139e-04 - KL loss: 481.3560 - beta: 3.2360e-05 - val_val_loss: 302382.3750 - val_val_recon_loss: 3.1614e-04 - val_val_KL loss: 484.9713 - val_beta: 3.2360e-05\n",
      "Epoch 2160/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 295393.3522 - recon_loss: 3.0882e-04 - KL loss: 484.0246 - beta: 3.2360e-05 - val_val_loss: 298825.6875 - val_val_recon_loss: 3.1242e-04 - val_val_KL loss: 479.1363 - val_beta: 3.2360e-05\n",
      "Epoch 2161/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 295673.0113 - recon_loss: 3.0912e-04 - KL loss: 480.0637 - beta: 3.2360e-05 - val_val_loss: 300141.3125 - val_val_recon_loss: 3.1380e-04 - val_val_KL loss: 479.4684 - val_beta: 3.2360e-05\n",
      "Epoch 2162/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 295853.6452 - recon_loss: 3.0931e-04 - KL loss: 479.9688 - beta: 3.2360e-05 - val_val_loss: 296546.8125 - val_val_recon_loss: 3.1003e-04 - val_val_KL loss: 480.8022 - val_beta: 3.2360e-05\n",
      "Epoch 2163/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 296953.8911 - recon_loss: 3.1046e-04 - KL loss: 483.8659 - beta: 3.2360e-05 - val_val_loss: 301405.1562 - val_val_recon_loss: 3.1512e-04 - val_val_KL loss: 484.7676 - val_beta: 3.2360e-059478 - reco\n",
      "Epoch 2164/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 297385.4169 - recon_loss: 3.1091e-04 - KL loss: 487.1901 - beta: 3.2360e-05 - val_val_loss: 300322.5938 - val_val_recon_loss: 3.1398e-04 - val_val_KL loss: 489.8914 - val_beta: 3.2360e-05\n",
      "Epoch 2165/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 299075.8569 - recon_loss: 3.1268e-04 - KL loss: 486.9270 - beta: 3.2360e-05 - val_val_loss: 298036.2188 - val_val_recon_loss: 3.1159e-04 - val_val_KL loss: 485.6565 - val_beta: 3.2360e-05\n",
      "Epoch 2166/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 293441.0687 - recon_loss: 3.0678e-04 - KL loss: 485.6719 - beta: 3.2360e-05 - val_val_loss: 298010.4062 - val_val_recon_loss: 3.1156e-04 - val_val_KL loss: 485.4921 - val_beta: 3.2360e-05\n",
      "Epoch 2167/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 292210.3645 - recon_loss: 3.0549e-04 - KL loss: 482.9679 - beta: 3.2360e-05 - ETA: 1s - loss: 292200.1254 - recon_loss: 3.0548e-04 - \n",
      "Epoch 02167: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 292211.0094 - recon_loss: 3.0549e-04 - KL loss: 482.9684 - beta: 3.2360e-05 - val_val_loss: 298059.5938 - val_val_recon_loss: 3.1161e-04 - val_val_KL loss: 486.7909 - val_beta: 3.2360e-05\n",
      "Epoch 2168/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 292213.5526 - recon_loss: 3.0549e-04 - KL loss: 485.7580 - beta: 3.2360e-05 - val_val_loss: 294679.0000 - val_val_recon_loss: 3.0807e-04 - val_val_KL loss: 484.7550 - val_beta: 3.2360e-05\n",
      "Epoch 2169/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 290992.9162 - recon_loss: 3.0421e-04 - KL loss: 484.9795 - beta: 3.2360e-05 - val_val_loss: 295391.6250 - val_val_recon_loss: 3.0882e-04 - val_val_KL loss: 483.8295 - val_beta: 3.2360e-05\n",
      "Epoch 2170/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 291603.8959 - recon_loss: 3.0486e-04 - KL loss: 483.3558 - beta: 3.2360e-05 - val_val_loss: 294457.5938 - val_val_recon_loss: 3.0784e-04 - val_val_KL loss: 482.9880 - val_beta: 3.2360e-05\n",
      "Epoch 2171/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 289122.4912 - recon_loss: 3.0226e-04 - KL loss: 483.4076 - beta: 3.2360e-05 - val_val_loss: 294480.6562 - val_val_recon_loss: 3.0787e-04 - val_val_KL loss: 484.5836 - val_beta: 3.2360e-05\n",
      "Epoch 2172/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 290063.7177 - recon_loss: 3.0324e-04 - KL loss: 485.0040 - beta: 3.2360e-05 - val_val_loss: 295540.1562 - val_val_recon_loss: 3.0897e-04 - val_val_KL loss: 486.8729 - val_beta: 3.2360e-05\n",
      "Epoch 2173/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 290874.7819 - recon_loss: 3.0409e-04 - KL loss: 486.5911 - beta: 3.2360e-05 - val_val_loss: 294532.1875 - val_val_recon_loss: 3.0792e-04 - val_val_KL loss: 487.8905 - val_beta: 3.2360e-050e-04 - KL\n",
      "Epoch 2174/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 288372.2692 - recon_loss: 3.0147e-04 - KL loss: 488.7951 - beta: 3.2360e-05 - val_val_loss: 293419.3125 - val_val_recon_loss: 3.0675e-04 - val_val_KL loss: 491.2599 - val_beta: 3.2360e-05\n",
      "Epoch 2175/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 289380.3895 - recon_loss: 3.0252e-04 - KL loss: 492.1621 - beta: 3.2360e-05 - val_val_loss: 293825.7500 - val_val_recon_loss: 3.0717e-04 - val_val_KL loss: 494.6841 - val_beta: 3.2360e-05\n",
      "Epoch 2176/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 288598.5086 - recon_loss: 3.0170e-04 - KL loss: 495.5926 - beta: 3.2360e-05 - val_val_loss: 292384.4062 - val_val_recon_loss: 3.0566e-04 - val_val_KL loss: 495.9695 - val_beta: 3.2360e-05\n",
      "Epoch 2177/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 286678.3000 - recon_loss: 2.9968e-04 - KL loss: 495.4441 - beta: 3.2360e-05 - val_val_loss: 292226.7500 - val_val_recon_loss: 3.0549e-04 - val_val_KL loss: 497.3113 - val_beta: 3.2360e-05\n",
      "Epoch 2178/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 288984.5370 - recon_loss: 3.0210e-04 - KL loss: 495.7959 - beta: 3.2360e-05 - val_val_loss: 292829.2188 - val_val_recon_loss: 3.0613e-04 - val_val_KL loss: 495.0693 - val_beta: 3.2360e-05\n",
      "Epoch 2179/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 291378.1209 - recon_loss: 3.0461e-04 - KL loss: 494.2279 - beta: 3.2360e-05 - val_val_loss: 291773.7812 - val_val_recon_loss: 3.0502e-04 - val_val_KL loss: 497.2854 - val_beta: 3.2360e-05\n",
      "Epoch 2180/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 286271.2485 - recon_loss: 2.9926e-04 - KL loss: 496.2737 - beta: 3.2360e-05 - val_val_loss: 293139.0938 - val_val_recon_loss: 3.0645e-04 - val_val_KL loss: 494.5558 - val_beta: 3.2360e-05\n",
      "Epoch 2181/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 288295.7453 - recon_loss: 3.0138e-04 - KL loss: 494.4970 - beta: 3.2360e-05 - val_val_loss: 291766.7188 - val_val_recon_loss: 3.0501e-04 - val_val_KL loss: 494.0688 - val_beta: 3.2360e-05\n",
      "Epoch 2182/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 287557.0258 - recon_loss: 3.0061e-04 - KL loss: 494.1724 - beta: 3.2360e-05 - val_val_loss: 291703.0938 - val_val_recon_loss: 3.0495e-04 - val_val_KL loss: 494.8326 - val_beta: 3.2360e-05\n",
      "Epoch 2183/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 284964.1504 - recon_loss: 2.9789e-04 - KL loss: 494.1779 - beta: 3.2360e-05 - val_val_loss: 291493.4062 - val_val_recon_loss: 3.0473e-04 - val_val_KL loss: 495.1057 - val_beta: 3.2360e-05\n",
      "Epoch 2184/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 284454.1634 - recon_loss: 2.9736e-04 - KL loss: 495.3914 - beta: 3.2360e-05 - val_val_loss: 291237.7500 - val_val_recon_loss: 3.0446e-04 - val_val_KL loss: 496.4085 - val_beta: 3.2360e-05\n",
      "Epoch 2185/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 286822.4270 - recon_loss: 2.9983e-04 - KL loss: 497.8880 - beta: 3.2360e-05 - val_val_loss: 290869.8125 - val_val_recon_loss: 3.0407e-04 - val_val_KL loss: 497.8084 - val_beta: 3.2360e-05\n",
      "Epoch 2186/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 286717.7889 - recon_loss: 2.9972e-04 - KL loss: 496.8231 - beta: 3.2360e-05 - val_val_loss: 292231.2812 - val_val_recon_loss: 3.0550e-04 - val_val_KL loss: 498.5103 - val_beta: 3.2360e-05\n",
      "Epoch 2187/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 287064.8337 - recon_loss: 3.0009e-04 - KL loss: 499.1579 - beta: 3.2360e-05 - val_val_loss: 291135.9688 - val_val_recon_loss: 3.0435e-04 - val_val_KL loss: 500.4780 - val_beta: 3.2360e-05\n",
      "Epoch 2188/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 284124.1080 - recon_loss: 2.9701e-04 - KL loss: 499.8450 - beta: 3.2360e-05 - val_val_loss: 290958.2500 - val_val_recon_loss: 3.0416e-04 - val_val_KL loss: 499.8362 - val_beta: 3.2360e-05\n",
      "Epoch 2189/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 286243.6256 - recon_loss: 2.9922e-04 - KL loss: 500.1668 - beta: 3.2360e-05 - val_val_loss: 291365.9062 - val_val_recon_loss: 3.0459e-04 - val_val_KL loss: 499.8527 - val_beta: 3.2360e-05\n",
      "Epoch 2190/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 283334.2321 - recon_loss: 2.9618e-04 - KL loss: 499.9674 - beta: 3.2360e-05 - val_val_loss: 290432.7500 - val_val_recon_loss: 3.0361e-04 - val_val_KL loss: 500.5216 - val_beta: 3.2360e-05\n",
      "Epoch 2191/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 285459.0844 - recon_loss: 2.9840e-04 - KL loss: 500.8144 - beta: 3.2360e-05 - val_val_loss: 290684.3750 - val_val_recon_loss: 3.0387e-04 - val_val_KL loss: 501.4996 - val_beta: 3.2360e-05\n",
      "Epoch 2192/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 287435.8330 - recon_loss: 3.0047e-04 - KL loss: 502.3549 - beta: 3.2360e-05 - val_val_loss: 290150.0938 - val_val_recon_loss: 3.0331e-04 - val_val_KL loss: 501.9753 - val_beta: 3.2360e-05\n",
      "Epoch 2193/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 286798.6933 - recon_loss: 2.9980e-04 - KL loss: 502.4962 - beta: 3.2360e-05 - val_val_loss: 291386.5312 - val_val_recon_loss: 3.0461e-04 - val_val_KL loss: 504.6208 - val_beta: 3.2360e-05\n",
      "Epoch 2194/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 284237.6810 - recon_loss: 2.9712e-04 - KL loss: 504.9273 - beta: 3.2360e-05 - val_val_loss: 289771.4062 - val_val_recon_loss: 3.0291e-04 - val_val_KL loss: 505.9958 - val_beta: 3.2360e-05\n",
      "Epoch 2195/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 283736.0175 - recon_loss: 2.9659e-04 - KL loss: 504.6351 - beta: 3.2360e-05 - val_val_loss: 289506.4062 - val_val_recon_loss: 3.0264e-04 - val_val_KL loss: 503.4158 - val_beta: 3.2360e-05\n",
      "Epoch 2196/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 285557.0637 - recon_loss: 2.9850e-04 - KL loss: 504.0519 - beta: 3.2360e-05 - val_val_loss: 290233.2812 - val_val_recon_loss: 3.0340e-04 - val_val_KL loss: 501.1299 - val_beta: 3.2360e-05\n",
      "Epoch 2197/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 285132.0537 - recon_loss: 2.9806e-04 - KL loss: 501.2854 - beta: 3.2360e-05 - val_val_loss: 290372.6250 - val_val_recon_loss: 3.0355e-04 - val_val_KL loss: 500.4880 - val_beta: 3.2360e-05\n",
      "Epoch 2198/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 283386.6254 - recon_loss: 2.9623e-04 - KL loss: 500.8186 - beta: 3.2360e-05 - val_val_loss: 289732.1250 - val_val_recon_loss: 3.0288e-04 - val_val_KL loss: 500.2059 - val_beta: 3.2360e-05\n",
      "Epoch 2199/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 285839.3438 - recon_loss: 2.9880e-04 - KL loss: 499.1089 - beta: 3.2360e-05 - val_val_loss: 290363.7500 - val_val_recon_loss: 3.0354e-04 - val_val_KL loss: 496.4050 - val_beta: 3.2360e-05\n",
      "Epoch 2200/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 284335.0113 - recon_loss: 2.9723e-04 - KL loss: 496.7789 - beta: 3.2360e-05\n",
      "Epoch 02200: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 284335.3235 - recon_loss: 2.9723e-04 - KL loss: 496.7783 - beta: 3.2360e-05 - val_val_loss: 291152.0938 - val_val_recon_loss: 3.0437e-04 - val_val_KL loss: 495.9653 - val_beta: 3.2360e-05\n",
      "Epoch 2201/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 284475.6268 - recon_loss: 2.9738e-04 - KL loss: 496.6199 - beta: 3.2360e-05 - val_val_loss: 290532.5312 - val_val_recon_loss: 3.0372e-04 - val_val_KL loss: 495.6200 - val_beta: 3.2360e-05\n",
      "Epoch 2202/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 282923.6450 - recon_loss: 2.9575e-04 - KL loss: 495.8852 - beta: 3.2360e-05 - val_val_loss: 290492.4062 - val_val_recon_loss: 3.0368e-04 - val_val_KL loss: 496.1338 - val_beta: 3.2360e-05\n",
      "Epoch 2203/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 283592.8436 - recon_loss: 2.9645e-04 - KL loss: 495.7974 - beta: 3.2360e-05 - val_val_loss: 290217.9688 - val_val_recon_loss: 3.0339e-04 - val_val_KL loss: 497.0466 - val_beta: 3.2360e-05\n",
      "Epoch 2204/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 282864.9501 - recon_loss: 2.9569e-04 - KL loss: 497.3916 - beta: 3.2360e-05 - val_val_loss: 289969.9375 - val_val_recon_loss: 3.0313e-04 - val_val_KL loss: 495.8534 - val_beta: 3.2360e-05\n",
      "Epoch 2205/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 283872.8277 - recon_loss: 2.9675e-04 - KL loss: 495.9079 - beta: 3.2360e-05\n",
      "Epoch 02205: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 283872.7446 - recon_loss: 2.9675e-04 - KL loss: 495.9080 - beta: 3.2360e-05 - val_val_loss: 289999.5625 - val_val_recon_loss: 3.0316e-04 - val_val_KL loss: 497.0072 - val_beta: 3.2360e-05\n",
      "Epoch 2205/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1090684.9128 - recon_loss: 3.5279e-04 - KL loss: 488.6679 - beta: 1.7989e-05 - val_val_loss: 1033352.5000 - val_val_recon_loss: 3.3422e-04 - val_val_KL loss: 533.4770 - val_beta: 1.7989e-05\n",
      "Epoch 2206/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 1019621.0883 - recon_loss: 3.2978e-04 - KL loss: 528.1897 - beta: 1.7989e-05 - val_val_loss: 1009307.4375 - val_val_recon_loss: 3.2644e-04 - val_val_KL loss: 540.7252 - val_beta: 1.7989e-05\n",
      "Epoch 2207/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1044578.5947 - recon_loss: 3.3786e-04 - KL loss: 527.9650 - beta: 1.7989e-05 - val_val_loss: 1021977.1875 - val_val_recon_loss: 3.3054e-04 - val_val_KL loss: 529.0657 - val_beta: 1.7989e-05\n",
      "Epoch 2208/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1002986.3747 - recon_loss: 3.2440e-04 - KL loss: 528.4498 - beta: 1.7989e-05 - val_val_loss: 1042929.1250 - val_val_recon_loss: 3.3732e-04 - val_val_KL loss: 529.4520 - val_beta: 1.7989e-05\n",
      "Epoch 2209/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1004210.2532 - recon_loss: 3.2479e-04 - KL loss: 533.2699 - beta: 1.7989e-05 - val_val_loss: 1048495.8125 - val_val_recon_loss: 3.3912e-04 - val_val_KL loss: 553.1553 - val_beta: 1.7989e-05\n",
      "Epoch 2210/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1008516.3899 - recon_loss: 3.2618e-04 - KL loss: 553.3757 - beta: 1.7989e-05 - val_val_loss: 1039932.5000 - val_val_recon_loss: 3.3634e-04 - val_val_KL loss: 561.9996 - val_beta: 1.7989e-05\n",
      "Epoch 2211/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1013590.6860 - recon_loss: 3.2782e-04 - KL loss: 558.6290 - beta: 1.7989e-05 - val_val_loss: 983016.6250 - val_val_recon_loss: 3.1792e-04 - val_val_KL loss: 562.5328 - val_beta: 1.7989e-05\n",
      "Epoch 2212/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 996740.1241 - recon_loss: 3.2236e-04 - KL loss: 566.7405 - beta: 1.7989e-05 - val_val_loss: 1003609.6875 - val_val_recon_loss: 3.2459e-04 - val_val_KL loss: 563.0518 - val_beta: 1.7989e-05\n",
      "Epoch 2213/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 985045.6173 - recon_loss: 3.1858e-04 - KL loss: 564.0429 - beta: 1.7989e-05 - val_val_loss: 987941.9375 - val_val_recon_loss: 3.1952e-04 - val_val_KL loss: 558.8907 - val_beta: 1.7989e-05\n",
      "Epoch 2214/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 995340.8605 - recon_loss: 3.2191e-04 - KL loss: 564.1654 - beta: 1.7989e-05 - val_val_loss: 1002543.4375 - val_val_recon_loss: 3.2424e-04 - val_val_KL loss: 573.0952 - val_beta: 1.7989e-05\n",
      "Epoch 2215/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 1015710.3038 - recon_loss: 3.2850e-04 - KL loss: 566.5831 - beta: 1.7989e-05 - val_val_loss: 1008812.6250 - val_val_recon_loss: 3.2627e-04 - val_val_KL loss: 574.8701 - val_beta: 1.7989e-05\n",
      "Epoch 2216/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1003302.8702 - recon_loss: 3.2448e-04 - KL loss: 574.8552 - beta: 1.7989e-05\n",
      "Epoch 02216: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1003306.6139 - recon_loss: 3.2449e-04 - KL loss: 574.8562 - beta: 1.7989e-05 - val_val_loss: 992789.5000 - val_val_recon_loss: 3.2108e-04 - val_val_KL loss: 582.9706 - val_beta: 1.7989e-05\n",
      "Epoch 2217/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 952699.2065 - recon_loss: 3.0811e-04 - KL loss: 584.6639 - beta: 1.7989e-05 - val_val_loss: 950994.3125 - val_val_recon_loss: 3.0755e-04 - val_val_KL loss: 585.2320 - val_beta: 1.7989e-05\n",
      "Epoch 2218/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 947722.1453 - recon_loss: 3.0649e-04 - KL loss: 587.4998 - beta: 1.7989e-05 - val_val_loss: 953933.8125 - val_val_recon_loss: 3.0850e-04 - val_val_KL loss: 594.0423 - val_beta: 1.7989e-05\n",
      "Epoch 2219/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 951493.0688 - recon_loss: 3.0771e-04 - KL loss: 594.8605 - beta: 1.7989e-05 - val_val_loss: 955169.4375 - val_val_recon_loss: 3.0890e-04 - val_val_KL loss: 594.4808 - val_beta: 1.7989e-05\n",
      "Epoch 2220/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 953074.1742 - recon_loss: 3.0822e-04 - KL loss: 594.3478 - beta: 1.7989e-05 - val_val_loss: 953468.2500 - val_val_recon_loss: 3.0835e-04 - val_val_KL loss: 593.3464 - val_beta: 1.7989e-05\n",
      "Epoch 2221/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 948820.2522 - recon_loss: 3.0685e-04 - KL loss: 595.2399 - beta: 1.7989e-05 - val_val_loss: 947406.9375 - val_val_recon_loss: 3.0639e-04 - val_val_KL loss: 596.5862 - val_beta: 1.7989e-05\n",
      "Epoch 2222/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 949346.8272 - recon_loss: 3.0702e-04 - KL loss: 598.2038 - beta: 1.7989e-05 - val_val_loss: 943431.7500 - val_val_recon_loss: 3.0510e-04 - val_val_KL loss: 603.0574 - val_beta: 1.7989e-05\n",
      "Epoch 2223/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 939447.7182 - recon_loss: 3.0381e-04 - KL loss: 605.4089 - beta: 1.7989e-05 - val_val_loss: 950574.7500 - val_val_recon_loss: 3.0741e-04 - val_val_KL loss: 603.5151 - val_beta: 1.7989e-05\n",
      "Epoch 2224/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 953696.4650 - recon_loss: 3.0842e-04 - KL loss: 613.8319 - beta: 1.7989e-05 - val_val_loss: 956236.3750 - val_val_recon_loss: 3.0924e-04 - val_val_KL loss: 610.6609 - val_beta: 1.7989e-05\n",
      "Epoch 2225/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 949275.9758 - recon_loss: 3.0699e-04 - KL loss: 613.9958 - beta: 1.7989e-05 - val_val_loss: 946964.9375 - val_val_recon_loss: 3.0624e-04 - val_val_KL loss: 608.7277 - val_beta: 1.7989e-05\n",
      "Epoch 2226/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 943826.4063 - recon_loss: 3.0523e-04 - KL loss: 609.2382 - beta: 1.7989e-05 - val_val_loss: 941520.1875 - val_val_recon_loss: 3.0448e-04 - val_val_KL loss: 604.8860 - val_beta: 1.7989e-05\n",
      "Epoch 2227/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 928186.2053 - recon_loss: 3.0017e-04 - KL loss: 603.6678 - beta: 1.7989e-05 - val_val_loss: 938021.3750 - val_val_recon_loss: 3.0335e-04 - val_val_KL loss: 606.3466 - val_beta: 1.7989e-05\n",
      "Epoch 2228/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 921510.3959 - recon_loss: 2.9801e-04 - KL loss: 604.7958 - beta: 1.7989e-05 - val_val_loss: 938168.0000 - val_val_recon_loss: 3.0340e-04 - val_val_KL loss: 604.5085 - val_beta: 1.7989e-05\n",
      "Epoch 2229/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 935805.6502 - recon_loss: 3.0263e-04 - KL loss: 604.7817 - beta: 1.7989e-05 - val_val_loss: 928872.6250 - val_val_recon_loss: 3.0039e-04 - val_val_KL loss: 606.5671 - val_beta: 1.7989e-05\n",
      "Epoch 2230/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 923027.7782 - recon_loss: 2.9849e-04 - KL loss: 612.3331 - beta: 1.7989e-05 - val_val_loss: 944811.5000 - val_val_recon_loss: 3.0554e-04 - val_val_KL loss: 616.0114 - val_beta: 1.7989e-05\n",
      "Epoch 2231/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 931277.3309 - recon_loss: 3.0116e-04 - KL loss: 614.5239 - beta: 1.7989e-05 - val_val_loss: 931505.1250 - val_val_recon_loss: 3.0124e-04 - val_val_KL loss: 610.5760 - val_beta: 1.7989e-05\n",
      "Epoch 2232/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 913876.7624 - recon_loss: 2.9553e-04 - KL loss: 609.6064 - beta: 1.7989e-05 - val_val_loss: 933840.5000 - val_val_recon_loss: 3.0200e-04 - val_val_KL loss: 606.2501 - val_beta: 1.7989e-05\n",
      "Epoch 2233/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 924717.7646 - recon_loss: 2.9904e-04 - KL loss: 609.5976 - beta: 1.7989e-05 - val_val_loss: 930127.1250 - val_val_recon_loss: 3.0079e-04 - val_val_KL loss: 607.1639 - val_beta: 1.7989e-05\n",
      "Epoch 2234/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 923584.0104 - recon_loss: 2.9868e-04 - KL loss: 608.8556 - beta: 1.7989e-05 - val_val_loss: 927909.5000 - val_val_recon_loss: 3.0008e-04 - val_val_KL loss: 609.3643 - val_beta: 1.7989e-05\n",
      "Epoch 2235/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 918239.7140 - recon_loss: 2.9695e-04 - KL loss: 610.3550 - beta: 1.7989e-05 - val_val_loss: 919439.8125 - val_val_recon_loss: 2.9733e-04 - val_val_KL loss: 611.2357 - val_beta: 1.7989e-05\n",
      "Epoch 2236/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 908013.2912 - recon_loss: 2.9364e-04 - KL loss: 610.5666 - beta: 1.7989e-05 - val_val_loss: 918596.5000 - val_val_recon_loss: 2.9706e-04 - val_val_KL loss: 606.7784 - val_beta: 1.7989e-05\n",
      "Epoch 2237/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 915581.3378 - recon_loss: 2.9609e-04 - KL loss: 603.7273 - beta: 1.7989e-05 - val_val_loss: 920839.0625 - val_val_recon_loss: 2.9779e-04 - val_val_KL loss: 604.5983 - val_beta: 1.7989e-05\n",
      "Epoch 2238/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 908150.5225 - recon_loss: 2.9368e-04 - KL loss: 603.7102 - beta: 1.7989e-05 - val_val_loss: 921828.0625 - val_val_recon_loss: 2.9811e-04 - val_val_KL loss: 606.2049 - val_beta: 1.7989e-05\n",
      "Epoch 2239/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 917439.4897 - recon_loss: 2.9669e-04 - KL loss: 603.8341 - beta: 1.7989e-05 - val_val_loss: 919907.6875 - val_val_recon_loss: 2.9749e-04 - val_val_KL loss: 605.9593 - val_beta: 1.7989e-05\n",
      "Epoch 2240/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 909561.9002 - recon_loss: 2.9414e-04 - KL loss: 605.2660 - beta: 1.7989e-05 - val_val_loss: 920512.2500 - val_val_recon_loss: 2.9768e-04 - val_val_KL loss: 605.1206 - val_beta: 1.7989e-05\n",
      "Epoch 2241/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 907468.2742 - recon_loss: 2.9346e-04 - KL loss: 604.6469 - beta: 1.7989e-05\n",
      "Epoch 02241: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 907470.0004 - recon_loss: 2.9346e-04 - KL loss: 604.6460 - beta: 1.7989e-05 - val_val_loss: 919615.6875 - val_val_recon_loss: 2.9739e-04 - val_val_KL loss: 603.0120 - val_beta: 1.7989e-05\n",
      "Epoch 2242/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 885179.1962 - recon_loss: 2.8625e-04 - KL loss: 601.2820 - beta: 1.7989e-05 - val_val_loss: 905900.5000 - val_val_recon_loss: 2.9296e-04 - val_val_KL loss: 603.4515 - val_beta: 1.7989e-05\n",
      "Epoch 2243/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 893602.3232 - recon_loss: 2.8898e-04 - KL loss: 603.7198 - beta: 1.7989e-05 - val_val_loss: 905520.2500 - val_val_recon_loss: 2.9283e-04 - val_val_KL loss: 604.6606 - val_beta: 1.7989e-05\n",
      "Epoch 2244/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 891877.4037 - recon_loss: 2.8842e-04 - KL loss: 603.9590 - beta: 1.7989e-05 - val_val_loss: 905419.8125 - val_val_recon_loss: 2.9280e-04 - val_val_KL loss: 605.4501 - val_beta: 1.7989e-05\n",
      "Epoch 2245/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 895295.5914 - recon_loss: 2.8952e-04 - KL loss: 604.3325 - beta: 1.7989e-05 - val_val_loss: 907949.4375 - val_val_recon_loss: 2.9362e-04 - val_val_KL loss: 607.7219 - val_beta: 1.7989e-05\n",
      "Epoch 2246/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 895001.0576 - recon_loss: 2.8943e-04 - KL loss: 608.0324 - beta: 1.7989e-05 - val_val_loss: 907335.0625 - val_val_recon_loss: 2.9342e-04 - val_val_KL loss: 607.2711 - val_beta: 1.7989e-05\n",
      "Epoch 2247/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 895520.2086 - recon_loss: 2.8959e-04 - KL loss: 607.9294 - beta: 1.7989e-05 - val_val_loss: 907705.7500 - val_val_recon_loss: 2.9354e-04 - val_val_KL loss: 609.5842 - val_beta: 1.7989e-05\n",
      "Epoch 2248/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 900368.7401 - recon_loss: 2.9116e-04 - KL loss: 609.6456 - beta: 1.7989e-05 - val_val_loss: 907093.9375 - val_val_recon_loss: 2.9334e-04 - val_val_KL loss: 608.5615 - val_beta: 1.7989e-05\n",
      "Epoch 2249/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 890869.6713 - recon_loss: 2.8809e-04 - KL loss: 610.2617 - beta: 1.7989e-05\n",
      "Epoch 02249: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 890871.2903 - recon_loss: 2.8809e-04 - KL loss: 610.2618 - beta: 1.7989e-05 - val_val_loss: 907203.1875 - val_val_recon_loss: 2.9337e-04 - val_val_KL loss: 609.7665 - val_beta: 1.7989e-05\n",
      "Epoch 2250/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 882817.8706 - recon_loss: 2.8548e-04 - KL loss: 610.4834 - beta: 1.7989e-05 - val_val_loss: 903687.5000 - val_val_recon_loss: 2.9224e-04 - val_val_KL loss: 609.9137 - val_beta: 1.7989e-05\n",
      "Epoch 2251/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 892869.7930 - recon_loss: 2.8874e-04 - KL loss: 609.9734 - beta: 1.7989e-05 - val_val_loss: 902280.8125 - val_val_recon_loss: 2.9178e-04 - val_val_KL loss: 610.0922 - val_beta: 1.7989e-05\n",
      "Epoch 2252/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 888910.4191 - recon_loss: 2.8745e-04 - KL loss: 611.0091 - beta: 1.7989e-05 - val_val_loss: 901326.6250 - val_val_recon_loss: 2.9147e-04 - val_val_KL loss: 610.6022 - val_beta: 1.7989e-05\n",
      "Epoch 2253/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 890155.4030 - recon_loss: 2.8786e-04 - KL loss: 609.9363 - beta: 1.7989e-05 - val_val_loss: 899942.2500 - val_val_recon_loss: 2.9103e-04 - val_val_KL loss: 610.2921 - val_beta: 1.7989e-05\n",
      "Epoch 2254/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 887316.3976 - recon_loss: 2.8694e-04 - KL loss: 611.0362 - beta: 1.7989e-05 - val_val_loss: 900586.5000 - val_val_recon_loss: 2.9123e-04 - val_val_KL loss: 610.7922 - val_beta: 1.7989e-05\n",
      "Epoch 2255/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 883920.6802 - recon_loss: 2.8584e-04 - KL loss: 610.9898 - beta: 1.7989e-05 - val_val_loss: 901519.2500 - val_val_recon_loss: 2.9154e-04 - val_val_KL loss: 610.9030 - val_beta: 1.7989e-05\n",
      "Epoch 2256/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 891948.0393 - recon_loss: 2.8844e-04 - KL loss: 610.7511 - beta: 1.7989e-05 - val_val_loss: 900902.6250 - val_val_recon_loss: 2.9134e-04 - val_val_KL loss: 611.7466 - val_beta: 1.7989e-05\n",
      "Epoch 2257/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 884873.2982 - recon_loss: 2.8615e-04 - KL loss: 610.3313 - beta: 1.7989e-05 - val_val_loss: 901715.6875 - val_val_recon_loss: 2.9160e-04 - val_val_KL loss: 611.4840 - val_beta: 1.7989e-05\n",
      "Epoch 2258/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 889297.1667 - recon_loss: 2.8758e-04 - KL loss: 612.0259 - beta: 1.7989e-05\n",
      "Epoch 02258: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 889294.6261 - recon_loss: 2.8758e-04 - KL loss: 612.0253 - beta: 1.7989e-05 - val_val_loss: 900191.6875 - val_val_recon_loss: 2.9111e-04 - val_val_KL loss: 611.8738 - val_beta: 1.7989e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2259/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 882412.8659 - recon_loss: 2.8535e-04 - KL loss: 611.7063 - beta: 1.7989e-05 - val_val_loss: 899735.9375 - val_val_recon_loss: 2.9096e-04 - val_val_KL loss: 611.9022 - val_beta: 1.7989e-05\n",
      "Epoch 2260/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 884381.7954 - recon_loss: 2.8599e-04 - KL loss: 610.3818 - beta: 1.7989e-05 - val_val_loss: 899912.7500 - val_val_recon_loss: 2.9101e-04 - val_val_KL loss: 612.3926 - val_beta: 1.7989e-05\n",
      "Epoch 2261/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 886747.4387 - recon_loss: 2.8675e-04 - KL loss: 611.3628 - beta: 1.7989e-05 - val_val_loss: 899546.5000 - val_val_recon_loss: 2.9090e-04 - val_val_KL loss: 612.1264 - val_beta: 1.7989e-05\n",
      "Epoch 2262/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 880006.6916 - recon_loss: 2.8457e-04 - KL loss: 612.2947 - beta: 1.7989e-05 - val_val_loss: 899541.0625 - val_val_recon_loss: 2.9089e-04 - val_val_KL loss: 612.1406 - val_beta: 1.7989e-05\n",
      "Epoch 2263/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 882024.5503 - recon_loss: 2.8523e-04 - KL loss: 612.5431 - beta: 1.7989e-05 - val_val_loss: 899358.6250 - val_val_recon_loss: 2.9084e-04 - val_val_KL loss: 612.1058 - val_beta: 1.7989e-05\n",
      "Epoch 2264/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 878161.9389 - recon_loss: 2.8398e-04 - KL loss: 611.7391 - beta: 1.7989e-05 - val_val_loss: 899121.6250 - val_val_recon_loss: 2.9076e-04 - val_val_KL loss: 612.2088 - val_beta: 1.7989e-05\n",
      "Epoch 2265/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 880395.2635 - recon_loss: 2.8470e-04 - KL loss: 611.7982 - beta: 1.7989e-05 - val_val_loss: 898814.8125 - val_val_recon_loss: 2.9066e-04 - val_val_KL loss: 613.2258 - val_beta: 1.7989e-05\n",
      "Epoch 2266/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 877976.0125 - recon_loss: 2.8392e-04 - KL loss: 612.3995 - beta: 1.7989e-05 - val_val_loss: 898678.6250 - val_val_recon_loss: 2.9062e-04 - val_val_KL loss: 612.3552 - val_beta: 1.7989e-05\n",
      "Epoch 2267/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 894065.7962 - recon_loss: 2.8912e-04 - KL loss: 613.7254 - beta: 1.7989e-05 - val_val_loss: 899792.7500 - val_val_recon_loss: 2.9098e-04 - val_val_KL loss: 612.7365 - val_beta: 1.7989e-05\n",
      "Epoch 2268/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 885059.7617 - recon_loss: 2.8621e-04 - KL loss: 612.2762 - beta: 1.7989e-05 - val_val_loss: 899188.1875 - val_val_recon_loss: 2.9078e-04 - val_val_KL loss: 613.0644 - val_beta: 1.7989e-05\n",
      "Epoch 2269/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 880036.1098 - recon_loss: 2.8458e-04 - KL loss: 612.0495 - beta: 1.7989e-05 - val_val_loss: 898614.6250 - val_val_recon_loss: 2.9059e-04 - val_val_KL loss: 613.1782 - val_beta: 1.7989e-05\n",
      "Epoch 2270/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 881253.8496 - recon_loss: 2.8498e-04 - KL loss: 612.9330 - beta: 1.7989e-05 - val_val_loss: 899258.0000 - val_val_recon_loss: 2.9080e-04 - val_val_KL loss: 613.0161 - val_beta: 1.7989e-05\n",
      "Epoch 2271/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 886654.3210 - recon_loss: 2.8672e-04 - KL loss: 613.5482 - beta: 1.7989e-05 - val_val_loss: 898149.2500 - val_val_recon_loss: 2.9044e-04 - val_val_KL loss: 613.5090 - val_beta: 1.7989e-05\n",
      "Epoch 2272/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 886576.9146 - recon_loss: 2.8670e-04 - KL loss: 612.8332 - beta: 1.7989e-05 - val_val_loss: 899800.6250 - val_val_recon_loss: 2.9098e-04 - val_val_KL loss: 613.3920 - val_beta: 1.7989e-05\n",
      "Epoch 2273/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 882324.2304 - recon_loss: 2.8532e-04 - KL loss: 612.8155 - beta: 1.7989e-05 - val_val_loss: 899319.6250 - val_val_recon_loss: 2.9082e-04 - val_val_KL loss: 613.5240 - val_beta: 1.7989e-05\n",
      "Epoch 2274/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 884895.4500 - recon_loss: 2.8615e-04 - KL loss: 613.4249 - beta: 1.7989e-05 - val_val_loss: 898706.8750 - val_val_recon_loss: 2.9062e-04 - val_val_KL loss: 613.3112 - val_beta: 1.7989e-05\n",
      "Epoch 2275/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 888976.6612 - recon_loss: 2.8748e-04 - KL loss: 613.9163 - beta: 1.7989e-05 - val_val_loss: 898212.1875 - val_val_recon_loss: 2.9046e-04 - val_val_KL loss: 613.3937 - val_beta: 1.7989e-05\n",
      "Epoch 2276/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 880417.2257 - recon_loss: 2.8471e-04 - KL loss: 612.2370 - beta: 1.7989e-05 - val_val_loss: 897951.1250 - val_val_recon_loss: 2.9038e-04 - val_val_KL loss: 613.8203 - val_beta: 1.7989e-05\n",
      "Epoch 2277/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 879363.6677 - recon_loss: 2.8437e-04 - KL loss: 613.0236 - beta: 1.7989e-05 - val_val_loss: 898607.2500 - val_val_recon_loss: 2.9059e-04 - val_val_KL loss: 614.3041 - val_beta: 1.7989e-05\n",
      "Epoch 2278/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 873472.1625 - recon_loss: 2.8246e-04 - KL loss: 613.8167 - beta: 1.7989e-05 - val_val_loss: 898644.7500 - val_val_recon_loss: 2.9060e-04 - val_val_KL loss: 614.5125 - val_beta: 1.7989e-05\n",
      "Epoch 2279/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 891041.6204 - recon_loss: 2.8814e-04 - KL loss: 614.6717 - beta: 1.7989e-05 - val_val_loss: 898791.7500 - val_val_recon_loss: 2.9065e-04 - val_val_KL loss: 614.1768 - val_beta: 1.7989e-05\n",
      "Epoch 2280/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 884006.8167 - recon_loss: 2.8587e-04 - KL loss: 613.9153 - beta: 1.7989e-05 - val_val_loss: 898326.8125 - val_val_recon_loss: 2.9050e-04 - val_val_KL loss: 614.3057 - val_beta: 1.7989e-05\n",
      "Epoch 2281/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 881616.1252 - recon_loss: 2.8509e-04 - KL loss: 613.9495 - beta: 1.7989e-05\n",
      "Epoch 02281: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 881614.6361 - recon_loss: 2.8509e-04 - KL loss: 613.9496 - beta: 1.7989e-05 - val_val_loss: 898452.7500 - val_val_recon_loss: 2.9054e-04 - val_val_KL loss: 614.5393 - val_beta: 1.7989e-05\n",
      "Epoch 2282/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 898146.6053 - recon_loss: 2.9044e-04 - KL loss: 614.5140 - beta: 1.7989e-05 - val_val_loss: 898587.5000 - val_val_recon_loss: 2.9059e-04 - val_val_KL loss: 614.6011 - val_beta: 1.7989e-05\n",
      "Epoch 2283/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 874273.2589 - recon_loss: 2.8272e-04 - KL loss: 614.0492 - beta: 1.7989e-05 - val_val_loss: 898540.5625 - val_val_recon_loss: 2.9057e-04 - val_val_KL loss: 614.6328 - val_beta: 1.7989e-05\n",
      "Epoch 2284/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 871277.8339 - recon_loss: 2.8175e-04 - KL loss: 615.1159 - beta: 1.7989e-05 - val_val_loss: 898435.7500 - val_val_recon_loss: 2.9054e-04 - val_val_KL loss: 614.7710 - val_beta: 1.7989e-05\n",
      "Epoch 2285/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 883145.3647 - recon_loss: 2.8559e-04 - KL loss: 614.2921 - beta: 1.7989e-05 - val_val_loss: 898199.1875 - val_val_recon_loss: 2.9046e-04 - val_val_KL loss: 614.7738 - val_beta: 1.7989e-05\n",
      "Epoch 2286/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 883939.1487 - recon_loss: 2.8585e-04 - KL loss: 613.9068 - beta: 1.7989e-05 - val_val_loss: 897791.9375 - val_val_recon_loss: 2.9033e-04 - val_val_KL loss: 614.7870 - val_beta: 1.7989e-05\n",
      "Epoch 2287/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 886709.3426 - recon_loss: 2.8674e-04 - KL loss: 615.2498 - beta: 1.7989e-05 - val_val_loss: 898425.1250 - val_val_recon_loss: 2.9053e-04 - val_val_KL loss: 614.9612 - val_beta: 1.7989e-05\n",
      "Epoch 2288/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 878401.5694 - recon_loss: 2.8405e-04 - KL loss: 614.8378 - beta: 1.7989e-05 - val_val_loss: 898284.7500 - val_val_recon_loss: 2.9049e-04 - val_val_KL loss: 614.8737 - val_beta: 1.7989e-05\n",
      "Epoch 2289/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 881975.0162 - recon_loss: 2.8521e-04 - KL loss: 614.3368 - beta: 1.7989e-05 - val_val_loss: 898151.1875 - val_val_recon_loss: 2.9044e-04 - val_val_KL loss: 614.8562 - val_beta: 1.7989e-05\n",
      "Epoch 2290/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 891833.3118 - recon_loss: 2.8840e-04 - KL loss: 613.9460 - beta: 1.7989e-05 - val_val_loss: 898537.6875 - val_val_recon_loss: 2.9057e-04 - val_val_KL loss: 614.9637 - val_beta: 1.7989e-05\n",
      "Epoch 2291/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 877426.4106 - recon_loss: 2.8374e-04 - KL loss: 615.1955 - beta: 1.7989e-05\n",
      "Epoch 02291: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877426.8922 - recon_loss: 2.8374e-04 - KL loss: 615.1953 - beta: 1.7989e-05 - val_val_loss: 898175.5000 - val_val_recon_loss: 2.9045e-04 - val_val_KL loss: 615.0010 - val_beta: 1.7989e-05\n",
      "Epoch 2292/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 883877.9698 - recon_loss: 2.8583e-04 - KL loss: 614.3421 - beta: 1.7989e-05 - val_val_loss: 897995.5000 - val_val_recon_loss: 2.9039e-04 - val_val_KL loss: 615.0605 - val_beta: 1.7989e-05\n",
      "Epoch 2293/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 869384.7732 - recon_loss: 2.8114e-04 - KL loss: 614.7287 - beta: 1.7989e-05 - val_val_loss: 898096.0625 - val_val_recon_loss: 2.9043e-04 - val_val_KL loss: 615.0485 - val_beta: 1.7989e-05\n",
      "Epoch 2294/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877058.0891 - recon_loss: 2.8362e-04 - KL loss: 614.7723 - beta: 1.7989e-05 - val_val_loss: 898487.8125 - val_val_recon_loss: 2.9055e-04 - val_val_KL loss: 615.0436 - val_beta: 1.7989e-05\n",
      "Epoch 2295/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 873848.9955 - recon_loss: 2.8258e-04 - KL loss: 614.2632 - beta: 1.7989e-05 - val_val_loss: 898401.1875 - val_val_recon_loss: 2.9052e-04 - val_val_KL loss: 615.0604 - val_beta: 1.7989e-05\n",
      "Epoch 2296/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 877759.9852 - recon_loss: 2.8385e-04 - KL loss: 613.6181 - beta: 1.7989e-05\n",
      "Epoch 02296: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877759.8523 - recon_loss: 2.8385e-04 - KL loss: 613.6188 - beta: 1.7989e-05 - val_val_loss: 898145.0625 - val_val_recon_loss: 2.9044e-04 - val_val_KL loss: 615.0303 - val_beta: 1.7989e-05\n",
      "Epoch 2296/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3454970.8427 - recon_loss: 3.4544e-04 - KL loss: 603.0506 - beta: 1.0000e-05 - val_val_loss: 3213510.5000 - val_val_recon_loss: 3.2129e-04 - val_val_KL loss: 618.5917 - val_beta: 1.0000e-05\n",
      "Epoch 2297/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3169530.9166 - recon_loss: 3.1689e-04 - KL loss: 628.4295 - beta: 1.0000e-05 - val_val_loss: 3296051.2500 - val_val_recon_loss: 3.2954e-04 - val_val_KL loss: 652.2473 - val_beta: 1.0000e-05\n",
      "Epoch 2298/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3222458.7435 - recon_loss: 3.2218e-04 - KL loss: 639.9225 - beta: 1.0000e-05 - val_val_loss: 3149541.5000 - val_val_recon_loss: 3.1489e-04 - val_val_KL loss: 638.7961 - val_beta: 1.0000e-05\n",
      "Epoch 2299/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3092989.6751 - recon_loss: 3.0924e-04 - KL loss: 636.4006 - beta: 1.0000e-05 - val_val_loss: 3120829.0000 - val_val_recon_loss: 3.1202e-04 - val_val_KL loss: 635.0659 - val_beta: 1.0000e-05\n",
      "Epoch 2300/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3102001.5020 - recon_loss: 3.1014e-04 - KL loss: 629.5608 - beta: 1.0000e-05 - val_val_loss: 3098571.5000 - val_val_recon_loss: 3.0979e-04 - val_val_KL loss: 636.4141 - val_beta: 1.0000e-05\n",
      "Epoch 2301/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3077015.6778 - recon_loss: 3.0764e-04 - KL loss: 635.0210 - beta: 1.0000e-05 - val_val_loss: 3253201.0000 - val_val_recon_loss: 3.2525e-04 - val_val_KL loss: 675.1694 - val_beta: 1.0000e-05\n",
      "Epoch 2302/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3155347.9895 - recon_loss: 3.1547e-04 - KL loss: 664.1638 - beta: 1.0000e-05 - val_val_loss: 3078380.2500 - val_val_recon_loss: 3.0777e-04 - val_val_KL loss: 647.4334 - val_beta: 1.0000e-05\n",
      "Epoch 2303/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3107777.9630 - recon_loss: 3.1071e-04 - KL loss: 648.4314 - beta: 1.0000e-05 - val_val_loss: 3188648.2500 - val_val_recon_loss: 3.1880e-04 - val_val_KL loss: 649.5064 - val_beta: 1.0000e-05\n",
      "Epoch 2304/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3152900.9770 - recon_loss: 3.1522e-04 - KL loss: 654.7722 - beta: 1.0000e-05 - val_val_loss: 3164033.5000 - val_val_recon_loss: 3.1634e-04 - val_val_KL loss: 666.2888 - val_beta: 1.0000e-05\n",
      "Epoch 2305/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3147491.4555 - recon_loss: 3.1468e-04 - KL loss: 671.8888 - beta: 1.0000e-05 - val_val_loss: 3231585.0000 - val_val_recon_loss: 3.2309e-04 - val_val_KL loss: 688.1216 - val_beta: 1.0000e-05\n",
      "Epoch 2306/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3229714.2590 - recon_loss: 3.2290e-04 - KL loss: 691.5973 - beta: 1.0000e-05 - val_val_loss: 3215420.2500 - val_val_recon_loss: 3.2147e-04 - val_val_KL loss: 706.8363 - val_beta: 1.0000e-05\n",
      "Epoch 2307/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3178627.5360 - recon_loss: 3.1779e-04 - KL loss: 708.2388 - beta: 1.0000e-05\n",
      "Epoch 02307: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3178625.7905 - recon_loss: 3.1779e-04 - KL loss: 708.2379 - beta: 1.0000e-05 - val_val_loss: 3183478.5000 - val_val_recon_loss: 3.1828e-04 - val_val_KL loss: 704.8354 - val_beta: 1.0000e-05\n",
      "Epoch 2308/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3008075.2365 - recon_loss: 3.0074e-04 - KL loss: 701.1326 - beta: 1.0000e-05 - val_val_loss: 3023344.7500 - val_val_recon_loss: 3.0226e-04 - val_val_KL loss: 705.4947 - val_beta: 1.0000e-05\n",
      "Epoch 2309/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2985982.1161 - recon_loss: 2.9853e-04 - KL loss: 703.4892 - beta: 1.0000e-05 - val_val_loss: 3003185.0000 - val_val_recon_loss: 3.0025e-04 - val_val_KL loss: 703.7880 - val_beta: 1.0000e-05\n",
      "Epoch 2310/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2995789.0385 - recon_loss: 2.9951e-04 - KL loss: 704.5927 - beta: 1.0000e-05 - val_val_loss: 2967106.2500 - val_val_recon_loss: 2.9664e-04 - val_val_KL loss: 707.8825 - val_beta: 1.0000e-05\n",
      "Epoch 2311/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2959442.2525 - recon_loss: 2.9587e-04 - KL loss: 708.0475 - beta: 1.0000e-05 - val_val_loss: 2971231.2500 - val_val_recon_loss: 2.9705e-04 - val_val_KL loss: 707.2488 - val_beta: 1.0000e-05\n",
      "Epoch 2312/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2914671.9518 - recon_loss: 2.9140e-04 - KL loss: 707.7186 - beta: 1.0000e-05 - val_val_loss: 2949702.5000 - val_val_recon_loss: 2.9490e-04 - val_val_KL loss: 704.4673 - val_beta: 1.0000e-05\n",
      "Epoch 2313/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2919975.9585 - recon_loss: 2.9193e-04 - KL loss: 706.5548 - beta: 1.0000e-05 - val_val_loss: 2958582.7500 - val_val_recon_loss: 2.9579e-04 - val_val_KL loss: 706.0988 - val_beta: 1.0000e-05\n",
      "Epoch 2314/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2904048.6768 - recon_loss: 2.9033e-04 - KL loss: 704.2227 - beta: 1.0000e-05 - val_val_loss: 2965854.7500 - val_val_recon_loss: 2.9652e-04 - val_val_KL loss: 703.8120 - val_beta: 1.0000e-05\n",
      "Epoch 2315/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2915563.8839 - recon_loss: 2.9149e-04 - KL loss: 703.9686 - beta: 1.0000e-05 - val_val_loss: 2955151.0000 - val_val_recon_loss: 2.9544e-04 - val_val_KL loss: 706.1060 - val_beta: 1.0000e-05\n",
      "Epoch 2316/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2948847.0440 - recon_loss: 2.9481e-04 - KL loss: 706.9006 - beta: 1.0000e-05 - val_val_loss: 2966728.2500 - val_val_recon_loss: 2.9660e-04 - val_val_KL loss: 710.4070 - val_beta: 1.0000e-05\n",
      "Epoch 2317/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2930900.8963 - recon_loss: 2.9302e-04 - KL loss: 708.7403 - beta: 1.0000e-05\n",
      "Epoch 02317: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2930894.6486 - recon_loss: 2.9302e-04 - KL loss: 708.7413 - beta: 1.0000e-05 - val_val_loss: 2961239.7500 - val_val_recon_loss: 2.9605e-04 - val_val_KL loss: 713.7335 - val_beta: 1.0000e-05\n",
      "Epoch 2318/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2897828.9006 - recon_loss: 2.8971e-04 - KL loss: 711.9934 - beta: 1.0000e-05 - val_val_loss: 2927363.7500 - val_val_recon_loss: 2.9266e-04 - val_val_KL loss: 713.6804 - val_beta: 1.0000e-05\n",
      "Epoch 2319/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2885403.7912 - recon_loss: 2.8847e-04 - KL loss: 715.3904 - beta: 1.0000e-05 - val_val_loss: 2920373.7500 - val_val_recon_loss: 2.9197e-04 - val_val_KL loss: 714.2808 - val_beta: 1.0000e-05\n",
      "Epoch 2320/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2851634.2125 - recon_loss: 2.8509e-04 - KL loss: 714.8456 - beta: 1.0000e-05 - val_val_loss: 2918655.0000 - val_val_recon_loss: 2.9179e-04 - val_val_KL loss: 716.5414 - val_beta: 1.0000e-05\n",
      "Epoch 2321/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2867233.9578 - recon_loss: 2.8665e-04 - KL loss: 716.5421 - beta: 1.0000e-05 - val_val_loss: 2912800.7500 - val_val_recon_loss: 2.9121e-04 - val_val_KL loss: 717.2277 - val_beta: 1.0000e-05\n",
      "Epoch 2322/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2852876.5617 - recon_loss: 2.8522e-04 - KL loss: 717.3269 - beta: 1.0000e-05 - val_val_loss: 2915382.0000 - val_val_recon_loss: 2.9147e-04 - val_val_KL loss: 716.1549 - val_beta: 1.0000e-05\n",
      "Epoch 2323/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2878126.1948 - recon_loss: 2.8774e-04 - KL loss: 717.2073 - beta: 1.0000e-05 - val_val_loss: 2909345.2500 - val_val_recon_loss: 2.9086e-04 - val_val_KL loss: 719.5070 - val_beta: 1.0000e-05\n",
      "Epoch 2324/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2876982.0542 - recon_loss: 2.8763e-04 - KL loss: 719.1661 - beta: 1.0000e-05 - val_val_loss: 2914883.0000 - val_val_recon_loss: 2.9142e-04 - val_val_KL loss: 720.3996 - val_beta: 1.0000e-05\n",
      "Epoch 2325/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2860845.2113 - recon_loss: 2.8601e-04 - KL loss: 719.6623 - beta: 1.0000e-05 - val_val_loss: 2924206.7500 - val_val_recon_loss: 2.9235e-04 - val_val_KL loss: 724.4875 - val_beta: 1.0000e-05\n",
      "Epoch 2326/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2888125.5342 - recon_loss: 2.8874e-04 - KL loss: 723.6635 - beta: 1.0000e-05 - val_val_loss: 2921769.2500 - val_val_recon_loss: 2.9210e-04 - val_val_KL loss: 722.5990 - val_beta: 1.0000e-05\n",
      "Epoch 2327/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2870521.9920 - recon_loss: 2.8698e-04 - KL loss: 722.8758 - beta: 1.0000e-05 - val_val_loss: 2934025.2500 - val_val_recon_loss: 2.9333e-04 - val_val_KL loss: 724.9891 - val_beta: 1.0000e-05\n",
      "Epoch 2328/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2890616.1940 - recon_loss: 2.8899e-04 - KL loss: 725.0059 - beta: 1.0000e-05\n",
      "Epoch 02328: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2890601.6918 - recon_loss: 2.8899e-04 - KL loss: 725.0063 - beta: 1.0000e-05 - val_val_loss: 2924036.2500 - val_val_recon_loss: 2.9233e-04 - val_val_KL loss: 725.9319 - val_beta: 1.0000e-05\n",
      "Epoch 2329/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2866285.3926 - recon_loss: 2.8656e-04 - KL loss: 724.8648 - beta: 1.0000e-05 - val_val_loss: 2908027.5000 - val_val_recon_loss: 2.9073e-04 - val_val_KL loss: 725.9888 - val_beta: 1.0000e-05\n",
      "Epoch 2330/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2872982.3531 - recon_loss: 2.8723e-04 - KL loss: 725.7753 - beta: 1.0000e-05 - val_val_loss: 2910661.0000 - val_val_recon_loss: 2.9099e-04 - val_val_KL loss: 726.2325 - val_beta: 1.0000e-05\n",
      "Epoch 2331/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2838926.0757 - recon_loss: 2.8382e-04 - KL loss: 725.3222 - beta: 1.0000e-05 - val_val_loss: 2911749.7500 - val_val_recon_loss: 2.9110e-04 - val_val_KL loss: 727.0541 - val_beta: 1.0000e-05\n",
      "Epoch 2332/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2874242.9166 - recon_loss: 2.8735e-04 - KL loss: 727.4156 - beta: 1.0000e-05 - val_val_loss: 2913515.2500 - val_val_recon_loss: 2.9128e-04 - val_val_KL loss: 728.2019 - val_beta: 1.0000e-05\n",
      "Epoch 2333/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2843955.7123 - recon_loss: 2.8432e-04 - KL loss: 726.9666 - beta: 1.0000e-05 - val_val_loss: 2914348.7500 - val_val_recon_loss: 2.9136e-04 - val_val_KL loss: 727.4863 - val_beta: 1.0000e-05\n",
      "Epoch 2334/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2863970.8510 - recon_loss: 2.8632e-04 - KL loss: 726.6221 - beta: 1.0000e-05\n",
      "Epoch 02334: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2863971.6966 - recon_loss: 2.8632e-04 - KL loss: 726.6219 - beta: 1.0000e-05 - val_val_loss: 2910167.7500 - val_val_recon_loss: 2.9094e-04 - val_val_KL loss: 726.4551 - val_beta: 1.0000e-05\n",
      "Epoch 2335/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2874076.3566 - recon_loss: 2.8734e-04 - KL loss: 725.8738 - beta: 1.0000e-05 - val_val_loss: 2906106.2500 - val_val_recon_loss: 2.9054e-04 - val_val_KL loss: 726.3480 - val_beta: 1.0000e-05\n",
      "Epoch 2336/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2853083.2997 - recon_loss: 2.8524e-04 - KL loss: 726.0234 - beta: 1.0000e-05 - val_val_loss: 2904304.2500 - val_val_recon_loss: 2.9036e-04 - val_val_KL loss: 726.2643 - val_beta: 1.0000e-05\n",
      "Epoch 2337/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2846373.2875 - recon_loss: 2.8456e-04 - KL loss: 726.5932 - beta: 1.0000e-05 - val_val_loss: 2902790.7500 - val_val_recon_loss: 2.9021e-04 - val_val_KL loss: 725.7319 - val_beta: 1.0000e-05\n",
      "Epoch 2338/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2855261.8387 - recon_loss: 2.8545e-04 - KL loss: 726.2676 - beta: 1.0000e-05 - val_val_loss: 2905109.7500 - val_val_recon_loss: 2.9044e-04 - val_val_KL loss: 726.2388 - val_beta: 1.0000e-05\n",
      "Epoch 2339/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2841795.6826 - recon_loss: 2.8411e-04 - KL loss: 726.3765 - beta: 1.0000e-05 - val_val_loss: 2904111.7500 - val_val_recon_loss: 2.9034e-04 - val_val_KL loss: 726.4036 - val_beta: 1.0000e-05\n",
      "Epoch 2340/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2856688.0617 - recon_loss: 2.8560e-04 - KL loss: 726.0558 - beta: 1.0000e-05 - val_val_loss: 2901268.2500 - val_val_recon_loss: 2.9005e-04 - val_val_KL loss: 727.1165 - val_beta: 1.0000e-05\n",
      "Epoch 2341/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2830457.8851 - recon_loss: 2.8297e-04 - KL loss: 726.2771 - beta: 1.0000e-05 - val_val_loss: 2900378.2500 - val_val_recon_loss: 2.8997e-04 - val_val_KL loss: 726.7467 - val_beta: 1.0000e-05\n",
      "Epoch 2342/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2864883.7620 - recon_loss: 2.8642e-04 - KL loss: 726.8654 - beta: 1.0000e-05 - val_val_loss: 2902621.7500 - val_val_recon_loss: 2.9019e-04 - val_val_KL loss: 727.6934 - val_beta: 1.0000e-05\n",
      "Epoch 2343/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2833675.7153 - recon_loss: 2.8329e-04 - KL loss: 727.7112 - beta: 1.0000e-05 - val_val_loss: 2899447.7500 - val_val_recon_loss: 2.8987e-04 - val_val_KL loss: 727.4595 - val_beta: 1.0000e-05\n",
      "Epoch 2344/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2829906.7540 - recon_loss: 2.8292e-04 - KL loss: 727.5084 - beta: 1.0000e-05 - val_val_loss: 2900767.7500 - val_val_recon_loss: 2.9000e-04 - val_val_KL loss: 727.8290 - val_beta: 1.0000e-05\n",
      "Epoch 2345/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2837978.9293 - recon_loss: 2.8373e-04 - KL loss: 726.7350 - beta: 1.0000e-05 - val_val_loss: 2898624.0000 - val_val_recon_loss: 2.8979e-04 - val_val_KL loss: 727.9992 - val_beta: 1.0000e-05\n",
      "Epoch 2346/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2841135.7760 - recon_loss: 2.8404e-04 - KL loss: 727.6665 - beta: 1.0000e-05 - val_val_loss: 2899601.5000 - val_val_recon_loss: 2.8989e-04 - val_val_KL loss: 727.4766 - val_beta: 1.0000e-05\n",
      "Epoch 2347/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2856773.9148 - recon_loss: 2.8560e-04 - KL loss: 726.9376 - beta: 1.0000e-05 - val_val_loss: 2900477.0000 - val_val_recon_loss: 2.8997e-04 - val_val_KL loss: 727.0720 - val_beta: 1.0000e-05\n",
      "Epoch 2348/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2838978.6379 - recon_loss: 2.8383e-04 - KL loss: 727.0980 - beta: 1.0000e-05 - val_val_loss: 2900242.0000 - val_val_recon_loss: 2.8995e-04 - val_val_KL loss: 727.7823 - val_beta: 1.0000e-05\n",
      "Epoch 2349/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2832888.5694 - recon_loss: 2.8322e-04 - KL loss: 727.9224 - beta: 1.0000e-05 - val_val_loss: 2899585.2500 - val_val_recon_loss: 2.8989e-04 - val_val_KL loss: 727.7307 - val_beta: 1.0000e-05\n",
      "Epoch 2350/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2863696.0410 - recon_loss: 2.8630e-04 - KL loss: 727.0441 - beta: 1.0000e-05\n",
      "Epoch 02350: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2863704.4241 - recon_loss: 2.8630e-04 - KL loss: 727.0442 - beta: 1.0000e-05 - val_val_loss: 2899355.7500 - val_val_recon_loss: 2.8986e-04 - val_val_KL loss: 727.6401 - val_beta: 1.0000e-05\n",
      "Epoch 2351/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2858441.4980 - recon_loss: 2.8577e-04 - KL loss: 727.8617 - beta: 1.0000e-05 - val_val_loss: 2898094.5000 - val_val_recon_loss: 2.8974e-04 - val_val_KL loss: 727.5042 - val_beta: 1.0000e-05\n",
      "Epoch 2352/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2834275.7265 - recon_loss: 2.8335e-04 - KL loss: 726.2296 - beta: 1.0000e-05 - val_val_loss: 2897145.0000 - val_val_recon_loss: 2.8964e-04 - val_val_KL loss: 727.6147 - val_beta: 1.0000e-05\n",
      "Epoch 2353/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2822225.8017 - recon_loss: 2.8215e-04 - KL loss: 727.0883 - beta: 1.0000e-05 - val_val_loss: 2897608.2500 - val_val_recon_loss: 2.8969e-04 - val_val_KL loss: 727.6956 - val_beta: 1.0000e-05\n",
      "Epoch 2354/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2855498.0360 - recon_loss: 2.8548e-04 - KL loss: 727.8582 - beta: 1.0000e-05 - val_val_loss: 2898382.7500 - val_val_recon_loss: 2.8977e-04 - val_val_KL loss: 727.9084 - val_beta: 1.0000e-05\n",
      "Epoch 2355/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2840465.4763 - recon_loss: 2.8397e-04 - KL loss: 728.3185 - beta: 1.0000e-05 - val_val_loss: 2897920.2500 - val_val_recon_loss: 2.8972e-04 - val_val_KL loss: 727.8809 - val_beta: 1.0000e-05\n",
      "Epoch 2356/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2843451.6221 - recon_loss: 2.8427e-04 - KL loss: 728.0938 - beta: 1.0000e-05 - val_val_loss: 2897206.7500 - val_val_recon_loss: 2.8965e-04 - val_val_KL loss: 727.9741 - val_beta: 1.0000e-05\n",
      "Epoch 2357/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2812644.3424 - recon_loss: 2.8119e-04 - KL loss: 727.9958 - beta: 1.0000e-05 - val_val_loss: 2896361.5000 - val_val_recon_loss: 2.8956e-04 - val_val_KL loss: 728.0094 - val_beta: 1.0000e-05\n",
      "Epoch 2358/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2861219.5360 - recon_loss: 2.8605e-04 - KL loss: 728.5773 - beta: 1.0000e-05 - val_val_loss: 2897393.5000 - val_val_recon_loss: 2.8967e-04 - val_val_KL loss: 727.7567 - val_beta: 1.0000e-05\n",
      "Epoch 2359/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2858687.7755 - recon_loss: 2.8580e-04 - KL loss: 727.6881 - beta: 1.0000e-05 - val_val_loss: 2897079.7500 - val_val_recon_loss: 2.8964e-04 - val_val_KL loss: 727.8647 - val_beta: 1.0000e-05\n",
      "Epoch 2360/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2826806.0052 - recon_loss: 2.8261e-04 - KL loss: 727.2490 - beta: 1.0000e-05 - val_val_loss: 2897014.5000 - val_val_recon_loss: 2.8963e-04 - val_val_KL loss: 728.0010 - val_beta: 1.0000e-05\n",
      "Epoch 2361/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2829831.6766 - recon_loss: 2.8291e-04 - KL loss: 727.6396 - beta: 1.0000e-05 - val_val_loss: 2897249.2500 - val_val_recon_loss: 2.8965e-04 - val_val_KL loss: 727.9574 - val_beta: 1.0000e-05\n",
      "Epoch 2362/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2843559.2435 - recon_loss: 2.8428e-04 - KL loss: 727.3554 - beta: 1.0000e-05\n",
      "Epoch 02362: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2843573.1299 - recon_loss: 2.8428e-04 - KL loss: 727.3559 - beta: 1.0000e-05 - val_val_loss: 2897901.0000 - val_val_recon_loss: 2.8972e-04 - val_val_KL loss: 728.1110 - val_beta: 1.0000e-05\n",
      "Epoch 2363/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2849971.4903 - recon_loss: 2.8492e-04 - KL loss: 728.4095 - beta: 1.0000e-05 - val_val_loss: 2898332.2500 - val_val_recon_loss: 2.8976e-04 - val_val_KL loss: 727.9624 - val_beta: 1.0000e-05\n",
      "Epoch 2364/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2819047.1613 - recon_loss: 2.8183e-04 - KL loss: 727.0203 - beta: 1.0000e-05 - val_val_loss: 2898497.5000 - val_val_recon_loss: 2.8978e-04 - val_val_KL loss: 728.0359 - val_beta: 1.0000e-05\n",
      "Epoch 2365/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2834232.5342 - recon_loss: 2.8335e-04 - KL loss: 727.8333 - beta: 1.0000e-05 - val_val_loss: 2898684.5000 - val_val_recon_loss: 2.8980e-04 - val_val_KL loss: 728.1230 - val_beta: 1.0000e-05\n",
      "Epoch 2366/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2815397.9183 - recon_loss: 2.8147e-04 - KL loss: 727.7991 - beta: 1.0000e-05 - val_val_loss: 2898771.7500 - val_val_recon_loss: 2.8980e-04 - val_val_KL loss: 728.1155 - val_beta: 1.0000e-05\n",
      "Epoch 2367/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2835737.0737 - recon_loss: 2.8350e-04 - KL loss: 727.5446 - beta: 1.0000e-05\n",
      "Epoch 02367: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2835742.6109 - recon_loss: 2.8350e-04 - KL loss: 727.5447 - beta: 1.0000e-05 - val_val_loss: 2898659.2500 - val_val_recon_loss: 2.8979e-04 - val_val_KL loss: 728.2251 - val_beta: 1.0000e-05\n",
      "Epoch 2367/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 908613.9050 - recon_loss: 2.9379e-04 - KL loss: 724.7508 - beta: 1.7989e-05 - val_val_loss: 941309.0625 - val_val_recon_loss: 3.0437e-04 - val_val_KL loss: 725.9889 - val_beta: 1.7989e-05\n",
      "Epoch 2368/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 929042.8519 - recon_loss: 3.0041e-04 - KL loss: 716.6467 - beta: 1.7989e-05 - val_val_loss: 947799.2500 - val_val_recon_loss: 3.0649e-04 - val_val_KL loss: 691.4429 - val_beta: 1.7989e-05\n",
      "Epoch 2369/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 957860.1692 - recon_loss: 3.0974e-04 - KL loss: 699.0391 - beta: 1.7989e-05 - val_val_loss: 955961.4375 - val_val_recon_loss: 3.0913e-04 - val_val_KL loss: 678.8056 - val_beta: 1.7989e-05\n",
      "Epoch 2370/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 947781.2760 - recon_loss: 3.0649e-04 - KL loss: 670.1675 - beta: 1.7989e-05 - val_val_loss: 943423.4375 - val_val_recon_loss: 3.0508e-04 - val_val_KL loss: 650.2931 - val_beta: 1.7989e-05\n",
      "Epoch 2371/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 949187.3309 - recon_loss: 3.0695e-04 - KL loss: 643.0070 - beta: 1.7989e-05 - val_val_loss: 976932.1875 - val_val_recon_loss: 3.1592e-04 - val_val_KL loss: 655.9236 - val_beta: 1.7989e-05\n",
      "Epoch 2372/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 974087.0864 - recon_loss: 3.1500e-04 - KL loss: 656.2278 - beta: 1.7989e-05\n",
      "Epoch 02372: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 974093.5378 - recon_loss: 3.1501e-04 - KL loss: 656.2264 - beta: 1.7989e-05 - val_val_loss: 986494.6250 - val_val_recon_loss: 3.1902e-04 - val_val_KL loss: 652.4816 - val_beta: 1.7989e-05\n",
      "Epoch 2373/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 949449.4392 - recon_loss: 3.0703e-04 - KL loss: 654.9781 - beta: 1.7989e-05 - val_val_loss: 937743.5000 - val_val_recon_loss: 3.0324e-04 - val_val_KL loss: 655.6418 - val_beta: 1.7989e-05\n",
      "Epoch 2374/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 925880.7008 - recon_loss: 2.9940e-04 - KL loss: 655.6007 - beta: 1.7989e-05 - val_val_loss: 934897.9375 - val_val_recon_loss: 3.0232e-04 - val_val_KL loss: 653.5966 - val_beta: 1.7989e-05\n",
      "Epoch 2375/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 921785.9622 - recon_loss: 2.9808e-04 - KL loss: 654.1944 - beta: 1.7989e-05 - val_val_loss: 930516.9375 - val_val_recon_loss: 3.0091e-04 - val_val_KL loss: 645.3622 - val_beta: 1.7989e-05\n",
      "Epoch 2376/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 918145.1418 - recon_loss: 2.9690e-04 - KL loss: 646.8637 - beta: 1.7989e-05 - val_val_loss: 923129.5000 - val_val_recon_loss: 2.9852e-04 - val_val_KL loss: 648.7879 - val_beta: 1.7989e-05\n",
      "Epoch 2377/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 923648.9806 - recon_loss: 2.9868e-04 - KL loss: 650.1849 - beta: 1.7989e-05 - val_val_loss: 929958.0000 - val_val_recon_loss: 3.0073e-04 - val_val_KL loss: 650.8208 - val_beta: 1.7989e-05\n",
      "Epoch 2378/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 912374.6781 - recon_loss: 2.9503e-04 - KL loss: 651.8729 - beta: 1.7989e-05 - val_val_loss: 990255.8125 - val_val_recon_loss: 3.2023e-04 - val_val_KL loss: 665.1854 - val_beta: 1.7989e-05\n",
      "Epoch 2379/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 946125.6032 - recon_loss: 3.0595e-04 - KL loss: 661.2571 - beta: 1.7989e-05 - val_val_loss: 942815.7500 - val_val_recon_loss: 3.0488e-04 - val_val_KL loss: 655.8957 - val_beta: 1.7989e-05\n",
      "Epoch 2380/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 948207.1949 - recon_loss: 3.0663e-04 - KL loss: 658.7930 - beta: 1.7989e-05 - val_val_loss: 946311.1250 - val_val_recon_loss: 3.0602e-04 - val_val_KL loss: 656.3209 - val_beta: 1.7989e-05\n",
      "Epoch 2381/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 942793.3867 - recon_loss: 3.0488e-04 - KL loss: 657.4297 - beta: 1.7989e-05\n",
      "Epoch 02381: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 942783.0536 - recon_loss: 3.0487e-04 - KL loss: 657.4286 - beta: 1.7989e-05 - val_val_loss: 936613.9375 - val_val_recon_loss: 3.0288e-04 - val_val_KL loss: 654.0981 - val_beta: 1.7989e-05\n",
      "Epoch 2382/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 918621.5519 - recon_loss: 2.9705e-04 - KL loss: 655.5725 - beta: 1.7989e-05 - val_val_loss: 926940.5000 - val_val_recon_loss: 2.9975e-04 - val_val_KL loss: 654.2908 - val_beta: 1.7989e-05\n",
      "Epoch 2383/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 913831.3176 - recon_loss: 2.9550e-04 - KL loss: 655.7867 - beta: 1.7989e-05 - val_val_loss: 920770.0000 - val_val_recon_loss: 2.9775e-04 - val_val_KL loss: 654.7888 - val_beta: 1.7989e-05\n",
      "Epoch 2384/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 906520.5734 - recon_loss: 2.9314e-04 - KL loss: 655.2667 - beta: 1.7989e-05 - val_val_loss: 915320.1875 - val_val_recon_loss: 2.9599e-04 - val_val_KL loss: 654.5641 - val_beta: 1.7989e-05\n",
      "Epoch 2385/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 903191.1091 - recon_loss: 2.9206e-04 - KL loss: 655.5199 - beta: 1.7989e-05 - val_val_loss: 913614.1875 - val_val_recon_loss: 2.9543e-04 - val_val_KL loss: 654.3950 - val_beta: 1.7989e-05\n",
      "Epoch 2386/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 904901.9776 - recon_loss: 2.9262e-04 - KL loss: 655.0446 - beta: 1.7989e-05 - val_val_loss: 913976.8125 - val_val_recon_loss: 2.9555e-04 - val_val_KL loss: 656.8167 - val_beta: 1.7989e-05\n",
      "Epoch 2387/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 895731.9628 - recon_loss: 2.8965e-04 - KL loss: 654.9554 - beta: 1.7989e-05 - val_val_loss: 910241.9375 - val_val_recon_loss: 2.9434e-04 - val_val_KL loss: 652.7347 - val_beta: 1.7989e-05\n",
      "Epoch 2388/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 893391.3076 - recon_loss: 2.8889e-04 - KL loss: 654.8939 - beta: 1.7989e-05 - val_val_loss: 911720.2500 - val_val_recon_loss: 2.9482e-04 - val_val_KL loss: 654.5618 - val_beta: 1.7989e-05\n",
      "Epoch 2389/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 900613.2602 - recon_loss: 2.9123e-04 - KL loss: 654.1865 - beta: 1.7989e-05 - val_val_loss: 907825.3750 - val_val_recon_loss: 2.9356e-04 - val_val_KL loss: 652.9179 - val_beta: 1.7989e-05\n",
      "Epoch 2390/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 896228.2622 - recon_loss: 2.8981e-04 - KL loss: 652.6656 - beta: 1.7989e-05 - val_val_loss: 912573.7500 - val_val_recon_loss: 2.9510e-04 - val_val_KL loss: 655.7377 - val_beta: 1.7989e-05\n",
      "Epoch 2391/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 902245.0310 - recon_loss: 2.9176e-04 - KL loss: 656.4350 - beta: 1.7989e-05 - val_val_loss: 910414.1875 - val_val_recon_loss: 2.9440e-04 - val_val_KL loss: 656.2360 - val_beta: 1.7989e-05\n",
      "Epoch 2392/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 897612.0707 - recon_loss: 2.9026e-04 - KL loss: 656.4792 - beta: 1.7989e-05 - val_val_loss: 911482.7500 - val_val_recon_loss: 2.9475e-04 - val_val_KL loss: 655.2008 - val_beta: 1.7989e-05\n",
      "Epoch 2393/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 898374.8634 - recon_loss: 2.9050e-04 - KL loss: 655.7868 - beta: 1.7989e-05 - val_val_loss: 906804.2500 - val_val_recon_loss: 2.9323e-04 - val_val_KL loss: 654.2538 - val_beta: 1.7989e-05\n",
      "Epoch 2394/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 894400.9279 - recon_loss: 2.8922e-04 - KL loss: 655.2810 - beta: 1.7989e-05 - val_val_loss: 906514.7500 - val_val_recon_loss: 2.9314e-04 - val_val_KL loss: 655.2172 - val_beta: 1.7989e-05\n",
      "Epoch 2395/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 884899.5243 - recon_loss: 2.8614e-04 - KL loss: 655.1931 - beta: 1.7989e-05 - val_val_loss: 904084.3750 - val_val_recon_loss: 2.9235e-04 - val_val_KL loss: 653.7946 - val_beta: 1.7989e-05\n",
      "Epoch 2396/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 893178.6325 - recon_loss: 2.8882e-04 - KL loss: 653.6833 - beta: 1.7989e-05 - val_val_loss: 904652.2500 - val_val_recon_loss: 2.9254e-04 - val_val_KL loss: 650.6085 - val_beta: 1.7989e-05\n",
      "Epoch 2397/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 889157.5682 - recon_loss: 2.8752e-04 - KL loss: 651.9347 - beta: 1.7989e-05 - val_val_loss: 904803.5000 - val_val_recon_loss: 2.9258e-04 - val_val_KL loss: 651.5197 - val_beta: 1.7989e-05\n",
      "Epoch 2398/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 896964.7941 - recon_loss: 2.9005e-04 - KL loss: 652.8662 - beta: 1.7989e-05 - val_val_loss: 907941.1250 - val_val_recon_loss: 2.9360e-04 - val_val_KL loss: 652.1981 - val_beta: 1.7989e-05\n",
      "Epoch 2399/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 878985.0136 - recon_loss: 2.8423e-04 - KL loss: 653.0836 - beta: 1.7989e-05 - val_val_loss: 905155.3750 - val_val_recon_loss: 2.9270e-04 - val_val_KL loss: 651.9424 - val_beta: 1.7989e-05\n",
      "Epoch 2400/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 889214.6679 - recon_loss: 2.8754e-04 - KL loss: 652.7425 - beta: 1.7989e-05\n",
      "Epoch 02400: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 889215.2614 - recon_loss: 2.8754e-04 - KL loss: 652.7425 - beta: 1.7989e-05 - val_val_loss: 904345.7500 - val_val_recon_loss: 2.9244e-04 - val_val_KL loss: 653.4625 - val_beta: 1.7989e-05\n",
      "Epoch 2401/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 891332.3649 - recon_loss: 2.8822e-04 - KL loss: 654.1257 - beta: 1.7989e-05 - val_val_loss: 901308.0000 - val_val_recon_loss: 2.9145e-04 - val_val_KL loss: 654.3448 - val_beta: 1.7989e-05\n",
      "Epoch 2402/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 881817.4720 - recon_loss: 2.8515e-04 - KL loss: 654.4781 - beta: 1.7989e-05 - val_val_loss: 902300.3750 - val_val_recon_loss: 2.9177e-04 - val_val_KL loss: 655.0184 - val_beta: 1.7989e-05\n",
      "Epoch 2403/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 887162.9633 - recon_loss: 2.8687e-04 - KL loss: 655.2686 - beta: 1.7989e-05 - val_val_loss: 900851.5000 - val_val_recon_loss: 2.9131e-04 - val_val_KL loss: 654.0812 - val_beta: 1.7989e-05\n",
      "Epoch 2404/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 874072.2659 - recon_loss: 2.8264e-04 - KL loss: 653.5795 - beta: 1.7989e-05 - val_val_loss: 899122.5625 - val_val_recon_loss: 2.9075e-04 - val_val_KL loss: 653.3619 - val_beta: 1.7989e-05\n",
      "Epoch 2405/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 881951.4033 - recon_loss: 2.8519e-04 - KL loss: 653.2339 - beta: 1.7989e-05 - val_val_loss: 898003.4375 - val_val_recon_loss: 2.9038e-04 - val_val_KL loss: 653.2202 - val_beta: 1.7989e-05\n",
      "Epoch 2406/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 893486.9776 - recon_loss: 2.8892e-04 - KL loss: 653.2339 - beta: 1.7989e-05 - val_val_loss: 898289.1250 - val_val_recon_loss: 2.9048e-04 - val_val_KL loss: 652.6708 - val_beta: 1.7989e-05\n",
      "Epoch 2407/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 884905.6357 - recon_loss: 2.8614e-04 - KL loss: 653.8697 - beta: 1.7989e-05 - val_val_loss: 897172.3125 - val_val_recon_loss: 2.9011e-04 - val_val_KL loss: 653.4554 - val_beta: 1.7989e-05\n",
      "Epoch 2408/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 883287.7011 - recon_loss: 2.8562e-04 - KL loss: 654.4269 - beta: 1.7989e-05 - val_val_loss: 899358.2500 - val_val_recon_loss: 2.9082e-04 - val_val_KL loss: 654.5035 - val_beta: 1.7989e-05\n",
      "Epoch 2409/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 884579.9264 - recon_loss: 2.8604e-04 - KL loss: 654.4156 - beta: 1.7989e-05 - val_val_loss: 900327.3750 - val_val_recon_loss: 2.9114e-04 - val_val_KL loss: 655.1906 - val_beta: 1.7989e-05\n",
      "Epoch 2410/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 874823.6601 - recon_loss: 2.8288e-04 - KL loss: 655.1683 - beta: 1.7989e-05 - val_val_loss: 898546.2500 - val_val_recon_loss: 2.9056e-04 - val_val_KL loss: 653.9063 - val_beta: 1.7989e-05\n",
      "Epoch 2411/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 890212.9942 - recon_loss: 2.8786e-04 - KL loss: 655.3365 - beta: 1.7989e-05 - val_val_loss: 899069.4375 - val_val_recon_loss: 2.9073e-04 - val_val_KL loss: 654.7628 - val_beta: 1.7989e-05\n",
      "Epoch 2412/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 889794.9693 - recon_loss: 2.8773e-04 - KL loss: 655.8154 - beta: 1.7989e-05 - val_val_loss: 896914.9375 - val_val_recon_loss: 2.9003e-04 - val_val_KL loss: 654.4633 - val_beta: 1.7989e-05\n",
      "Epoch 2413/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 885633.8989 - recon_loss: 2.8638e-04 - KL loss: 654.6365 - beta: 1.7989e-05 - val_val_loss: 897434.0000 - val_val_recon_loss: 2.9020e-04 - val_val_KL loss: 654.6941 - val_beta: 1.7989e-05\n",
      "Epoch 2414/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 880058.7479 - recon_loss: 2.8458e-04 - KL loss: 654.9520 - beta: 1.7989e-05 - val_val_loss: 896922.9375 - val_val_recon_loss: 2.9003e-04 - val_val_KL loss: 654.4662 - val_beta: 1.7989e-05\n",
      "Epoch 2415/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 877159.4529 - recon_loss: 2.8364e-04 - KL loss: 653.6779 - beta: 1.7989e-05 - val_val_loss: 895401.8125 - val_val_recon_loss: 2.8954e-04 - val_val_KL loss: 653.4845 - val_beta: 1.7989e-05\n",
      "Epoch 2416/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 875881.6289 - recon_loss: 2.8322e-04 - KL loss: 653.8653 - beta: 1.7989e-05 - val_val_loss: 895996.3125 - val_val_recon_loss: 2.8973e-04 - val_val_KL loss: 655.1616 - val_beta: 1.7989e-05\n",
      "Epoch 2417/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 879972.5452 - recon_loss: 2.8455e-04 - KL loss: 655.3352 - beta: 1.7989e-05 - val_val_loss: 896541.6875 - val_val_recon_loss: 2.8991e-04 - val_val_KL loss: 655.0551 - val_beta: 1.7989e-05\n",
      "Epoch 2418/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 879083.4896 - recon_loss: 2.8426e-04 - KL loss: 655.8936 - beta: 1.7989e-05 - val_val_loss: 896294.1875 - val_val_recon_loss: 2.8983e-04 - val_val_KL loss: 655.3705 - val_beta: 1.7989e-05\n",
      "Epoch 2419/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 885093.5503 - recon_loss: 2.8621e-04 - KL loss: 655.7721 - beta: 1.7989e-05 - val_val_loss: 896432.1875 - val_val_recon_loss: 2.8987e-04 - val_val_KL loss: 654.6090 - val_beta: 1.7989e-05\n",
      "Epoch 2420/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 879310.3865 - recon_loss: 2.8433e-04 - KL loss: 654.5896 - beta: 1.7989e-05\n",
      "Epoch 02420: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 879308.7230 - recon_loss: 2.8433e-04 - KL loss: 654.5898 - beta: 1.7989e-05 - val_val_loss: 895806.2500 - val_val_recon_loss: 2.8967e-04 - val_val_KL loss: 655.6976 - val_beta: 1.7989e-05\n",
      "Epoch 2421/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 878415.8609 - recon_loss: 2.8404e-04 - KL loss: 655.7665 - beta: 1.7989e-05 - val_val_loss: 894083.6875 - val_val_recon_loss: 2.8911e-04 - val_val_KL loss: 655.6155 - val_beta: 1.7989e-05\n",
      "Epoch 2422/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877481.4450 - recon_loss: 2.8374e-04 - KL loss: 655.9907 - beta: 1.7989e-05 - val_val_loss: 894229.2500 - val_val_recon_loss: 2.8916e-04 - val_val_KL loss: 655.7866 - val_beta: 1.7989e-05\n",
      "Epoch 2423/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 118s 118ms/step - loss: 872799.8819 - recon_loss: 2.8223e-04 - KL loss: 656.0815 - beta: 1.7989e-05 - val_val_loss: 894301.2500 - val_val_recon_loss: 2.8918e-04 - val_val_KL loss: 656.1031 - val_beta: 1.7989e-05\n",
      "Epoch 2424/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 882966.4001 - recon_loss: 2.8552e-04 - KL loss: 656.3425 - beta: 1.7989e-05 - val_val_loss: 893844.6250 - val_val_recon_loss: 2.8904e-04 - val_val_KL loss: 655.8304 - val_beta: 1.7989e-05\n",
      "Epoch 2425/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 875119.5102 - recon_loss: 2.8298e-04 - KL loss: 655.4140 - beta: 1.7989e-05 - val_val_loss: 894959.8125 - val_val_recon_loss: 2.8940e-04 - val_val_KL loss: 655.5814 - val_beta: 1.7989e-05\n",
      "Epoch 2426/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 879421.5943 - recon_loss: 2.8437e-04 - KL loss: 656.2728 - beta: 1.7989e-05 - val_val_loss: 893967.9375 - val_val_recon_loss: 2.8908e-04 - val_val_KL loss: 655.9849 - val_beta: 1.7989e-05\n",
      "Epoch 2427/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 881762.4314 - recon_loss: 2.8513e-04 - KL loss: 655.9195 - beta: 1.7989e-05 - val_val_loss: 893737.2500 - val_val_recon_loss: 2.8900e-04 - val_val_KL loss: 655.9991 - val_beta: 1.7989e-05\n",
      "Epoch 2428/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 871075.6442 - recon_loss: 2.8167e-04 - KL loss: 656.1989 - beta: 1.7989e-05 - val_val_loss: 893365.7500 - val_val_recon_loss: 2.8888e-04 - val_val_KL loss: 656.1817 - val_beta: 1.7989e-05\n",
      "Epoch 2429/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 875605.3643 - recon_loss: 2.8313e-04 - KL loss: 656.0835 - beta: 1.7989e-05 - val_val_loss: 894558.5000 - val_val_recon_loss: 2.8927e-04 - val_val_KL loss: 655.2186 - val_beta: 1.7989e-05\n",
      "Epoch 2430/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 874663.1036 - recon_loss: 2.8283e-04 - KL loss: 656.1266 - beta: 1.7989e-05 - val_val_loss: 893647.0625 - val_val_recon_loss: 2.8897e-04 - val_val_KL loss: 655.5285 - val_beta: 1.7989e-05\n",
      "Epoch 2431/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 876916.4279 - recon_loss: 2.8356e-04 - KL loss: 656.0735 - beta: 1.7989e-05 - val_val_loss: 893040.8125 - val_val_recon_loss: 2.8878e-04 - val_val_KL loss: 655.2916 - val_beta: 1.7989e-05\n",
      "Epoch 2432/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 870833.5549 - recon_loss: 2.8159e-04 - KL loss: 655.5756 - beta: 1.7989e-05 - val_val_loss: 893218.0625 - val_val_recon_loss: 2.8883e-04 - val_val_KL loss: 655.2061 - val_beta: 1.7989e-05\n",
      "Epoch 2433/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 873729.6091 - recon_loss: 2.8253e-04 - KL loss: 655.7764 - beta: 1.7989e-05 - val_val_loss: 893204.5000 - val_val_recon_loss: 2.8883e-04 - val_val_KL loss: 654.7241 - val_beta: 1.7989e-05\n",
      "Epoch 2434/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877031.2722 - recon_loss: 2.8360e-04 - KL loss: 654.7697 - beta: 1.7989e-05 - val_val_loss: 893082.0625 - val_val_recon_loss: 2.8879e-04 - val_val_KL loss: 654.9927 - val_beta: 1.7989e-05\n",
      "Epoch 2435/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 874658.7173 - recon_loss: 2.8283e-04 - KL loss: 654.5980 - beta: 1.7989e-05 - val_val_loss: 892708.8125 - val_val_recon_loss: 2.8867e-04 - val_val_KL loss: 654.9647 - val_beta: 1.7989e-05\n",
      "Epoch 2436/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877827.7815 - recon_loss: 2.8385e-04 - KL loss: 656.5033 - beta: 1.7989e-05 - val_val_loss: 893374.7500 - val_val_recon_loss: 2.8889e-04 - val_val_KL loss: 655.3126 - val_beta: 1.7989e-05\n",
      "Epoch 2437/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 872193.8430 - recon_loss: 2.8203e-04 - KL loss: 656.3110 - beta: 1.7989e-05 - val_val_loss: 893545.7500 - val_val_recon_loss: 2.8894e-04 - val_val_KL loss: 655.2642 - val_beta: 1.7989e-05\n",
      "Epoch 2438/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 878020.7454 - recon_loss: 2.8392e-04 - KL loss: 655.0615 - beta: 1.7989e-05 - val_val_loss: 893451.6250 - val_val_recon_loss: 2.8891e-04 - val_val_KL loss: 656.1115 - val_beta: 1.7989e-05\n",
      "Epoch 2439/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877343.5930 - recon_loss: 2.8370e-04 - KL loss: 656.2763 - beta: 1.7989e-05 - val_val_loss: 893956.7500 - val_val_recon_loss: 2.8907e-04 - val_val_KL loss: 656.1252 - val_beta: 1.7989e-05\n",
      "Epoch 2440/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 885346.6459 - recon_loss: 2.8629e-04 - KL loss: 655.8189 - beta: 1.7989e-05\n",
      "Epoch 02440: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 885339.5652 - recon_loss: 2.8628e-04 - KL loss: 655.8196 - beta: 1.7989e-05 - val_val_loss: 894577.8125 - val_val_recon_loss: 2.8927e-04 - val_val_KL loss: 655.8759 - val_beta: 1.7989e-05\n",
      "Epoch 2441/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 876307.2692 - recon_loss: 2.8336e-04 - KL loss: 655.9019 - beta: 1.7989e-05 - val_val_loss: 894033.4375 - val_val_recon_loss: 2.8910e-04 - val_val_KL loss: 655.8933 - val_beta: 1.7989e-05\n",
      "Epoch 2442/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 873442.3495 - recon_loss: 2.8244e-04 - KL loss: 655.5107 - beta: 1.7989e-05 - val_val_loss: 893910.1875 - val_val_recon_loss: 2.8906e-04 - val_val_KL loss: 656.0372 - val_beta: 1.7989e-05\n",
      "Epoch 2443/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 880373.2539 - recon_loss: 2.8468e-04 - KL loss: 656.0058 - beta: 1.7989e-05 - val_val_loss: 893834.8750 - val_val_recon_loss: 2.8903e-04 - val_val_KL loss: 655.8324 - val_beta: 1.7989e-05\n",
      "Epoch 2444/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 879449.9008 - recon_loss: 2.8438e-04 - KL loss: 656.7401 - beta: 1.7989e-05 - val_val_loss: 893762.5000 - val_val_recon_loss: 2.8901e-04 - val_val_KL loss: 656.0566 - val_beta: 1.7989e-05\n",
      "Epoch 2445/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 876022.1249 - recon_loss: 2.8327e-04 - KL loss: 656.6549 - beta: 1.7989e-05\n",
      "Epoch 02445: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 876023.8146 - recon_loss: 2.8327e-04 - KL loss: 656.6544 - beta: 1.7989e-05 - val_val_loss: 893678.1875 - val_val_recon_loss: 2.8898e-04 - val_val_KL loss: 655.8602 - val_beta: 1.7989e-05\n",
      "Epoch 2445/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 282177.5911 - recon_loss: 2.9481e-04 - KL loss: 653.6869 - beta: 3.2360e-05 - val_val_loss: 283704.5312 - val_val_recon_loss: 2.9643e-04 - val_val_KL loss: 625.6135 - val_beta: 3.2360e-05\n",
      "Epoch 2446/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 279273.4223 - recon_loss: 2.9180e-04 - KL loss: 615.3681 - beta: 3.2360e-05 - val_val_loss: 284173.6250 - val_val_recon_loss: 2.9697e-04 - val_val_KL loss: 584.0211 - val_beta: 3.2360e-05\n",
      "Epoch 2447/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 283928.1791 - recon_loss: 2.9672e-04 - KL loss: 575.7451 - beta: 3.2360e-05 - val_val_loss: 287683.4688 - val_val_recon_loss: 3.0067e-04 - val_val_KL loss: 562.4349 - val_beta: 3.2360e-05\n",
      "Epoch 2448/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 284666.2426 - recon_loss: 2.9751e-04 - KL loss: 556.1345 - beta: 3.2360e-05 - val_val_loss: 284301.7500 - val_val_recon_loss: 2.9714e-04 - val_val_KL loss: 547.3989 - val_beta: 3.2360e-05\n",
      "Epoch 2449/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 284516.9771 - recon_loss: 2.9736e-04 - KL loss: 549.1733 - beta: 3.2360e-05 - val_val_loss: 298938.5938 - val_val_recon_loss: 3.1246e-04 - val_val_KL loss: 555.4518 - val_beta: 3.2360e-05\n",
      "Epoch 2450/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 291978.2746 - recon_loss: 3.0518e-04 - KL loss: 545.0239 - beta: 3.2360e-05\n",
      "Epoch 02450: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 291976.1773 - recon_loss: 3.0518e-04 - KL loss: 545.0165 - beta: 3.2360e-05 - val_val_loss: 290850.5312 - val_val_recon_loss: 3.0400e-04 - val_val_KL loss: 542.6628 - val_beta: 3.2360e-05\n",
      "Epoch 2451/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 277598.0853 - recon_loss: 2.9013e-04 - KL loss: 541.7607 - beta: 3.2360e-05 - val_val_loss: 279475.0938 - val_val_recon_loss: 2.9209e-04 - val_val_KL loss: 544.1175 - val_beta: 3.2360e-05\n",
      "Epoch 2452/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 274560.7141 - recon_loss: 2.8694e-04 - KL loss: 543.8881 - beta: 3.2360e-05 - val_val_loss: 277777.6875 - val_val_recon_loss: 2.9031e-04 - val_val_KL loss: 546.7164 - val_beta: 3.2360e-05\n",
      "Epoch 2453/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 272304.2622 - recon_loss: 2.8458e-04 - KL loss: 547.2404 - beta: 3.2360e-05 - val_val_loss: 279607.0938 - val_val_recon_loss: 2.9222e-04 - val_val_KL loss: 549.1418 - val_beta: 3.2360e-05\n",
      "Epoch 2454/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 273964.6315 - recon_loss: 2.8632e-04 - KL loss: 548.1341 - beta: 3.2360e-05 - val_val_loss: 279714.4688 - val_val_recon_loss: 2.9233e-04 - val_val_KL loss: 553.5623 - val_beta: 3.2360e-05\n",
      "Epoch 2455/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 276523.7360 - recon_loss: 2.8899e-04 - KL loss: 554.2873 - beta: 3.2360e-05 - val_val_loss: 282087.1562 - val_val_recon_loss: 2.9481e-04 - val_val_KL loss: 559.7781 - val_beta: 3.2360e-05\n",
      "Epoch 2456/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 278022.4029 - recon_loss: 2.9055e-04 - KL loss: 562.6755 - beta: 3.2360e-05 - val_val_loss: 280565.2188 - val_val_recon_loss: 2.9321e-04 - val_val_KL loss: 564.4656 - val_beta: 3.2360e-05\n",
      "Epoch 2457/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 276061.4717 - recon_loss: 2.8849e-04 - KL loss: 565.9425 - beta: 3.2360e-05\n",
      "Epoch 02457: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 276063.5540 - recon_loss: 2.8850e-04 - KL loss: 565.9453 - beta: 3.2360e-05 - val_val_loss: 288196.7812 - val_val_recon_loss: 3.0119e-04 - val_val_KL loss: 573.0881 - val_beta: 3.2360e-05\n",
      "Epoch 2458/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 280609.8560 - recon_loss: 2.9325e-04 - KL loss: 574.1728 - beta: 3.2360e-05 - val_val_loss: 281059.0625 - val_val_recon_loss: 2.9372e-04 - val_val_KL loss: 575.4836 - val_beta: 3.2360e-05\n",
      "Epoch 2459/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 278361.5425 - recon_loss: 2.9089e-04 - KL loss: 575.1217 - beta: 3.2360e-05 - val_val_loss: 280389.2812 - val_val_recon_loss: 2.9301e-04 - val_val_KL loss: 576.0125 - val_beta: 3.2360e-05\n",
      "Epoch 2460/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 275578.2595 - recon_loss: 2.8798e-04 - KL loss: 575.6297 - beta: 3.2360e-05 - val_val_loss: 278739.6875 - val_val_recon_loss: 2.9129e-04 - val_val_KL loss: 574.4670 - val_beta: 3.2360e-05\n",
      "Epoch 2461/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 273908.0615 - recon_loss: 2.8623e-04 - KL loss: 574.2538 - beta: 3.2360e-05 - val_val_loss: 277555.8750 - val_val_recon_loss: 2.9005e-04 - val_val_KL loss: 573.6417 - val_beta: 3.2360e-05\n",
      "Epoch 2462/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 271362.2075 - recon_loss: 2.8356e-04 - KL loss: 573.0007 - beta: 3.2360e-05 - val_val_loss: 276707.5938 - val_val_recon_loss: 2.8916e-04 - val_val_KL loss: 572.9517 - val_beta: 3.2360e-05\n",
      "Epoch 2463/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 272264.6288 - recon_loss: 2.8451e-04 - KL loss: 573.9384 - beta: 3.2360e-05 - val_val_loss: 276782.5000 - val_val_recon_loss: 2.8924e-04 - val_val_KL loss: 573.4517 - val_beta: 3.2360e-05\n",
      "Epoch 2464/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 272128.5284 - recon_loss: 2.8437e-04 - KL loss: 572.3950 - beta: 3.2360e-05 - val_val_loss: 275955.3125 - val_val_recon_loss: 2.8838e-04 - val_val_KL loss: 569.7417 - val_beta: 3.2360e-05\n",
      "Epoch 2465/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 269416.9791 - recon_loss: 2.8153e-04 - KL loss: 570.0001 - beta: 3.2360e-05 - val_val_loss: 276214.5938 - val_val_recon_loss: 2.8865e-04 - val_val_KL loss: 568.4308 - val_beta: 3.2360e-05\n",
      "Epoch 2466/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 272992.6282 - recon_loss: 2.8527e-04 - KL loss: 570.1818 - beta: 3.2360e-05 - val_val_loss: 275894.9062 - val_val_recon_loss: 2.8831e-04 - val_val_KL loss: 571.4423 - val_beta: 3.2360e-05\n",
      "Epoch 2467/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 270693.4409 - recon_loss: 2.8287e-04 - KL loss: 570.7042 - beta: 3.2360e-05 - val_val_loss: 275596.9688 - val_val_recon_loss: 2.8800e-04 - val_val_KL loss: 570.8421 - val_beta: 3.2360e-05\n",
      "Epoch 2468/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 271100.4293 - recon_loss: 2.8329e-04 - KL loss: 571.6091 - beta: 3.2360e-05 - val_val_loss: 275990.8125 - val_val_recon_loss: 2.8841e-04 - val_val_KL loss: 572.1919 - val_beta: 3.2360e-05\n",
      "Epoch 2469/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 269833.3585 - recon_loss: 2.8197e-04 - KL loss: 571.5120 - beta: 3.2360e-05 - val_val_loss: 276299.9688 - val_val_recon_loss: 2.8874e-04 - val_val_KL loss: 571.3346 - val_beta: 3.2360e-05\n",
      "Epoch 2470/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 269832.3694 - recon_loss: 2.8196e-04 - KL loss: 572.1065 - beta: 3.2360e-05 - val_val_loss: 273593.5312 - val_val_recon_loss: 2.8590e-04 - val_val_KL loss: 570.8616 - val_beta: 3.2360e-05\n",
      "Epoch 2471/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 269973.4001 - recon_loss: 2.8211e-04 - KL loss: 572.7541 - beta: 3.2360e-05 - val_val_loss: 272892.0625 - val_val_recon_loss: 2.8517e-04 - val_val_KL loss: 572.3854 - val_beta: 3.2360e-05\n",
      "Epoch 2472/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 269566.4054 - recon_loss: 2.8168e-04 - KL loss: 572.6980 - beta: 3.2360e-05 - val_val_loss: 272680.0625 - val_val_recon_loss: 2.8495e-04 - val_val_KL loss: 571.2725 - val_beta: 3.2360e-05\n",
      "Epoch 2473/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 267552.7234 - recon_loss: 2.7958e-04 - KL loss: 571.4293 - beta: 3.2360e-05 - val_val_loss: 272149.8750 - val_val_recon_loss: 2.8439e-04 - val_val_KL loss: 570.9525 - val_beta: 3.2360e-05\n",
      "Epoch 2474/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 267315.8947 - recon_loss: 2.7933e-04 - KL loss: 571.2985 - beta: 3.2360e-05 - val_val_loss: 272534.9688 - val_val_recon_loss: 2.8480e-04 - val_val_KL loss: 569.6647 - val_beta: 3.2360e-05\n",
      "Epoch 2475/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264164.2983 - recon_loss: 2.7603e-04 - KL loss: 569.2815 - beta: 3.2360e-05 - val_val_loss: 272307.3750 - val_val_recon_loss: 2.8456e-04 - val_val_KL loss: 569.9006 - val_beta: 3.2360e-05\n",
      "Epoch 2476/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 271013.0736 - recon_loss: 2.8320e-04 - KL loss: 571.7244 - beta: 3.2360e-05 - val_val_loss: 273412.7500 - val_val_recon_loss: 2.8571e-04 - val_val_KL loss: 572.1266 - val_beta: 3.2360e-05\n",
      "Epoch 2477/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266410.7740 - recon_loss: 2.7838e-04 - KL loss: 572.1945 - beta: 3.2360e-05 - val_val_loss: 273983.9688 - val_val_recon_loss: 2.8631e-04 - val_val_KL loss: 569.8759 - val_beta: 3.2360e-05\n",
      "Epoch 2478/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 269958.8075 - recon_loss: 2.8210e-04 - KL loss: 570.8831 - beta: 3.2360e-05\n",
      "Epoch 02478: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 269958.3858 - recon_loss: 2.8210e-04 - KL loss: 570.8830 - beta: 3.2360e-05 - val_val_loss: 272158.0938 - val_val_recon_loss: 2.8440e-04 - val_val_KL loss: 570.5865 - val_beta: 3.2360e-05\n",
      "Epoch 2479/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 267152.2721 - recon_loss: 2.7916e-04 - KL loss: 571.6440 - beta: 3.2360e-05 - val_val_loss: 271890.5000 - val_val_recon_loss: 2.8412e-04 - val_val_KL loss: 570.4731 - val_beta: 3.2360e-05\n",
      "Epoch 2480/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 264914.4218 - recon_loss: 2.7681e-04 - KL loss: 571.6652 - beta: 3.2360e-05 - val_val_loss: 271441.6875 - val_val_recon_loss: 2.8365e-04 - val_val_KL loss: 571.6622 - val_beta: 3.2360e-05\n",
      "Epoch 2481/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264594.6557 - recon_loss: 2.7648e-04 - KL loss: 571.9243 - beta: 3.2360e-05 - val_val_loss: 271470.2500 - val_val_recon_loss: 2.8368e-04 - val_val_KL loss: 572.1317 - val_beta: 3.2360e-05\n",
      "Epoch 2482/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 264677.3513 - recon_loss: 2.7656e-04 - KL loss: 572.3597 - beta: 3.2360e-05 - val_val_loss: 271775.5938 - val_val_recon_loss: 2.8400e-04 - val_val_KL loss: 571.6602 - val_beta: 3.2360e-05\n",
      "Epoch 2483/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 267485.5384 - recon_loss: 2.7951e-04 - KL loss: 572.1812 - beta: 3.2360e-05 - val_val_loss: 271435.9062 - val_val_recon_loss: 2.8364e-04 - val_val_KL loss: 571.9886 - val_beta: 3.2360e-05\n",
      "Epoch 2484/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 267280.5897 - recon_loss: 2.7929e-04 - KL loss: 572.2521 - beta: 3.2360e-05 - val_val_loss: 271738.9375 - val_val_recon_loss: 2.8396e-04 - val_val_KL loss: 571.8267 - val_beta: 3.2360e-05\n",
      "Epoch 2485/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264104.9673 - recon_loss: 2.7597e-04 - KL loss: 571.8300 - beta: 3.2360e-05 - val_val_loss: 271542.3750 - val_val_recon_loss: 2.8375e-04 - val_val_KL loss: 572.2039 - val_beta: 3.2360e-05\n",
      "Epoch 2486/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 267647.7875 - recon_loss: 2.7967e-04 - KL loss: 573.7673 - beta: 3.2360e-05 - val_val_loss: 271805.4375 - val_val_recon_loss: 2.8403e-04 - val_val_KL loss: 573.3004 - val_beta: 3.2360e-05\n",
      "Epoch 2487/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 262897.8587 - recon_loss: 2.7470e-04 - KL loss: 573.7093 - beta: 3.2360e-05 - val_val_loss: 271521.3125 - val_val_recon_loss: 2.8373e-04 - val_val_KL loss: 573.7185 - val_beta: 3.2360e-05\n",
      "Epoch 2488/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 265816.5613 - recon_loss: 2.7776e-04 - KL loss: 573.8025 - beta: 3.2360e-05\n",
      "Epoch 02488: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265817.8246 - recon_loss: 2.7776e-04 - KL loss: 573.8025 - beta: 3.2360e-05 - val_val_loss: 271657.7500 - val_val_recon_loss: 2.8387e-04 - val_val_KL loss: 574.0180 - val_beta: 3.2360e-05\n",
      "Epoch 2489/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264051.8869 - recon_loss: 2.7591e-04 - KL loss: 573.6161 - beta: 3.2360e-05 - val_val_loss: 271287.5938 - val_val_recon_loss: 2.8349e-04 - val_val_KL loss: 573.6197 - val_beta: 3.2360e-05\n",
      "Epoch 2490/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266899.6791 - recon_loss: 2.7889e-04 - KL loss: 573.6098 - beta: 3.2360e-05 - val_val_loss: 271234.5000 - val_val_recon_loss: 2.8343e-04 - val_val_KL loss: 573.7648 - val_beta: 3.2360e-05\n",
      "Epoch 2491/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266739.6813 - recon_loss: 2.7872e-04 - KL loss: 574.2400 - beta: 3.2360e-05 - val_val_loss: 271687.5938 - val_val_recon_loss: 2.8390e-04 - val_val_KL loss: 574.0987 - val_beta: 3.2360e-05\n",
      "Epoch 2492/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 264950.1915 - recon_loss: 2.7685e-04 - KL loss: 574.2711 - beta: 3.2360e-05 - val_val_loss: 271178.1250 - val_val_recon_loss: 2.8337e-04 - val_val_KL loss: 574.1799 - val_beta: 3.2360e-05\n",
      "Epoch 2493/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264772.7117 - recon_loss: 2.7666e-04 - KL loss: 574.1927 - beta: 3.2360e-05 - val_val_loss: 271273.0625 - val_val_recon_loss: 2.8347e-04 - val_val_KL loss: 574.2121 - val_beta: 3.2360e-05\n",
      "Epoch 2494/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 263978.8305 - recon_loss: 2.7583e-04 - KL loss: 573.5580 - beta: 3.2360e-05 - val_val_loss: 271153.0625 - val_val_recon_loss: 2.8334e-04 - val_val_KL loss: 573.9656 - val_beta: 3.2360e-05\n",
      "Epoch 2495/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265327.5473 - recon_loss: 2.7724e-04 - KL loss: 574.0343 - beta: 3.2360e-05 - val_val_loss: 271280.8750 - val_val_recon_loss: 2.8348e-04 - val_val_KL loss: 574.5823 - val_beta: 3.2360e-05\n",
      "Epoch 2496/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265929.4200 - recon_loss: 2.7787e-04 - KL loss: 574.3404 - beta: 3.2360e-05 - val_val_loss: 271019.4062 - val_val_recon_loss: 2.8320e-04 - val_val_KL loss: 574.4773 - val_beta: 3.2360e-05\n",
      "Epoch 2497/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266773.6585 - recon_loss: 2.7876e-04 - KL loss: 574.6724 - beta: 3.2360e-05 - val_val_loss: 270989.3750 - val_val_recon_loss: 2.8317e-04 - val_val_KL loss: 574.3219 - val_beta: 3.2360e-05\n",
      "Epoch 2498/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266501.3264 - recon_loss: 2.7847e-04 - KL loss: 574.4012 - beta: 3.2360e-05 - val_val_loss: 271163.6875 - val_val_recon_loss: 2.8336e-04 - val_val_KL loss: 574.2444 - val_beta: 3.2360e-05\n",
      "Epoch 2499/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 263995.8588 - recon_loss: 2.7585e-04 - KL loss: 574.6972 - beta: 3.2360e-05 - val_val_loss: 271235.6562 - val_val_recon_loss: 2.8343e-04 - val_val_KL loss: 574.7355 - val_beta: 3.2360e-05\n",
      "Epoch 2500/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 264336.1354 - recon_loss: 2.7621e-04 - KL loss: 574.5448 - beta: 3.2360e-05 - val_val_loss: 271165.5625 - val_val_recon_loss: 2.8336e-04 - val_val_KL loss: 574.5131 - val_beta: 3.2360e-05\n",
      "Epoch 2501/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265736.9885 - recon_loss: 2.7767e-04 - KL loss: 575.9039 - beta: 3.2360e-05 - val_val_loss: 271031.3750 - val_val_recon_loss: 2.8322e-04 - val_val_KL loss: 574.9777 - val_beta: 3.2360e-05\n",
      "Epoch 2502/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 263428.4070 - recon_loss: 2.7525e-04 - KL loss: 575.1283 - beta: 3.2360e-05\n",
      "Epoch 02502: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 263430.4929 - recon_loss: 2.7526e-04 - KL loss: 575.1286 - beta: 3.2360e-05 - val_val_loss: 271110.3750 - val_val_recon_loss: 2.8330e-04 - val_val_KL loss: 574.9935 - val_beta: 3.2360e-05\n",
      "Epoch 2503/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 266775.8994 - recon_loss: 2.7876e-04 - KL loss: 576.2317 - beta: 3.2360e-05 - val_val_loss: 271054.6250 - val_val_recon_loss: 2.8324e-04 - val_val_KL loss: 574.8461 - val_beta: 3.2360e-05\n",
      "Epoch 2504/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265205.4625 - recon_loss: 2.7712e-04 - KL loss: 575.2466 - beta: 3.2360e-05 - val_val_loss: 271098.2188 - val_val_recon_loss: 2.8329e-04 - val_val_KL loss: 574.7294 - val_beta: 3.2360e-05\n",
      "Epoch 2505/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 267734.5861 - recon_loss: 2.7976e-04 - KL loss: 575.0524 - beta: 3.2360e-05 - val_val_loss: 271221.9688 - val_val_recon_loss: 2.8342e-04 - val_val_KL loss: 574.9198 - val_beta: 3.2360e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2506/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 264340.1816 - recon_loss: 2.7621e-04 - KL loss: 574.9579 - beta: 3.2360e-05 - val_val_loss: 271151.0312 - val_val_recon_loss: 2.8334e-04 - val_val_KL loss: 574.8605 - val_beta: 3.2360e-05\n",
      "Epoch 2507/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 262778.1948 - recon_loss: 2.7457e-04 - KL loss: 575.4402 - beta: 3.2360e-05\n",
      "Epoch 02507: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 262780.0092 - recon_loss: 2.7457e-04 - KL loss: 575.4403 - beta: 3.2360e-05 - val_val_loss: 271136.1562 - val_val_recon_loss: 2.8333e-04 - val_val_KL loss: 574.9332 - val_beta: 3.2360e-05\n",
      "Epoch 2507/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 85200.3785 - recon_loss: 2.8682e-04 - KL loss: 559.0300 - beta: 5.8212e-05 - val_val_loss: 87768.2500 - val_val_recon_loss: 2.9565e-04 - val_val_KL loss: 523.1606 - val_beta: 5.8212e-05\n",
      "Epoch 2508/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 87260.9803 - recon_loss: 2.9396e-04 - KL loss: 513.9755 - beta: 5.8212e-05 - val_val_loss: 89802.1406 - val_val_recon_loss: 3.0265e-04 - val_val_KL loss: 491.0803 - val_beta: 5.8212e-05\n",
      "Epoch 2509/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 89299.9869 - recon_loss: 3.0094e-04 - KL loss: 491.1847 - beta: 5.8212e-05 - val_val_loss: 89969.7500 - val_val_recon_loss: 3.0326e-04 - val_val_KL loss: 477.4188 - val_beta: 5.8212e-05\n",
      "Epoch 2510/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 88162.8581 - recon_loss: 2.9718e-04 - KL loss: 466.4533 - beta: 5.8212e-05 - val_val_loss: 87133.0391 - val_val_recon_loss: 2.9370e-04 - val_val_KL loss: 461.5467 - val_beta: 5.8212e-05\n",
      "Epoch 2511/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 87796.6684 - recon_loss: 2.9593e-04 - KL loss: 467.7728 - beta: 5.8212e-05 - val_val_loss: 89928.8672 - val_val_recon_loss: 3.0313e-04 - val_val_KL loss: 476.1548 - val_beta: 5.8212e-05\n",
      "Epoch 2512/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 89453.9218 - recon_loss: 3.0150e-04 - KL loss: 480.6314 - beta: 5.8212e-05 - val_val_loss: 94102.7422 - val_val_recon_loss: 3.1727e-04 - val_val_KL loss: 477.1838 - val_beta: 5.8212e-05\n",
      "Epoch 2513/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 99412.2671 - recon_loss: 3.3516e-04 - KL loss: 505.3603 - beta: 5.8212e-05 - val_val_loss: 98183.1406 - val_val_recon_loss: 3.3104e-04 - val_val_KL loss: 492.1324 - val_beta: 5.8212e-05\n",
      "Epoch 2514/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95169.1400 - recon_loss: 3.2089e-04 - KL loss: 474.0261 - beta: 5.8212e-05 - val_val_loss: 91140.0391 - val_val_recon_loss: 3.0725e-04 - val_val_KL loss: 471.7370 - val_beta: 5.8212e-05\n",
      "Epoch 2515/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 89277.0118 - recon_loss: 3.0097e-04 - KL loss: 461.8648 - beta: 5.8212e-05\n",
      "Epoch 02515: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 89276.3292 - recon_loss: 3.0096e-04 - KL loss: 461.8646 - beta: 5.8212e-05 - val_val_loss: 88973.9375 - val_val_recon_loss: 2.9992e-04 - val_val_KL loss: 466.6274 - val_beta: 5.8212e-05\n",
      "Epoch 2516/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 84444.9538 - recon_loss: 2.8457e-04 - KL loss: 469.4992 - beta: 5.8212e-05 - val_val_loss: 85024.0312 - val_val_recon_loss: 2.8652e-04 - val_val_KL loss: 473.1319 - val_beta: 5.8212e-05\n",
      "Epoch 2517/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 84242.9881 - recon_loss: 2.8386e-04 - KL loss: 475.7279 - beta: 5.8212e-05 - val_val_loss: 84466.0469 - val_val_recon_loss: 2.8462e-04 - val_val_KL loss: 474.6087 - val_beta: 5.8212e-05\n",
      "Epoch 2518/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83236.9994 - recon_loss: 2.8044e-04 - KL loss: 479.0911 - beta: 5.8212e-05 - val_val_loss: 83890.5234 - val_val_recon_loss: 2.8266e-04 - val_val_KL loss: 477.6901 - val_beta: 5.8212e-05\n",
      "Epoch 2519/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 82447.2632 - recon_loss: 2.7777e-04 - KL loss: 477.9153 - beta: 5.8212e-05 - val_val_loss: 83685.6094 - val_val_recon_loss: 2.8197e-04 - val_val_KL loss: 477.0750 - val_beta: 5.8212e-05\n",
      "Epoch 2520/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81990.5922 - recon_loss: 2.7623e-04 - KL loss: 474.3635 - beta: 5.8212e-05 - val_val_loss: 84030.1797 - val_val_recon_loss: 2.8315e-04 - val_val_KL loss: 471.6098 - val_beta: 5.8212e-05\n",
      "Epoch 2521/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 82870.4948 - recon_loss: 2.7923e-04 - KL loss: 470.8229 - beta: 5.8212e-05 - val_val_loss: 82836.4375 - val_val_recon_loss: 2.7911e-04 - val_val_KL loss: 469.8975 - val_beta: 5.8212e-05\n",
      "Epoch 2522/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81624.1372 - recon_loss: 2.7500e-04 - KL loss: 472.1822 - beta: 5.8212e-05 - val_val_loss: 82527.0000 - val_val_recon_loss: 2.7805e-04 - val_val_KL loss: 475.3277 - val_beta: 5.8212e-05\n",
      "Epoch 2523/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 82398.3259 - recon_loss: 2.7762e-04 - KL loss: 471.5304 - beta: 5.8212e-05 - val_val_loss: 82506.3516 - val_val_recon_loss: 2.7798e-04 - val_val_KL loss: 474.5482 - val_beta: 5.8212e-05\n",
      "Epoch 2524/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 81238.0178 - recon_loss: 2.7369e-04 - KL loss: 471.9924 - beta: 5.8212e-05 - val_val_loss: 82681.1562 - val_val_recon_loss: 2.7860e-04 - val_val_KL loss: 467.0157 - val_beta: 5.8212e-05\n",
      "Epoch 2525/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81589.0100 - recon_loss: 2.7488e-04 - KL loss: 470.9693 - beta: 5.8212e-05 - val_val_loss: 82314.5391 - val_val_recon_loss: 2.7734e-04 - val_val_KL loss: 472.0271 - val_beta: 5.8212e-05\n",
      "Epoch 2526/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 81128.4288 - recon_loss: 2.7332e-04 - KL loss: 472.6751 - beta: 5.8212e-05 - val_val_loss: 81830.0703 - val_val_recon_loss: 2.7568e-04 - val_val_KL loss: 476.7408 - val_beta: 5.8212e-05\n",
      "Epoch 2527/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 80793.0068 - recon_loss: 2.7217e-04 - KL loss: 476.2956 - beta: 5.8212e-05 - val_val_loss: 82349.2500 - val_val_recon_loss: 2.7745e-04 - val_val_KL loss: 474.0510 - val_beta: 5.8212e-05\n",
      "Epoch 2528/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 80188.5287 - recon_loss: 2.7012e-04 - KL loss: 475.0780 - beta: 5.8212e-05 - val_val_loss: 81948.0000 - val_val_recon_loss: 2.7609e-04 - val_val_KL loss: 473.5084 - val_beta: 5.8212e-05\n",
      "Epoch 2529/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81302.3196 - recon_loss: 2.7390e-04 - KL loss: 475.0602 - beta: 5.8212e-05 - val_val_loss: 81895.3984 - val_val_recon_loss: 2.7590e-04 - val_val_KL loss: 477.1858 - val_beta: 5.8212e-05\n",
      "Epoch 2530/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80790.6785 - recon_loss: 2.7216e-04 - KL loss: 476.9966 - beta: 5.8212e-05 - val_val_loss: 82673.4766 - val_val_recon_loss: 2.7853e-04 - val_val_KL loss: 480.3725 - val_beta: 5.8212e-05\n",
      "Epoch 2531/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 81364.0261 - recon_loss: 2.7410e-04 - KL loss: 478.5328 - beta: 5.8212e-05\n",
      "Epoch 02531: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81364.1750 - recon_loss: 2.7410e-04 - KL loss: 478.5336 - beta: 5.8212e-05 - val_val_loss: 83232.7734 - val_val_recon_loss: 2.8041e-04 - val_val_KL loss: 483.4545 - val_beta: 5.8212e-05\n",
      "Epoch 2532/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80298.9295 - recon_loss: 2.7047e-04 - KL loss: 482.4870 - beta: 5.8212e-05 - val_val_loss: 81224.0000 - val_val_recon_loss: 2.7360e-04 - val_val_KL loss: 483.5193 - val_beta: 5.8212e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2533/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 80324.8313 - recon_loss: 2.7055e-04 - KL loss: 484.0915 - beta: 5.8212e-05 - val_val_loss: 81185.7969 - val_val_recon_loss: 2.7348e-04 - val_val_KL loss: 481.9892 - val_beta: 5.8212e-05\n",
      "Epoch 2534/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80672.7840 - recon_loss: 2.7174e-04 - KL loss: 483.1789 - beta: 5.8212e-05 - val_val_loss: 81078.6094 - val_val_recon_loss: 2.7311e-04 - val_val_KL loss: 485.1581 - val_beta: 5.8212e-05\n",
      "Epoch 2535/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 79657.8084 - recon_loss: 2.6830e-04 - KL loss: 483.8371 - beta: 5.8212e-05 - val_val_loss: 81365.9219 - val_val_recon_loss: 2.7407e-04 - val_val_KL loss: 486.6000 - val_beta: 5.8212e-05\n",
      "Epoch 2536/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80004.3853 - recon_loss: 2.6946e-04 - KL loss: 485.7593 - beta: 5.8212e-05 - val_val_loss: 81098.2812 - val_val_recon_loss: 2.7316e-04 - val_val_KL loss: 487.4651 - val_beta: 5.8212e-05\n",
      "Epoch 2537/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79417.6842 - recon_loss: 2.6747e-04 - KL loss: 487.0960 - beta: 5.8212e-05 - val_val_loss: 80967.5312 - val_val_recon_loss: 2.7273e-04 - val_val_KL loss: 485.9956 - val_beta: 5.8212e-05\n",
      "Epoch 2538/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80329.2431 - recon_loss: 2.7056e-04 - KL loss: 485.9922 - beta: 5.8212e-05 - val_val_loss: 80786.2344 - val_val_recon_loss: 2.7211e-04 - val_val_KL loss: 485.8827 - val_beta: 5.8212e-05\n",
      "Epoch 2539/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80105.0206 - recon_loss: 2.6980e-04 - KL loss: 486.1826 - beta: 5.8212e-05 - val_val_loss: 80873.4609 - val_val_recon_loss: 2.7241e-04 - val_val_KL loss: 486.5912 - val_beta: 5.8212e-05\n",
      "Epoch 2540/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80121.3623 - recon_loss: 2.6986e-04 - KL loss: 486.1222 - beta: 5.8212e-05 - val_val_loss: 80444.6562 - val_val_recon_loss: 2.7096e-04 - val_val_KL loss: 485.3160 - val_beta: 5.8212e-05\n",
      "Epoch 2541/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79071.7275 - recon_loss: 2.6630e-04 - KL loss: 486.2814 - beta: 5.8212e-05 - val_val_loss: 80581.9062 - val_val_recon_loss: 2.7141e-04 - val_val_KL loss: 487.9920 - val_beta: 5.8212e-05\n",
      "Epoch 2542/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 79643.1437 - recon_loss: 2.6824e-04 - KL loss: 486.4040 - beta: 5.8212e-05 - val_val_loss: 80482.1719 - val_val_recon_loss: 2.7108e-04 - val_val_KL loss: 486.7122 - val_beta: 5.8212e-05\n",
      "Epoch 2543/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79228.1205 - recon_loss: 2.6684e-04 - KL loss: 484.4713 - beta: 5.8212e-05 - val_val_loss: 80505.8984 - val_val_recon_loss: 2.7116e-04 - val_val_KL loss: 485.7428 - val_beta: 5.8212e-05\n",
      "Epoch 2544/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79829.8216 - recon_loss: 2.6887e-04 - KL loss: 487.0747 - beta: 5.8212e-05 - val_val_loss: 80698.9531 - val_val_recon_loss: 2.7182e-04 - val_val_KL loss: 484.7943 - val_beta: 5.8212e-05\n",
      "Epoch 2545/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 79222.4387 - recon_loss: 2.6682e-04 - KL loss: 485.0322 - beta: 5.8212e-05\n",
      "Epoch 02545: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79222.5676 - recon_loss: 2.6682e-04 - KL loss: 485.0328 - beta: 5.8212e-05 - val_val_loss: 80693.6016 - val_val_recon_loss: 2.7180e-04 - val_val_KL loss: 485.9272 - val_beta: 5.8212e-05\n",
      "Epoch 2546/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78894.3517 - recon_loss: 2.6570e-04 - KL loss: 486.3081 - beta: 5.8212e-05 - val_val_loss: 80227.4062 - val_val_recon_loss: 2.7022e-04 - val_val_KL loss: 485.0730 - val_beta: 5.8212e-05\n",
      "Epoch 2547/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78938.7252 - recon_loss: 2.6585e-04 - KL loss: 485.9889 - beta: 5.8212e-05 - val_val_loss: 80147.4688 - val_val_recon_loss: 2.6995e-04 - val_val_KL loss: 486.5014 - val_beta: 5.8212e-05\n",
      "Epoch 2548/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79448.4417 - recon_loss: 2.6758e-04 - KL loss: 486.3103 - beta: 5.8212e-05 - val_val_loss: 80166.2969 - val_val_recon_loss: 2.7002e-04 - val_val_KL loss: 484.8665 - val_beta: 5.8212e-05\n",
      "Epoch 2549/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 78694.8263 - recon_loss: 2.6503e-04 - KL loss: 484.9518 - beta: 5.8212e-05 - val_val_loss: 79951.5312 - val_val_recon_loss: 2.6929e-04 - val_val_KL loss: 485.5802 - val_beta: 5.8212e-05\n",
      "Epoch 2550/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78316.4568 - recon_loss: 2.6374e-04 - KL loss: 485.7831 - beta: 5.8212e-05 - val_val_loss: 79943.9062 - val_val_recon_loss: 2.6926e-04 - val_val_KL loss: 485.1504 - val_beta: 5.8212e-05\n",
      "Epoch 2551/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78116.5005 - recon_loss: 2.6307e-04 - KL loss: 484.9877 - beta: 5.8212e-05 - val_val_loss: 80053.1328 - val_val_recon_loss: 2.6963e-04 - val_val_KL loss: 485.8207 - val_beta: 5.8212e-05\n",
      "Epoch 2552/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78262.1167 - recon_loss: 2.6356e-04 - KL loss: 485.8830 - beta: 5.8212e-05 - val_val_loss: 80110.3594 - val_val_recon_loss: 2.6983e-04 - val_val_KL loss: 485.0107 - val_beta: 5.8212e-05\n",
      "Epoch 2553/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78484.5308 - recon_loss: 2.6432e-04 - KL loss: 484.9433 - beta: 5.8212e-05 - val_val_loss: 80023.7812 - val_val_recon_loss: 2.6953e-04 - val_val_KL loss: 485.8507 - val_beta: 5.8212e-05\n",
      "Epoch 2554/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78304.6504 - recon_loss: 2.6370e-04 - KL loss: 485.9629 - beta: 5.8212e-05 - val_val_loss: 79984.7734 - val_val_recon_loss: 2.6939e-04 - val_val_KL loss: 486.5711 - val_beta: 5.8212e-05\n",
      "Epoch 2555/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 78132.9516 - recon_loss: 2.6312e-04 - KL loss: 485.8073 - beta: 5.8212e-05\n",
      "Epoch 02555: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78133.3140 - recon_loss: 2.6312e-04 - KL loss: 485.8077 - beta: 5.8212e-05 - val_val_loss: 80034.7656 - val_val_recon_loss: 2.6957e-04 - val_val_KL loss: 486.1093 - val_beta: 5.8212e-05\n",
      "Epoch 2556/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79113.8664 - recon_loss: 2.6644e-04 - KL loss: 487.1619 - beta: 5.8212e-05 - val_val_loss: 79909.4062 - val_val_recon_loss: 2.6914e-04 - val_val_KL loss: 486.8780 - val_beta: 5.8212e-05\n",
      "Epoch 2557/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78289.1181 - recon_loss: 2.6365e-04 - KL loss: 486.6589 - beta: 5.8212e-05 - val_val_loss: 79879.0000 - val_val_recon_loss: 2.6904e-04 - val_val_KL loss: 486.5330 - val_beta: 5.8212e-05\n",
      "Epoch 2558/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78920.0017 - recon_loss: 2.6579e-04 - KL loss: 486.5030 - beta: 5.8212e-05 - val_val_loss: 79894.0781 - val_val_recon_loss: 2.6909e-04 - val_val_KL loss: 486.7914 - val_beta: 5.8212e-05\n",
      "Epoch 2559/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 78551.1028 - recon_loss: 2.6453e-04 - KL loss: 487.4214 - beta: 5.8212e-05 - val_val_loss: 79905.2266 - val_val_recon_loss: 2.6912e-04 - val_val_KL loss: 486.8318 - val_beta: 5.8212e-05\n",
      "Epoch 2560/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 78722.2727 - recon_loss: 2.6511e-04 - KL loss: 486.9353 - beta: 5.8212e-05 - val_val_loss: 79848.6484 - val_val_recon_loss: 2.6893e-04 - val_val_KL loss: 486.5870 - val_beta: 5.8212e-05\n",
      "Epoch 2561/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78455.8972 - recon_loss: 2.6421e-04 - KL loss: 486.6996 - beta: 5.8212e-05 - val_val_loss: 79866.1641 - val_val_recon_loss: 2.6899e-04 - val_val_KL loss: 486.7551 - val_beta: 5.8212e-05\n",
      "Epoch 2562/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 78783.2251 - recon_loss: 2.6532e-04 - KL loss: 486.8215 - beta: 5.8212e-05 - val_val_loss: 79846.4688 - val_val_recon_loss: 2.6892e-04 - val_val_KL loss: 486.8573 - val_beta: 5.8212e-05\n",
      "Epoch 2563/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78517.5607 - recon_loss: 2.6442e-04 - KL loss: 486.9429 - beta: 5.8212e-05 - val_val_loss: 79875.4531 - val_val_recon_loss: 2.6902e-04 - val_val_KL loss: 486.7966 - val_beta: 5.8212e-05\n",
      "Epoch 2564/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78436.6378 - recon_loss: 2.6415e-04 - KL loss: 487.2449 - beta: 5.8212e-05 - val_val_loss: 79875.7422 - val_val_recon_loss: 2.6902e-04 - val_val_KL loss: 486.7436 - val_beta: 5.8212e-05\n",
      "Epoch 2565/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 77971.9721 - recon_loss: 2.6257e-04 - KL loss: 486.2575 - beta: 5.8212e-05 - val_val_loss: 79824.1250 - val_val_recon_loss: 2.6885e-04 - val_val_KL loss: 486.4280 - val_beta: 5.8212e-05\n",
      "Epoch 2566/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 78379.9974 - recon_loss: 2.6396e-04 - KL loss: 485.8361 - beta: 5.8212e-05 - val_val_loss: 79809.3281 - val_val_recon_loss: 2.6880e-04 - val_val_KL loss: 486.8463 - val_beta: 5.8212e-05\n",
      "Epoch 2567/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77738.9833 - recon_loss: 2.6178e-04 - KL loss: 486.3182 - beta: 5.8212e-05 - val_val_loss: 79806.3672 - val_val_recon_loss: 2.6879e-04 - val_val_KL loss: 486.7211 - val_beta: 5.8212e-05\n",
      "Epoch 2568/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78849.8373 - recon_loss: 2.6555e-04 - KL loss: 487.0943 - beta: 5.8212e-05 - val_val_loss: 79774.1016 - val_val_recon_loss: 2.6868e-04 - val_val_KL loss: 487.2054 - val_beta: 5.8212e-05\n",
      "Epoch 2569/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78047.2842 - recon_loss: 2.6283e-04 - KL loss: 487.0622 - beta: 5.8212e-05 - val_val_loss: 79730.7109 - val_val_recon_loss: 2.6853e-04 - val_val_KL loss: 487.0976 - val_beta: 5.8212e-05\n",
      "Epoch 2570/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78188.3821 - recon_loss: 2.6331e-04 - KL loss: 486.5964 - beta: 5.8212e-05 - val_val_loss: 79751.0469 - val_val_recon_loss: 2.6860e-04 - val_val_KL loss: 486.8380 - val_beta: 5.8212e-05\n",
      "Epoch 2571/10000\n",
      "1000/1000 [==============================] - 126s 126ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2572/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2573/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2574/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05\n",
      "Epoch 02574: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2575/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2576/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2577/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2578/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2579/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05\n",
      "Epoch 02579: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2579/10000\n",
      "1000/1000 [==============================] - 127s 127ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2580/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2581/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2582/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2583/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04\n",
      "Epoch 02583: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2584/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2585/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2586/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2587/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2588/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04\n",
      "Epoch 02588: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2588/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2589/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2590/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2591/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2592/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04\n",
      "Epoch 02592: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2593/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2594/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2595/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2596/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2597/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04\n",
      "Epoch 02597: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2597/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2598/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2599/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2600/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2601/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04\n",
      "Epoch 02601: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2602/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2603/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2604/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2605/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2606/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04\n",
      "Epoch 02606: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2606/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2607/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2608/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2609/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2610/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04\n",
      "Epoch 02610: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2611/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2612/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2613/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2614/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2615/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04\n",
      "Epoch 02615: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2615/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2616/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2617/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2618/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2619/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011\n",
      "Epoch 02619: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2620/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2621/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2622/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2623/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2624/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011\n",
      "Epoch 02624: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2624/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2625/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2626/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2627/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2628/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020\n",
      "Epoch 02628: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2629/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2630/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2631/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2632/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2633/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020\n",
      "Epoch 02633: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2633/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2634/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2635/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2636/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2637/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035\n",
      "Epoch 02637: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2638/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2639/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2640/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2641/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2642/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035\n",
      "Epoch 02642: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2642/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2643/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2644/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2645/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2646/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064\n",
      "Epoch 02646: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2647/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2648/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2649/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2650/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2651/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064\n",
      "Epoch 02651: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2651/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2652/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2653/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2654/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2655/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115\n",
      "Epoch 02655: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2656/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2657/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2658/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2659/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2660/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115\n",
      "Epoch 02660: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2660/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2661/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2662/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2663/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2664/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207\n",
      "Epoch 02664: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2665/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2666/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2667/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2668/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2669/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207\n",
      "Epoch 02669: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2669/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2670/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2671/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2672/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2673/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372\n",
      "Epoch 02673: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2674/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2675/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2676/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2677/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2678/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372\n",
      "Epoch 02678: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2678/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2679/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2680/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2681/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2682/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668\n",
      "Epoch 02682: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2683/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2684/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2685/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2686/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2687/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668\n",
      "Epoch 02687: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2687/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2688/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2689/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2690/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2691/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202\n",
      "Epoch 02691: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2692/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2693/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2694/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2695/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2696/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202\n",
      "Epoch 02696: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2696/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2697/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2698/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2699/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2700/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163\n",
      "Epoch 02700: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2701/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2702/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2703/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2704/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2705/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163\n",
      "Epoch 02705: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2705/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2706/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2707/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2708/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2709/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891\n",
      "Epoch 02709: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2710/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2711/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2712/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2713/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2714/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891\n",
      "Epoch 02714: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2714/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2715/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2716/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2717/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2718/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000\n",
      "Epoch 02718: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2719/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2720/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2721/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2722/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2723/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000\n",
      "Epoch 02723: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n"
     ]
    }
   ],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_val_loss', min_delta=0., patience=10, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "\n",
    "for beta in np.concatenate((np.logspace(-4,np.log10(0.7),15),\n",
    "               np.logspace(np.log10(0.7),-5,20)[1:],\n",
    "                np.logspace(-5,np.log10(0.7),20)[1:])):\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,3e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b956daf2b92b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'my_history' is not defined"
     ]
    }
   ],
   "source": [
    "my_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.94342112e-01, -8.01087950e-03, -9.59239693e-02,\n",
       "         5.94732045e-01],\n",
       "       [ 3.20266890e-01,  1.36259927e-02,  1.71835828e-01,\n",
       "         3.20508258e-01],\n",
       "       [ 2.70634347e-02, -5.70251954e-02,  2.03458772e-01,\n",
       "         2.71074501e-02],\n",
       "       [ 1.67915073e-02, -5.83480486e-02,  1.27207984e-01,\n",
       "         1.68200987e-02],\n",
       "       [ 1.65186960e-02,  5.90673387e-02, -1.34921235e-01,\n",
       "         1.65475208e-02],\n",
       "       [ 4.71925992e-03,  9.60208657e-01,  2.47662626e-01,\n",
       "         7.06722029e-03],\n",
       "       [ 4.24085623e-03, -6.37045126e-02, -1.61667501e-01,\n",
       "         4.24946440e-03],\n",
       "       [ 3.17943365e-03, -3.47312263e-01, -8.84293165e-01,\n",
       "         3.37312991e-03],\n",
       "       [ 3.15840949e-03,  1.84969735e-02, -2.06772569e-01,\n",
       "         3.15894981e-03],\n",
       "       [ 2.70254265e-03, -8.54734571e-01,  1.71867674e-01,\n",
       "         3.75132707e-03],\n",
       "       [ 1.88874218e-03,  7.52684646e-01, -2.48769901e-01,\n",
       "         2.44950139e-03],\n",
       "       [ 1.53140233e-03, -5.97810065e-01, -2.43046386e-01,\n",
       "         2.42206498e-03],\n",
       "       [ 9.73207088e-04,  2.45642873e-03,  4.44749771e-01,\n",
       "         9.73210024e-04],\n",
       "       [ 9.48412427e-04,  1.52024855e-01,  1.22599145e-01,\n",
       "         9.59393195e-04],\n",
       "       [ 6.04432723e-04,  2.90407388e-01, -3.44442884e-01,\n",
       "         6.30100212e-04],\n",
       "       [ 3.97123277e-04, -2.05377039e-01, -9.00767365e-01,\n",
       "         4.05528033e-04],\n",
       "       [ 2.90979703e-04, -5.48501009e-01, -4.66053749e-01,\n",
       "         3.35859268e-04],\n",
       "       [ 1.98330908e-04, -2.77912763e-01, -6.78513741e-01,\n",
       "         2.06039425e-04],\n",
       "       [ 1.01832898e-04,  1.95487263e-01,  2.22977253e-01,\n",
       "         1.03784888e-04],\n",
       "       [ 4.74774761e-05,  7.16436690e-01, -1.76010884e-01,\n",
       "         6.01923111e-05],\n",
       "       [ 3.49167341e-05, -4.07727633e-01,  3.25300168e-01,\n",
       "         3.78594754e-05],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[344577]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4.75817262e-01,  2.66602718e-02,  9.90336365e-01,\n",
       "         -1.38686278e-01, -7.42237833e-01],\n",
       "        [ 3.78478884e-01, -1.23382600e-02,  9.84472615e-01,\n",
       "          1.75538232e-01, -9.71309188e-01],\n",
       "        [ 3.88847388e-02, -5.61368658e-02,  9.98044277e-01,\n",
       "          6.25109604e-02, -3.24557832e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01]],\n",
       "\n",
       "       [[ 9.21532888e-01, -3.50221957e-02,  9.99996328e-01,\n",
       "         -2.70998044e-03, -8.09998991e-02],\n",
       "        [ 1.66717116e-02,  1.09351969e-01,  9.99491337e-01,\n",
       "          3.18914776e-02, -4.08241210e+00],\n",
       "        [ 1.05050968e-02, -3.16219896e-02,  9.90696950e-01,\n",
       "          1.36086569e-01, -4.54110070e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01]],\n",
       "\n",
       "       [[ 5.27065277e-01, -4.65420074e-02,  9.92720395e-01,\n",
       "          1.20441759e-01, -6.39315265e-01],\n",
       "        [ 3.74650562e-01,  6.47182471e-02,  9.86742438e-01,\n",
       "         -1.62294057e-01, -9.79346033e-01],\n",
       "        [ 6.26936816e-02, -5.41253648e-02,  9.99769673e-01,\n",
       "          2.14616040e-02, -2.76782812e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 5.04941221e-01, -1.45442798e-01,  9.99076107e-01,\n",
       "          4.29759453e-02, -6.72323535e-01],\n",
       "        [ 4.27118872e-01,  1.54132651e-01,  9.99063081e-01,\n",
       "         -4.32777017e-02, -8.38376622e-01],\n",
       "        [ 2.77872638e-02,  2.26747931e-01,  9.97389692e-01,\n",
       "         -7.22066638e-02, -3.55423968e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01]],\n",
       "\n",
       "       [[ 5.03551740e-01, -9.53539035e-02,  9.98895825e-01,\n",
       "         -4.69801207e-02, -6.80969432e-01],\n",
       "        [ 3.49003398e-01,  1.63410362e-01,  9.95083541e-01,\n",
       "          9.90391174e-02, -1.03919140e+00],\n",
       "        [ 8.58754468e-02, -3.58760659e-02,  9.94611172e-01,\n",
       "         -1.03675535e-01, -2.45308432e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01]],\n",
       "\n",
       "       [[ 4.88555593e-01, -6.52367141e-02,  9.93347638e-01,\n",
       "          1.15154114e-01, -7.14077929e-01],\n",
       "        [ 4.14467559e-01,  7.98555861e-02,  9.91791028e-01,\n",
       "         -1.27869293e-01, -8.77397333e-01],\n",
       "        [ 7.68246266e-02, -7.69388662e-03,  9.99527208e-01,\n",
       "         -3.07467225e-02, -2.56465037e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[344599:344699]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_dir + '/model_weights_{epoch:02d}_' + str(beta) + '.hdf5'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
