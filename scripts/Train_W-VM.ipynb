{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on W-jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "# from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization\n",
    "# from tensorflow.keras.layers import Conv1D\n",
    "# from tensorflow.keras.layers import Flatten, Reshape, Lambda\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# from tensorflow.keras import Model\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "#from scipy import linalg as LA\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.tf_sinkhorn import ground_distance_tf_nograd, sinkhorn_knopp_tf_scaling_stabilized_class\n",
    "import utils.VAE_model_tools_vm\n",
    "from utils.VAE_model_tools_vm import build_and_compile_annealing_vae, betaVAEModel, reset_metrics\n",
    "\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir_path):\n",
    "    ''' Creates a directory (or nested directories) if they don't exist.\n",
    "    '''\n",
    "    if not osp.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    return dir_path\n",
    "\n",
    "def ptetaphiE_to_Epxpypz(jets):\n",
    "    pt = jets[:,:,0]\n",
    "    eta = jets[:,:,1]\n",
    "    phi = jets[:,:,2]\n",
    "    E = jets[:,:,3]\n",
    "    \n",
    "    px = pt * np.cos(phi)\n",
    "    py = pt * np.sin(phi)\n",
    "    pz = pt * np.sinh(eta)\n",
    "    \n",
    "    newjets = np.zeros(jets.shape)\n",
    "    newjets[:,:,0] = E\n",
    "    newjets[:,:,1] = px\n",
    "    newjets[:,:,2] = py\n",
    "    newjets[:,:,3] = pz\n",
    "    \n",
    "    return newjets\n",
    "\n",
    "\n",
    "\n",
    "def ptetaphiE_to_ptyphim(jets):\n",
    "    pt = jets[:,:,0]\n",
    "    eta = jets[:,:,1]\n",
    "    phi = jets[:,:,2]\n",
    "    E = jets[:,:,3]\n",
    "    \n",
    "    pz = pt * np.sinh(eta)\n",
    "    y = 0.5*np.nan_to_num(np.log((E+pz)/(E-pz)))\n",
    "    \n",
    "    msqr = np.square(E)-np.square(pt)-np.square(pz)\n",
    "    msqr[np.abs(msqr) < 1e-6] = 0\n",
    "    m = np.sqrt(msqr)\n",
    "    \n",
    "    newjets = np.zeros(jets.shape)\n",
    "    newjets[:,:,0] = pt\n",
    "    newjets[:,:,1] = y\n",
    "    newjets[:,:,2] = phi\n",
    "    newjets[:,:,3] = m\n",
    "    \n",
    "    return newjets\n",
    "    \n",
    "def ptyphim_to_ptetaphiE(jets):\n",
    "    \n",
    "    pt = jets[:,:,0]\n",
    "    y = jets[:,:,1]\n",
    "    phi = jets[:,:,2]\n",
    "    m = jets[:,:,3]\n",
    "    \n",
    "    eta = np.nan_to_num(np.arcsinh(np.sinh(y)*np.sqrt(1+np.square(m/pt))))\n",
    "    pz = pt * np.sinh(eta)\n",
    "    E = np.sqrt(np.square(pz)+np.square(pt)+np.square(m))\n",
    "    \n",
    "    newjets = np.zeros(jets.shape)\n",
    "    newjets[:,:,0] = pt\n",
    "    newjets[:,:,1] = eta\n",
    "    newjets[:,:,2] = phi\n",
    "    newjets[:,:,3] = E\n",
    "    \n",
    "    return newjets\n",
    "    \n",
    "def center_jets_ptetaphiE(jets):\n",
    "    cartesian_jets = ptetaphiE_to_Epxpypz(jets)\n",
    "    sumjet_cartesian = np.sum(cartesian_jets,axis=1)\n",
    "    \n",
    "    sumjet_phi = np.arctan2(sumjet_cartesian[:,2],sumjet_cartesian[:,1])\n",
    "    sumjet_y = 0.5*np.log((sumjet_cartesian[:,0] + sumjet_cartesian[:,-1])/(sumjet_cartesian[:,0] - sumjet_cartesian[:,-1]))\n",
    "    \n",
    "    ptyphim_jets = ptetaphiE_to_ptyphim(jets)\n",
    "    #print(ptyphim_jets[:3,:,:])\n",
    "    \n",
    "    transformed_jets = np.copy(ptyphim_jets)\n",
    "    transformed_jets[:,:,1] = ptyphim_jets[:,:,1] - sumjet_y[:,None]\n",
    "    transformed_jets[:,:,2] = ptyphim_jets[:,:,2] - sumjet_phi[:,None]\n",
    "    transformed_jets[:,:,2] = transformed_jets[:,:,2] + np.pi\n",
    "    transformed_jets[:,:,2] = np.mod(transformed_jets[:,:,2],2*np.pi)\n",
    "    transformed_jets[:,:,2] = transformed_jets[:,:,2] - np.pi\n",
    "\n",
    "    transformed_jets[transformed_jets[:,:,0] == 0] = 0\n",
    "    \n",
    "    newjets = ptyphim_to_ptetaphiE(transformed_jets)\n",
    "    return newjets\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess train/val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 8)\n",
      "Memory in GB: 0.1341104507446289\n"
     ]
    }
   ],
   "source": [
    "# path to file\n",
    "fn =  '/home/jcollins/projects/EMD_VAE/in_data/monoW-data-parton.h5'\n",
    "# fn =  '/media/jcollins/MAGIC!/monoW-data-3.h5'\n",
    "\n",
    "# Option 1: Load everything into memory\n",
    "df = pandas.read_hdf(fn,stop=1000000)\n",
    "print(df.shape)\n",
    "print(\"Memory in GB:\",sum(df.memory_usage(deep=True)) / (1024**3)+sum(df.memory_usage(deep=True)) / (1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file contains, for each event, 50 particles (with zero padding), each particle with pT, eta, phi, E.\n",
    "data = df.values.reshape((-1,2,4))\n",
    "\n",
    "# Normalize pTs so that HT = 1\n",
    "HT = np.sum(data[:,:,0],axis=-1)\n",
    "data[:,:,0] = data[:,:,0]/HT[:,None]\n",
    "data[:,:,-1] = data[:,:,-1]/HT[:,None]\n",
    "\n",
    "# Center jet (optional)\n",
    "# data = center_jets_ptetaphiE(data)\n",
    "\n",
    "# Inputs x to NN will be: pT, eta, cos(phi), sin(phi), log E\n",
    "# Separated phi into cos and sin for continuity around full detector, so make things easier for NN.\n",
    "# Also adding the log E is mainly because it seems like it should make things easier for NN, since there is an exponential spread in particle energies.\n",
    "# Feel free to change these choices as desired. E.g. px, py might be equally as good as pt, sin, cos.\n",
    "sig_input = np.zeros((len(data),2,5))\n",
    "sig_input[:,:,:2] = data[:,:,:2]\n",
    "sig_input[:,:,2] = np.cos(data[:,:,2])\n",
    "sig_input[:,:,3] = np.sin(data[:,:,2])\n",
    "sig_input[:,:,4] = np.log(data[:,:,3]+1e-8)\n",
    "\n",
    "\n",
    "data_x = sig_input\n",
    "# Event 'labels' y are [pT, eta, phi], which is used to calculate EMD to output which is also pT, eta, phi.\n",
    "data_y = data[:,:,:3]\n",
    "\n",
    "\n",
    "train_x = data_x[:500000]\n",
    "train_y = data_y[:500000]\n",
    "valid_x = data_x[500000:600000]\n",
    "valid_y = data_y[500000:600000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, 2, 5)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 2, 2048)      12288       inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 2, 2048)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 2, 2048)      0           re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 2, 1024)      2098176     dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 2, 1024)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 2, 1024)      0           re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 2, 1024)      1049600     dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 2, 1024)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 2, 1024)      0           re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 2, 1024)      1049600     dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 2, 1024)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 2, 1024)      0           re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_2 (TensorFlowOp multiple             0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_RealDiv_8 (TensorFl multiple             0           tf_op_layer_Sum_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2048)         2099200     tf_op_layer_RealDiv_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 2048)         0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 2048)         0           re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1024)         2098176     dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 1024)         0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1024)         0           re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1024)         1049600     dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 1024)         0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 1024)         0           re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 512)          524800      dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 512)          0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 512)          0           re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 512)          3584        dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder_vm_z_log_var (Dense)    (None, 1)            513         batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp_5 (TensorFlowOp multiple             0           encoder_vm_z_log_var[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BesselI0e_2 (Tensor multiple             0           tf_op_layer_Exp_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BesselI1e_2 (Tensor multiple             0           tf_op_layer_Exp_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_7 (TensorFlowOp multiple             0           tf_op_layer_Exp_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder_vm_z_mean_x (Dense)     (None, 1)            513         batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_vm_z_mean_y (Dense)     (None, 1)            513         batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_RealDiv_11 (TensorF multiple             0           tf_op_layer_BesselI1e_2[0][0]    \n",
      "                                                                 tf_op_layer_BesselI0e_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Log_6 (TensorFlowOp multiple             0           tf_op_layer_Mul_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            1026        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1)            7           encoder_vm_z_mean_x[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1)            7           encoder_vm_z_mean_y[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            1026        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_RealDiv_10 (TensorF multiple             0           tf_op_layer_BesselI0e_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_8 (TensorFlowOp multiple             0           tf_op_layer_RealDiv_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_4 (TensorFlowOp multiple             0           tf_op_layer_Log_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_encoder_vm_z_mean_2 multiple             0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_6 (TensorFlow multiple             0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square_2 (TensorFlo multiple             0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Log_7 (TensorFlowOp multiple             0           tf_op_layer_RealDiv_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_8 (TensorFlowOp multiple             0           tf_op_layer_Exp_5[0][0]          \n",
      "                                                                 tf_op_layer_Sub_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Less_2 (TensorFlowO multiple             0           tf_op_layer_Exp_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_RealDiv_9 (TensorFl multiple             0           tf_op_layer_Neg_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_8 (TensorFlowO multiple             0           tf_op_layer_encoder_vm_z_mean_2[0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_10 (TensorFlow multiple             0           tf_op_layer_Exp_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_6 (TensorFlowOp multiple             0           tf_op_layer_AddV2_6[0][0]        \n",
      "                                                                 tf_op_layer_Square_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp_4 (TensorFlowOp multiple             0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_7 (TensorFlow multiple             0           tf_op_layer_Log_7[0][0]          \n",
      "                                                                 tf_op_layer_Mul_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_SelectV2_2 (TensorF multiple             0           tf_op_layer_Less_2[0][0]         \n",
      "                                                                 tf_op_layer_RealDiv_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Log_8 (TensorFlowOp multiple             0           tf_op_layer_Cast_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_7 (TensorFlowOp multiple             0           tf_op_layer_Sub_6[0][0]          \n",
      "                                                                 tf_op_layer_Exp_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_8 (TensorFlow multiple             0           tf_op_layer_AddV2_7[0][0]        \n",
      "                                                                 tf_op_layer_SelectV2_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack_4 (TensorFlow multiple             0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack_5 (TensorFlow multiple             0           tf_op_layer_Cast_8[0][0]         \n",
      "                                                                 tf_op_layer_Exp_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            [(None, 3), (None, 3 9988629     inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_9 (TensorFlowO multiple             0           tf_op_layer_Cast_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_5 (TensorFlowOp multiple             0           tf_op_layer_Log_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_6 (TensorFlowOp multiple             0           tf_op_layer_Sub_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_11 (TensorFlow multiple             0           tf_op_layer_AddV2_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gauss_distribution (Dis ((None, 2), (None, 2 0           tf_op_layer_stack_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_vm_distribution (Distri ((None, 1), (None, 1 0           tf_op_layer_stack_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, 50, 3)        12186312    encoder[0][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 3)            0           z_mean[0][0]                     \n",
      "                                                                 tf_op_layer_Cast_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 3)            0           z_log_var[0][0]                  \n",
      "                                                                 tf_op_layer_Neg_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 3)            0           tf_op_layer_Mul_6[0][0]          \n",
      "                                                                 tf_op_layer_Cast_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 3)            0           encoder_gauss_distribution[0][0] \n",
      "                                                                 encoder_vm_distribution[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "loss (Mean)                     multiple             2                                            \n",
      "__________________________________________________________________________________________________\n",
      "recon_loss (Mean)               multiple             2                                            \n",
      "__________________________________________________________________________________________________\n",
      "KL_loss (Mean)                  multiple             2                                            \n",
      "__________________________________________________________________________________________________\n",
      "KL_VM_loss (Mean)               multiple             2                                            \n",
      "==================================================================================================\n",
      "Total params: 22,174,951\n",
      "Trainable params: 22,172,371\n",
      "Non-trainable params: 2,580\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 646ms/step - loss: 95.2586 - recon_loss: 3.5033 - KL loss: 92.5854 - KL VM loss: 0.9216 - beta: 1.0000 - alpha: 1.0000 - val_loss: 4.3783 - val_recon_loss: 4.4232 - val_KL loss: 1.0834 - val_KL VM loss: 1.0834\n"
     ]
    }
   ],
   "source": [
    "output_dir = './data/'\n",
    "\n",
    "experiment_name = 'W-parton-uncentered-vm-3'\n",
    "train_output_dir = create_dir(osp.join(output_dir, experiment_name))\n",
    "vae, encoder, decoder = build_and_compile_annealing_vae(optimizer=keras.optimizers.Adam(lr=0.001,clipnorm=0.1),\n",
    "                                    encoder_conv_layers = [2048,1024,1024,1024],\n",
    "                                    dense_size = [2048,1024,1024,512],\n",
    "                                    decoder = [4096,2048,1024,1024,512],\n",
    "                                    numItermaxinner = 10,   # EMD approximation params\n",
    "                                    numIter=10,\n",
    "                                    reg_init = 1.,\n",
    "                                    reg_final = 0.01,\n",
    "                                    stopThr=1e-3,\n",
    "                                    num_inputs=5,           # Size of x (e.g. pT, eta, sin, cos, log E)\n",
    "                                    num_particles_in=2,\n",
    "                                    latent_dim = 2,\n",
    "                                    latent_dim_vm = 1,\n",
    "                                    verbose=0,\n",
    "                                    dropout = 0.2,\n",
    "                                    renorm_clip = {'rmin':5.,'rmax':5.,'dmax':5.})    # Num particles per event.\n",
    "\n",
    "batch_size=100\n",
    "save_period=2\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=0)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(train_output_dir + '/model_weights_{epoch:02d}.hdf5', save_freq = save_period*5000, save_weights_only=True)\n",
    "reset_metrics_inst = reset_metrics()\n",
    "\n",
    "callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "\n",
    "\n",
    "# Need to train on at least one example before model params can be loaded for annoying reasons.\n",
    "\n",
    "history = vae.fit(x=train_x[:10], y=train_y[:10], batch_size=batch_size,\n",
    "                epochs=1,verbose=1,#initial_epoch=int(vae.optimizer.iterations/numbatches),\n",
    "                validation_data = (valid_x[:10],valid_y[:10]),\n",
    "                callbacks = callbacks\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.          6.30957344  3.98107171  2.51188643  1.58489319  1.\n",
      "  0.63095734  0.39810717  0.25118864  0.15848932  0.1         0.15848932\n",
      "  0.25118864  0.39810717  0.63095734  1.          1.58489319  2.51188643\n",
      "  3.98107171  6.30957344 10.          6.30957344  3.98107171  2.51188643\n",
      "  1.58489319  1.          0.63095734  0.39810717  0.25118864  0.15848932\n",
      "  0.1         0.15848932  0.25118864  0.39810717  0.63095734  1.\n",
      "  1.58489319  2.51188643  3.98107171  6.30957344 10.        ]\n"
     ]
    }
   ],
   "source": [
    "betas = np.concatenate((np.logspace(1.,-1,11),\n",
    "                       np.flip(np.logspace(1,-1,11))[1:],\n",
    "                       np.logspace(1.,-1,11)[1:],\n",
    "                       np.flip(np.logspace(1,-1,11))[1:]))\n",
    "print(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.        ,  7.94328235,  6.30957344,  5.01187234,  3.98107171,\n",
       "        3.16227766,  2.51188643,  1.99526231,  1.58489319,  1.25892541,\n",
       "        1.        ,  0.79432823,  0.63095734,  0.50118723,  0.39810717,\n",
       "        0.31622777,  0.25118864,  0.19952623,  0.15848932,  0.12589254,\n",
       "        0.1       ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(1.,-1,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(betas)\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9810717055349722"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 4e+00\n",
    "vae.load_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Changing beta to 3.9810717055349722\n",
      "Epoch 191/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1220 - recon_loss: 3.7663 - KL loss: 3.7603e-05 - KL VM loss: 0.0031 - beta: 3.9811 - alpha: 1.0000 - val_loss: 0.1293 - val_recon_loss: 3.9004 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 192/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1302 - recon_loss: 3.7681 - KL loss: 0.0218 - KL VM loss: 0.0032 - beta: 3.9811 - alpha: 1.0000 - val_loss: 0.1287 - val_recon_loss: 3.8803 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 193/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1222 - recon_loss: 3.7741 - KL loss: 2.7862e-05 - KL VM loss: 0.0031 - beta: 3.9811 - alpha: 1.0000 - val_loss: 0.1292 - val_recon_loss: 3.8963 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 194/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1230 - recon_loss: 3.7696 - KL loss: 6.7177e-04 - KL VM loss: 0.0031 - beta: 3.9811 - alpha: 1.0000 - val_loss: 0.1286 - val_recon_loss: 3.8793 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 195/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1220 - recon_loss: 3.7691 - KL loss: 2.5601e-06 - KL VM loss: 0.0031 - beta: 3.9811 - alpha: 1.0000 - val_loss: 0.1292 - val_recon_loss: 3.8977 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 196/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1220 - recon_loss: 3.7664 - KL loss: 5.2227e-07 - KL VM loss: 0.0031 - beta: 3.9811 - alpha: 1.0000\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1220 - recon_loss: 3.7664 - KL loss: 5.2211e-07 - KL VM loss: 0.0031 - beta: 3.9811 - alpha: 1.0000 - val_loss: 0.1289 - val_recon_loss: 3.8865 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 197/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1224 - recon_loss: 3.7737 - KL loss: 8.8852e-05 - KL VM loss: 0.0031 - beta: 3.9811 - alpha: 1.0000 - val_loss: 0.1287 - val_recon_loss: 3.8814 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 198/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1219 - recon_loss: 3.7636 - KL loss: 9.0347e-08 - KL VM loss: 0.0031 - beta: 3.9811 - alpha: 1.0000 - val_loss: 0.1287 - val_recon_loss: 3.8826 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 199/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2084 - recon_loss: 3.7718 - KL loss: 0.0136 - KL VM loss: 0.0031 - beta: 3.9811 - alpha: 1.0000 - val_loss: 0.1317 - val_recon_loss: 3.8833 - val_KL loss: 0.0046 - val_KL VM loss: 0.0046\n",
      "Epoch 200/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1230 - recon_loss: 3.7701 - KL loss: 0.0012 - KL VM loss: 0.0031 - beta: 3.9811 - alpha: 1.0000\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 9.999999259090306e-06.\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1230 - recon_loss: 3.7703 - KL loss: 0.0012 - KL VM loss: 0.0031 - beta: 3.9811 - alpha: 1.0000 - val_loss: 0.1294 - val_recon_loss: 3.8775 - val_KL loss: 0.0035 - val_KL VM loss: 0.0035\n",
      "\n",
      " Changing beta to 2.5118864315095797\n",
      "Epoch 200/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.9967 - recon_loss: 3.7701 - KL loss: 0.6543 - KL VM loss: 0.0032 - beta: 2.5119 - alpha: 1.0000 - val_loss: 0.3448 - val_recon_loss: 3.8696 - val_KL loss: 0.0191 - val_KL VM loss: 0.0191\n",
      "Epoch 201/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 2.7795 - recon_loss: 3.7665 - KL loss: 0.7962 - KL VM loss: 0.0032 - beta: 2.5119 - alpha: 1.0000 - val_loss: 0.4117 - val_recon_loss: 3.8738 - val_KL loss: 0.0524 - val_KL VM loss: 0.0524\n",
      "Epoch 202/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.3643 - recon_loss: 3.7670 - KL loss: 0.0790 - KL VM loss: 0.0032 - beta: 2.5119 - alpha: 1.0000 - val_loss: 0.4044 - val_recon_loss: 3.9122 - val_KL loss: 0.0472 - val_KL VM loss: 0.0472\n",
      "Epoch 203/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.3442 - recon_loss: 3.7688 - KL loss: 0.0446 - KL VM loss: 0.0032 - beta: 2.5119 - alpha: 1.0000 - val_loss: 0.3863 - val_recon_loss: 3.8825 - val_KL loss: 0.0393 - val_KL VM loss: 0.0393\n",
      "Epoch 204/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.3372 - recon_loss: 3.7689 - KL loss: 0.0370 - KL VM loss: 0.0033 - beta: 2.5119 - alpha: 1.0000\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.3372 - recon_loss: 3.7689 - KL loss: 0.0370 - KL VM loss: 0.0033 - beta: 2.5119 - alpha: 1.0000 - val_loss: 0.3676 - val_recon_loss: 3.9016 - val_KL loss: 0.0292 - val_KL VM loss: 0.0292\n",
      "Epoch 205/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.3267 - recon_loss: 3.7706 - KL loss: 0.0258 - KL VM loss: 0.0031 - beta: 2.5119 - alpha: 1.0000 - val_loss: 0.3549 - val_recon_loss: 3.8802 - val_KL loss: 0.0237 - val_KL VM loss: 0.0237\n",
      "Epoch 206/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.3213 - recon_loss: 3.7660 - KL loss: 0.0209 - KL VM loss: 0.0031 - beta: 2.5119 - alpha: 1.0000"
     ]
    }
   ],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "# init_epoch=0\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=4, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0., patience=6, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "# init_epoch=0\n",
    "\n",
    "for beta in betas[2:]:\n",
    "    \n",
    "    print(\"\\n Changing beta to\", beta)\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "#             modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,1e-4)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.99526231  1.58489319  1.25892541  1.          0.79432823  0.63095734\n",
      "  0.50118723  0.39810717  0.31622777  0.25118864  0.19952623  0.15848932\n",
      "  0.12589254  0.1         0.15848932  0.25118864  0.39810717  0.63095734\n",
      "  1.          1.58489319  2.51188643  3.98107171  6.30957344 10.\n",
      "  6.30957344  3.98107171  2.51188643  1.58489319  1.          0.63095734\n",
      "  0.39810717  0.25118864  0.15848932  0.1         0.15848932  0.25118864\n",
      "  0.39810717  0.63095734  1.          1.58489319  2.51188643  3.98107171\n",
      "  6.30957344 10.        ]\n"
     ]
    }
   ],
   "source": [
    "betas = np.concatenate((np.logspace(1.,-1,21)[7:],\n",
    "                       np.flip(np.logspace(1,-1,11))[1:],\n",
    "                       np.logspace(1.,-1,11)[1:],\n",
    "                       np.flip(np.logspace(1,-1,11))[1:]))\n",
    "print(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Setting beta to 1.9952623149688793\n",
      "Epoch 1/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.4937 - recon_loss: 3.7788 - KL loss: 0.0323 - KL VM loss: 0.0167 - beta: 1.9953 - alpha: 1.0000 - val_loss: 0.4945 - val_recon_loss: 3.8693 - val_KL loss: 0.0043 - val_KL VM loss: 0.0043\n",
      "Epoch 2/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.4825 - recon_loss: 3.7868 - KL loss: 0.0042 - KL VM loss: 0.0033 - beta: 1.9953 - alpha: 1.0000 - val_loss: 0.4944 - val_recon_loss: 3.8860 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 3/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.4786 - recon_loss: 3.7658 - KL loss: 0.0027 - KL VM loss: 0.0032 - beta: 1.9953 - alpha: 1.0000 - val_loss: 0.4947 - val_recon_loss: 3.8827 - val_KL loss: 0.0035 - val_KL VM loss: 0.0035\n",
      "Epoch 4/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.4794 - recon_loss: 3.7760 - KL loss: 0.0021 - KL VM loss: 0.0032 - beta: 1.9953 - alpha: 1.0000 - val_loss: 0.4966 - val_recon_loss: 3.9025 - val_KL loss: 0.0032 - val_KL VM loss: 0.0032\n",
      "Epoch 5/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.4778 - recon_loss: 3.7659 - KL loss: 0.0018 - KL VM loss: 0.0032 - beta: 1.9953 - alpha: 1.0000 - val_loss: 0.4945 - val_recon_loss: 3.8870 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 6/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.4784 - recon_loss: 3.7724 - KL loss: 0.0015 - KL VM loss: 0.0032 - beta: 1.9953 - alpha: 1.0000\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.4784 - recon_loss: 3.7724 - KL loss: 0.0015 - KL VM loss: 0.0032 - beta: 1.9953 - alpha: 1.0000 - val_loss: 0.4959 - val_recon_loss: 3.8984 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 7/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.4781 - recon_loss: 3.7713 - KL loss: 0.0013 - KL VM loss: 0.0032 - beta: 1.9953 - alpha: 1.0000 - val_loss: 0.4937 - val_recon_loss: 3.8811 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 8/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.4782 - recon_loss: 3.7722 - KL loss: 0.0012 - KL VM loss: 0.0032 - beta: 1.9953 - alpha: 1.0000 - val_loss: 0.4955 - val_recon_loss: 3.8949 - val_KL loss: 0.0032 - val_KL VM loss: 0.0032\n",
      "Epoch 9/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.4776 - recon_loss: 3.7684 - KL loss: 0.0012 - KL VM loss: 0.0032 - beta: 1.9953 - alpha: 1.0000 - val_loss: 0.4940 - val_recon_loss: 3.8836 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 10/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.4776 - recon_loss: 3.7688 - KL loss: 0.0011 - KL VM loss: 0.0032 - beta: 1.9953 - alpha: 1.0000 - val_loss: 0.4943 - val_recon_loss: 3.8855 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 11/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.4776 - recon_loss: 3.7691 - KL loss: 0.0011 - KL VM loss: 0.0032 - beta: 1.9953 - alpha: 1.0000\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999259090306e-06.\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.4776 - recon_loss: 3.7691 - KL loss: 0.0011 - KL VM loss: 0.0032 - beta: 1.9953 - alpha: 1.0000 - val_loss: 0.4940 - val_recon_loss: 3.8830 - val_KL loss: 0.0032 - val_KL VM loss: 0.0032\n",
      "Epoch 12/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.4780 - recon_loss: 3.7725 - KL loss: 0.0010 - KL VM loss: 0.0032 - beta: 1.9953 - alpha: 1.0000 - val_loss: 0.4944 - val_recon_loss: 3.8868 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 13/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.4782 - recon_loss: 3.7747 - KL loss: 9.9219e-04 - KL VM loss: 0.0032 - beta: 1.9953 - alpha: 1.0000 - val_loss: 0.4943 - val_recon_loss: 3.8857 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "\n",
      " Setting beta to 1.5848931924611134\n",
      "Epoch 13/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.7538 - recon_loss: 3.7665 - KL loss: 9.7987e-04 - KL VM loss: 0.0032 - beta: 1.5849 - alpha: 1.0000 - val_loss: 0.7803 - val_recon_loss: 3.8887 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 14/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.7544 - recon_loss: 3.7701 - KL loss: 8.6271e-04 - KL VM loss: 0.0031 - beta: 1.5849 - alpha: 1.0000 - val_loss: 0.7811 - val_recon_loss: 3.8927 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 15/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.7534 - recon_loss: 3.7651 - KL loss: 8.0451e-04 - KL VM loss: 0.0031 - beta: 1.5849 - alpha: 1.0000 - val_loss: 0.7786 - val_recon_loss: 3.8802 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 16/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.7564 - recon_loss: 3.7805 - KL loss: 7.5754e-04 - KL VM loss: 0.0031 - beta: 1.5849 - alpha: 1.0000 - val_loss: 0.7809 - val_recon_loss: 3.8919 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 17/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.7543 - recon_loss: 3.7704 - KL loss: 6.9851e-04 - KL VM loss: 0.0031 - beta: 1.5849 - alpha: 1.0000 - val_loss: 0.7795 - val_recon_loss: 3.8843 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 18/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.7545 - recon_loss: 3.7713 - KL loss: 6.5192e-04 - KL VM loss: 0.0031 - beta: 1.5849 - alpha: 1.0000 - val_loss: 0.7814 - val_recon_loss: 3.8939 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 19/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.7531 - recon_loss: 3.7646 - KL loss: 6.2387e-04 - KL VM loss: 0.0031 - beta: 1.5849 - alpha: 1.0000\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.7531 - recon_loss: 3.7646 - KL loss: 6.2386e-04 - KL VM loss: 0.0031 - beta: 1.5849 - alpha: 1.0000 - val_loss: 0.7810 - val_recon_loss: 3.8921 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 20/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.7538 - recon_loss: 3.7683 - KL loss: 5.8587e-04 - KL VM loss: 0.0031 - beta: 1.5849 - alpha: 1.0000 - val_loss: 0.7794 - val_recon_loss: 3.8841 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 21/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.7544 - recon_loss: 3.7714 - KL loss: 5.6559e-04 - KL VM loss: 0.0031 - beta: 1.5849 - alpha: 1.0000 - val_loss: 0.7803 - val_recon_loss: 3.8886 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "\n",
      " Setting beta to 1.258925411794167\n",
      "Epoch 21/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.1936 - recon_loss: 3.7716 - KL loss: 5.5448e-04 - KL VM loss: 0.0031 - beta: 1.2589 - alpha: 1.0000 - val_loss: 1.2298 - val_recon_loss: 3.8783 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 22/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.1930 - recon_loss: 3.7700 - KL loss: 5.3429e-04 - KL VM loss: 0.0031 - beta: 1.2589 - alpha: 1.0000 - val_loss: 1.2325 - val_recon_loss: 3.8867 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 23/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.1931 - recon_loss: 3.7703 - KL loss: 5.0008e-04 - KL VM loss: 0.0031 - beta: 1.2589 - alpha: 1.0000 - val_loss: 1.2305 - val_recon_loss: 3.8804 - val_KL loss: 0.0032 - val_KL VM loss: 0.0032\n",
      "Epoch 24/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.1932 - recon_loss: 3.7709 - KL loss: 4.7705e-04 - KL VM loss: 0.0031 - beta: 1.2589 - alpha: 1.0000 - val_loss: 1.2334 - val_recon_loss: 3.8897 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 25/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1.1918 - recon_loss: 3.7663 - KL loss: 4.3514e-04 - KL VM loss: 0.0031 - beta: 1.2589 - alpha: 1.0000\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.1918 - recon_loss: 3.7663 - KL loss: 4.3513e-04 - KL VM loss: 0.0031 - beta: 1.2589 - alpha: 1.0000 - val_loss: 1.2328 - val_recon_loss: 3.8878 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.1911 - recon_loss: 3.7644 - KL loss: 4.0446e-04 - KL VM loss: 0.0031 - beta: 1.2589 - alpha: 1.0000 - val_loss: 1.2319 - val_recon_loss: 3.8850 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 27/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.1951 - recon_loss: 3.7769 - KL loss: 3.9802e-04 - KL VM loss: 0.0031 - beta: 1.2589 - alpha: 1.0000 - val_loss: 1.2326 - val_recon_loss: 3.8871 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031_loss: 3.7778 - KL loss: 3.9809e-04 - KL VM loss: 0.0031 - beta: 1.\n",
      "\n",
      " Setting beta to 1.0\n",
      "Epoch 27/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.8879 - recon_loss: 3.7687 - KL loss: 3.9012e-04 - KL VM loss: 0.0031 - beta: 1.0000 - alpha: 1.0000 - val_loss: 1.9474 - val_recon_loss: 3.8822 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 28/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.8873 - recon_loss: 3.7676 - KL loss: 3.6276e-04 - KL VM loss: 0.0031 - beta: 1.0000 - alpha: 1.0000 - val_loss: 1.9496 - val_recon_loss: 3.8866 - val_KL loss: 0.0032 - val_KL VM loss: 0.0032\n",
      "Epoch 29/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.8891 - recon_loss: 3.7712 - KL loss: 3.5937e-04 - KL VM loss: 0.0031 - beta: 1.0000 - alpha: 1.0000 - val_loss: 1.9497 - val_recon_loss: 3.8868 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 30/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.8892 - recon_loss: 3.7714 - KL loss: 3.1301e-04 - KL VM loss: 0.0031 - beta: 1.0000 - alpha: 1.0000 - val_loss: 1.9501 - val_recon_loss: 3.8876 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 31/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1.8880 - recon_loss: 3.7691 - KL loss: 2.9484e-04 - KL VM loss: 0.0031 - beta: 1.0000 - alpha: 1.0000\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.8880 - recon_loss: 3.7692 - KL loss: 2.9482e-04 - KL VM loss: 0.0031 - beta: 1.0000 - alpha: 1.0000 - val_loss: 1.9502 - val_recon_loss: 3.8879 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 32/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.8878 - recon_loss: 3.7689 - KL loss: 2.7014e-04 - KL VM loss: 0.0031 - beta: 1.0000 - alpha: 1.0000 - val_loss: 1.9475 - val_recon_loss: 3.8826 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 33/10000\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.8880 - recon_loss: 3.7692 - KL loss: 2.6446e-04 - KL VM loss: 0.0031 - beta: 1.0000 - alpha: 1.0000 - val_loss: 1.9479 - val_recon_loss: 3.8834 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "\n",
      " Setting beta to 0.7943282347242814\n",
      "Epoch 33/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 2.9937 - recon_loss: 3.7736 - KL loss: 2.6015e-04 - KL VM loss: 0.0031 - beta: 0.7943 - alpha: 1.0000 - val_loss: 3.0854 - val_recon_loss: 3.8856 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 34/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 2.9912 - recon_loss: 3.7704 - KL loss: 2.9162e-04 - KL VM loss: 0.0031 - beta: 0.7943 - alpha: 1.0000 - val_loss: 3.0806 - val_recon_loss: 3.8796 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 35/10000\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 2.9875 - recon_loss: 3.7657 - KL loss: 2.3712e-04 - KL VM loss: 0.0031 - beta: 0.7943 - alpha: 1.0000 - val_loss: 3.0893 - val_recon_loss: 3.8905 - val_KL loss: 0.0031 - val_KL VM loss: 0.0031\n",
      "Epoch 36/10000\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 2.7925 - recon_loss: 3.2970 - KL loss: 0.0357 - KL VM loss: 0.0032 - beta: 0.7943 - alpha: 1.0000 - val_loss: 3.0787 - val_recon_loss: 2.5039 - val_KL loss: 0.5473 - val_KL VM loss: 0.5473\n",
      "Epoch 37/10000\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 2.3863 - recon_loss: 2.3605 - KL loss: 0.5169 - KL VM loss: 0.0033 - beta: 0.7943 - alpha: 1.0000 - val_loss: 3.1141 - val_recon_loss: 2.5565 - val_KL loss: 0.5441 - val_KL VM loss: 0.5441\n",
      "Epoch 38/10000\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 2.3674 - recon_loss: 2.3219 - KL loss: 0.5267 - KL VM loss: 0.0032 - beta: 0.7943 - alpha: 1.0000 - val_loss: 2.9685 - val_recon_loss: 2.3139 - val_KL loss: 0.5674 - val_KL VM loss: 0.5674\n",
      "Epoch 39/10000\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 2.3656 - recon_loss: 2.3234 - KL loss: 0.5165 - KL VM loss: 0.0032 - beta: 0.7943 - alpha: 1.0000 - val_loss: 2.8214 - val_recon_loss: 2.1873 - val_KL loss: 0.5440 - val_KL VM loss: 0.54407943 - alpha:  - ETA: 11s - loss: 2.3752 - recon_loss: 2.3354 - KL loss: 0.5127 - KL VM loss: 0.0032 - beta: 0.7943 - alpha: 1 - ETA: 10s - loss: 2.3751 - rec\n",
      "Epoch 40/10000\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 2.3609 - recon_loss: 2.3118 - KL loss: 0.5202 - KL VM loss: 0.0032 - beta: 0.7943 - alpha: 1.0000 - val_loss: 2.9600 - val_recon_loss: 2.4154 - val_KL loss: 0.5230 - val_KL VM loss: 0.5230\n",
      "Epoch 41/10000\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 2.3544 - recon_loss: 2.3164 - KL loss: 0.5110 - KL VM loss: 0.0032 - beta: 0.7943 - alpha: 1.0000 - val_loss: 3.1594 - val_recon_loss: 2.5262 - val_KL loss: 0.5788 - val_KL VM loss: 0.5788: 2.352\n",
      "Epoch 42/10000\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 2.3512 - recon_loss: 2.3006 - KL loss: 0.5233 - KL VM loss: 0.0032 - beta: 0.7943 - alpha: 1.0000 - val_loss: 2.9018 - val_recon_loss: 2.2476 - val_KL loss: 0.5603 - val_KL VM loss: 0.5603\n",
      "Epoch 43/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3504 - recon_loss: 2.3014 - KL loss: 0.5178 - KL VM loss: 0.0032 - beta: 0.7943 - alpha: 1.0000\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 2.3504 - recon_loss: 2.3014 - KL loss: 0.5178 - KL VM loss: 0.0032 - beta: 0.7943 - alpha: 1.0000 - val_loss: 2.9659 - val_recon_loss: 2.3461 - val_KL loss: 0.5534 - val_KL VM loss: 0.5534\n",
      "Epoch 44/10000\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 2.3453 - recon_loss: 2.3014 - KL loss: 0.5208 - KL VM loss: 0.0032 - beta: 0.7943 - alpha: 1.0000 - val_loss: 3.0576 - val_recon_loss: 2.4760 - val_KL loss: 0.5478 - val_KL VM loss: 0.5478\n",
      "Epoch 45/10000\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 2.3479 - recon_loss: 2.2971 - KL loss: 0.5230 - KL VM loss: 0.0032 - beta: 0.7943 - alpha: 1.0000 - val_loss: 2.9823 - val_recon_loss: 2.4787 - val_KL loss: 0.5090 - val_KL VM loss: 0.5090\n",
      "\n",
      " Setting beta to 0.630957344480193\n",
      "Epoch 45/10000\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 3.3859 - recon_loss: 2.1672 - KL loss: 0.6470 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000 - val_loss: 4.2148 - val_recon_loss: 2.2066 - val_KL loss: 0.7217 - val_KL VM loss: 0.7217\n",
      "Epoch 46/10000\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 3.3951 - recon_loss: 2.1696 - KL loss: 0.6723 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000 - val_loss: 4.2924 - val_recon_loss: 2.3899 - val_KL loss: 0.6454 - val_KL VM loss: 0.6454\n",
      "Epoch 47/10000\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 3.3973 - recon_loss: 2.1626 - KL loss: 0.6711 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000 - val_loss: 4.1372 - val_recon_loss: 2.1775 - val_KL loss: 0.7012 - val_KL VM loss: 0.7012\n",
      "Epoch 48/10000\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 3.3638 - recon_loss: 2.1538 - KL loss: 0.6660 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000 - val_loss: 4.0918 - val_recon_loss: 2.2245 - val_KL loss: 0.6490 - val_KL VM loss: 0.6490\n",
      "Epoch 49/10000\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 3.3812 - recon_loss: 2.1535 - KL loss: 0.6673 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000 - val_loss: 4.1493 - val_recon_loss: 2.2262 - val_KL loss: 0.6766 - val_KL VM loss: 0.6766\n",
      "Epoch 50/10000\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 3.3754 - recon_loss: 2.1451 - KL loss: 0.6758 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000 - val_loss: 4.3375 - val_recon_loss: 2.1976 - val_KL loss: 0.7887 - val_KL VM loss: 0.7887\n",
      "Epoch 51/10000\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 3.3807 - recon_loss: 2.1542 - KL loss: 0.6701 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000 - val_loss: 4.0168 - val_recon_loss: 2.1044 - val_KL loss: 0.6869 - val_KL VM loss: 0.6869\n",
      "Epoch 52/10000\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 3.3803 - recon_loss: 2.1568 - KL loss: 0.6573 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000 - val_loss: 4.3275 - val_recon_loss: 2.4017 - val_KL loss: 0.6555 - val_KL VM loss: 0.6555\n",
      "Epoch 53/10000\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 3.3748 - recon_loss: 2.1538 - KL loss: 0.6776 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000 - val_loss: 4.2025 - val_recon_loss: 2.2323 - val_KL loss: 0.6994 - val_KL VM loss: 0.6994\n",
      "Epoch 54/10000\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 3.3913 - recon_loss: 2.1670 - KL loss: 0.6593 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000 - val_loss: 4.0265 - val_recon_loss: 2.1854 - val_KL loss: 0.6409 - val_KL VM loss: 0.6409\n",
      "Epoch 55/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3.3789 - recon_loss: 2.1680 - KL loss: 0.6447 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 3.3789 - recon_loss: 2.1680 - KL loss: 0.6447 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000 - val_loss: 4.1369 - val_recon_loss: 2.1315 - val_KL loss: 0.7299 - val_KL VM loss: 0.7299\n",
      "Epoch 56/10000\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 3.3634 - recon_loss: 2.1446 - KL loss: 0.6720 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000 - val_loss: 4.2314 - val_recon_loss: 2.2395 - val_KL loss: 0.7094 - val_KL VM loss: 0.7094\n",
      "Epoch 57/10000\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 3.3761 - recon_loss: 2.1572 - KL loss: 0.6676 - KL VM loss: 0.0032 - beta: 0.6310 - alpha: 1.0000 - val_loss: 4.3464 - val_recon_loss: 2.4118 - val_KL loss: 0.6586 - val_KL VM loss: 0.6586\n",
      "\n",
      " Setting beta to 0.5011872336272722\n",
      "Epoch 57/10000\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 4.9502 - recon_loss: 2.0984 - KL loss: 0.7536 - KL VM loss: 0.0032 - beta: 0.5012 - alpha: 1.0000 - val_loss: 5.7943 - val_recon_loss: 2.1232 - val_KL loss: 0.7840 - val_KL VM loss: 0.7840\n",
      "Epoch 58/10000\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 4.9085 - recon_loss: 2.0630 - KL loss: 0.7914 - KL VM loss: 0.0032 - beta: 0.5012 - alpha: 1.0000 - val_loss: 6.0142 - val_recon_loss: 2.1581 - val_KL loss: 0.8593 - val_KL VM loss: 0.8593\n",
      "Epoch 59/10000\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 4.9399 - recon_loss: 2.0941 - KL loss: 0.7675 - KL VM loss: 0.0032 - beta: 0.5012 - alpha: 1.0000 - val_loss: 5.9881 - val_recon_loss: 2.1720 - val_KL loss: 0.8323 - val_KL VM loss: 0.8323\n",
      "Epoch 60/10000\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 4.9274 - recon_loss: 2.0693 - KL loss: 0.8077 - KL VM loss: 0.0032 - beta: 0.5012 - alpha: 1.0000 - val_loss: 5.8732 - val_recon_loss: 2.1405 - val_KL loss: 0.8063 - val_KL VM loss: 0.8063\n",
      "Epoch 61/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.9267 - recon_loss: 2.0761 - KL loss: 0.7880 - KL VM loss: 0.0032 - beta: 0.5012 - alpha: 1.0000\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 4.9267 - recon_loss: 2.0761 - KL loss: 0.7880 - KL VM loss: 0.0032 - beta: 0.5012 - alpha: 1.0000 - val_loss: 6.1015 - val_recon_loss: 2.2051 - val_KL loss: 0.8561 - val_KL VM loss: 0.8561\n",
      "Epoch 62/10000\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 4.9149 - recon_loss: 2.0743 - KL loss: 0.7914 - KL VM loss: 0.0032 - beta: 0.5012 - alpha: 1.0000 - val_loss: 5.9809 - val_recon_loss: 2.1701 - val_KL loss: 0.8306 - val_KL VM loss: 0.8306\n",
      "Epoch 63/10000\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 4.9073 - recon_loss: 2.0586 - KL loss: 0.8075 - KL VM loss: 0.0032 - beta: 0.5012 - alpha: 1.0000 - val_loss: 5.9104 - val_recon_loss: 2.1568 - val_KL loss: 0.8086 - val_KL VM loss: 0.8086\n",
      "\n",
      " Setting beta to 0.39810717055349715\n",
      "Epoch 63/10000\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 5.5527 - recon_loss: 1.2478 - KL loss: 1.2731 - KL VM loss: 0.0032 - beta: 0.3981 - alpha: 1.0000 - val_loss: 6.4793 - val_recon_loss: 0.8027 - val_KL loss: 1.9735 - val_KL VM loss: 1.9735\n",
      "Epoch 64/10000\n",
      " 374/1000 [==========>...................] - ETA: 14s - loss: 4.7827 - recon_loss: 0.8685 - KL loss: 2.0249 - KL VM loss: 0.0033 - beta: 0.3981 - alpha: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-0c009032c184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "init_epoch=0\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=4, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0., patience=6, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "# init_epoch=0\n",
    "\n",
    "for beta in betas:\n",
    "    print(\"\\n Setting beta to\", beta)\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "#             modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,1e-4)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "#     vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(betas)\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5253/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1669589.6191 - recon_loss: 1.6689e-04 - KL loss: 727.0038 - beta: 1.0000e-05 - val_loss: 1795552.2500 - val_recon_loss: 1.7949e-04 - val_KL loss: 689.0992 - val_beta: 1.0000e-05\n",
      "Epoch 5254/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1613050.6335 - recon_loss: 1.6123e-04 - KL loss: 705.3825 - beta: 1.0000e-05 - val_loss: 1789260.7500 - val_recon_loss: 1.7886e-04 - val_KL loss: 690.1434 - val_beta: 1.0000e-05\n",
      "Epoch 5255/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1594401.8824 - recon_loss: 1.5937e-04 - KL loss: 704.6334 - beta: 1.0000e-05 - val_loss: 1766201.7500 - val_recon_loss: 1.7655e-04 - val_KL loss: 675.4101 - val_beta: 1.0000e-05\n",
      "Epoch 5256/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1601507.6085 - recon_loss: 1.6008e-04 - KL loss: 699.3842 - beta: 1.0000e-05 - val_loss: 1829615.7500 - val_recon_loss: 1.8289e-04 - val_KL loss: 698.7684 - val_beta: 1.0000e-05\n",
      "Epoch 5257/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1628575.5932 - recon_loss: 1.6279e-04 - KL loss: 710.3479 - beta: 1.0000e-05 - val_loss: 1729732.8750 - val_recon_loss: 1.7291e-04 - val_KL loss: 678.2570 - val_beta: 1.0000e-05\n",
      "Epoch 5258/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1575949.1643 - recon_loss: 1.5753e-04 - KL loss: 697.0012 - beta: 1.0000e-05 - val_loss: 1825873.6250 - val_recon_loss: 1.8252e-04 - val_KL loss: 674.8643 - val_beta: 1.0000e-05\n",
      "Epoch 5259/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1622412.4291 - recon_loss: 1.6217e-04 - KL loss: 693.9299 - beta: 1.0000e-05 - val_loss: 1751667.8750 - val_recon_loss: 1.7510e-04 - val_KL loss: 669.9830 - val_beta: 1.0000e-05\n",
      "Epoch 5260/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1582323.9527 - recon_loss: 1.5816e-04 - KL loss: 686.7581 - beta: 1.0000e-05 - val_loss: 1769050.1250 - val_recon_loss: 1.7684e-04 - val_KL loss: 673.3507 - val_beta: 1.0000e-05\n",
      "Epoch 5261/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 1574772.8757 - recon_loss: 1.5741e-04 - KL loss: 677.1355 - beta: 1.0000e-05 - val_loss: 1761332.1250 - val_recon_loss: 1.7607e-04 - val_KL loss: 658.5458 - val_beta: 1.0000e-05\n",
      "Epoch 5262/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1598623.3964 - recon_loss: 1.5980e-04 - KL loss: 666.3479 - beta: 1.0000e-05\n",
      "Epoch 05262: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1598624.1193 - recon_loss: 1.5980e-04 - KL loss: 666.3456 - beta: 1.0000e-05 - val_loss: 1809515.1250 - val_recon_loss: 1.8089e-04 - val_KL loss: 656.3503 - val_beta: 1.0000e-05\n",
      "Epoch 5263/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 1542189.2469 - recon_loss: 1.5415e-04 - KL loss: 661.5182 - beta: 1.0000e-05 - val_loss: 1724721.3750 - val_recon_loss: 1.7241e-04 - val_KL loss: 652.7121 - val_beta: 1.0000e-05\n",
      "Epoch 5264/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1534752.7128 - recon_loss: 1.5341e-04 - KL loss: 657.8498 - beta: 1.0000e-05 - val_loss: 1734087.0000 - val_recon_loss: 1.7334e-04 - val_KL loss: 655.4501 - val_beta: 1.0000e-05\n",
      "Epoch 5265/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1529927.4015 - recon_loss: 1.5293e-04 - KL loss: 658.1650 - beta: 1.0000e-05 - val_loss: 1832218.3750 - val_recon_loss: 1.8316e-04 - val_KL loss: 652.4949 - val_beta: 1.0000e-05\n",
      "Epoch 5266/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1562769.2665 - recon_loss: 1.5621e-04 - KL loss: 656.4243 - beta: 1.0000e-05 - val_loss: 1811007.5000 - val_recon_loss: 1.8104e-04 - val_KL loss: 650.7452 - val_beta: 1.0000e-05\n",
      "Epoch 5267/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 1548326.5112 - recon_loss: 1.5477e-04 - KL loss: 656.3305 - beta: 1.0000e-05 - val_loss: 1777072.0000 - val_recon_loss: 1.7764e-04 - val_KL loss: 655.7803 - val_beta: 1.0000e-05\n",
      "Epoch 5268/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1537846.7896 - recon_loss: 1.5372e-04 - KL loss: 657.5681 - beta: 1.0000e-05\n",
      "Epoch 05268: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 1537843.6164 - recon_loss: 1.5372e-04 - KL loss: 657.5681 - beta: 1.0000e-05 - val_loss: 1798378.6250 - val_recon_loss: 1.7977e-04 - val_KL loss: 656.0275 - val_beta: 1.0000e-05\n",
      "Epoch 5269/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 1533641.3454 - recon_loss: 1.5330e-04 - KL loss: 659.9714 - beta: 1.0000e-05 - val_loss: 1752689.3750 - val_recon_loss: 1.7520e-04 - val_KL loss: 654.9344 - val_beta: 1.0000e-05\n",
      "Epoch 5270/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1518193.5905 - recon_loss: 1.5175e-04 - KL loss: 658.9094 - beta: 1.0000e-05 - val_loss: 1751821.2500 - val_recon_loss: 1.7512e-04 - val_KL loss: 655.8647 - val_beta: 1.0000e-05\n",
      "Epoch 5271/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 1510975.6773 - recon_loss: 1.5103e-04 - KL loss: 659.2900 - beta: 1.0000e-05 - val_loss: 1759349.2500 - val_recon_loss: 1.7587e-04 - val_KL loss: 656.7368 - val_beta: 1.0000e-05\n",
      "Epoch 5272/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1518466.7175 - recon_loss: 1.5178e-04 - KL loss: 659.1290 - beta: 1.0000e-05 - val_loss: 1771038.6250 - val_recon_loss: 1.7704e-04 - val_KL loss: 653.4207 - val_beta: 1.0000e-05\n",
      "Epoch 5273/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1524918.8399 - recon_loss: 1.5243e-04 - KL loss: 657.8037 - beta: 1.0000e-05\n",
      "Epoch 05273: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 1524912.3453 - recon_loss: 1.5243e-04 - KL loss: 657.8031 - beta: 1.0000e-05 - val_loss: 1762182.0000 - val_recon_loss: 1.7615e-04 - val_KL loss: 652.3571 - val_beta: 1.0000e-05\n",
      "Epoch 5273/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 601636.4482 - recon_loss: 1.5096e-04 - KL loss: 655.0288 - beta: 1.5849e-05 - val_loss: 699433.6875 - val_recon_loss: 1.7553e-04 - val_KL loss: 641.6793 - val_beta: 1.5849e-05\n",
      "Epoch 5274/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 625658.8961 - recon_loss: 1.5700e-04 - KL loss: 644.3700 - beta: 1.5849e-05 - val_loss: 676394.1250 - val_recon_loss: 1.6974e-04 - val_KL loss: 638.7444 - val_beta: 1.5849e-05\n",
      "Epoch 5275/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 626539.5235 - recon_loss: 1.5722e-04 - KL loss: 638.4703 - beta: 1.5849e-05 - val_loss: 721104.7500 - val_recon_loss: 1.8097e-04 - val_KL loss: 631.5993 - val_beta: 1.5849e-05\n",
      "Epoch 5276/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 614411.6952 - recon_loss: 1.5417e-04 - KL loss: 631.1156 - beta: 1.5849e-05 - val_loss: 722748.8750 - val_recon_loss: 1.8139e-04 - val_KL loss: 621.3796 - val_beta: 1.5849e-05\n",
      "Epoch 5277/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 613543.3236 - recon_loss: 1.5396e-04 - KL loss: 628.2476 - beta: 1.5849e-05 - val_loss: 762743.6250 - val_recon_loss: 1.9144e-04 - val_KL loss: 621.2437 - val_beta: 1.5849e-05\n",
      "Epoch 5278/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 623666.4070 - recon_loss: 1.5650e-04 - KL loss: 618.1776 - beta: 1.5849e-05 - val_loss: 722729.8750 - val_recon_loss: 1.8139e-04 - val_KL loss: 591.4000 - val_beta: 1.5849e-05\n",
      "Epoch 5279/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 614462.4921 - recon_loss: 1.5420e-04 - KL loss: 591.7155 - beta: 1.5849e-05\n",
      "Epoch 05279: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 614463.1892 - recon_loss: 1.5420e-04 - KL loss: 591.7178 - beta: 1.5849e-05 - val_loss: 807768.1250 - val_recon_loss: 2.0275e-04 - val_KL loss: 596.9481 - val_beta: 1.5849e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5280/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 610225.8239 - recon_loss: 1.5313e-04 - KL loss: 600.7452 - beta: 1.5849e-05 - val_loss: 724000.5000 - val_recon_loss: 1.8171e-04 - val_KL loss: 596.4158 - val_beta: 1.5849e-05\n",
      "Epoch 5281/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 602156.5837 - recon_loss: 1.5110e-04 - KL loss: 599.7987 - beta: 1.5849e-05 - val_loss: 685870.8125 - val_recon_loss: 1.7213e-04 - val_KL loss: 594.0389 - val_beta: 1.5849e-05\n",
      "Epoch 5282/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 605967.5826 - recon_loss: 1.5206e-04 - KL loss: 598.6597 - beta: 1.5849e-05 - val_loss: 724084.8125 - val_recon_loss: 1.8173e-04 - val_KL loss: 598.3728 - val_beta: 1.5849e-05\n",
      "Epoch 5283/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 603684.6718 - recon_loss: 1.5149e-04 - KL loss: 602.9632 - beta: 1.5849e-05 - val_loss: 707715.0000 - val_recon_loss: 1.7762e-04 - val_KL loss: 597.7789 - val_beta: 1.5849e-05\n",
      "Epoch 5284/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 597330.0175 - recon_loss: 1.4989e-04 - KL loss: 601.0319 - beta: 1.5849e-05\n",
      "Epoch 05284: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 597329.7547 - recon_loss: 1.4989e-04 - KL loss: 601.0330 - beta: 1.5849e-05 - val_loss: 694658.9375 - val_recon_loss: 1.7434e-04 - val_KL loss: 599.7552 - val_beta: 1.5849e-05\n",
      "Epoch 5284/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 238364.9136 - recon_loss: 1.5002e-04 - KL loss: 597.9068 - beta: 2.5119e-05 - val_loss: 290666.7188 - val_recon_loss: 1.8303e-04 - val_KL loss: 583.8965 - val_beta: 2.5119e-05\n",
      "Epoch 5285/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 238433.3163 - recon_loss: 1.5007e-04 - KL loss: 581.9067 - beta: 2.5119e-05 - val_loss: 280996.8750 - val_recon_loss: 1.7694e-04 - val_KL loss: 563.6100 - val_beta: 2.5119e-05\n",
      "Epoch 5286/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 241584.6748 - recon_loss: 1.5207e-04 - KL loss: 564.2473 - beta: 2.5119e-05 - val_loss: 301427.1250 - val_recon_loss: 1.8984e-04 - val_KL loss: 555.0168 - val_beta: 2.5119e-05\n",
      "Epoch 5287/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 241356.0788 - recon_loss: 1.5194e-04 - KL loss: 554.6929 - beta: 2.5119e-05 - val_loss: 315753.6562 - val_recon_loss: 1.9889e-04 - val_KL loss: 540.3391 - val_beta: 2.5119e-05\n",
      "Epoch 5288/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 243101.7171 - recon_loss: 1.5304e-04 - KL loss: 543.4889 - beta: 2.5119e-05 - val_loss: 270359.1250 - val_recon_loss: 1.7025e-04 - val_KL loss: 536.9628 - val_beta: 2.5119e-05\n",
      "Epoch 5289/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 245116.2140 - recon_loss: 1.5432e-04 - KL loss: 540.1401 - beta: 2.5119e-05 - val_loss: 291027.3438 - val_recon_loss: 1.8329e-04 - val_KL loss: 530.4874 - val_beta: 2.5119e-05\n",
      "Epoch 5290/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 244295.7346 - recon_loss: 1.5381e-04 - KL loss: 526.6349 - beta: 2.5119e-05 - val_loss: 285073.4375 - val_recon_loss: 1.7954e-04 - val_KL loss: 523.5126 - val_beta: 2.5119e-05\n",
      "Epoch 5291/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 245484.9950 - recon_loss: 1.5455e-04 - KL loss: 533.5422 - beta: 2.5119e-05 - val_loss: 269532.0312 - val_recon_loss: 1.6973e-04 - val_KL loss: 528.1692 - val_beta: 2.5119e-05\n",
      "Epoch 5292/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 245706.2565 - recon_loss: 1.5469e-04 - KL loss: 532.7649 - beta: 2.5119e-05 - val_loss: 346515.3750 - val_recon_loss: 2.1831e-04 - val_KL loss: 523.3640 - val_beta: 2.5119e-05\n",
      "Epoch 5293/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 247459.6617 - recon_loss: 1.5580e-04 - KL loss: 531.4061 - beta: 2.5119e-05 - val_loss: 319163.5938 - val_recon_loss: 2.0105e-04 - val_KL loss: 513.9599 - val_beta: 2.5119e-05\n",
      "Epoch 5294/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 239649.5523 - recon_loss: 1.5088e-04 - KL loss: 520.6273 - beta: 2.5119e-05 - val_loss: 314805.7188 - val_recon_loss: 1.9829e-04 - val_KL loss: 529.4843 - val_beta: 2.5119e-05\n",
      "Epoch 5295/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 239085.4685 - recon_loss: 1.5052e-04 - KL loss: 525.1805 - beta: 2.5119e-05 - val_loss: 288612.9688 - val_recon_loss: 1.8177e-04 - val_KL loss: 519.8687 - val_beta: 2.5119e-05\n",
      "Epoch 5296/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 241527.3465 - recon_loss: 1.5206e-04 - KL loss: 522.9991 - beta: 2.5119e-05 - val_loss: 265373.0938 - val_recon_loss: 1.6711e-04 - val_KL loss: 523.2797 - val_beta: 2.5119e-05\n",
      "Epoch 5297/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 246871.6894 - recon_loss: 1.5543e-04 - KL loss: 527.9625 - beta: 2.5119e-05 - val_loss: 263689.6250 - val_recon_loss: 1.6605e-04 - val_KL loss: 514.3796 - val_beta: 2.5119e-05\n",
      "Epoch 5298/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 242494.0614 - recon_loss: 1.5267e-04 - KL loss: 525.3878 - beta: 2.5119e-05 - val_loss: 267389.9688 - val_recon_loss: 1.6838e-04 - val_KL loss: 523.1906 - val_beta: 2.5119e-05\n",
      "Epoch 5299/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 238165.5088 - recon_loss: 1.4994e-04 - KL loss: 527.4345 - beta: 2.5119e-05 - val_loss: 281317.3750 - val_recon_loss: 1.7717e-04 - val_KL loss: 525.6066 - val_beta: 2.5119e-05\n",
      "Epoch 5300/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 242939.7504 - recon_loss: 1.5295e-04 - KL loss: 526.4828 - beta: 2.5119e-05 - val_loss: 269200.9062 - val_recon_loss: 1.6953e-04 - val_KL loss: 515.2191 - val_beta: 2.5119e-05\n",
      "Epoch 5301/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 240814.9197 - recon_loss: 1.5162e-04 - KL loss: 517.5594 - beta: 2.5119e-05 - val_loss: 280666.5625 - val_recon_loss: 1.7675e-04 - val_KL loss: 530.0553 - val_beta: 2.5119e-05\n",
      "Epoch 5302/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 242469.6637 - recon_loss: 1.5266e-04 - KL loss: 523.1767 - beta: 2.5119e-05\n",
      "Epoch 05302: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 242470.2906 - recon_loss: 1.5266e-04 - KL loss: 523.1725 - beta: 2.5119e-05 - val_loss: 274428.6250 - val_recon_loss: 1.7282e-04 - val_KL loss: 520.0947 - val_beta: 2.5119e-05\n",
      "Epoch 5303/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 237418.4926 - recon_loss: 1.4947e-04 - KL loss: 526.2389 - beta: 2.5119e-05 - val_loss: 272667.0312 - val_recon_loss: 1.7171e-04 - val_KL loss: 529.6613 - val_beta: 2.5119e-05\n",
      "Epoch 5304/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 239607.8356 - recon_loss: 1.5085e-04 - KL loss: 528.2230 - beta: 2.5119e-05 - val_loss: 270418.5938 - val_recon_loss: 1.7030e-04 - val_KL loss: 518.9900 - val_beta: 2.5119e-05\n",
      "Epoch 5305/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 235791.7451 - recon_loss: 1.4845e-04 - KL loss: 521.2604 - beta: 2.5119e-05 - val_loss: 267066.7188 - val_recon_loss: 1.6818e-04 - val_KL loss: 521.2505 - val_beta: 2.5119e-05\n",
      "Epoch 5306/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 236079.8259 - recon_loss: 1.4863e-04 - KL loss: 523.1366 - beta: 2.5119e-05 - val_loss: 269151.0312 - val_recon_loss: 1.6949e-04 - val_KL loss: 524.2060 - val_beta: 2.5119e-05\n",
      "Epoch 5307/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 235185.4620 - recon_loss: 1.4806e-04 - KL loss: 524.3754 - beta: 2.5119e-05\n",
      "Epoch 05307: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 235186.8038 - recon_loss: 1.4806e-04 - KL loss: 524.3761 - beta: 2.5119e-05 - val_loss: 279185.0312 - val_recon_loss: 1.7582e-04 - val_KL loss: 527.2947 - val_beta: 2.5119e-05\n",
      "Epoch 5307/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 58s 58ms/step - loss: 95272.2791 - recon_loss: 1.5017e-04 - KL loss: 523.4447 - beta: 3.9811e-05 - val_loss: 109208.8906 - val_recon_loss: 1.7228e-04 - val_KL loss: 509.8805 - val_beta: 3.9811e-05\n",
      "Epoch 5308/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 95012.9091 - recon_loss: 1.4978e-04 - KL loss: 505.0115 - beta: 3.9811e-05 - val_loss: 107502.0859 - val_recon_loss: 1.6960e-04 - val_KL loss: 489.7235 - val_beta: 3.9811e-05\n",
      "Epoch 5309/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 96442.2236 - recon_loss: 1.5208e-04 - KL loss: 488.2570 - beta: 3.9811e-05 - val_loss: 111044.1172 - val_recon_loss: 1.7523e-04 - val_KL loss: 483.3026 - val_beta: 3.9811e-05\n",
      "Epoch 5310/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 97179.0026 - recon_loss: 1.5327e-04 - KL loss: 474.4754 - beta: 3.9811e-05 - val_loss: 107453.6016 - val_recon_loss: 1.6957e-04 - val_KL loss: 464.4773 - val_beta: 3.9811e-05\n",
      "Epoch 5311/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 95714.8298 - recon_loss: 1.5096e-04 - KL loss: 465.9784 - beta: 3.9811e-05 - val_loss: 106648.9062 - val_recon_loss: 1.6829e-04 - val_KL loss: 464.8754 - val_beta: 3.9811e-05\n",
      "Epoch 5312/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 96216.0697 - recon_loss: 1.5176e-04 - KL loss: 464.6071 - beta: 3.9811e-05 - val_loss: 104660.5547 - val_recon_loss: 1.6514e-04 - val_KL loss: 462.7471 - val_beta: 3.9811e-05\n",
      "Epoch 5313/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 97377.9535 - recon_loss: 1.5360e-04 - KL loss: 464.8713 - beta: 3.9811e-05 - val_loss: 109128.9531 - val_recon_loss: 1.7222e-04 - val_KL loss: 465.1355 - val_beta: 3.9811e-05\n",
      "Epoch 5314/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 97697.8749 - recon_loss: 1.5411e-04 - KL loss: 462.5957 - beta: 3.9811e-05 - val_loss: 113798.5234 - val_recon_loss: 1.7962e-04 - val_KL loss: 464.2045 - val_beta: 3.9811e-05\n",
      "Epoch 5315/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 97025.4488 - recon_loss: 1.5304e-04 - KL loss: 465.7652 - beta: 3.9811e-05 - val_loss: 106416.2891 - val_recon_loss: 1.6793e-04 - val_KL loss: 459.9949 - val_beta: 3.9811e-05\n",
      "Epoch 5316/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 97017.9966 - recon_loss: 1.5303e-04 - KL loss: 460.5619 - beta: 3.9811e-05 - val_loss: 105491.4688 - val_recon_loss: 1.6646e-04 - val_KL loss: 459.3011 - val_beta: 3.9811e-05\n",
      "Epoch 5317/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 98337.2649 - recon_loss: 1.5512e-04 - KL loss: 460.4169 - beta: 3.9811e-05\n",
      "Epoch 05317: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 98336.5859 - recon_loss: 1.5512e-04 - KL loss: 460.4171 - beta: 3.9811e-05 - val_loss: 105732.1094 - val_recon_loss: 1.6684e-04 - val_KL loss: 465.5629 - val_beta: 3.9811e-05\n",
      "Epoch 5318/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 95345.8861 - recon_loss: 1.5038e-04 - KL loss: 461.9866 - beta: 3.9811e-05 - val_loss: 104052.6562 - val_recon_loss: 1.6418e-04 - val_KL loss: 462.5921 - val_beta: 3.9811e-05\n",
      "Epoch 5319/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 95240.6733 - recon_loss: 1.5022e-04 - KL loss: 460.9300 - beta: 3.9811e-05 - val_loss: 103759.4844 - val_recon_loss: 1.6372e-04 - val_KL loss: 461.7847 - val_beta: 3.9811e-05\n",
      "Epoch 5320/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 95241.6485 - recon_loss: 1.5021e-04 - KL loss: 464.0511 - beta: 3.9811e-05 - val_loss: 104551.7969 - val_recon_loss: 1.6496e-04 - val_KL loss: 466.6562 - val_beta: 3.9811e-05\n",
      "Epoch 5321/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 95238.3704 - recon_loss: 1.5021e-04 - KL loss: 464.2984 - beta: 3.9811e-05 - val_loss: 106245.3750 - val_recon_loss: 1.6765e-04 - val_KL loss: 465.1548 - val_beta: 3.9811e-05\n",
      "Epoch 5322/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 94924.0084 - recon_loss: 1.4971e-04 - KL loss: 462.0803 - beta: 3.9811e-05 - val_loss: 115350.2734 - val_recon_loss: 1.8207e-04 - val_KL loss: 474.3728 - val_beta: 3.9811e-05\n",
      "Epoch 5323/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 95913.7985 - recon_loss: 1.5126e-04 - KL loss: 472.9898 - beta: 3.9811e-05 - val_loss: 106169.4141 - val_recon_loss: 1.6753e-04 - val_KL loss: 466.5600 - val_beta: 3.9811e-05\n",
      "Epoch 5324/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 95053.4662 - recon_loss: 1.4991e-04 - KL loss: 465.9092 - beta: 3.9811e-05\n",
      "Epoch 05324: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 95054.0535 - recon_loss: 1.4991e-04 - KL loss: 465.9090 - beta: 3.9811e-05 - val_loss: 106473.0859 - val_recon_loss: 1.6801e-04 - val_KL loss: 468.5486 - val_beta: 3.9811e-05\n",
      "Epoch 5325/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 95905.6872 - recon_loss: 1.5126e-04 - KL loss: 466.1456 - beta: 3.9811e-05 - val_loss: 105163.4219 - val_recon_loss: 1.6593e-04 - val_KL loss: 468.8221 - val_beta: 3.9811e-05\n",
      "Epoch 5326/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 95300.6894 - recon_loss: 1.5030e-04 - KL loss: 465.4497 - beta: 3.9811e-05 - val_loss: 106605.3516 - val_recon_loss: 1.6822e-04 - val_KL loss: 467.5336 - val_beta: 3.9811e-05\n",
      "Epoch 5327/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 94373.9280 - recon_loss: 1.4884e-04 - KL loss: 465.1893 - beta: 3.9811e-05 - val_loss: 106054.2422 - val_recon_loss: 1.6734e-04 - val_KL loss: 467.7606 - val_beta: 3.9811e-05\n",
      "Epoch 5328/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 95192.0565 - recon_loss: 1.5013e-04 - KL loss: 465.2356 - beta: 3.9811e-05 - val_loss: 103824.6484 - val_recon_loss: 1.6381e-04 - val_KL loss: 465.7057 - val_beta: 3.9811e-05\n",
      "Epoch 5329/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 95172.6093 - recon_loss: 1.5010e-04 - KL loss: 463.6165 - beta: 3.9811e-05\n",
      "Epoch 05329: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 95172.0926 - recon_loss: 1.5010e-04 - KL loss: 463.6170 - beta: 3.9811e-05 - val_loss: 105683.4141 - val_recon_loss: 1.6676e-04 - val_KL loss: 467.2775 - val_beta: 3.9811e-05\n",
      "Epoch 5329/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 38654.3220 - recon_loss: 1.5207e-04 - KL loss: 457.0416 - beta: 6.3096e-05 - val_loss: 42215.0547 - val_recon_loss: 1.6630e-04 - val_KL loss: 441.5755 - val_beta: 6.3096e-05\n",
      "Epoch 5330/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 38524.6864 - recon_loss: 1.5165e-04 - KL loss: 431.6388 - beta: 6.3096e-05 - val_loss: 42309.8047 - val_recon_loss: 1.6677e-04 - val_KL loss: 418.3136 - val_beta: 6.3096e-05\n",
      "Epoch 5331/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 38877.4571 - recon_loss: 1.5312e-04 - KL loss: 414.9339 - beta: 6.3096e-05 - val_loss: 42820.6992 - val_recon_loss: 1.6884e-04 - val_KL loss: 409.8107 - val_beta: 6.3096e-05\n",
      "Epoch 5332/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 39225.5042 - recon_loss: 1.5455e-04 - KL loss: 405.3919 - beta: 6.3096e-05 - val_loss: 40902.0703 - val_recon_loss: 1.6125e-04 - val_KL loss: 398.5725 - val_beta: 6.3096e-05\n",
      "Epoch 5333/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 39766.7426 - recon_loss: 1.5673e-04 - KL loss: 398.4392 - beta: 6.3096e-05 - val_loss: 42635.0547 - val_recon_loss: 1.6814e-04 - val_KL loss: 400.9203 - val_beta: 6.3096e-05\n",
      "Epoch 5334/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 38912.6950 - recon_loss: 1.5333e-04 - KL loss: 398.1246 - beta: 6.3096e-05 - val_loss: 43308.5742 - val_recon_loss: 1.7084e-04 - val_KL loss: 396.6303 - val_beta: 6.3096e-05\n",
      "Epoch 5335/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 38598.9533 - recon_loss: 1.5210e-04 - KL loss: 392.6815 - beta: 6.3096e-05 - val_loss: 43027.5977 - val_recon_loss: 1.6971e-04 - val_KL loss: 398.1739 - val_beta: 6.3096e-05\n",
      "Epoch 5336/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 38436.8645 - recon_loss: 1.5145e-04 - KL loss: 393.1557 - beta: 6.3096e-05 - val_loss: 42592.5352 - val_recon_loss: 1.6797e-04 - val_KL loss: 399.3917 - val_beta: 6.3096e-05\n",
      "Epoch 5337/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 38663.7040 - recon_loss: 1.5234e-04 - KL loss: 396.9091 - beta: 6.3096e-05\n",
      "Epoch 05337: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 38663.9416 - recon_loss: 1.5234e-04 - KL loss: 396.9078 - beta: 6.3096e-05 - val_loss: 44582.5430 - val_recon_loss: 1.7593e-04 - val_KL loss: 390.7684 - val_beta: 6.3096e-05\n",
      "Epoch 5338/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 38123.6322 - recon_loss: 1.5022e-04 - KL loss: 390.1012 - beta: 6.3096e-05 - val_loss: 41798.0859 - val_recon_loss: 1.6483e-04 - val_KL loss: 395.2443 - val_beta: 6.3096e-05\n",
      "Epoch 5339/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 37485.8285 - recon_loss: 1.4767e-04 - KL loss: 393.8092 - beta: 6.3096e-05 - val_loss: 41994.7070 - val_recon_loss: 1.6560e-04 - val_KL loss: 397.6488 - val_beta: 6.3096e-05\n",
      "Epoch 5340/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 37504.3176 - recon_loss: 1.4773e-04 - KL loss: 396.7092 - beta: 6.3096e-05 - val_loss: 41340.5039 - val_recon_loss: 1.6299e-04 - val_KL loss: 398.4639 - val_beta: 6.3096e-05\n",
      "Epoch 5341/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 37624.6497 - recon_loss: 1.4821e-04 - KL loss: 396.5440 - beta: 6.3096e-05 - val_loss: 41698.2930 - val_recon_loss: 1.6441e-04 - val_KL loss: 400.5450 - val_beta: 6.3096e-05\n",
      "Epoch 5342/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 37331.5843 - recon_loss: 1.4703e-04 - KL loss: 398.6514 - beta: 6.3096e-05 - val_loss: 40645.8398 - val_recon_loss: 1.6021e-04 - val_KL loss: 401.7447 - val_beta: 6.3096e-05\n",
      "Epoch 5343/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 38044.2614 - recon_loss: 1.4987e-04 - KL loss: 398.8067 - beta: 6.3096e-05 - val_loss: 40712.4531 - val_recon_loss: 1.6047e-04 - val_KL loss: 404.3619 - val_beta: 6.3096e-05\n",
      "Epoch 5344/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 37817.3735 - recon_loss: 1.4896e-04 - KL loss: 401.2244 - beta: 6.3096e-05 - val_loss: 41145.9453 - val_recon_loss: 1.6220e-04 - val_KL loss: 402.0007 - val_beta: 6.3096e-05\n",
      "Epoch 5345/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 37472.3897 - recon_loss: 1.4759e-04 - KL loss: 398.2649 - beta: 6.3096e-05 - val_loss: 41262.1133 - val_recon_loss: 1.6267e-04 - val_KL loss: 400.5665 - val_beta: 6.3096e-05\n",
      "Epoch 5346/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 37205.6892 - recon_loss: 1.4654e-04 - KL loss: 397.3475 - beta: 6.3096e-05 - val_loss: 41058.7930 - val_recon_loss: 1.6187e-04 - val_KL loss: 399.6490 - val_beta: 6.3096e-05\n",
      "Epoch 5347/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 37514.1599 - recon_loss: 1.4776e-04 - KL loss: 398.7074 - beta: 6.3096e-05\n",
      "Epoch 05347: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 37514.1585 - recon_loss: 1.4776e-04 - KL loss: 398.7091 - beta: 6.3096e-05 - val_loss: 41281.0000 - val_recon_loss: 1.6272e-04 - val_KL loss: 408.2861 - val_beta: 6.3096e-05\n",
      "Epoch 5348/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 37563.1195 - recon_loss: 1.4793e-04 - KL loss: 404.1162 - beta: 6.3096e-05 - val_loss: 41371.8320 - val_recon_loss: 1.6309e-04 - val_KL loss: 404.8914 - val_beta: 6.3096e-05\n",
      "Epoch 5349/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 36995.3577 - recon_loss: 1.4568e-04 - KL loss: 401.2430 - beta: 6.3096e-05 - val_loss: 40967.6836 - val_recon_loss: 1.6148e-04 - val_KL loss: 404.7900 - val_beta: 6.3096e-05\n",
      "Epoch 5350/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 37426.6957 - recon_loss: 1.4740e-04 - KL loss: 401.3557 - beta: 6.3096e-05 - val_loss: 40559.0938 - val_recon_loss: 1.5986e-04 - val_KL loss: 404.4686 - val_beta: 6.3096e-05\n",
      "Epoch 5351/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 37423.0640 - recon_loss: 1.4739e-04 - KL loss: 400.6403 - beta: 6.3096e-05 - val_loss: 40452.5586 - val_recon_loss: 1.5944e-04 - val_KL loss: 403.5759 - val_beta: 6.3096e-05\n",
      "Epoch 5352/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 37016.5286 - recon_loss: 1.4578e-04 - KL loss: 399.3011 - beta: 6.3096e-05 - val_loss: 40788.2109 - val_recon_loss: 1.6078e-04 - val_KL loss: 402.7493 - val_beta: 6.3096e-05\n",
      "Epoch 5353/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 37091.1872 - recon_loss: 1.4607e-04 - KL loss: 399.4431 - beta: 6.3096e-05 - val_loss: 40522.2344 - val_recon_loss: 1.5972e-04 - val_KL loss: 402.3637 - val_beta: 6.3096e-05\n",
      "Epoch 5354/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36901.0827 - recon_loss: 1.4532e-04 - KL loss: 398.7176 - beta: 6.3096e-05 - val_loss: 40959.7812 - val_recon_loss: 1.6145e-04 - val_KL loss: 404.3726 - val_beta: 6.3096e-05\n",
      "Epoch 5355/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36996.2944 - recon_loss: 1.4569e-04 - KL loss: 400.4145 - beta: 6.3096e-05 - val_loss: 40329.1250 - val_recon_loss: 1.5895e-04 - val_KL loss: 403.7502 - val_beta: 6.3096e-05\n",
      "Epoch 5356/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 37145.7118 - recon_loss: 1.4629e-04 - KL loss: 400.1164 - beta: 6.3096e-05 - val_loss: 40890.9336 - val_recon_loss: 1.6119e-04 - val_KL loss: 402.8670 - val_beta: 6.3096e-05\n",
      "Epoch 5357/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 36965.0264 - recon_loss: 1.4557e-04 - KL loss: 398.7060 - beta: 6.3096e-05 - val_loss: 40359.7891 - val_recon_loss: 1.5907e-04 - val_KL loss: 403.6034 - val_beta: 6.3096e-05\n",
      "Epoch 5358/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 36751.8939 - recon_loss: 1.4472e-04 - KL loss: 399.4232 - beta: 6.3096e-05 - val_loss: 40478.0156 - val_recon_loss: 1.5954e-04 - val_KL loss: 403.3647 - val_beta: 6.3096e-05\n",
      "Epoch 5359/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 36872.5368 - recon_loss: 1.4520e-04 - KL loss: 399.8986 - beta: 6.3096e-05 - val_loss: 40232.4883 - val_recon_loss: 1.5856e-04 - val_KL loss: 403.1308 - val_beta: 6.3096e-05\n",
      "Epoch 5360/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 37160.9482 - recon_loss: 1.4635e-04 - KL loss: 399.6438 - beta: 6.3096e-05 - val_loss: 40468.2539 - val_recon_loss: 1.5950e-04 - val_KL loss: 402.7616 - val_beta: 6.3096e-05\n",
      "Epoch 5361/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36872.6682 - recon_loss: 1.4520e-04 - KL loss: 400.1288 - beta: 6.3096e-05 - val_loss: 40215.3320 - val_recon_loss: 1.5849e-04 - val_KL loss: 404.0874 - val_beta: 6.3096e-05\n",
      "Epoch 5362/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36471.2850 - recon_loss: 1.4360e-04 - KL loss: 400.0155 - beta: 6.3096e-05 - val_loss: 40319.5273 - val_recon_loss: 1.5890e-04 - val_KL loss: 404.5167 - val_beta: 6.3096e-05\n",
      "Epoch 5363/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 36903.3636 - recon_loss: 1.4532e-04 - KL loss: 401.1539 - beta: 6.3096e-05 - val_loss: 40122.7617 - val_recon_loss: 1.5812e-04 - val_KL loss: 403.6749 - val_beta: 6.3096e-05\n",
      "Epoch 5364/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 36939.3909 - recon_loss: 1.4547e-04 - KL loss: 398.3834 - beta: 6.3096e-05 - val_loss: 40197.5273 - val_recon_loss: 1.5843e-04 - val_KL loss: 402.1940 - val_beta: 6.3096e-05\n",
      "Epoch 5365/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36640.8287 - recon_loss: 1.4428e-04 - KL loss: 398.9831 - beta: 6.3096e-05 - val_loss: 40353.0898 - val_recon_loss: 1.5905e-04 - val_KL loss: 402.7389 - val_beta: 6.3096e-05\n",
      "Epoch 5366/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36286.1945 - recon_loss: 1.4287e-04 - KL loss: 399.0514 - beta: 6.3096e-05 - val_loss: 40198.4180 - val_recon_loss: 1.5842e-04 - val_KL loss: 404.2502 - val_beta: 6.3096e-05\n",
      "Epoch 5367/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 36636.9507 - recon_loss: 1.4426e-04 - KL loss: 399.9033 - beta: 6.3096e-05 - val_loss: 40052.9492 - val_recon_loss: 1.5784e-04 - val_KL loss: 405.6031 - val_beta: 6.3096e-05\n",
      "Epoch 5368/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 36850.3383 - recon_loss: 1.4510e-04 - KL loss: 401.7549 - beta: 6.3096e-05 - val_loss: 40181.5352 - val_recon_loss: 1.5835e-04 - val_KL loss: 405.0958 - val_beta: 6.3096e-05\n",
      "Epoch 5369/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36493.4229 - recon_loss: 1.4369e-04 - KL loss: 401.1267 - beta: 6.3096e-05 - val_loss: 40136.9961 - val_recon_loss: 1.5818e-04 - val_KL loss: 403.9182 - val_beta: 6.3096e-05\n",
      "Epoch 5370/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 36595.3978 - recon_loss: 1.4410e-04 - KL loss: 399.7874 - beta: 6.3096e-05 - val_loss: 40469.4102 - val_recon_loss: 1.5951e-04 - val_KL loss: 403.0789 - val_beta: 6.3096e-05\n",
      "Epoch 5371/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 36749.1997 - recon_loss: 1.4471e-04 - KL loss: 400.4202 - beta: 6.3096e-05 - val_loss: 40387.0703 - val_recon_loss: 1.5918e-04 - val_KL loss: 403.1023 - val_beta: 6.3096e-05\n",
      "Epoch 5372/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 36850.9778 - recon_loss: 1.4511e-04 - KL loss: 400.4706 - beta: 6.3096e-05\n",
      "Epoch 05372: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 36850.9653 - recon_loss: 1.4511e-04 - KL loss: 400.4704 - beta: 6.3096e-05 - val_loss: 40306.2891 - val_recon_loss: 1.5886e-04 - val_KL loss: 403.0132 - val_beta: 6.3096e-05\n",
      "Epoch 5373/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36607.9028 - recon_loss: 1.4415e-04 - KL loss: 399.8670 - beta: 6.3096e-05 - val_loss: 40362.5352 - val_recon_loss: 1.5908e-04 - val_KL loss: 403.5867 - val_beta: 6.3096e-05\n",
      "Epoch 5374/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 36482.0864 - recon_loss: 1.4364e-04 - KL loss: 400.2475 - beta: 6.3096e-05 - val_loss: 40378.3438 - val_recon_loss: 1.5914e-04 - val_KL loss: 403.5948 - val_beta: 6.3096e-05\n",
      "Epoch 5375/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36645.1994 - recon_loss: 1.4429e-04 - KL loss: 400.0969 - beta: 6.3096e-05 - val_loss: 40405.9180 - val_recon_loss: 1.5925e-04 - val_KL loss: 403.3799 - val_beta: 6.3096e-05\n",
      "Epoch 5376/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36574.1874 - recon_loss: 1.4401e-04 - KL loss: 400.5303 - beta: 6.3096e-05 - val_loss: 40313.0078 - val_recon_loss: 1.5888e-04 - val_KL loss: 403.6514 - val_beta: 6.3096e-05\n",
      "Epoch 5377/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 36555.2566 - recon_loss: 1.4393e-04 - KL loss: 400.8898 - beta: 6.3096e-05\n",
      "Epoch 05377: ReduceLROnPlateau reducing learning rate to 9.999999654550589e-08.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 36555.2527 - recon_loss: 1.4393e-04 - KL loss: 400.8893 - beta: 6.3096e-05 - val_loss: 40405.3086 - val_recon_loss: 1.5925e-04 - val_KL loss: 403.7054 - val_beta: 6.3096e-05\n",
      "Epoch 5377/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 15088.4023 - recon_loss: 1.4698e-04 - KL loss: 390.2105 - beta: 1.0000e-04 - val_loss: 16526.0703 - val_recon_loss: 1.6165e-04 - val_KL loss: 361.1443 - val_beta: 1.0000e-04\n",
      "Epoch 5378/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15139.5465 - recon_loss: 1.4787e-04 - KL loss: 352.3456 - beta: 1.0000e-04 - val_loss: 16987.7559 - val_recon_loss: 1.6643e-04 - val_KL loss: 344.8783 - val_beta: 1.0000e-04\n",
      "Epoch 5379/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 15109.8723 - recon_loss: 1.4772e-04 - KL loss: 338.3107 - beta: 1.0000e-04 - val_loss: 17608.4414 - val_recon_loss: 1.7273e-04 - val_KL loss: 335.3045 - val_beta: 1.0000e-04\n",
      "Epoch 5380/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 15251.9988 - recon_loss: 1.4920e-04 - KL loss: 331.7779 - beta: 1.0000e-04 - val_loss: 18478.5488 - val_recon_loss: 1.8143e-04 - val_KL loss: 335.1910 - val_beta: 1.0000e-04\n",
      "Epoch 5381/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15485.2759 - recon_loss: 1.5154e-04 - KL loss: 331.0134 - beta: 1.0000e-04 - val_loss: 17862.0996 - val_recon_loss: 1.7536e-04 - val_KL loss: 326.2410 - val_beta: 1.0000e-04\n",
      "Epoch 5382/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 15417.2562 - recon_loss: 1.5091e-04 - KL loss: 325.8897 - beta: 1.0000e-04\n",
      "Epoch 05382: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15417.2736 - recon_loss: 1.5091e-04 - KL loss: 325.8899 - beta: 1.0000e-04 - val_loss: 17547.3516 - val_recon_loss: 1.7220e-04 - val_KL loss: 327.1150 - val_beta: 1.0000e-04\n",
      "Epoch 5383/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 15147.0733 - recon_loss: 1.4822e-04 - KL loss: 325.3310 - beta: 1.0000e-04 - val_loss: 17339.9570 - val_recon_loss: 1.7011e-04 - val_KL loss: 329.2354 - val_beta: 1.0000e-04\n",
      "Epoch 5384/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 14953.0459 - recon_loss: 1.4626e-04 - KL loss: 327.4041 - beta: 1.0000e-04 - val_loss: 17403.5176 - val_recon_loss: 1.7076e-04 - val_KL loss: 327.8563 - val_beta: 1.0000e-04\n",
      "Epoch 5385/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 14988.8902 - recon_loss: 1.4662e-04 - KL loss: 326.4885 - beta: 1.0000e-04 - val_loss: 17400.0352 - val_recon_loss: 1.7069e-04 - val_KL loss: 331.0229 - val_beta: 1.0000e-04\n",
      "Epoch 5386/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15061.0601 - recon_loss: 1.4733e-04 - KL loss: 327.8799 - beta: 1.0000e-04 - val_loss: 17711.3223 - val_recon_loss: 1.7380e-04 - val_KL loss: 331.0647 - val_beta: 1.0000e-04\n",
      "Epoch 5387/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14804.6943 - recon_loss: 1.4476e-04 - KL loss: 328.3098 - beta: 1.0000e-04\n",
      "Epoch 05387: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 14804.7735 - recon_loss: 1.4476e-04 - KL loss: 328.3092 - beta: 1.0000e-04 - val_loss: 17413.2227 - val_recon_loss: 1.7086e-04 - val_KL loss: 327.5819 - val_beta: 1.0000e-04\n",
      "Epoch 5387/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6194.2993 - recon_loss: 1.4779e-04 - KL loss: 310.6519 - beta: 1.5849e-04 - val_loss: 7595.0830 - val_recon_loss: 1.8368e-04 - val_KL loss: 282.8458 - val_beta: 1.5849e-04\n",
      "Epoch 5388/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6442.0818 - recon_loss: 1.5490e-04 - KL loss: 275.2314 - beta: 1.5849e-04 - val_loss: 7016.0337 - val_recon_loss: 1.6956e-04 - val_KL loss: 265.5330 - val_beta: 1.5849e-04\n",
      "Epoch 5389/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6463.8507 - recon_loss: 1.5563e-04 - KL loss: 268.2005 - beta: 1.5849e-04 - val_loss: 7228.7705 - val_recon_loss: 1.7499e-04 - val_KL loss: 262.3930 - val_beta: 1.5849e-04\n",
      "Epoch 5390/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6415.9149 - recon_loss: 1.5455e-04 - KL loss: 263.2221 - beta: 1.5849e-04 - val_loss: 6918.9683 - val_recon_loss: 1.6740e-04 - val_KL loss: 254.6025 - val_beta: 1.5849e-04\n",
      "Epoch 5391/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6396.3586 - recon_loss: 1.5419e-04 - KL loss: 258.0128 - beta: 1.5849e-04 - val_loss: 7123.9121 - val_recon_loss: 1.7260e-04 - val_KL loss: 252.5658 - val_beta: 1.5849e-04\n",
      "Epoch 5392/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6460.0950 - recon_loss: 1.5582e-04 - KL loss: 256.6528 - beta: 1.5849e-04 - val_loss: 6981.8145 - val_recon_loss: 1.6901e-04 - val_KL loss: 253.2523 - val_beta: 1.5849e-04\n",
      "Epoch 5393/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6480.4750 - recon_loss: 1.5633e-04 - KL loss: 256.7058 - beta: 1.5849e-04 - val_loss: 7537.8779 - val_recon_loss: 1.8298e-04 - val_KL loss: 253.4421 - val_beta: 1.5849e-04\n",
      "Epoch 5394/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6436.1544 - recon_loss: 1.5531e-04 - KL loss: 253.2644 - beta: 1.5849e-04 - val_loss: 7645.8838 - val_recon_loss: 1.8587e-04 - val_KL loss: 246.4303 - val_beta: 1.5849e-04\n",
      "Epoch 5395/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 6415.4673 - recon_loss: 1.5480e-04 - KL loss: 252.5739 - beta: 1.5849e-04\n",
      "Epoch 05395: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6415.6298 - recon_loss: 1.5481e-04 - KL loss: 252.5753 - beta: 1.5849e-04 - val_loss: 7542.9395 - val_recon_loss: 1.8317e-04 - val_KL loss: 250.9697 - val_beta: 1.5849e-04\n",
      "Epoch 5396/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6564.7093 - recon_loss: 1.5853e-04 - KL loss: 253.5449 - beta: 1.5849e-04 - val_loss: 7263.5503 - val_recon_loss: 1.7615e-04 - val_KL loss: 250.8988 - val_beta: 1.5849e-04\n",
      "Epoch 5397/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6397.7337 - recon_loss: 1.5438e-04 - KL loss: 251.6060 - beta: 1.5849e-04 - val_loss: 6994.3418 - val_recon_loss: 1.6940e-04 - val_KL loss: 250.3824 - val_beta: 1.5849e-04\n",
      "Epoch 5398/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6292.7099 - recon_loss: 1.5176e-04 - KL loss: 251.2162 - beta: 1.5849e-04 - val_loss: 7671.9673 - val_recon_loss: 1.8645e-04 - val_KL loss: 249.3731 - val_beta: 1.5849e-04\n",
      "Epoch 5399/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6334.7820 - recon_loss: 1.5281e-04 - KL loss: 251.1695 - beta: 1.5849e-04 - val_loss: 6956.8047 - val_recon_loss: 1.6846e-04 - val_KL loss: 250.1142 - val_beta: 1.5849e-04\n",
      "Epoch 5400/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6239.1775 - recon_loss: 1.5041e-04 - KL loss: 251.4323 - beta: 1.5849e-04\n",
      "Epoch 05400: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6239.1526 - recon_loss: 1.5040e-04 - KL loss: 251.4321 - beta: 1.5849e-04 - val_loss: 7182.3262 - val_recon_loss: 1.7419e-04 - val_KL loss: 247.6863 - val_beta: 1.5849e-04\n",
      "Epoch 5400/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2626.5903 - recon_loss: 1.5121e-04 - KL loss: 230.0775 - beta: 2.5119e-04 - val_loss: 2937.4746 - val_recon_loss: 1.7297e-04 - val_KL loss: 196.0986 - val_beta: 2.5119e-04\n",
      "Epoch 5401/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2612.8384 - recon_loss: 1.5241e-04 - KL loss: 197.3309 - beta: 2.5119e-04 - val_loss: 3213.7866 - val_recon_loss: 1.9085e-04 - val_KL loss: 189.0317 - val_beta: 2.5119e-04\n",
      "Epoch 5402/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2630.6534 - recon_loss: 1.5390e-04 - KL loss: 191.5591 - beta: 2.5119e-04 - val_loss: 2992.4607 - val_recon_loss: 1.7708e-04 - val_KL loss: 185.9945 - val_beta: 2.5119e-04\n",
      "Epoch 5403/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2715.1166 - recon_loss: 1.5943e-04 - KL loss: 188.3612 - beta: 2.5119e-04 - val_loss: 2986.1418 - val_recon_loss: 1.7664e-04 - val_KL loss: 186.5282 - val_beta: 2.5119e-04\n",
      "Epoch 5404/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2672.6184 - recon_loss: 1.5681e-04 - KL loss: 187.3671 - beta: 2.5119e-04 - val_loss: 3205.3767 - val_recon_loss: 1.9058e-04 - val_KL loss: 184.9521 - val_beta: 2.5119e-04\n",
      "Epoch 5405/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 2648.5981 - recon_loss: 1.5550e-04 - KL loss: 184.1168 - beta: 2.5119e-04\n",
      "Epoch 05405: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2648.5783 - recon_loss: 1.5550e-04 - KL loss: 184.1141 - beta: 2.5119e-04 - val_loss: 2954.9343 - val_recon_loss: 1.7518e-04 - val_KL loss: 178.5374 - val_beta: 2.5119e-04\n",
      "Epoch 5406/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2586.7778 - recon_loss: 1.5186e-04 - KL loss: 179.9627 - beta: 2.5119e-04 - val_loss: 3441.2256 - val_recon_loss: 2.0571e-04 - val_KL loss: 180.9804 - val_beta: 2.5119e-04\n",
      "Epoch 5407/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2567.6838 - recon_loss: 1.5052e-04 - KL loss: 182.1444 - beta: 2.5119e-04 - val_loss: 3158.8125 - val_recon_loss: 1.8790e-04 - val_KL loss: 180.8571 - val_beta: 2.5119e-04\n",
      "Epoch 5408/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2562.9711 - recon_loss: 1.5030e-04 - KL loss: 180.8310 - beta: 2.5119e-04 - val_loss: 3098.1052 - val_recon_loss: 1.8407e-04 - val_KL loss: 180.8591 - val_beta: 2.5119e-04\n",
      "Epoch 5409/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2548.6239 - recon_loss: 1.4937e-04 - KL loss: 181.2318 - beta: 2.5119e-04 - val_loss: 3317.8098 - val_recon_loss: 1.9797e-04 - val_KL loss: 180.2068 - val_beta: 2.5119e-04\n",
      "Epoch 5410/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2523.0407 - recon_loss: 1.4778e-04 - KL loss: 180.9410 - beta: 2.5119e-04\n",
      "Epoch 05410: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2523.0528 - recon_loss: 1.4778e-04 - KL loss: 180.9409 - beta: 2.5119e-04 - val_loss: 3163.9956 - val_recon_loss: 1.8824e-04 - val_KL loss: 180.5852 - val_beta: 2.5119e-04\n",
      "Epoch 5410/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1109.3372 - recon_loss: 1.5072e-04 - KL loss: 158.3586 - beta: 3.9811e-04 - val_loss: 1461.3876 - val_recon_loss: 2.0910e-04 - val_KL loss: 142.0377 - val_beta: 3.9811e-04\n",
      "Epoch 5411/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1137.2226 - recon_loss: 1.5820e-04 - KL loss: 139.0777 - beta: 3.9811e-04 - val_loss: 1395.8225 - val_recon_loss: 2.0014e-04 - val_KL loss: 133.0524 - val_beta: 3.9811e-04\n",
      "Epoch 5412/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1133.9158 - recon_loss: 1.5834e-04 - KL loss: 134.8339 - beta: 3.9811e-04 - val_loss: 1328.6577 - val_recon_loss: 1.8988e-04 - val_KL loss: 130.5714 - val_beta: 3.9811e-04\n",
      "Epoch 5413/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1120.3593 - recon_loss: 1.5663e-04 - KL loss: 132.0749 - beta: 3.9811e-04 - val_loss: 1336.1880 - val_recon_loss: 1.9127e-04 - val_KL loss: 129.3513 - val_beta: 3.9811e-04\n",
      "Epoch 5414/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1120.5336 - recon_loss: 1.5707e-04 - KL loss: 129.5191 - beta: 3.9811e-04 - val_loss: 1300.9670 - val_recon_loss: 1.8591e-04 - val_KL loss: 127.9850 - val_beta: 3.9811e-04\n",
      "Epoch 5415/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1131.3897 - recon_loss: 1.5894e-04 - KL loss: 128.5426 - beta: 3.9811e-04 - val_loss: 1390.4763 - val_recon_loss: 2.0061e-04 - val_KL loss: 124.7107 - val_beta: 3.9811e-04\n",
      "Epoch 5416/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1121.4746 - recon_loss: 1.5779e-04 - KL loss: 125.9118 - beta: 3.9811e-04 - val_loss: 1420.0121 - val_recon_loss: 2.0556e-04 - val_KL loss: 122.9986 - val_beta: 3.9811e-04\n",
      "Epoch 5417/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1127.3327 - recon_loss: 1.5903e-04 - KL loss: 123.9441 - beta: 3.9811e-04 - val_loss: 1436.7808 - val_recon_loss: 2.0874e-04 - val_KL loss: 119.7115 - val_beta: 3.9811e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5418/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1105.2600 - recon_loss: 1.5591e-04 - KL loss: 121.5607 - beta: 3.9811e-04 - val_loss: 1336.3907 - val_recon_loss: 1.9264e-04 - val_KL loss: 120.9202 - val_beta: 3.9811e-04\n",
      "Epoch 5419/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1117.9997 - recon_loss: 1.5780e-04 - KL loss: 122.3797 - beta: 3.9811e-04\n",
      "Epoch 05419: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1118.0156 - recon_loss: 1.5780e-04 - KL loss: 122.3789 - beta: 3.9811e-04 - val_loss: 1371.3956 - val_recon_loss: 1.9854e-04 - val_KL loss: 118.7236 - val_beta: 3.9811e-04\n",
      "Epoch 5420/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1107.4640 - recon_loss: 1.5636e-04 - KL loss: 120.9005 - beta: 3.9811e-04 - val_loss: 1468.4768 - val_recon_loss: 2.1372e-04 - val_KL loss: 119.9816 - val_beta: 3.9811e-04\n",
      "Epoch 5421/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1102.2364 - recon_loss: 1.5552e-04 - KL loss: 120.9467 - beta: 3.9811e-04 - val_loss: 1392.3342 - val_recon_loss: 2.0170e-04 - val_KL loss: 119.6996 - val_beta: 3.9811e-04\n",
      "Epoch 5422/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1092.8987 - recon_loss: 1.5415e-04 - KL loss: 120.2505 - beta: 3.9811e-04 - val_loss: 1323.6058 - val_recon_loss: 1.9067e-04 - val_KL loss: 120.5744 - val_beta: 3.9811e-04\n",
      "Epoch 5423/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1097.8869 - recon_loss: 1.5491e-04 - KL loss: 120.4519 - beta: 3.9811e-04 - val_loss: 1299.0109 - val_recon_loss: 1.8697e-04 - val_KL loss: 119.3260 - val_beta: 3.9811e-04\n",
      "Epoch 5424/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1088.4183 - recon_loss: 1.5352e-04 - KL loss: 119.7879 - beta: 3.9811e-04 - val_loss: 1357.0708 - val_recon_loss: 1.9598e-04 - val_KL loss: 120.5269 - val_beta: 3.9811e-04\n",
      "Epoch 5425/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1078.2089 - recon_loss: 1.5195e-04 - KL loss: 119.4741 - beta: 3.9811e-04 - val_loss: 1331.0585 - val_recon_loss: 1.9188e-04 - val_KL loss: 120.3982 - val_beta: 3.9811e-04\n",
      "Epoch 5426/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1076.7269 - recon_loss: 1.5167e-04 - KL loss: 119.7505 - beta: 3.9811e-04 - val_loss: 1301.7366 - val_recon_loss: 1.8748e-04 - val_KL loss: 118.8482 - val_beta: 3.9811e-04\n",
      "Epoch 5427/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1080.8705 - recon_loss: 1.5255e-04 - KL loss: 118.3618 - beta: 3.9811e-04 - val_loss: 1287.6243 - val_recon_loss: 1.8535e-04 - val_KL loss: 118.1702 - val_beta: 3.9811e-04\n",
      "Epoch 5428/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1081.8687 - recon_loss: 1.5272e-04 - KL loss: 118.2764 - beta: 3.9811e-04 - val_loss: 1308.8485 - val_recon_loss: 1.8865e-04 - val_KL loss: 118.5724 - val_beta: 3.9811e-04\n",
      "Epoch 5429/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1084.7818 - recon_loss: 1.5311e-04 - KL loss: 118.7431 - beta: 3.9811e-04 - val_loss: 1288.5190 - val_recon_loss: 1.8569e-04 - val_KL loss: 116.9119 - val_beta: 3.9811e-04\n",
      "Epoch 5430/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1077.4469 - recon_loss: 1.5215e-04 - KL loss: 117.4746 - beta: 3.9811e-04 - val_loss: 1355.9818 - val_recon_loss: 1.9622e-04 - val_KL loss: 117.8893 - val_beta: 3.9811e-04\n",
      "Epoch 5431/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1075.0525 - recon_loss: 1.5170e-04 - KL loss: 117.8755 - beta: 3.9811e-04 - val_loss: 1183.9047 - val_recon_loss: 1.6871e-04 - val_KL loss: 119.3958 - val_beta: 3.9811e-04\n",
      "Epoch 5432/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1076.1823 - recon_loss: 1.5192e-04 - KL loss: 117.6153 - beta: 3.9811e-04 - val_loss: 1190.0085 - val_recon_loss: 1.7005e-04 - val_KL loss: 117.0770 - val_beta: 3.9811e-04\n",
      "Epoch 5433/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1078.3308 - recon_loss: 1.5232e-04 - KL loss: 117.2455 - beta: 3.9811e-04 - val_loss: 1236.3867 - val_recon_loss: 1.7742e-04 - val_KL loss: 116.9645 - val_beta: 3.9811e-04\n",
      "Epoch 5434/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1072.8308 - recon_loss: 1.5153e-04 - KL loss: 116.7511 - beta: 3.9811e-04 - val_loss: 1239.7845 - val_recon_loss: 1.7809e-04 - val_KL loss: 116.1125 - val_beta: 3.9811e-04\n",
      "Epoch 5435/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1075.4902 - recon_loss: 1.5212e-04 - KL loss: 115.6557 - beta: 3.9811e-04 - val_loss: 1229.3982 - val_recon_loss: 1.7616e-04 - val_KL loss: 117.8935 - val_beta: 3.9811e-04\n",
      "Epoch 5436/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1066.6735 - recon_loss: 1.5062e-04 - KL loss: 116.3378 - beta: 3.9811e-04\n",
      "Epoch 05436: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1066.6741 - recon_loss: 1.5062e-04 - KL loss: 116.3371 - beta: 3.9811e-04 - val_loss: 1213.6353 - val_recon_loss: 1.7380e-04 - val_KL loss: 117.0111 - val_beta: 3.9811e-04\n",
      "Epoch 5437/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1076.1745 - recon_loss: 1.5202e-04 - KL loss: 116.9672 - beta: 3.9811e-04 - val_loss: 1238.5474 - val_recon_loss: 1.7782e-04 - val_KL loss: 116.5741 - val_beta: 3.9811e-04\n",
      "Epoch 5438/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1055.3026 - recon_loss: 1.4884e-04 - KL loss: 116.1895 - beta: 3.9811e-04 - val_loss: 1227.3259 - val_recon_loss: 1.7607e-04 - val_KL loss: 116.4207 - val_beta: 3.9811e-04\n",
      "Epoch 5439/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1061.7064 - recon_loss: 1.4991e-04 - KL loss: 115.8551 - beta: 3.9811e-04 - val_loss: 1243.3784 - val_recon_loss: 1.7860e-04 - val_KL loss: 116.4907 - val_beta: 3.9811e-04\n",
      "Epoch 5440/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1053.6915 - recon_loss: 1.4865e-04 - KL loss: 115.7550 - beta: 3.9811e-04 - val_loss: 1212.3572 - val_recon_loss: 1.7375e-04 - val_KL loss: 116.0430 - val_beta: 3.9811e-04\n",
      "Epoch 5441/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1062.0320 - recon_loss: 1.4997e-04 - KL loss: 115.7972 - beta: 3.9811e-04\n",
      "Epoch 05441: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1062.0282 - recon_loss: 1.4997e-04 - KL loss: 115.7972 - beta: 3.9811e-04 - val_loss: 1187.5593 - val_recon_loss: 1.6980e-04 - val_KL loss: 116.2025 - val_beta: 3.9811e-04\n",
      "Epoch 5441/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 494.9987 - recon_loss: 1.5667e-04 - KL loss: 101.4516 - beta: 6.3096e-04 - val_loss: 600.9965 - val_recon_loss: 2.0227e-04 - val_KL loss: 92.9071 - val_beta: 6.3096e-04\n",
      "Epoch 5442/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 490.8072 - recon_loss: 1.5869e-04 - KL loss: 92.2079 - beta: 6.3096e-04 - val_loss: 559.7309 - val_recon_loss: 1.8738e-04 - val_KL loss: 89.0545 - val_beta: 6.3096e-04\n",
      "Epoch 5443/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 493.3587 - recon_loss: 1.6094e-04 - KL loss: 89.1072 - beta: 6.3096e-04 - val_loss: 544.5699 - val_recon_loss: 1.8137e-04 - val_KL loss: 88.9849 - val_beta: 6.3096e-04\n",
      "Epoch 5444/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 501.9382 - recon_loss: 1.6501e-04 - KL loss: 87.4588 - beta: 6.3096e-04 - val_loss: 578.6259 - val_recon_loss: 1.9593e-04 - val_KL loss: 86.4824 - val_beta: 6.3096e-04\n",
      "Epoch 5445/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 496.2124 - recon_loss: 1.6392e-04 - KL loss: 84.4629 - beta: 6.3096e-04 - val_loss: 602.6913 - val_recon_loss: 2.0616e-04 - val_KL loss: 84.8481 - val_beta: 6.3096e-04\n",
      "Epoch 5446/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 490.9412 - recon_loss: 1.6182e-04 - KL loss: 84.4595 - beta: 6.3096e-04 - val_loss: 554.6821 - val_recon_loss: 1.8761e-04 - val_KL loss: 83.4343 - val_beta: 6.3096e-04\n",
      "Epoch 5447/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 486.2318 - recon_loss: 1.6033e-04 - KL loss: 83.4949 - beta: 6.3096e-04 - val_loss: 641.7432 - val_recon_loss: 2.2241e-04 - val_KL loss: 83.0692 - val_beta: 6.3096e-04\n",
      "Epoch 5448/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 492.3655 - recon_loss: 1.6295e-04 - KL loss: 83.0519 - beta: 6.3096e-04\n",
      "Epoch 05448: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 492.3643 - recon_loss: 1.6295e-04 - KL loss: 83.0514 - beta: 6.3096e-04 - val_loss: 599.7244 - val_recon_loss: 2.0615e-04 - val_KL loss: 81.8933 - val_beta: 6.3096e-04\n",
      "Epoch 5449/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 480.0218 - recon_loss: 1.5839e-04 - KL loss: 82.1607 - beta: 6.3096e-04 - val_loss: 616.5767 - val_recon_loss: 2.1292e-04 - val_KL loss: 81.7371 - val_beta: 6.3096e-04\n",
      "Epoch 5450/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 482.0449 - recon_loss: 1.5910e-04 - KL loss: 82.4042 - beta: 6.3096e-04 - val_loss: 581.6905 - val_recon_loss: 1.9928e-04 - val_KL loss: 81.1131 - val_beta: 6.3096e-04\n",
      "Epoch 5451/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 479.5349 - recon_loss: 1.5846e-04 - KL loss: 81.5118 - beta: 6.3096e-04 - val_loss: 613.2412 - val_recon_loss: 2.1180e-04 - val_KL loss: 81.2268 - val_beta: 6.3096e-04\n",
      "Epoch 5452/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 478.8059 - recon_loss: 1.5829e-04 - KL loss: 81.1916 - beta: 6.3096e-04 - val_loss: 554.7310 - val_recon_loss: 1.8875e-04 - val_KL loss: 80.6176 - val_beta: 6.3096e-04\n",
      "Epoch 5453/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 479.0450 - recon_loss: 1.5835e-04 - KL loss: 81.2838 - beta: 6.3096e-04 - val_loss: 536.0533 - val_recon_loss: 1.8128e-04 - val_KL loss: 80.6917 - val_beta: 6.3096e-04\n",
      "Epoch 5454/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 476.8872 - recon_loss: 1.5755e-04 - KL loss: 81.1478 - beta: 6.3096e-04 - val_loss: 536.9578 - val_recon_loss: 1.8177e-04 - val_KL loss: 80.3741 - val_beta: 6.3096e-04\n",
      "Epoch 5455/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 474.6810 - recon_loss: 1.5692e-04 - KL loss: 80.5159 - beta: 6.3096e-04 - val_loss: 538.4694 - val_recon_loss: 1.8254e-04 - val_KL loss: 79.9587 - val_beta: 6.3096e-04\n",
      "Epoch 5456/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 474.9309 - recon_loss: 1.5710e-04 - KL loss: 80.3127 - beta: 6.3096e-04 - val_loss: 533.0212 - val_recon_loss: 1.8068e-04 - val_KL loss: 79.1817 - val_beta: 6.3096e-04\n",
      "Epoch 5457/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 475.5361 - recon_loss: 1.5740e-04 - KL loss: 80.1764 - beta: 6.3096e-04 - val_loss: 528.0078 - val_recon_loss: 1.7865e-04 - val_KL loss: 79.2576 - val_beta: 6.3096e-04\n",
      "Epoch 5458/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 470.9502 - recon_loss: 1.5577e-04 - KL loss: 79.6647 - beta: 6.3096e-04 - val_loss: 533.3209 - val_recon_loss: 1.8089e-04 - val_KL loss: 78.9532 - val_beta: 6.3096e-04\n",
      "Epoch 5459/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 476.4557 - recon_loss: 1.5800e-04 - KL loss: 79.5804 - beta: 6.3096e-04 - val_loss: 539.0178 - val_recon_loss: 1.8334e-04 - val_KL loss: 78.4926 - val_beta: 6.3096e-04\n",
      "Epoch 5460/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 472.0252 - recon_loss: 1.5657e-04 - KL loss: 78.7282 - beta: 6.3096e-04 - val_loss: 550.6296 - val_recon_loss: 1.8815e-04 - val_KL loss: 78.0084 - val_beta: 6.3096e-04\n",
      "Epoch 5461/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 473.2330 - recon_loss: 1.5712e-04 - KL loss: 78.5584 - beta: 6.3096e-04 - val_loss: 527.2103 - val_recon_loss: 1.7853e-04 - val_KL loss: 78.7737 - val_beta: 6.3096e-04\n",
      "Epoch 5462/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 474.7760 - recon_loss: 1.5756e-04 - KL loss: 79.0088 - beta: 6.3096e-04 - val_loss: 611.4547 - val_recon_loss: 2.1227e-04 - val_KL loss: 78.2497 - val_beta: 6.3096e-04\n",
      "Epoch 5463/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 474.9915 - recon_loss: 1.5754e-04 - KL loss: 79.2626 - beta: 6.3096e-04 - val_loss: 569.6996 - val_recon_loss: 1.9589e-04 - val_KL loss: 77.6368 - val_beta: 6.3096e-04\n",
      "Epoch 5464/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 475.8386 - recon_loss: 1.5800e-04 - KL loss: 78.9491 - beta: 6.3096e-04 - val_loss: 609.4142 - val_recon_loss: 2.1187e-04 - val_KL loss: 77.2236 - val_beta: 6.3096e-04\n",
      "Epoch 5465/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 473.9959 - recon_loss: 1.5750e-04 - KL loss: 78.3658 - beta: 6.3096e-04 - val_loss: 538.0456 - val_recon_loss: 1.8320e-04 - val_KL loss: 77.8658 - val_beta: 6.3096e-04\n",
      "Epoch 5466/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 475.0823 - recon_loss: 1.5775e-04 - KL loss: 78.8441 - beta: 6.3096e-04 - val_loss: 513.7185 - val_recon_loss: 1.7370e-04 - val_KL loss: 77.3919 - val_beta: 6.3096e-04\n",
      "Epoch 5467/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 472.5117 - recon_loss: 1.5700e-04 - KL loss: 78.1476 - beta: 6.3096e-04 - val_loss: 539.8247 - val_recon_loss: 1.8397e-04 - val_KL loss: 77.7195 - val_beta: 6.3096e-04\n",
      "Epoch 5468/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 470.9683 - recon_loss: 1.5646e-04 - KL loss: 77.9711 - beta: 6.3096e-04 - val_loss: 587.1309 - val_recon_loss: 2.0293e-04 - val_KL loss: 77.3958 - val_beta: 6.3096e-04\n",
      "Epoch 5469/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 471.9078 - recon_loss: 1.5683e-04 - KL loss: 77.9613 - beta: 6.3096e-04 - val_loss: 570.9549 - val_recon_loss: 1.9649e-04 - val_KL loss: 77.3852 - val_beta: 6.3096e-04\n",
      "Epoch 5470/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 472.5004 - recon_loss: 1.5706e-04 - KL loss: 77.9912 - beta: 6.3096e-04 - val_loss: 655.8260 - val_recon_loss: 2.3047e-04 - val_KL loss: 76.9239 - val_beta: 6.3096e-04\n",
      "Epoch 5471/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 469.3376 - recon_loss: 1.5602e-04 - KL loss: 77.4280 - beta: 6.3096e-04\n",
      "Epoch 05471: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 469.3362 - recon_loss: 1.5602e-04 - KL loss: 77.4279 - beta: 6.3096e-04 - val_loss: 612.9751 - val_recon_loss: 2.1366e-04 - val_KL loss: 76.2775 - val_beta: 6.3096e-04\n",
      "Epoch 5472/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 469.6081 - recon_loss: 1.5624e-04 - KL loss: 77.1487 - beta: 6.3096e-04 - val_loss: 599.3876 - val_recon_loss: 2.0792e-04 - val_KL loss: 77.1215 - val_beta: 6.3096e-04\n",
      "Epoch 5473/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 466.7325 - recon_loss: 1.5495e-04 - KL loss: 77.5129 - beta: 6.3096e-04 - val_loss: 566.8546 - val_recon_loss: 1.9502e-04 - val_KL loss: 76.9987 - val_beta: 6.3096e-04\n",
      "Epoch 5474/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 465.3797 - recon_loss: 1.5457e-04 - KL loss: 77.1205 - beta: 6.3096e-04 - val_loss: 575.0050 - val_recon_loss: 1.9837e-04 - val_KL loss: 76.7302 - val_beta: 6.3096e-04\n",
      "Epoch 5475/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 471.5982 - recon_loss: 1.5697e-04 - KL loss: 77.2971 - beta: 6.3096e-04 - val_loss: 532.5733 - val_recon_loss: 1.8161e-04 - val_KL loss: 76.3909 - val_beta: 6.3096e-04\n",
      "Epoch 5476/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 465.7336 - recon_loss: 1.5478e-04 - KL loss: 76.9416 - beta: 6.3096e-04\n",
      "Epoch 05476: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 465.7328 - recon_loss: 1.5478e-04 - KL loss: 76.9416 - beta: 6.3096e-04 - val_loss: 530.9067 - val_recon_loss: 1.8085e-04 - val_KL loss: 76.6200 - val_beta: 6.3096e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5476/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 229.3198 - recon_loss: 1.6162e-04 - KL loss: 67.6967 - beta: 0.0010 - val_loss: 270.0468 - val_recon_loss: 2.0748e-04 - val_KL loss: 62.5680 - val_beta: 0.0010\n",
      "Epoch 5477/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 229.6943 - recon_loss: 1.6743e-04 - KL loss: 62.2683 - beta: 0.0010 - val_loss: 261.6338 - val_recon_loss: 2.0106e-04 - val_KL loss: 60.5773 - val_beta: 0.0010\n",
      "Epoch 5478/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 229.4995 - recon_loss: 1.6908e-04 - KL loss: 60.4210 - beta: 0.0010 - val_loss: 253.0796 - val_recon_loss: 1.9365e-04 - val_KL loss: 59.4335 - val_beta: 0.0010\n",
      "Epoch 5479/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 230.1753 - recon_loss: 1.7080e-04 - KL loss: 59.3755 - beta: 0.0010 - val_loss: 256.1212 - val_recon_loss: 1.9791e-04 - val_KL loss: 58.2146 - val_beta: 0.0010\n",
      "Epoch 5480/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 229.9716 - recon_loss: 1.7178e-04 - KL loss: 58.1960 - beta: 0.0010 - val_loss: 244.5140 - val_recon_loss: 1.8752e-04 - val_KL loss: 56.9917 - val_beta: 0.0010\n",
      "Epoch 5481/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 231.2568 - recon_loss: 1.7396e-04 - KL loss: 57.2980 - beta: 0.0010 - val_loss: 248.9497 - val_recon_loss: 1.9176e-04 - val_KL loss: 57.1893 - val_beta: 0.0010\n",
      "Epoch 5482/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 229.8178 - recon_loss: 1.7340e-04 - KL loss: 56.4227 - beta: 0.0010 - val_loss: 252.5567 - val_recon_loss: 1.9704e-04 - val_KL loss: 55.5124 - val_beta: 0.0010\n",
      "Epoch 5483/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 231.3805 - recon_loss: 1.7609e-04 - KL loss: 55.2941 - beta: 0.0010 - val_loss: 242.9674 - val_recon_loss: 1.8850e-04 - val_KL loss: 54.4688 - val_beta: 0.0010\n",
      "Epoch 5484/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 228.8938 - recon_loss: 1.7417e-04 - KL loss: 54.7205 - beta: 0.0010 - val_loss: 257.7974 - val_recon_loss: 2.0393e-04 - val_KL loss: 53.8702 - val_beta: 0.0010\n",
      "Epoch 5485/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 226.1692 - recon_loss: 1.7217e-04 - KL loss: 54.0006 - beta: 0.0010 - val_loss: 257.5704 - val_recon_loss: 2.0340e-04 - val_KL loss: 54.1748 - val_beta: 0.0010\n",
      "Epoch 5486/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 223.8099 - recon_loss: 1.7035e-04 - KL loss: 53.4629 - beta: 0.0010 - val_loss: 259.3158 - val_recon_loss: 2.0601e-04 - val_KL loss: 53.3049 - val_beta: 0.0010\n",
      "Epoch 5487/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 224.3314 - recon_loss: 1.7121e-04 - KL loss: 53.1186 - beta: 0.0010 - val_loss: 242.5388 - val_recon_loss: 1.9028e-04 - val_KL loss: 52.2571 - val_beta: 0.0010\n",
      "Epoch 5488/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 225.2761 - recon_loss: 1.7247e-04 - KL loss: 52.8061 - beta: 0.0010 - val_loss: 257.4550 - val_recon_loss: 2.0425e-04 - val_KL loss: 53.2012 - val_beta: 0.0010\n",
      "Epoch 5489/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 227.4676 - recon_loss: 1.7467e-04 - KL loss: 52.8012 - beta: 0.0010 - val_loss: 245.5569 - val_recon_loss: 1.9273e-04 - val_KL loss: 52.8264 - val_beta: 0.0010\n",
      "Epoch 5490/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 226.7034 - recon_loss: 1.7424e-04 - KL loss: 52.4609 - beta: 0.0010 - val_loss: 241.7512 - val_recon_loss: 1.8948e-04 - val_KL loss: 52.2725 - val_beta: 0.0010\n",
      "Epoch 5491/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 227.4969 - recon_loss: 1.7527e-04 - KL loss: 52.2299 - beta: 0.0010 - val_loss: 250.0855 - val_recon_loss: 1.9678e-04 - val_KL loss: 53.3067 - val_beta: 0.0010\n",
      "Epoch 5492/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 228.5379 - recon_loss: 1.7674e-04 - KL loss: 51.7947 - beta: 0.0010 - val_loss: 262.6232 - val_recon_loss: 2.0980e-04 - val_KL loss: 52.8232 - val_beta: 0.0010\n",
      "Epoch 5493/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 227.0309 - recon_loss: 1.7512e-04 - KL loss: 51.9076 - beta: 0.0010 - val_loss: 243.0649 - val_recon_loss: 1.9112e-04 - val_KL loss: 51.9470 - val_beta: 0.0010\n",
      "Epoch 5494/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 224.7662 - recon_loss: 1.7386e-04 - KL loss: 50.9049 - beta: 0.0010 - val_loss: 245.0436 - val_recon_loss: 1.9391e-04 - val_KL loss: 51.1370 - val_beta: 0.0010\n",
      "Epoch 5495/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 222.0033 - recon_loss: 1.7093e-04 - KL loss: 51.0738 - beta: 0.0010\n",
      "Epoch 05495: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 222.0031 - recon_loss: 1.7093e-04 - KL loss: 51.0737 - beta: 0.0010 - val_loss: 246.6559 - val_recon_loss: 1.9534e-04 - val_KL loss: 51.3130 - val_beta: 0.0010\n",
      "Epoch 5496/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 219.1100 - recon_loss: 1.6837e-04 - KL loss: 50.7380 - beta: 0.0010 - val_loss: 241.3640 - val_recon_loss: 1.9073e-04 - val_KL loss: 50.6370 - val_beta: 0.0010\n",
      "Epoch 5497/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 220.1032 - recon_loss: 1.6942e-04 - KL loss: 50.6814 - beta: 0.0010 - val_loss: 246.4839 - val_recon_loss: 1.9582e-04 - val_KL loss: 50.6635 - val_beta: 0.0010\n",
      "Epoch 5498/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 217.8417 - recon_loss: 1.6721e-04 - KL loss: 50.6296 - beta: 0.0010 - val_loss: 235.6967 - val_recon_loss: 1.8470e-04 - val_KL loss: 50.9918 - val_beta: 0.0010\n",
      "Epoch 5499/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 217.9399 - recon_loss: 1.6731e-04 - KL loss: 50.6277 - beta: 0.0010 - val_loss: 229.9936 - val_recon_loss: 1.7938e-04 - val_KL loss: 50.6108 - val_beta: 0.0010\n",
      "Epoch 5500/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 217.6076 - recon_loss: 1.6704e-04 - KL loss: 50.5651 - beta: 0.0010 - val_loss: 242.5247 - val_recon_loss: 1.9138e-04 - val_KL loss: 51.1412 - val_beta: 0.0010\n",
      "Epoch 5501/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 216.4211 - recon_loss: 1.6574e-04 - KL loss: 50.6848 - beta: 0.0010 - val_loss: 240.0206 - val_recon_loss: 1.8924e-04 - val_KL loss: 50.7822 - val_beta: 0.0010\n",
      "Epoch 5502/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 216.1214 - recon_loss: 1.6556e-04 - KL loss: 50.5648 - beta: 0.0010 - val_loss: 241.9504 - val_recon_loss: 1.9114e-04 - val_KL loss: 50.8142 - val_beta: 0.0010\n",
      "Epoch 5503/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 216.7639 - recon_loss: 1.6617e-04 - KL loss: 50.5895 - beta: 0.0010 - val_loss: 237.4463 - val_recon_loss: 1.8677e-04 - val_KL loss: 50.6741 - val_beta: 0.0010\n",
      "Epoch 5504/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 217.6468 - recon_loss: 1.6712e-04 - KL loss: 50.5223 - beta: 0.0010\n",
      "Epoch 05504: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 217.6459 - recon_loss: 1.6712e-04 - KL loss: 50.5222 - beta: 0.0010 - val_loss: 239.1670 - val_recon_loss: 1.8878e-04 - val_KL loss: 50.3886 - val_beta: 0.0010\n",
      "Epoch 5505/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 215.6810 - recon_loss: 1.6532e-04 - KL loss: 50.3647 - beta: 0.0010 - val_loss: 237.7264 - val_recon_loss: 1.8722e-04 - val_KL loss: 50.5062 - val_beta: 0.0010\n",
      "Epoch 5506/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 216.3282 - recon_loss: 1.6579e-04 - KL loss: 50.5398 - beta: 0.0010 - val_loss: 234.8720 - val_recon_loss: 1.8431e-04 - val_KL loss: 50.5609 - val_beta: 0.0010\n",
      "Epoch 5507/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 215.2392 - recon_loss: 1.6484e-04 - KL loss: 50.3973 - beta: 0.0010 - val_loss: 238.9393 - val_recon_loss: 1.8826e-04 - val_KL loss: 50.6773 - val_beta: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5508/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 216.1355 - recon_loss: 1.6561e-04 - KL loss: 50.5234 - beta: 0.0010 - val_loss: 237.1612 - val_recon_loss: 1.8655e-04 - val_KL loss: 50.6142 - val_beta: 0.0010\n",
      "Epoch 5509/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 214.4907 - recon_loss: 1.6400e-04 - KL loss: 50.4902 - beta: 0.0010\n",
      "Epoch 05509: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 214.4917 - recon_loss: 1.6400e-04 - KL loss: 50.4902 - beta: 0.0010 - val_loss: 239.5420 - val_recon_loss: 1.8911e-04 - val_KL loss: 50.4290 - val_beta: 0.0010\n",
      "Epoch 5509/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 116.0457 - recon_loss: 1.8105e-04 - KL loss: 43.9695 - beta: 0.0016 - val_loss: 124.1311 - val_recon_loss: 2.0858e-04 - val_KL loss: 41.0929 - val_beta: 0.0016\n",
      "Epoch 5510/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 113.7714 - recon_loss: 1.8383e-04 - KL loss: 40.5882 - beta: 0.0016 - val_loss: 120.6323 - val_recon_loss: 2.0270e-04 - val_KL loss: 39.9340 - val_beta: 0.0016\n",
      "Epoch 5511/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 113.5086 - recon_loss: 1.8572e-04 - KL loss: 39.5704 - beta: 0.0016 - val_loss: 117.7590 - val_recon_loss: 1.9776e-04 - val_KL loss: 39.0287 - val_beta: 0.0016\n",
      "Epoch 5512/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 113.4532 - recon_loss: 1.8765e-04 - KL loss: 38.7498 - beta: 0.0016 - val_loss: 124.1293 - val_recon_loss: 2.1458e-04 - val_KL loss: 38.7051 - val_beta: 0.0016\n",
      "Epoch 5513/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 117.7829 - recon_loss: 1.9895e-04 - KL loss: 38.5790 - beta: 0.0016 - val_loss: 126.6317 - val_recon_loss: 2.2212e-04 - val_KL loss: 38.2036 - val_beta: 0.0016\n",
      "Epoch 5514/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 119.7739 - recon_loss: 2.0438e-04 - KL loss: 38.4070 - beta: 0.0016 - val_loss: 125.6431 - val_recon_loss: 2.2083e-04 - val_KL loss: 37.7300 - val_beta: 0.0016\n",
      "Epoch 5515/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 115.4794 - recon_loss: 1.9556e-04 - KL loss: 37.6246 - beta: 0.0016 - val_loss: 123.5326 - val_recon_loss: 2.1671e-04 - val_KL loss: 37.2583 - val_beta: 0.0016\n",
      "Epoch 5516/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 116.2992 - recon_loss: 1.9811e-04 - KL loss: 37.4312 - beta: 0.0016\n",
      "Epoch 05516: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 116.2987 - recon_loss: 1.9811e-04 - KL loss: 37.4309 - beta: 0.0016 - val_loss: 121.2142 - val_recon_loss: 2.1044e-04 - val_KL loss: 37.4361 - val_beta: 0.0016\n",
      "Epoch 5517/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 112.2023 - recon_loss: 1.8856e-04 - KL loss: 37.1357 - beta: 0.0016 - val_loss: 116.1798 - val_recon_loss: 1.9810e-04 - val_KL loss: 37.3132 - val_beta: 0.0016\n",
      "Epoch 5518/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 112.4124 - recon_loss: 1.8915e-04 - KL loss: 37.1086 - beta: 0.0016 - val_loss: 117.2217 - val_recon_loss: 2.0094e-04 - val_KL loss: 37.2242 - val_beta: 0.0016\n",
      "Epoch 5519/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 111.6416 - recon_loss: 1.8759e-04 - KL loss: 36.9609 - beta: 0.0016 - val_loss: 118.4644 - val_recon_loss: 2.0485e-04 - val_KL loss: 36.9138 - val_beta: 0.0016\n",
      "Epoch 5520/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 111.6076 - recon_loss: 1.8771e-04 - KL loss: 36.8803 - beta: 0.0016 - val_loss: 120.6624 - val_recon_loss: 2.1015e-04 - val_KL loss: 36.9994 - val_beta: 0.0016\n",
      "Epoch 5521/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 112.1259 - recon_loss: 1.8874e-04 - KL loss: 36.9868 - beta: 0.0016 - val_loss: 119.7608 - val_recon_loss: 2.0825e-04 - val_KL loss: 36.8563 - val_beta: 0.0016\n",
      "Epoch 5522/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 111.9576 - recon_loss: 1.8848e-04 - KL loss: 36.9238 - beta: 0.0016\n",
      "Epoch 05522: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 111.9571 - recon_loss: 1.8848e-04 - KL loss: 36.9237 - beta: 0.0016 - val_loss: 118.2631 - val_recon_loss: 2.0488e-04 - val_KL loss: 36.7009 - val_beta: 0.0016\n",
      "Epoch 5523/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 111.0189 - recon_loss: 1.8649e-04 - KL loss: 36.7744 - beta: 0.0016 - val_loss: 114.2214 - val_recon_loss: 1.9444e-04 - val_KL loss: 36.8133 - val_beta: 0.0016\n",
      "Epoch 5524/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 110.5486 - recon_loss: 1.8542e-04 - KL loss: 36.7331 - beta: 0.0016 - val_loss: 116.1080 - val_recon_loss: 1.9940e-04 - val_KL loss: 36.7240 - val_beta: 0.0016\n",
      "Epoch 5525/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 110.8343 - recon_loss: 1.8615e-04 - KL loss: 36.7269 - beta: 0.0016 - val_loss: 117.3093 - val_recon_loss: 2.0239e-04 - val_KL loss: 36.7376 - val_beta: 0.0016\n",
      "Epoch 5526/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 111.4743 - recon_loss: 1.8753e-04 - KL loss: 36.8167 - beta: 0.0016 - val_loss: 116.5944 - val_recon_loss: 2.0058e-04 - val_KL loss: 36.7417 - val_beta: 0.0016\n",
      "Epoch 5527/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 110.7643 - recon_loss: 1.8589e-04 - KL loss: 36.7618 - beta: 0.0016 - val_loss: 116.5042 - val_recon_loss: 2.0077e-04 - val_KL loss: 36.5772 - val_beta: 0.0016\n",
      "Epoch 5528/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 110.1543 - recon_loss: 1.8472e-04 - KL loss: 36.6158 - beta: 0.0016\n",
      "Epoch 05528: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 110.1544 - recon_loss: 1.8472e-04 - KL loss: 36.6158 - beta: 0.0016 - val_loss: 115.5679 - val_recon_loss: 1.9836e-04 - val_KL loss: 36.6005 - val_beta: 0.0016\n",
      "Epoch 5529/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 110.3602 - recon_loss: 1.8513e-04 - KL loss: 36.6600 - beta: 0.0016 - val_loss: 116.3860 - val_recon_loss: 2.0049e-04 - val_KL loss: 36.5683 - val_beta: 0.0016\n",
      "Epoch 5530/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 110.5244 - recon_loss: 1.8559e-04 - KL loss: 36.6380 - beta: 0.0016 - val_loss: 115.0573 - val_recon_loss: 1.9718e-04 - val_KL loss: 36.5598 - val_beta: 0.0016\n",
      "Epoch 5531/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 110.7496 - recon_loss: 1.8607e-04 - KL loss: 36.6729 - beta: 0.0016 - val_loss: 119.4372 - val_recon_loss: 2.0811e-04 - val_KL loss: 36.5858 - val_beta: 0.0016\n",
      "Epoch 5532/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 110.7303 - recon_loss: 1.8608e-04 - KL loss: 36.6500 - beta: 0.0016 - val_loss: 115.8039 - val_recon_loss: 1.9900e-04 - val_KL loss: 36.5819 - val_beta: 0.0016\n",
      "Epoch 5533/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 110.6219 - recon_loss: 1.8592e-04 - KL loss: 36.6072 - beta: 0.0016\n",
      "Epoch 05533: ReduceLROnPlateau reducing learning rate to 9.999999654550589e-08.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 110.6218 - recon_loss: 1.8592e-04 - KL loss: 36.6072 - beta: 0.0016 - val_loss: 118.0107 - val_recon_loss: 2.0454e-04 - val_KL loss: 36.5827 - val_beta: 0.0016\n",
      "Epoch 5533/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 64.0598 - recon_loss: 2.0786e-04 - KL loss: 31.1169 - beta: 0.0025 - val_loss: 65.7615 - val_recon_loss: 2.3224e-04 - val_KL loss: 28.9538 - val_beta: 0.0025\n",
      "Epoch 5534/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 64.1424 - recon_loss: 2.2201e-04 - KL loss: 28.9561 - beta: 0.0025 - val_loss: 66.2557 - val_recon_loss: 2.3987e-04 - val_KL loss: 28.2391 - val_beta: 0.0025\n",
      "Epoch 5535/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 63.8755 - recon_loss: 2.2487e-04 - KL loss: 28.2355 - beta: 0.0025 - val_loss: 67.2615 - val_recon_loss: 2.4883e-04 - val_KL loss: 27.8248 - val_beta: 0.0025\n",
      "Epoch 5536/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 65.1430 - recon_loss: 2.3382e-04 - KL loss: 28.0847 - beta: 0.0025 - val_loss: 66.6768 - val_recon_loss: 2.4583e-04 - val_KL loss: 27.7156 - val_beta: 0.0025\n",
      "Epoch 5537/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 66.4934 - recon_loss: 2.4323e-04 - KL loss: 27.9440 - beta: 0.0025 - val_loss: 69.7609 - val_recon_loss: 2.6663e-04 - val_KL loss: 27.5037 - val_beta: 0.0025\n",
      "Epoch 5538/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 65.4092 - recon_loss: 2.3974e-04 - KL loss: 27.4126 - beta: 0.0025 - val_loss: 65.6797 - val_recon_loss: 2.4486e-04 - val_KL loss: 26.8716 - val_beta: 0.0025\n",
      "Epoch 5539/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 63.6975 - recon_loss: 2.3198e-04 - KL loss: 26.9318 - beta: 0.0025 - val_loss: 67.0851 - val_recon_loss: 2.5803e-04 - val_KL loss: 26.1901 - val_beta: 0.0025\n",
      "Epoch 5540/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 63.7354 - recon_loss: 2.3403e-04 - KL loss: 26.6446 - beta: 0.0025 - val_loss: 64.4255 - val_recon_loss: 2.3986e-04 - val_KL loss: 26.4100 - val_beta: 0.0025\n",
      "Epoch 5541/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 62.9120 - recon_loss: 2.2930e-04 - KL loss: 26.5701 - beta: 0.0025 - val_loss: 64.8729 - val_recon_loss: 2.4417e-04 - val_KL loss: 26.1742 - val_beta: 0.0025\n",
      "Epoch 5542/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 62.7996 - recon_loss: 2.3002e-04 - KL loss: 26.3436 - beta: 0.0025 - val_loss: 66.7598 - val_recon_loss: 2.5675e-04 - val_KL loss: 26.0680 - val_beta: 0.0025\n",
      "Epoch 5543/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 63.2395 - recon_loss: 2.3377e-04 - KL loss: 26.1900 - beta: 0.0025 - val_loss: 64.2047 - val_recon_loss: 2.4095e-04 - val_KL loss: 26.0162 - val_beta: 0.0025\n",
      "Epoch 5544/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 62.8985 - recon_loss: 2.3114e-04 - KL loss: 26.2652 - beta: 0.0025 - val_loss: 63.9993 - val_recon_loss: 2.3998e-04 - val_KL loss: 25.9652 - val_beta: 0.0025\n",
      "Epoch 5545/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 62.6000 - recon_loss: 2.3017e-04 - KL loss: 26.1212 - beta: 0.0025 - val_loss: 67.3493 - val_recon_loss: 2.5866e-04 - val_KL loss: 26.3545 - val_beta: 0.0025\n",
      "Epoch 5546/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 63.4383 - recon_loss: 2.3605e-04 - KL loss: 26.0273 - beta: 0.0025 - val_loss: 65.4138 - val_recon_loss: 2.5095e-04 - val_KL loss: 25.6406 - val_beta: 0.0025\n",
      "Epoch 5547/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 62.5784 - recon_loss: 2.3167e-04 - KL loss: 25.8619 - beta: 0.0025 - val_loss: 63.2559 - val_recon_loss: 2.3652e-04 - val_KL loss: 25.7701 - val_beta: 0.0025\n",
      "Epoch 5548/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 62.5990 - recon_loss: 2.3219e-04 - KL loss: 25.7999 - beta: 0.0025 - val_loss: 63.4799 - val_recon_loss: 2.3789e-04 - val_KL loss: 25.7768 - val_beta: 0.0025\n",
      "Epoch 5549/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 62.7847 - recon_loss: 2.3271e-04 - KL loss: 25.9026 - beta: 0.0025 - val_loss: 64.1881 - val_recon_loss: 2.4429e-04 - val_KL loss: 25.4709 - val_beta: 0.0025\n",
      "Epoch 5550/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 61.5838 - recon_loss: 2.2646e-04 - KL loss: 25.6926 - beta: 0.0025 - val_loss: 63.9231 - val_recon_loss: 2.4388e-04 - val_KL loss: 25.2715 - val_beta: 0.0025\n",
      "Epoch 5551/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 61.2285 - recon_loss: 2.2497e-04 - KL loss: 25.5730 - beta: 0.0025 - val_loss: 63.6430 - val_recon_loss: 2.4217e-04 - val_KL loss: 25.2612 - val_beta: 0.0025\n",
      "Epoch 5552/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 61.1678 - recon_loss: 2.2527e-04 - KL loss: 25.4644 - beta: 0.0025 - val_loss: 63.2294 - val_recon_loss: 2.4037e-04 - val_KL loss: 25.1334 - val_beta: 0.0025\n",
      "Epoch 5553/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 61.0970 - recon_loss: 2.2526e-04 - KL loss: 25.3961 - beta: 0.0025 - val_loss: 65.3176 - val_recon_loss: 2.5340e-04 - val_KL loss: 25.1566 - val_beta: 0.0025\n",
      "Epoch 5554/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 61.3935 - recon_loss: 2.2715e-04 - KL loss: 25.3920 - beta: 0.0025 - val_loss: 65.3398 - val_recon_loss: 2.5332e-04 - val_KL loss: 25.1917 - val_beta: 0.0025\n",
      "Epoch 5555/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 61.5485 - recon_loss: 2.2805e-04 - KL loss: 25.4052 - beta: 0.0025 - val_loss: 62.9991 - val_recon_loss: 2.3943e-04 - val_KL loss: 25.0523 - val_beta: 0.0025\n",
      "Epoch 5556/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 61.4119 - recon_loss: 2.2725e-04 - KL loss: 25.3959 - beta: 0.0025 - val_loss: 65.7463 - val_recon_loss: 2.5708e-04 - val_KL loss: 25.0020 - val_beta: 0.0025\n",
      "Epoch 5557/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 60.8073 - recon_loss: 2.2456e-04 - KL loss: 25.2174 - beta: 0.0025 - val_loss: 62.0735 - val_recon_loss: 2.3471e-04 - val_KL loss: 24.8742 - val_beta: 0.0025\n",
      "Epoch 5558/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 60.6183 - recon_loss: 2.2400e-04 - KL loss: 25.1161 - beta: 0.0025 - val_loss: 65.8587 - val_recon_loss: 2.5727e-04 - val_KL loss: 25.0834 - val_beta: 0.0025\n",
      "Epoch 5559/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 60.9411 - recon_loss: 2.2563e-04 - KL loss: 25.1809 - beta: 0.0025 - val_loss: 66.1842 - val_recon_loss: 2.6137e-04 - val_KL loss: 24.7597 - val_beta: 0.0025\n",
      "Epoch 5560/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 60.5268 - recon_loss: 2.2464e-04 - KL loss: 24.9234 - beta: 0.0025 - val_loss: 65.9546 - val_recon_loss: 2.5871e-04 - val_KL loss: 24.9516 - val_beta: 0.0025\n",
      "Epoch 5561/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 60.5971 - recon_loss: 2.2435e-04 - KL loss: 25.0392 - beta: 0.0025 - val_loss: 65.9339 - val_recon_loss: 2.5913e-04 - val_KL loss: 24.8645 - val_beta: 0.0025\n",
      "Epoch 5562/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 60.7642 - recon_loss: 2.2549e-04 - KL loss: 25.0259 - beta: 0.0025\n",
      "Epoch 05562: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 60.7644 - recon_loss: 2.2549e-04 - KL loss: 25.0259 - beta: 0.0025 - val_loss: 62.6615 - val_recon_loss: 2.3907e-04 - val_KL loss: 24.7709 - val_beta: 0.0025\n",
      "Epoch 5563/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 59.8922 - recon_loss: 2.2086e-04 - KL loss: 24.8882 - beta: 0.0025 - val_loss: 61.0833 - val_recon_loss: 2.2910e-04 - val_KL loss: 24.7736 - val_beta: 0.0025\n",
      "Epoch 5564/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 60.1061 - recon_loss: 2.2122e-04 - KL loss: 25.0448 - beta: 0.0025 - val_loss: 61.3566 - val_recon_loss: 2.3137e-04 - val_KL loss: 24.6870 - val_beta: 0.0025\n",
      "Epoch 5565/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 60.2171 - recon_loss: 2.2246e-04 - KL loss: 24.9589 - beta: 0.0025 - val_loss: 60.2136 - val_recon_loss: 2.2371e-04 - val_KL loss: 24.7587 - val_beta: 0.0025\n",
      "Epoch 5566/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 60.0659 - recon_loss: 2.2087e-04 - KL loss: 25.0599 - beta: 0.0025 - val_loss: 61.2847 - val_recon_loss: 2.3028e-04 - val_KL loss: 24.7886 - val_beta: 0.0025\n",
      "Epoch 5567/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 60.2274 - recon_loss: 2.2179e-04 - KL loss: 25.0762 - beta: 0.0025 - val_loss: 61.5338 - val_recon_loss: 2.3212e-04 - val_KL loss: 24.7451 - val_beta: 0.0025\n",
      "Epoch 5568/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 58s 58ms/step - loss: 59.7612 - recon_loss: 2.1936e-04 - KL loss: 24.9945 - beta: 0.0025 - val_loss: 65.2166 - val_recon_loss: 2.5233e-04 - val_KL loss: 25.2250 - val_beta: 0.0025\n",
      "Epoch 5569/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 59.7387 - recon_loss: 2.1920e-04 - KL loss: 24.9980 - beta: 0.0025 - val_loss: 61.7553 - val_recon_loss: 2.3447e-04 - val_KL loss: 24.5944 - val_beta: 0.0025\n",
      "Epoch 5570/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 59.6074 - recon_loss: 2.1935e-04 - KL loss: 24.8424 - beta: 0.0025 - val_loss: 59.7872 - val_recon_loss: 2.2209e-04 - val_KL loss: 24.5888 - val_beta: 0.0025\n",
      "Epoch 5571/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 59.6015 - recon_loss: 2.1894e-04 - KL loss: 24.9014 - beta: 0.0025 - val_loss: 61.5341 - val_recon_loss: 2.3370e-04 - val_KL loss: 24.4951 - val_beta: 0.0025\n",
      "Epoch 5572/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 59.8408 - recon_loss: 2.2002e-04 - KL loss: 24.9697 - beta: 0.0025 - val_loss: 63.0044 - val_recon_loss: 2.4254e-04 - val_KL loss: 24.5639 - val_beta: 0.0025\n",
      "Epoch 5573/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 59.6354 - recon_loss: 2.1920e-04 - KL loss: 24.8938 - beta: 0.0025 - val_loss: 63.1213 - val_recon_loss: 2.4233e-04 - val_KL loss: 24.7138 - val_beta: 0.0025\n",
      "Epoch 5574/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 59.7863 - recon_loss: 2.2006e-04 - KL loss: 24.9089 - beta: 0.0025 - val_loss: 62.5444 - val_recon_loss: 2.4041e-04 - val_KL loss: 24.4416 - val_beta: 0.0025\n",
      "Epoch 5575/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 59.3260 - recon_loss: 2.1835e-04 - KL loss: 24.7204 - beta: 0.0025\n",
      "Epoch 05575: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 59.3260 - recon_loss: 2.1835e-04 - KL loss: 24.7204 - beta: 0.0025 - val_loss: 62.1515 - val_recon_loss: 2.3833e-04 - val_KL loss: 24.3794 - val_beta: 0.0025\n",
      "Epoch 5576/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 59.2297 - recon_loss: 2.1752e-04 - KL loss: 24.7552 - beta: 0.0025 - val_loss: 62.9610 - val_recon_loss: 2.4267e-04 - val_KL loss: 24.4999 - val_beta: 0.0025\n",
      "Epoch 5577/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 59.2715 - recon_loss: 2.1743e-04 - KL loss: 24.8109 - beta: 0.0025 - val_loss: 61.1765 - val_recon_loss: 2.3145e-04 - val_KL loss: 24.4948 - val_beta: 0.0025\n",
      "Epoch 5578/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 59.3333 - recon_loss: 2.1783e-04 - KL loss: 24.8099 - beta: 0.0025 - val_loss: 59.7427 - val_recon_loss: 2.2250e-04 - val_KL loss: 24.4782 - val_beta: 0.0025\n",
      "Epoch 5579/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 59.3724 - recon_loss: 2.1815e-04 - KL loss: 24.7983 - beta: 0.0025 - val_loss: 60.8980 - val_recon_loss: 2.2995e-04 - val_KL loss: 24.4535 - val_beta: 0.0025\n",
      "Epoch 5580/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 59.2095 - recon_loss: 2.1740e-04 - KL loss: 24.7537 - beta: 0.0025 - val_loss: 60.4953 - val_recon_loss: 2.2669e-04 - val_KL loss: 24.5677 - val_beta: 0.0025\n",
      "Epoch 5581/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 59.1605 - recon_loss: 2.1700e-04 - KL loss: 24.7676 - beta: 0.0025 - val_loss: 61.3934 - val_recon_loss: 2.3199e-04 - val_KL loss: 24.6258 - val_beta: 0.0025\n",
      "Epoch 5582/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 59.4701 - recon_loss: 2.1824e-04 - KL loss: 24.8819 - beta: 0.0025 - val_loss: 62.2158 - val_recon_loss: 2.3738e-04 - val_KL loss: 24.5934 - val_beta: 0.0025\n",
      "Epoch 5583/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 59.1668 - recon_loss: 2.1665e-04 - KL loss: 24.8308 - beta: 0.0025\n",
      "Epoch 05583: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 59.1664 - recon_loss: 2.1664e-04 - KL loss: 24.8307 - beta: 0.0025 - val_loss: 64.3601 - val_recon_loss: 2.5146e-04 - val_KL loss: 24.5064 - val_beta: 0.0025\n",
      "Epoch 5584/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 59.2711 - recon_loss: 2.1737e-04 - KL loss: 24.8209 - beta: 0.0025 - val_loss: 60.7394 - val_recon_loss: 2.2882e-04 - val_KL loss: 24.4738 - val_beta: 0.0025\n",
      "Epoch 5585/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 59.2986 - recon_loss: 2.1747e-04 - KL loss: 24.8314 - beta: 0.0025 - val_loss: 62.1528 - val_recon_loss: 2.3747e-04 - val_KL loss: 24.5169 - val_beta: 0.0025\n",
      "Epoch 5586/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 59.0266 - recon_loss: 2.1605e-04 - KL loss: 24.7850 - beta: 0.0025 - val_loss: 60.6953 - val_recon_loss: 2.2842e-04 - val_KL loss: 24.4934 - val_beta: 0.0025\n",
      "Epoch 5587/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 59.0129 - recon_loss: 2.1622e-04 - KL loss: 24.7444 - beta: 0.0025 - val_loss: 62.4308 - val_recon_loss: 2.3941e-04 - val_KL loss: 24.4868 - val_beta: 0.0025\n",
      "Epoch 5588/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 59.1171 - recon_loss: 2.1628e-04 - KL loss: 24.8387 - beta: 0.0025\n",
      "Epoch 05588: ReduceLROnPlateau reducing learning rate to 9.999999654550589e-08.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 59.1172 - recon_loss: 2.1628e-04 - KL loss: 24.8387 - beta: 0.0025 - val_loss: 60.7955 - val_recon_loss: 2.2921e-04 - val_KL loss: 24.4681 - val_beta: 0.0025\n",
      "Epoch 5588/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 110.8396 - recon_loss: 2.0354e-04 - KL loss: 29.8074 - beta: 0.0016 - val_loss: 123.3826 - val_recon_loss: 2.3234e-04 - val_KL loss: 30.8855 - val_beta: 0.0016\n",
      "Epoch 5589/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 110.4880 - recon_loss: 2.0018e-04 - KL loss: 30.7956 - beta: 0.0016 - val_loss: 114.1464 - val_recon_loss: 2.0753e-04 - val_KL loss: 31.5281 - val_beta: 0.0016\n",
      "Epoch 5590/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 109.4564 - recon_loss: 1.9671e-04 - KL loss: 31.1440 - beta: 0.0016 - val_loss: 113.6978 - val_recon_loss: 2.0808e-04 - val_KL loss: 30.8616 - val_beta: 0.0016\n",
      "Epoch 5591/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 108.9355 - recon_loss: 1.9528e-04 - KL loss: 31.1948 - beta: 0.0016 - val_loss: 113.0446 - val_recon_loss: 2.0573e-04 - val_KL loss: 31.1431 - val_beta: 0.0016\n",
      "Epoch 5592/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 107.9720 - recon_loss: 1.9244e-04 - KL loss: 31.3614 - beta: 0.0016 - val_loss: 111.8364 - val_recon_loss: 2.0224e-04 - val_KL loss: 31.3213 - val_beta: 0.0016\n",
      "Epoch 5593/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 107.9326 - recon_loss: 1.9198e-04 - KL loss: 31.5023 - beta: 0.0016 - val_loss: 113.6041 - val_recon_loss: 2.0657e-04 - val_KL loss: 31.3675 - val_beta: 0.0016\n",
      "Epoch 5594/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 108.0762 - recon_loss: 1.9223e-04 - KL loss: 31.5498 - beta: 0.0016 - val_loss: 120.0172 - val_recon_loss: 2.2277e-04 - val_KL loss: 31.3297 - val_beta: 0.0016\n",
      "Epoch 5595/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 107.4182 - recon_loss: 1.9067e-04 - KL loss: 31.5114 - beta: 0.0016 - val_loss: 121.5884 - val_recon_loss: 2.2778e-04 - val_KL loss: 30.9076 - val_beta: 0.0016\n",
      "Epoch 5596/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 108.4557 - recon_loss: 1.9328e-04 - KL loss: 31.5082 - beta: 0.0016 - val_loss: 119.5436 - val_recon_loss: 2.2102e-04 - val_KL loss: 31.5554 - val_beta: 0.0016\n",
      "Epoch 5597/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 108.2177 - recon_loss: 1.9250e-04 - KL loss: 31.5807 - beta: 0.0016\n",
      "Epoch 05597: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 108.2177 - recon_loss: 1.9250e-04 - KL loss: 31.5806 - beta: 0.0016 - val_loss: 114.5441 - val_recon_loss: 2.0923e-04 - val_KL loss: 31.2466 - val_beta: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5598/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 106.3919 - recon_loss: 1.8771e-04 - KL loss: 31.6651 - beta: 0.0016 - val_loss: 110.8397 - val_recon_loss: 1.9927e-04 - val_KL loss: 31.5077 - val_beta: 0.0016\n",
      "Epoch 5599/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 105.9044 - recon_loss: 1.8639e-04 - KL loss: 31.7007 - beta: 0.0016 - val_loss: 118.7605 - val_recon_loss: 2.1915e-04 - val_KL loss: 31.5149 - val_beta: 0.0016\n",
      "Epoch 5600/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 105.7353 - recon_loss: 1.8577e-04 - KL loss: 31.7778 - beta: 0.0016 - val_loss: 117.8394 - val_recon_loss: 2.1699e-04 - val_KL loss: 31.4555 - val_beta: 0.0016\n",
      "Epoch 5601/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 106.2108 - recon_loss: 1.8701e-04 - KL loss: 31.7595 - beta: 0.0016 - val_loss: 116.3658 - val_recon_loss: 2.1335e-04 - val_KL loss: 31.4308 - val_beta: 0.0016\n",
      "Epoch 5602/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 106.4525 - recon_loss: 1.8740e-04 - KL loss: 31.8479 - beta: 0.0016 - val_loss: 118.4013 - val_recon_loss: 2.1827e-04 - val_KL loss: 31.5075 - val_beta: 0.0016\n",
      "Epoch 5603/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 106.2476 - recon_loss: 1.8673e-04 - KL loss: 31.9078 - beta: 0.0016\n",
      "Epoch 05603: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 106.2471 - recon_loss: 1.8673e-04 - KL loss: 31.9077 - beta: 0.0016 - val_loss: 118.4294 - val_recon_loss: 2.1794e-04 - val_KL loss: 31.6672 - val_beta: 0.0016\n",
      "Epoch 5604/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 105.2664 - recon_loss: 1.8454e-04 - KL loss: 31.7995 - beta: 0.0016 - val_loss: 119.3316 - val_recon_loss: 2.2022e-04 - val_KL loss: 31.6613 - val_beta: 0.0016\n",
      "Epoch 5605/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 105.6583 - recon_loss: 1.8551e-04 - KL loss: 31.8040 - beta: 0.0016 - val_loss: 118.0687 - val_recon_loss: 2.1700e-04 - val_KL loss: 31.6806 - val_beta: 0.0016\n",
      "Epoch 5606/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 105.0579 - recon_loss: 1.8397e-04 - KL loss: 31.8197 - beta: 0.0016 - val_loss: 120.9526 - val_recon_loss: 2.2416e-04 - val_KL loss: 31.7139 - val_beta: 0.0016\n",
      "Epoch 5607/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 104.5949 - recon_loss: 1.8274e-04 - KL loss: 31.8442 - beta: 0.0016 - val_loss: 118.5673 - val_recon_loss: 2.1801e-04 - val_KL loss: 31.7744 - val_beta: 0.0016\n",
      "Epoch 5608/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 105.5349 - recon_loss: 1.8492e-04 - KL loss: 31.9157 - beta: 0.0016\n",
      "Epoch 05608: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 105.5345 - recon_loss: 1.8492e-04 - KL loss: 31.9156 - beta: 0.0016 - val_loss: 116.0053 - val_recon_loss: 2.1185e-04 - val_KL loss: 31.6649 - val_beta: 0.0016\n",
      "Epoch 5608/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 218.8135 - recon_loss: 1.8133e-04 - KL loss: 37.4848 - beta: 0.0010 - val_loss: 243.4077 - val_recon_loss: 2.0454e-04 - val_KL loss: 38.8672 - val_beta: 0.0010\n",
      "Epoch 5609/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 220.1933 - recon_loss: 1.8100e-04 - KL loss: 39.1967 - beta: 0.0010 - val_loss: 290.7429 - val_recon_loss: 2.5120e-04 - val_KL loss: 39.5411 - val_beta: 0.0010\n",
      "Epoch 5610/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 223.6087 - recon_loss: 1.8364e-04 - KL loss: 39.9696 - beta: 0.0010 - val_loss: 229.5708 - val_recon_loss: 1.9003e-04 - val_KL loss: 39.5414 - val_beta: 0.0010\n",
      "Epoch 5611/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 217.2301 - recon_loss: 1.7751e-04 - KL loss: 39.7238 - beta: 0.0010 - val_loss: 231.6744 - val_recon_loss: 1.9194e-04 - val_KL loss: 39.7344 - val_beta: 0.0010\n",
      "Epoch 5612/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 216.5305 - recon_loss: 1.7654e-04 - KL loss: 39.9942 - beta: 0.0010 - val_loss: 231.9690 - val_recon_loss: 1.9215e-04 - val_KL loss: 39.8219 - val_beta: 0.0010\n",
      "Epoch 5613/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 215.7789 - recon_loss: 1.7574e-04 - KL loss: 40.0404 - beta: 0.0010 - val_loss: 225.2873 - val_recon_loss: 1.8573e-04 - val_KL loss: 39.5554 - val_beta: 0.0010\n",
      "Epoch 5614/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 215.6611 - recon_loss: 1.7545e-04 - KL loss: 40.2145 - beta: 0.0010 - val_loss: 236.0641 - val_recon_loss: 1.9603e-04 - val_KL loss: 40.0375 - val_beta: 0.0010\n",
      "Epoch 5615/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 216.8677 - recon_loss: 1.7672e-04 - KL loss: 40.1455 - beta: 0.0010 - val_loss: 306.2794 - val_recon_loss: 2.6612e-04 - val_KL loss: 40.1564 - val_beta: 0.0010\n",
      "Epoch 5616/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 214.1011 - recon_loss: 1.7368e-04 - KL loss: 40.4231 - beta: 0.0010 - val_loss: 231.3414 - val_recon_loss: 1.9189e-04 - val_KL loss: 39.4523 - val_beta: 0.0010\n",
      "Epoch 5617/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 214.4200 - recon_loss: 1.7423e-04 - KL loss: 40.1915 - beta: 0.0010 - val_loss: 230.9410 - val_recon_loss: 1.9065e-04 - val_KL loss: 40.2891 - val_beta: 0.0010\n",
      "Epoch 5618/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 213.1819 - recon_loss: 1.7267e-04 - KL loss: 40.5100 - beta: 0.0010\n",
      "Epoch 05618: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 213.1842 - recon_loss: 1.7267e-04 - KL loss: 40.5102 - beta: 0.0010 - val_loss: 230.7066 - val_recon_loss: 1.9015e-04 - val_KL loss: 40.5601 - val_beta: 0.0010\n",
      "Epoch 5619/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 210.8022 - recon_loss: 1.7026e-04 - KL loss: 40.5440 - beta: 0.0010 - val_loss: 253.3956 - val_recon_loss: 2.1283e-04 - val_KL loss: 40.5614 - val_beta: 0.0010\n",
      "Epoch 5620/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 211.9457 - recon_loss: 1.7113e-04 - KL loss: 40.8164 - beta: 0.0010 - val_loss: 237.8979 - val_recon_loss: 1.9730e-04 - val_KL loss: 40.5997 - val_beta: 0.0010\n",
      "Epoch 5621/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 210.9117 - recon_loss: 1.7016e-04 - KL loss: 40.7559 - beta: 0.0010 - val_loss: 231.4523 - val_recon_loss: 1.9090e-04 - val_KL loss: 40.5525 - val_beta: 0.0010\n",
      "Epoch 5622/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 210.4611 - recon_loss: 1.6953e-04 - KL loss: 40.9351 - beta: 0.0010 - val_loss: 235.6955 - val_recon_loss: 1.9498e-04 - val_KL loss: 40.7113 - val_beta: 0.0010\n",
      "Epoch 5623/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 212.0113 - recon_loss: 1.7089e-04 - KL loss: 41.1206 - beta: 0.0010\n",
      "Epoch 05623: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 212.0110 - recon_loss: 1.7089e-04 - KL loss: 41.1205 - beta: 0.0010 - val_loss: 233.9127 - val_recon_loss: 1.9318e-04 - val_KL loss: 40.7363 - val_beta: 0.0010\n",
      "Epoch 5623/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 477.4989 - recon_loss: 1.7125e-04 - KL loss: 47.3374 - beta: 6.3096e-04 - val_loss: 493.9869 - val_recon_loss: 1.7728e-04 - val_KL loss: 48.6676 - val_beta: 6.3096e-04\n",
      "Epoch 5624/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 469.5627 - recon_loss: 1.6715e-04 - KL loss: 49.6976 - beta: 6.3096e-04 - val_loss: 491.4006 - val_recon_loss: 1.7600e-04 - val_KL loss: 49.3194 - val_beta: 6.3096e-04\n",
      "Epoch 5625/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 465.4421 - recon_loss: 1.6556e-04 - KL loss: 49.5634 - beta: 6.3096e-04 - val_loss: 556.3045 - val_recon_loss: 2.0174e-04 - val_KL loss: 49.5532 - val_beta: 6.3096e-04\n",
      "Epoch 5626/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 58s 58ms/step - loss: 466.3461 - recon_loss: 1.6590e-04 - KL loss: 49.6302 - beta: 6.3096e-04 - val_loss: 511.1614 - val_recon_loss: 1.8351e-04 - val_KL loss: 50.2005 - val_beta: 6.3096e-04\n",
      "Epoch 5627/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 462.7946 - recon_loss: 1.6426e-04 - KL loss: 50.1812 - beta: 6.3096e-04 - val_loss: 490.8061 - val_recon_loss: 1.7543e-04 - val_KL loss: 50.1395 - val_beta: 6.3096e-04\n",
      "Epoch 5628/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 464.5603 - recon_loss: 1.6482e-04 - KL loss: 50.5435 - beta: 6.3096e-04 - val_loss: 539.5032 - val_recon_loss: 1.9475e-04 - val_KL loss: 50.3045 - val_beta: 6.3096e-04\n",
      "Epoch 5629/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 468.0493 - recon_loss: 1.6609e-04 - KL loss: 50.8561 - beta: 6.3096e-04 - val_loss: 509.1945 - val_recon_loss: 1.8275e-04 - val_KL loss: 50.1360 - val_beta: 6.3096e-04\n",
      "Epoch 5630/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 467.2182 - recon_loss: 1.6587e-04 - KL loss: 50.5725 - beta: 6.3096e-04 - val_loss: 517.4337 - val_recon_loss: 1.8526e-04 - val_KL loss: 52.0902 - val_beta: 6.3096e-04\n",
      "Epoch 5631/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 473.2979 - recon_loss: 1.6788e-04 - KL loss: 51.6061 - beta: 6.3096e-04 - val_loss: 507.7279 - val_recon_loss: 1.8179e-04 - val_KL loss: 51.0957 - val_beta: 6.3096e-04\n",
      "Epoch 5632/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 472.5893 - recon_loss: 1.6766e-04 - KL loss: 51.4453 - beta: 6.3096e-04\n",
      "Epoch 05632: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 472.5938 - recon_loss: 1.6766e-04 - KL loss: 51.4454 - beta: 6.3096e-04 - val_loss: 566.0972 - val_recon_loss: 2.0452e-04 - val_KL loss: 52.3686 - val_beta: 6.3096e-04\n",
      "Epoch 5633/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 464.5587 - recon_loss: 1.6439e-04 - KL loss: 51.6252 - beta: 6.3096e-04 - val_loss: 567.1488 - val_recon_loss: 2.0485e-04 - val_KL loss: 52.5944 - val_beta: 6.3096e-04\n",
      "Epoch 5634/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 457.6188 - recon_loss: 1.6158e-04 - KL loss: 51.7514 - beta: 6.3096e-04 - val_loss: 542.5836 - val_recon_loss: 1.9509e-04 - val_KL loss: 52.5474 - val_beta: 6.3096e-04\n",
      "Epoch 5635/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 463.1953 - recon_loss: 1.6372e-04 - KL loss: 51.9511 - beta: 6.3096e-04 - val_loss: 534.3256 - val_recon_loss: 1.9198e-04 - val_KL loss: 52.0906 - val_beta: 6.3096e-04\n",
      "Epoch 5636/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 465.5086 - recon_loss: 1.6462e-04 - KL loss: 52.0101 - beta: 6.3096e-04 - val_loss: 540.4077 - val_recon_loss: 1.9414e-04 - val_KL loss: 52.7609 - val_beta: 6.3096e-04\n",
      "Epoch 5637/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 459.9085 - recon_loss: 1.6235e-04 - KL loss: 52.0940 - beta: 6.3096e-04\n",
      "Epoch 05637: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 459.9082 - recon_loss: 1.6235e-04 - KL loss: 52.0939 - beta: 6.3096e-04 - val_loss: 556.8743 - val_recon_loss: 2.0087e-04 - val_KL loss: 52.3209 - val_beta: 6.3096e-04\n",
      "Epoch 5637/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1102.2052 - recon_loss: 1.6522e-04 - KL loss: 59.7401 - beta: 3.9811e-04 - val_loss: 1453.6089 - val_recon_loss: 2.2038e-04 - val_KL loss: 63.1205 - val_beta: 3.9811e-04\n",
      "Epoch 5638/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1096.9296 - recon_loss: 1.6377e-04 - KL loss: 63.5798 - beta: 3.9811e-04 - val_loss: 1252.6318 - val_recon_loss: 1.8832e-04 - val_KL loss: 64.4246 - val_beta: 3.9811e-04\n",
      "Epoch 5639/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1082.4025 - recon_loss: 1.6143e-04 - KL loss: 63.8349 - beta: 3.9811e-04 - val_loss: 1157.7129 - val_recon_loss: 1.7329e-04 - val_KL loss: 64.3579 - val_beta: 3.9811e-04\n",
      "Epoch 5640/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1069.4773 - recon_loss: 1.5926e-04 - KL loss: 64.5984 - beta: 3.9811e-04 - val_loss: 1195.7197 - val_recon_loss: 1.7935e-04 - val_KL loss: 64.0732 - val_beta: 3.9811e-04\n",
      "Epoch 5641/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1088.3770 - recon_loss: 1.6229e-04 - KL loss: 64.3802 - beta: 3.9811e-04 - val_loss: 1176.2742 - val_recon_loss: 1.7613e-04 - val_KL loss: 64.9879 - val_beta: 3.9811e-04\n",
      "Epoch 5642/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1076.0840 - recon_loss: 1.6021e-04 - KL loss: 65.2163 - beta: 3.9811e-04 - val_loss: 1164.6356 - val_recon_loss: 1.7430e-04 - val_KL loss: 64.8698 - val_beta: 3.9811e-04\n",
      "Epoch 5643/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1068.5510 - recon_loss: 1.5907e-04 - KL loss: 64.9063 - beta: 3.9811e-04 - val_loss: 1207.3954 - val_recon_loss: 1.8107e-04 - val_KL loss: 64.9014 - val_beta: 3.9811e-04\n",
      "Epoch 5644/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1065.9695 - recon_loss: 1.5860e-04 - KL loss: 65.2880 - beta: 3.9811e-04\n",
      "Epoch 05644: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1065.9777 - recon_loss: 1.5860e-04 - KL loss: 65.2881 - beta: 3.9811e-04 - val_loss: 1221.0837 - val_recon_loss: 1.8328e-04 - val_KL loss: 64.6878 - val_beta: 3.9811e-04\n",
      "Epoch 5645/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1054.6292 - recon_loss: 1.5686e-04 - KL loss: 64.9180 - beta: 3.9811e-04 - val_loss: 1235.3035 - val_recon_loss: 1.8539e-04 - val_KL loss: 65.5581 - val_beta: 3.9811e-04\n",
      "Epoch 5646/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1056.8566 - recon_loss: 1.5709e-04 - KL loss: 65.6696 - beta: 3.9811e-04 - val_loss: 1219.3229 - val_recon_loss: 1.8279e-04 - val_KL loss: 66.0186 - val_beta: 3.9811e-04\n",
      "Epoch 5647/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1061.1514 - recon_loss: 1.5769e-04 - KL loss: 66.1817 - beta: 3.9811e-04 - val_loss: 1160.4091 - val_recon_loss: 1.7351e-04 - val_KL loss: 65.6636 - val_beta: 3.9811e-04\n",
      "Epoch 5648/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1055.9124 - recon_loss: 1.5692e-04 - KL loss: 65.7931 - beta: 3.9811e-04 - val_loss: 1186.6526 - val_recon_loss: 1.7770e-04 - val_KL loss: 65.4158 - val_beta: 3.9811e-04\n",
      "Epoch 5649/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1049.1138 - recon_loss: 1.5586e-04 - KL loss: 65.7042 - beta: 3.9811e-04\n",
      "Epoch 05649: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1049.1163 - recon_loss: 1.5586e-04 - KL loss: 65.7043 - beta: 3.9811e-04 - val_loss: 1159.0103 - val_recon_loss: 1.7328e-04 - val_KL loss: 65.7179 - val_beta: 3.9811e-04\n",
      "Epoch 5649/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2647.6274 - recon_loss: 1.6234e-04 - KL loss: 74.7153 - beta: 2.5119e-04 - val_loss: 2810.2344 - val_recon_loss: 1.7210e-04 - val_KL loss: 82.6575 - val_beta: 2.5119e-04\n",
      "Epoch 5650/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2579.1878 - recon_loss: 1.5746e-04 - KL loss: 83.5379 - beta: 2.5119e-04 - val_loss: 2840.1875 - val_recon_loss: 1.7391e-04 - val_KL loss: 83.8577 - val_beta: 2.5119e-04\n",
      "Epoch 5651/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2605.4746 - recon_loss: 1.5904e-04 - KL loss: 84.7947 - beta: 2.5119e-04 - val_loss: 2792.3840 - val_recon_loss: 1.7082e-04 - val_KL loss: 85.1404 - val_beta: 2.5119e-04\n",
      "Epoch 5652/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 2557.4072 - recon_loss: 1.5597e-04 - KL loss: 85.3803 - beta: 2.5119e-04 - val_loss: 2828.0032 - val_recon_loss: 1.7299e-04 - val_KL loss: 86.2221 - val_beta: 2.5119e-04\n",
      "Epoch 5653/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2545.2126 - recon_loss: 1.5512e-04 - KL loss: 86.6912 - beta: 2.5119e-04 - val_loss: 2812.2268 - val_recon_loss: 1.7198e-04 - val_KL loss: 86.6030 - val_beta: 2.5119e-04\n",
      "Epoch 5654/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2518.2794 - recon_loss: 1.5344e-04 - KL loss: 86.4763 - beta: 2.5119e-04 - val_loss: 2827.4055 - val_recon_loss: 1.7286e-04 - val_KL loss: 87.6805 - val_beta: 2.5119e-04\n",
      "Epoch 5655/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2549.7131 - recon_loss: 1.5533e-04 - KL loss: 87.9708 - beta: 2.5119e-04 - val_loss: 2814.7327 - val_recon_loss: 1.7193e-04 - val_KL loss: 89.8159 - val_beta: 2.5119e-04\n",
      "Epoch 5656/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2604.0534 - recon_loss: 1.5870e-04 - KL loss: 88.7697 - beta: 2.5119e-04\n",
      "Epoch 05656: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 2604.0635 - recon_loss: 1.5870e-04 - KL loss: 88.7694 - beta: 2.5119e-04 - val_loss: 2841.7649 - val_recon_loss: 1.7381e-04 - val_KL loss: 87.1126 - val_beta: 2.5119e-04\n",
      "Epoch 5657/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2543.5962 - recon_loss: 1.5496e-04 - KL loss: 87.7132 - beta: 2.5119e-04 - val_loss: 2791.5916 - val_recon_loss: 1.7057e-04 - val_KL loss: 88.2162 - val_beta: 2.5119e-04\n",
      "Epoch 5658/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2563.8906 - recon_loss: 1.5617e-04 - KL loss: 88.7000 - beta: 2.5119e-04 - val_loss: 2674.8523 - val_recon_loss: 1.6324e-04 - val_KL loss: 87.6173 - val_beta: 2.5119e-04\n",
      "Epoch 5659/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2531.5858 - recon_loss: 1.5417e-04 - KL loss: 88.1194 - beta: 2.5119e-04 - val_loss: 2697.8862 - val_recon_loss: 1.6464e-04 - val_KL loss: 88.5413 - val_beta: 2.5119e-04\n",
      "Epoch 5660/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2533.5394 - recon_loss: 1.5426e-04 - KL loss: 88.6789 - beta: 2.5119e-04 - val_loss: 2661.0847 - val_recon_loss: 1.6230e-04 - val_KL loss: 88.8380 - val_beta: 2.5119e-04\n",
      "Epoch 5661/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2472.8506 - recon_loss: 1.5045e-04 - KL loss: 88.4279 - beta: 2.5119e-04 - val_loss: 2673.5767 - val_recon_loss: 1.6312e-04 - val_KL loss: 88.3685 - val_beta: 2.5119e-04\n",
      "Epoch 5662/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2513.0014 - recon_loss: 1.5296e-04 - KL loss: 88.7448 - beta: 2.5119e-04 - val_loss: 2724.1819 - val_recon_loss: 1.6632e-04 - val_KL loss: 88.1210 - val_beta: 2.5119e-04\n",
      "Epoch 5663/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2483.3181 - recon_loss: 1.5110e-04 - KL loss: 88.5481 - beta: 2.5119e-04 - val_loss: 2737.8386 - val_recon_loss: 1.6716e-04 - val_KL loss: 88.5852 - val_beta: 2.5119e-04\n",
      "Epoch 5664/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2480.5724 - recon_loss: 1.5094e-04 - KL loss: 88.3758 - beta: 2.5119e-04 - val_loss: 2753.9385 - val_recon_loss: 1.6820e-04 - val_KL loss: 88.2214 - val_beta: 2.5119e-04\n",
      "Epoch 5665/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2499.0364 - recon_loss: 1.5211e-04 - KL loss: 88.2678 - beta: 2.5119e-04\n",
      "Epoch 05665: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2499.0464 - recon_loss: 1.5211e-04 - KL loss: 88.2680 - beta: 2.5119e-04 - val_loss: 2763.3501 - val_recon_loss: 1.6879e-04 - val_KL loss: 88.2863 - val_beta: 2.5119e-04\n",
      "Epoch 5666/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2460.8460 - recon_loss: 1.4970e-04 - KL loss: 88.2134 - beta: 2.5119e-04 - val_loss: 2702.6443 - val_recon_loss: 1.6498e-04 - val_KL loss: 87.8712 - val_beta: 2.5119e-04\n",
      "Epoch 5667/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2477.9616 - recon_loss: 1.5078e-04 - KL loss: 88.2674 - beta: 2.5119e-04 - val_loss: 2640.1921 - val_recon_loss: 1.6103e-04 - val_KL loss: 88.0306 - val_beta: 2.5119e-04\n",
      "Epoch 5668/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2474.6257 - recon_loss: 1.5052e-04 - KL loss: 88.9918 - beta: 2.5119e-04 - val_loss: 2722.3418 - val_recon_loss: 1.6624e-04 - val_KL loss: 87.6318 - val_beta: 2.5119e-04\n",
      "Epoch 5669/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2476.3401 - recon_loss: 1.5069e-04 - KL loss: 88.0975 - beta: 2.5119e-04 - val_loss: 2719.8838 - val_recon_loss: 1.6607e-04 - val_KL loss: 87.8273 - val_beta: 2.5119e-04\n",
      "Epoch 5670/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2466.6181 - recon_loss: 1.5006e-04 - KL loss: 88.2517 - beta: 2.5119e-04 - val_loss: 2664.9412 - val_recon_loss: 1.6259e-04 - val_KL loss: 88.0195 - val_beta: 2.5119e-04\n",
      "Epoch 5671/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2440.4523 - recon_loss: 1.4842e-04 - KL loss: 88.1265 - beta: 2.5119e-04 - val_loss: 2697.3066 - val_recon_loss: 1.6463e-04 - val_KL loss: 88.0738 - val_beta: 2.5119e-04\n",
      "Epoch 5672/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2457.6179 - recon_loss: 1.4949e-04 - KL loss: 88.4102 - beta: 2.5119e-04\n",
      "Epoch 05672: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2457.6190 - recon_loss: 1.4949e-04 - KL loss: 88.4102 - beta: 2.5119e-04 - val_loss: 2732.0681 - val_recon_loss: 1.6682e-04 - val_KL loss: 88.0984 - val_beta: 2.5119e-04\n",
      "Epoch 5673/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2455.5973 - recon_loss: 1.4937e-04 - KL loss: 88.2985 - beta: 2.5119e-04 - val_loss: 2680.4709 - val_recon_loss: 1.6355e-04 - val_KL loss: 88.3134 - val_beta: 2.5119e-04\n",
      "Epoch 5674/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 2449.1214 - recon_loss: 1.4895e-04 - KL loss: 88.5009 - beta: 2.5119e-04 - val_loss: 2683.4912 - val_recon_loss: 1.6372e-04 - val_KL loss: 88.7611 - val_beta: 2.5119e-04\n",
      "Epoch 5675/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2443.8559 - recon_loss: 1.4860e-04 - KL loss: 88.7796 - beta: 2.5119e-04 - val_loss: 2637.7952 - val_recon_loss: 1.6084e-04 - val_KL loss: 88.6308 - val_beta: 2.5119e-04\n",
      "Epoch 5676/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2442.9338 - recon_loss: 1.4853e-04 - KL loss: 88.8772 - beta: 2.5119e-04 - val_loss: 2646.0718 - val_recon_loss: 1.6137e-04 - val_KL loss: 88.5880 - val_beta: 2.5119e-04\n",
      "Epoch 5677/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2455.8260 - recon_loss: 1.4935e-04 - KL loss: 88.7284 - beta: 2.5119e-04 - val_loss: 2674.4233 - val_recon_loss: 1.6316e-04 - val_KL loss: 88.5476 - val_beta: 2.5119e-04\n",
      "Epoch 5678/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2454.0578 - recon_loss: 1.4924e-04 - KL loss: 88.7847 - beta: 2.5119e-04 - val_loss: 2696.4395 - val_recon_loss: 1.6454e-04 - val_KL loss: 88.6692 - val_beta: 2.5119e-04\n",
      "Epoch 5679/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2436.1513 - recon_loss: 1.4810e-04 - KL loss: 88.9407 - beta: 2.5119e-04 - val_loss: 2706.9783 - val_recon_loss: 1.6520e-04 - val_KL loss: 88.6645 - val_beta: 2.5119e-04\n",
      "Epoch 5680/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2446.8368 - recon_loss: 1.4880e-04 - KL loss: 88.5819 - beta: 2.5119e-04\n",
      "Epoch 05680: ReduceLROnPlateau reducing learning rate to 9.999999654550589e-08.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2446.8304 - recon_loss: 1.4880e-04 - KL loss: 88.5820 - beta: 2.5119e-04 - val_loss: 2660.2192 - val_recon_loss: 1.6226e-04 - val_KL loss: 88.6217 - val_beta: 2.5119e-04\n",
      "Epoch 5681/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 2448.2343 - recon_loss: 1.4885e-04 - KL loss: 89.0634 - beta: 2.5119e-04 - val_loss: 2676.3740 - val_recon_loss: 1.6327e-04 - val_KL loss: 88.6452 - val_beta: 2.5119e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5682/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2450.2377 - recon_loss: 1.4898e-04 - KL loss: 88.9971 - beta: 2.5119e-04 - val_loss: 2709.2607 - val_recon_loss: 1.6535e-04 - val_KL loss: 88.6621 - val_beta: 2.5119e-04\n",
      "Epoch 5683/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2426.3738 - recon_loss: 1.4749e-04 - KL loss: 88.7871 - beta: 2.5119e-04 - val_loss: 2711.6995 - val_recon_loss: 1.6550e-04 - val_KL loss: 88.6443 - val_beta: 2.5119e-04\n",
      "Epoch 5684/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2448.4418 - recon_loss: 1.4889e-04 - KL loss: 88.6748 - beta: 2.5119e-04 - val_loss: 2724.3594 - val_recon_loss: 1.6630e-04 - val_KL loss: 88.6781 - val_beta: 2.5119e-04\n",
      "Epoch 5685/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2426.4394 - recon_loss: 1.4751e-04 - KL loss: 88.5619 - beta: 2.5119e-04\n",
      "Epoch 05685: ReduceLROnPlateau reducing learning rate to 3.1622774724297223e-08.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2426.4422 - recon_loss: 1.4751e-04 - KL loss: 88.5619 - beta: 2.5119e-04 - val_loss: 2678.5400 - val_recon_loss: 1.6341e-04 - val_KL loss: 88.6587 - val_beta: 2.5119e-04\n",
      "Epoch 5685/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6434.7532 - recon_loss: 1.5913e-04 - KL loss: 99.7063 - beta: 1.5849e-04 - val_loss: 7079.9058 - val_recon_loss: 1.7500e-04 - val_KL loss: 112.9937 - val_beta: 1.5849e-04\n",
      "Epoch 5686/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6405.1498 - recon_loss: 1.5805e-04 - KL loss: 113.2020 - beta: 1.5849e-04 - val_loss: 6574.8447 - val_recon_loss: 1.6230e-04 - val_KL loss: 113.4992 - val_beta: 1.5849e-04\n",
      "Epoch 5687/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6233.1434 - recon_loss: 1.5365e-04 - KL loss: 116.2061 - beta: 1.5849e-04 - val_loss: 6622.7324 - val_recon_loss: 1.6341e-04 - val_KL loss: 117.1254 - val_beta: 1.5849e-04\n",
      "Epoch 5688/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6226.5348 - recon_loss: 1.5343e-04 - KL loss: 118.2679 - beta: 1.5849e-04 - val_loss: 6485.4526 - val_recon_loss: 1.5997e-04 - val_KL loss: 116.7928 - val_beta: 1.5849e-04\n",
      "Epoch 5689/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6173.9495 - recon_loss: 1.5212e-04 - KL loss: 118.0785 - beta: 1.5849e-04 - val_loss: 6570.5562 - val_recon_loss: 1.6210e-04 - val_KL loss: 117.3129 - val_beta: 1.5849e-04\n",
      "Epoch 5690/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6100.1408 - recon_loss: 1.5023e-04 - KL loss: 119.1829 - beta: 1.5849e-04 - val_loss: 6786.0762 - val_recon_loss: 1.6745e-04 - val_KL loss: 119.8963 - val_beta: 1.5849e-04\n",
      "Epoch 5691/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6195.4037 - recon_loss: 1.5255e-04 - KL loss: 122.2681 - beta: 1.5849e-04 - val_loss: 6648.5625 - val_recon_loss: 1.6390e-04 - val_KL loss: 123.5990 - val_beta: 1.5849e-04\n",
      "Epoch 5692/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6197.5496 - recon_loss: 1.5261e-04 - KL loss: 122.0339 - beta: 1.5849e-04 - val_loss: 7047.0542 - val_recon_loss: 1.7405e-04 - val_KL loss: 117.8305 - val_beta: 1.5849e-04\n",
      "Epoch 5693/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6201.7099 - recon_loss: 1.5276e-04 - KL loss: 120.1747 - beta: 1.5849e-04\n",
      "Epoch 05693: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6201.6627 - recon_loss: 1.5276e-04 - KL loss: 120.1750 - beta: 1.5849e-04 - val_loss: 6647.3125 - val_recon_loss: 1.6396e-04 - val_KL loss: 119.8015 - val_beta: 1.5849e-04\n",
      "Epoch 5694/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6017.5648 - recon_loss: 1.4810e-04 - KL loss: 121.7745 - beta: 1.5849e-04 - val_loss: 6449.9492 - val_recon_loss: 1.5897e-04 - val_KL loss: 121.0739 - val_beta: 1.5849e-04\n",
      "Epoch 5695/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5977.6040 - recon_loss: 1.4708e-04 - KL loss: 122.3069 - beta: 1.5849e-04 - val_loss: 6501.8384 - val_recon_loss: 1.6027e-04 - val_KL loss: 121.5723 - val_beta: 1.5849e-04\n",
      "Epoch 5696/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6018.2634 - recon_loss: 1.4810e-04 - KL loss: 122.4356 - beta: 1.5849e-04 - val_loss: 6408.0488 - val_recon_loss: 1.5790e-04 - val_KL loss: 122.0197 - val_beta: 1.5849e-04\n",
      "Epoch 5697/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5941.8563 - recon_loss: 1.4614e-04 - KL loss: 123.8197 - beta: 1.5849e-04 - val_loss: 6482.1240 - val_recon_loss: 1.5978e-04 - val_KL loss: 121.2111 - val_beta: 1.5849e-04\n",
      "Epoch 5698/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5934.8350 - recon_loss: 1.4599e-04 - KL loss: 123.0610 - beta: 1.5849e-04 - val_loss: 6453.6875 - val_recon_loss: 1.5904e-04 - val_KL loss: 122.2503 - val_beta: 1.5849e-04\n",
      "Epoch 5699/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5991.4415 - recon_loss: 1.4739e-04 - KL loss: 123.5933 - beta: 1.5849e-04 - val_loss: 6800.8101 - val_recon_loss: 1.6772e-04 - val_KL loss: 123.8905 - val_beta: 1.5849e-04\n",
      "Epoch 5700/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6016.7426 - recon_loss: 1.4803e-04 - KL loss: 123.6848 - beta: 1.5849e-04 - val_loss: 6932.8525 - val_recon_loss: 1.7107e-04 - val_KL loss: 122.5360 - val_beta: 1.5849e-04\n",
      "Epoch 5701/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5870.8639 - recon_loss: 1.4438e-04 - KL loss: 123.1373 - beta: 1.5849e-04\n",
      "Epoch 05701: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5870.9205 - recon_loss: 1.4438e-04 - KL loss: 123.1373 - beta: 1.5849e-04 - val_loss: 6685.2915 - val_recon_loss: 1.6486e-04 - val_KL loss: 122.2788 - val_beta: 1.5849e-04\n",
      "Epoch 5702/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5911.5583 - recon_loss: 1.4538e-04 - KL loss: 123.8516 - beta: 1.5849e-04 - val_loss: 6591.7886 - val_recon_loss: 1.6250e-04 - val_KL loss: 122.5139 - val_beta: 1.5849e-04\n",
      "Epoch 5703/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5882.6659 - recon_loss: 1.4466e-04 - KL loss: 123.7592 - beta: 1.5849e-04 - val_loss: 6542.1577 - val_recon_loss: 1.6127e-04 - val_KL loss: 121.7642 - val_beta: 1.5849e-04\n",
      "Epoch 5704/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5930.4834 - recon_loss: 1.4586e-04 - KL loss: 123.7025 - beta: 1.5849e-04 - val_loss: 6431.2939 - val_recon_loss: 1.5847e-04 - val_KL loss: 122.3678 - val_beta: 1.5849e-04\n",
      "Epoch 5705/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5900.7902 - recon_loss: 1.4511e-04 - KL loss: 123.8042 - beta: 1.5849e-04 - val_loss: 6428.5630 - val_recon_loss: 1.5839e-04 - val_KL loss: 122.8173 - val_beta: 1.5849e-04\n",
      "Epoch 5706/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5877.2336 - recon_loss: 1.4450e-04 - KL loss: 124.4086 - beta: 1.5849e-04\n",
      "Epoch 05706: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5877.2508 - recon_loss: 1.4450e-04 - KL loss: 124.4088 - beta: 1.5849e-04 - val_loss: 6450.5269 - val_recon_loss: 1.5892e-04 - val_KL loss: 123.6371 - val_beta: 1.5849e-04\n",
      "Epoch 5706/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 15468.2516 - recon_loss: 1.5334e-04 - KL loss: 134.3997 - beta: 1.0000e-04 - val_loss: 17633.6465 - val_recon_loss: 1.7485e-04 - val_KL loss: 148.3574 - val_beta: 1.0000e-04\n",
      "Epoch 5707/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 14950.0975 - recon_loss: 1.4799e-04 - KL loss: 150.7252 - beta: 1.0000e-04 - val_loss: 16655.2969 - val_recon_loss: 1.6499e-04 - val_KL loss: 155.9084 - val_beta: 1.0000e-04\n",
      "Epoch 5708/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 15104.3044 - recon_loss: 1.4947e-04 - KL loss: 156.9125 - beta: 1.0000e-04 - val_loss: 16830.0020 - val_recon_loss: 1.6673e-04 - val_KL loss: 156.6580 - val_beta: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5709/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 15117.2750 - recon_loss: 1.4957e-04 - KL loss: 160.6579 - beta: 1.0000e-04 - val_loss: 17291.8691 - val_recon_loss: 1.7132e-04 - val_KL loss: 159.5261 - val_beta: 1.0000e-04\n",
      "Epoch 5710/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 15046.8286 - recon_loss: 1.4885e-04 - KL loss: 162.1072 - beta: 1.0000e-04 - val_loss: 16719.5508 - val_recon_loss: 1.6557e-04 - val_KL loss: 162.1354 - val_beta: 1.0000e-04\n",
      "Epoch 5711/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14970.3170 - recon_loss: 1.4806e-04 - KL loss: 164.7021 - beta: 1.0000e-04 - val_loss: 16225.5391 - val_recon_loss: 1.6061e-04 - val_KL loss: 164.6063 - val_beta: 1.0000e-04\n",
      "Epoch 5712/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14966.9936 - recon_loss: 1.4799e-04 - KL loss: 167.7187 - beta: 1.0000e-04 - val_loss: 16090.4980 - val_recon_loss: 1.5921e-04 - val_KL loss: 169.3027 - val_beta: 1.0000e-04\n",
      "Epoch 5713/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 15539.7219 - recon_loss: 1.5370e-04 - KL loss: 169.7961 - beta: 1.0000e-04 - val_loss: 18005.3320 - val_recon_loss: 1.7829e-04 - val_KL loss: 176.6299 - val_beta: 1.0000e-04\n",
      "Epoch 5714/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 15946.8890 - recon_loss: 1.5771e-04 - KL loss: 175.7189 - beta: 1.0000e-04 - val_loss: 17788.1270 - val_recon_loss: 1.7611e-04 - val_KL loss: 177.1137 - val_beta: 1.0000e-04\n",
      "Epoch 5715/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 16229.1119 - recon_loss: 1.6051e-04 - KL loss: 178.5059 - beta: 1.0000e-04 - val_loss: 18374.0781 - val_recon_loss: 1.8192e-04 - val_KL loss: 182.3603 - val_beta: 1.0000e-04\n",
      "Epoch 5716/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 16241.2276 - recon_loss: 1.6060e-04 - KL loss: 180.8502 - beta: 1.0000e-04 - val_loss: 16811.1914 - val_recon_loss: 1.6632e-04 - val_KL loss: 179.1587 - val_beta: 1.0000e-04\n",
      "Epoch 5717/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 16319.9262 - recon_loss: 1.6140e-04 - KL loss: 180.2609 - beta: 1.0000e-04\n",
      "Epoch 05717: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 16319.5264 - recon_loss: 1.6139e-04 - KL loss: 180.2601 - beta: 1.0000e-04 - val_loss: 17968.2051 - val_recon_loss: 1.7788e-04 - val_KL loss: 180.1398 - val_beta: 1.0000e-04\n",
      "Epoch 5718/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15653.1794 - recon_loss: 1.5474e-04 - KL loss: 179.3752 - beta: 1.0000e-04 - val_loss: 18447.1504 - val_recon_loss: 1.8266e-04 - val_KL loss: 181.4649 - val_beta: 1.0000e-04\n",
      "Epoch 5719/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 15489.1047 - recon_loss: 1.5308e-04 - KL loss: 181.5389 - beta: 1.0000e-04 - val_loss: 17262.0742 - val_recon_loss: 1.7083e-04 - val_KL loss: 178.6896 - val_beta: 1.0000e-04\n",
      "Epoch 5720/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15338.5103 - recon_loss: 1.5159e-04 - KL loss: 179.6249 - beta: 1.0000e-04 - val_loss: 17011.7812 - val_recon_loss: 1.6833e-04 - val_KL loss: 179.1370 - val_beta: 1.0000e-04\n",
      "Epoch 5721/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 15225.6626 - recon_loss: 1.5048e-04 - KL loss: 177.7097 - beta: 1.0000e-04 - val_loss: 16658.1777 - val_recon_loss: 1.6480e-04 - val_KL loss: 178.4362 - val_beta: 1.0000e-04\n",
      "Epoch 5722/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 15051.4629 - recon_loss: 1.4872e-04 - KL loss: 179.4969 - beta: 1.0000e-04\n",
      "Epoch 05722: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 15051.5646 - recon_loss: 1.4872e-04 - KL loss: 179.4992 - beta: 1.0000e-04 - val_loss: 17604.3945 - val_recon_loss: 1.7424e-04 - val_KL loss: 180.6410 - val_beta: 1.0000e-04\n",
      "Epoch 5722/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 41324.2714 - recon_loss: 1.6374e-04 - KL loss: 195.2524 - beta: 6.3096e-05 - val_loss: 46201.3320 - val_recon_loss: 1.8308e-04 - val_KL loss: 213.8889 - val_beta: 6.3096e-05\n",
      "Epoch 5723/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 41534.1722 - recon_loss: 1.6450e-04 - KL loss: 212.8219 - beta: 6.3096e-05 - val_loss: 42918.4805 - val_recon_loss: 1.7001e-04 - val_KL loss: 213.9489 - val_beta: 6.3096e-05\n",
      "Epoch 5724/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 39848.5266 - recon_loss: 1.5779e-04 - KL loss: 212.3562 - beta: 6.3096e-05 - val_loss: 43555.6367 - val_recon_loss: 1.7251e-04 - val_KL loss: 221.8757 - val_beta: 6.3096e-05\n",
      "Epoch 5725/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 40471.3004 - recon_loss: 1.6023e-04 - KL loss: 223.4358 - beta: 6.3096e-05 - val_loss: 43201.4219 - val_recon_loss: 1.7107e-04 - val_KL loss: 229.9549 - val_beta: 6.3096e-05\n",
      "Epoch 5726/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 39046.8556 - recon_loss: 1.5454e-04 - KL loss: 226.9843 - beta: 6.3096e-05 - val_loss: 46692.2852 - val_recon_loss: 1.8494e-04 - val_KL loss: 236.5030 - val_beta: 6.3096e-05\n",
      "Epoch 5727/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 39627.5245 - recon_loss: 1.5682e-04 - KL loss: 235.6782 - beta: 6.3096e-05 - val_loss: 50409.2773 - val_recon_loss: 1.9975e-04 - val_KL loss: 233.6319 - val_beta: 6.3096e-05\n",
      "Epoch 5728/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 39685.6919 - recon_loss: 1.5706e-04 - KL loss: 233.4753 - beta: 6.3096e-05\n",
      "Epoch 05728: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 39686.0014 - recon_loss: 1.5706e-04 - KL loss: 233.4774 - beta: 6.3096e-05 - val_loss: 44766.4570 - val_recon_loss: 1.7726e-04 - val_KL loss: 240.3664 - val_beta: 6.3096e-05\n",
      "Epoch 5729/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 40558.9166 - recon_loss: 1.6051e-04 - KL loss: 241.4723 - beta: 6.3096e-05 - val_loss: 43619.2500 - val_recon_loss: 1.7269e-04 - val_KL loss: 241.4834 - val_beta: 6.3096e-05\n",
      "Epoch 5730/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 39397.6817 - recon_loss: 1.5588e-04 - KL loss: 241.5022 - beta: 6.3096e-05 - val_loss: 42189.1875 - val_recon_loss: 1.6699e-04 - val_KL loss: 243.9474 - val_beta: 6.3096e-05\n",
      "Epoch 5731/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 39046.1857 - recon_loss: 1.5448e-04 - KL loss: 242.8539 - beta: 6.3096e-05 - val_loss: 40610.2617 - val_recon_loss: 1.6071e-04 - val_KL loss: 242.8433 - val_beta: 6.3096e-05\n",
      "Epoch 5732/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 38808.4474 - recon_loss: 1.5353e-04 - KL loss: 243.8890 - beta: 6.3096e-05 - val_loss: 42224.2188 - val_recon_loss: 1.6711e-04 - val_KL loss: 247.3658 - val_beta: 6.3096e-05\n",
      "Epoch 5733/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 38725.7367 - recon_loss: 1.5319e-04 - KL loss: 245.4163 - beta: 6.3096e-05 - val_loss: 41844.8438 - val_recon_loss: 1.6562e-04 - val_KL loss: 242.7762 - val_beta: 6.3096e-05\n",
      "Epoch 5734/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 38599.3497 - recon_loss: 1.5270e-04 - KL loss: 242.2005 - beta: 6.3096e-05 - val_loss: 41106.2344 - val_recon_loss: 1.6267e-04 - val_KL loss: 244.1325 - val_beta: 6.3096e-05\n",
      "Epoch 5735/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 38520.2563 - recon_loss: 1.5238e-04 - KL loss: 244.0442 - beta: 6.3096e-05 - val_loss: 42452.6484 - val_recon_loss: 1.6803e-04 - val_KL loss: 244.8259 - val_beta: 6.3096e-05\n",
      "Epoch 5736/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 38421.3761 - recon_loss: 1.5199e-04 - KL loss: 244.2918 - beta: 6.3096e-05\n",
      "Epoch 05736: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 38421.3216 - recon_loss: 1.5199e-04 - KL loss: 244.2930 - beta: 6.3096e-05 - val_loss: 41338.1914 - val_recon_loss: 1.6359e-04 - val_KL loss: 246.8654 - val_beta: 6.3096e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5737/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 37982.3112 - recon_loss: 1.5023e-04 - KL loss: 246.6837 - beta: 6.3096e-05 - val_loss: 41677.4492 - val_recon_loss: 1.6494e-04 - val_KL loss: 247.3541 - val_beta: 6.3096e-05\n",
      "Epoch 5738/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 37783.9837 - recon_loss: 1.4944e-04 - KL loss: 246.7959 - beta: 6.3096e-05 - val_loss: 43521.9844 - val_recon_loss: 1.7228e-04 - val_KL loss: 247.0612 - val_beta: 6.3096e-05\n",
      "Epoch 5739/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 37381.8966 - recon_loss: 1.4784e-04 - KL loss: 246.5908 - beta: 6.3096e-05 - val_loss: 42523.1992 - val_recon_loss: 1.6830e-04 - val_KL loss: 248.3254 - val_beta: 6.3096e-05\n",
      "Epoch 5740/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 37951.0926 - recon_loss: 1.5010e-04 - KL loss: 247.9267 - beta: 6.3096e-05 - val_loss: 40960.0703 - val_recon_loss: 1.6208e-04 - val_KL loss: 247.4369 - val_beta: 6.3096e-05\n",
      "Epoch 5741/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 38075.3187 - recon_loss: 1.5060e-04 - KL loss: 247.5011 - beta: 6.3096e-05\n",
      "Epoch 05741: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 38075.1374 - recon_loss: 1.5059e-04 - KL loss: 247.5013 - beta: 6.3096e-05 - val_loss: 40639.3086 - val_recon_loss: 1.6080e-04 - val_KL loss: 248.7027 - val_beta: 6.3096e-05\n",
      "Epoch 5741/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 100789.1031 - recon_loss: 1.5933e-04 - KL loss: 255.8395 - beta: 3.9811e-05 - val_loss: 105063.3672 - val_recon_loss: 1.6609e-04 - val_KL loss: 265.6382 - val_beta: 3.9811e-05\n",
      "Epoch 5742/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 98434.6060 - recon_loss: 1.5559e-04 - KL loss: 266.9390 - beta: 3.9811e-05 - val_loss: 104253.0156 - val_recon_loss: 1.6480e-04 - val_KL loss: 269.2125 - val_beta: 3.9811e-05\n",
      "Epoch 5743/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 97148.1064 - recon_loss: 1.5354e-04 - KL loss: 271.0966 - beta: 3.9811e-05 - val_loss: 105636.2969 - val_recon_loss: 1.6698e-04 - val_KL loss: 281.3925 - val_beta: 3.9811e-05\n",
      "Epoch 5744/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 98036.4433 - recon_loss: 1.5493e-04 - KL loss: 280.8373 - beta: 3.9811e-05 - val_loss: 105693.7969 - val_recon_loss: 1.6706e-04 - val_KL loss: 284.8090 - val_beta: 3.9811e-05\n",
      "Epoch 5745/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 97191.9745 - recon_loss: 1.5358e-04 - KL loss: 287.6331 - beta: 3.9811e-05 - val_loss: 104876.4766 - val_recon_loss: 1.6575e-04 - val_KL loss: 293.0838 - val_beta: 3.9811e-05\n",
      "Epoch 5746/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 99401.2394 - recon_loss: 1.5707e-04 - KL loss: 294.8325 - beta: 3.9811e-05 - val_loss: 105404.9062 - val_recon_loss: 1.6659e-04 - val_KL loss: 295.1516 - val_beta: 3.9811e-05\n",
      "Epoch 5747/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 96601.2874 - recon_loss: 1.5264e-04 - KL loss: 291.0235 - beta: 3.9811e-05\n",
      "Epoch 05747: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 96600.2164 - recon_loss: 1.5264e-04 - KL loss: 291.0221 - beta: 3.9811e-05 - val_loss: 105173.2500 - val_recon_loss: 1.6623e-04 - val_KL loss: 290.8209 - val_beta: 3.9811e-05\n",
      "Epoch 5748/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 94559.8873 - recon_loss: 1.4940e-04 - KL loss: 291.8666 - beta: 3.9811e-05 - val_loss: 108044.6641 - val_recon_loss: 1.7077e-04 - val_KL loss: 298.3713 - val_beta: 3.9811e-05\n",
      "Epoch 5749/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 94750.1448 - recon_loss: 1.4970e-04 - KL loss: 297.9118 - beta: 3.9811e-05 - val_loss: 106130.4531 - val_recon_loss: 1.6773e-04 - val_KL loss: 297.2329 - val_beta: 3.9811e-05\n",
      "Epoch 5750/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 94687.5785 - recon_loss: 1.4960e-04 - KL loss: 296.0030 - beta: 3.9811e-05 - val_loss: 99917.7422 - val_recon_loss: 1.5788e-04 - val_KL loss: 299.3021 - val_beta: 3.9811e-05\n",
      "Epoch 5751/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 93019.6138 - recon_loss: 1.4695e-04 - KL loss: 299.3124 - beta: 3.9811e-05 - val_loss: 107411.6719 - val_recon_loss: 1.6977e-04 - val_KL loss: 296.2519 - val_beta: 3.9811e-05\n",
      "Epoch 5752/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 93530.5520 - recon_loss: 1.4777e-04 - KL loss: 296.8634 - beta: 3.9811e-05 - val_loss: 98696.4844 - val_recon_loss: 1.5595e-04 - val_KL loss: 297.7838 - val_beta: 3.9811e-05\n",
      "Epoch 5753/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 93179.8748 - recon_loss: 1.4721e-04 - KL loss: 298.6436 - beta: 3.9811e-05 - val_loss: 98293.0859 - val_recon_loss: 1.5531e-04 - val_KL loss: 300.6635 - val_beta: 3.9811e-05\n",
      "Epoch 5754/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 92066.9724 - recon_loss: 1.4544e-04 - KL loss: 300.7442 - beta: 3.9811e-05 - val_loss: 99965.5469 - val_recon_loss: 1.5795e-04 - val_KL loss: 303.0457 - val_beta: 3.9811e-05\n",
      "Epoch 5755/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 92850.2353 - recon_loss: 1.4668e-04 - KL loss: 304.0064 - beta: 3.9811e-05 - val_loss: 100403.2969 - val_recon_loss: 1.5864e-04 - val_KL loss: 305.2069 - val_beta: 3.9811e-05\n",
      "Epoch 5756/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 93342.7333 - recon_loss: 1.4745e-04 - KL loss: 307.6134 - beta: 3.9811e-05 - val_loss: 99953.4375 - val_recon_loss: 1.5792e-04 - val_KL loss: 313.1502 - val_beta: 3.9811e-05\n",
      "Epoch 5757/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 92116.1147 - recon_loss: 1.4550e-04 - KL loss: 312.5782 - beta: 3.9811e-05 - val_loss: 98177.1328 - val_recon_loss: 1.5511e-04 - val_KL loss: 311.9034 - val_beta: 3.9811e-05\n",
      "Epoch 5758/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 92851.0476 - recon_loss: 1.4666e-04 - KL loss: 312.0450 - beta: 3.9811e-05 - val_loss: 100136.1953 - val_recon_loss: 1.5821e-04 - val_KL loss: 311.8731 - val_beta: 3.9811e-05\n",
      "Epoch 5759/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 93564.3397 - recon_loss: 1.4779e-04 - KL loss: 314.6948 - beta: 3.9811e-05 - val_loss: 99360.4531 - val_recon_loss: 1.5698e-04 - val_KL loss: 312.8298 - val_beta: 3.9811e-05\n",
      "Epoch 5760/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 93647.4958 - recon_loss: 1.4793e-04 - KL loss: 312.1578 - beta: 3.9811e-05 - val_loss: 99660.2422 - val_recon_loss: 1.5745e-04 - val_KL loss: 312.9023 - val_beta: 3.9811e-05\n",
      "Epoch 5761/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 92382.2379 - recon_loss: 1.4592e-04 - KL loss: 313.4514 - beta: 3.9811e-05 - val_loss: 103208.8594 - val_recon_loss: 1.6307e-04 - val_KL loss: 316.2650 - val_beta: 3.9811e-05\n",
      "Epoch 5762/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 91779.8619 - recon_loss: 1.4496e-04 - KL loss: 316.9015 - beta: 3.9811e-05\n",
      "Epoch 05762: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 91779.8439 - recon_loss: 1.4496e-04 - KL loss: 316.9017 - beta: 3.9811e-05 - val_loss: 99721.5703 - val_recon_loss: 1.5755e-04 - val_KL loss: 317.0590 - val_beta: 3.9811e-05\n",
      "Epoch 5763/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 92213.5190 - recon_loss: 1.4564e-04 - KL loss: 318.5130 - beta: 3.9811e-05 - val_loss: 97775.0078 - val_recon_loss: 1.5446e-04 - val_KL loss: 318.1237 - val_beta: 3.9811e-05\n",
      "Epoch 5764/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 92470.3486 - recon_loss: 1.4605e-04 - KL loss: 318.9381 - beta: 3.9811e-05 - val_loss: 97601.3828 - val_recon_loss: 1.5418e-04 - val_KL loss: 320.9526 - val_beta: 3.9811e-05\n",
      "Epoch 5765/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 91607.5207 - recon_loss: 1.4468e-04 - KL loss: 321.1689 - beta: 3.9811e-05 - val_loss: 97433.4375 - val_recon_loss: 1.5391e-04 - val_KL loss: 319.8141 - val_beta: 3.9811e-05\n",
      "Epoch 5766/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 92456.6829 - recon_loss: 1.4603e-04 - KL loss: 320.8276 - beta: 3.9811e-05 - val_loss: 98518.7344 - val_recon_loss: 1.5563e-04 - val_KL loss: 319.7664 - val_beta: 3.9811e-05\n",
      "Epoch 5767/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 91243.7234 - recon_loss: 1.4410e-04 - KL loss: 320.5264 - beta: 3.9811e-05 - val_loss: 98581.8125 - val_recon_loss: 1.5574e-04 - val_KL loss: 319.5851 - val_beta: 3.9811e-05\n",
      "Epoch 5768/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 91250.6115 - recon_loss: 1.4412e-04 - KL loss: 319.9974 - beta: 3.9811e-05 - val_loss: 98856.0234 - val_recon_loss: 1.5617e-04 - val_KL loss: 318.9363 - val_beta: 3.9811e-05\n",
      "Epoch 5769/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 91996.1515 - recon_loss: 1.4530e-04 - KL loss: 319.3047 - beta: 3.9811e-05 - val_loss: 99230.3438 - val_recon_loss: 1.5677e-04 - val_KL loss: 318.1902 - val_beta: 3.9811e-05\n",
      "Epoch 5770/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 91374.2625 - recon_loss: 1.4431e-04 - KL loss: 319.7843 - beta: 3.9811e-05\n",
      "Epoch 05770: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 91374.4776 - recon_loss: 1.4431e-04 - KL loss: 319.7848 - beta: 3.9811e-05 - val_loss: 98134.7500 - val_recon_loss: 1.5503e-04 - val_KL loss: 319.7144 - val_beta: 3.9811e-05\n",
      "Epoch 5771/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 91288.1700 - recon_loss: 1.4417e-04 - KL loss: 320.6481 - beta: 3.9811e-05 - val_loss: 97962.1094 - val_recon_loss: 1.5475e-04 - val_KL loss: 319.7404 - val_beta: 3.9811e-05\n",
      "Epoch 5772/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 91024.1532 - recon_loss: 1.4376e-04 - KL loss: 320.1334 - beta: 3.9811e-05 - val_loss: 98272.6875 - val_recon_loss: 1.5524e-04 - val_KL loss: 319.8028 - val_beta: 3.9811e-05\n",
      "Epoch 5773/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 91565.2496 - recon_loss: 1.4461e-04 - KL loss: 320.7907 - beta: 3.9811e-05 - val_loss: 97713.8984 - val_recon_loss: 1.5436e-04 - val_KL loss: 320.7340 - val_beta: 3.9811e-05\n",
      "Epoch 5774/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 90972.8588 - recon_loss: 1.4367e-04 - KL loss: 321.3960 - beta: 3.9811e-05 - val_loss: 97799.5938 - val_recon_loss: 1.5449e-04 - val_KL loss: 320.8147 - val_beta: 3.9811e-05\n",
      "Epoch 5775/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 90872.6593 - recon_loss: 1.4351e-04 - KL loss: 321.4298 - beta: 3.9811e-05\n",
      "Epoch 05775: ReduceLROnPlateau reducing learning rate to 9.999999654550589e-08.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 90872.8280 - recon_loss: 1.4351e-04 - KL loss: 321.4297 - beta: 3.9811e-05 - val_loss: 98339.9609 - val_recon_loss: 1.5535e-04 - val_KL loss: 320.5129 - val_beta: 3.9811e-05\n",
      "Epoch 5775/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 250824.9841 - recon_loss: 1.5805e-04 - KL loss: 331.6966 - beta: 2.5119e-05 - val_loss: 252091.6250 - val_recon_loss: 1.5885e-04 - val_KL loss: 324.0930 - val_beta: 2.5119e-05\n",
      "Epoch 5776/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 237692.4467 - recon_loss: 1.4977e-04 - KL loss: 330.0655 - beta: 2.5119e-05 - val_loss: 253566.1406 - val_recon_loss: 1.5977e-04 - val_KL loss: 343.8775 - val_beta: 2.5119e-05\n",
      "Epoch 5777/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 238149.7264 - recon_loss: 1.5005e-04 - KL loss: 342.2012 - beta: 2.5119e-05 - val_loss: 276997.7188 - val_recon_loss: 1.7456e-04 - val_KL loss: 338.5671 - val_beta: 2.5119e-05\n",
      "Epoch 5778/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 237266.6085 - recon_loss: 1.4949e-04 - KL loss: 341.4970 - beta: 2.5119e-05 - val_loss: 257169.7031 - val_recon_loss: 1.6205e-04 - val_KL loss: 341.5044 - val_beta: 2.5119e-05\n",
      "Epoch 5779/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 236397.1479 - recon_loss: 1.4894e-04 - KL loss: 346.8378 - beta: 2.5119e-05 - val_loss: 267880.4375 - val_recon_loss: 1.6880e-04 - val_KL loss: 352.4302 - val_beta: 2.5119e-05\n",
      "Epoch 5780/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 236872.3469 - recon_loss: 1.4923e-04 - KL loss: 355.6786 - beta: 2.5119e-05\n",
      "Epoch 05780: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 236871.8838 - recon_loss: 1.4923e-04 - KL loss: 355.6812 - beta: 2.5119e-05 - val_loss: 281398.7188 - val_recon_loss: 1.7732e-04 - val_KL loss: 366.7094 - val_beta: 2.5119e-05\n",
      "Epoch 5781/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 235597.0515 - recon_loss: 1.4842e-04 - KL loss: 364.6924 - beta: 2.5119e-05 - val_loss: 255727.7188 - val_recon_loss: 1.6112e-04 - val_KL loss: 363.9870 - val_beta: 2.5119e-05\n",
      "Epoch 5782/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 230172.2028 - recon_loss: 1.4500e-04 - KL loss: 363.6602 - beta: 2.5119e-05 - val_loss: 258376.9844 - val_recon_loss: 1.6280e-04 - val_KL loss: 361.9040 - val_beta: 2.5119e-05\n",
      "Epoch 5783/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 230820.1494 - recon_loss: 1.4541e-04 - KL loss: 362.9523 - beta: 2.5119e-05 - val_loss: 256528.4531 - val_recon_loss: 1.6163e-04 - val_KL loss: 364.1311 - val_beta: 2.5119e-05\n",
      "Epoch 5784/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 228816.4570 - recon_loss: 1.4414e-04 - KL loss: 365.5281 - beta: 2.5119e-05 - val_loss: 244603.7188 - val_recon_loss: 1.5410e-04 - val_KL loss: 364.3960 - val_beta: 2.5119e-05\n",
      "Epoch 5785/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 226723.1786 - recon_loss: 1.4282e-04 - KL loss: 365.6761 - beta: 2.5119e-05 - val_loss: 253554.0312 - val_recon_loss: 1.5975e-04 - val_KL loss: 365.3504 - val_beta: 2.5119e-05\n",
      "Epoch 5786/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 224907.7695 - recon_loss: 1.4168e-04 - KL loss: 365.6195 - beta: 2.5119e-05 - val_loss: 252978.9375 - val_recon_loss: 1.5939e-04 - val_KL loss: 366.0756 - val_beta: 2.5119e-05\n",
      "Epoch 5787/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 228859.7980 - recon_loss: 1.4417e-04 - KL loss: 366.7991 - beta: 2.5119e-05 - val_loss: 246911.2656 - val_recon_loss: 1.5556e-04 - val_KL loss: 366.1099 - val_beta: 2.5119e-05\n",
      "Epoch 5788/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 229221.0105 - recon_loss: 1.4440e-04 - KL loss: 368.8888 - beta: 2.5119e-05 - val_loss: 255710.7969 - val_recon_loss: 1.6111e-04 - val_KL loss: 370.3651 - val_beta: 2.5119e-05\n",
      "Epoch 5789/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 229201.3039 - recon_loss: 1.4438e-04 - KL loss: 369.4384 - beta: 2.5119e-05\n",
      "Epoch 05789: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 229200.9841 - recon_loss: 1.4438e-04 - KL loss: 369.4385 - beta: 2.5119e-05 - val_loss: 251948.5625 - val_recon_loss: 1.5873e-04 - val_KL loss: 370.6596 - val_beta: 2.5119e-05\n",
      "Epoch 5790/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 226550.2208 - recon_loss: 1.4271e-04 - KL loss: 371.8346 - beta: 2.5119e-05 - val_loss: 248484.5312 - val_recon_loss: 1.5655e-04 - val_KL loss: 370.4520 - val_beta: 2.5119e-05\n",
      "Epoch 5791/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 225299.7451 - recon_loss: 1.4192e-04 - KL loss: 371.9064 - beta: 2.5119e-05 - val_loss: 248682.5469 - val_recon_loss: 1.5667e-04 - val_KL loss: 371.2433 - val_beta: 2.5119e-05\n",
      "Epoch 5792/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 223651.3843 - recon_loss: 1.4088e-04 - KL loss: 371.9450 - beta: 2.5119e-05 - val_loss: 250119.7500 - val_recon_loss: 1.5758e-04 - val_KL loss: 371.2731 - val_beta: 2.5119e-05\n",
      "Epoch 5793/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 225867.8523 - recon_loss: 1.4228e-04 - KL loss: 372.1821 - beta: 2.5119e-05 - val_loss: 255912.8594 - val_recon_loss: 1.6124e-04 - val_KL loss: 369.9228 - val_beta: 2.5119e-05\n",
      "Epoch 5794/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 225280.3505 - recon_loss: 1.4191e-04 - KL loss: 370.2969 - beta: 2.5119e-05\n",
      "Epoch 05794: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 225281.0898 - recon_loss: 1.4191e-04 - KL loss: 370.2974 - beta: 2.5119e-05 - val_loss: 261070.0312 - val_recon_loss: 1.6449e-04 - val_KL loss: 371.0625 - val_beta: 2.5119e-05\n",
      "Epoch 5794/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 602511.8299 - recon_loss: 1.5125e-04 - KL loss: 375.7165 - beta: 1.5849e-05 - val_loss: 624305.8750 - val_recon_loss: 1.5672e-04 - val_KL loss: 390.4990 - val_beta: 1.5849e-05\n",
      "Epoch 5795/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 595458.3903 - recon_loss: 1.4947e-04 - KL loss: 389.0505 - beta: 1.5849e-05 - val_loss: 622139.8750 - val_recon_loss: 1.5618e-04 - val_KL loss: 386.2001 - val_beta: 1.5849e-05\n",
      "Epoch 5796/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 585644.3822 - recon_loss: 1.4701e-04 - KL loss: 389.6229 - beta: 1.5849e-05 - val_loss: 657476.3125 - val_recon_loss: 1.6505e-04 - val_KL loss: 396.1069 - val_beta: 1.5849e-05\n",
      "Epoch 5797/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 591623.9963 - recon_loss: 1.4851e-04 - KL loss: 395.9667 - beta: 1.5849e-05 - val_loss: 636012.3125 - val_recon_loss: 1.5966e-04 - val_KL loss: 397.2179 - val_beta: 1.5849e-05\n",
      "Epoch 5798/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 596231.0847 - recon_loss: 1.4967e-04 - KL loss: 400.3151 - beta: 1.5849e-05 - val_loss: 722367.8750 - val_recon_loss: 1.8134e-04 - val_KL loss: 444.5132 - val_beta: 1.5849e-05\n",
      "Epoch 5799/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 652122.1529 - recon_loss: 1.6370e-04 - KL loss: 433.3721 - beta: 1.5849e-05 - val_loss: 686330.3125 - val_recon_loss: 1.7229e-04 - val_KL loss: 419.2691 - val_beta: 1.5849e-05\n",
      "Epoch 5800/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 625358.9795 - recon_loss: 1.5698e-04 - KL loss: 419.5677 - beta: 1.5849e-05\n",
      "Epoch 05800: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 625346.8811 - recon_loss: 1.5697e-04 - KL loss: 419.5745 - beta: 1.5849e-05 - val_loss: 646714.5625 - val_recon_loss: 1.6234e-04 - val_KL loss: 426.9237 - val_beta: 1.5849e-05\n",
      "Epoch 5801/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 596533.3618 - recon_loss: 1.4974e-04 - KL loss: 426.0899 - beta: 1.5849e-05 - val_loss: 617588.5000 - val_recon_loss: 1.5502e-04 - val_KL loss: 426.8734 - val_beta: 1.5849e-05\n",
      "Epoch 5802/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 605384.5691 - recon_loss: 1.5196e-04 - KL loss: 427.0179 - beta: 1.5849e-05 - val_loss: 620385.1250 - val_recon_loss: 1.5573e-04 - val_KL loss: 426.3531 - val_beta: 1.5849e-05\n",
      "Epoch 5803/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 594874.5685 - recon_loss: 1.4932e-04 - KL loss: 429.3710 - beta: 1.5849e-05 - val_loss: 625315.2500 - val_recon_loss: 1.5696e-04 - val_KL loss: 428.7811 - val_beta: 1.5849e-05\n",
      "Epoch 5804/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 596135.9040 - recon_loss: 1.4963e-04 - KL loss: 430.5592 - beta: 1.5849e-05 - val_loss: 620641.9375 - val_recon_loss: 1.5579e-04 - val_KL loss: 430.7592 - val_beta: 1.5849e-05\n",
      "Epoch 5805/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 593720.3578 - recon_loss: 1.4903e-04 - KL loss: 430.5519 - beta: 1.5849e-05 - val_loss: 609878.0000 - val_recon_loss: 1.5309e-04 - val_KL loss: 429.9803 - val_beta: 1.5849e-05\n",
      "Epoch 5806/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 591291.8538 - recon_loss: 1.4842e-04 - KL loss: 434.1578 - beta: 1.5849e-05 - val_loss: 619806.8125 - val_recon_loss: 1.5558e-04 - val_KL loss: 438.8946 - val_beta: 1.5849e-05\n",
      "Epoch 5807/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 590050.9735 - recon_loss: 1.4810e-04 - KL loss: 438.0996 - beta: 1.5849e-05 - val_loss: 638159.0000 - val_recon_loss: 1.6019e-04 - val_KL loss: 439.5167 - val_beta: 1.5849e-05\n",
      "Epoch 5808/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 588539.6001 - recon_loss: 1.4772e-04 - KL loss: 438.6391 - beta: 1.5849e-05 - val_loss: 624632.3750 - val_recon_loss: 1.5679e-04 - val_KL loss: 437.3817 - val_beta: 1.5849e-05\n",
      "Epoch 5809/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 580318.0549 - recon_loss: 1.4566e-04 - KL loss: 440.0983 - beta: 1.5849e-05 - val_loss: 639663.4375 - val_recon_loss: 1.6057e-04 - val_KL loss: 440.7109 - val_beta: 1.5849e-05\n",
      "Epoch 5810/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 590142.3030 - recon_loss: 1.4813e-04 - KL loss: 437.7731 - beta: 1.5849e-05\n",
      "Epoch 05810: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 590138.9044 - recon_loss: 1.4813e-04 - KL loss: 437.7714 - beta: 1.5849e-05 - val_loss: 628741.3125 - val_recon_loss: 1.5782e-04 - val_KL loss: 436.5709 - val_beta: 1.5849e-05\n",
      "Epoch 5811/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 574437.9766 - recon_loss: 1.4418e-04 - KL loss: 435.4438 - beta: 1.5849e-05 - val_loss: 618977.5000 - val_recon_loss: 1.5537e-04 - val_KL loss: 435.2292 - val_beta: 1.5849e-05\n",
      "Epoch 5812/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 571533.1937 - recon_loss: 1.4345e-04 - KL loss: 435.6006 - beta: 1.5849e-05 - val_loss: 613808.5000 - val_recon_loss: 1.5407e-04 - val_KL loss: 437.0850 - val_beta: 1.5849e-05\n",
      "Epoch 5813/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 569166.8509 - recon_loss: 1.4286e-04 - KL loss: 436.8559 - beta: 1.5849e-05 - val_loss: 616736.3125 - val_recon_loss: 1.5481e-04 - val_KL loss: 437.7730 - val_beta: 1.5849e-05\n",
      "Epoch 5814/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 571684.1994 - recon_loss: 1.4349e-04 - KL loss: 439.0616 - beta: 1.5849e-05 - val_loss: 606595.6250 - val_recon_loss: 1.5226e-04 - val_KL loss: 439.9366 - val_beta: 1.5849e-05\n",
      "Epoch 5815/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 570810.7604 - recon_loss: 1.4327e-04 - KL loss: 440.3668 - beta: 1.5849e-05 - val_loss: 621376.2500 - val_recon_loss: 1.5597e-04 - val_KL loss: 441.6335 - val_beta: 1.5849e-05\n",
      "Epoch 5816/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 571137.8327 - recon_loss: 1.4335e-04 - KL loss: 440.7372 - beta: 1.5849e-05 - val_loss: 612201.8125 - val_recon_loss: 1.5367e-04 - val_KL loss: 441.1857 - val_beta: 1.5849e-05\n",
      "Epoch 5817/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 574416.4430 - recon_loss: 1.4418e-04 - KL loss: 441.3695 - beta: 1.5849e-05 - val_loss: 616081.5625 - val_recon_loss: 1.5464e-04 - val_KL loss: 441.7595 - val_beta: 1.5849e-05\n",
      "Epoch 5818/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 578094.0106 - recon_loss: 1.4510e-04 - KL loss: 442.1686 - beta: 1.5849e-05 - val_loss: 622189.8750 - val_recon_loss: 1.5618e-04 - val_KL loss: 441.6053 - val_beta: 1.5849e-05\n",
      "Epoch 5819/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 572951.4016 - recon_loss: 1.4381e-04 - KL loss: 440.8655 - beta: 1.5849e-05\n",
      "Epoch 05819: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 572947.9565 - recon_loss: 1.4381e-04 - KL loss: 440.8662 - beta: 1.5849e-05 - val_loss: 610258.7500 - val_recon_loss: 1.5318e-04 - val_KL loss: 441.3259 - val_beta: 1.5849e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5820/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 570564.3226 - recon_loss: 1.4321e-04 - KL loss: 441.7551 - beta: 1.5849e-05 - val_loss: 603880.3125 - val_recon_loss: 1.5158e-04 - val_KL loss: 441.9325 - val_beta: 1.5849e-05\n",
      "Epoch 5821/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 569890.3624 - recon_loss: 1.4304e-04 - KL loss: 441.1847 - beta: 1.5849e-05 - val_loss: 604144.0625 - val_recon_loss: 1.5164e-04 - val_KL loss: 441.4881 - val_beta: 1.5849e-05\n",
      "Epoch 5822/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 570643.9435 - recon_loss: 1.4323e-04 - KL loss: 441.8489 - beta: 1.5849e-05 - val_loss: 603028.1875 - val_recon_loss: 1.5136e-04 - val_KL loss: 441.0775 - val_beta: 1.5849e-05\n",
      "Epoch 5823/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 569385.8758 - recon_loss: 1.4291e-04 - KL loss: 440.7322 - beta: 1.5849e-05 - val_loss: 606147.0625 - val_recon_loss: 1.5215e-04 - val_KL loss: 442.2198 - val_beta: 1.5849e-05\n",
      "Epoch 5824/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 568294.3475 - recon_loss: 1.4264e-04 - KL loss: 442.3487 - beta: 1.5849e-05 - val_loss: 604853.1250 - val_recon_loss: 1.5182e-04 - val_KL loss: 442.6056 - val_beta: 1.5849e-05\n",
      "Epoch 5825/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 573001.8482 - recon_loss: 1.4382e-04 - KL loss: 442.9122 - beta: 1.5849e-05 - val_loss: 603777.1250 - val_recon_loss: 1.5155e-04 - val_KL loss: 443.4322 - val_beta: 1.5849e-05\n",
      "Epoch 5826/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 566437.0100 - recon_loss: 1.4217e-04 - KL loss: 443.5064 - beta: 1.5849e-05 - val_loss: 605874.5000 - val_recon_loss: 1.5208e-04 - val_KL loss: 444.0438 - val_beta: 1.5849e-05\n",
      "Epoch 5827/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 572167.7309 - recon_loss: 1.4361e-04 - KL loss: 443.8166 - beta: 1.5849e-05\n",
      "Epoch 05827: ReduceLROnPlateau reducing learning rate to 9.999999654550589e-08.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 572167.1647 - recon_loss: 1.4361e-04 - KL loss: 443.8167 - beta: 1.5849e-05 - val_loss: 605675.8125 - val_recon_loss: 1.5203e-04 - val_KL loss: 443.7465 - val_beta: 1.5849e-05\n",
      "Epoch 5828/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 565410.0277 - recon_loss: 1.4191e-04 - KL loss: 443.9624 - beta: 1.5849e-05 - val_loss: 605361.4375 - val_recon_loss: 1.5195e-04 - val_KL loss: 443.9220 - val_beta: 1.5849e-05\n",
      "Epoch 5829/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 569401.0408 - recon_loss: 1.4292e-04 - KL loss: 443.6021 - beta: 1.5849e-05 - val_loss: 604927.3125 - val_recon_loss: 1.5184e-04 - val_KL loss: 444.0620 - val_beta: 1.5849e-05\n",
      "Epoch 5830/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 566968.1080 - recon_loss: 1.4230e-04 - KL loss: 443.6668 - beta: 1.5849e-05 - val_loss: 603195.3750 - val_recon_loss: 1.5140e-04 - val_KL loss: 444.1120 - val_beta: 1.5849e-05\n",
      "Epoch 5831/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 569255.4816 - recon_loss: 1.4288e-04 - KL loss: 443.8061 - beta: 1.5849e-05 - val_loss: 604015.3125 - val_recon_loss: 1.5161e-04 - val_KL loss: 444.1586 - val_beta: 1.5849e-05\n",
      "Epoch 5832/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 564951.1104 - recon_loss: 1.4180e-04 - KL loss: 443.9729 - beta: 1.5849e-05\n",
      "Epoch 05832: ReduceLROnPlateau reducing learning rate to 3.1622774724297223e-08.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 564953.5481 - recon_loss: 1.4180e-04 - KL loss: 443.9728 - beta: 1.5849e-05 - val_loss: 605285.5625 - val_recon_loss: 1.5193e-04 - val_KL loss: 444.1734 - val_beta: 1.5849e-05\n",
      "Epoch 5832/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1558601.9945 - recon_loss: 1.5582e-04 - KL loss: 447.2156 - beta: 1.0000e-05 - val_loss: 1611434.8750 - val_recon_loss: 1.6110e-04 - val_KL loss: 442.9346 - val_beta: 1.0000e-05\n",
      "Epoch 5833/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1495812.8297 - recon_loss: 1.4954e-04 - KL loss: 450.7761 - beta: 1.0000e-05 - val_loss: 1572507.2500 - val_recon_loss: 1.5720e-04 - val_KL loss: 461.8765 - val_beta: 1.0000e-05\n",
      "Epoch 5834/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1519330.2220 - recon_loss: 1.5189e-04 - KL loss: 464.6353 - beta: 1.0000e-05 - val_loss: 1618984.0000 - val_recon_loss: 1.6185e-04 - val_KL loss: 462.4333 - val_beta: 1.0000e-05\n",
      "Epoch 5835/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1487236.7440 - recon_loss: 1.4868e-04 - KL loss: 464.2113 - beta: 1.0000e-05 - val_loss: 1521122.5000 - val_recon_loss: 1.5207e-04 - val_KL loss: 469.5088 - val_beta: 1.0000e-05\n",
      "Epoch 5836/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1473354.3257 - recon_loss: 1.4729e-04 - KL loss: 469.8032 - beta: 1.0000e-05 - val_loss: 1607956.1250 - val_recon_loss: 1.6075e-04 - val_KL loss: 467.3009 - val_beta: 1.0000e-05\n",
      "Epoch 5837/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1482094.8695 - recon_loss: 1.4816e-04 - KL loss: 472.7991 - beta: 1.0000e-05 - val_loss: 1595979.1250 - val_recon_loss: 1.5955e-04 - val_KL loss: 475.1490 - val_beta: 1.0000e-05\n",
      "Epoch 5838/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1470704.3263 - recon_loss: 1.4702e-04 - KL loss: 478.0117 - beta: 1.0000e-05 - val_loss: 1567111.0000 - val_recon_loss: 1.5666e-04 - val_KL loss: 482.6293 - val_beta: 1.0000e-05\n",
      "Epoch 5839/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1468259.6722 - recon_loss: 1.4678e-04 - KL loss: 483.0092 - beta: 1.0000e-05 - val_loss: 1593160.2500 - val_recon_loss: 1.5927e-04 - val_KL loss: 485.3640 - val_beta: 1.0000e-05\n",
      "Epoch 5840/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1465544.7631 - recon_loss: 1.4651e-04 - KL loss: 483.4229 - beta: 1.0000e-05\n",
      "Epoch 05840: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 1465554.9901 - recon_loss: 1.4651e-04 - KL loss: 483.4247 - beta: 1.0000e-05 - val_loss: 1566963.5000 - val_recon_loss: 1.5665e-04 - val_KL loss: 485.4825 - val_beta: 1.0000e-05\n",
      "Epoch 5841/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1449618.9809 - recon_loss: 1.4491e-04 - KL loss: 486.6712 - beta: 1.0000e-05 - val_loss: 1625514.8750 - val_recon_loss: 1.6250e-04 - val_KL loss: 486.0907 - val_beta: 1.0000e-05\n",
      "Epoch 5842/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1444321.3606 - recon_loss: 1.4438e-04 - KL loss: 487.6447 - beta: 1.0000e-05 - val_loss: 1534694.6250 - val_recon_loss: 1.5342e-04 - val_KL loss: 491.6575 - val_beta: 1.0000e-05\n",
      "Epoch 5843/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1428039.1299 - recon_loss: 1.4275e-04 - KL loss: 490.3679 - beta: 1.0000e-05 - val_loss: 1525984.0000 - val_recon_loss: 1.5255e-04 - val_KL loss: 489.7950 - val_beta: 1.0000e-05\n",
      "Epoch 5844/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1429524.1968 - recon_loss: 1.4290e-04 - KL loss: 489.8154 - beta: 1.0000e-05 - val_loss: 1504125.7500 - val_recon_loss: 1.5036e-04 - val_KL loss: 487.1201 - val_beta: 1.0000e-05\n",
      "Epoch 5845/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1445250.5032 - recon_loss: 1.4448e-04 - KL loss: 489.0189 - beta: 1.0000e-05 - val_loss: 1519123.6250 - val_recon_loss: 1.5186e-04 - val_KL loss: 490.8984 - val_beta: 1.0000e-05\n",
      "Epoch 5846/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1438784.1173 - recon_loss: 1.4383e-04 - KL loss: 491.3926 - beta: 1.0000e-05 - val_loss: 1510402.3750 - val_recon_loss: 1.5099e-04 - val_KL loss: 491.8929 - val_beta: 1.0000e-05\n",
      "Epoch 5847/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1439530.8199 - recon_loss: 1.4390e-04 - KL loss: 494.5545 - beta: 1.0000e-05 - val_loss: 1540576.8750 - val_recon_loss: 1.5401e-04 - val_KL loss: 494.5758 - val_beta: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5848/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1429238.2922 - recon_loss: 1.4287e-04 - KL loss: 494.6115 - beta: 1.0000e-05 - val_loss: 1520548.8750 - val_recon_loss: 1.5201e-04 - val_KL loss: 497.0237 - val_beta: 1.0000e-05\n",
      "Epoch 5849/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1400527.4684 - recon_loss: 1.4000e-04 - KL loss: 496.6633 - beta: 1.0000e-05\n",
      "Epoch 05849: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1400533.2255 - recon_loss: 1.4000e-04 - KL loss: 496.6642 - beta: 1.0000e-05 - val_loss: 1509164.6250 - val_recon_loss: 1.5087e-04 - val_KL loss: 500.7595 - val_beta: 1.0000e-05\n",
      "Epoch 5850/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1425116.3590 - recon_loss: 1.4246e-04 - KL loss: 502.1984 - beta: 1.0000e-05 - val_loss: 1497694.6250 - val_recon_loss: 1.4972e-04 - val_KL loss: 500.5880 - val_beta: 1.0000e-05\n",
      "Epoch 5851/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1407953.7737 - recon_loss: 1.4075e-04 - KL loss: 501.4927 - beta: 1.0000e-05 - val_loss: 1569036.7500 - val_recon_loss: 1.5685e-04 - val_KL loss: 501.1354 - val_beta: 1.0000e-05\n",
      "Epoch 5852/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1396664.2459 - recon_loss: 1.3962e-04 - KL loss: 502.4691 - beta: 1.0000e-05 - val_loss: 1538187.7500 - val_recon_loss: 1.5377e-04 - val_KL loss: 505.1779 - val_beta: 1.0000e-05\n",
      "Epoch 5853/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1400955.6349 - recon_loss: 1.4005e-04 - KL loss: 505.0974 - beta: 1.0000e-05 - val_loss: 1554894.8750 - val_recon_loss: 1.5544e-04 - val_KL loss: 506.2179 - val_beta: 1.0000e-05\n",
      "Epoch 5854/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1402584.8936 - recon_loss: 1.4021e-04 - KL loss: 506.1214 - beta: 1.0000e-05 - val_loss: 1518367.0000 - val_recon_loss: 1.5179e-04 - val_KL loss: 506.1249 - val_beta: 1.0000e-05\n",
      "Epoch 5855/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1423374.4094 - recon_loss: 1.4229e-04 - KL loss: 506.0046 - beta: 1.0000e-05\n",
      "Epoch 05855: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1423368.5385 - recon_loss: 1.4229e-04 - KL loss: 506.0041 - beta: 1.0000e-05 - val_loss: 1522656.3750 - val_recon_loss: 1.5222e-04 - val_KL loss: 505.1224 - val_beta: 1.0000e-05\n",
      "Epoch 5856/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1410633.4834 - recon_loss: 1.4101e-04 - KL loss: 505.2450 - beta: 1.0000e-05 - val_loss: 1518523.2500 - val_recon_loss: 1.5180e-04 - val_KL loss: 505.0507 - val_beta: 1.0000e-05\n",
      "Epoch 5857/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1403641.8879 - recon_loss: 1.4031e-04 - KL loss: 505.3233 - beta: 1.0000e-05 - val_loss: 1519852.5000 - val_recon_loss: 1.5193e-04 - val_KL loss: 504.9891 - val_beta: 1.0000e-05\n",
      "Epoch 5858/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1404568.1847 - recon_loss: 1.4041e-04 - KL loss: 504.3148 - beta: 1.0000e-05 - val_loss: 1516119.7500 - val_recon_loss: 1.5156e-04 - val_KL loss: 505.3543 - val_beta: 1.0000e-05\n",
      "Epoch 5859/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1400925.3576 - recon_loss: 1.4004e-04 - KL loss: 505.8741 - beta: 1.0000e-05 - val_loss: 1519973.7500 - val_recon_loss: 1.5195e-04 - val_KL loss: 506.5528 - val_beta: 1.0000e-05\n",
      "Epoch 5860/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1386739.7212 - recon_loss: 1.3862e-04 - KL loss: 506.5336 - beta: 1.0000e-05\n",
      "Epoch 05860: ReduceLROnPlateau reducing learning rate to 9.999999654550589e-08.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1386756.0557 - recon_loss: 1.3862e-04 - KL loss: 506.5338 - beta: 1.0000e-05 - val_loss: 1519507.0000 - val_recon_loss: 1.5190e-04 - val_KL loss: 506.3034 - val_beta: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0., patience=10, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "# init_epoch=0\n",
    "\n",
    "for beta in betas:\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "#             modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,1e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt10lEQVR4nO3de3zU9Z3v8dd3ciUXEkNCYi4kAXKZoKAtIrQgEYokRKt2T1FPq91dqlW36qpVkdCzlwNIpdWWnkprpaeV7qqcXestgYAoCi0ocQWFXElICIGQC+ROrvM9fyR2KeUSkpn5/mbm83w8eAg/kt/v7Zh5+3nM/L7fUVprhBBCeD+b6QBCCCHcQwpfCCF8hBS+EEL4CCl8IYTwEVL4QgjhI/xNB7iY6OhonZKSYjqGEEJ4lE8++aRZax1z7nFLF35KSgrFxcWmYwghhEdRStWe77glX9JRSt2ilHqxra3NdBQhhPAalix8rfXbWuv7IiIiTEcRQgivYcnCF0II4XxS+EII4SOk8IUQwkdI4QshhI+QwhdCCB8hhe+FtNa8feA4LZ29pqMIISxECt8LFR06yUOvfMpT//m56ShCCAuRwvcyfQMO1m4pJdDPxrulJ/lTVbPpSEIIi5DC9zKb9tZS09LN+ruuJSFyHKsLSnE45FPNhBBS+F6ltbuP9TsqmZcWzeJpsTyZk8Gh4+28/mm96WhCCAuQwvciP3/vMO09/axYYkcpxddnxDMjKZIfF5XT3TdgOp4QwjApfC9R09zFy3tquGNmEvYrxwOglOKHeXYa2nv49YdHDCcUQpgmhe8l1m4pI8DPxmM3pf/F8ZkpUSy5Oo5ffVhFY3uPoXRCCCuQwvcCHx85xdZDDTwwfwoTw4P/6u+fysmkf9DBT7ZVGEgnhLAKKXwP53BoVheUEDc+mO/Om3zer0meEMp35qSw+ZM6So63uzmhEMIqpPA93FsHjnPgWBtPLM5gXKDfBb/uoQVpRIwLYE1hKVrLbZpC+CIpfA/W0z/Is1vLuCphPLdfm3DRr40ICeCRhWnsPtzMzvImNyUUQliJFL4H27j7CMfbeliZl4XNpi759d+6PpnU6FBWF5YyMOhwQ0IhhJVI4Xuopo5eXnj/MIuyYpk9ecKIvifQ38bTuZkcbuzklX11Lk4ohLAatxW+UsqulPqlUuo/lFIPuOu63ur5dyvoHXDwdG7mZX3foqxYrk+N4qfbK2jv6XdROiGEFY2o8JVSv1FKNSqlDp5zPEcpVa6UOqyUWn6xc2itS7XW9wNLga+OPrKoONnBqx8f5duzk5kcE3ZZ36uUYmVeFi1dfbzwfpWLEgohrGikE/5vgZyzDyil/IBfALlAFnCXUipLKXW1Uuqdc35NHP6erwMFQKHT/g180OqCUsKC/HlkYdqovv/qxAi+cW0Cv/njEepOdTs5nRDCqkZU+FrrD4FT5xyeBRzWWldrrfuAV4Fbtdafa61vPudX4/B53tJa5wLfcua/hC/5sKKJDyqaeHhhGleEBo76PD9YnIFNwbNF5U5MJ4SwsrG8hp8AnP3O37HhY+ellMpWSq1XSv2Ki0z4Sqn7lFLFSqnipia5ffBsgw7N6oJSJkWFcPec5DGdKz5yHPfOm8zbB47z6dHTTkoohLAyt71pq7XeqbV+WGv9Pa31Ly7ydS9qrWdqrWfGxMS4K55H2FxcR/nJDpbnZhLkf+FFViN1//wpxIQHsapAFmMJ4QvGUvj1QNJZf04cPiZcoLN3gJ9sq2Bm8hXkXhXnlHOGBvnz+KJ0Pqk9TeHnDU45pxDCusZS+PuANKVUqlIqELgTeMsZoZRStyilXmxra3PG6bzCrz6oormzl5U3Z6HUpRdZjdQ3ZyaRGRfO2q2l9A4MOu28QgjrGeltma8Ae4AMpdQxpdQyrfUA8H2gCCgFNmutDzkjlNb6ba31fREREc44ncc73nqGFz+s5usz4rkmKdKp5/azKfLz7NSdOsPLf6p16rmFENbiP5Iv0lrfdYHjhcgtli7346JyNPBkToZLzj8vLYbsjBjWv1fJ33w5kagx3P0jhLAu2VrB4j471srrn9azbG4qiVeEuOw6K5bY6eodYP2OSpddQwhhlhS+hWmtWVVQyoTQQB7MnuLSa6XHhnPXrEn8fm8tVU2dLr2WEMIMSxa+vGk7ZFvJST4+copHF6UTHhzg8us9uiid4AA/niksc/m1hBDuZ8nClzdtoW/AwdotZaRNDOPO65Iu/Q1OEB0WxIM3TuHd0pPsqWpxyzWFEO5jycIX8Pu9tRxp7mLFEjv+fu77z/T3X00lIXIcqwpKcDhkMZYQ3kQK34LauvtZ/14l89Kiyc5w72rj4AA/nszJ4NDxdl7/VNbRCeFNLFn4vv4a/s/fq6TtTD8rltidushqpG6ZHs+MpEh+XFROd9+A268vhHANSxa+L7+GX9Pcxe/21LD0y0nYrxxvJIPNpvhhnp2G9h5+/eERIxmEEM5nycL3ZT/aWkaAn43Hb0o3mmNmShRLro7jVx9W0djeYzSLEMI5pPAtZF/NKbYcbOD++VOYOD7YdByeysmkf9DBj7fJnvlCeAMpfItwODSr3ikhbnww986bbDoOAMkTQvnOnBT+3yfHKDnebjqOEGKMpPAt4u3PjnPgWBtPLM5gXODY97p3locWpBExLoA1hbJnvhCezpKF72t36fT0D/Ls1nKuShjP7dde8EPDjIgICeCRhWnsPtzMznL5BDIhPJklC9/X7tLZuPsI9a1nyF+Shc3m/tswL+Vb1yeTGh3K6sJSBgYdpuMIIUbJkoXvS5o7e9mws4pFWbHMmTLBdJzzCvS38XRuJocbO3llX92lv0EIYUlS+IY9v72Cnv5Bns7NNB3lohZlxXJ9ahQ/3V5Be0+/6ThCiFGQwjeo4mQHr3x8lG/PTmZyTJjpOBellGJlXhYtXX288H6V6ThCiFGQwjdoTWEpYUH+PLIwzXSUEbk6MYJvfCmB3/zxCHWnuk3HEUJcJil8Qz6saGJneRMPLUjjCg/6SMEnFmdgU7CuSBZjCeFpLFn43n5b5qBDs6awlElRIdzzlWTTcS7LlRHjuHfeZN46cJxPj542HUcIcRksWfjeflvm/yuuo6yhg+W5mQT5W2eR1UjdP38KMeFBrCqQxVhCeBJLFr436+wd4CfbK5iZfAW5V8WZjjMqoUH+PL4onU9qT7PlYIPpOEKIEZLCd7NffVBFU0cv+Xlm9rp3lm/OTCIzLpxntpTSOzBoOo4QYgSk8N3oRNsZfr2rmq/PiOfaSVeYjjMmfjZFfp6dulNnePlPtabjCCFGQArfjdYVlePQ8GROhukoTjEvLYbsjBjWv1fJqa4+03GEEJcghe8mnx9r4/X/qufvv5pK4hUhpuM4zYoldrp6B1i/o9J0FGGY7LNkfZYsfG+7LVNrzaqCEiaEBvLgjVNMx3Gq9Nhw7po1id/vraWqqdN0HGHIrsomvrzqXT6qbjEdRVyEJQvf227L3F5yko+OnOIfF6UzPjjAdByne3RROsEBfqzdUmY6ijBgYNDBv7xdQtuZfv71nRIcDrlV16osWfjepG/AwTNbypg6MYy7rksyHcclosOCeCB7CttLTrKnSiY8X/PKvjoON3Zy2zXxHDrezuuf1puOJC5ACt/F/u2jWo40d5G/xI6/n/c+3MvmppIQOY7VhTLh+ZKOnn5+ur2CWalRPLf0GmYkRfLjonLO9MmtulbkvQ1kAW3d/fxsRyVzp0aTnRFjOo5LBQf48WROBgfr2/mDTHg+44WdVbR09bEyz47Npvhhnp2G9h5+vavadDRxHlL4LvTz9yppO9PPiiWevchqpG6ZHs+MxAjWyYTnE+pOdbNx9xG+cW0C0xMjAZiZEsWSq+P45QdVNLb3mA0o/ooUvovUtnTxuz01LP1yElnx403HcQubTbHy5iyZ8HzEuqJyFPCDxX+5ruSpnEz6Bx38ZFuFmWDigqTwXeRHW8sI8LPx+E3ppqO41XUpUeReJROet9tf18pbB45z77zJxEeO+4u/S54Qyt9+JYXNn9RRcrzdUEJxPlL4LrCv5hSFnzfwvRumMHF8sOk4brc8VyY8b6a1ZtU7JUSHBXF/9vnXlXz/xjQixgWwplB2VLUSKXwnczg0qwpKiRsfzL03pJqOY0TyhFC+M2dowis9IROet9lysIHi2tM8flM6YUH+5/2aiJAAHlmYxu7Dzewsb3JzQnEhUvhO9vZnxzlQ18oPFmcQEnj+J4MveGjB0IS3WvbM9yq9A4Os3VJGRmw4S2defF3Jt2cnMzk6lNWFpbLtgkVYsvA9dWuFnv5Bnt1azrT48Xzj2gTTcYyKCAng4QUy4XmbTXtqOXqqm/w8O362i995FuBnY3luJocbO3llX52bEoqLsWThe+rWCr/54xHqW8+QP3xPsq/79uxkUmXC8xqnu/pYv6OS+ekx3JA+snUli7JiuT41ip9ur6Cjp9/FCcWlWLLwPVFzZy8vvF/F1+yxfGVKtOk4lhDo/98T3qsy4Xm8n+2opLN3gPw8+4i/RynFD2/O4lR3Hy/srHJhOjESUvhO8vz2Cnr6B3l6SabpKJZyU1Yss1KjeF4mPI9W3dTJ7/fWcuesSaTHhl/W916VEMHt1yawcfcR6k51uyihGAkpfCeoPNnBKx8f5duzk5kSE2Y6jqUopfhhXhYtXTLhebJntpQR5G/j0a+Nbl3JE4szsKmhxVrCHCl8J1hTWEpokD8PL0wzHcWSrk6M4BvDE96x0zLheZq91S1sLznJgzdOJSY8aFTnuDJiHPfNm8xbB47z6dHTTk4oRkoKf4x2VTbxfnkTDy2YSlRooOk4lvWDxRko4NmtMuF5kqF1JSXERwSzbO7Y1pV8b/4UYsKDWCW36hojhT8Ggw7N6oJSkqLG8Z2vpJiOY2nxkeO4d3jC21/XajqOGKE/fFrPwfp2nszJJDjAb0znCg3y5/FF6XxSe5otBxuclFBcDin8MfiPT+ooa+hgeY6dIP+xPRl8wf3ZU4gOC2LVOyUy4XmAM32DrCsqZ3piBF+fEe+Uc35zZhKZceGs3VJG74DsqOpuUvij1NU7wI+3VfDl5CtYcnWc6TgeISzIn8dvSqdYJjyP8NKuahrae1iZl+W0dSV+NkV+np2jp7p5+U+1TjmnGDkp/FH61QdVNHX0kp/nG3vdO8vSmUlkxMqEZ3WN7T1s+KCKnGlxzEqNcuq556XFkJ0Rw8/fq+R0V59Tzy0uTgp/FE60neHFXdXcMiOeL026wnQcj3L2hLdpj0x4VvXc9gr6Bx0sz3XNupL8JXa6+gb52Y5Kl5xfnJ8U/iisKyrHoeHJcz74QYzMDekxzE+PYf0OmfCsqKyhnc3FddwzJ4WU6FCXXCMtNpw7r0vi93trqW7qdMk1xF+Twr9MB+vbeP2/6vm7r6aQFBViOo7Hys+z09k7IBOexWg9dOdZeHAADy2Y6tJrPbooneAAP57ZUubS64j/ZsnCt+pumVoP3ZMcFRrIP9zo2ieDt0uPDefOWZNkwrOYnRVN7Kps5uGFaUSGuHZdSXRYEA/eOIXtJSfZU9Xi0muJIZYsfKvulvluaSN7q0/x6NfSGB8cYDqOx3v0a+kE+dtYKxOeJQwMOlhTUErKhBDunp3slmv+/VdTSYgcx+rCEhwOuVXX1SxZ+FbUP+jgmcJSpsSEctesSabjeIWY8CAevHEq20pOsrdaJjzTXiuuo7Kxk+W5dgL93VMNwQF+PJmTwcH6dv7wab1brunLpPBH6N/21lLd3EV+nh1/P3nYnGXZ3FTiI4JZVSATnkkdPf08t62CWalRLJ4W69Zr3zI9nhlJkawrKudMn9yq60rSXCPQ1t3Pz3ZU8tWpE7gxY6LpOF5laMLL5GB9O2/slwnPlA07q2jp6mOlgXUlNpvih3l2Gtp7+PWuarde29dI4Y/A/3m/ktYz/eQvyZJFVi7w9RnxTE+M4NmtMuGZcOx0Ny/tPsLt1yYwPTHSSIaZKVHkXhXHLz+oorG9x0gGXyCFfwlHW7r53Z9q+eaXE8mKH286jley2RQr87JoaO/hJZnw3G5dUTmKoT3rTVqem0n/oIPntlcYzeHNpPAv4Udby/CzKR6/SRZZudKs1ChypsWx4YMqGjtkwnOX/XWtvLn/OPfOm0x85DijWZInhPKdOSm8VlxH6Yl2o1m8lRT+RXxSe4qCz0/wvfmTiR0fbDqO1/vzhLdNJjx3GFpkVUJ0WBD3Z08xHQeAhxakETEugDWFsme+K0jhX4DWmv/9Timx44O474bJpuP4hJToUO6Zk8Lm4jrKGmTCc7WtBxvYV3Oax29KJyzI33QcACJCAnhkYRq7KpvZWdFkOo7XkcK/gLc/O8H+ulZ+cFMGIYHWeDL4gocWTCU8OIDV8qlILtU34GDt1jIyYsNZOjPJdJy/8K3rk0mNDmV1QSkDgw7TcbyKFP559PQP8qMtZWRdOZ6/+VKi6Tg+JTIkkIdlwnO5l/fUUNvSzYo8O35O2uveWQL9bSzPzeRwYyev7qszHcerSOGfx//9Yw31rWdYmWd32gc/iJG7e3YyKRNCWCMTnkuc7upj/Y5K5g/vWmpFN2XFcn1qFM9vr6Cjp990HK8hhX+O5s5eXnj/MF+zT+QrU6NNx/FJQxOencrGTl4rlgnP2da/V0ln7wD5eXbTUS5IqaFbdVu6+nhhZ5XpOF5DCv8cP323gu7+QZbnWvfJ4AsWT4tlVkoUz22TCc+Zqps62bSnljuum0R6bLjpOBd1dWIE37g2gY27j3DsdLfpOF5BCv8shxs7eOXjOr59/SSmTgwzHcenKaVYebOdlq4+NsiE5zRrt5QR5G/jsUXppqOMyA8WZ2BTQ4vDxNhJ4Z9lTWEZIYF+PPI1z3gyeLvpiZHcfm0CL8mE5xR7q1vYVnKSB2+cSkx4kOk4IxIfOY57503mzf3H2V/XajqOx5PCH7a7spn3yhr5/o1TiQp17Qc/iJF7YnEGCpnwxsrhGPrwnviIYJbNTTUd57J8b/4UosOCWPVOidyqO0ZS+MDg8JMhKWoc3/lKiuk44iwy4TnHG/vrOVjfzpM5mQQH+JmOc1nCgvz5wU3pFNeeZuvBBtNxPJoUPvCfnxyjrKGDpzzwyeAL7s8emvBWF8iENxpn+gZZV1TO9MQIvj4j3nScUfnmzCQy48J5ZksZvQOyo+po+Xzhd/UOsG5bOV+aFEne1VeajiPOIyzIn8cWpbOvRia80XhpVzUn2npYmZflsetK/GyKFUvsHD3VzaY9tabjeCyfL/xffVhNU0cvK2+Wve6tbOnMRDJiw1m7tYy+AVmMNVKNHT1s+KCKnGlxzEqNMh1nTG5IjyE7I4b1Oyo53dVnOo5HcmvhK6VClVLFSqmb3XndC2lo6+HFD6u4efqVfGnSFabjiIvw97OxIs9ObUs3L++pMR3HYzy/vYL+QQfLczNNR3GKFUvsdPYO8LMdlaajeKQRFb5S6jdKqUal1MFzjucopcqVUoeVUstHcKqngM2jCeoK64rKcTjgqRzveDJ4u/npMdyQLhPeSJU1tPPavjrunp1CSnSo6ThOkR4bzp2zJvH7vbVUN3WajuNxRjrh/xbIOfuAUsoP+AWQC2QBdymlspRSVyul3jnn10Sl1CKgBGh0Yv5RO1jfxuufHuPv5qaQFBViOo4YofzhCW/9ezLhXcrqglLCgwN4eOFU01Gc6tGvpRMc4MfaLWWmo3icERW+1vpD4NQ5h2cBh7XW1VrrPuBV4Fat9eda65vP+dUIZAOzgf8J3KuUOu+1lVL3Db/sU9zU5JrdEoc++KGUK0IC+YcbvevJ4O0y4sK547pJbNojE97F7CxvZFdlMw8vTCMyxLvWlcSEB/FA9hS2lZxkb3WL6TgeZSyv4ScAZ+9sdWz42HlprfO11v8I/Dvwa631ed9501q/qLWeqbWeGRPjmp383i1tZE91C//4tTTGBwe45BrCdR5blE6Qv00mvAsYGHSwuqCUlAkh3D072XQcl1g2N5WEyHGsKijB4ZBbdUfK7XfpaK1/q7V+x93X/UL/oINnCkuZEhPKXbMmmYohxiAmPIgHb5wqE94FvFZcR2VjJ8tz7QT6e+eNeMEBfjyZk8HB+nbe2F9vOo7HGMtPQz1w9kflJA4fs7R//+go1c1drFhiJ8DPO58MvmDZ3FTiI4JZXVAqE95ZOnr6eX57BbNSolg8LdZ0HJe6ZXo8MxIjeHZrOWf6ZDHWSIyl8fYBaUqpVKVUIHAn8JYzQimlblFKvdjW1uaM0/1Z25l+fvpuBV+ZMoEFmROdem7hXsEBfjyRk8Hn9W0y4Z1lw84qmjv7WHmz3evXldhsipU3Z9HQ3sNLu6pNx/EII70t8xVgD5ChlDqmlFqmtR4Avg8UAaXAZq31IWeE0lq/rbW+LyIiwhmn+7NfvH+Y1jP95Od5/5PBF9w6I4HpiRGsK5IJD6C+9Qwbdx/h9msTmJ4YaTqOW1yXEkXOtDg2fFBFY3uP6TiWN9K7dO7SWl+ptQ7QWidqrTcOHy/UWqdrradorVe7NurYHG3p5rd/rOF/fCmRafHO/R+JMMNmG/pUpBNtPWzcLRPeuq1Db2I/sTjDcBL3Wp6bSf+gg+e2V5iOYnk+8yL2j7aW4WdT/MDHngzeblbq0GvVL+ysorHDdye8/XWtvLH/ON+dl0p85DjTcdwqJTqUe+aksLm4jtIT7abjWJolC9/Zr+F/UnuKgs9P8L35k4kdH+yUcwrrWJ5rp3/QwfM+OuENrSspIToskAeyfXNdyUMLphIeHMCawlLZUfUiLFn4znwNX2vN/36nlNjxQdx3w2QnpBNWkxodyt2zU3htXx1lDb434RUdamBfzWkeW5RBWJC/6ThGRIYE8sjCNHZVNrOzwjULNr2BJQvfmd7+7AT761p5/KYMQgJ988ngCx5eODThrS4oNR3FrfoGHDyzpYz02DCWzkw0Hceob89OJjU6lDUFpQwMyo6q5+PVhd/TP8iPtpSRdeV4/uZLvv1k8HaRIYE8/MWEV26J7Zrc4uU9NdS2dJOfl4W/j68rCfS38VROJpWNnby6r+7S3+CDvPon5P/+sYb61jOszLPj56Ef/CBG7u7ZyaRMCGFNoW9MeK3dffz8vcPckB7D/HTXbEPiaRZPi2VWahTPb6+go6ffdBzLsWThO+NN25bOXl54/zALMyfylanRTkwnrCrQ38by3EwqTnbyWrH3T3g/21FJR08/+UvspqNYhlKKlXl2Wrr6eGFnlek4lmPJwnfGm7Y/fbeS7v5BnpYng09ZPC2OWSneP+Edae5i055a7rhuEhlx4abjWMr0xEhuvzaBjbuPcOx0t+k4lmLJwh+rw40d/PvHR/nW9ZOYOjHMdBzhRkopVt5sp7mzj19+4L0T3totpQT523hsUbrpKJb0xOIMFEMfciT+m1cW/k+2VRAS4McjC9NMRxEGTE+M5LZr4nlp1xHqW8+YjuN0H1W3UHToJA9kTyEmPMh0HEuKjxzHvfMm8+b+4+yvazUdxzK8svD/6ZZprP+f1zIhTJ4MvuqJ4Y+t/GK7AW/hcGhWFZQSHxHMd+fJupKLuT97CtFhQax6p0QWYw2zZOGP9U3buIhgbsyQ3TB9WULkOL47L5U39h/ngBdNeG8eqOfz+jaeyMkgOMDPdBxLCwvy5/Gb0imuPc3Wgw2m41iCJQvfVbtlCt/yQPZUosMCWVXgHRPemb5Bnt1azvTECG6dccEPlxNnWToziYzYcJ7ZUkbvgOyoasnCF8IZwoL8eWxRBvtqTlN0yPMnvI27qznR1kP+Ejs2WVcyIn42xYo8O0dPdbNpT63pOMZJ4QuvtnRmIumxYTyzpYy+Ac9djNXY0cOGnVUsnhbL9ZMnmI7jUeYPL0xbv6OS0119puMYJYUvvJq/n40VS+zUtnTz8p4a03FG7fntFfQOOFieK+tKRiM/z05n7wA/21FpOopRUvjC62VnTOSG9Bh+/t5hWrs9b8Irb+jgtX113DMnhdToUNNxPFJ6bDh3XDeJ3++tpbqp03QcY6TwhU/IX2Kno6ef9TsOm45y2VYXlhIeHMDDC31zr3tneWxROkH+NtZu8a5bdS+HJQvfVR9iLnxXRlw4d1yXxMt7ajjS3GU6zojtLG/kw4omHlowlciQQNNxPFpMeBAP3jiVbSUn2VvdYjqOEZYsfLktU7jCo3+e8Dxjz/yBQQdrCktJmRDCPXNSTMfxCsvmphIfEcyqghIcDs+/VfdyWbLwhXCFieHBPJA9haJDJ/nIAya8zcXHqDjZyfLcTAL95anqDMEBfjyZk8nB+nbe2F9vOo7byU+R8CnL5k7myohgVhWUWnrC6+jp57nt5cxKiWLxtDjTcbzK12fEMz0xgme3lnOmz7cWY0nhC58yLtCPJ3My+Ly+jTcPWHfC++UHVTR39pGfZ0cpWWTlTDabYmVeFg3tPby0q9p0HLeSwhc+59YZCZae8Opbz/DSriPcdk08M5IiTcfxSrNSo8iZFseGD6po7OgxHcdtpPCFz7HZFPlL7Jxo62HjbutNeF/s8PnFjp/CNZbnZtI/6OC5bRWmo7iNFL7wSddPnsDiabFs2GmtCe+zY628sf84352XSkLkONNxvFpKdCh3z05hc3EdZQ3tpuO4hSULX+7DF+6wPNdO74CD57dbY7m91ppV75QSHRbI/fOnmI7jEx5eOJXw4ABWF5R6xY6ql2LJwpf78IU7pEaHcvecZF7bd5Tyhg7TcSg61MDHNad4dFE64cEBpuP4hMiQQB5emMauymZ2VjSZjuNylix8IdzlkYVpQxNeodnFWH0DDtZuKSM9Now7ZiYZzeJr7p6dTMqEENYUlDIw6Lk7qo6EFL7waZEhgTy0YCofVjSxs7zRWI5Ne2upaelmxRI7/n7ytHSnQH8by3PtVDZ28uq+OtNxXEp+soTPu2dOCskTQlhTaGbCa+3uY/2OSualRZMtH81pxOJpscxKieL57RV09PSbjuMyUvjC5wX623g6N5OKk51sLj7m9uuv33GYjp5+8vNkr3tTlFKsvNlOS1cfG3ZWmY7jMlL4QgCLp8UxKyWK57aX09k74LbrHmnuYtPeGu64LonMuPFuu674a9MTI7n92gRe2n2EY6e7TcdxCSl8IRia8PLz7DR39rFhp/v2zF+7pZRAPxuPLkp32zXFhT2xOAMFrCsqNx3FJaTwhRg2IymS266J56VdRzjeesbl1/uouoWiQyd5IHsKE8ODXX49cWnxkeP47rxU3tx/nP11rabjOJ0UvhBn+WI7A1dPeA6HZnVhKVdGBLNs7mSXXktcngeypxIdFsiqd0q8bjGWJQtfVtoKUxKGJ7w/fFrPARdOeG8eqOezY208mZPBuEA/l11HXL6wIH8eW5RBce1pth5sMB3HqSxZ+LLSVpj0xYTnquX2Z/oGeXZrOdMTI7h1RoLTzy/GbunMRNJjw1i7tYzeAevtqDpalix8IUwKC/Ln0UXpfFxziqJDJ51+/o27qznR1kP+Ejs2m+x1b0X+fjby87Kobelm055a03GcRgpfiPO4Y2YS6bFhPLOllL4B5y3GauroZcPOKhZPi+X6yROcdl7hfPPTY7ghPYb1Oyo53dVnOo5TSOELcR7+fjZWLLEPTXh7nTfhPbe9gt4BB8tzZZGVJ8hfYqezd4D171ljR9WxksIX4gKyMyYyLy2a9Tsqae0e+4RX3tDBa/uOcvecZFKjQ52QULhaRlw4d1w3iU17aqlu6jQdZ8yk8IW4iPw8Ox09/azfMfbFWKsLSwkPDuCRhWlOSCbc5bFF6QT521i7pcx0lDGTwhfiIjLjxnPHdUls2ltDTXPXqM+zs7yRDyuaeGjBVCJDAp2YULhaTHgQD944lW0lJ9lb3WI6zphI4QtxCY8uSifQb/QT3sCggzWFpSRPCOGeOSnODSfcYtncVOIjgllVUILD4bmLsaTwhbiEieHBPJA9ha2HGvhoFBPe5uJjVJzsZHlOJoH+8pTzRMEBfjyRk8HB+nb+8Gm96TijJj99QozAsrmTuTIimNWFpZc14XX2DvDc9nJmpUSRc1WcCxMKV7t1RgLTEyNYV1TOmT7PXIwlhS/ECIwL9OOJxRl8dqyNtw4cH/H3bdh5mObOPvLz7Cgli6w8mc2mWJmXRUN7Dy/tqjYdZ1Sk8IUYoduuSeDqhAie3VpGT/+lJ7zjrWd4adcRbrsmnhlJka4PKFxuVmoUi6fFsuGDKho7ekzHuWxS+EKM0NCEZ+d4Ww8bdx+55Nd/sePmFztwCu+wPNdO/6CD57ZVmI5y2aTwhbgM10+ewOJpsbzw/mGaOnov+HUH6lr5w6f1LJubSkLkODcmFK6WGh3K3bNT2FxcR1lDu+k4l8WShS/bIwsrW55rp3fAwXPbzz/haa1ZXVBKdFggD2RPcXM64Q4PL5xKeHCAy3ZUdRVLFr5sjyysLDU6lLvnJPPavqOUN3T81d8XHTrJxzWneHRROuHBAQYSCleLDAnk4YVp7KpsZmdFk+k4I2bJwhfC6h5ZmEZ4cABrCkv/4njfgIO1W0pJmxjGHTOTDKUT7nD37GRSJoSwpqCUgUHn7ajqSlL4QoxCZEggDy2YygcVTXxw1oS3aW8tNS3drMiz4+8nTy9vFuhvY3luJpWNnbxWXGc6zojIT6QQo3TPnBSShye8QYemtbuP9TsqmZcWTXZ6jOl4wg0WT4tjVkoUz2+voKOn33ScS5LCF2KUAv1tPJ2bSfnJDjYX1/Hz9w7T0dMvi6x8iFKKlTfbae7sY8POKtNxLkkKX4gx+GLCW1dUzst7alg6M4nMuPGmYwk3mp4YyW3XxLNx9xHqW8+YjnNRUvhCjIFSivw8O6e6+gjws/HYTemmIwkDvlhct26rtffMl8IXYoxmJEXyv27O4iffnMHE8GDTcYQBCZHj+O68VN7Yf5z9da2m41yQFL4QTvD3c1PJvfpK0zGEQQ9kTyU6LJDVBSWWXYwlhS+EEE4QFuTPY4sy2FdzmqJDDabjnJcUvhBCOMnSmYmkx4bxzJYy+gastxhLCl8IIZzE389Gfl4WtS3dvLynxnScvyKFL4QQTjQ/PYYb0mP4+XuHae3uMx3nL0jhCyGEk+UvsdPR08/PdlSajvIXpPCFEMLJMuLCueO6SWzaU8uR5i7Tcf5MCl8IIVzgsUXpBPnbWLul9NJf7CZS+EII4QIx4UE8kD2FokMn2VvdYjoOIIUvhBAu8915k4mPCGZ1QSkOh/nFWFL4QgjhIsEBfjyRk8Hn9W28eaDedBwpfCGEcKVbZyQwPTGCZ7eWc6Zv0GgWtxW+UipbKbVLKfVLpVS2u64rhBAm2WyK/CV2TrT1sHF3tdksI/kipdRvlFKNSqmD5xzPUUqVK6UOK6WWX+I0GugEgoFjo4srhBCe5/rJE1g8LZYNO6to7OgxlmOkE/5vgZyzDyil/IBfALlAFnCXUipLKXW1Uuqdc35NBHZprXOBp4B/cd6/ghBCWN/yXDu9Aw6e325uMdaICl9r/SFw6pzDs4DDWutqrXUf8Cpwq9b6c631zef8atRaf7GT0Gkg6ELXUkrdp5QqVkoVNzU1XejLhBDCo6RGh3L3nGRe23eU8oYOIxnG8hp+AnD2R7UfGz52XkqpbyilfgVsAv7Phb5Oa/2i1nqm1npmTIx8ELQQwns8sjCN8OAAVheaWYzltjdttdava62/p7W+Q2u9013XFUIIq4gMCeShBVP5sKKJneWNbr/+WAq/Hkg668+Jw8eEEEJcwD1zUkieEMKawlIGBt27Z/5YCn8fkKaUSlVKBQJ3Am85I5RS6hal1IttbW3OOJ0QQlhGoL+Np3MzqTjZyeZi996wONLbMl8B9gAZSqljSqllWusB4PtAEVAKbNZaH3JGKK3121rr+yIiIpxxOiGEsJTF0+KYlRLFc9vL6ewdcNt1R3qXzl1a6yu11gFa60St9cbh44Va63St9RSt9WrXRhVCCO+glCI/z05zZx8bdh5223VlawUhhDBgRlIkt10Tz0u7jnC89YxbrmnJwpfX8IUQvuCJnEwA1hWVu+V6lix8eQ1fCOELEiLHsWxuKn/4tJ4Dda0uv54lC18IIXzFA9lTiA4LZHVBKVq7ds98KXwhhDAoPDiARxel83HNKYoOnXTptaTwhRDCsDtmJpE2MYy1W0rpG3DdYixLFr68aSuE8CX+fjZW5Nmpaelm095al13HkoUvb9oKIXxNdnoM89KiWb+jktbuPpdcw5KFL4QQvuaLxVgdPf2s3+GaxVhS+EIIYRGZceNZOjOJTXtrqGnucvr5/Z1+RiGEEKP22E3p1Leeoc8FO2lK4QshhIVMDA9m07LrXXJuS76kI3fpCCGE81my8OUuHSGEcD5LFr4QQgjnk8IXQggfIYUvhBA+QgpfCCF8hCULX+7SEUII57Nk4ctdOkII4XzK1Rvuj4VSqgkY7dZx0UCzE+O4i+R2L0/NDZ6bXXK7XrLWOubcg5Yu/LFQShVrrWeaznG5JLd7eWpu8NzsktscS76kI4QQwvmk8IUQwkd4c+G/aDrAKElu9/LU3OC52SW3IV77Gr4QQoi/5M0TvhBCiLNI4QshhI/wysJXSuUopcqVUoeVUstN5xkppVSNUupzpdR+pVSx6TwXopT6jVKqUSl18KxjUUqp7UqpyuF/XmEy4/lcIPc/K6Xqhx/z/UqpJSYzno9SKkkp9b5SqkQpdUgp9cjwcUs/5hfJbenHXCkVrJT6WCl1YDj3vwwfT1VKfTTcK68ppQJNZ71cXvcavlLKD6gAFgHHgH3AXVrrEqPBRkApVQPM1FpbenGHUuoGoBN4WWt91fCxZ4FTWuu1w/+TvUJr/ZTJnOe6QO5/Bjq11j82me1ilFJXAldqrf9LKRUOfALcBvwtFn7ML5J7KRZ+zJVSCgjVWncqpQKA3cAjwGPA61rrV5VSvwQOaK03mMx6ubxxwp8FHNZaV2ut+4BXgVsNZ/IqWusPgVPnHL4V+N3w73/H0BPbUi6Q2/K01ie01v81/PsOoBRIwOKP+UVyW5oe0jn8x4DhXxpYAPzH8HHLPd4j4Y2FnwDUnfXnY3jAD9kwDWxTSn2ilLrPdJjLFKu1PjH8+wYg1mSYy/R9pdRnwy/5WOplkXMppVKAa4GP8KDH/JzcYPHHXCnlp5TaDzQC24EqoFVrPTD8JZ7UK3/mjYXvyeZqrb8E5AL/MPwShMfRQ68TesprhRuAKcA1wAngJ0bTXIRSKgz4T+AftdbtZ/+dlR/z8+S2/GOutR7UWl8DJDL0qkGm2UTO4Y2FXw8knfXnxOFjlqe1rh/+ZyPwB4Z+0DzFyeHXbL947bbRcJ4R0VqfHH5yO4BfY9HHfPi15P8E/k1r/frwYcs/5ufL7SmPOYDWuhV4H5gDRCql/If/ymN65WzeWPj7gLThd9QDgTuBtwxnuiSlVOjwG1sopUKBm4CDF/8uS3kL+M7w778DvGkwy4h9UZjDbseCj/nwm4gbgVKt9XNn/ZWlH/ML5bb6Y66UilFKRQ7/fhxDN4CUMlT8/2P4yyz3eI+E192lAzB8m9dPAT/gN1rr1WYTXZpSajJDUz2AP/DvVs2tlHoFyGZou9iTwD8BbwCbgUkMbWm9VGttqTdIL5A7m6GXFjRQA3zvrNfFLUEpNRfYBXwOOIYPr2Do9XDLPuYXyX0XFn7MlVLTGXpT1o+hoXiz1vpfh5+jrwJRwKfAt7XWveaSXj6vLHwhhBB/zRtf0hFCCHEeUvhCCOEjpPCFEMJHSOELIYSPkMIXQggfIYUvhBA+QgpfCCF8xP8H1qV3xAcuOlwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(betas)\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4277/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 73914.4335 - recon_loss: 2.9333e-04 - KL loss: 233.2556 - beta: 6.3096e-05 - val_loss: 81207.3125 - val_recon_loss: 3.2242e-04 - val_KL loss: 220.1159 - val_beta: 6.3096e-05\n",
      "Epoch 4278/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 74487.1938 - recon_loss: 2.9564e-04 - KL loss: 225.5300 - beta: 6.3096e-05 - val_loss: 92260.8359 - val_recon_loss: 3.6637e-04 - val_KL loss: 231.7334 - val_beta: 6.3096e-05\n",
      "Epoch 4279/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 75256.3566 - recon_loss: 2.9870e-04 - KL loss: 225.9325 - beta: 6.3096e-05 - val_loss: 86923.5703 - val_recon_loss: 3.4512e-04 - val_KL loss: 233.0823 - val_beta: 6.3096e-05\n",
      "Epoch 4280/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 83009.7690 - recon_loss: 3.2946e-04 - KL loss: 254.0937 - beta: 6.3096e-05 - val_loss: 103231.7266 - val_recon_loss: 4.1000e-04 - val_KL loss: 243.2094 - val_beta: 6.3096e-05\n",
      "Epoch 4281/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 79905.4554 - recon_loss: 3.1709e-04 - KL loss: 255.7370 - beta: 6.3096e-05 - val_loss: 90502.7734 - val_recon_loss: 3.5932e-04 - val_KL loss: 246.5228 - val_beta: 6.3096e-05\n",
      "Epoch 4282/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 76528.0747 - recon_loss: 3.0368e-04 - KL loss: 247.9384 - beta: 6.3096e-05\n",
      "Epoch 04282: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 76528.0036 - recon_loss: 3.0368e-04 - KL loss: 247.9383 - beta: 6.3096e-05 - val_loss: 87505.1016 - val_recon_loss: 3.4738e-04 - val_KL loss: 247.5393 - val_beta: 6.3096e-05\n",
      "Epoch 4283/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 74645.6167 - recon_loss: 2.9615e-04 - KL loss: 255.5551 - beta: 6.3096e-05 - val_loss: 80044.9375 - val_recon_loss: 3.1766e-04 - val_KL loss: 253.4517 - val_beta: 6.3096e-05\n",
      "Epoch 4284/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 73628.3676 - recon_loss: 2.9207e-04 - KL loss: 262.5965 - beta: 6.3096e-05 - val_loss: 88209.2266 - val_recon_loss: 3.5014e-04 - val_KL loss: 258.1914 - val_beta: 6.3096e-05\n",
      "Epoch 4285/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 71919.9936 - recon_loss: 2.8531e-04 - KL loss: 252.8365 - beta: 6.3096e-05 - val_loss: 86406.1797 - val_recon_loss: 3.4298e-04 - val_KL loss: 254.0691 - val_beta: 6.3096e-05\n",
      "Epoch 4286/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 72071.7759 - recon_loss: 2.8591e-04 - KL loss: 254.8114 - beta: 6.3096e-05 - val_loss: 80994.2578 - val_recon_loss: 3.2145e-04 - val_KL loss: 248.4435 - val_beta: 6.3096e-05\n",
      "Epoch 4287/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 71401.9818 - recon_loss: 2.8325e-04 - KL loss: 253.1727 - beta: 6.3096e-05 - val_loss: 81965.3750 - val_recon_loss: 3.2531e-04 - val_KL loss: 250.7558 - val_beta: 6.3096e-05\n",
      "Epoch 4288/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 70421.6902 - recon_loss: 2.7936e-04 - KL loss: 250.3561 - beta: 6.3096e-05 - val_loss: 75633.9531 - val_recon_loss: 3.0014e-04 - val_KL loss: 241.8050 - val_beta: 6.3096e-05\n",
      "Epoch 4289/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 70685.6165 - recon_loss: 2.8042e-04 - KL loss: 246.5611 - beta: 6.3096e-05 - val_loss: 80965.2266 - val_recon_loss: 3.2138e-04 - val_KL loss: 239.2994 - val_beta: 6.3096e-05\n",
      "Epoch 4290/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 69270.8839 - recon_loss: 2.7479e-04 - KL loss: 245.9312 - beta: 6.3096e-05 - val_loss: 79755.1250 - val_recon_loss: 3.1654e-04 - val_KL loss: 243.3380 - val_beta: 6.3096e-05\n",
      "Epoch 4291/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 70245.3206 - recon_loss: 2.7867e-04 - KL loss: 246.5031 - beta: 6.3096e-05 - val_loss: 78126.2891 - val_recon_loss: 3.1007e-04 - val_KL loss: 240.9555 - val_beta: 6.3096e-05\n",
      "Epoch 4292/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 69018.1877 - recon_loss: 2.7378e-04 - KL loss: 247.0189 - beta: 6.3096e-05 - val_loss: 78200.1641 - val_recon_loss: 3.1034e-04 - val_KL loss: 246.1735 - val_beta: 6.3096e-05\n",
      "Epoch 4293/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 69861.0660 - recon_loss: 2.7712e-04 - KL loss: 251.0937 - beta: 6.3096e-05\n",
      "Epoch 04293: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 69860.9640 - recon_loss: 2.7712e-04 - KL loss: 251.0914 - beta: 6.3096e-05 - val_loss: 77763.7188 - val_recon_loss: 3.0861e-04 - val_KL loss: 243.2775 - val_beta: 6.3096e-05\n",
      "Epoch 4294/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 69452.9567 - recon_loss: 2.7551e-04 - KL loss: 248.2742 - beta: 6.3096e-05 - val_loss: 76388.2500 - val_recon_loss: 3.0313e-04 - val_KL loss: 245.4941 - val_beta: 6.3096e-05\n",
      "Epoch 4295/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68961.9261 - recon_loss: 2.7355e-04 - KL loss: 249.1991 - beta: 6.3096e-05 - val_loss: 76370.6250 - val_recon_loss: 3.0305e-04 - val_KL loss: 246.7642 - val_beta: 6.3096e-05\n",
      "Epoch 4296/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68533.8727 - recon_loss: 2.7184e-04 - KL loss: 249.9201 - beta: 6.3096e-05 - val_loss: 74862.6562 - val_recon_loss: 2.9704e-04 - val_KL loss: 250.4391 - val_beta: 6.3096e-05\n",
      "Epoch 4297/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68616.8423 - recon_loss: 2.7216e-04 - KL loss: 254.1064 - beta: 6.3096e-05 - val_loss: 74602.1562 - val_recon_loss: 2.9599e-04 - val_KL loss: 252.2070 - val_beta: 6.3096e-05\n",
      "Epoch 4298/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68770.4736 - recon_loss: 2.7276e-04 - KL loss: 255.5423 - beta: 6.3096e-05 - val_loss: 74975.9609 - val_recon_loss: 2.9749e-04 - val_KL loss: 250.1844 - val_beta: 6.3096e-05\n",
      "Epoch 4299/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 67571.7841 - recon_loss: 2.6799e-04 - KL loss: 254.9003 - beta: 6.3096e-05 - val_loss: 74771.2031 - val_recon_loss: 2.9666e-04 - val_KL loss: 253.0125 - val_beta: 6.3096e-05\n",
      "Epoch 4300/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68718.7485 - recon_loss: 2.7255e-04 - KL loss: 256.4455 - beta: 6.3096e-05 - val_loss: 74217.9375 - val_recon_loss: 2.9447e-04 - val_KL loss: 250.0652 - val_beta: 6.3096e-05\n",
      "Epoch 4301/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68299.8290 - recon_loss: 2.7089e-04 - KL loss: 255.3952 - beta: 6.3096e-05 - val_loss: 75340.2812 - val_recon_loss: 2.9893e-04 - val_KL loss: 252.3792 - val_beta: 6.3096e-05\n",
      "Epoch 4302/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68025.3987 - recon_loss: 2.6980e-04 - KL loss: 254.3672 - beta: 6.3096e-05 - val_loss: 74746.8359 - val_recon_loss: 2.9656e-04 - val_KL loss: 254.0671 - val_beta: 6.3096e-05\n",
      "Epoch 4303/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 67289.4453 - recon_loss: 2.6686e-04 - KL loss: 256.7992 - beta: 6.3096e-05 - val_loss: 75220.4688 - val_recon_loss: 2.9845e-04 - val_KL loss: 252.6611 - val_beta: 6.3096e-05\n",
      "Epoch 4304/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 67320.9457 - recon_loss: 2.6699e-04 - KL loss: 256.4654 - beta: 6.3096e-05 - val_loss: 75032.0156 - val_recon_loss: 2.9770e-04 - val_KL loss: 253.0074 - val_beta: 6.3096e-05\n",
      "Epoch 4305/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 66895.4518 - recon_loss: 2.6530e-04 - KL loss: 255.9349 - beta: 6.3096e-05\n",
      "Epoch 04305: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 66895.4245 - recon_loss: 2.6530e-04 - KL loss: 255.9351 - beta: 6.3096e-05 - val_loss: 75428.7031 - val_recon_loss: 2.9928e-04 - val_KL loss: 253.9910 - val_beta: 6.3096e-05\n",
      "Epoch 4306/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 66952.8139 - recon_loss: 2.6552e-04 - KL loss: 257.1451 - beta: 6.3096e-05 - val_loss: 75420.5781 - val_recon_loss: 2.9924e-04 - val_KL loss: 254.5856 - val_beta: 6.3096e-05\n",
      "Epoch 4307/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 66416.9253 - recon_loss: 2.6339e-04 - KL loss: 257.5776 - beta: 6.3096e-05 - val_loss: 75084.3594 - val_recon_loss: 2.9790e-04 - val_KL loss: 254.1898 - val_beta: 6.3096e-05\n",
      "Epoch 4308/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 66710.5865 - recon_loss: 2.6455e-04 - KL loss: 257.6475 - beta: 6.3096e-05 - val_loss: 75348.9062 - val_recon_loss: 2.9896e-04 - val_KL loss: 253.3149 - val_beta: 6.3096e-05\n",
      "Epoch 4309/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 66762.7191 - recon_loss: 2.6476e-04 - KL loss: 257.0673 - beta: 6.3096e-05 - val_loss: 76201.6484 - val_recon_loss: 3.0235e-04 - val_KL loss: 253.8508 - val_beta: 6.3096e-05\n",
      "Epoch 4310/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 67016.7206 - recon_loss: 2.6577e-04 - KL loss: 257.4927 - beta: 6.3096e-05\n",
      "Epoch 04310: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 67016.4208 - recon_loss: 2.6577e-04 - KL loss: 257.4931 - beta: 6.3096e-05 - val_loss: 75307.6484 - val_recon_loss: 2.9879e-04 - val_KL loss: 254.3112 - val_beta: 6.3096e-05\n",
      "Epoch 4310/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 28372.1458 - recon_loss: 2.8122e-04 - KL loss: 249.8148 - beta: 1.0000e-04 - val_loss: 33472.4180 - val_recon_loss: 3.3231e-04 - val_KL loss: 241.4983 - val_beta: 1.0000e-04\n",
      "Epoch 4311/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 30440.9055 - recon_loss: 3.0205e-04 - KL loss: 235.6384 - beta: 1.0000e-04 - val_loss: 32107.1406 - val_recon_loss: 3.1897e-04 - val_KL loss: 210.3068 - val_beta: 1.0000e-04\n",
      "Epoch 4312/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 30410.8537 - recon_loss: 3.0192e-04 - KL loss: 218.8026 - beta: 1.0000e-04 - val_loss: 32961.9062 - val_recon_loss: 3.2758e-04 - val_KL loss: 204.1490 - val_beta: 1.0000e-04\n",
      "Epoch 4313/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 29548.4777 - recon_loss: 2.9344e-04 - KL loss: 204.8444 - beta: 1.0000e-04 - val_loss: 37780.1680 - val_recon_loss: 3.7572e-04 - val_KL loss: 208.5675 - val_beta: 1.0000e-04\n",
      "Epoch 4314/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 31719.3045 - recon_loss: 3.1504e-04 - KL loss: 215.7538 - beta: 1.0000e-04 - val_loss: 35977.8320 - val_recon_loss: 3.5770e-04 - val_KL loss: 207.4702 - val_beta: 1.0000e-04\n",
      "Epoch 4315/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 30746.6720 - recon_loss: 3.0536e-04 - KL loss: 210.7712 - beta: 1.0000e-04 - val_loss: 38543.8398 - val_recon_loss: 3.8338e-04 - val_KL loss: 206.2118 - val_beta: 1.0000e-04\n",
      "Epoch 4316/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 30043.9812 - recon_loss: 2.9835e-04 - KL loss: 209.3333 - beta: 1.0000e-04 - val_loss: 31484.2500 - val_recon_loss: 3.1276e-04 - val_KL loss: 208.5890 - val_beta: 1.0000e-04\n",
      "Epoch 4317/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 29053.3138 - recon_loss: 2.8845e-04 - KL loss: 208.0266 - beta: 1.0000e-04 - val_loss: 32031.3574 - val_recon_loss: 3.1829e-04 - val_KL loss: 202.1797 - val_beta: 1.0000e-04\n",
      "Epoch 4318/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 30045.7383 - recon_loss: 2.9838e-04 - KL loss: 207.7203 - beta: 1.0000e-04 - val_loss: 33830.8008 - val_recon_loss: 3.3619e-04 - val_KL loss: 211.9668 - val_beta: 1.0000e-04\n",
      "Epoch 4319/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 29848.0908 - recon_loss: 2.9635e-04 - KL loss: 212.8703 - beta: 1.0000e-04 - val_loss: 39184.5703 - val_recon_loss: 3.8973e-04 - val_KL loss: 211.1200 - val_beta: 1.0000e-04\n",
      "Epoch 4320/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 29443.9181 - recon_loss: 2.9233e-04 - KL loss: 211.0694 - beta: 1.0000e-04 - val_loss: 30908.7949 - val_recon_loss: 3.0695e-04 - val_KL loss: 213.2976 - val_beta: 1.0000e-04\n",
      "Epoch 4321/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 28885.4217 - recon_loss: 2.8671e-04 - KL loss: 214.9159 - beta: 1.0000e-04 - val_loss: 28934.5039 - val_recon_loss: 2.8730e-04 - val_KL loss: 204.7845 - val_beta: 1.0000e-04\n",
      "Epoch 4322/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 28560.5422 - recon_loss: 2.8349e-04 - KL loss: 211.1759 - beta: 1.0000e-04 - val_loss: 32898.4297 - val_recon_loss: 3.2675e-04 - val_KL loss: 223.1875 - val_beta: 1.0000e-04\n",
      "Epoch 4323/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 29971.3062 - recon_loss: 2.9758e-04 - KL loss: 213.4366 - beta: 1.0000e-04 - val_loss: 31878.5762 - val_recon_loss: 3.1661e-04 - val_KL loss: 217.7006 - val_beta: 1.0000e-04\n",
      "Epoch 4324/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 29522.0698 - recon_loss: 2.9321e-04 - KL loss: 201.0038 - beta: 1.0000e-04 - val_loss: 29474.1055 - val_recon_loss: 2.9270e-04 - val_KL loss: 203.7704 - val_beta: 1.0000e-04\n",
      "Epoch 4325/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28566.0118 - recon_loss: 2.8360e-04 - KL loss: 206.1987 - beta: 1.0000e-04 - val_loss: 30562.9180 - val_recon_loss: 3.0358e-04 - val_KL loss: 205.0561 - val_beta: 1.0000e-04\n",
      "Epoch 4326/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 28407.9922 - recon_loss: 2.8199e-04 - KL loss: 209.1147 - beta: 1.0000e-04\n",
      "Epoch 04326: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 28408.0738 - recon_loss: 2.8199e-04 - KL loss: 209.1165 - beta: 1.0000e-04 - val_loss: 29808.4102 - val_recon_loss: 2.9591e-04 - val_KL loss: 217.0816 - val_beta: 1.0000e-04\n",
      "Epoch 4327/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 27617.2917 - recon_loss: 2.7401e-04 - KL loss: 216.2581 - beta: 1.0000e-04 - val_loss: 28168.4590 - val_recon_loss: 2.7952e-04 - val_KL loss: 216.4304 - val_beta: 1.0000e-04\n",
      "Epoch 4328/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 26882.0212 - recon_loss: 2.6664e-04 - KL loss: 218.0296 - beta: 1.0000e-04 - val_loss: 27670.7305 - val_recon_loss: 2.7457e-04 - val_KL loss: 213.8191 - val_beta: 1.0000e-04\n",
      "Epoch 4329/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 26906.9945 - recon_loss: 2.6693e-04 - KL loss: 214.2832 - beta: 1.0000e-04 - val_loss: 27571.6133 - val_recon_loss: 2.7355e-04 - val_KL loss: 216.8479 - val_beta: 1.0000e-04\n",
      "Epoch 4330/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 26721.2951 - recon_loss: 2.6502e-04 - KL loss: 219.3777 - beta: 1.0000e-04 - val_loss: 27317.3359 - val_recon_loss: 2.7103e-04 - val_KL loss: 213.8797 - val_beta: 1.0000e-04\n",
      "Epoch 4331/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 26904.6665 - recon_loss: 2.6688e-04 - KL loss: 216.6264 - beta: 1.0000e-04 - val_loss: 27346.5000 - val_recon_loss: 2.7128e-04 - val_KL loss: 218.6323 - val_beta: 1.0000e-04\n",
      "Epoch 4332/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 26861.0468 - recon_loss: 2.6644e-04 - KL loss: 217.0916 - beta: 1.0000e-04 - val_loss: 26898.6875 - val_recon_loss: 2.6683e-04 - val_KL loss: 215.6040 - val_beta: 1.0000e-04\n",
      "Epoch 4333/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 26659.8198 - recon_loss: 2.6441e-04 - KL loss: 218.8553 - beta: 1.0000e-04 - val_loss: 26744.1738 - val_recon_loss: 2.6529e-04 - val_KL loss: 215.6315 - val_beta: 1.0000e-04\n",
      "Epoch 4334/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 26312.6181 - recon_loss: 2.6095e-04 - KL loss: 217.1827 - beta: 1.0000e-04 - val_loss: 27448.8477 - val_recon_loss: 2.7230e-04 - val_KL loss: 218.6459 - val_beta: 1.0000e-04\n",
      "Epoch 4335/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 26382.6676 - recon_loss: 2.6165e-04 - KL loss: 218.1542 - beta: 1.0000e-04 - val_loss: 27582.9062 - val_recon_loss: 2.7366e-04 - val_KL loss: 216.5128 - val_beta: 1.0000e-04\n",
      "Epoch 4336/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 26672.9099 - recon_loss: 2.6455e-04 - KL loss: 217.5944 - beta: 1.0000e-04 - val_loss: 27880.9043 - val_recon_loss: 2.7669e-04 - val_KL loss: 211.8913 - val_beta: 1.0000e-04\n",
      "Epoch 4337/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 26319.9375 - recon_loss: 2.6104e-04 - KL loss: 215.6977 - beta: 1.0000e-04 - val_loss: 27296.3359 - val_recon_loss: 2.7078e-04 - val_KL loss: 218.4993 - val_beta: 1.0000e-04\n",
      "Epoch 4338/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 25916.7649 - recon_loss: 2.5698e-04 - KL loss: 219.0054 - beta: 1.0000e-04\n",
      "Epoch 04338: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25916.9655 - recon_loss: 2.5698e-04 - KL loss: 219.0049 - beta: 1.0000e-04 - val_loss: 28158.4648 - val_recon_loss: 2.7941e-04 - val_KL loss: 217.0340 - val_beta: 1.0000e-04\n",
      "Epoch 4339/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 26095.9832 - recon_loss: 2.5879e-04 - KL loss: 217.4056 - beta: 1.0000e-04 - val_loss: 26736.6211 - val_recon_loss: 2.6519e-04 - val_KL loss: 217.7550 - val_beta: 1.0000e-04\n",
      "Epoch 4340/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25998.1095 - recon_loss: 2.5780e-04 - KL loss: 217.8206 - beta: 1.0000e-04 - val_loss: 26442.0840 - val_recon_loss: 2.6226e-04 - val_KL loss: 216.2796 - val_beta: 1.0000e-04\n",
      "Epoch 4341/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 25707.1210 - recon_loss: 2.5490e-04 - KL loss: 217.3134 - beta: 1.0000e-04 - val_loss: 26423.3770 - val_recon_loss: 2.6206e-04 - val_KL loss: 217.2669 - val_beta: 1.0000e-04\n",
      "Epoch 4342/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25308.3885 - recon_loss: 2.5090e-04 - KL loss: 218.6223 - beta: 1.0000e-04 - val_loss: 26534.0000 - val_recon_loss: 2.6316e-04 - val_KL loss: 218.3033 - val_beta: 1.0000e-04\n",
      "Epoch 4343/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25623.2196 - recon_loss: 2.5404e-04 - KL loss: 219.0803 - beta: 1.0000e-04 - val_loss: 26799.7793 - val_recon_loss: 2.6580e-04 - val_KL loss: 219.9539 - val_beta: 1.0000e-04\n",
      "Epoch 4344/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 25491.3658 - recon_loss: 2.5270e-04 - KL loss: 221.5359 - beta: 1.0000e-04 - val_loss: 27167.2656 - val_recon_loss: 2.6944e-04 - val_KL loss: 222.9977 - val_beta: 1.0000e-04\n",
      "Epoch 4345/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 25328.5406 - recon_loss: 2.5106e-04 - KL loss: 222.2029 - beta: 1.0000e-04 - val_loss: 26652.5879 - val_recon_loss: 2.6431e-04 - val_KL loss: 221.2338 - val_beta: 1.0000e-04\n",
      "Epoch 4346/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 25642.8715 - recon_loss: 2.5420e-04 - KL loss: 222.5434 - beta: 1.0000e-04\n",
      "Epoch 04346: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25642.9807 - recon_loss: 2.5420e-04 - KL loss: 222.5430 - beta: 1.0000e-04 - val_loss: 27578.5781 - val_recon_loss: 2.7357e-04 - val_KL loss: 221.8414 - val_beta: 1.0000e-04\n",
      "Epoch 4347/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 25428.2832 - recon_loss: 2.5206e-04 - KL loss: 222.2397 - beta: 1.0000e-04 - val_loss: 29880.0098 - val_recon_loss: 2.9658e-04 - val_KL loss: 222.4237 - val_beta: 1.0000e-04\n",
      "Epoch 4348/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25705.9497 - recon_loss: 2.5483e-04 - KL loss: 223.0682 - beta: 1.0000e-04 - val_loss: 26490.0215 - val_recon_loss: 2.6270e-04 - val_KL loss: 220.1095 - val_beta: 1.0000e-04\n",
      "Epoch 4349/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 25521.5420 - recon_loss: 2.5299e-04 - KL loss: 222.0776 - beta: 1.0000e-04 - val_loss: 26508.2910 - val_recon_loss: 2.6288e-04 - val_KL loss: 219.7919 - val_beta: 1.0000e-04\n",
      "Epoch 4350/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25414.9637 - recon_loss: 2.5193e-04 - KL loss: 221.8429 - beta: 1.0000e-04 - val_loss: 26500.9668 - val_recon_loss: 2.6281e-04 - val_KL loss: 220.2607 - val_beta: 1.0000e-04\n",
      "Epoch 4351/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 25276.2908 - recon_loss: 2.5054e-04 - KL loss: 221.9068 - beta: 1.0000e-04\n",
      "Epoch 04351: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 25276.2480 - recon_loss: 2.5054e-04 - KL loss: 221.9070 - beta: 1.0000e-04 - val_loss: 26569.0156 - val_recon_loss: 2.6349e-04 - val_KL loss: 219.6505 - val_beta: 1.0000e-04\n",
      "Epoch 4351/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10626.0464 - recon_loss: 2.6166e-04 - KL loss: 209.0087 - beta: 1.5849e-04 - val_loss: 11500.2822 - val_recon_loss: 2.8441e-04 - val_KL loss: 177.5968 - val_beta: 1.5849e-04\n",
      "Epoch 4352/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10711.3229 - recon_loss: 2.6464e-04 - KL loss: 175.6905 - beta: 1.5849e-04 - val_loss: 11644.3594 - val_recon_loss: 2.8831e-04 - val_KL loss: 166.4420 - val_beta: 1.5849e-04\n",
      "Epoch 4353/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11017.8976 - recon_loss: 2.7253e-04 - KL loss: 168.2867 - beta: 1.5849e-04 - val_loss: 11667.9512 - val_recon_loss: 2.8912e-04 - val_KL loss: 157.9948 - val_beta: 1.5849e-04\n",
      "Epoch 4354/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 11397.0408 - recon_loss: 2.8216e-04 - KL loss: 164.0996 - beta: 1.5849e-04 - val_loss: 13562.2012 - val_recon_loss: 3.3677e-04 - val_KL loss: 155.2620 - val_beta: 1.5849e-04\n",
      "Epoch 4355/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 11681.4021 - recon_loss: 2.8933e-04 - KL loss: 162.8864 - beta: 1.5849e-04 - val_loss: 13261.5410 - val_recon_loss: 3.2890e-04 - val_KL loss: 167.8178 - val_beta: 1.5849e-04\n",
      "Epoch 4356/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 11114.4408 - recon_loss: 2.7494e-04 - KL loss: 168.9742 - beta: 1.5849e-04\n",
      "Epoch 04356: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 11114.4208 - recon_loss: 2.7494e-04 - KL loss: 168.9756 - beta: 1.5849e-04 - val_loss: 11916.4043 - val_recon_loss: 2.9519e-04 - val_KL loss: 164.5549 - val_beta: 1.5849e-04\n",
      "Epoch 4357/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 10788.5883 - recon_loss: 2.6685e-04 - KL loss: 165.2000 - beta: 1.5849e-04 - val_loss: 11919.5986 - val_recon_loss: 2.9527e-04 - val_KL loss: 164.5259 - val_beta: 1.5849e-04\n",
      "Epoch 4358/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 10660.0416 - recon_loss: 2.6356e-04 - KL loss: 167.4419 - beta: 1.5849e-04 - val_loss: 11007.5859 - val_recon_loss: 2.7234e-04 - val_KL loss: 165.4779 - val_beta: 1.5849e-04\n",
      "Epoch 4359/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10555.2910 - recon_loss: 2.6091e-04 - KL loss: 168.1098 - beta: 1.5849e-04 - val_loss: 10851.1660 - val_recon_loss: 2.6835e-04 - val_KL loss: 167.8282 - val_beta: 1.5849e-04\n",
      "Epoch 4360/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10424.3855 - recon_loss: 2.5762e-04 - KL loss: 168.3933 - beta: 1.5849e-04 - val_loss: 12995.5439 - val_recon_loss: 3.2222e-04 - val_KL loss: 167.9171 - val_beta: 1.5849e-04\n",
      "Epoch 4361/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 10527.0398 - recon_loss: 2.6019e-04 - KL loss: 168.8066 - beta: 1.5849e-04 - val_loss: 10353.2734 - val_recon_loss: 2.5599e-04 - val_KL loss: 162.1262 - val_beta: 1.5849e-04\n",
      "Epoch 4362/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 10442.6424 - recon_loss: 2.5819e-04 - KL loss: 163.9607 - beta: 1.5849e-04 - val_loss: 10854.3027 - val_recon_loss: 2.6861e-04 - val_KL loss: 160.8862 - val_beta: 1.5849e-04\n",
      "Epoch 4363/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10357.6286 - recon_loss: 2.5601e-04 - KL loss: 165.4949 - beta: 1.5849e-04 - val_loss: 11127.5693 - val_recon_loss: 2.7539e-04 - val_KL loss: 164.1689 - val_beta: 1.5849e-04\n",
      "Epoch 4364/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10362.9733 - recon_loss: 2.5621e-04 - KL loss: 163.2577 - beta: 1.5849e-04 - val_loss: 10620.0322 - val_recon_loss: 2.6275e-04 - val_KL loss: 159.5877 - val_beta: 1.5849e-04\n",
      "Epoch 4365/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 10647.6708 - recon_loss: 2.6333e-04 - KL loss: 164.1881 - beta: 1.5849e-04 - val_loss: 11422.5596 - val_recon_loss: 2.8281e-04 - val_KL loss: 163.7125 - val_beta: 1.5849e-04\n",
      "Epoch 4366/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10402.7637 - recon_loss: 2.5711e-04 - KL loss: 167.0619 - beta: 1.5849e-04\n",
      "Epoch 04366: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10402.8077 - recon_loss: 2.5711e-04 - KL loss: 167.0621 - beta: 1.5849e-04 - val_loss: 10858.7490 - val_recon_loss: 2.6860e-04 - val_KL loss: 165.7759 - val_beta: 1.5849e-04\n",
      "Epoch 4367/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10336.2952 - recon_loss: 2.5543e-04 - KL loss: 167.4832 - beta: 1.5849e-04 - val_loss: 11044.0508 - val_recon_loss: 2.7334e-04 - val_KL loss: 162.1089 - val_beta: 1.5849e-04\n",
      "Epoch 4368/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10337.6597 - recon_loss: 2.5550e-04 - KL loss: 165.8529 - beta: 1.5849e-04 - val_loss: 11311.9609 - val_recon_loss: 2.8006e-04 - val_KL loss: 162.5241 - val_beta: 1.5849e-04\n",
      "Epoch 4369/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10211.6431 - recon_loss: 2.5233e-04 - KL loss: 166.0951 - beta: 1.5849e-04 - val_loss: 11402.9297 - val_recon_loss: 2.8229e-04 - val_KL loss: 164.7860 - val_beta: 1.5849e-04\n",
      "Epoch 4370/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10338.8378 - recon_loss: 2.5549e-04 - KL loss: 167.4957 - beta: 1.5849e-04 - val_loss: 12451.2861 - val_recon_loss: 3.0859e-04 - val_KL loss: 165.9367 - val_beta: 1.5849e-04\n",
      "Epoch 4371/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10292.4397 - recon_loss: 2.5431e-04 - KL loss: 168.1697 - beta: 1.5849e-04\n",
      "Epoch 04371: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10292.3527 - recon_loss: 2.5431e-04 - KL loss: 168.1695 - beta: 1.5849e-04 - val_loss: 11311.1230 - val_recon_loss: 2.7997e-04 - val_KL loss: 165.1811 - val_beta: 1.5849e-04\n",
      "Epoch 4371/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4246.1715 - recon_loss: 2.5851e-04 - KL loss: 149.0626 - beta: 2.5119e-04 - val_loss: 5332.0781 - val_recon_loss: 3.2850e-04 - val_KL loss: 125.7506 - val_beta: 2.5119e-04\n",
      "Epoch 4372/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4738.8113 - recon_loss: 2.9122e-04 - KL loss: 123.2513 - beta: 2.5119e-04 - val_loss: 4525.0566 - val_recon_loss: 2.7811e-04 - val_KL loss: 117.3515 - val_beta: 2.5119e-04\n",
      "Epoch 4373/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4491.8032 - recon_loss: 2.7580e-04 - KL loss: 120.6200 - beta: 2.5119e-04 - val_loss: 4754.7246 - val_recon_loss: 2.9255e-04 - val_KL loss: 118.0416 - val_beta: 2.5119e-04\n",
      "Epoch 4374/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4397.6730 - recon_loss: 2.7003e-04 - KL loss: 118.0590 - beta: 2.5119e-04 - val_loss: 7018.0371 - val_recon_loss: 4.3352e-04 - val_KL loss: 147.1714 - val_beta: 2.5119e-04\n",
      "Epoch 4375/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4900.3324 - recon_loss: 3.0122e-04 - KL loss: 126.2844 - beta: 2.5119e-04 - val_loss: 7364.6313 - val_recon_loss: 4.5386e-04 - val_KL loss: 171.5075 - val_beta: 2.5119e-04\n",
      "Epoch 4376/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5151.3130 - recon_loss: 3.1701e-04 - KL loss: 127.0226 - beta: 2.5119e-04 - val_loss: 4762.8462 - val_recon_loss: 2.9373e-04 - val_KL loss: 107.5850 - val_beta: 2.5119e-04\n",
      "Epoch 4377/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4400.5657 - recon_loss: 2.7057e-04 - KL loss: 112.2517 - beta: 2.5119e-04\n",
      "Epoch 04377: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4400.5344 - recon_loss: 2.7057e-04 - KL loss: 112.2530 - beta: 2.5119e-04 - val_loss: 4531.1162 - val_recon_loss: 2.7866e-04 - val_KL loss: 114.5784 - val_beta: 2.5119e-04\n",
      "Epoch 4378/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4219.0558 - recon_loss: 2.5888e-04 - KL loss: 116.0581 - beta: 2.5119e-04 - val_loss: 4494.3618 - val_recon_loss: 2.7639e-04 - val_KL loss: 113.8377 - val_beta: 2.5119e-04\n",
      "Epoch 4379/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4086.0258 - recon_loss: 2.5055e-04 - KL loss: 115.0975 - beta: 2.5119e-04 - val_loss: 4392.3687 - val_recon_loss: 2.6991e-04 - val_KL loss: 114.5146 - val_beta: 2.5119e-04\n",
      "Epoch 4380/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4094.0755 - recon_loss: 2.5111e-04 - KL loss: 114.2454 - beta: 2.5119e-04 - val_loss: 4240.6226 - val_recon_loss: 2.6039e-04 - val_KL loss: 113.7789 - val_beta: 2.5119e-04\n",
      "Epoch 4381/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4109.2092 - recon_loss: 2.5213e-04 - KL loss: 113.1390 - beta: 2.5119e-04 - val_loss: 4102.4106 - val_recon_loss: 2.5180e-04 - val_KL loss: 111.5717 - val_beta: 2.5119e-04\n",
      "Epoch 4382/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4067.0597 - recon_loss: 2.4949e-04 - KL loss: 112.9646 - beta: 2.5119e-04 - val_loss: 4095.4590 - val_recon_loss: 2.5144e-04 - val_KL loss: 110.4598 - val_beta: 2.5119e-04\n",
      "Epoch 4383/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4150.0945 - recon_loss: 2.5462e-04 - KL loss: 114.5877 - beta: 2.5119e-04 - val_loss: 4238.4521 - val_recon_loss: 2.6038e-04 - val_KL loss: 111.7274 - val_beta: 2.5119e-04\n",
      "Epoch 4384/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4060.6571 - recon_loss: 2.4912e-04 - KL loss: 112.3020 - beta: 2.5119e-04 - val_loss: 4191.0903 - val_recon_loss: 2.5746e-04 - val_KL loss: 110.5566 - val_beta: 2.5119e-04\n",
      "Epoch 4385/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4076.7865 - recon_loss: 2.5008e-04 - KL loss: 113.3349 - beta: 2.5119e-04 - val_loss: 4242.0483 - val_recon_loss: 2.6065e-04 - val_KL loss: 111.0447 - val_beta: 2.5119e-04\n",
      "Epoch 4386/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4072.2905 - recon_loss: 2.4980e-04 - KL loss: 113.2877 - beta: 2.5119e-04 - val_loss: 4254.8799 - val_recon_loss: 2.6160e-04 - val_KL loss: 108.8463 - val_beta: 2.5119e-04\n",
      "Epoch 4387/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4104.5879 - recon_loss: 2.5196e-04 - KL loss: 111.2266 - beta: 2.5119e-04\n",
      "Epoch 04387: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4104.5842 - recon_loss: 2.5196e-04 - KL loss: 111.2276 - beta: 2.5119e-04 - val_loss: 4223.4014 - val_recon_loss: 2.5937e-04 - val_KL loss: 112.7213 - val_beta: 2.5119e-04\n",
      "Epoch 4388/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4052.6669 - recon_loss: 2.4856e-04 - KL loss: 113.2803 - beta: 2.5119e-04 - val_loss: 4223.8467 - val_recon_loss: 2.5936e-04 - val_KL loss: 113.2158 - val_beta: 2.5119e-04\n",
      "Epoch 4389/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4015.6004 - recon_loss: 2.4619e-04 - KL loss: 113.7514 - beta: 2.5119e-04 - val_loss: 4291.4785 - val_recon_loss: 2.6369e-04 - val_KL loss: 112.3453 - val_beta: 2.5119e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4390/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4005.7799 - recon_loss: 2.4558e-04 - KL loss: 113.5549 - beta: 2.5119e-04 - val_loss: 4122.2666 - val_recon_loss: 2.5298e-04 - val_KL loss: 112.8570 - val_beta: 2.5119e-04\n",
      "Epoch 4391/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3967.4524 - recon_loss: 2.4321e-04 - KL loss: 112.8918 - beta: 2.5119e-04 - val_loss: 3987.9141 - val_recon_loss: 2.4456e-04 - val_KL loss: 111.8367 - val_beta: 2.5119e-04\n",
      "Epoch 4392/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3961.9593 - recon_loss: 2.4289e-04 - KL loss: 112.4313 - beta: 2.5119e-04 - val_loss: 4151.3301 - val_recon_loss: 2.5493e-04 - val_KL loss: 110.9773 - val_beta: 2.5119e-04\n",
      "Epoch 4393/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3970.2016 - recon_loss: 2.4341e-04 - KL loss: 112.4555 - beta: 2.5119e-04 - val_loss: 4375.8950 - val_recon_loss: 2.6894e-04 - val_KL loss: 113.5263 - val_beta: 2.5119e-04\n",
      "Epoch 4394/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3992.0764 - recon_loss: 2.4473e-04 - KL loss: 113.3237 - beta: 2.5119e-04 - val_loss: 4185.3916 - val_recon_loss: 2.5695e-04 - val_KL loss: 113.0746 - val_beta: 2.5119e-04\n",
      "Epoch 4395/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4096.4170 - recon_loss: 2.5127e-04 - KL loss: 114.0505 - beta: 2.5119e-04 - val_loss: 4216.9155 - val_recon_loss: 2.5895e-04 - val_KL loss: 112.7794 - val_beta: 2.5119e-04\n",
      "Epoch 4396/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 3953.1503 - recon_loss: 2.4231e-04 - KL loss: 112.8414 - beta: 2.5119e-04\n",
      "Epoch 04396: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3953.1499 - recon_loss: 2.4231e-04 - KL loss: 112.8414 - beta: 2.5119e-04 - val_loss: 4274.2354 - val_recon_loss: 2.6260e-04 - val_KL loss: 112.3639 - val_beta: 2.5119e-04\n",
      "Epoch 4397/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4019.5091 - recon_loss: 2.4647e-04 - KL loss: 113.1707 - beta: 2.5119e-04 - val_loss: 4680.4194 - val_recon_loss: 2.8827e-04 - val_KL loss: 111.5966 - val_beta: 2.5119e-04\n",
      "Epoch 4398/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3943.6599 - recon_loss: 2.4175e-04 - KL loss: 112.2098 - beta: 2.5119e-04 - val_loss: 4184.2651 - val_recon_loss: 2.5691e-04 - val_KL loss: 112.4577 - val_beta: 2.5119e-04\n",
      "Epoch 4399/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3953.8112 - recon_loss: 2.4235e-04 - KL loss: 112.7741 - beta: 2.5119e-04 - val_loss: 4187.9766 - val_recon_loss: 2.5722e-04 - val_KL loss: 111.3350 - val_beta: 2.5119e-04\n",
      "Epoch 4400/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3927.7719 - recon_loss: 2.4070e-04 - KL loss: 112.9913 - beta: 2.5119e-04 - val_loss: 4172.4175 - val_recon_loss: 2.5624e-04 - val_KL loss: 111.3190 - val_beta: 2.5119e-04\n",
      "Epoch 4401/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3993.0196 - recon_loss: 2.4480e-04 - KL loss: 113.2563 - beta: 2.5119e-04\n",
      "Epoch 04401: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3992.9873 - recon_loss: 2.4479e-04 - KL loss: 113.2562 - beta: 2.5119e-04 - val_loss: 4237.3105 - val_recon_loss: 2.6035e-04 - val_KL loss: 111.0215 - val_beta: 2.5119e-04\n",
      "Epoch 4401/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1676.4002 - recon_loss: 2.5005e-04 - KL loss: 98.6660 - beta: 3.9811e-04 - val_loss: 1873.8639 - val_recon_loss: 2.8403e-04 - val_KL loss: 81.7286 - val_beta: 3.9811e-04\n",
      "Epoch 4402/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1751.8815 - recon_loss: 2.6406e-04 - KL loss: 85.8042 - beta: 3.9811e-04 - val_loss: 1776.0959 - val_recon_loss: 2.6849e-04 - val_KL loss: 82.0694 - val_beta: 3.9811e-04\n",
      "Epoch 4403/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1737.5962 - recon_loss: 2.6215e-04 - KL loss: 83.5719 - beta: 3.9811e-04 - val_loss: 1930.8989 - val_recon_loss: 2.9340e-04 - val_KL loss: 79.6537 - val_beta: 3.9811e-04\n",
      "Epoch 4404/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1884.1836 - recon_loss: 2.8558e-04 - KL loss: 82.3007 - beta: 3.9811e-04 - val_loss: 1901.2356 - val_recon_loss: 2.8834e-04 - val_KL loss: 81.9539 - val_beta: 3.9811e-04\n",
      "Epoch 4405/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1887.0466 - recon_loss: 2.8626e-04 - KL loss: 80.8798 - beta: 3.9811e-04 - val_loss: 1889.6581 - val_recon_loss: 2.8629e-04 - val_KL loss: 83.3179 - val_beta: 3.9811e-04\n",
      "Epoch 4406/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1877.1745 - recon_loss: 2.8500e-04 - KL loss: 78.9424 - beta: 3.9811e-04 - val_loss: 1947.0422 - val_recon_loss: 2.9621e-04 - val_KL loss: 78.0745 - val_beta: 3.9811e-04\n",
      "Epoch 4407/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1825.4451 - recon_loss: 2.7676e-04 - KL loss: 79.1853 - beta: 3.9811e-04\n",
      "Epoch 04407: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1825.4466 - recon_loss: 2.7676e-04 - KL loss: 79.1854 - beta: 3.9811e-04 - val_loss: 1899.7661 - val_recon_loss: 2.8890e-04 - val_KL loss: 76.9509 - val_beta: 3.9811e-04\n",
      "Epoch 4408/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1738.3945 - recon_loss: 2.6306e-04 - KL loss: 78.5717 - beta: 3.9811e-04 - val_loss: 1859.8523 - val_recon_loss: 2.8242e-04 - val_KL loss: 77.8885 - val_beta: 3.9811e-04\n",
      "Epoch 4409/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1705.6291 - recon_loss: 2.5784e-04 - KL loss: 78.7601 - beta: 3.9811e-04 - val_loss: 1862.6544 - val_recon_loss: 2.8307e-04 - val_KL loss: 76.5750 - val_beta: 3.9811e-04\n",
      "Epoch 4410/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1683.5457 - recon_loss: 2.5452e-04 - KL loss: 77.6497 - beta: 3.9811e-04 - val_loss: 1786.6469 - val_recon_loss: 2.7061e-04 - val_KL loss: 79.1964 - val_beta: 3.9811e-04\n",
      "Epoch 4411/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1667.8075 - recon_loss: 2.5201e-04 - KL loss: 77.7463 - beta: 3.9811e-04 - val_loss: 1735.3649 - val_recon_loss: 2.6284e-04 - val_KL loss: 76.9666 - val_beta: 3.9811e-04\n",
      "Epoch 4412/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1636.8388 - recon_loss: 2.4714e-04 - KL loss: 77.5094 - beta: 3.9811e-04 - val_loss: 1790.6364 - val_recon_loss: 2.7147e-04 - val_KL loss: 77.7617 - val_beta: 3.9811e-04\n",
      "Epoch 4413/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1624.4734 - recon_loss: 2.4512e-04 - KL loss: 77.8799 - beta: 3.9811e-04 - val_loss: 1731.7239 - val_recon_loss: 2.6196e-04 - val_KL loss: 78.8520 - val_beta: 3.9811e-04\n",
      "Epoch 4414/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 1626.2533 - recon_loss: 2.4551e-04 - KL loss: 77.2045 - beta: 3.9811e-04 - val_loss: 1810.7994 - val_recon_loss: 2.7485e-04 - val_KL loss: 76.6402 - val_beta: 3.9811e-04\n",
      "Epoch 4415/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1655.7163 - recon_loss: 2.5013e-04 - KL loss: 77.5047 - beta: 3.9811e-04 - val_loss: 1748.3044 - val_recon_loss: 2.6479e-04 - val_KL loss: 77.5647 - val_beta: 3.9811e-04\n",
      "Epoch 4416/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 1649.3014 - recon_loss: 2.4906e-04 - KL loss: 77.8137 - beta: 3.9811e-04 - val_loss: 1802.2632 - val_recon_loss: 2.7329e-04 - val_KL loss: 77.9346 - val_beta: 3.9811e-04\n",
      "Epoch 4417/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1661.5275 - recon_loss: 2.5101e-04 - KL loss: 77.7425 - beta: 3.9811e-04 - val_loss: 1703.9321 - val_recon_loss: 2.5783e-04 - val_KL loss: 77.1397 - val_beta: 3.9811e-04\n",
      "Epoch 4418/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1632.2770 - recon_loss: 2.4638e-04 - KL loss: 77.7427 - beta: 3.9811e-04 - val_loss: 1686.3300 - val_recon_loss: 2.5502e-04 - val_KL loss: 77.2498 - val_beta: 3.9811e-04\n",
      "Epoch 4419/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1649.4029 - recon_loss: 2.4912e-04 - KL loss: 77.5756 - beta: 3.9811e-04 - val_loss: 1783.3251 - val_recon_loss: 2.7011e-04 - val_KL loss: 79.0458 - val_beta: 3.9811e-04\n",
      "Epoch 4420/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1685.1432 - recon_loss: 2.5453e-04 - KL loss: 79.1793 - beta: 3.9811e-04 - val_loss: 1980.1064 - val_recon_loss: 3.0146e-04 - val_KL loss: 78.0289 - val_beta: 3.9811e-04\n",
      "Epoch 4421/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1693.7446 - recon_loss: 2.5604e-04 - KL loss: 78.2577 - beta: 3.9811e-04 - val_loss: 2099.4797 - val_recon_loss: 3.2038e-04 - val_KL loss: 78.0058 - val_beta: 3.9811e-04\n",
      "Epoch 4422/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1662.2599 - recon_loss: 2.5123e-04 - KL loss: 77.1210 - beta: 3.9811e-04 - val_loss: 1801.7311 - val_recon_loss: 2.7342e-04 - val_KL loss: 76.5866 - val_beta: 3.9811e-04\n",
      "Epoch 4423/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1656.5568 - recon_loss: 2.5037e-04 - KL loss: 76.8558 - beta: 3.9811e-04\n",
      "Epoch 04423: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1656.5275 - recon_loss: 2.5036e-04 - KL loss: 76.8546 - beta: 3.9811e-04 - val_loss: 1751.0286 - val_recon_loss: 2.6566e-04 - val_KL loss: 74.8120 - val_beta: 3.9811e-04\n",
      "Epoch 4424/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1602.1448 - recon_loss: 2.4185e-04 - KL loss: 76.1578 - beta: 3.9811e-04 - val_loss: 1770.8552 - val_recon_loss: 2.6845e-04 - val_KL loss: 77.0613 - val_beta: 3.9811e-04\n",
      "Epoch 4425/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1609.1695 - recon_loss: 2.4282e-04 - KL loss: 77.0582 - beta: 3.9811e-04 - val_loss: 1832.0912 - val_recon_loss: 2.7811e-04 - val_KL loss: 77.3383 - val_beta: 3.9811e-04\n",
      "Epoch 4426/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1623.2469 - recon_loss: 2.4494e-04 - KL loss: 77.8042 - beta: 3.9811e-04 - val_loss: 1876.5995 - val_recon_loss: 2.8504e-04 - val_KL loss: 78.1498 - val_beta: 3.9811e-04\n",
      "Epoch 4427/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1617.5134 - recon_loss: 2.4408e-04 - KL loss: 77.4857 - beta: 3.9811e-04 - val_loss: 1763.9111 - val_recon_loss: 2.6707e-04 - val_KL loss: 78.8177 - val_beta: 3.9811e-04\n",
      "Epoch 4428/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1628.2570 - recon_loss: 2.4575e-04 - KL loss: 77.7032 - beta: 3.9811e-04\n",
      "Epoch 04428: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1628.2525 - recon_loss: 2.4575e-04 - KL loss: 77.7031 - beta: 3.9811e-04 - val_loss: 1812.7805 - val_recon_loss: 2.7487e-04 - val_KL loss: 78.4526 - val_beta: 3.9811e-04\n",
      "Epoch 4428/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 703.8880 - recon_loss: 2.5341e-04 - KL loss: 67.3498 - beta: 6.3096e-04 - val_loss: 726.3513 - val_recon_loss: 2.6422e-04 - val_KL loss: 62.6602 - val_beta: 6.3096e-04\n",
      "Epoch 4429/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 701.4819 - recon_loss: 2.5475e-04 - KL loss: 61.5890 - beta: 6.3096e-04 - val_loss: 725.7274 - val_recon_loss: 2.6521e-04 - val_KL loss: 59.5512 - val_beta: 6.3096e-04\n",
      "Epoch 4430/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 707.6327 - recon_loss: 2.5779e-04 - KL loss: 60.0964 - beta: 6.3096e-04 - val_loss: 835.1157 - val_recon_loss: 3.0922e-04 - val_KL loss: 58.3838 - val_beta: 6.3096e-04\n",
      "Epoch 4431/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 723.2329 - recon_loss: 2.6464e-04 - KL loss: 58.4842 - beta: 6.3096e-04 - val_loss: 747.0386 - val_recon_loss: 2.7495e-04 - val_KL loss: 56.3971 - val_beta: 6.3096e-04\n",
      "Epoch 4432/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 758.8594 - recon_loss: 2.7919e-04 - KL loss: 57.5765 - beta: 6.3096e-04 - val_loss: 859.3026 - val_recon_loss: 3.1941e-04 - val_KL loss: 56.9753 - val_beta: 6.3096e-04\n",
      "Epoch 4433/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 757.7298 - recon_loss: 2.7922e-04 - KL loss: 56.3561 - beta: 6.3096e-04 - val_loss: 769.5010 - val_recon_loss: 2.8365e-04 - val_KL loss: 56.9930 - val_beta: 6.3096e-04\n",
      "Epoch 4434/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 742.6809 - recon_loss: 2.7334e-04 - KL loss: 56.0787 - beta: 6.3096e-04\n",
      "Epoch 04434: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 742.6737 - recon_loss: 2.7334e-04 - KL loss: 56.0785 - beta: 6.3096e-04 - val_loss: 780.2792 - val_recon_loss: 2.8785e-04 - val_KL loss: 57.2391 - val_beta: 6.3096e-04\n",
      "Epoch 4435/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 706.1626 - recon_loss: 2.5870e-04 - KL loss: 56.3316 - beta: 6.3096e-04 - val_loss: 803.8796 - val_recon_loss: 2.9775e-04 - val_KL loss: 55.9579 - val_beta: 6.3096e-04\n",
      "Epoch 4436/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 717.6686 - recon_loss: 2.6337e-04 - KL loss: 56.1194 - beta: 6.3096e-04 - val_loss: 734.5457 - val_recon_loss: 2.7066e-04 - val_KL loss: 54.6712 - val_beta: 6.3096e-04\n",
      "Epoch 4437/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 695.8142 - recon_loss: 2.5472e-04 - KL loss: 55.9947 - beta: 6.3096e-04 - val_loss: 729.1348 - val_recon_loss: 2.6854e-04 - val_KL loss: 54.5887 - val_beta: 6.3096e-04\n",
      "Epoch 4438/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 681.0450 - recon_loss: 2.4930e-04 - KL loss: 54.8256 - beta: 6.3096e-04 - val_loss: 734.6642 - val_recon_loss: 2.7044e-04 - val_KL loss: 55.3388 - val_beta: 6.3096e-04\n",
      "Epoch 4439/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 680.7992 - recon_loss: 2.4900e-04 - KL loss: 55.3305 - beta: 6.3096e-04\n",
      "Epoch 04439: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 680.8060 - recon_loss: 2.4901e-04 - KL loss: 55.3307 - beta: 6.3096e-04 - val_loss: 742.1440 - val_recon_loss: 2.7376e-04 - val_KL loss: 54.4885 - val_beta: 6.3096e-04\n",
      "Epoch 4439/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 307.6434 - recon_loss: 2.5870e-04 - KL loss: 48.9430 - beta: 0.0010 - val_loss: 339.5626 - val_recon_loss: 2.9528e-04 - val_KL loss: 44.2818 - val_beta: 0.0010\n",
      "Epoch 4440/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 313.3919 - recon_loss: 2.6906e-04 - KL loss: 44.3363 - beta: 0.0010 - val_loss: 331.4344 - val_recon_loss: 2.8760e-04 - val_KL loss: 43.8345 - val_beta: 0.0010\n",
      "Epoch 4441/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 304.5936 - recon_loss: 2.6134e-04 - KL loss: 43.2580 - beta: 0.0010 - val_loss: 331.5344 - val_recon_loss: 2.9002e-04 - val_KL loss: 41.5129 - val_beta: 0.0010\n",
      "Epoch 4442/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 306.1311 - recon_loss: 2.6356e-04 - KL loss: 42.5708 - beta: 0.0010 - val_loss: 327.5160 - val_recon_loss: 2.8575e-04 - val_KL loss: 41.7622 - val_beta: 0.0010\n",
      "Epoch 4443/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 305.5144 - recon_loss: 2.6371e-04 - KL loss: 41.8058 - beta: 0.0010 - val_loss: 360.8527 - val_recon_loss: 3.1751e-04 - val_KL loss: 43.3475 - val_beta: 0.0010\n",
      "Epoch 4444/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 335.9724 - recon_loss: 2.9376e-04 - KL loss: 42.2076 - beta: 0.0010 - val_loss: 318.2032 - val_recon_loss: 2.7713e-04 - val_KL loss: 41.0704 - val_beta: 0.0010\n",
      "Epoch 4445/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 58s 58ms/step - loss: 311.1907 - recon_loss: 2.7060e-04 - KL loss: 40.5934 - beta: 0.0010 - val_loss: 321.0327 - val_recon_loss: 2.8101e-04 - val_KL loss: 40.0203 - val_beta: 0.0010\n",
      "Epoch 4446/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 300.5617 - recon_loss: 2.6019e-04 - KL loss: 40.3697 - beta: 0.0010 - val_loss: 339.5599 - val_recon_loss: 2.9891e-04 - val_KL loss: 40.6494 - val_beta: 0.0010\n",
      "Epoch 4447/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 306.8790 - recon_loss: 2.6659e-04 - KL loss: 40.2861 - beta: 0.0010 - val_loss: 305.8668 - val_recon_loss: 2.6613e-04 - val_KL loss: 39.7408 - val_beta: 0.0010\n",
      "Epoch 4448/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 306.6380 - recon_loss: 2.6637e-04 - KL loss: 40.2665 - beta: 0.0010 - val_loss: 347.8137 - val_recon_loss: 3.0740e-04 - val_KL loss: 40.4138 - val_beta: 0.0010\n",
      "Epoch 4449/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 315.9141 - recon_loss: 2.7567e-04 - KL loss: 40.2405 - beta: 0.0010 - val_loss: 340.9173 - val_recon_loss: 3.0152e-04 - val_KL loss: 39.3950 - val_beta: 0.0010\n",
      "Epoch 4450/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 322.4720 - recon_loss: 2.8261e-04 - KL loss: 39.8657 - beta: 0.0010 - val_loss: 499.8522 - val_recon_loss: 4.5852e-04 - val_KL loss: 41.3342 - val_beta: 0.0010\n",
      "Epoch 4451/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 347.5424 - recon_loss: 3.0680e-04 - KL loss: 40.7439 - beta: 0.0010 - val_loss: 373.1334 - val_recon_loss: 3.3219e-04 - val_KL loss: 40.9438 - val_beta: 0.0010\n",
      "Epoch 4452/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 355.7517 - recon_loss: 3.1497e-04 - KL loss: 40.7835 - beta: 0.0010\n",
      "Epoch 04452: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 355.7733 - recon_loss: 3.1499e-04 - KL loss: 40.7844 - beta: 0.0010 - val_loss: 439.9684 - val_recon_loss: 3.9810e-04 - val_KL loss: 41.8715 - val_beta: 0.0010\n",
      "Epoch 4453/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 386.2230 - recon_loss: 3.4370e-04 - KL loss: 42.5274 - beta: 0.0010 - val_loss: 360.7723 - val_recon_loss: 3.1845e-04 - val_KL loss: 42.3247 - val_beta: 0.0010\n",
      "Epoch 4454/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 351.4652 - recon_loss: 3.0942e-04 - KL loss: 42.0489 - beta: 0.0010 - val_loss: 344.4698 - val_recon_loss: 3.0315e-04 - val_KL loss: 41.3186 - val_beta: 0.0010\n",
      "Epoch 4455/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 343.0628 - recon_loss: 3.0080e-04 - KL loss: 42.2598 - beta: 0.0010 - val_loss: 354.0388 - val_recon_loss: 3.1256e-04 - val_KL loss: 41.4829 - val_beta: 0.0010\n",
      "Epoch 4456/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 343.6373 - recon_loss: 3.0128e-04 - KL loss: 42.3526 - beta: 0.0010 - val_loss: 341.2279 - val_recon_loss: 2.9982e-04 - val_KL loss: 41.4114 - val_beta: 0.0010\n",
      "Epoch 4457/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 331.0684 - recon_loss: 2.8936e-04 - KL loss: 41.7094 - beta: 0.0010\n",
      "Epoch 04457: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 331.0652 - recon_loss: 2.8936e-04 - KL loss: 41.7093 - beta: 0.0010 - val_loss: 327.0327 - val_recon_loss: 2.8640e-04 - val_KL loss: 40.6337 - val_beta: 0.0010\n",
      "Epoch 4457/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 151.9643 - recon_loss: 2.9237e-04 - KL loss: 35.5714 - beta: 0.0016 - val_loss: 158.3342 - val_recon_loss: 3.1251e-04 - val_KL loss: 33.9226 - val_beta: 0.0016\n",
      "Epoch 4458/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 158.0078 - recon_loss: 3.1399e-04 - KL loss: 33.0063 - beta: 0.0016 - val_loss: 167.0800 - val_recon_loss: 3.3875e-04 - val_KL loss: 32.2206 - val_beta: 0.0016\n",
      "Epoch 4459/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 147.7636 - recon_loss: 2.9257e-04 - KL loss: 31.2910 - beta: 0.0016 - val_loss: 186.5945 - val_recon_loss: 3.8879e-04 - val_KL loss: 31.8155 - val_beta: 0.0016\n",
      "Epoch 4460/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 158.3184 - recon_loss: 3.2079e-04 - KL loss: 30.6107 - beta: 0.0016 - val_loss: 161.4662 - val_recon_loss: 3.2831e-04 - val_KL loss: 30.7653 - val_beta: 0.0016\n",
      "Epoch 4461/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 147.5656 - recon_loss: 2.9392e-04 - KL loss: 30.5531 - beta: 0.0016 - val_loss: 154.5776 - val_recon_loss: 3.1056e-04 - val_KL loss: 30.9415 - val_beta: 0.0016\n",
      "Epoch 4462/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 145.9387 - recon_loss: 2.8978e-04 - KL loss: 30.5741 - beta: 0.0016 - val_loss: 145.2094 - val_recon_loss: 2.8863e-04 - val_KL loss: 30.3049 - val_beta: 0.0016\n",
      "Epoch 4463/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 150.0734 - recon_loss: 2.9976e-04 - KL loss: 30.7355 - beta: 0.0016 - val_loss: 156.9458 - val_recon_loss: 3.1404e-04 - val_KL loss: 31.9230 - val_beta: 0.0016\n",
      "Epoch 4464/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 160.0893 - recon_loss: 3.2334e-04 - KL loss: 31.3643 - beta: 0.0016 - val_loss: 170.2998 - val_recon_loss: 3.5036e-04 - val_KL loss: 30.8171 - val_beta: 0.0016\n",
      "Epoch 4465/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 159.3996 - recon_loss: 3.2572e-04 - KL loss: 29.7296 - beta: 0.0016 - val_loss: 163.1695 - val_recon_loss: 3.3269e-04 - val_KL loss: 30.7236 - val_beta: 0.0016\n",
      "Epoch 4466/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 148.4716 - recon_loss: 2.9794e-04 - KL loss: 29.8614 - beta: 0.0016 - val_loss: 156.9662 - val_recon_loss: 3.1949e-04 - val_KL loss: 29.7763 - val_beta: 0.0016\n",
      "Epoch 4467/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 145.6720 - recon_loss: 2.9153e-04 - KL loss: 29.6119 - beta: 0.0016\n",
      "Epoch 04467: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 145.6699 - recon_loss: 2.9153e-04 - KL loss: 29.6117 - beta: 0.0016 - val_loss: 156.6009 - val_recon_loss: 3.1833e-04 - val_KL loss: 29.8711 - val_beta: 0.0016\n",
      "Epoch 4468/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 138.3665 - recon_loss: 2.7287e-04 - KL loss: 29.7339 - beta: 0.0016 - val_loss: 175.1306 - val_recon_loss: 3.6405e-04 - val_KL loss: 30.1984 - val_beta: 0.0016\n",
      "Epoch 4469/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 137.9636 - recon_loss: 2.7185e-04 - KL loss: 29.7395 - beta: 0.0016 - val_loss: 153.5501 - val_recon_loss: 3.1085e-04 - val_KL loss: 29.7986 - val_beta: 0.0016\n",
      "Epoch 4470/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 137.6097 - recon_loss: 2.7077e-04 - KL loss: 29.8134 - beta: 0.0016 - val_loss: 152.6684 - val_recon_loss: 3.0981e-04 - val_KL loss: 29.3295 - val_beta: 0.0016\n",
      "Epoch 4471/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 135.6043 - recon_loss: 2.6617e-04 - KL loss: 29.6408 - beta: 0.0016 - val_loss: 147.1098 - val_recon_loss: 2.9519e-04 - val_KL loss: 29.5936 - val_beta: 0.0016\n",
      "Epoch 4472/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 134.7057 - recon_loss: 2.6448e-04 - KL loss: 29.4124 - beta: 0.0016 - val_loss: 144.3083 - val_recon_loss: 2.8805e-04 - val_KL loss: 29.6328 - val_beta: 0.0016\n",
      "Epoch 4473/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 133.4460 - recon_loss: 2.6143e-04 - KL loss: 29.3689 - beta: 0.0016 - val_loss: 143.5945 - val_recon_loss: 2.8628e-04 - val_KL loss: 29.6236 - val_beta: 0.0016\n",
      "Epoch 4474/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 134.9687 - recon_loss: 2.6471e-04 - KL loss: 29.5845 - beta: 0.0016 - val_loss: 145.2925 - val_recon_loss: 2.8842e-04 - val_KL loss: 30.4713 - val_beta: 0.0016\n",
      "Epoch 4475/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 139.1033 - recon_loss: 2.7417e-04 - KL loss: 29.9554 - beta: 0.0016 - val_loss: 140.7425 - val_recon_loss: 2.7956e-04 - val_KL loss: 29.4485 - val_beta: 0.0016\n",
      "Epoch 4476/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 137.4626 - recon_loss: 2.7008e-04 - KL loss: 29.9405 - beta: 0.0016 - val_loss: 146.3787 - val_recon_loss: 2.9262e-04 - val_KL loss: 29.8861 - val_beta: 0.0016\n",
      "Epoch 4477/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 147.3031 - recon_loss: 2.9281e-04 - KL loss: 30.7323 - beta: 0.0016 - val_loss: 149.9849 - val_recon_loss: 3.0055e-04 - val_KL loss: 30.3324 - val_beta: 0.0016\n",
      "Epoch 4478/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 144.6808 - recon_loss: 2.8691e-04 - KL loss: 30.4587 - beta: 0.0016 - val_loss: 145.6989 - val_recon_loss: 2.9016e-04 - val_KL loss: 30.1860 - val_beta: 0.0016\n",
      "Epoch 4479/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 142.8243 - recon_loss: 2.8233e-04 - KL loss: 30.4261 - beta: 0.0016 - val_loss: 146.9872 - val_recon_loss: 2.9356e-04 - val_KL loss: 30.1197 - val_beta: 0.0016\n",
      "Epoch 4480/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 141.9631 - recon_loss: 2.8044e-04 - KL loss: 30.3169 - beta: 0.0016\n",
      "Epoch 04480: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 141.9637 - recon_loss: 2.8044e-04 - KL loss: 30.3169 - beta: 0.0016 - val_loss: 144.2081 - val_recon_loss: 2.8752e-04 - val_KL loss: 29.7438 - val_beta: 0.0016\n",
      "Epoch 4481/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 138.0878 - recon_loss: 2.7168e-04 - KL loss: 29.9317 - beta: 0.0016 - val_loss: 141.1246 - val_recon_loss: 2.7928e-04 - val_KL loss: 29.9393 - val_beta: 0.0016\n",
      "Epoch 4482/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 138.6442 - recon_loss: 2.7210e-04 - KL loss: 30.3185 - beta: 0.0016 - val_loss: 138.8342 - val_recon_loss: 2.7261e-04 - val_KL loss: 30.3067 - val_beta: 0.0016\n",
      "Epoch 4483/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 138.1802 - recon_loss: 2.7095e-04 - KL loss: 30.3133 - beta: 0.0016 - val_loss: 143.4651 - val_recon_loss: 2.8498e-04 - val_KL loss: 30.0112 - val_beta: 0.0016\n",
      "Epoch 4484/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 137.5771 - recon_loss: 2.6955e-04 - KL loss: 30.2654 - beta: 0.0016 - val_loss: 139.5013 - val_recon_loss: 2.7471e-04 - val_KL loss: 30.1393 - val_beta: 0.0016\n",
      "Epoch 4485/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 138.0144 - recon_loss: 2.7061e-04 - KL loss: 30.2819 - beta: 0.0016 - val_loss: 140.6373 - val_recon_loss: 2.7788e-04 - val_KL loss: 30.0094 - val_beta: 0.0016\n",
      "Epoch 4486/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 137.2161 - recon_loss: 2.6862e-04 - KL loss: 30.2753 - beta: 0.0016 - val_loss: 136.9061 - val_recon_loss: 2.6929e-04 - val_KL loss: 29.6994 - val_beta: 0.0016\n",
      "Epoch 4487/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 137.1758 - recon_loss: 2.6856e-04 - KL loss: 30.2595 - beta: 0.0016 - val_loss: 138.4669 - val_recon_loss: 2.7259e-04 - val_KL loss: 29.9484 - val_beta: 0.0016\n",
      "Epoch 4488/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 136.1004 - recon_loss: 2.6663e-04 - KL loss: 29.9520 - beta: 0.0016 - val_loss: 139.7842 - val_recon_loss: 2.7680e-04 - val_KL loss: 29.5877 - val_beta: 0.0016\n",
      "Epoch 4489/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 136.4939 - recon_loss: 2.6780e-04 - KL loss: 29.8799 - beta: 0.0016 - val_loss: 138.8592 - val_recon_loss: 2.7471e-04 - val_KL loss: 29.4954 - val_beta: 0.0016\n",
      "Epoch 4490/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 135.7448 - recon_loss: 2.6595e-04 - KL loss: 29.8694 - beta: 0.0016 - val_loss: 136.0721 - val_recon_loss: 2.6706e-04 - val_KL loss: 29.7548 - val_beta: 0.0016\n",
      "Epoch 4491/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 135.1234 - recon_loss: 2.6416e-04 - KL loss: 29.9609 - beta: 0.0016 - val_loss: 136.1902 - val_recon_loss: 2.6729e-04 - val_KL loss: 29.7812 - val_beta: 0.0016\n",
      "Epoch 4492/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 135.5434 - recon_loss: 2.6511e-04 - KL loss: 30.0006 - beta: 0.0016 - val_loss: 145.6614 - val_recon_loss: 2.9072e-04 - val_KL loss: 29.9243 - val_beta: 0.0016\n",
      "Epoch 4493/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 135.3284 - recon_loss: 2.6484e-04 - KL loss: 29.8935 - beta: 0.0016 - val_loss: 135.6219 - val_recon_loss: 2.6648e-04 - val_KL loss: 29.5357 - val_beta: 0.0016\n",
      "Epoch 4494/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 137.1824 - recon_loss: 2.6913e-04 - KL loss: 30.0414 - beta: 0.0016 - val_loss: 138.3704 - val_recon_loss: 2.7316e-04 - val_KL loss: 29.6249 - val_beta: 0.0016\n",
      "Epoch 4495/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 135.1135 - recon_loss: 2.6429e-04 - KL loss: 29.8987 - beta: 0.0016 - val_loss: 134.1904 - val_recon_loss: 2.6324e-04 - val_KL loss: 29.3944 - val_beta: 0.0016\n",
      "Epoch 4496/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 135.2489 - recon_loss: 2.6448e-04 - KL loss: 29.9567 - beta: 0.0016 - val_loss: 136.9269 - val_recon_loss: 2.7009e-04 - val_KL loss: 29.4002 - val_beta: 0.0016\n",
      "Epoch 4497/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 135.9066 - recon_loss: 2.6616e-04 - KL loss: 29.9460 - beta: 0.0016 - val_loss: 138.5351 - val_recon_loss: 2.7367e-04 - val_KL loss: 29.5841 - val_beta: 0.0016\n",
      "Epoch 4498/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 134.1481 - recon_loss: 2.6204e-04 - KL loss: 29.8283 - beta: 0.0016 - val_loss: 136.6487 - val_recon_loss: 2.6915e-04 - val_KL loss: 29.4983 - val_beta: 0.0016\n",
      "Epoch 4499/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 134.3346 - recon_loss: 2.6249e-04 - KL loss: 29.8363 - beta: 0.0016 - val_loss: 136.1456 - val_recon_loss: 2.6775e-04 - val_KL loss: 29.5538 - val_beta: 0.0016\n",
      "Epoch 4500/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 133.5712 - recon_loss: 2.6054e-04 - KL loss: 29.8482 - beta: 0.0016\n",
      "Epoch 04500: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 133.5720 - recon_loss: 2.6054e-04 - KL loss: 29.8483 - beta: 0.0016 - val_loss: 136.4238 - val_recon_loss: 2.6868e-04 - val_KL loss: 29.4619 - val_beta: 0.0016\n",
      "Epoch 4501/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 135.2231 - recon_loss: 2.6420e-04 - KL loss: 30.0424 - beta: 0.0016 - val_loss: 133.4908 - val_recon_loss: 2.6125e-04 - val_KL loss: 29.4843 - val_beta: 0.0016\n",
      "Epoch 4502/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 135.6769 - recon_loss: 2.6530e-04 - KL loss: 30.0598 - beta: 0.0016 - val_loss: 134.2952 - val_recon_loss: 2.6347e-04 - val_KL loss: 29.4075 - val_beta: 0.0016\n",
      "Epoch 4503/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 133.9706 - recon_loss: 2.6128e-04 - KL loss: 29.9537 - beta: 0.0016 - val_loss: 135.9326 - val_recon_loss: 2.6742e-04 - val_KL loss: 29.4697 - val_beta: 0.0016\n",
      "Epoch 4504/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 134.7666 - recon_loss: 2.6320e-04 - KL loss: 29.9861 - beta: 0.0016 - val_loss: 136.8529 - val_recon_loss: 2.6928e-04 - val_KL loss: 29.6494 - val_beta: 0.0016\n",
      "Epoch 4505/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 134.7263 - recon_loss: 2.6311e-04 - KL loss: 29.9792 - beta: 0.0016 - val_loss: 135.1844 - val_recon_loss: 2.6526e-04 - val_KL loss: 29.5808 - val_beta: 0.0016\n",
      "Epoch 4506/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 134.6938 - recon_loss: 2.6304e-04 - KL loss: 29.9761 - beta: 0.0016\n",
      "Epoch 04506: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 134.6936 - recon_loss: 2.6304e-04 - KL loss: 29.9760 - beta: 0.0016 - val_loss: 136.5538 - val_recon_loss: 2.6852e-04 - val_KL loss: 29.6526 - val_beta: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4507/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 133.5888 - recon_loss: 2.6029e-04 - KL loss: 29.9650 - beta: 0.0016 - val_loss: 137.5383 - val_recon_loss: 2.7105e-04 - val_KL loss: 29.6324 - val_beta: 0.0016\n",
      "Epoch 4508/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 133.0413 - recon_loss: 2.5895e-04 - KL loss: 29.9511 - beta: 0.0016 - val_loss: 137.0866 - val_recon_loss: 2.6964e-04 - val_KL loss: 29.7400 - val_beta: 0.0016\n",
      "Epoch 4509/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 133.9986 - recon_loss: 2.6146e-04 - KL loss: 29.9094 - beta: 0.0016 - val_loss: 134.1930 - val_recon_loss: 2.6278e-04 - val_KL loss: 29.5795 - val_beta: 0.0016\n",
      "Epoch 4510/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 134.1869 - recon_loss: 2.6179e-04 - KL loss: 29.9670 - beta: 0.0016 - val_loss: 136.8755 - val_recon_loss: 2.6953e-04 - val_KL loss: 29.5742 - val_beta: 0.0016\n",
      "Epoch 4511/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 133.3345 - recon_loss: 2.5976e-04 - KL loss: 29.9220 - beta: 0.0016 - val_loss: 132.5528 - val_recon_loss: 2.5885e-04 - val_KL loss: 29.5013 - val_beta: 0.0016\n",
      "Epoch 4512/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 134.2339 - recon_loss: 2.6202e-04 - KL loss: 29.9221 - beta: 0.0016 - val_loss: 135.7061 - val_recon_loss: 2.6685e-04 - val_KL loss: 29.4718 - val_beta: 0.0016\n",
      "Epoch 4513/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 134.1504 - recon_loss: 2.6183e-04 - KL loss: 29.9121 - beta: 0.0016 - val_loss: 135.3834 - val_recon_loss: 2.6598e-04 - val_KL loss: 29.4938 - val_beta: 0.0016\n",
      "Epoch 4514/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 133.6157 - recon_loss: 2.6040e-04 - KL loss: 29.9469 - beta: 0.0016 - val_loss: 133.0882 - val_recon_loss: 2.6010e-04 - val_KL loss: 29.5421 - val_beta: 0.0016\n",
      "Epoch 4515/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 133.2868 - recon_loss: 2.5958e-04 - KL loss: 29.9476 - beta: 0.0016 - val_loss: 137.0086 - val_recon_loss: 2.7008e-04 - val_KL loss: 29.4886 - val_beta: 0.0016\n",
      "Epoch 4516/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 134.4284 - recon_loss: 2.6266e-04 - KL loss: 29.8635 - beta: 0.0016\n",
      "Epoch 04516: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 134.4277 - recon_loss: 2.6265e-04 - KL loss: 29.8635 - beta: 0.0016 - val_loss: 133.9856 - val_recon_loss: 2.6262e-04 - val_KL loss: 29.4365 - val_beta: 0.0016\n",
      "Epoch 4517/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 132.5060 - recon_loss: 2.5790e-04 - KL loss: 29.8335 - beta: 0.0016 - val_loss: 134.5832 - val_recon_loss: 2.6408e-04 - val_KL loss: 29.4514 - val_beta: 0.0016\n",
      "Epoch 4518/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 133.6495 - recon_loss: 2.6073e-04 - KL loss: 29.8507 - beta: 0.0016 - val_loss: 133.9694 - val_recon_loss: 2.6252e-04 - val_KL loss: 29.4594 - val_beta: 0.0016\n",
      "Epoch 4519/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 133.4178 - recon_loss: 2.6010e-04 - KL loss: 29.8697 - beta: 0.0016 - val_loss: 133.5385 - val_recon_loss: 2.6144e-04 - val_KL loss: 29.4562 - val_beta: 0.0016\n",
      "Epoch 4520/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 133.6081 - recon_loss: 2.6066e-04 - KL loss: 29.8387 - beta: 0.0016 - val_loss: 134.0906 - val_recon_loss: 2.6273e-04 - val_KL loss: 29.4945 - val_beta: 0.0016\n",
      "Epoch 4521/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 132.7890 - recon_loss: 2.5850e-04 - KL loss: 29.8800 - beta: 0.0016\n",
      "Epoch 04521: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 132.7900 - recon_loss: 2.5850e-04 - KL loss: 29.8800 - beta: 0.0016 - val_loss: 134.3197 - val_recon_loss: 2.6328e-04 - val_KL loss: 29.5074 - val_beta: 0.0016\n",
      "Epoch 4521/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 343.5874 - recon_loss: 3.0899e-04 - KL loss: 34.5973 - beta: 0.0010 - val_loss: 342.5100 - val_recon_loss: 3.0744e-04 - val_KL loss: 35.0747 - val_beta: 0.0010\n",
      "Epoch 4522/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 320.8164 - recon_loss: 2.8525e-04 - KL loss: 35.5655 - beta: 0.0010 - val_loss: 331.7913 - val_recon_loss: 2.9652e-04 - val_KL loss: 35.2670 - val_beta: 0.0010\n",
      "Epoch 4523/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 333.5976 - recon_loss: 2.9744e-04 - KL loss: 36.1557 - beta: 0.0010 - val_loss: 398.7997 - val_recon_loss: 3.6031e-04 - val_KL loss: 38.4903 - val_beta: 0.0010\n",
      "Epoch 4524/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 381.4680 - recon_loss: 3.4391e-04 - KL loss: 37.5599 - beta: 0.0010 - val_loss: 347.2734 - val_recon_loss: 3.1074e-04 - val_KL loss: 36.5344 - val_beta: 0.0010\n",
      "Epoch 4525/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 349.9871 - recon_loss: 3.1316e-04 - KL loss: 36.8295 - beta: 0.0010 - val_loss: 413.5245 - val_recon_loss: 3.7744e-04 - val_KL loss: 36.0832 - val_beta: 0.0010\n",
      "Epoch 4526/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 358.7886 - recon_loss: 3.2221e-04 - KL loss: 36.5835 - beta: 0.0010 - val_loss: 361.3917 - val_recon_loss: 3.2477e-04 - val_KL loss: 36.6264 - val_beta: 0.0010\n",
      "Epoch 4527/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 314.1729 - recon_loss: 2.7784e-04 - KL loss: 36.3337 - beta: 0.0010\n",
      "Epoch 04527: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 314.1707 - recon_loss: 2.7784e-04 - KL loss: 36.3336 - beta: 0.0010 - val_loss: 369.8868 - val_recon_loss: 3.3333e-04 - val_KL loss: 36.5599 - val_beta: 0.0010\n",
      "Epoch 4528/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 295.8813 - recon_loss: 2.5955e-04 - KL loss: 36.3315 - beta: 0.0010 - val_loss: 319.5326 - val_recon_loss: 2.8312e-04 - val_KL loss: 36.4131 - val_beta: 0.0010\n",
      "Epoch 4529/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 298.2414 - recon_loss: 2.6182e-04 - KL loss: 36.4217 - beta: 0.0010 - val_loss: 330.8990 - val_recon_loss: 2.9314e-04 - val_KL loss: 37.7583 - val_beta: 0.0010\n",
      "Epoch 4530/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 295.3390 - recon_loss: 2.5849e-04 - KL loss: 36.8450 - beta: 0.0010 - val_loss: 330.5850 - val_recon_loss: 2.9331e-04 - val_KL loss: 37.2799 - val_beta: 0.0010\n",
      "Epoch 4531/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 298.9577 - recon_loss: 2.6217e-04 - KL loss: 36.7846 - beta: 0.0010 - val_loss: 328.4551 - val_recon_loss: 2.9134e-04 - val_KL loss: 37.1106 - val_beta: 0.0010\n",
      "Epoch 4532/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 296.8667 - recon_loss: 2.6036e-04 - KL loss: 36.5017 - beta: 0.0010 - val_loss: 316.2159 - val_recon_loss: 2.7950e-04 - val_KL loss: 36.7189 - val_beta: 0.0010\n",
      "Epoch 4533/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 293.5677 - recon_loss: 2.5678e-04 - KL loss: 36.7917 - beta: 0.0010 - val_loss: 309.6220 - val_recon_loss: 2.7275e-04 - val_KL loss: 36.8720 - val_beta: 0.0010\n",
      "Epoch 4534/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 303.0928 - recon_loss: 2.6574e-04 - KL loss: 37.3578 - beta: 0.0010 - val_loss: 317.8811 - val_recon_loss: 2.8059e-04 - val_KL loss: 37.2887 - val_beta: 0.0010\n",
      "Epoch 4535/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 293.8468 - recon_loss: 2.5736e-04 - KL loss: 36.4838 - beta: 0.0010 - val_loss: 303.7544 - val_recon_loss: 2.6671e-04 - val_KL loss: 37.0417 - val_beta: 0.0010\n",
      "Epoch 4536/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 292.2841 - recon_loss: 2.5538e-04 - KL loss: 36.9010 - beta: 0.0010 - val_loss: 306.2804 - val_recon_loss: 2.6923e-04 - val_KL loss: 37.0475 - val_beta: 0.0010\n",
      "Epoch 4537/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 58s 58ms/step - loss: 292.5692 - recon_loss: 2.5577e-04 - KL loss: 36.7978 - beta: 0.0010 - val_loss: 308.8798 - val_recon_loss: 2.7172e-04 - val_KL loss: 37.1591 - val_beta: 0.0010\n",
      "Epoch 4538/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 294.0912 - recon_loss: 2.5721e-04 - KL loss: 36.8795 - beta: 0.0010 - val_loss: 346.4140 - val_recon_loss: 3.0890e-04 - val_KL loss: 37.5126 - val_beta: 0.0010\n",
      "Epoch 4539/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 306.5018 - recon_loss: 2.6894e-04 - KL loss: 37.5652 - beta: 0.0010 - val_loss: 338.6946 - val_recon_loss: 3.0098e-04 - val_KL loss: 37.7149 - val_beta: 0.0010\n",
      "Epoch 4540/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 302.5660 - recon_loss: 2.6535e-04 - KL loss: 37.2150 - beta: 0.0010\n",
      "Epoch 04540: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 302.5695 - recon_loss: 2.6535e-04 - KL loss: 37.2150 - beta: 0.0010 - val_loss: 306.8212 - val_recon_loss: 2.6936e-04 - val_KL loss: 37.4627 - val_beta: 0.0010\n",
      "Epoch 4541/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 307.6497 - recon_loss: 2.7012e-04 - KL loss: 37.5317 - beta: 0.0010 - val_loss: 293.8717 - val_recon_loss: 2.5657e-04 - val_KL loss: 37.3060 - val_beta: 0.0010\n",
      "Epoch 4542/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 299.9890 - recon_loss: 2.6254e-04 - KL loss: 37.4474 - beta: 0.0010 - val_loss: 294.8099 - val_recon_loss: 2.5724e-04 - val_KL loss: 37.5679 - val_beta: 0.0010\n",
      "Epoch 4543/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 301.0659 - recon_loss: 2.6338e-04 - KL loss: 37.6842 - beta: 0.0010 - val_loss: 296.6302 - val_recon_loss: 2.5922e-04 - val_KL loss: 37.4066 - val_beta: 0.0010\n",
      "Epoch 4544/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 298.6851 - recon_loss: 2.6118e-04 - KL loss: 37.5101 - beta: 0.0010 - val_loss: 293.5190 - val_recon_loss: 2.5604e-04 - val_KL loss: 37.4758 - val_beta: 0.0010\n",
      "Epoch 4545/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 297.4964 - recon_loss: 2.5991e-04 - KL loss: 37.5867 - beta: 0.0010 - val_loss: 292.7970 - val_recon_loss: 2.5560e-04 - val_KL loss: 37.2011 - val_beta: 0.0010\n",
      "Epoch 4546/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 292.5091 - recon_loss: 2.5500e-04 - KL loss: 37.5068 - beta: 0.0010 - val_loss: 293.4177 - val_recon_loss: 2.5586e-04 - val_KL loss: 37.5548 - val_beta: 0.0010\n",
      "Epoch 4547/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 292.2539 - recon_loss: 2.5483e-04 - KL loss: 37.4266 - beta: 0.0010 - val_loss: 286.1479 - val_recon_loss: 2.4878e-04 - val_KL loss: 37.3716 - val_beta: 0.0010\n",
      "Epoch 4548/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 291.6712 - recon_loss: 2.5430e-04 - KL loss: 37.3712 - beta: 0.0010 - val_loss: 293.1722 - val_recon_loss: 2.5549e-04 - val_KL loss: 37.6825 - val_beta: 0.0010\n",
      "Epoch 4549/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 292.3918 - recon_loss: 2.5466e-04 - KL loss: 37.7275 - beta: 0.0010 - val_loss: 285.3760 - val_recon_loss: 2.4749e-04 - val_KL loss: 37.8908 - val_beta: 0.0010\n",
      "Epoch 4550/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 291.1775 - recon_loss: 2.5384e-04 - KL loss: 37.3332 - beta: 0.0010 - val_loss: 288.9717 - val_recon_loss: 2.5148e-04 - val_KL loss: 37.4943 - val_beta: 0.0010\n",
      "Epoch 4551/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 291.9670 - recon_loss: 2.5439e-04 - KL loss: 37.5773 - beta: 0.0010 - val_loss: 286.9336 - val_recon_loss: 2.4944e-04 - val_KL loss: 37.4956 - val_beta: 0.0010\n",
      "Epoch 4552/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 288.5791 - recon_loss: 2.5132e-04 - KL loss: 37.2631 - beta: 0.0010 - val_loss: 289.5778 - val_recon_loss: 2.5174e-04 - val_KL loss: 37.8414 - val_beta: 0.0010\n",
      "Epoch 4553/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 287.6242 - recon_loss: 2.5031e-04 - KL loss: 37.3170 - beta: 0.0010 - val_loss: 285.0747 - val_recon_loss: 2.4789e-04 - val_KL loss: 37.1817 - val_beta: 0.0010\n",
      "Epoch 4554/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 285.8713 - recon_loss: 2.4882e-04 - KL loss: 37.0538 - beta: 0.0010 - val_loss: 286.3295 - val_recon_loss: 2.4905e-04 - val_KL loss: 37.2817 - val_beta: 0.0010\n",
      "Epoch 4555/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 285.4064 - recon_loss: 2.4806e-04 - KL loss: 37.3430 - beta: 0.0010 - val_loss: 283.8682 - val_recon_loss: 2.4681e-04 - val_KL loss: 37.0538 - val_beta: 0.0010\n",
      "Epoch 4556/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 285.1522 - recon_loss: 2.4797e-04 - KL loss: 37.1825 - beta: 0.0010 - val_loss: 282.5598 - val_recon_loss: 2.4475e-04 - val_KL loss: 37.8139 - val_beta: 0.0010\n",
      "Epoch 4557/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 284.0485 - recon_loss: 2.4698e-04 - KL loss: 37.0686 - beta: 0.0010 - val_loss: 284.0652 - val_recon_loss: 2.4662e-04 - val_KL loss: 37.4480 - val_beta: 0.0010\n",
      "Epoch 4558/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 283.2801 - recon_loss: 2.4623e-04 - KL loss: 37.0519 - beta: 0.0010 - val_loss: 283.3168 - val_recon_loss: 2.4555e-04 - val_KL loss: 37.7622 - val_beta: 0.0010\n",
      "Epoch 4559/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 282.4121 - recon_loss: 2.4529e-04 - KL loss: 37.1239 - beta: 0.0010 - val_loss: 279.5904 - val_recon_loss: 2.4266e-04 - val_KL loss: 36.9287 - val_beta: 0.0010\n",
      "Epoch 4560/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 281.4460 - recon_loss: 2.4445e-04 - KL loss: 36.9977 - beta: 0.0010 - val_loss: 279.5634 - val_recon_loss: 2.4234e-04 - val_KL loss: 37.2187 - val_beta: 0.0010\n",
      "Epoch 4561/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 282.8656 - recon_loss: 2.4582e-04 - KL loss: 37.0449 - beta: 0.0010 - val_loss: 282.2560 - val_recon_loss: 2.4488e-04 - val_KL loss: 37.3765 - val_beta: 0.0010\n",
      "Epoch 4562/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 281.4323 - recon_loss: 2.4435e-04 - KL loss: 37.0813 - beta: 0.0010 - val_loss: 282.6140 - val_recon_loss: 2.4524e-04 - val_KL loss: 37.3747 - val_beta: 0.0010\n",
      "Epoch 4563/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 280.3755 - recon_loss: 2.4320e-04 - KL loss: 37.1743 - beta: 0.0010 - val_loss: 285.5668 - val_recon_loss: 2.4841e-04 - val_KL loss: 37.1535 - val_beta: 0.0010\n",
      "Epoch 4564/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 281.1150 - recon_loss: 2.4359e-04 - KL loss: 37.5288 - beta: 0.0010 - val_loss: 297.8900 - val_recon_loss: 2.6052e-04 - val_KL loss: 37.3652 - val_beta: 0.0010\n",
      "Epoch 4565/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 282.0046 - recon_loss: 2.4511e-04 - KL loss: 36.8911 - beta: 0.0010\n",
      "Epoch 04565: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 282.0043 - recon_loss: 2.4511e-04 - KL loss: 36.8910 - beta: 0.0010 - val_loss: 280.1847 - val_recon_loss: 2.4290e-04 - val_KL loss: 37.2868 - val_beta: 0.0010\n",
      "Epoch 4566/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 282.3578 - recon_loss: 2.4549e-04 - KL loss: 36.8690 - beta: 0.0010 - val_loss: 287.6887 - val_recon_loss: 2.5019e-04 - val_KL loss: 37.4939 - val_beta: 0.0010\n",
      "Epoch 4567/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 278.5427 - recon_loss: 2.4147e-04 - KL loss: 37.0765 - beta: 0.0010 - val_loss: 284.8465 - val_recon_loss: 2.4744e-04 - val_KL loss: 37.4033 - val_beta: 0.0010\n",
      "Epoch 4568/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 280.7340 - recon_loss: 2.4366e-04 - KL loss: 37.0772 - beta: 0.0010 - val_loss: 285.2522 - val_recon_loss: 2.4749e-04 - val_KL loss: 37.7664 - val_beta: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4569/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 277.7595 - recon_loss: 2.4073e-04 - KL loss: 37.0324 - beta: 0.0010 - val_loss: 286.6957 - val_recon_loss: 2.4908e-04 - val_KL loss: 37.6123 - val_beta: 0.0010\n",
      "Epoch 4570/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 279.5449 - recon_loss: 2.4240e-04 - KL loss: 37.1487 - beta: 0.0010\n",
      "Epoch 04570: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 279.5451 - recon_loss: 2.4240e-04 - KL loss: 37.1487 - beta: 0.0010 - val_loss: 281.0164 - val_recon_loss: 2.4336e-04 - val_KL loss: 37.6582 - val_beta: 0.0010\n",
      "Epoch 4570/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 831.2062 - recon_loss: 3.1367e-04 - KL loss: 43.2917 - beta: 6.3096e-04 - val_loss: 808.8658 - val_recon_loss: 3.0509e-04 - val_KL loss: 42.5143 - val_beta: 6.3096e-04\n",
      "Epoch 4571/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 716.1721 - recon_loss: 2.6825e-04 - KL loss: 42.3692 - beta: 6.3096e-04 - val_loss: 734.8423 - val_recon_loss: 2.7512e-04 - val_KL loss: 43.7629 - val_beta: 6.3096e-04\n",
      "Epoch 4572/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 744.4008 - recon_loss: 2.7890e-04 - KL loss: 43.8395 - beta: 6.3096e-04 - val_loss: 802.9728 - val_recon_loss: 3.0273e-04 - val_KL loss: 42.5484 - val_beta: 6.3096e-04\n",
      "Epoch 4573/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 733.9969 - recon_loss: 2.7485e-04 - KL loss: 43.6031 - beta: 6.3096e-04 - val_loss: 864.0734 - val_recon_loss: 3.2503e-04 - val_KL loss: 47.6264 - val_beta: 6.3096e-04\n",
      "Epoch 4574/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 761.9434 - recon_loss: 2.8590e-04 - KL loss: 43.7858 - beta: 6.3096e-04 - val_loss: 733.6583 - val_recon_loss: 2.7527e-04 - val_KL loss: 42.2226 - val_beta: 6.3096e-04\n",
      "Epoch 4575/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 721.2848 - recon_loss: 2.6979e-04 - KL loss: 43.5932 - beta: 6.3096e-04 - val_loss: 796.5029 - val_recon_loss: 2.9952e-04 - val_KL loss: 44.1387 - val_beta: 6.3096e-04\n",
      "Epoch 4576/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 713.6035 - recon_loss: 2.6702e-04 - KL loss: 42.8805 - beta: 6.3096e-04 - val_loss: 773.5306 - val_recon_loss: 2.9046e-04 - val_KL loss: 43.9391 - val_beta: 6.3096e-04\n",
      "Epoch 4577/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 687.9400 - recon_loss: 2.5669e-04 - KL loss: 43.1584 - beta: 6.3096e-04 - val_loss: 786.7645 - val_recon_loss: 2.9608e-04 - val_KL loss: 43.0460 - val_beta: 6.3096e-04\n",
      "Epoch 4578/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 684.1811 - recon_loss: 2.5523e-04 - KL loss: 43.0761 - beta: 6.3096e-04 - val_loss: 733.3633 - val_recon_loss: 2.7482e-04 - val_KL loss: 43.0362 - val_beta: 6.3096e-04\n",
      "Epoch 4579/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 678.3692 - recon_loss: 2.5309e-04 - KL loss: 42.6313 - beta: 6.3096e-04 - val_loss: 792.3566 - val_recon_loss: 2.9780e-04 - val_KL loss: 44.3163 - val_beta: 6.3096e-04\n",
      "Epoch 4580/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 701.0874 - recon_loss: 2.6196e-04 - KL loss: 43.0621 - beta: 6.3096e-04 - val_loss: 738.1509 - val_recon_loss: 2.7676e-04 - val_KL loss: 42.9583 - val_beta: 6.3096e-04\n",
      "Epoch 4581/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 679.0922 - recon_loss: 2.5315e-04 - KL loss: 43.2097 - beta: 6.3096e-04 - val_loss: 716.0807 - val_recon_loss: 2.6778e-04 - val_KL loss: 43.4403 - val_beta: 6.3096e-04\n",
      "Epoch 4582/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 673.6968 - recon_loss: 2.5109e-04 - KL loss: 42.9886 - beta: 6.3096e-04 - val_loss: 709.3704 - val_recon_loss: 2.6510e-04 - val_KL loss: 43.4763 - val_beta: 6.3096e-04\n",
      "Epoch 4583/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 667.8603 - recon_loss: 2.4877e-04 - KL loss: 42.9874 - beta: 6.3096e-04 - val_loss: 868.1600 - val_recon_loss: 3.2872e-04 - val_KL loss: 42.4480 - val_beta: 6.3096e-04\n",
      "Epoch 4584/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 685.3196 - recon_loss: 2.5556e-04 - KL loss: 43.3870 - beta: 6.3096e-04 - val_loss: 700.1845 - val_recon_loss: 2.6163e-04 - val_KL loss: 42.9981 - val_beta: 6.3096e-04\n",
      "Epoch 4585/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 699.7789 - recon_loss: 2.6130e-04 - KL loss: 43.4344 - beta: 6.3096e-04 - val_loss: 842.4351 - val_recon_loss: 3.1784e-04 - val_KL loss: 44.0450 - val_beta: 6.3096e-04\n",
      "Epoch 4586/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 686.9951 - recon_loss: 2.5614e-04 - KL loss: 43.6026 - beta: 6.3096e-04 - val_loss: 828.9167 - val_recon_loss: 3.1261e-04 - val_KL loss: 43.6676 - val_beta: 6.3096e-04\n",
      "Epoch 4587/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 701.4286 - recon_loss: 2.6167e-04 - KL loss: 44.1512 - beta: 6.3096e-04 - val_loss: 759.4225 - val_recon_loss: 2.8525e-04 - val_KL loss: 42.8951 - val_beta: 6.3096e-04\n",
      "Epoch 4588/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 681.0416 - recon_loss: 2.5373e-04 - KL loss: 43.7053 - beta: 6.3096e-04 - val_loss: 753.2673 - val_recon_loss: 2.8268e-04 - val_KL loss: 43.1989 - val_beta: 6.3096e-04\n",
      "Epoch 4589/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 679.1667 - recon_loss: 2.5300e-04 - KL loss: 43.6540 - beta: 6.3096e-04\n",
      "Epoch 04589: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 679.1489 - recon_loss: 2.5300e-04 - KL loss: 43.6537 - beta: 6.3096e-04 - val_loss: 708.5037 - val_recon_loss: 2.6451e-04 - val_KL loss: 44.0806 - val_beta: 6.3096e-04\n",
      "Epoch 4590/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 629.4947 - recon_loss: 2.3323e-04 - KL loss: 43.6485 - beta: 6.3096e-04 - val_loss: 683.8098 - val_recon_loss: 2.5445e-04 - val_KL loss: 44.6715 - val_beta: 6.3096e-04\n",
      "Epoch 4591/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 635.9528 - recon_loss: 2.3564e-04 - KL loss: 44.0500 - beta: 6.3096e-04 - val_loss: 685.4401 - val_recon_loss: 2.5572e-04 - val_KL loss: 43.1032 - val_beta: 6.3096e-04\n",
      "Epoch 4592/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 634.0774 - recon_loss: 2.3496e-04 - KL loss: 43.8784 - beta: 6.3096e-04 - val_loss: 658.9092 - val_recon_loss: 2.4487e-04 - val_KL loss: 43.8306 - val_beta: 6.3096e-04\n",
      "Epoch 4593/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 631.3509 - recon_loss: 2.3390e-04 - KL loss: 43.8184 - beta: 6.3096e-04 - val_loss: 674.3582 - val_recon_loss: 2.5115e-04 - val_KL loss: 43.5041 - val_beta: 6.3096e-04\n",
      "Epoch 4594/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 620.7542 - recon_loss: 2.2977e-04 - KL loss: 43.6034 - beta: 6.3096e-04 - val_loss: 710.1981 - val_recon_loss: 2.6528e-04 - val_KL loss: 43.8498 - val_beta: 6.3096e-04\n",
      "Epoch 4595/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 623.0743 - recon_loss: 2.3056e-04 - KL loss: 43.9439 - beta: 6.3096e-04 - val_loss: 703.6440 - val_recon_loss: 2.6278e-04 - val_KL loss: 43.5640 - val_beta: 6.3096e-04\n",
      "Epoch 4596/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 633.5406 - recon_loss: 2.3461e-04 - KL loss: 44.2293 - beta: 6.3096e-04 - val_loss: 666.9838 - val_recon_loss: 2.4838e-04 - val_KL loss: 43.0916 - val_beta: 6.3096e-04\n",
      "Epoch 4597/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 634.1714 - recon_loss: 2.3527e-04 - KL loss: 43.2024 - beta: 6.3096e-04\n",
      "Epoch 04597: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 634.1655 - recon_loss: 2.3527e-04 - KL loss: 43.2024 - beta: 6.3096e-04 - val_loss: 699.8068 - val_recon_loss: 2.6136e-04 - val_KL loss: 43.3030 - val_beta: 6.3096e-04\n",
      "Epoch 4598/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 606.3693 - recon_loss: 2.2407e-04 - KL loss: 43.5280 - beta: 6.3096e-04 - val_loss: 689.7249 - val_recon_loss: 2.5728e-04 - val_KL loss: 43.4701 - val_beta: 6.3096e-04\n",
      "Epoch 4599/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 607.3523 - recon_loss: 2.2435e-04 - KL loss: 43.8078 - beta: 6.3096e-04 - val_loss: 678.9301 - val_recon_loss: 2.5261e-04 - val_KL loss: 44.3907 - val_beta: 6.3096e-04\n",
      "Epoch 4600/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 607.1370 - recon_loss: 2.2417e-04 - KL loss: 44.0558 - beta: 6.3096e-04 - val_loss: 689.2209 - val_recon_loss: 2.5684e-04 - val_KL loss: 44.0756 - val_beta: 6.3096e-04\n",
      "Epoch 4601/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 612.3579 - recon_loss: 2.2638e-04 - KL loss: 43.7214 - beta: 6.3096e-04 - val_loss: 685.1071 - val_recon_loss: 2.5508e-04 - val_KL loss: 44.3692 - val_beta: 6.3096e-04\n",
      "Epoch 4602/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 606.5436 - recon_loss: 2.2399e-04 - KL loss: 43.9028 - beta: 6.3096e-04\n",
      "Epoch 04602: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 606.5397 - recon_loss: 2.2399e-04 - KL loss: 43.9029 - beta: 6.3096e-04 - val_loss: 703.6068 - val_recon_loss: 2.6252e-04 - val_KL loss: 44.1883 - val_beta: 6.3096e-04\n",
      "Epoch 4602/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1831.5317 - recon_loss: 2.8218e-04 - KL loss: 51.0673 - beta: 3.9811e-04 - val_loss: 1801.9648 - val_recon_loss: 2.7743e-04 - val_KL loss: 51.5131 - val_beta: 3.9811e-04\n",
      "Epoch 4603/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1573.4589 - recon_loss: 2.4121e-04 - KL loss: 51.5128 - beta: 3.9811e-04 - val_loss: 1773.3729 - val_recon_loss: 2.7281e-04 - val_KL loss: 52.0569 - val_beta: 3.9811e-04\n",
      "Epoch 4604/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1562.6473 - recon_loss: 2.3946e-04 - KL loss: 51.7295 - beta: 3.9811e-04 - val_loss: 2058.9561 - val_recon_loss: 3.1848e-04 - val_KL loss: 49.4907 - val_beta: 3.9811e-04\n",
      "Epoch 4605/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1627.3828 - recon_loss: 2.4974e-04 - KL loss: 51.6464 - beta: 3.9811e-04 - val_loss: 2501.5891 - val_recon_loss: 3.8725e-04 - val_KL loss: 58.1844 - val_beta: 3.9811e-04\n",
      "Epoch 4606/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1698.3455 - recon_loss: 2.6058e-04 - KL loss: 54.1730 - beta: 3.9811e-04 - val_loss: 1836.7638 - val_recon_loss: 2.8232e-04 - val_KL loss: 55.4395 - val_beta: 3.9811e-04\n",
      "Epoch 4607/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1759.7926 - recon_loss: 2.7018e-04 - KL loss: 55.0971 - beta: 3.9811e-04 - val_loss: 1694.9500 - val_recon_loss: 2.6006e-04 - val_KL loss: 54.0690 - val_beta: 3.9811e-04\n",
      "Epoch 4608/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1642.0748 - recon_loss: 2.5172e-04 - KL loss: 53.8365 - beta: 3.9811e-04 - val_loss: 1906.2759 - val_recon_loss: 2.9378e-04 - val_KL loss: 52.6761 - val_beta: 3.9811e-04\n",
      "Epoch 4609/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1651.6389 - recon_loss: 2.5325e-04 - KL loss: 53.7330 - beta: 3.9811e-04 - val_loss: 1724.3549 - val_recon_loss: 2.6459e-04 - val_KL loss: 54.9303 - val_beta: 3.9811e-04\n",
      "Epoch 4610/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1573.2076 - recon_loss: 2.4097e-04 - KL loss: 52.7870 - beta: 3.9811e-04 - val_loss: 1598.5461 - val_recon_loss: 2.4504e-04 - val_KL loss: 52.4672 - val_beta: 3.9811e-04\n",
      "Epoch 4611/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1521.2743 - recon_loss: 2.3279e-04 - KL loss: 52.4560 - beta: 3.9811e-04 - val_loss: 1646.6458 - val_recon_loss: 2.5252e-04 - val_KL loss: 53.3440 - val_beta: 3.9811e-04\n",
      "Epoch 4612/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1547.8836 - recon_loss: 2.3688e-04 - KL loss: 53.2509 - beta: 3.9811e-04 - val_loss: 1675.0140 - val_recon_loss: 2.5654e-04 - val_KL loss: 56.3726 - val_beta: 3.9811e-04\n",
      "Epoch 4613/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1646.7174 - recon_loss: 2.5232e-04 - KL loss: 54.6894 - beta: 3.9811e-04 - val_loss: 1786.8820 - val_recon_loss: 2.7443e-04 - val_KL loss: 55.3167 - val_beta: 3.9811e-04\n",
      "Epoch 4614/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1585.0427 - recon_loss: 2.4254e-04 - KL loss: 54.6973 - beta: 3.9811e-04 - val_loss: 1667.7483 - val_recon_loss: 2.5598e-04 - val_KL loss: 52.6149 - val_beta: 3.9811e-04\n",
      "Epoch 4615/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1554.3058 - recon_loss: 2.3769e-04 - KL loss: 54.5705 - beta: 3.9811e-04\n",
      "Epoch 04615: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1554.3199 - recon_loss: 2.3769e-04 - KL loss: 54.5712 - beta: 3.9811e-04 - val_loss: 1700.9229 - val_recon_loss: 2.6114e-04 - val_KL loss: 53.2531 - val_beta: 3.9811e-04\n",
      "Epoch 4616/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1518.5603 - recon_loss: 2.3204e-04 - KL loss: 54.4812 - beta: 3.9811e-04 - val_loss: 1638.2828 - val_recon_loss: 2.5089e-04 - val_KL loss: 55.3002 - val_beta: 3.9811e-04\n",
      "Epoch 4617/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1489.4564 - recon_loss: 2.2735e-04 - KL loss: 54.9916 - beta: 3.9811e-04 - val_loss: 1819.2124 - val_recon_loss: 2.7950e-04 - val_KL loss: 55.6598 - val_beta: 3.9811e-04\n",
      "Epoch 4618/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1530.0680 - recon_loss: 2.3374e-04 - KL loss: 55.2546 - beta: 3.9811e-04 - val_loss: 1706.6316 - val_recon_loss: 2.6180e-04 - val_KL loss: 54.8037 - val_beta: 3.9811e-04\n",
      "Epoch 4619/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1510.2547 - recon_loss: 2.3064e-04 - KL loss: 55.0286 - beta: 3.9811e-04 - val_loss: 1948.1520 - val_recon_loss: 3.0005e-04 - val_KL loss: 54.9840 - val_beta: 3.9811e-04\n",
      "Epoch 4620/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1558.5262 - recon_loss: 2.3810e-04 - KL loss: 56.1876 - beta: 3.9811e-04\n",
      "Epoch 04620: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1558.5333 - recon_loss: 2.3811e-04 - KL loss: 56.1874 - beta: 3.9811e-04 - val_loss: 1650.9186 - val_recon_loss: 2.5332e-04 - val_KL loss: 52.6004 - val_beta: 3.9811e-04\n",
      "Epoch 4620/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4405.8057 - recon_loss: 2.7397e-04 - KL loss: 63.6631 - beta: 2.5119e-04 - val_loss: 4200.5732 - val_recon_loss: 2.6079e-04 - val_KL loss: 67.3613 - val_beta: 2.5119e-04\n",
      "Epoch 4621/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4006.4327 - recon_loss: 2.4842e-04 - KL loss: 69.2193 - beta: 2.5119e-04 - val_loss: 4236.1846 - val_recon_loss: 2.6303e-04 - val_KL loss: 67.4727 - val_beta: 2.5119e-04\n",
      "Epoch 4622/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3815.0713 - recon_loss: 2.3643e-04 - KL loss: 67.9654 - beta: 2.5119e-04 - val_loss: 4279.8042 - val_recon_loss: 2.6560e-04 - val_KL loss: 70.3005 - val_beta: 2.5119e-04\n",
      "Epoch 4623/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3860.9559 - recon_loss: 2.3927e-04 - KL loss: 68.8287 - beta: 2.5119e-04 - val_loss: 4149.5884 - val_recon_loss: 2.5750e-04 - val_KL loss: 68.4872 - val_beta: 2.5119e-04\n",
      "Epoch 4624/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3830.9673 - recon_loss: 2.3740e-04 - KL loss: 68.4201 - beta: 2.5119e-04 - val_loss: 3948.6462 - val_recon_loss: 2.4470e-04 - val_KL loss: 70.4748 - val_beta: 2.5119e-04\n",
      "Epoch 4625/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4100.3552 - recon_loss: 2.5420e-04 - KL loss: 71.6341 - beta: 2.5119e-04 - val_loss: 4209.0762 - val_recon_loss: 2.6104e-04 - val_KL loss: 71.8000 - val_beta: 2.5119e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4626/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3924.8006 - recon_loss: 2.4310e-04 - KL loss: 71.9169 - beta: 2.5119e-04 - val_loss: 4506.8193 - val_recon_loss: 2.7951e-04 - val_KL loss: 76.9281 - val_beta: 2.5119e-04\n",
      "Epoch 4627/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3938.9025 - recon_loss: 2.4397e-04 - KL loss: 72.2200 - beta: 2.5119e-04 - val_loss: 3973.8518 - val_recon_loss: 2.4637e-04 - val_KL loss: 69.2040 - val_beta: 2.5119e-04\n",
      "Epoch 4628/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3751.2145 - recon_loss: 2.3233e-04 - KL loss: 69.0227 - beta: 2.5119e-04 - val_loss: 3921.2520 - val_recon_loss: 2.4303e-04 - val_KL loss: 69.4430 - val_beta: 2.5119e-04\n",
      "Epoch 4629/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3745.5072 - recon_loss: 2.3191e-04 - KL loss: 70.0450 - beta: 2.5119e-04 - val_loss: 4882.8853 - val_recon_loss: 3.0310e-04 - val_KL loss: 79.1189 - val_beta: 2.5119e-04\n",
      "Epoch 4630/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4008.5244 - recon_loss: 2.4816e-04 - KL loss: 75.5228 - beta: 2.5119e-04 - val_loss: 4304.9873 - val_recon_loss: 2.6697e-04 - val_KL loss: 73.8066 - val_beta: 2.5119e-04\n",
      "Epoch 4631/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3928.0977 - recon_loss: 2.4310e-04 - KL loss: 75.1813 - beta: 2.5119e-04 - val_loss: 4835.7861 - val_recon_loss: 2.9989e-04 - val_KL loss: 82.8014 - val_beta: 2.5119e-04\n",
      "Epoch 4632/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4148.7334 - recon_loss: 2.5682e-04 - KL loss: 78.4345 - beta: 2.5119e-04 - val_loss: 4108.0820 - val_recon_loss: 2.5454e-04 - val_KL loss: 73.8465 - val_beta: 2.5119e-04\n",
      "Epoch 4633/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3752.9671 - recon_loss: 2.3216e-04 - KL loss: 73.4262 - beta: 2.5119e-04\n",
      "Epoch 04633: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3753.1049 - recon_loss: 2.3217e-04 - KL loss: 73.4272 - beta: 2.5119e-04 - val_loss: 4596.8838 - val_recon_loss: 2.8493e-04 - val_KL loss: 81.0827 - val_beta: 2.5119e-04\n",
      "Epoch 4634/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3853.9943 - recon_loss: 2.3817e-04 - KL loss: 79.3060 - beta: 2.5119e-04 - val_loss: 4398.7031 - val_recon_loss: 2.7271e-04 - val_KL loss: 76.6191 - val_beta: 2.5119e-04\n",
      "Epoch 4635/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3672.9402 - recon_loss: 2.2701e-04 - KL loss: 75.0847 - beta: 2.5119e-04 - val_loss: 4243.8330 - val_recon_loss: 2.6275e-04 - val_KL loss: 79.5362 - val_beta: 2.5119e-04\n",
      "Epoch 4636/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3641.1399 - recon_loss: 2.2493e-04 - KL loss: 76.2560 - beta: 2.5119e-04 - val_loss: 4556.4785 - val_recon_loss: 2.8245e-04 - val_KL loss: 79.9708 - val_beta: 2.5119e-04\n",
      "Epoch 4637/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3649.1838 - recon_loss: 2.2547e-04 - KL loss: 75.8027 - beta: 2.5119e-04 - val_loss: 4419.2241 - val_recon_loss: 2.7363e-04 - val_KL loss: 82.5322 - val_beta: 2.5119e-04\n",
      "Epoch 4638/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 3682.0261 - recon_loss: 2.2758e-04 - KL loss: 75.0987 - beta: 2.5119e-04\n",
      "Epoch 04638: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3681.9982 - recon_loss: 2.2758e-04 - KL loss: 75.0975 - beta: 2.5119e-04 - val_loss: 4427.3340 - val_recon_loss: 2.7419e-04 - val_KL loss: 81.7107 - val_beta: 2.5119e-04\n",
      "Epoch 4638/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 10014.3611 - recon_loss: 2.4935e-04 - KL loss: 87.6110 - beta: 1.5849e-04 - val_loss: 11963.9951 - val_recon_loss: 2.9790e-04 - val_KL loss: 104.2311 - val_beta: 1.5849e-04\n",
      "Epoch 4639/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 9677.2406 - recon_loss: 2.4045e-04 - KL loss: 104.7112 - beta: 1.5849e-04 - val_loss: 11919.4590 - val_recon_loss: 2.9699e-04 - val_KL loss: 95.9435 - val_beta: 1.5849e-04\n",
      "Epoch 4640/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 9280.5447 - recon_loss: 2.3061e-04 - KL loss: 99.6061 - beta: 1.5849e-04 - val_loss: 12826.3809 - val_recon_loss: 3.1961e-04 - val_KL loss: 102.5094 - val_beta: 1.5849e-04\n",
      "Epoch 4641/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10843.4344 - recon_loss: 2.6975e-04 - KL loss: 104.6748 - beta: 1.5849e-04 - val_loss: 10553.1270 - val_recon_loss: 2.6229e-04 - val_KL loss: 111.3585 - val_beta: 1.5849e-04\n",
      "Epoch 4642/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10028.0875 - recon_loss: 2.4922e-04 - KL loss: 106.4439 - beta: 1.5849e-04 - val_loss: 10208.7266 - val_recon_loss: 2.5352e-04 - val_KL loss: 115.7311 - val_beta: 1.5849e-04\n",
      "Epoch 4643/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 10352.5534 - recon_loss: 2.5726e-04 - KL loss: 110.7669 - beta: 1.5849e-04 - val_loss: 9653.7188 - val_recon_loss: 2.3964e-04 - val_KL loss: 113.5043 - val_beta: 1.5849e-04\n",
      "Epoch 4644/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9855.2342 - recon_loss: 2.4473e-04 - KL loss: 112.5419 - beta: 1.5849e-04 - val_loss: 10784.8232 - val_recon_loss: 2.6800e-04 - val_KL loss: 115.7117 - val_beta: 1.5849e-04\n",
      "Epoch 4645/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 9764.5697 - recon_loss: 2.4244e-04 - KL loss: 112.9423 - beta: 1.5849e-04 - val_loss: 11247.7178 - val_recon_loss: 2.7970e-04 - val_KL loss: 112.6873 - val_beta: 1.5849e-04\n",
      "Epoch 4646/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 9390.1576 - recon_loss: 2.3313e-04 - KL loss: 108.9006 - beta: 1.5849e-04 - val_loss: 10192.1904 - val_recon_loss: 2.5319e-04 - val_KL loss: 112.7039 - val_beta: 1.5849e-04\n",
      "Epoch 4647/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 9170.1608 - recon_loss: 2.2757e-04 - KL loss: 110.4705 - beta: 1.5849e-04 - val_loss: 10665.1084 - val_recon_loss: 2.6498e-04 - val_KL loss: 115.9336 - val_beta: 1.5849e-04\n",
      "Epoch 4648/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9793.5811 - recon_loss: 2.4312e-04 - KL loss: 114.6824 - beta: 1.5849e-04\n",
      "Epoch 04648: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9793.6872 - recon_loss: 2.4313e-04 - KL loss: 114.6831 - beta: 1.5849e-04 - val_loss: 10501.9619 - val_recon_loss: 2.6093e-04 - val_KL loss: 114.0245 - val_beta: 1.5849e-04\n",
      "Epoch 4649/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 8964.7162 - recon_loss: 2.2237e-04 - KL loss: 112.0263 - beta: 1.5849e-04 - val_loss: 10515.7881 - val_recon_loss: 2.6124e-04 - val_KL loss: 115.5854 - val_beta: 1.5849e-04\n",
      "Epoch 4650/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 8716.6699 - recon_loss: 2.1614e-04 - KL loss: 112.1478 - beta: 1.5849e-04 - val_loss: 9860.7119 - val_recon_loss: 2.4485e-04 - val_KL loss: 113.1657 - val_beta: 1.5849e-04\n",
      "Epoch 4651/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 8606.2970 - recon_loss: 2.1340e-04 - KL loss: 110.5796 - beta: 1.5849e-04 - val_loss: 10173.8672 - val_recon_loss: 2.5270e-04 - val_KL loss: 113.7299 - val_beta: 1.5849e-04\n",
      "Epoch 4652/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 8733.6584 - recon_loss: 2.1657e-04 - KL loss: 111.8440 - beta: 1.5849e-04 - val_loss: 10224.6602 - val_recon_loss: 2.5399e-04 - val_KL loss: 112.9845 - val_beta: 1.5849e-04\n",
      "Epoch 4653/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8512.6034 - recon_loss: 2.1107e-04 - KL loss: 109.5725 - beta: 1.5849e-04\n",
      "Epoch 04653: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 8512.6286 - recon_loss: 2.1108e-04 - KL loss: 109.5724 - beta: 1.5849e-04 - val_loss: 10909.6377 - val_recon_loss: 2.7125e-04 - val_KL loss: 111.0662 - val_beta: 1.5849e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4653/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 24701.3364 - recon_loss: 2.4571e-04 - KL loss: 130.6341 - beta: 1.0000e-04 - val_loss: 30401.8594 - val_recon_loss: 3.0244e-04 - val_KL loss: 157.5731 - val_beta: 1.0000e-04\n",
      "Epoch 4654/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 24494.1806 - recon_loss: 2.4335e-04 - KL loss: 159.1488 - beta: 1.0000e-04 - val_loss: 25696.8613 - val_recon_loss: 2.5545e-04 - val_KL loss: 151.3886 - val_beta: 1.0000e-04\n",
      "Epoch 4655/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 22764.8708 - recon_loss: 2.2610e-04 - KL loss: 155.1443 - beta: 1.0000e-04 - val_loss: 25211.3594 - val_recon_loss: 2.5049e-04 - val_KL loss: 162.0933 - val_beta: 1.0000e-04\n",
      "Epoch 4656/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23754.8724 - recon_loss: 2.3591e-04 - KL loss: 163.8965 - beta: 1.0000e-04 - val_loss: 25973.4922 - val_recon_loss: 2.5807e-04 - val_KL loss: 166.9452 - val_beta: 1.0000e-04\n",
      "Epoch 4657/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 22853.5814 - recon_loss: 2.2689e-04 - KL loss: 164.5290 - beta: 1.0000e-04 - val_loss: 27075.3418 - val_recon_loss: 2.6912e-04 - val_KL loss: 163.3197 - val_beta: 1.0000e-04\n",
      "Epoch 4658/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 22138.0837 - recon_loss: 2.1975e-04 - KL loss: 162.6940 - beta: 1.0000e-04 - val_loss: 26862.7598 - val_recon_loss: 2.6684e-04 - val_KL loss: 178.6137 - val_beta: 1.0000e-04\n",
      "Epoch 4659/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 23893.7143 - recon_loss: 2.3720e-04 - KL loss: 173.4292 - beta: 1.0000e-04 - val_loss: 28713.1895 - val_recon_loss: 2.8541e-04 - val_KL loss: 172.3023 - val_beta: 1.0000e-04\n",
      "Epoch 4660/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 25141.8430 - recon_loss: 2.4970e-04 - KL loss: 171.4009 - beta: 1.0000e-04\n",
      "Epoch 04660: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 25140.4431 - recon_loss: 2.4969e-04 - KL loss: 171.3973 - beta: 1.0000e-04 - val_loss: 25497.9590 - val_recon_loss: 2.5331e-04 - val_KL loss: 166.6307 - val_beta: 1.0000e-04\n",
      "Epoch 4661/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 21622.6617 - recon_loss: 2.1452e-04 - KL loss: 170.8376 - beta: 1.0000e-04 - val_loss: 25036.5586 - val_recon_loss: 2.4867e-04 - val_KL loss: 170.0378 - val_beta: 1.0000e-04\n",
      "Epoch 4662/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21337.4424 - recon_loss: 2.1164e-04 - KL loss: 173.8835 - beta: 1.0000e-04 - val_loss: 24525.2246 - val_recon_loss: 2.4352e-04 - val_KL loss: 172.8813 - val_beta: 1.0000e-04\n",
      "Epoch 4663/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21046.5629 - recon_loss: 2.0871e-04 - KL loss: 175.5151 - beta: 1.0000e-04 - val_loss: 24507.6230 - val_recon_loss: 2.4332e-04 - val_KL loss: 175.6328 - val_beta: 1.0000e-04\n",
      "Epoch 4664/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21568.6226 - recon_loss: 2.1389e-04 - KL loss: 179.2586 - beta: 1.0000e-04 - val_loss: 23001.2617 - val_recon_loss: 2.2827e-04 - val_KL loss: 174.6773 - val_beta: 1.0000e-04\n",
      "Epoch 4665/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20972.2398 - recon_loss: 2.0798e-04 - KL loss: 174.1122 - beta: 1.0000e-04 - val_loss: 23359.7461 - val_recon_loss: 2.3190e-04 - val_KL loss: 169.3214 - val_beta: 1.0000e-04\n",
      "Epoch 4666/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 20721.6303 - recon_loss: 2.0548e-04 - KL loss: 173.9008 - beta: 1.0000e-04 - val_loss: 23408.0605 - val_recon_loss: 2.3233e-04 - val_KL loss: 174.6145 - val_beta: 1.0000e-04\n",
      "Epoch 4667/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 21208.3398 - recon_loss: 2.1031e-04 - KL loss: 177.8127 - beta: 1.0000e-04 - val_loss: 25157.4160 - val_recon_loss: 2.4984e-04 - val_KL loss: 173.1986 - val_beta: 1.0000e-04\n",
      "Epoch 4668/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21342.7675 - recon_loss: 2.1166e-04 - KL loss: 176.4354 - beta: 1.0000e-04 - val_loss: 22866.1875 - val_recon_loss: 2.2700e-04 - val_KL loss: 166.5434 - val_beta: 1.0000e-04\n",
      "Epoch 4669/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20861.5679 - recon_loss: 2.0689e-04 - KL loss: 172.4322 - beta: 1.0000e-04 - val_loss: 22091.4473 - val_recon_loss: 2.1919e-04 - val_KL loss: 172.3441 - val_beta: 1.0000e-04\n",
      "Epoch 4670/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 21235.7597 - recon_loss: 2.1059e-04 - KL loss: 177.1207 - beta: 1.0000e-04 - val_loss: 23428.6055 - val_recon_loss: 2.3264e-04 - val_KL loss: 164.7551 - val_beta: 1.0000e-04\n",
      "Epoch 4671/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20998.2402 - recon_loss: 2.0827e-04 - KL loss: 171.5195 - beta: 1.0000e-04 - val_loss: 23605.3223 - val_recon_loss: 2.3435e-04 - val_KL loss: 170.2977 - val_beta: 1.0000e-04\n",
      "Epoch 4672/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 20407.4405 - recon_loss: 2.0235e-04 - KL loss: 172.8752 - beta: 1.0000e-04 - val_loss: 23631.5020 - val_recon_loss: 2.3462e-04 - val_KL loss: 169.0219 - val_beta: 1.0000e-04\n",
      "Epoch 4673/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 20675.0447 - recon_loss: 2.0502e-04 - KL loss: 172.7188 - beta: 1.0000e-04 - val_loss: 22685.6973 - val_recon_loss: 2.2514e-04 - val_KL loss: 171.2255 - val_beta: 1.0000e-04\n",
      "Epoch 4674/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 20434.0299 - recon_loss: 2.0261e-04 - KL loss: 173.1966 - beta: 1.0000e-04\n",
      "Epoch 04674: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 20433.9253 - recon_loss: 2.0261e-04 - KL loss: 173.1971 - beta: 1.0000e-04 - val_loss: 22930.5703 - val_recon_loss: 2.2759e-04 - val_KL loss: 171.2928 - val_beta: 1.0000e-04\n",
      "Epoch 4675/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20657.0851 - recon_loss: 2.0481e-04 - KL loss: 176.3096 - beta: 1.0000e-04 - val_loss: 22723.2598 - val_recon_loss: 2.2553e-04 - val_KL loss: 170.3444 - val_beta: 1.0000e-04\n",
      "Epoch 4676/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20239.6644 - recon_loss: 2.0066e-04 - KL loss: 173.4837 - beta: 1.0000e-04 - val_loss: 23189.8477 - val_recon_loss: 2.3021e-04 - val_KL loss: 168.8860 - val_beta: 1.0000e-04\n",
      "Epoch 4677/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 20135.7079 - recon_loss: 1.9964e-04 - KL loss: 171.3358 - beta: 1.0000e-04 - val_loss: 22902.6738 - val_recon_loss: 2.2735e-04 - val_KL loss: 167.8943 - val_beta: 1.0000e-04\n",
      "Epoch 4678/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20004.3444 - recon_loss: 1.9833e-04 - KL loss: 171.1208 - beta: 1.0000e-04 - val_loss: 22893.4473 - val_recon_loss: 2.2725e-04 - val_KL loss: 168.5857 - val_beta: 1.0000e-04\n",
      "Epoch 4679/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 20048.3106 - recon_loss: 1.9877e-04 - KL loss: 171.6191 - beta: 1.0000e-04\n",
      "Epoch 04679: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 20048.2180 - recon_loss: 1.9877e-04 - KL loss: 171.6180 - beta: 1.0000e-04 - val_loss: 23759.4160 - val_recon_loss: 2.3591e-04 - val_KL loss: 168.4759 - val_beta: 1.0000e-04\n",
      "Epoch 4679/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 58495.0799 - recon_loss: 2.3212e-04 - KL loss: 188.9784 - beta: 6.3096e-05 - val_loss: 61305.7383 - val_recon_loss: 2.4320e-04 - val_KL loss: 215.7915 - val_beta: 6.3096e-05\n",
      "Epoch 4680/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 55446.3842 - recon_loss: 2.1984e-04 - KL loss: 223.9756 - beta: 6.3096e-05 - val_loss: 62722.9258 - val_recon_loss: 2.4879e-04 - val_KL loss: 229.4551 - val_beta: 6.3096e-05\n",
      "Epoch 4681/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 54595.9643 - recon_loss: 2.1642e-04 - KL loss: 234.7535 - beta: 6.3096e-05 - val_loss: 60135.4805 - val_recon_loss: 2.3849e-04 - val_KL loss: 229.1864 - val_beta: 6.3096e-05\n",
      "Epoch 4682/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 56116.1848 - recon_loss: 2.2246e-04 - KL loss: 236.7282 - beta: 6.3096e-05 - val_loss: 60964.1562 - val_recon_loss: 2.4174e-04 - val_KL loss: 242.2096 - val_beta: 6.3096e-05\n",
      "Epoch 4683/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 57627.7426 - recon_loss: 2.2843e-04 - KL loss: 247.8623 - beta: 6.3096e-05 - val_loss: 67775.7891 - val_recon_loss: 2.6873e-04 - val_KL loss: 272.9404 - val_beta: 6.3096e-05\n",
      "Epoch 4684/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 58403.0241 - recon_loss: 2.3148e-04 - KL loss: 257.3014 - beta: 6.3096e-05 - val_loss: 61244.6719 - val_recon_loss: 2.4279e-04 - val_KL loss: 257.7575 - val_beta: 6.3096e-05\n",
      "Epoch 4685/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 55117.0267 - recon_loss: 2.1842e-04 - KL loss: 252.6884 - beta: 6.3096e-05 - val_loss: 68300.3047 - val_recon_loss: 2.7087e-04 - val_KL loss: 261.5834 - val_beta: 6.3096e-05\n",
      "Epoch 4686/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 57925.4751 - recon_loss: 2.2956e-04 - KL loss: 261.5157 - beta: 6.3096e-05\n",
      "Epoch 04686: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 57927.7694 - recon_loss: 2.2957e-04 - KL loss: 261.5336 - beta: 6.3096e-05 - val_loss: 65730.6562 - val_recon_loss: 2.6058e-04 - val_KL loss: 277.1129 - val_beta: 6.3096e-05\n",
      "Epoch 4687/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 55941.7321 - recon_loss: 2.2164e-04 - KL loss: 267.2872 - beta: 6.3096e-05 - val_loss: 63300.6953 - val_recon_loss: 2.5092e-04 - val_KL loss: 273.2061 - val_beta: 6.3096e-05\n",
      "Epoch 4688/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 54796.2732 - recon_loss: 2.1710e-04 - KL loss: 262.5917 - beta: 6.3096e-05 - val_loss: 63291.9336 - val_recon_loss: 2.5087e-04 - val_KL loss: 277.1950 - val_beta: 6.3096e-05\n",
      "Epoch 4689/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 53493.0560 - recon_loss: 2.1191e-04 - KL loss: 262.7535 - beta: 6.3096e-05 - val_loss: 60845.3008 - val_recon_loss: 2.4119e-04 - val_KL loss: 260.0305 - val_beta: 6.3096e-05\n",
      "Epoch 4690/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 52243.8518 - recon_loss: 2.0697e-04 - KL loss: 255.5662 - beta: 6.3096e-05 - val_loss: 60055.8672 - val_recon_loss: 2.3803e-04 - val_KL loss: 265.0055 - val_beta: 6.3096e-05\n",
      "Epoch 4691/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 51919.5612 - recon_loss: 2.0568e-04 - KL loss: 256.2063 - beta: 6.3096e-05 - val_loss: 60094.3789 - val_recon_loss: 2.3821e-04 - val_KL loss: 259.2623 - val_beta: 6.3096e-05\n",
      "Epoch 4692/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 52128.1186 - recon_loss: 2.0650e-04 - KL loss: 256.7687 - beta: 6.3096e-05 - val_loss: 60289.6523 - val_recon_loss: 2.3895e-04 - val_KL loss: 267.4752 - val_beta: 6.3096e-05\n",
      "Epoch 4693/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 52172.0052 - recon_loss: 2.0668e-04 - KL loss: 255.6442 - beta: 6.3096e-05 - val_loss: 59951.9648 - val_recon_loss: 2.3766e-04 - val_KL loss: 254.6981 - val_beta: 6.3096e-05\n",
      "Epoch 4694/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 50831.5497 - recon_loss: 2.0136e-04 - KL loss: 251.0716 - beta: 6.3096e-05 - val_loss: 57564.5156 - val_recon_loss: 2.2811e-04 - val_KL loss: 265.1383 - val_beta: 6.3096e-05\n",
      "Epoch 4695/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 51634.9618 - recon_loss: 2.0452e-04 - KL loss: 261.9023 - beta: 6.3096e-05 - val_loss: 59131.6523 - val_recon_loss: 2.3437e-04 - val_KL loss: 261.6317 - val_beta: 6.3096e-05\n",
      "Epoch 4696/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 52693.3200 - recon_loss: 2.0873e-04 - KL loss: 262.3194 - beta: 6.3096e-05 - val_loss: 63727.9688 - val_recon_loss: 2.5263e-04 - val_KL loss: 269.2474 - val_beta: 6.3096e-05\n",
      "Epoch 4697/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 52665.8070 - recon_loss: 2.0862e-04 - KL loss: 263.1642 - beta: 6.3096e-05 - val_loss: 64980.9531 - val_recon_loss: 2.5759e-04 - val_KL loss: 277.1060 - val_beta: 6.3096e-05\n",
      "Epoch 4698/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 52016.8215 - recon_loss: 2.0603e-04 - KL loss: 264.7257 - beta: 6.3096e-05 - val_loss: 64450.3203 - val_recon_loss: 2.5552e-04 - val_KL loss: 265.9265 - val_beta: 6.3096e-05\n",
      "Epoch 4699/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 51602.4786 - recon_loss: 2.0441e-04 - KL loss: 257.7759 - beta: 6.3096e-05\n",
      "Epoch 04699: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 51602.3067 - recon_loss: 2.0441e-04 - KL loss: 257.7756 - beta: 6.3096e-05 - val_loss: 62858.6758 - val_recon_loss: 2.4916e-04 - val_KL loss: 271.2779 - val_beta: 6.3096e-05\n",
      "Epoch 4700/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 51546.3591 - recon_loss: 2.0416e-04 - KL loss: 263.3835 - beta: 6.3096e-05 - val_loss: 62303.6562 - val_recon_loss: 2.4696e-04 - val_KL loss: 269.2436 - val_beta: 6.3096e-05\n",
      "Epoch 4701/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 51870.6099 - recon_loss: 2.0545e-04 - KL loss: 262.6776 - beta: 6.3096e-05 - val_loss: 62442.3398 - val_recon_loss: 2.4752e-04 - val_KL loss: 269.0887 - val_beta: 6.3096e-05\n",
      "Epoch 4702/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 51482.3608 - recon_loss: 2.0392e-04 - KL loss: 260.1345 - beta: 6.3096e-05 - val_loss: 61501.3203 - val_recon_loss: 2.4379e-04 - val_KL loss: 263.5987 - val_beta: 6.3096e-05\n",
      "Epoch 4703/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 50760.4809 - recon_loss: 2.0105e-04 - KL loss: 258.6570 - beta: 6.3096e-05 - val_loss: 62146.3438 - val_recon_loss: 2.4634e-04 - val_KL loss: 267.9968 - val_beta: 6.3096e-05\n",
      "Epoch 4704/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 51636.2124 - recon_loss: 2.0452e-04 - KL loss: 262.7206 - beta: 6.3096e-05\n",
      "Epoch 04704: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 51635.5760 - recon_loss: 2.0452e-04 - KL loss: 262.7202 - beta: 6.3096e-05 - val_loss: 61412.7188 - val_recon_loss: 2.4343e-04 - val_KL loss: 266.6160 - val_beta: 6.3096e-05\n",
      "Epoch 4704/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 151716.3164 - recon_loss: 2.4003e-04 - KL loss: 264.8012 - beta: 3.9811e-05 - val_loss: 157105.2812 - val_recon_loss: 2.4855e-04 - val_KL loss: 279.0351 - val_beta: 3.9811e-05\n",
      "Epoch 4705/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 160020.8416 - recon_loss: 2.5314e-04 - KL loss: 301.8840 - beta: 3.9811e-05 - val_loss: 162282.5156 - val_recon_loss: 2.5672e-04 - val_KL loss: 300.3038 - val_beta: 3.9811e-05\n",
      "Epoch 4706/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 148378.2282 - recon_loss: 2.3466e-04 - KL loss: 317.0447 - beta: 3.9811e-05 - val_loss: 153023.7656 - val_recon_loss: 2.4202e-04 - val_KL loss: 321.1678 - val_beta: 3.9811e-05\n",
      "Epoch 4707/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 144202.0996 - recon_loss: 2.2804e-04 - KL loss: 319.3629 - beta: 3.9811e-05 - val_loss: 148745.2344 - val_recon_loss: 2.3525e-04 - val_KL loss: 313.3032 - val_beta: 3.9811e-05\n",
      "Epoch 4708/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 145841.8793 - recon_loss: 2.3064e-04 - KL loss: 315.1090 - beta: 3.9811e-05 - val_loss: 145638.9844 - val_recon_loss: 2.3031e-04 - val_KL loss: 321.4829 - val_beta: 3.9811e-05\n",
      "Epoch 4709/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 135288.9193 - recon_loss: 2.1390e-04 - KL loss: 327.1476 - beta: 3.9811e-05 - val_loss: 142395.6250 - val_recon_loss: 2.2516e-04 - val_KL loss: 328.2403 - val_beta: 3.9811e-05\n",
      "Epoch 4710/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 132226.4634 - recon_loss: 2.0905e-04 - KL loss: 324.2990 - beta: 3.9811e-05 - val_loss: 142200.5469 - val_recon_loss: 2.2485e-04 - val_KL loss: 332.1836 - val_beta: 3.9811e-05\n",
      "Epoch 4711/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 134706.5604 - recon_loss: 2.1298e-04 - KL loss: 326.1742 - beta: 3.9811e-05 - val_loss: 157597.3594 - val_recon_loss: 2.4925e-04 - val_KL loss: 330.3501 - val_beta: 3.9811e-05\n",
      "Epoch 4712/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 164766.3158 - recon_loss: 2.6054e-04 - KL loss: 375.2385 - beta: 3.9811e-05 - val_loss: 166709.4531 - val_recon_loss: 2.6363e-04 - val_KL loss: 367.3263 - val_beta: 3.9811e-05\n",
      "Epoch 4713/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 149757.7804 - recon_loss: 2.3677e-04 - KL loss: 368.4470 - beta: 3.9811e-05 - val_loss: 143234.1562 - val_recon_loss: 2.2646e-04 - val_KL loss: 348.0891 - val_beta: 3.9811e-05\n",
      "Epoch 4714/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 139409.6571 - recon_loss: 2.2039e-04 - KL loss: 354.0851 - beta: 3.9811e-05 - val_loss: 140772.9375 - val_recon_loss: 2.2254e-04 - val_KL loss: 358.1586 - val_beta: 3.9811e-05\n",
      "Epoch 4715/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 146881.5926 - recon_loss: 2.3222e-04 - KL loss: 362.2682 - beta: 3.9811e-05 - val_loss: 144088.2812 - val_recon_loss: 2.2779e-04 - val_KL loss: 360.2115 - val_beta: 3.9811e-05\n",
      "Epoch 4716/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 139630.0950 - recon_loss: 2.2074e-04 - KL loss: 354.2471 - beta: 3.9811e-05 - val_loss: 148640.0000 - val_recon_loss: 2.3500e-04 - val_KL loss: 362.8906 - val_beta: 3.9811e-05\n",
      "Epoch 4717/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 135280.5102 - recon_loss: 2.1384e-04 - KL loss: 354.1464 - beta: 3.9811e-05 - val_loss: 151338.1719 - val_recon_loss: 2.3926e-04 - val_KL loss: 374.1211 - val_beta: 3.9811e-05\n",
      "Epoch 4718/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 139080.7118 - recon_loss: 2.1985e-04 - KL loss: 363.2267 - beta: 3.9811e-05 - val_loss: 135806.6875 - val_recon_loss: 2.1469e-04 - val_KL loss: 347.6371 - val_beta: 3.9811e-05\n",
      "Epoch 4719/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 137465.3285 - recon_loss: 2.1732e-04 - KL loss: 342.6261 - beta: 3.9811e-05 - val_loss: 151034.9844 - val_recon_loss: 2.3884e-04 - val_KL loss: 337.0385 - val_beta: 3.9811e-05\n",
      "Epoch 4720/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 138694.8530 - recon_loss: 2.1927e-04 - KL loss: 345.7150 - beta: 3.9811e-05 - val_loss: 148858.0938 - val_recon_loss: 2.3536e-04 - val_KL loss: 358.5616 - val_beta: 3.9811e-05\n",
      "Epoch 4721/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 135385.4483 - recon_loss: 2.1401e-04 - KL loss: 354.2728 - beta: 3.9811e-05 - val_loss: 157950.5625 - val_recon_loss: 2.4979e-04 - val_KL loss: 344.2151 - val_beta: 3.9811e-05\n",
      "Epoch 4722/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 137431.4262 - recon_loss: 2.1727e-04 - KL loss: 344.8963 - beta: 3.9811e-05 - val_loss: 134358.1406 - val_recon_loss: 2.1239e-04 - val_KL loss: 348.8820 - val_beta: 3.9811e-05\n",
      "Epoch 4723/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 136801.5989 - recon_loss: 2.1627e-04 - KL loss: 345.1071 - beta: 3.9811e-05 - val_loss: 134957.9219 - val_recon_loss: 2.1332e-04 - val_KL loss: 360.0331 - val_beta: 3.9811e-05\n",
      "Epoch 4724/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 131544.6767 - recon_loss: 2.0792e-04 - KL loss: 358.4583 - beta: 3.9811e-05 - val_loss: 132153.1875 - val_recon_loss: 2.0886e-04 - val_KL loss: 369.0428 - val_beta: 3.9811e-05\n",
      "Epoch 4725/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 129925.5486 - recon_loss: 2.0534e-04 - KL loss: 362.6626 - beta: 3.9811e-05 - val_loss: 138133.8125 - val_recon_loss: 2.1836e-04 - val_KL loss: 356.2023 - val_beta: 3.9811e-05\n",
      "Epoch 4726/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 129401.0579 - recon_loss: 2.0452e-04 - KL loss: 357.7840 - beta: 3.9811e-05 - val_loss: 132235.6719 - val_recon_loss: 2.0901e-04 - val_KL loss: 356.6505 - val_beta: 3.9811e-05\n",
      "Epoch 4727/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 132244.4798 - recon_loss: 2.0903e-04 - KL loss: 353.0729 - beta: 3.9811e-05 - val_loss: 156020.8750 - val_recon_loss: 2.4669e-04 - val_KL loss: 367.4628 - val_beta: 3.9811e-05\n",
      "Epoch 4728/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 138435.6500 - recon_loss: 2.1883e-04 - KL loss: 361.4248 - beta: 3.9811e-05 - val_loss: 137125.0312 - val_recon_loss: 2.1675e-04 - val_KL loss: 363.9259 - val_beta: 3.9811e-05\n",
      "Epoch 4729/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 134124.8838 - recon_loss: 2.1202e-04 - KL loss: 352.2287 - beta: 3.9811e-05\n",
      "Epoch 04729: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 134120.6741 - recon_loss: 2.1201e-04 - KL loss: 352.2279 - beta: 3.9811e-05 - val_loss: 139108.5469 - val_recon_loss: 2.1990e-04 - val_KL loss: 362.5600 - val_beta: 3.9811e-05\n",
      "Epoch 4730/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 122889.5226 - recon_loss: 1.9419e-04 - KL loss: 360.9957 - beta: 3.9811e-05 - val_loss: 122992.8359 - val_recon_loss: 1.9435e-04 - val_KL loss: 367.2231 - val_beta: 3.9811e-05\n",
      "Epoch 4731/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 125053.9302 - recon_loss: 1.9762e-04 - KL loss: 364.4906 - beta: 3.9811e-05 - val_loss: 130907.5469 - val_recon_loss: 2.0689e-04 - val_KL loss: 370.4874 - val_beta: 3.9811e-05\n",
      "Epoch 4732/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 125659.9528 - recon_loss: 1.9858e-04 - KL loss: 366.4661 - beta: 3.9811e-05 - val_loss: 128420.3828 - val_recon_loss: 2.0293e-04 - val_KL loss: 383.1671 - val_beta: 3.9811e-05\n",
      "Epoch 4733/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 126686.9345 - recon_loss: 2.0020e-04 - KL loss: 372.3575 - beta: 3.9811e-05 - val_loss: 127697.1250 - val_recon_loss: 2.0178e-04 - val_KL loss: 379.6571 - val_beta: 3.9811e-05\n",
      "Epoch 4734/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 126004.9707 - recon_loss: 1.9911e-04 - KL loss: 375.5709 - beta: 3.9811e-05 - val_loss: 128800.2188 - val_recon_loss: 2.0353e-04 - val_KL loss: 380.1985 - val_beta: 3.9811e-05\n",
      "Epoch 4735/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 123632.9733 - recon_loss: 1.9536e-04 - KL loss: 371.1119 - beta: 3.9811e-05\n",
      "Epoch 04735: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 123632.0572 - recon_loss: 1.9536e-04 - KL loss: 371.1087 - beta: 3.9811e-05 - val_loss: 123308.4141 - val_recon_loss: 1.9483e-04 - val_KL loss: 376.5892 - val_beta: 3.9811e-05\n",
      "Epoch 4736/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 121162.3230 - recon_loss: 1.9144e-04 - KL loss: 373.8708 - beta: 3.9811e-05 - val_loss: 122208.8125 - val_recon_loss: 1.9309e-04 - val_KL loss: 379.7296 - val_beta: 3.9811e-05\n",
      "Epoch 4737/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 120667.9646 - recon_loss: 1.9065e-04 - KL loss: 372.8620 - beta: 3.9811e-05 - val_loss: 125467.3281 - val_recon_loss: 1.9824e-04 - val_KL loss: 384.7560 - val_beta: 3.9811e-05\n",
      "Epoch 4738/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 120240.0992 - recon_loss: 1.8997e-04 - KL loss: 375.5967 - beta: 3.9811e-05 - val_loss: 122841.8516 - val_recon_loss: 1.9409e-04 - val_KL loss: 380.1338 - val_beta: 3.9811e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4739/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 118403.7992 - recon_loss: 1.8707e-04 - KL loss: 372.4973 - beta: 3.9811e-05 - val_loss: 122567.9688 - val_recon_loss: 1.9365e-04 - val_KL loss: 385.4078 - val_beta: 3.9811e-05\n",
      "Epoch 4740/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 120282.0911 - recon_loss: 1.9004e-04 - KL loss: 375.6560 - beta: 3.9811e-05 - val_loss: 120851.5469 - val_recon_loss: 1.9094e-04 - val_KL loss: 377.4134 - val_beta: 3.9811e-05\n",
      "Epoch 4741/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 118724.7948 - recon_loss: 1.8758e-04 - KL loss: 371.5041 - beta: 3.9811e-05 - val_loss: 120805.9609 - val_recon_loss: 1.9086e-04 - val_KL loss: 378.4872 - val_beta: 3.9811e-05\n",
      "Epoch 4742/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 117611.5146 - recon_loss: 1.8581e-04 - KL loss: 370.1667 - beta: 3.9811e-05 - val_loss: 119202.1406 - val_recon_loss: 1.8832e-04 - val_KL loss: 377.4075 - val_beta: 3.9811e-05\n",
      "Epoch 4743/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 118916.2220 - recon_loss: 1.8788e-04 - KL loss: 369.1343 - beta: 3.9811e-05 - val_loss: 118990.6250 - val_recon_loss: 1.8799e-04 - val_KL loss: 374.1581 - val_beta: 3.9811e-05\n",
      "Epoch 4744/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 118266.8983 - recon_loss: 1.8686e-04 - KL loss: 368.1172 - beta: 3.9811e-05 - val_loss: 119390.6797 - val_recon_loss: 1.8863e-04 - val_KL loss: 375.8035 - val_beta: 3.9811e-05\n",
      "Epoch 4745/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 116794.5514 - recon_loss: 1.8452e-04 - KL loss: 368.9817 - beta: 3.9811e-05 - val_loss: 118802.6953 - val_recon_loss: 1.8769e-04 - val_KL loss: 376.3242 - val_beta: 3.9811e-05\n",
      "Epoch 4746/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 118392.6292 - recon_loss: 1.8705e-04 - KL loss: 370.0528 - beta: 3.9811e-05 - val_loss: 118921.7031 - val_recon_loss: 1.8788e-04 - val_KL loss: 375.9094 - val_beta: 3.9811e-05\n",
      "Epoch 4747/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 117416.2028 - recon_loss: 1.8550e-04 - KL loss: 371.5977 - beta: 3.9811e-05 - val_loss: 119804.9219 - val_recon_loss: 1.8927e-04 - val_KL loss: 381.3869 - val_beta: 3.9811e-05\n",
      "Epoch 4748/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 117110.1369 - recon_loss: 1.8502e-04 - KL loss: 372.3546 - beta: 3.9811e-05 - val_loss: 119333.3203 - val_recon_loss: 1.8854e-04 - val_KL loss: 371.2462 - val_beta: 3.9811e-05\n",
      "Epoch 4749/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 117182.4708 - recon_loss: 1.8513e-04 - KL loss: 370.4982 - beta: 3.9811e-05 - val_loss: 121241.3750 - val_recon_loss: 1.9157e-04 - val_KL loss: 371.1268 - val_beta: 3.9811e-05\n",
      "Epoch 4750/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 116615.0781 - recon_loss: 1.8424e-04 - KL loss: 366.7847 - beta: 3.9811e-05 - val_loss: 118755.7734 - val_recon_loss: 1.8763e-04 - val_KL loss: 370.9062 - val_beta: 3.9811e-05\n",
      "Epoch 4751/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 117925.5848 - recon_loss: 1.8632e-04 - KL loss: 367.6772 - beta: 3.9811e-05 - val_loss: 120063.6016 - val_recon_loss: 1.8970e-04 - val_KL loss: 371.5703 - val_beta: 3.9811e-05\n",
      "Epoch 4752/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 117189.3453 - recon_loss: 1.8515e-04 - KL loss: 368.0009 - beta: 3.9811e-05 - val_loss: 119065.6562 - val_recon_loss: 1.8812e-04 - val_KL loss: 370.6041 - val_beta: 3.9811e-05\n",
      "Epoch 4753/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 116157.5986 - recon_loss: 1.8352e-04 - KL loss: 365.4184 - beta: 3.9811e-05 - val_loss: 119955.6016 - val_recon_loss: 1.8953e-04 - val_KL loss: 369.2607 - val_beta: 3.9811e-05\n",
      "Epoch 4754/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 117149.4703 - recon_loss: 1.8509e-04 - KL loss: 366.5871 - beta: 3.9811e-05 - val_loss: 118358.6484 - val_recon_loss: 1.8700e-04 - val_KL loss: 372.5291 - val_beta: 3.9811e-05\n",
      "Epoch 4755/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 116275.1234 - recon_loss: 1.8370e-04 - KL loss: 366.6563 - beta: 3.9811e-05 - val_loss: 128950.5469 - val_recon_loss: 2.0378e-04 - val_KL loss: 373.2650 - val_beta: 3.9811e-05\n",
      "Epoch 4756/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 117549.1225 - recon_loss: 1.8572e-04 - KL loss: 367.4871 - beta: 3.9811e-05 - val_loss: 130835.4531 - val_recon_loss: 2.0677e-04 - val_KL loss: 370.9672 - val_beta: 3.9811e-05\n",
      "Epoch 4757/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 117402.0681 - recon_loss: 1.8549e-04 - KL loss: 366.3588 - beta: 3.9811e-05 - val_loss: 129367.7344 - val_recon_loss: 2.0445e-04 - val_KL loss: 370.7944 - val_beta: 3.9811e-05\n",
      "Epoch 4758/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 116465.4981 - recon_loss: 1.8400e-04 - KL loss: 367.6622 - beta: 3.9811e-05 - val_loss: 124559.2891 - val_recon_loss: 1.9683e-04 - val_KL loss: 367.9672 - val_beta: 3.9811e-05\n",
      "Epoch 4759/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 116038.5309 - recon_loss: 1.8333e-04 - KL loss: 365.1926 - beta: 3.9811e-05\n",
      "Epoch 04759: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 116038.2612 - recon_loss: 1.8333e-04 - KL loss: 365.1934 - beta: 3.9811e-05 - val_loss: 133314.4844 - val_recon_loss: 2.1070e-04 - val_KL loss: 369.7593 - val_beta: 3.9811e-05\n",
      "Epoch 4760/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 115265.5559 - recon_loss: 1.8210e-04 - KL loss: 367.2115 - beta: 3.9811e-05 - val_loss: 130038.4766 - val_recon_loss: 2.0551e-04 - val_KL loss: 371.0885 - val_beta: 3.9811e-05\n",
      "Epoch 4761/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 116695.6873 - recon_loss: 1.8437e-04 - KL loss: 367.9844 - beta: 3.9811e-05 - val_loss: 132309.0156 - val_recon_loss: 2.0911e-04 - val_KL loss: 370.8981 - val_beta: 3.9811e-05\n",
      "Epoch 4762/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 115773.5695 - recon_loss: 1.8291e-04 - KL loss: 367.2200 - beta: 3.9811e-05 - val_loss: 131017.0312 - val_recon_loss: 2.0706e-04 - val_KL loss: 371.1779 - val_beta: 3.9811e-05\n",
      "Epoch 4763/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 116252.0001 - recon_loss: 1.8366e-04 - KL loss: 367.9177 - beta: 3.9811e-05 - val_loss: 133085.1094 - val_recon_loss: 2.1034e-04 - val_KL loss: 370.8637 - val_beta: 3.9811e-05\n",
      "Epoch 4764/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 116981.4205 - recon_loss: 1.8482e-04 - KL loss: 368.2799 - beta: 3.9811e-05\n",
      "Epoch 04764: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 116981.2318 - recon_loss: 1.8482e-04 - KL loss: 368.2804 - beta: 3.9811e-05 - val_loss: 132848.4219 - val_recon_loss: 2.0996e-04 - val_KL loss: 372.2025 - val_beta: 3.9811e-05\n",
      "Epoch 4764/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 360156.0415 - recon_loss: 2.2701e-04 - KL loss: 376.2747 - beta: 2.5119e-05 - val_loss: 376052.6250 - val_recon_loss: 2.3702e-04 - val_KL loss: 401.0674 - val_beta: 2.5119e-05\n",
      "Epoch 4765/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 342307.3839 - recon_loss: 2.1572e-04 - KL loss: 408.3656 - beta: 2.5119e-05 - val_loss: 388426.2188 - val_recon_loss: 2.4481e-04 - val_KL loss: 426.5427 - val_beta: 2.5119e-05\n",
      "Epoch 4766/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 327467.0850 - recon_loss: 2.0636e-04 - KL loss: 407.6733 - beta: 2.5119e-05 - val_loss: 407694.0000 - val_recon_loss: 2.5697e-04 - val_KL loss: 427.9015 - val_beta: 2.5119e-05\n",
      "Epoch 4767/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 360981.1507 - recon_loss: 2.2749e-04 - KL loss: 436.0139 - beta: 2.5119e-05 - val_loss: 361963.3750 - val_recon_loss: 2.2813e-04 - val_KL loss: 400.4689 - val_beta: 2.5119e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4768/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 322847.9987 - recon_loss: 2.0345e-04 - KL loss: 404.9993 - beta: 2.5119e-05 - val_loss: 527208.7500 - val_recon_loss: 3.3239e-04 - val_KL loss: 411.3291 - val_beta: 2.5119e-05\n",
      "Epoch 4769/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 378249.7908 - recon_loss: 2.3838e-04 - KL loss: 447.4368 - beta: 2.5119e-05 - val_loss: 359727.0000 - val_recon_loss: 2.2671e-04 - val_KL loss: 414.2017 - val_beta: 2.5119e-05\n",
      "Epoch 4770/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 319691.6385 - recon_loss: 2.0145e-04 - KL loss: 414.4704 - beta: 2.5119e-05 - val_loss: 391967.5312 - val_recon_loss: 2.4704e-04 - val_KL loss: 437.2427 - val_beta: 2.5119e-05\n",
      "Epoch 4771/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 347545.1553 - recon_loss: 2.1901e-04 - KL loss: 439.2685 - beta: 2.5119e-05 - val_loss: 362141.9688 - val_recon_loss: 2.2824e-04 - val_KL loss: 413.3111 - val_beta: 2.5119e-05\n",
      "Epoch 4772/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 322707.8999 - recon_loss: 2.0335e-04 - KL loss: 421.1163 - beta: 2.5119e-05 - val_loss: 366573.9062 - val_recon_loss: 2.3103e-04 - val_KL loss: 419.4131 - val_beta: 2.5119e-05\n",
      "Epoch 4773/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 336708.9618 - recon_loss: 2.1218e-04 - KL loss: 429.2044 - beta: 2.5119e-05 - val_loss: 390442.4375 - val_recon_loss: 2.4606e-04 - val_KL loss: 462.6689 - val_beta: 2.5119e-05\n",
      "Epoch 4774/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 355439.5631 - recon_loss: 2.2397e-04 - KL loss: 467.6799 - beta: 2.5119e-05\n",
      "Epoch 04774: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 355455.5288 - recon_loss: 2.2398e-04 - KL loss: 467.6942 - beta: 2.5119e-05 - val_loss: 388238.1562 - val_recon_loss: 2.4466e-04 - val_KL loss: 481.9398 - val_beta: 2.5119e-05\n",
      "Epoch 4775/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 351587.3634 - recon_loss: 2.2153e-04 - KL loss: 486.3357 - beta: 2.5119e-05 - val_loss: 351388.9375 - val_recon_loss: 2.2142e-04 - val_KL loss: 469.3042 - val_beta: 2.5119e-05\n",
      "Epoch 4776/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 331005.6699 - recon_loss: 2.0855e-04 - KL loss: 476.7352 - beta: 2.5119e-05 - val_loss: 401309.9062 - val_recon_loss: 2.5292e-04 - val_KL loss: 461.0638 - val_beta: 2.5119e-05\n",
      "Epoch 4777/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 324685.7056 - recon_loss: 2.0457e-04 - KL loss: 462.5441 - beta: 2.5119e-05 - val_loss: 348562.5625 - val_recon_loss: 2.1964e-04 - val_KL loss: 449.4055 - val_beta: 2.5119e-05\n",
      "Epoch 4778/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 314250.5898 - recon_loss: 1.9799e-04 - KL loss: 454.2568 - beta: 2.5119e-05 - val_loss: 334792.2812 - val_recon_loss: 2.1095e-04 - val_KL loss: 452.1061 - val_beta: 2.5119e-05\n",
      "Epoch 4779/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 305832.7697 - recon_loss: 1.9268e-04 - KL loss: 453.2564 - beta: 2.5119e-05 - val_loss: 351510.0312 - val_recon_loss: 2.2150e-04 - val_KL loss: 449.6093 - val_beta: 2.5119e-05\n",
      "Epoch 4780/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 303591.9769 - recon_loss: 1.9127e-04 - KL loss: 453.2219 - beta: 2.5119e-05 - val_loss: 346999.9688 - val_recon_loss: 2.1866e-04 - val_KL loss: 450.6022 - val_beta: 2.5119e-05\n",
      "Epoch 4781/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 305025.5571 - recon_loss: 1.9217e-04 - KL loss: 451.6084 - beta: 2.5119e-05 - val_loss: 340106.9375 - val_recon_loss: 2.1431e-04 - val_KL loss: 449.4280 - val_beta: 2.5119e-05\n",
      "Epoch 4782/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 301475.4872 - recon_loss: 1.8993e-04 - KL loss: 451.5411 - beta: 2.5119e-05 - val_loss: 355734.2188 - val_recon_loss: 2.2417e-04 - val_KL loss: 445.6733 - val_beta: 2.5119e-05\n",
      "Epoch 4783/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 302648.1759 - recon_loss: 1.9067e-04 - KL loss: 451.4399 - beta: 2.5119e-05 - val_loss: 328177.0938 - val_recon_loss: 2.0678e-04 - val_KL loss: 453.6747 - val_beta: 2.5119e-05\n",
      "Epoch 4784/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 303108.9367 - recon_loss: 1.9096e-04 - KL loss: 454.9582 - beta: 2.5119e-05 - val_loss: 319915.4062 - val_recon_loss: 2.0156e-04 - val_KL loss: 459.7331 - val_beta: 2.5119e-05\n",
      "Epoch 4785/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 304653.8470 - recon_loss: 1.9193e-04 - KL loss: 461.4033 - beta: 2.5119e-05 - val_loss: 316389.0938 - val_recon_loss: 1.9934e-04 - val_KL loss: 451.0467 - val_beta: 2.5119e-05\n",
      "Epoch 4786/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 302244.9515 - recon_loss: 1.9042e-04 - KL loss: 454.2619 - beta: 2.5119e-05 - val_loss: 330169.1250 - val_recon_loss: 2.0803e-04 - val_KL loss: 457.3811 - val_beta: 2.5119e-05\n",
      "Epoch 4787/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 307612.8618 - recon_loss: 1.9380e-04 - KL loss: 457.6527 - beta: 2.5119e-05 - val_loss: 321576.5625 - val_recon_loss: 2.0261e-04 - val_KL loss: 459.1192 - val_beta: 2.5119e-05\n",
      "Epoch 4788/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 302422.1071 - recon_loss: 1.9053e-04 - KL loss: 455.9108 - beta: 2.5119e-05 - val_loss: 323284.9375 - val_recon_loss: 2.0369e-04 - val_KL loss: 453.9965 - val_beta: 2.5119e-05\n",
      "Epoch 4789/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 299586.1619 - recon_loss: 1.8874e-04 - KL loss: 460.3095 - beta: 2.5119e-05 - val_loss: 326297.1875 - val_recon_loss: 2.0559e-04 - val_KL loss: 455.8900 - val_beta: 2.5119e-05\n",
      "Epoch 4790/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 298282.8123 - recon_loss: 1.8791e-04 - KL loss: 459.9975 - beta: 2.5119e-05\n",
      "Epoch 04790: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 298282.6723 - recon_loss: 1.8791e-04 - KL loss: 459.9922 - beta: 2.5119e-05 - val_loss: 345027.9688 - val_recon_loss: 2.1741e-04 - val_KL loss: 454.4028 - val_beta: 2.5119e-05\n",
      "Epoch 4791/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 290946.6784 - recon_loss: 1.8329e-04 - KL loss: 454.0089 - beta: 2.5119e-05 - val_loss: 339233.4375 - val_recon_loss: 2.1375e-04 - val_KL loss: 456.1574 - val_beta: 2.5119e-05\n",
      "Epoch 4792/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 290507.1202 - recon_loss: 1.8301e-04 - KL loss: 457.0523 - beta: 2.5119e-05 - val_loss: 318546.2188 - val_recon_loss: 2.0070e-04 - val_KL loss: 456.3507 - val_beta: 2.5119e-05\n",
      "Epoch 4793/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 290053.4038 - recon_loss: 1.8272e-04 - KL loss: 457.7575 - beta: 2.5119e-05 - val_loss: 324917.1562 - val_recon_loss: 2.0472e-04 - val_KL loss: 454.5537 - val_beta: 2.5119e-05\n",
      "Epoch 4794/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 286996.8410 - recon_loss: 1.8080e-04 - KL loss: 455.1486 - beta: 2.5119e-05 - val_loss: 326504.1562 - val_recon_loss: 2.0572e-04 - val_KL loss: 453.5452 - val_beta: 2.5119e-05\n",
      "Epoch 4795/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 287093.3081 - recon_loss: 1.8086e-04 - KL loss: 454.9409 - beta: 2.5119e-05\n",
      "Epoch 04795: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 287092.5829 - recon_loss: 1.8086e-04 - KL loss: 454.9417 - beta: 2.5119e-05 - val_loss: 322348.1562 - val_recon_loss: 2.0310e-04 - val_KL loss: 454.9529 - val_beta: 2.5119e-05\n",
      "Epoch 4795/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 874269.7442 - recon_loss: 2.1949e-04 - KL loss: 454.2637 - beta: 1.5849e-05 - val_loss: 869233.0000 - val_recon_loss: 2.1822e-04 - val_KL loss: 470.4517 - val_beta: 1.5849e-05\n",
      "Epoch 4796/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 58s 58ms/step - loss: 829450.5241 - recon_loss: 2.0823e-04 - KL loss: 470.3651 - beta: 1.5849e-05 - val_loss: 857710.9375 - val_recon_loss: 2.1533e-04 - val_KL loss: 463.6705 - val_beta: 1.5849e-05\n",
      "Epoch 4797/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 790347.6450 - recon_loss: 1.9841e-04 - KL loss: 471.3766 - beta: 1.5849e-05 - val_loss: 870859.8750 - val_recon_loss: 2.1863e-04 - val_KL loss: 487.8849 - val_beta: 1.5849e-05\n",
      "Epoch 4798/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 833642.9169 - recon_loss: 2.0928e-04 - KL loss: 498.2630 - beta: 1.5849e-05 - val_loss: 882539.7500 - val_recon_loss: 2.2156e-04 - val_KL loss: 503.2677 - val_beta: 1.5849e-05\n",
      "Epoch 4799/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 837172.4421 - recon_loss: 2.1016e-04 - KL loss: 503.1326 - beta: 1.5849e-05 - val_loss: 927479.6250 - val_recon_loss: 2.3285e-04 - val_KL loss: 500.5504 - val_beta: 1.5849e-05\n",
      "Epoch 4800/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 890589.5167 - recon_loss: 2.2357e-04 - KL loss: 526.5261 - beta: 1.5849e-05 - val_loss: 966459.3750 - val_recon_loss: 2.4263e-04 - val_KL loss: 528.1241 - val_beta: 1.5849e-05\n",
      "Epoch 4801/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 912368.1723 - recon_loss: 2.2904e-04 - KL loss: 549.2925 - beta: 1.5849e-05\n",
      "Epoch 04801: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 912375.9432 - recon_loss: 2.2904e-04 - KL loss: 549.2954 - beta: 1.5849e-05 - val_loss: 982596.0625 - val_recon_loss: 2.4668e-04 - val_KL loss: 527.0538 - val_beta: 1.5849e-05\n",
      "Epoch 4802/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 836217.0818 - recon_loss: 2.0992e-04 - KL loss: 522.0389 - beta: 1.5849e-05 - val_loss: 953829.5625 - val_recon_loss: 2.3946e-04 - val_KL loss: 506.4244 - val_beta: 1.5849e-05\n",
      "Epoch 4803/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 802112.8606 - recon_loss: 2.0135e-04 - KL loss: 520.8013 - beta: 1.5849e-05 - val_loss: 914814.8750 - val_recon_loss: 2.2966e-04 - val_KL loss: 526.4431 - val_beta: 1.5849e-05\n",
      "Epoch 4804/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 781219.2528 - recon_loss: 1.9610e-04 - KL loss: 539.1402 - beta: 1.5849e-05 - val_loss: 867342.1875 - val_recon_loss: 2.1773e-04 - val_KL loss: 535.7678 - val_beta: 1.5849e-05\n",
      "Epoch 4805/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 786719.6246 - recon_loss: 1.9748e-04 - KL loss: 544.1797 - beta: 1.5849e-05 - val_loss: 812841.1250 - val_recon_loss: 2.0404e-04 - val_KL loss: 528.6100 - val_beta: 1.5849e-05\n",
      "Epoch 4806/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 764777.4179 - recon_loss: 1.9197e-04 - KL loss: 530.2172 - beta: 1.5849e-05 - val_loss: 815828.4375 - val_recon_loss: 2.0480e-04 - val_KL loss: 522.8297 - val_beta: 1.5849e-05\n",
      "Epoch 4807/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 763922.9324 - recon_loss: 1.9175e-04 - KL loss: 535.3583 - beta: 1.5849e-05 - val_loss: 904441.9375 - val_recon_loss: 2.2705e-04 - val_KL loss: 532.4232 - val_beta: 1.5849e-05\n",
      "Epoch 4808/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 774192.4828 - recon_loss: 1.9433e-04 - KL loss: 546.7001 - beta: 1.5849e-05 - val_loss: 878007.3125 - val_recon_loss: 2.2041e-04 - val_KL loss: 536.0264 - val_beta: 1.5849e-05\n",
      "Epoch 4809/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 770407.2817 - recon_loss: 1.9338e-04 - KL loss: 550.6658 - beta: 1.5849e-05 - val_loss: 800227.1250 - val_recon_loss: 2.0087e-04 - val_KL loss: 548.2314 - val_beta: 1.5849e-05\n",
      "Epoch 4810/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 774036.4086 - recon_loss: 1.9429e-04 - KL loss: 553.1738 - beta: 1.5849e-05 - val_loss: 858595.5625 - val_recon_loss: 2.1553e-04 - val_KL loss: 557.2020 - val_beta: 1.5849e-05\n",
      "Epoch 4811/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 781040.3158 - recon_loss: 1.9604e-04 - KL loss: 574.7442 - beta: 1.5849e-05 - val_loss: 825443.9375 - val_recon_loss: 2.0720e-04 - val_KL loss: 557.4502 - val_beta: 1.5849e-05\n",
      "Epoch 4812/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 770576.9090 - recon_loss: 1.9342e-04 - KL loss: 564.3801 - beta: 1.5849e-05 - val_loss: 821802.3750 - val_recon_loss: 2.0629e-04 - val_KL loss: 555.9949 - val_beta: 1.5849e-05\n",
      "Epoch 4813/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 770007.5357 - recon_loss: 1.9327e-04 - KL loss: 572.4543 - beta: 1.5849e-05 - val_loss: 827185.9375 - val_recon_loss: 2.0764e-04 - val_KL loss: 558.8705 - val_beta: 1.5849e-05\n",
      "Epoch 4814/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 785376.3371 - recon_loss: 1.9713e-04 - KL loss: 580.8436 - beta: 1.5849e-05 ETA: 3s -\n",
      "Epoch 04814: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 785381.0302 - recon_loss: 1.9713e-04 - KL loss: 580.8495 - beta: 1.5849e-05 - val_loss: 893735.8750 - val_recon_loss: 2.2435e-04 - val_KL loss: 572.7422 - val_beta: 1.5849e-05\n",
      "Epoch 4815/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 758978.6251 - recon_loss: 1.9050e-04 - KL loss: 581.9140 - beta: 1.5849e-05 - val_loss: 800449.4375 - val_recon_loss: 2.0092e-04 - val_KL loss: 558.2001 - val_beta: 1.5849e-05\n",
      "Epoch 4816/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 744469.6874 - recon_loss: 1.8686e-04 - KL loss: 573.5778 - beta: 1.5849e-05 - val_loss: 802571.8125 - val_recon_loss: 2.0146e-04 - val_KL loss: 561.1379 - val_beta: 1.5849e-05\n",
      "Epoch 4817/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 752538.4459 - recon_loss: 1.8888e-04 - KL loss: 581.0295 - beta: 1.5849e-05 - val_loss: 793734.5000 - val_recon_loss: 1.9923e-04 - val_KL loss: 568.0256 - val_beta: 1.5849e-05\n",
      "Epoch 4818/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 745747.5253 - recon_loss: 1.8718e-04 - KL loss: 581.1799 - beta: 1.5849e-05 - val_loss: 798793.6250 - val_recon_loss: 2.0051e-04 - val_KL loss: 563.7872 - val_beta: 1.5849e-05\n",
      "Epoch 4819/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 747494.1211 - recon_loss: 1.8762e-04 - KL loss: 577.4468 - beta: 1.5849e-05 - val_loss: 897198.5000 - val_recon_loss: 2.2522e-04 - val_KL loss: 575.2830 - val_beta: 1.5849e-05\n",
      "Epoch 4820/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 748558.1311 - recon_loss: 1.8788e-04 - KL loss: 587.0390 - beta: 1.5849e-05 - val_loss: 929688.2500 - val_recon_loss: 2.3338e-04 - val_KL loss: 576.3889 - val_beta: 1.5849e-05\n",
      "Epoch 4821/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 754217.2596 - recon_loss: 1.8930e-04 - KL loss: 588.6862 - beta: 1.5849e-05 - val_loss: 917139.1250 - val_recon_loss: 2.3023e-04 - val_KL loss: 570.1514 - val_beta: 1.5849e-05\n",
      "Epoch 4822/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 753186.7806 - recon_loss: 1.8905e-04 - KL loss: 582.0826 - beta: 1.5849e-05\n",
      "Epoch 04822: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 753183.9464 - recon_loss: 1.8904e-04 - KL loss: 582.0825 - beta: 1.5849e-05 - val_loss: 805983.5000 - val_recon_loss: 2.0231e-04 - val_KL loss: 563.1699 - val_beta: 1.5849e-05\n",
      "Epoch 4823/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 733695.1075 - recon_loss: 1.8415e-04 - KL loss: 575.6451 - beta: 1.5849e-05 - val_loss: 792678.4375 - val_recon_loss: 1.9897e-04 - val_KL loss: 563.8445 - val_beta: 1.5849e-05\n",
      "Epoch 4824/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 735769.9192 - recon_loss: 1.8467e-04 - KL loss: 578.8086 - beta: 1.5849e-05 - val_loss: 787801.6875 - val_recon_loss: 1.9775e-04 - val_KL loss: 562.7756 - val_beta: 1.5849e-05\n",
      "Epoch 4825/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 58s 58ms/step - loss: 739217.6764 - recon_loss: 1.8554e-04 - KL loss: 576.9873 - beta: 1.5849e-05 - val_loss: 787198.5000 - val_recon_loss: 1.9759e-04 - val_KL loss: 565.4828 - val_beta: 1.5849e-05\n",
      "Epoch 4826/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 740046.0416 - recon_loss: 1.8575e-04 - KL loss: 578.6898 - beta: 1.5849e-05 - val_loss: 809483.9375 - val_recon_loss: 2.0319e-04 - val_KL loss: 568.1829 - val_beta: 1.5849e-05\n",
      "Epoch 4827/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 738203.9252 - recon_loss: 1.8528e-04 - KL loss: 580.6128 - beta: 1.5849e-05 - val_loss: 833190.3125 - val_recon_loss: 2.0915e-04 - val_KL loss: 568.3317 - val_beta: 1.5849e-05\n",
      "Epoch 4828/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 747163.4606 - recon_loss: 1.8753e-04 - KL loss: 581.7955 - beta: 1.5849e-05 - val_loss: 799299.1250 - val_recon_loss: 2.0063e-04 - val_KL loss: 570.0364 - val_beta: 1.5849e-05\n",
      "Epoch 4829/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 738280.9653 - recon_loss: 1.8530e-04 - KL loss: 584.4350 - beta: 1.5849e-05 - val_loss: 797702.8125 - val_recon_loss: 2.0023e-04 - val_KL loss: 572.8363 - val_beta: 1.5849e-05\n",
      "Epoch 4830/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 747430.8484 - recon_loss: 1.8760e-04 - KL loss: 585.9890 - beta: 1.5849e-05\n",
      "Epoch 04830: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 747428.2960 - recon_loss: 1.8760e-04 - KL loss: 585.9902 - beta: 1.5849e-05 - val_loss: 806054.3125 - val_recon_loss: 2.0233e-04 - val_KL loss: 575.4827 - val_beta: 1.5849e-05\n",
      "Epoch 4831/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 752236.9507 - recon_loss: 1.8881e-04 - KL loss: 588.2895 - beta: 1.5849e-05 - val_loss: 796877.3750 - val_recon_loss: 2.0002e-04 - val_KL loss: 576.4476 - val_beta: 1.5849e-05\n",
      "Epoch 4832/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 738431.2042 - recon_loss: 1.8534e-04 - KL loss: 590.4187 - beta: 1.5849e-05 - val_loss: 797621.0625 - val_recon_loss: 2.0021e-04 - val_KL loss: 577.0983 - val_beta: 1.5849e-05\n",
      "Epoch 4833/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 733626.2823 - recon_loss: 1.8413e-04 - KL loss: 591.9100 - beta: 1.5849e-05 - val_loss: 901320.0000 - val_recon_loss: 2.2626e-04 - val_KL loss: 577.1591 - val_beta: 1.5849e-05\n",
      "Epoch 4834/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 742800.9777 - recon_loss: 1.8643e-04 - KL loss: 590.7596 - beta: 1.5849e-05 - val_loss: 929267.8125 - val_recon_loss: 2.3328e-04 - val_KL loss: 578.6349 - val_beta: 1.5849e-05\n",
      "Epoch 4835/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 742169.2057 - recon_loss: 1.8628e-04 - KL loss: 593.4855 - beta: 1.5849e-05\n",
      "Epoch 04835: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 742171.3284 - recon_loss: 1.8628e-04 - KL loss: 593.4851 - beta: 1.5849e-05 - val_loss: 868188.0000 - val_recon_loss: 2.1793e-04 - val_KL loss: 579.2781 - val_beta: 1.5849e-05\n",
      "Epoch 4835/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 309893.5926 - recon_loss: 1.9516e-04 - KL loss: 586.2445 - beta: 2.5119e-05 - val_loss: 335703.6562 - val_recon_loss: 2.1147e-04 - val_KL loss: 550.9518 - val_beta: 2.5119e-05\n",
      "Epoch 4836/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 319578.3099 - recon_loss: 2.0129e-04 - KL loss: 551.2425 - beta: 2.5119e-05 - val_loss: 340244.2188 - val_recon_loss: 2.1434e-04 - val_KL loss: 536.6824 - val_beta: 2.5119e-05\n",
      "Epoch 4837/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 331678.1245 - recon_loss: 2.0894e-04 - KL loss: 537.4569 - beta: 2.5119e-05 - val_loss: 347363.5000 - val_recon_loss: 2.1886e-04 - val_KL loss: 486.9787 - val_beta: 2.5119e-05\n",
      "Epoch 4838/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 326921.9117 - recon_loss: 2.0597e-04 - KL loss: 484.9558 - beta: 2.5119e-05 - val_loss: 343789.6562 - val_recon_loss: 2.1661e-04 - val_KL loss: 480.9261 - val_beta: 2.5119e-05\n",
      "Epoch 4839/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 326508.1450 - recon_loss: 2.0571e-04 - KL loss: 483.7800 - beta: 2.5119e-05 - val_loss: 443092.4688 - val_recon_loss: 2.7927e-04 - val_KL loss: 478.2766 - val_beta: 2.5119e-05\n",
      "Epoch 4840/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 338673.7004 - recon_loss: 2.1338e-04 - KL loss: 492.8380 - beta: 2.5119e-05 - val_loss: 327975.5312 - val_recon_loss: 2.0664e-04 - val_KL loss: 480.3970 - val_beta: 2.5119e-05\n",
      "Epoch 4841/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 333435.8368 - recon_loss: 2.1007e-04 - KL loss: 495.0238 - beta: 2.5119e-05 - val_loss: 351693.8438 - val_recon_loss: 2.2160e-04 - val_KL loss: 477.0752 - val_beta: 2.5119e-05\n",
      "Epoch 4842/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 326653.3039 - recon_loss: 2.0579e-04 - KL loss: 491.1560 - beta: 2.5119e-05 - val_loss: 321969.2188 - val_recon_loss: 2.0285e-04 - val_KL loss: 478.7046 - val_beta: 2.5119e-05\n",
      "Epoch 4843/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 328299.2189 - recon_loss: 2.0684e-04 - KL loss: 487.6389 - beta: 2.5119e-05 - val_loss: 333287.4375 - val_recon_loss: 2.0999e-04 - val_KL loss: 473.7647 - val_beta: 2.5119e-05\n",
      "Epoch 4844/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 334070.9166 - recon_loss: 2.1048e-04 - KL loss: 489.3347 - beta: 2.5119e-05 - val_loss: 331316.3438 - val_recon_loss: 2.0874e-04 - val_KL loss: 485.4800 - val_beta: 2.5119e-05\n",
      "Epoch 4845/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 329798.2775 - recon_loss: 2.0778e-04 - KL loss: 485.7204 - beta: 2.5119e-05 - val_loss: 328964.6562 - val_recon_loss: 2.0726e-04 - val_KL loss: 479.5332 - val_beta: 2.5119e-05\n",
      "Epoch 4846/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 338601.1660 - recon_loss: 2.1333e-04 - KL loss: 488.4345 - beta: 2.5119e-05 - val_loss: 401741.4375 - val_recon_loss: 2.5316e-04 - val_KL loss: 504.2529 - val_beta: 2.5119e-05\n",
      "Epoch 4847/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 341028.9813 - recon_loss: 2.1486e-04 - KL loss: 498.1126 - beta: 2.5119e-05\n",
      "Epoch 04847: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 341027.7071 - recon_loss: 2.1486e-04 - KL loss: 498.1091 - beta: 2.5119e-05 - val_loss: 342079.3438 - val_recon_loss: 2.1552e-04 - val_KL loss: 495.7591 - val_beta: 2.5119e-05\n",
      "Epoch 4848/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 315553.7506 - recon_loss: 1.9879e-04 - KL loss: 498.3153 - beta: 2.5119e-05 - val_loss: 311839.0000 - val_recon_loss: 1.9644e-04 - val_KL loss: 495.0748 - val_beta: 2.5119e-05\n",
      "Epoch 4849/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 303067.4033 - recon_loss: 1.9091e-04 - KL loss: 495.2315 - beta: 2.5119e-05 - val_loss: 310684.4062 - val_recon_loss: 1.9571e-04 - val_KL loss: 504.2750 - val_beta: 2.5119e-05\n",
      "Epoch 4850/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 303804.6324 - recon_loss: 1.9137e-04 - KL loss: 503.3051 - beta: 2.5119e-05 - val_loss: 313164.7188 - val_recon_loss: 1.9728e-04 - val_KL loss: 499.1938 - val_beta: 2.5119e-05\n",
      "Epoch 4851/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 299272.6604 - recon_loss: 1.8851e-04 - KL loss: 496.9136 - beta: 2.5119e-05 - val_loss: 310798.1250 - val_recon_loss: 1.9579e-04 - val_KL loss: 495.4172 - val_beta: 2.5119e-05\n",
      "Epoch 4852/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 302049.6046 - recon_loss: 1.9027e-04 - KL loss: 498.6395 - beta: 2.5119e-05 - val_loss: 308966.4062 - val_recon_loss: 1.9463e-04 - val_KL loss: 503.8558 - val_beta: 2.5119e-05\n",
      "Epoch 4853/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 302632.0548 - recon_loss: 1.9063e-04 - KL loss: 505.9539 - beta: 2.5119e-05 - val_loss: 310994.3750 - val_recon_loss: 1.9591e-04 - val_KL loss: 504.2632 - val_beta: 2.5119e-05\n",
      "Epoch 4854/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 305516.9282 - recon_loss: 1.9245e-04 - KL loss: 511.2031 - beta: 2.5119e-05 - val_loss: 346443.6875 - val_recon_loss: 2.1827e-04 - val_KL loss: 508.4036 - val_beta: 2.5119e-05\n",
      "Epoch 4855/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 299940.3926 - recon_loss: 1.8893e-04 - KL loss: 511.3579 - beta: 2.5119e-05 - val_loss: 349168.0625 - val_recon_loss: 2.1998e-04 - val_KL loss: 516.3563 - val_beta: 2.5119e-05\n",
      "Epoch 4856/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 306947.4985 - recon_loss: 1.9335e-04 - KL loss: 511.2981 - beta: 2.5119e-05 - val_loss: 345287.4375 - val_recon_loss: 2.1755e-04 - val_KL loss: 501.6437 - val_beta: 2.5119e-05\n",
      "Epoch 4857/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 305668.6310 - recon_loss: 1.9254e-04 - KL loss: 514.6524 - beta: 2.5119e-05\n",
      "Epoch 04857: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 305660.6818 - recon_loss: 1.9253e-04 - KL loss: 514.6430 - beta: 2.5119e-05 - val_loss: 315416.6875 - val_recon_loss: 1.9870e-04 - val_KL loss: 502.1935 - val_beta: 2.5119e-05\n",
      "Epoch 4858/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 294099.7487 - recon_loss: 1.8525e-04 - KL loss: 505.7390 - beta: 2.5119e-05 - val_loss: 315351.4375 - val_recon_loss: 1.9866e-04 - val_KL loss: 503.6121 - val_beta: 2.5119e-05\n",
      "Epoch 4859/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 293378.5348 - recon_loss: 1.8479e-04 - KL loss: 504.7811 - beta: 2.5119e-05 - val_loss: 313951.0938 - val_recon_loss: 1.9777e-04 - val_KL loss: 510.9001 - val_beta: 2.5119e-05\n",
      "Epoch 4860/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 286819.0850 - recon_loss: 1.8065e-04 - KL loss: 505.2663 - beta: 2.5119e-05 - val_loss: 310283.6250 - val_recon_loss: 1.9546e-04 - val_KL loss: 501.8993 - val_beta: 2.5119e-05\n",
      "Epoch 4861/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 288960.8975 - recon_loss: 1.8200e-04 - KL loss: 503.4588 - beta: 2.5119e-05 - val_loss: 321278.7500 - val_recon_loss: 2.0240e-04 - val_KL loss: 499.8526 - val_beta: 2.5119e-05\n",
      "Epoch 4862/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 291077.6964 - recon_loss: 1.8334e-04 - KL loss: 502.9642 - beta: 2.5119e-05\n",
      "Epoch 04862: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 291075.4720 - recon_loss: 1.8334e-04 - KL loss: 502.9639 - beta: 2.5119e-05 - val_loss: 318111.1250 - val_recon_loss: 2.0040e-04 - val_KL loss: 502.9976 - val_beta: 2.5119e-05\n",
      "Epoch 4862/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 119740.0878 - recon_loss: 1.8900e-04 - KL loss: 488.4304 - beta: 3.9811e-05 - val_loss: 124093.3359 - val_recon_loss: 1.9595e-04 - val_KL loss: 456.5106 - val_beta: 3.9811e-05\n",
      "Epoch 4863/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 127736.9807 - recon_loss: 2.0173e-04 - KL loss: 451.4317 - beta: 3.9811e-05 - val_loss: 124863.5547 - val_recon_loss: 1.9720e-04 - val_KL loss: 440.5974 - val_beta: 3.9811e-05\n",
      "Epoch 4864/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 128489.8045 - recon_loss: 2.0295e-04 - KL loss: 438.3725 - beta: 3.9811e-05 - val_loss: 170949.6250 - val_recon_loss: 2.7020e-04 - val_KL loss: 466.4326 - val_beta: 3.9811e-05\n",
      "Epoch 4865/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 146263.8524 - recon_loss: 2.3111e-04 - KL loss: 446.4407 - beta: 3.9811e-05 - val_loss: 141470.9531 - val_recon_loss: 2.2357e-04 - val_KL loss: 408.5094 - val_beta: 3.9811e-05\n",
      "Epoch 4866/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 131246.7210 - recon_loss: 2.0736e-04 - KL loss: 412.0040 - beta: 3.9811e-05 - val_loss: 130072.6250 - val_recon_loss: 2.0548e-04 - val_KL loss: 425.8292 - val_beta: 3.9811e-05\n",
      "Epoch 4867/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 130958.3046 - recon_loss: 2.0688e-04 - KL loss: 428.9882 - beta: 3.9811e-05\n",
      "Epoch 04867: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 130956.8131 - recon_loss: 2.0687e-04 - KL loss: 428.9858 - beta: 3.9811e-05 - val_loss: 128502.4844 - val_recon_loss: 2.0298e-04 - val_KL loss: 428.0160 - val_beta: 3.9811e-05\n",
      "Epoch 4868/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 121805.1865 - recon_loss: 1.9237e-04 - KL loss: 427.5448 - beta: 3.9811e-05 - val_loss: 124421.8438 - val_recon_loss: 1.9651e-04 - val_KL loss: 434.7772 - val_beta: 3.9811e-05\n",
      "Epoch 4869/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 119071.4824 - recon_loss: 1.8803e-04 - KL loss: 435.1293 - beta: 3.9811e-05 - val_loss: 149889.2344 - val_recon_loss: 2.3686e-04 - val_KL loss: 441.0939 - val_beta: 3.9811e-05\n",
      "Epoch 4870/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 120507.9891 - recon_loss: 1.9029e-04 - KL loss: 441.2681 - beta: 3.9811e-05 - val_loss: 123143.0078 - val_recon_loss: 1.9448e-04 - val_KL loss: 433.5724 - val_beta: 3.9811e-05\n",
      "Epoch 4871/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 118895.2616 - recon_loss: 1.8774e-04 - KL loss: 438.6100 - beta: 3.9811e-05 - val_loss: 129346.4688 - val_recon_loss: 2.0432e-04 - val_KL loss: 431.8941 - val_beta: 3.9811e-05\n",
      "Epoch 4872/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 118815.8498 - recon_loss: 1.8762e-04 - KL loss: 435.8020 - beta: 3.9811e-05 - val_loss: 122914.8672 - val_recon_loss: 1.9413e-04 - val_KL loss: 426.9263 - val_beta: 3.9811e-05\n",
      "Epoch 4873/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 117190.3526 - recon_loss: 1.8505e-04 - KL loss: 431.9424 - beta: 3.9811e-05 - val_loss: 121700.9297 - val_recon_loss: 1.9221e-04 - val_KL loss: 424.8730 - val_beta: 3.9811e-05\n",
      "Epoch 4874/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 118384.3189 - recon_loss: 1.8694e-04 - KL loss: 431.6378 - beta: 3.9811e-05 - val_loss: 122448.0859 - val_recon_loss: 1.9338e-04 - val_KL loss: 433.8471 - val_beta: 3.9811e-05\n",
      "Epoch 4875/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 120461.0844 - recon_loss: 1.9023e-04 - KL loss: 435.4544 - beta: 3.9811e-05 - val_loss: 126491.5781 - val_recon_loss: 1.9980e-04 - val_KL loss: 426.9670 - val_beta: 3.9811e-05\n",
      "Epoch 4876/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 121795.3209 - recon_loss: 1.9234e-04 - KL loss: 435.8437 - beta: 3.9811e-05 - val_loss: 128475.9297 - val_recon_loss: 2.0293e-04 - val_KL loss: 437.3589 - val_beta: 3.9811e-05\n",
      "Epoch 4877/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 119054.6279 - recon_loss: 1.8799e-04 - KL loss: 440.8480 - beta: 3.9811e-05 - val_loss: 124005.7344 - val_recon_loss: 1.9583e-04 - val_KL loss: 447.1341 - val_beta: 3.9811e-05\n",
      "Epoch 4878/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 123545.5376 - recon_loss: 1.9509e-04 - KL loss: 449.3604 - beta: 3.9811e-05 - val_loss: 121635.6797 - val_recon_loss: 1.9207e-04 - val_KL loss: 445.6048 - val_beta: 3.9811e-05\n",
      "Epoch 4879/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 120595.8597 - recon_loss: 1.9042e-04 - KL loss: 446.1990 - beta: 3.9811e-05 - val_loss: 132937.9531 - val_recon_loss: 2.0997e-04 - val_KL loss: 455.6156 - val_beta: 3.9811e-05\n",
      "Epoch 4880/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 122699.8215 - recon_loss: 1.9374e-04 - KL loss: 456.9895 - beta: 3.9811e-05 - val_loss: 122702.0156 - val_recon_loss: 1.9375e-04 - val_KL loss: 455.1198 - val_beta: 3.9811e-05\n",
      "Epoch 4881/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 118915.4612 - recon_loss: 1.8775e-04 - KL loss: 451.1097 - beta: 3.9811e-05 - val_loss: 123848.3828 - val_recon_loss: 1.9557e-04 - val_KL loss: 455.1479 - val_beta: 3.9811e-05\n",
      "Epoch 4882/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 119231.3952 - recon_loss: 1.8825e-04 - KL loss: 451.7457 - beta: 3.9811e-05 - val_loss: 130443.9375 - val_recon_loss: 2.0601e-04 - val_KL loss: 463.2244 - val_beta: 3.9811e-05\n",
      "Epoch 4883/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 120999.6819 - recon_loss: 1.9105e-04 - KL loss: 458.2139 - beta: 3.9811e-05\n",
      "Epoch 04883: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 121000.6769 - recon_loss: 1.9105e-04 - KL loss: 458.2132 - beta: 3.9811e-05 - val_loss: 128384.1875 - val_recon_loss: 2.0274e-04 - val_KL loss: 460.8683 - val_beta: 3.9811e-05\n",
      "Epoch 4884/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 120533.3380 - recon_loss: 1.9031e-04 - KL loss: 455.8037 - beta: 3.9811e-05 - val_loss: 126721.2891 - val_recon_loss: 2.0012e-04 - val_KL loss: 456.8743 - val_beta: 3.9811e-05\n",
      "Epoch 4885/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 116958.6402 - recon_loss: 1.8465e-04 - KL loss: 454.3552 - beta: 3.9811e-05 - val_loss: 128371.6016 - val_recon_loss: 2.0273e-04 - val_KL loss: 455.6385 - val_beta: 3.9811e-05\n",
      "Epoch 4886/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 114979.1397 - recon_loss: 1.8151e-04 - KL loss: 453.2707 - beta: 3.9811e-05 - val_loss: 120300.3281 - val_recon_loss: 1.8995e-04 - val_KL loss: 453.0953 - val_beta: 3.9811e-05\n",
      "Epoch 4887/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 115195.5292 - recon_loss: 1.8186e-04 - KL loss: 450.7664 - beta: 3.9811e-05 - val_loss: 119556.7969 - val_recon_loss: 1.8877e-04 - val_KL loss: 449.8030 - val_beta: 3.9811e-05\n",
      "Epoch 4888/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 116188.6658 - recon_loss: 1.8343e-04 - KL loss: 449.0776 - beta: 3.9811e-05 - val_loss: 120380.5312 - val_recon_loss: 1.9008e-04 - val_KL loss: 448.3686 - val_beta: 3.9811e-05\n",
      "Epoch 4889/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 114115.1731 - recon_loss: 1.8015e-04 - KL loss: 447.4535 - beta: 3.9811e-05 - val_loss: 118428.0547 - val_recon_loss: 1.8699e-04 - val_KL loss: 447.1594 - val_beta: 3.9811e-05\n",
      "Epoch 4890/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 115765.6136 - recon_loss: 1.8276e-04 - KL loss: 449.7951 - beta: 3.9811e-05 - val_loss: 120785.1953 - val_recon_loss: 1.9072e-04 - val_KL loss: 448.6963 - val_beta: 3.9811e-05\n",
      "Epoch 4891/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 115117.2214 - recon_loss: 1.8174e-04 - KL loss: 449.1120 - beta: 3.9811e-05 - val_loss: 118381.6641 - val_recon_loss: 1.8691e-04 - val_KL loss: 448.2691 - val_beta: 3.9811e-05\n",
      "Epoch 4892/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 114919.9282 - recon_loss: 1.8143e-04 - KL loss: 448.2312 - beta: 3.9811e-05 - val_loss: 120093.4062 - val_recon_loss: 1.8962e-04 - val_KL loss: 448.2740 - val_beta: 3.9811e-05\n",
      "Epoch 4893/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 113803.0823 - recon_loss: 1.7965e-04 - KL loss: 448.9023 - beta: 3.9811e-05 - val_loss: 117787.8672 - val_recon_loss: 1.8597e-04 - val_KL loss: 448.3921 - val_beta: 3.9811e-05\n",
      "Epoch 4894/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 114713.3215 - recon_loss: 1.8110e-04 - KL loss: 449.2645 - beta: 3.9811e-05 - val_loss: 118018.1953 - val_recon_loss: 1.8634e-04 - val_KL loss: 448.2365 - val_beta: 3.9811e-05\n",
      "Epoch 4895/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 115297.2103 - recon_loss: 1.8202e-04 - KL loss: 447.8106 - beta: 3.9811e-05 - val_loss: 120321.3281 - val_recon_loss: 1.8998e-04 - val_KL loss: 453.5728 - val_beta: 3.9811e-05\n",
      "Epoch 4896/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 114059.6237 - recon_loss: 1.8006e-04 - KL loss: 452.2005 - beta: 3.9811e-05 - val_loss: 118518.5859 - val_recon_loss: 1.8712e-04 - val_KL loss: 454.3484 - val_beta: 3.9811e-05\n",
      "Epoch 4897/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 114002.9520 - recon_loss: 1.7996e-04 - KL loss: 455.0656 - beta: 3.9811e-05 - val_loss: 117855.4609 - val_recon_loss: 1.8607e-04 - val_KL loss: 451.2716 - val_beta: 3.9811e-05\n",
      "Epoch 4898/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 113466.6987 - recon_loss: 1.7912e-04 - KL loss: 450.1423 - beta: 3.9811e-05 - val_loss: 117031.8203 - val_recon_loss: 1.8477e-04 - val_KL loss: 452.9529 - val_beta: 3.9811e-05\n",
      "Epoch 4899/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 113891.4350 - recon_loss: 1.7979e-04 - KL loss: 452.6895 - beta: 3.9811e-05 - val_loss: 117385.3281 - val_recon_loss: 1.8533e-04 - val_KL loss: 451.7014 - val_beta: 3.9811e-05\n",
      "Epoch 4900/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 113782.7134 - recon_loss: 1.7962e-04 - KL loss: 451.7522 - beta: 3.9811e-05 - val_loss: 117229.5469 - val_recon_loss: 1.8508e-04 - val_KL loss: 452.7690 - val_beta: 3.9811e-05\n",
      "Epoch 4901/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 113339.2831 - recon_loss: 1.7891e-04 - KL loss: 452.5402 - beta: 3.9811e-05 - val_loss: 117183.6328 - val_recon_loss: 1.8501e-04 - val_KL loss: 448.8385 - val_beta: 3.9811e-05\n",
      "Epoch 4902/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 112637.1800 - recon_loss: 1.7781e-04 - KL loss: 449.1974 - beta: 3.9811e-05 - val_loss: 116451.5781 - val_recon_loss: 1.8385e-04 - val_KL loss: 448.5983 - val_beta: 3.9811e-05\n",
      "Epoch 4903/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 112027.4723 - recon_loss: 1.7684e-04 - KL loss: 450.2807 - beta: 3.9811e-05 - val_loss: 116371.8516 - val_recon_loss: 1.8372e-04 - val_KL loss: 452.8374 - val_beta: 3.9811e-05\n",
      "Epoch 4904/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 114979.7762 - recon_loss: 1.8151e-04 - KL loss: 452.4236 - beta: 3.9811e-05 - val_loss: 116613.1484 - val_recon_loss: 1.8410e-04 - val_KL loss: 452.5413 - val_beta: 3.9811e-05\n",
      "Epoch 4905/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 112739.9455 - recon_loss: 1.7797e-04 - KL loss: 450.8372 - beta: 3.9811e-05 - val_loss: 116972.0469 - val_recon_loss: 1.8468e-04 - val_KL loss: 449.5082 - val_beta: 3.9811e-05\n",
      "Epoch 4906/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 114519.0053 - recon_loss: 1.8079e-04 - KL loss: 449.6944 - beta: 3.9811e-05 - val_loss: 116497.6562 - val_recon_loss: 1.8393e-04 - val_KL loss: 445.5023 - val_beta: 3.9811e-05\n",
      "Epoch 4907/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 112858.0745 - recon_loss: 1.7816e-04 - KL loss: 447.4700 - beta: 3.9811e-05 - val_loss: 116741.9453 - val_recon_loss: 1.8431e-04 - val_KL loss: 449.7014 - val_beta: 3.9811e-05\n",
      "Epoch 4908/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 112520.2167 - recon_loss: 1.7762e-04 - KL loss: 449.2769 - beta: 3.9811e-05\n",
      "Epoch 04908: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 112520.7780 - recon_loss: 1.7762e-04 - KL loss: 449.2770 - beta: 3.9811e-05 - val_loss: 118740.8672 - val_recon_loss: 1.8748e-04 - val_KL loss: 450.8786 - val_beta: 3.9811e-05\n",
      "Epoch 4909/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 113117.8135 - recon_loss: 1.7856e-04 - KL loss: 452.2817 - beta: 3.9811e-05 - val_loss: 116937.5000 - val_recon_loss: 1.8462e-04 - val_KL loss: 452.4878 - val_beta: 3.9811e-05\n",
      "Epoch 4910/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 112734.5603 - recon_loss: 1.7796e-04 - KL loss: 452.3740 - beta: 3.9811e-05 - val_loss: 118146.4375 - val_recon_loss: 1.8653e-04 - val_KL loss: 451.2486 - val_beta: 3.9811e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4911/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 113790.3809 - recon_loss: 1.7963e-04 - KL loss: 451.5742 - beta: 3.9811e-05 - val_loss: 117725.0078 - val_recon_loss: 1.8586e-04 - val_KL loss: 454.0622 - val_beta: 3.9811e-05\n",
      "Epoch 4912/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 114091.4468 - recon_loss: 1.8010e-04 - KL loss: 453.5145 - beta: 3.9811e-05 - val_loss: 118394.1953 - val_recon_loss: 1.8693e-04 - val_KL loss: 452.1983 - val_beta: 3.9811e-05\n",
      "Epoch 4913/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 113082.6640 - recon_loss: 1.7851e-04 - KL loss: 452.3455 - beta: 3.9811e-05\n",
      "Epoch 04913: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 113082.4355 - recon_loss: 1.7851e-04 - KL loss: 452.3455 - beta: 3.9811e-05 - val_loss: 118598.9219 - val_recon_loss: 1.8725e-04 - val_KL loss: 452.4116 - val_beta: 3.9811e-05\n",
      "Epoch 4913/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 47127.3169 - recon_loss: 1.8588e-04 - KL loss: 435.2951 - beta: 6.3096e-05 - val_loss: 49878.7070 - val_recon_loss: 1.9701e-04 - val_KL loss: 390.9398 - val_beta: 6.3096e-05\n",
      "Epoch 4914/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 48726.3412 - recon_loss: 1.9241e-04 - KL loss: 394.8335 - beta: 6.3096e-05 - val_loss: 50432.5625 - val_recon_loss: 1.9928e-04 - val_KL loss: 375.2131 - val_beta: 6.3096e-05\n",
      "Epoch 4915/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 48583.3034 - recon_loss: 1.9191e-04 - KL loss: 376.9890 - beta: 6.3096e-05 - val_loss: 53210.5664 - val_recon_loss: 2.1031e-04 - val_KL loss: 383.4550 - val_beta: 6.3096e-05\n",
      "Epoch 4916/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 50265.2625 - recon_loss: 1.9865e-04 - KL loss: 366.8684 - beta: 6.3096e-05 - val_loss: 55921.1172 - val_recon_loss: 2.2117e-04 - val_KL loss: 364.9048 - val_beta: 6.3096e-05\n",
      "Epoch 4917/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 49449.9542 - recon_loss: 1.9539e-04 - KL loss: 370.2162 - beta: 6.3096e-05 - val_loss: 51813.4766 - val_recon_loss: 2.0485e-04 - val_KL loss: 357.8033 - val_beta: 6.3096e-05\n",
      "Epoch 4918/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 50059.2853 - recon_loss: 1.9784e-04 - KL loss: 364.2068 - beta: 6.3096e-05\n",
      "Epoch 04918: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 50060.0240 - recon_loss: 1.9784e-04 - KL loss: 364.1892 - beta: 6.3096e-05 - val_loss: 52268.3008 - val_recon_loss: 2.0671e-04 - val_KL loss: 345.6737 - val_beta: 6.3096e-05\n",
      "Epoch 4919/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 48814.6186 - recon_loss: 1.9294e-04 - KL loss: 351.4667 - beta: 6.3096e-05 - val_loss: 49864.3516 - val_recon_loss: 1.9709e-04 - val_KL loss: 358.7680 - val_beta: 6.3096e-05\n",
      "Epoch 4920/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 47226.3086 - recon_loss: 1.8658e-04 - KL loss: 360.6125 - beta: 6.3096e-05 - val_loss: 48911.8242 - val_recon_loss: 1.9328e-04 - val_KL loss: 362.6105 - val_beta: 6.3096e-05\n",
      "Epoch 4921/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 47154.1860 - recon_loss: 1.8626e-04 - KL loss: 367.4383 - beta: 6.3096e-05 - val_loss: 49669.6016 - val_recon_loss: 1.9629e-04 - val_KL loss: 364.9008 - val_beta: 6.3096e-05\n",
      "Epoch 4922/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 46102.0267 - recon_loss: 1.8209e-04 - KL loss: 362.7724 - beta: 6.3096e-05 - val_loss: 49191.1289 - val_recon_loss: 1.9437e-04 - val_KL loss: 366.5562 - val_beta: 6.3096e-05\n",
      "Epoch 4923/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 46248.2197 - recon_loss: 1.8266e-04 - KL loss: 365.0769 - beta: 6.3096e-05 - val_loss: 48115.7266 - val_recon_loss: 1.9013e-04 - val_KL loss: 356.3354 - val_beta: 6.3096e-05\n",
      "Epoch 4924/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 45684.2197 - recon_loss: 1.8043e-04 - KL loss: 361.7580 - beta: 6.3096e-05 - val_loss: 53598.5156 - val_recon_loss: 2.1192e-04 - val_KL loss: 365.6773 - val_beta: 6.3096e-05\n",
      "Epoch 4925/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 47636.7986 - recon_loss: 1.8814e-04 - KL loss: 379.1405 - beta: 6.3096e-05 - val_loss: 48998.1055 - val_recon_loss: 1.9360e-04 - val_KL loss: 366.9156 - val_beta: 6.3096e-05\n",
      "Epoch 4926/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 46516.7088 - recon_loss: 1.8376e-04 - KL loss: 358.9202 - beta: 6.3096e-05 - val_loss: 51646.1562 - val_recon_loss: 2.0417e-04 - val_KL loss: 361.2196 - val_beta: 6.3096e-05\n",
      "Epoch 4927/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 45725.6165 - recon_loss: 1.8060e-04 - KL loss: 361.8194 - beta: 6.3096e-05 - val_loss: 49939.9453 - val_recon_loss: 1.9737e-04 - val_KL loss: 362.4505 - val_beta: 6.3096e-05\n",
      "Epoch 4928/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 46369.4068 - recon_loss: 1.8315e-04 - KL loss: 363.5039 - beta: 6.3096e-05\n",
      "Epoch 04928: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 46369.2136 - recon_loss: 1.8315e-04 - KL loss: 363.5044 - beta: 6.3096e-05 - val_loss: 55210.0859 - val_recon_loss: 2.1838e-04 - val_KL loss: 355.5184 - val_beta: 6.3096e-05\n",
      "Epoch 4929/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 45183.5667 - recon_loss: 1.7845e-04 - KL loss: 359.7274 - beta: 6.3096e-05 - val_loss: 52625.3047 - val_recon_loss: 2.0806e-04 - val_KL loss: 362.7365 - val_beta: 6.3096e-05\n",
      "Epoch 4930/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 44993.6211 - recon_loss: 1.7766e-04 - KL loss: 366.2048 - beta: 6.3096e-05 - val_loss: 49447.6406 - val_recon_loss: 1.9542e-04 - val_KL loss: 360.4429 - val_beta: 6.3096e-05\n",
      "Epoch 4931/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 44824.4818 - recon_loss: 1.7700e-04 - KL loss: 364.3959 - beta: 6.3096e-05 - val_loss: 47865.1094 - val_recon_loss: 1.8909e-04 - val_KL loss: 367.9501 - val_beta: 6.3096e-05\n",
      "Epoch 4932/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 44881.9035 - recon_loss: 1.7722e-04 - KL loss: 367.4813 - beta: 6.3096e-05 - val_loss: 47568.4570 - val_recon_loss: 1.8791e-04 - val_KL loss: 367.2389 - val_beta: 6.3096e-05\n",
      "Epoch 4933/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 45083.6365 - recon_loss: 1.7801e-04 - KL loss: 369.9833 - beta: 6.3096e-05 - val_loss: 47574.4922 - val_recon_loss: 1.8793e-04 - val_KL loss: 369.0121 - val_beta: 6.3096e-05\n",
      "Epoch 4934/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 44952.6000 - recon_loss: 1.7748e-04 - KL loss: 370.9810 - beta: 6.3096e-05 - val_loss: 47740.0430 - val_recon_loss: 1.8855e-04 - val_KL loss: 378.6784 - val_beta: 6.3096e-05\n",
      "Epoch 4935/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 45391.9033 - recon_loss: 1.7921e-04 - KL loss: 377.0502 - beta: 6.3096e-05 - val_loss: 47024.1875 - val_recon_loss: 1.8573e-04 - val_KL loss: 370.4509 - val_beta: 6.3096e-05\n",
      "Epoch 4936/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44751.6729 - recon_loss: 1.7668e-04 - KL loss: 370.4862 - beta: 6.3096e-05 - val_loss: 47370.6758 - val_recon_loss: 1.8712e-04 - val_KL loss: 368.9816 - val_beta: 6.3096e-05\n",
      "Epoch 4937/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 44757.0764 - recon_loss: 1.7672e-04 - KL loss: 368.0928 - beta: 6.3096e-05 - val_loss: 46282.5547 - val_recon_loss: 1.8279e-04 - val_KL loss: 367.6451 - val_beta: 6.3096e-05\n",
      "Epoch 4938/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 44417.3072 - recon_loss: 1.7536e-04 - KL loss: 369.5305 - beta: 6.3096e-05 - val_loss: 47782.6133 - val_recon_loss: 1.8876e-04 - val_KL loss: 367.4099 - val_beta: 6.3096e-05\n",
      "Epoch 4939/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 44207.6420 - recon_loss: 1.7453e-04 - KL loss: 368.0998 - beta: 6.3096e-05 - val_loss: 46276.7695 - val_recon_loss: 1.8276e-04 - val_KL loss: 369.3520 - val_beta: 6.3096e-05\n",
      "Epoch 4940/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 44195.5397 - recon_loss: 1.7447e-04 - KL loss: 371.0791 - beta: 6.3096e-05 - val_loss: 47718.5820 - val_recon_loss: 1.8849e-04 - val_KL loss: 372.5689 - val_beta: 6.3096e-05\n",
      "Epoch 4941/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44599.6839 - recon_loss: 1.7607e-04 - KL loss: 372.6840 - beta: 6.3096e-05 - val_loss: 47715.7773 - val_recon_loss: 1.8849e-04 - val_KL loss: 369.8532 - val_beta: 6.3096e-05\n",
      "Epoch 4942/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 44753.9314 - recon_loss: 1.7669e-04 - KL loss: 371.5928 - beta: 6.3096e-05 - val_loss: 47584.4141 - val_recon_loss: 1.8799e-04 - val_KL loss: 362.2124 - val_beta: 6.3096e-05\n",
      "Epoch 4943/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 43965.0463 - recon_loss: 1.7357e-04 - KL loss: 365.2022 - beta: 6.3096e-05 - val_loss: 50217.6211 - val_recon_loss: 1.9848e-04 - val_KL loss: 360.8754 - val_beta: 6.3096e-05\n",
      "Epoch 4944/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 44790.6193 - recon_loss: 1.7686e-04 - KL loss: 365.5589 - beta: 6.3096e-05\n",
      "Epoch 04944: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 44790.2932 - recon_loss: 1.7686e-04 - KL loss: 365.5582 - beta: 6.3096e-05 - val_loss: 49861.5547 - val_recon_loss: 1.9704e-04 - val_KL loss: 366.5406 - val_beta: 6.3096e-05\n",
      "Epoch 4945/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44249.0823 - recon_loss: 1.7469e-04 - KL loss: 370.0974 - beta: 6.3096e-05 - val_loss: 52190.3398 - val_recon_loss: 2.0632e-04 - val_KL loss: 365.3207 - val_beta: 6.3096e-05\n",
      "Epoch 4946/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 43640.2200 - recon_loss: 1.7227e-04 - KL loss: 368.8054 - beta: 6.3096e-05 - val_loss: 47768.2188 - val_recon_loss: 1.8873e-04 - val_KL loss: 361.2113 - val_beta: 6.3096e-05\n",
      "Epoch 4947/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 43852.1814 - recon_loss: 1.7312e-04 - KL loss: 366.2614 - beta: 6.3096e-05 - val_loss: 47079.1250 - val_recon_loss: 1.8598e-04 - val_KL loss: 363.2119 - val_beta: 6.3096e-05\n",
      "Epoch 4948/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44024.5753 - recon_loss: 1.7380e-04 - KL loss: 368.2201 - beta: 6.3096e-05 - val_loss: 46971.4766 - val_recon_loss: 1.8555e-04 - val_KL loss: 363.3960 - val_beta: 6.3096e-05\n",
      "Epoch 4949/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 43963.4009 - recon_loss: 1.7356e-04 - KL loss: 367.6346 - beta: 6.3096e-05\n",
      "Epoch 04949: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 43963.2135 - recon_loss: 1.7356e-04 - KL loss: 367.6345 - beta: 6.3096e-05 - val_loss: 46529.9609 - val_recon_loss: 1.8379e-04 - val_KL loss: 363.4100 - val_beta: 6.3096e-05\n",
      "Epoch 4949/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18810.3349 - recon_loss: 1.8467e-04 - KL loss: 343.5567 - beta: 1.0000e-04 - val_loss: 24863.1328 - val_recon_loss: 2.4506e-04 - val_KL loss: 357.5376 - val_beta: 1.0000e-04\n",
      "Epoch 4950/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21246.0409 - recon_loss: 2.0927e-04 - KL loss: 318.6507 - beta: 1.0000e-04 - val_loss: 21522.7383 - val_recon_loss: 2.1226e-04 - val_KL loss: 296.2730 - val_beta: 1.0000e-04\n",
      "Epoch 4951/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 22067.8319 - recon_loss: 2.1794e-04 - KL loss: 273.3354 - beta: 1.0000e-04 - val_loss: 21291.0430 - val_recon_loss: 2.1003e-04 - val_KL loss: 287.6378 - val_beta: 1.0000e-04\n",
      "Epoch 4952/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20139.1577 - recon_loss: 1.9844e-04 - KL loss: 294.9254 - beta: 1.0000e-04 - val_loss: 21623.8477 - val_recon_loss: 2.1334e-04 - val_KL loss: 289.8250 - val_beta: 1.0000e-04\n",
      "Epoch 4953/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 19967.0438 - recon_loss: 1.9682e-04 - KL loss: 284.9011 - beta: 1.0000e-04 - val_loss: 22256.8984 - val_recon_loss: 2.1983e-04 - val_KL loss: 274.0008 - val_beta: 1.0000e-04\n",
      "Epoch 4954/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 19736.1888 - recon_loss: 1.9454e-04 - KL loss: 281.7717 - beta: 1.0000e-04 - val_loss: 20163.6543 - val_recon_loss: 1.9889e-04 - val_KL loss: 274.6910 - val_beta: 1.0000e-04\n",
      "Epoch 4955/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 19771.8267 - recon_loss: 1.9496e-04 - KL loss: 276.2582 - beta: 1.0000e-04 - val_loss: 20236.5371 - val_recon_loss: 1.9960e-04 - val_KL loss: 276.8214 - val_beta: 1.0000e-04\n",
      "Epoch 4956/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 19505.7955 - recon_loss: 1.9228e-04 - KL loss: 277.7598 - beta: 1.0000e-04 - val_loss: 21897.3301 - val_recon_loss: 2.1611e-04 - val_KL loss: 286.5614 - val_beta: 1.0000e-04\n",
      "Epoch 4957/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 20288.5171 - recon_loss: 2.0007e-04 - KL loss: 281.8144 - beta: 1.0000e-04 - val_loss: 21559.6855 - val_recon_loss: 2.1280e-04 - val_KL loss: 279.5137 - val_beta: 1.0000e-04\n",
      "Epoch 4958/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 20746.3874 - recon_loss: 2.0467e-04 - KL loss: 279.7675 - beta: 1.0000e-04 - val_loss: 25703.5762 - val_recon_loss: 2.5415e-04 - val_KL loss: 288.5700 - val_beta: 1.0000e-04\n",
      "Epoch 4959/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 21178.5103 - recon_loss: 2.0896e-04 - KL loss: 282.8628 - beta: 1.0000e-04\n",
      "Epoch 04959: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 21177.6692 - recon_loss: 2.0895e-04 - KL loss: 282.8526 - beta: 1.0000e-04 - val_loss: 20795.3770 - val_recon_loss: 2.0521e-04 - val_KL loss: 274.7369 - val_beta: 1.0000e-04\n",
      "Epoch 4960/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 19321.4832 - recon_loss: 1.9047e-04 - KL loss: 274.8887 - beta: 1.0000e-04 - val_loss: 20218.9277 - val_recon_loss: 1.9944e-04 - val_KL loss: 275.2381 - val_beta: 1.0000e-04\n",
      "Epoch 4961/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 18587.9415 - recon_loss: 1.8312e-04 - KL loss: 275.7713 - beta: 1.0000e-04 - val_loss: 20248.2188 - val_recon_loss: 1.9972e-04 - val_KL loss: 276.4268 - val_beta: 1.0000e-04\n",
      "Epoch 4962/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 18685.9034 - recon_loss: 1.8411e-04 - KL loss: 275.1384 - beta: 1.0000e-04 - val_loss: 19799.4199 - val_recon_loss: 1.9523e-04 - val_KL loss: 276.2724 - val_beta: 1.0000e-04\n",
      "Epoch 4963/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 18649.6076 - recon_loss: 1.8374e-04 - KL loss: 275.6040 - beta: 1.0000e-04 - val_loss: 20807.5820 - val_recon_loss: 2.0540e-04 - val_KL loss: 267.0826 - val_beta: 1.0000e-04\n",
      "Epoch 4964/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 18359.0996 - recon_loss: 1.8087e-04 - KL loss: 272.2755 - beta: 1.0000e-04 - val_loss: 19993.0898 - val_recon_loss: 1.9722e-04 - val_KL loss: 270.6900 - val_beta: 1.0000e-04\n",
      "Epoch 4965/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18858.5319 - recon_loss: 1.8575e-04 - KL loss: 283.7093 - beta: 1.0000e-04 - val_loss: 21028.5410 - val_recon_loss: 2.0751e-04 - val_KL loss: 277.0995 - val_beta: 1.0000e-04\n",
      "Epoch 4966/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 18648.2095 - recon_loss: 1.8369e-04 - KL loss: 278.9805 - beta: 1.0000e-04 - val_loss: 20347.4609 - val_recon_loss: 2.0073e-04 - val_KL loss: 274.2180 - val_beta: 1.0000e-04\n",
      "Epoch 4967/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 18580.4279 - recon_loss: 1.8301e-04 - KL loss: 279.6592 - beta: 1.0000e-04\n",
      "Epoch 04967: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 18580.3491 - recon_loss: 1.8301e-04 - KL loss: 279.6564 - beta: 1.0000e-04 - val_loss: 20567.3652 - val_recon_loss: 2.0297e-04 - val_KL loss: 269.9067 - val_beta: 1.0000e-04\n",
      "Epoch 4968/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18247.4231 - recon_loss: 1.7976e-04 - KL loss: 271.3207 - beta: 1.0000e-04 - val_loss: 20387.3613 - val_recon_loss: 2.0115e-04 - val_KL loss: 272.2310 - val_beta: 1.0000e-04\n",
      "Epoch 4969/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 17918.9261 - recon_loss: 1.7645e-04 - KL loss: 273.8983 - beta: 1.0000e-04 - val_loss: 19888.0234 - val_recon_loss: 1.9614e-04 - val_KL loss: 273.9198 - val_beta: 1.0000e-04\n",
      "Epoch 4970/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 17890.2209 - recon_loss: 1.7614e-04 - KL loss: 276.3275 - beta: 1.0000e-04 - val_loss: 19924.9961 - val_recon_loss: 1.9651e-04 - val_KL loss: 273.6114 - val_beta: 1.0000e-04\n",
      "Epoch 4971/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 18019.4628 - recon_loss: 1.7743e-04 - KL loss: 276.2503 - beta: 1.0000e-04 - val_loss: 20140.1172 - val_recon_loss: 1.9865e-04 - val_KL loss: 275.5512 - val_beta: 1.0000e-04\n",
      "Epoch 4972/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18080.7036 - recon_loss: 1.7804e-04 - KL loss: 276.6600 - beta: 1.0000e-04\n",
      "Epoch 04972: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18080.6728 - recon_loss: 1.7804e-04 - KL loss: 276.6599 - beta: 1.0000e-04 - val_loss: 19921.2930 - val_recon_loss: 1.9646e-04 - val_KL loss: 275.0182 - val_beta: 1.0000e-04\n",
      "Epoch 4972/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7546.1974 - recon_loss: 1.8324e-04 - KL loss: 251.0867 - beta: 1.5849e-04 - val_loss: 8396.6572 - val_recon_loss: 2.0565e-04 - val_KL loss: 209.4837 - val_beta: 1.5849e-04\n",
      "Epoch 4973/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7850.6772 - recon_loss: 1.9187e-04 - KL loss: 212.2390 - beta: 1.5849e-04 - val_loss: 8652.4658 - val_recon_loss: 2.1216e-04 - val_KL loss: 206.2110 - val_beta: 1.5849e-04\n",
      "Epoch 4974/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 8012.9079 - recon_loss: 1.9608e-04 - KL loss: 206.6851 - beta: 1.5849e-04 - val_loss: 8447.5625 - val_recon_loss: 2.0716e-04 - val_KL loss: 200.5439 - val_beta: 1.5849e-04\n",
      "Epoch 4975/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7823.8889 - recon_loss: 1.9142e-04 - KL loss: 203.2538 - beta: 1.5849e-04 - val_loss: 9491.5078 - val_recon_loss: 2.3347e-04 - val_KL loss: 196.8067 - val_beta: 1.5849e-04\n",
      "Epoch 4976/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 8515.2932 - recon_loss: 2.0874e-04 - KL loss: 205.0313 - beta: 1.5849e-04 - val_loss: 9688.7041 - val_recon_loss: 2.3837e-04 - val_KL loss: 199.1940 - val_beta: 1.5849e-04\n",
      "Epoch 4977/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8803.3219 - recon_loss: 2.1592e-04 - KL loss: 207.5110 - beta: 1.5849e-04\n",
      "Epoch 04977: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 8803.5250 - recon_loss: 2.1592e-04 - KL loss: 207.5083 - beta: 1.5849e-04 - val_loss: 9613.6602 - val_recon_loss: 2.3652e-04 - val_KL loss: 197.4857 - val_beta: 1.5849e-04\n",
      "Epoch 4978/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 8140.5897 - recon_loss: 1.9949e-04 - KL loss: 198.7021 - beta: 1.5849e-04 - val_loss: 10362.8984 - val_recon_loss: 2.5520e-04 - val_KL loss: 203.3297 - val_beta: 1.5849e-04\n",
      "Epoch 4979/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 8148.6386 - recon_loss: 1.9951e-04 - KL loss: 206.0171 - beta: 1.5849e-04 - val_loss: 9032.8877 - val_recon_loss: 2.2174e-04 - val_KL loss: 205.4529 - val_beta: 1.5849e-04\n",
      "Epoch 4980/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7872.5068 - recon_loss: 1.9266e-04 - KL loss: 202.6973 - beta: 1.5849e-04 - val_loss: 9752.4102 - val_recon_loss: 2.3989e-04 - val_KL loss: 202.3325 - val_beta: 1.5849e-04\n",
      "Epoch 4981/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7848.4958 - recon_loss: 1.9217e-04 - KL loss: 198.1070 - beta: 1.5849e-04 - val_loss: 10583.4062 - val_recon_loss: 2.6076e-04 - val_KL loss: 202.5003 - val_beta: 1.5849e-04\n",
      "Epoch 4982/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7812.8250 - recon_loss: 1.9119e-04 - KL loss: 201.3406 - beta: 1.5849e-04\n",
      "Epoch 04982: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7812.8216 - recon_loss: 1.9119e-04 - KL loss: 201.3413 - beta: 1.5849e-04 - val_loss: 9175.4492 - val_recon_loss: 2.2535e-04 - val_KL loss: 204.2305 - val_beta: 1.5849e-04\n",
      "Epoch 4982/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3189.8312 - recon_loss: 1.9031e-04 - KL loss: 173.5636 - beta: 2.5119e-04 - val_loss: 3767.3594 - val_recon_loss: 2.2805e-04 - val_KL loss: 152.9473 - val_beta: 2.5119e-04\n",
      "Epoch 4983/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3193.3687 - recon_loss: 1.9216e-04 - KL loss: 147.8450 - beta: 2.5119e-04 - val_loss: 3833.1052 - val_recon_loss: 2.3245e-04 - val_KL loss: 149.0740 - val_beta: 2.5119e-04\n",
      "Epoch 4984/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3378.0176 - recon_loss: 2.0380e-04 - KL loss: 147.9285 - beta: 2.5119e-04 - val_loss: 3677.8633 - val_recon_loss: 2.2274e-04 - val_KL loss: 147.7037 - val_beta: 2.5119e-04\n",
      "Epoch 4985/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3411.9077 - recon_loss: 2.0605e-04 - KL loss: 146.1938 - beta: 2.5119e-04 - val_loss: 3655.2104 - val_recon_loss: 2.2127e-04 - val_KL loss: 148.2877 - val_beta: 2.5119e-04\n",
      "Epoch 4986/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3232.6262 - recon_loss: 1.9501e-04 - KL loss: 141.9793 - beta: 2.5119e-04 - val_loss: 3650.4116 - val_recon_loss: 2.2154e-04 - val_KL loss: 139.1859 - val_beta: 2.5119e-04\n",
      "Epoch 4987/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3309.2713 - recon_loss: 2.0004e-04 - KL loss: 138.8793 - beta: 2.5119e-04 - val_loss: 3738.1418 - val_recon_loss: 2.2719e-04 - val_KL loss: 137.4188 - val_beta: 2.5119e-04\n",
      "Epoch 4988/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3232.8633 - recon_loss: 1.9557e-04 - KL loss: 133.2155 - beta: 2.5119e-04 - val_loss: 3947.6860 - val_recon_loss: 2.4046e-04 - val_KL loss: 136.7072 - val_beta: 2.5119e-04\n",
      "Epoch 4989/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3221.3060 - recon_loss: 1.9492e-04 - KL loss: 132.0404 - beta: 2.5119e-04 - val_loss: 3725.5554 - val_recon_loss: 2.2657e-04 - val_KL loss: 134.6434 - val_beta: 2.5119e-04\n",
      "Epoch 4990/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3212.9468 - recon_loss: 1.9458e-04 - KL loss: 129.1009 - beta: 2.5119e-04 - val_loss: 3604.2207 - val_recon_loss: 2.1927e-04 - val_KL loss: 128.9487 - val_beta: 2.5119e-04\n",
      "Epoch 4991/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3204.8030 - recon_loss: 1.9419e-04 - KL loss: 127.0916 - beta: 2.5119e-04 - val_loss: 4748.3091 - val_recon_loss: 2.9144e-04 - val_KL loss: 129.3480 - val_beta: 2.5119e-04\n",
      "Epoch 4992/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3303.6259 - recon_loss: 2.0029e-04 - KL loss: 129.2679 - beta: 2.5119e-04 - val_loss: 3431.3198 - val_recon_loss: 2.0828e-04 - val_KL loss: 130.2950 - val_beta: 2.5119e-04\n",
      "Epoch 4993/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3242.5228 - recon_loss: 1.9649e-04 - KL loss: 128.4048 - beta: 2.5119e-04 - val_loss: 3334.5718 - val_recon_loss: 2.0251e-04 - val_KL loss: 125.0427 - val_beta: 2.5119e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4994/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3285.3749 - recon_loss: 1.9940e-04 - KL loss: 125.1723 - beta: 2.5119e-04 - val_loss: 3733.1724 - val_recon_loss: 2.2730e-04 - val_KL loss: 130.7041 - val_beta: 2.5119e-04\n",
      "Epoch 4995/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3271.2386 - recon_loss: 1.9845e-04 - KL loss: 126.0259 - beta: 2.5119e-04 - val_loss: 3897.7947 - val_recon_loss: 2.3716e-04 - val_KL loss: 139.1124 - val_beta: 2.5119e-04\n",
      "Epoch 4996/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3598.0776 - recon_loss: 2.1881e-04 - KL loss: 130.1574 - beta: 2.5119e-04 - val_loss: 4639.3940 - val_recon_loss: 2.8133e-04 - val_KL loss: 180.6015 - val_beta: 2.5119e-04\n",
      "Epoch 4997/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4212.9917 - recon_loss: 2.5685e-04 - KL loss: 142.1896 - beta: 2.5119e-04 - val_loss: 3818.6584 - val_recon_loss: 2.3325e-04 - val_KL loss: 121.8889 - val_beta: 2.5119e-04\n",
      "Epoch 4998/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3475.6801 - recon_loss: 2.1154e-04 - KL loss: 123.0012 - beta: 2.5119e-04\n",
      "Epoch 04998: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3475.6136 - recon_loss: 2.1154e-04 - KL loss: 123.0019 - beta: 2.5119e-04 - val_loss: 4079.1553 - val_recon_loss: 2.4778e-04 - val_KL loss: 152.0516 - val_beta: 2.5119e-04\n",
      "Epoch 4999/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3345.0092 - recon_loss: 2.0276e-04 - KL loss: 131.5202 - beta: 2.5119e-04 - val_loss: 3794.8062 - val_recon_loss: 2.3148e-04 - val_KL loss: 126.1231 - val_beta: 2.5119e-04\n",
      "Epoch 5000/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3147.5400 - recon_loss: 1.9079e-04 - KL loss: 123.6454 - beta: 2.5119e-04 - val_loss: 3495.3193 - val_recon_loss: 2.1274e-04 - val_KL loss: 123.6570 - val_beta: 2.5119e-04\n",
      "Epoch 5001/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3178.3935 - recon_loss: 1.9277e-04 - KL loss: 123.1234 - beta: 2.5119e-04 - val_loss: 3569.9177 - val_recon_loss: 2.1718e-04 - val_KL loss: 127.7915 - val_beta: 2.5119e-04\n",
      "Epoch 5002/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3096.7194 - recon_loss: 1.8753e-04 - KL loss: 124.5588 - beta: 2.5119e-04 - val_loss: 3438.8420 - val_recon_loss: 2.0907e-04 - val_KL loss: 125.2340 - val_beta: 2.5119e-04\n",
      "Epoch 5003/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 3133.3384 - recon_loss: 1.8988e-04 - KL loss: 124.0089 - beta: 2.5119e-04\n",
      "Epoch 05003: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3133.2993 - recon_loss: 1.8987e-04 - KL loss: 124.0108 - beta: 2.5119e-04 - val_loss: 3448.5190 - val_recon_loss: 2.0949e-04 - val_KL loss: 128.3859 - val_beta: 2.5119e-04\n",
      "Epoch 5003/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1309.2846 - recon_loss: 1.9037e-04 - KL loss: 108.1115 - beta: 3.9811e-04 - val_loss: 1392.1265 - val_recon_loss: 2.0460e-04 - val_KL loss: 101.1771 - val_beta: 3.9811e-04\n",
      "Epoch 5004/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1318.9708 - recon_loss: 1.9350e-04 - KL loss: 98.0698 - beta: 3.9811e-04 - val_loss: 1380.5399 - val_recon_loss: 2.0366e-04 - val_KL loss: 95.5475 - val_beta: 3.9811e-04\n",
      "Epoch 5005/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1301.9784 - recon_loss: 1.9129e-04 - KL loss: 95.0069 - beta: 3.9811e-04 - val_loss: 1370.1523 - val_recon_loss: 2.0181e-04 - val_KL loss: 96.7949 - val_beta: 3.9811e-04\n",
      "Epoch 5006/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1319.7136 - recon_loss: 1.9421e-04 - KL loss: 94.3600 - beta: 3.9811e-04 - val_loss: 1460.5165 - val_recon_loss: 2.1678e-04 - val_KL loss: 92.7029 - val_beta: 3.9811e-04\n",
      "Epoch 5007/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1486.8604 - recon_loss: 2.2027e-04 - KL loss: 97.0812 - beta: 3.9811e-04 - val_loss: 1744.9146 - val_recon_loss: 2.6243e-04 - val_KL loss: 89.1211 - val_beta: 3.9811e-04\n",
      "Epoch 5008/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1513.9950 - recon_loss: 2.2534e-04 - KL loss: 92.1987 - beta: 3.9811e-04 - val_loss: 1662.6628 - val_recon_loss: 2.4919e-04 - val_KL loss: 90.3489 - val_beta: 3.9811e-04\n",
      "Epoch 5009/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1428.0453 - recon_loss: 2.1238e-04 - KL loss: 88.0354 - beta: 3.9811e-04 - val_loss: 1531.7047 - val_recon_loss: 2.2829e-04 - val_KL loss: 91.2889 - val_beta: 3.9811e-04\n",
      "Epoch 5010/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1456.9479 - recon_loss: 2.1657e-04 - KL loss: 90.5050 - beta: 3.9811e-04\n",
      "Epoch 05010: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1456.9724 - recon_loss: 2.1657e-04 - KL loss: 90.5054 - beta: 3.9811e-04 - val_loss: 1575.4005 - val_recon_loss: 2.3491e-04 - val_KL loss: 93.2074 - val_beta: 3.9811e-04\n",
      "Epoch 5011/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1376.3191 - recon_loss: 2.0408e-04 - KL loss: 88.6615 - beta: 3.9811e-04 - val_loss: 1500.0120 - val_recon_loss: 2.2307e-04 - val_KL loss: 92.5187 - val_beta: 3.9811e-04\n",
      "Epoch 5012/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1352.4774 - recon_loss: 2.0038e-04 - KL loss: 88.1889 - beta: 3.9811e-04 - val_loss: 1474.3365 - val_recon_loss: 2.1923e-04 - val_KL loss: 91.1135 - val_beta: 3.9811e-04\n",
      "Epoch 5013/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1320.9488 - recon_loss: 1.9541e-04 - KL loss: 87.9736 - beta: 3.9811e-04 - val_loss: 1448.3602 - val_recon_loss: 2.1491e-04 - val_KL loss: 92.3618 - val_beta: 3.9811e-04\n",
      "Epoch 5014/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1311.3024 - recon_loss: 1.9391e-04 - KL loss: 87.8439 - beta: 3.9811e-04 - val_loss: 1473.2220 - val_recon_loss: 2.1843e-04 - val_KL loss: 95.0136 - val_beta: 3.9811e-04\n",
      "Epoch 5015/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1311.6638 - recon_loss: 1.9394e-04 - KL loss: 87.9853 - beta: 3.9811e-04\n",
      "Epoch 05015: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1311.6615 - recon_loss: 1.9394e-04 - KL loss: 87.9847 - beta: 3.9811e-04 - val_loss: 1559.8951 - val_recon_loss: 2.3335e-04 - val_KL loss: 87.5823 - val_beta: 3.9811e-04\n",
      "Epoch 5015/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4153.8031 - recon_loss: 2.5506e-04 - KL loss: 111.3961 - beta: 2.5119e-04 - val_loss: 4197.6519 - val_recon_loss: 2.5735e-04 - val_KL loss: 118.9590 - val_beta: 2.5119e-04\n",
      "Epoch 5016/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3681.2710 - recon_loss: 2.2503e-04 - KL loss: 114.8491 - beta: 2.5119e-04 - val_loss: 3725.6946 - val_recon_loss: 2.2754e-04 - val_KL loss: 119.4727 - val_beta: 2.5119e-04\n",
      "Epoch 5017/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3506.7099 - recon_loss: 2.1419e-04 - KL loss: 112.0430 - beta: 2.5119e-04 - val_loss: 3698.7227 - val_recon_loss: 2.2579e-04 - val_KL loss: 120.1581 - val_beta: 2.5119e-04\n",
      "Epoch 5018/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3601.6418 - recon_loss: 2.1990e-04 - KL loss: 116.4411 - beta: 2.5119e-04 - val_loss: 3971.1951 - val_recon_loss: 2.4344e-04 - val_KL loss: 112.9735 - val_beta: 2.5119e-04\n",
      "Epoch 5019/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3458.9577 - recon_loss: 2.1104e-04 - KL loss: 114.1893 - beta: 2.5119e-04 - val_loss: 3596.7971 - val_recon_loss: 2.1962e-04 - val_KL loss: 116.0067 - val_beta: 2.5119e-04\n",
      "Epoch 5020/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 3442.5086 - recon_loss: 2.0991e-04 - KL loss: 115.5901 - beta: 2.5119e-04 - val_loss: 4160.8145 - val_recon_loss: 2.5484e-04 - val_KL loss: 121.9138 - val_beta: 2.5119e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5021/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3445.4522 - recon_loss: 2.1008e-04 - KL loss: 115.8708 - beta: 2.5119e-04 - val_loss: 3691.2754 - val_recon_loss: 2.2566e-04 - val_KL loss: 114.8256 - val_beta: 2.5119e-04\n",
      "Epoch 5022/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3342.5390 - recon_loss: 2.0369e-04 - KL loss: 114.2060 - beta: 2.5119e-04 - val_loss: 4052.9849 - val_recon_loss: 2.4842e-04 - val_KL loss: 115.7382 - val_beta: 2.5119e-04\n",
      "Epoch 5023/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3514.8704 - recon_loss: 2.1427e-04 - KL loss: 118.9411 - beta: 2.5119e-04 - val_loss: 3841.5249 - val_recon_loss: 2.3513e-04 - val_KL loss: 114.9177 - val_beta: 2.5119e-04\n",
      "Epoch 5024/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 3358.5779 - recon_loss: 2.0463e-04 - KL loss: 115.3546 - beta: 2.5119e-04\n",
      "Epoch 05024: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3358.6035 - recon_loss: 2.0464e-04 - KL loss: 115.3528 - beta: 2.5119e-04 - val_loss: 3759.8110 - val_recon_loss: 2.2995e-04 - val_KL loss: 115.4112 - val_beta: 2.5119e-04\n",
      "Epoch 5025/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3127.5913 - recon_loss: 1.9019e-04 - KL loss: 113.2334 - beta: 2.5119e-04 - val_loss: 3900.8386 - val_recon_loss: 2.3873e-04 - val_KL loss: 117.2158 - val_beta: 2.5119e-04\n",
      "Epoch 5026/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3117.0135 - recon_loss: 1.8945e-04 - KL loss: 114.3986 - beta: 2.5119e-04 - val_loss: 3550.8115 - val_recon_loss: 2.1663e-04 - val_KL loss: 117.4475 - val_beta: 2.5119e-04\n",
      "Epoch 5027/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3108.6132 - recon_loss: 1.8892e-04 - KL loss: 114.4838 - beta: 2.5119e-04 - val_loss: 3578.9294 - val_recon_loss: 2.1848e-04 - val_KL loss: 116.3087 - val_beta: 2.5119e-04\n",
      "Epoch 5028/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3066.0164 - recon_loss: 1.8626e-04 - KL loss: 114.0581 - beta: 2.5119e-04 - val_loss: 3614.9978 - val_recon_loss: 2.2077e-04 - val_KL loss: 116.0073 - val_beta: 2.5119e-04\n",
      "Epoch 5029/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3052.3074 - recon_loss: 1.8537e-04 - KL loss: 114.3957 - beta: 2.5119e-04 - val_loss: 3485.6213 - val_recon_loss: 2.1264e-04 - val_KL loss: 115.4457 - val_beta: 2.5119e-04\n",
      "Epoch 5030/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3042.7572 - recon_loss: 1.8481e-04 - KL loss: 113.6761 - beta: 2.5119e-04 - val_loss: 3521.0293 - val_recon_loss: 2.1458e-04 - val_KL loss: 120.1791 - val_beta: 2.5119e-04\n",
      "Epoch 5031/10000\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 3111.5966 - recon_loss: 1.8902e-04 - KL loss: 115.8036 - beta: 2.5119e-04 - val_loss: 3380.6523 - val_recon_loss: 2.0590e-04 - val_KL loss: 117.4188 - val_beta: 2.5119e-04\n",
      "Epoch 5032/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3013.3733 - recon_loss: 1.8302e-04 - KL loss: 112.6634 - beta: 2.5119e-04 - val_loss: 4069.0293 - val_recon_loss: 2.4934e-04 - val_KL loss: 117.2129 - val_beta: 2.5119e-04\n",
      "Epoch 5033/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3052.9558 - recon_loss: 1.8537e-04 - KL loss: 114.9803 - beta: 2.5119e-04 - val_loss: 3692.8994 - val_recon_loss: 2.2567e-04 - val_KL loss: 116.3212 - val_beta: 2.5119e-04\n",
      "Epoch 5034/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3043.3805 - recon_loss: 1.8490e-04 - KL loss: 112.8512 - beta: 2.5119e-04 - val_loss: 3491.8860 - val_recon_loss: 2.1296e-04 - val_KL loss: 116.7001 - val_beta: 2.5119e-04\n",
      "Epoch 5035/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3065.3170 - recon_loss: 1.8635e-04 - KL loss: 111.8531 - beta: 2.5119e-04 - val_loss: 3517.9128 - val_recon_loss: 2.1488e-04 - val_KL loss: 112.2607 - val_beta: 2.5119e-04\n",
      "Epoch 5036/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 3013.5789 - recon_loss: 1.8314e-04 - KL loss: 111.0174 - beta: 2.5119e-04\n",
      "Epoch 05036: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3013.5364 - recon_loss: 1.8314e-04 - KL loss: 111.0167 - beta: 2.5119e-04 - val_loss: 3498.4377 - val_recon_loss: 2.1364e-04 - val_KL loss: 112.5467 - val_beta: 2.5119e-04\n",
      "Epoch 5037/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2916.7444 - recon_loss: 1.7704e-04 - KL loss: 110.8499 - beta: 2.5119e-04 - val_loss: 3939.9846 - val_recon_loss: 2.4154e-04 - val_KL loss: 111.8063 - val_beta: 2.5119e-04\n",
      "Epoch 5038/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2927.3369 - recon_loss: 1.7770e-04 - KL loss: 110.9566 - beta: 2.5119e-04 - val_loss: 3544.8384 - val_recon_loss: 2.1655e-04 - val_KL loss: 112.6883 - val_beta: 2.5119e-04\n",
      "Epoch 5039/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2920.9561 - recon_loss: 1.7729e-04 - KL loss: 111.0610 - beta: 2.5119e-04 - val_loss: 3400.5452 - val_recon_loss: 2.0752e-04 - val_KL loss: 111.5796 - val_beta: 2.5119e-04\n",
      "Epoch 5040/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2889.1661 - recon_loss: 1.7530e-04 - KL loss: 110.7723 - beta: 2.5119e-04 - val_loss: 3460.6934 - val_recon_loss: 2.1124e-04 - val_KL loss: 112.8144 - val_beta: 2.5119e-04\n",
      "Epoch 5041/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 2926.3659 - recon_loss: 1.7762e-04 - KL loss: 111.3090 - beta: 2.5119e-04 ETA: 0s - loss: 2926.3648 - recon_loss: 1.7762e-04 - KL loss: 111.3077 - beta: 2.\n",
      "Epoch 05041: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2926.3659 - recon_loss: 1.7762e-04 - KL loss: 111.3096 - beta: 2.5119e-04 - val_loss: 3471.2209 - val_recon_loss: 2.1188e-04 - val_KL loss: 113.0709 - val_beta: 2.5119e-04\n",
      "Epoch 5041/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 8686.4471 - recon_loss: 2.1487e-04 - KL loss: 132.2321 - beta: 1.5849e-04 - val_loss: 8893.6523 - val_recon_loss: 2.1977e-04 - val_KL loss: 144.4753 - val_beta: 1.5849e-04\n",
      "Epoch 5042/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7974.7257 - recon_loss: 1.9668e-04 - KL loss: 144.8597 - beta: 1.5849e-04 - val_loss: 8724.8418 - val_recon_loss: 2.1541e-04 - val_KL loss: 149.1530 - val_beta: 1.5849e-04\n",
      "Epoch 5043/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7654.4322 - recon_loss: 1.8867e-04 - KL loss: 143.3973 - beta: 1.5849e-04 - val_loss: 8986.1387 - val_recon_loss: 2.2217e-04 - val_KL loss: 141.5113 - val_beta: 1.5849e-04\n",
      "Epoch 5044/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7977.2024 - recon_loss: 1.9678e-04 - KL loss: 143.1641 - beta: 1.5849e-04 - val_loss: 9680.9795 - val_recon_loss: 2.3946e-04 - val_KL loss: 147.8066 - val_beta: 1.5849e-04\n",
      "Epoch 5045/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 8043.6141 - recon_loss: 1.9846e-04 - KL loss: 142.9170 - beta: 1.5849e-04 - val_loss: 8640.3252 - val_recon_loss: 2.1332e-04 - val_KL loss: 147.8272 - val_beta: 1.5849e-04\n",
      "Epoch 5046/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7835.6206 - recon_loss: 1.9317e-04 - KL loss: 145.5203 - beta: 1.5849e-04 - val_loss: 8862.0781 - val_recon_loss: 2.1909e-04 - val_KL loss: 139.8217 - val_beta: 1.5849e-04\n",
      "Epoch 5047/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7973.1269 - recon_loss: 1.9663e-04 - KL loss: 145.2798 - beta: 1.5849e-04 - val_loss: 8746.7881 - val_recon_loss: 2.1607e-04 - val_KL loss: 144.8339 - val_beta: 1.5849e-04\n",
      "Epoch 5048/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7899.5436 - recon_loss: 1.9478e-04 - KL loss: 145.1906 - beta: 1.5849e-04 - val_loss: 9377.0244 - val_recon_loss: 2.3167e-04 - val_KL loss: 154.1328 - val_beta: 1.5849e-04\n",
      "Epoch 5049/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7847.8486 - recon_loss: 1.9344e-04 - KL loss: 146.8850 - beta: 1.5849e-04 - val_loss: 8914.9785 - val_recon_loss: 2.2023e-04 - val_KL loss: 147.4610 - val_beta: 1.5849e-04\n",
      "Epoch 5050/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7661.4039 - recon_loss: 1.8881e-04 - KL loss: 144.6715 - beta: 1.5849e-04 - val_loss: 8459.3955 - val_recon_loss: 2.0885e-04 - val_KL loss: 145.0128 - val_beta: 1.5849e-04\n",
      "Epoch 5051/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7713.0310 - recon_loss: 1.9013e-04 - KL loss: 143.9724 - beta: 1.5849e-04 - val_loss: 8969.4873 - val_recon_loss: 2.2170e-04 - val_KL loss: 143.6347 - val_beta: 1.5849e-04\n",
      "Epoch 5052/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7596.7835 - recon_loss: 1.8723e-04 - KL loss: 142.9744 - beta: 1.5849e-04 - val_loss: 8578.9385 - val_recon_loss: 2.1184e-04 - val_KL loss: 145.2891 - val_beta: 1.5849e-04\n",
      "Epoch 5053/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7651.1467 - recon_loss: 1.8860e-04 - KL loss: 143.0143 - beta: 1.5849e-04 - val_loss: 8916.8369 - val_recon_loss: 2.2040e-04 - val_KL loss: 142.4208 - val_beta: 1.5849e-04\n",
      "Epoch 5054/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7724.0114 - recon_loss: 1.9046e-04 - KL loss: 141.7094 - beta: 1.5849e-04 - val_loss: 8655.2979 - val_recon_loss: 2.1364e-04 - val_KL loss: 149.9874 - val_beta: 1.5849e-04\n",
      "Epoch 5055/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7914.8805 - recon_loss: 1.9505e-04 - KL loss: 149.8963 - beta: 1.5849e-04\n",
      "Epoch 05055: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7914.8339 - recon_loss: 1.9505e-04 - KL loss: 149.8955 - beta: 1.5849e-04 - val_loss: 8831.9688 - val_recon_loss: 2.1822e-04 - val_KL loss: 144.3701 - val_beta: 1.5849e-04\n",
      "Epoch 5056/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7211.3558 - recon_loss: 1.7747e-04 - KL loss: 146.2556 - beta: 1.5849e-04 - val_loss: 9406.6846 - val_recon_loss: 2.3258e-04 - val_KL loss: 147.3199 - val_beta: 1.5849e-04\n",
      "Epoch 5057/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7191.7823 - recon_loss: 1.7687e-04 - KL loss: 150.3169 - beta: 1.5849e-04 - val_loss: 8741.0400 - val_recon_loss: 2.1566e-04 - val_KL loss: 155.4920 - val_beta: 1.5849e-04\n",
      "Epoch 5058/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7132.1284 - recon_loss: 1.7539e-04 - KL loss: 149.8580 - beta: 1.5849e-04 - val_loss: 8591.4092 - val_recon_loss: 2.1202e-04 - val_KL loss: 150.7345 - val_beta: 1.5849e-04\n",
      "Epoch 5059/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7155.1975 - recon_loss: 1.7601e-04 - KL loss: 148.1121 - beta: 1.5849e-04 - val_loss: 9072.5293 - val_recon_loss: 2.2411e-04 - val_KL loss: 150.5735 - val_beta: 1.5849e-04\n",
      "Epoch 5060/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7154.9407 - recon_loss: 1.7597e-04 - KL loss: 149.4662 - beta: 1.5849e-04 - val_loss: 8058.9019 - val_recon_loss: 1.9860e-04 - val_KL loss: 152.3131 - val_beta: 1.5849e-04\n",
      "Epoch 5061/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7153.3375 - recon_loss: 1.7589e-04 - KL loss: 150.9120 - beta: 1.5849e-04 - val_loss: 8329.9941 - val_recon_loss: 2.0545e-04 - val_KL loss: 150.7253 - val_beta: 1.5849e-04\n",
      "Epoch 5062/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7089.3834 - recon_loss: 1.7434e-04 - KL loss: 148.8420 - beta: 1.5849e-04 - val_loss: 9021.7227 - val_recon_loss: 2.2281e-04 - val_KL loss: 151.4450 - val_beta: 1.5849e-04\n",
      "Epoch 5063/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7219.9280 - recon_loss: 1.7757e-04 - KL loss: 150.5674 - beta: 1.5849e-04 - val_loss: 9300.0781 - val_recon_loss: 2.2957e-04 - val_KL loss: 160.8046 - val_beta: 1.5849e-04\n",
      "Epoch 5064/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7496.6616 - recon_loss: 1.8435e-04 - KL loss: 157.6514 - beta: 1.5849e-04 - val_loss: 8333.5674 - val_recon_loss: 2.0542e-04 - val_KL loss: 155.4955 - val_beta: 1.5849e-04\n",
      "Epoch 5065/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7225.6328 - recon_loss: 1.7761e-04 - KL loss: 154.8072 - beta: 1.5849e-04\n",
      "Epoch 05065: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 7225.6761 - recon_loss: 1.7761e-04 - KL loss: 154.8075 - beta: 1.5849e-04 - val_loss: 8323.1211 - val_recon_loss: 2.0522e-04 - val_KL loss: 153.2806 - val_beta: 1.5849e-04\n",
      "Epoch 5066/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7087.1091 - recon_loss: 1.7415e-04 - KL loss: 154.0264 - beta: 1.5849e-04 - val_loss: 8783.4043 - val_recon_loss: 2.1679e-04 - val_KL loss: 152.8474 - val_beta: 1.5849e-04\n",
      "Epoch 5067/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7026.7332 - recon_loss: 1.7267e-04 - KL loss: 152.7246 - beta: 1.5849e-04 - val_loss: 8123.7461 - val_recon_loss: 2.0021e-04 - val_KL loss: 153.3739 - val_beta: 1.5849e-04\n",
      "Epoch 5068/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6963.2813 - recon_loss: 1.7105e-04 - KL loss: 153.5816 - beta: 1.5849e-04 - val_loss: 8749.0439 - val_recon_loss: 2.1589e-04 - val_KL loss: 154.2492 - val_beta: 1.5849e-04\n",
      "Epoch 5069/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7047.9502 - recon_loss: 1.7315e-04 - KL loss: 154.8980 - beta: 1.5849e-04 - val_loss: 8451.0703 - val_recon_loss: 2.0842e-04 - val_KL loss: 153.7452 - val_beta: 1.5849e-04\n",
      "Epoch 5070/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7025.9741 - recon_loss: 1.7261e-04 - KL loss: 154.3097 - beta: 1.5849e-04\n",
      "Epoch 05070: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7025.9888 - recon_loss: 1.7261e-04 - KL loss: 154.3102 - beta: 1.5849e-04 - val_loss: 9576.9795 - val_recon_loss: 2.3668e-04 - val_KL loss: 154.4751 - val_beta: 1.5849e-04\n",
      "Epoch 5070/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21325.3224 - recon_loss: 2.1150e-04 - KL loss: 175.4371 - beta: 1.0000e-04 - val_loss: 23483.6543 - val_recon_loss: 2.3274e-04 - val_KL loss: 210.0026 - val_beta: 1.0000e-04\n",
      "Epoch 5071/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 20450.3442 - recon_loss: 2.0239e-04 - KL loss: 210.8834 - beta: 1.0000e-04 - val_loss: 22301.2285 - val_recon_loss: 2.2096e-04 - val_KL loss: 204.8655 - val_beta: 1.0000e-04\n",
      "Epoch 5072/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 19347.7654 - recon_loss: 1.9144e-04 - KL loss: 203.8392 - beta: 1.0000e-04 - val_loss: 20107.0820 - val_recon_loss: 1.9912e-04 - val_KL loss: 194.9381 - val_beta: 1.0000e-04\n",
      "Epoch 5073/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 19054.3623 - recon_loss: 1.8852e-04 - KL loss: 202.8344 - beta: 1.0000e-04 - val_loss: 23051.5293 - val_recon_loss: 2.2843e-04 - val_KL loss: 208.5413 - val_beta: 1.0000e-04\n",
      "Epoch 5074/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 19304.6011 - recon_loss: 1.9106e-04 - KL loss: 198.1322 - beta: 1.0000e-04 - val_loss: 22202.1367 - val_recon_loss: 2.2000e-04 - val_KL loss: 201.8504 - val_beta: 1.0000e-04\n",
      "Epoch 5075/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 19220.4734 - recon_loss: 1.9019e-04 - KL loss: 201.0592 - beta: 1.0000e-04 - val_loss: 22554.5371 - val_recon_loss: 2.2359e-04 - val_KL loss: 195.2946 - val_beta: 1.0000e-04\n",
      "Epoch 5076/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 19069.3776 - recon_loss: 1.8874e-04 - KL loss: 195.5056 - beta: 1.0000e-04 - val_loss: 22236.9922 - val_recon_loss: 2.2036e-04 - val_KL loss: 200.8768 - val_beta: 1.0000e-04\n",
      "Epoch 5077/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 18548.9699 - recon_loss: 1.8349e-04 - KL loss: 199.9003 - beta: 1.0000e-04\n",
      "Epoch 05077: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18549.1502 - recon_loss: 1.8349e-04 - KL loss: 199.9010 - beta: 1.0000e-04 - val_loss: 21846.8809 - val_recon_loss: 2.1635e-04 - val_KL loss: 211.6549 - val_beta: 1.0000e-04\n",
      "Epoch 5078/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18347.5955 - recon_loss: 1.8138e-04 - KL loss: 209.2961 - beta: 1.0000e-04 - val_loss: 20580.7363 - val_recon_loss: 2.0372e-04 - val_KL loss: 208.9640 - val_beta: 1.0000e-04\n",
      "Epoch 5079/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 17664.3553 - recon_loss: 1.7455e-04 - KL loss: 209.6562 - beta: 1.0000e-04 - val_loss: 19644.2227 - val_recon_loss: 1.9436e-04 - val_KL loss: 208.4674 - val_beta: 1.0000e-04\n",
      "Epoch 5080/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17314.9524 - recon_loss: 1.7108e-04 - KL loss: 207.1864 - beta: 1.0000e-04 - val_loss: 20349.5176 - val_recon_loss: 2.0139e-04 - val_KL loss: 210.9047 - val_beta: 1.0000e-04\n",
      "Epoch 5081/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17538.9816 - recon_loss: 1.7327e-04 - KL loss: 211.9729 - beta: 1.0000e-04 - val_loss: 19142.2461 - val_recon_loss: 1.8926e-04 - val_KL loss: 216.2978 - val_beta: 1.0000e-04\n",
      "Epoch 5082/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 17724.2903 - recon_loss: 1.7509e-04 - KL loss: 215.6702 - beta: 1.0000e-04 - val_loss: 19646.8516 - val_recon_loss: 1.9438e-04 - val_KL loss: 208.4305 - val_beta: 1.0000e-04\n",
      "Epoch 5083/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 17539.2594 - recon_loss: 1.7327e-04 - KL loss: 212.0972 - beta: 1.0000e-04 - val_loss: 20595.2637 - val_recon_loss: 2.0389e-04 - val_KL loss: 206.3450 - val_beta: 1.0000e-04\n",
      "Epoch 5084/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 17276.7922 - recon_loss: 1.7067e-04 - KL loss: 209.8460 - beta: 1.0000e-04 - val_loss: 19603.3574 - val_recon_loss: 1.9395e-04 - val_KL loss: 208.0261 - val_beta: 1.0000e-04\n",
      "Epoch 5085/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17424.3995 - recon_loss: 1.7216e-04 - KL loss: 208.3709 - beta: 1.0000e-04 - val_loss: 20452.9277 - val_recon_loss: 2.0252e-04 - val_KL loss: 201.1544 - val_beta: 1.0000e-04\n",
      "Epoch 5086/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17008.1320 - recon_loss: 1.6805e-04 - KL loss: 203.3535 - beta: 1.0000e-04- ETA: 1s - loss: 17005.2949 - recon_loss: 1.6802e-04 - KL loss: 203.3\n",
      "Epoch 05086: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17008.2243 - recon_loss: 1.6805e-04 - KL loss: 203.3532 - beta: 1.0000e-04 - val_loss: 19617.4297 - val_recon_loss: 1.9414e-04 - val_KL loss: 203.6278 - val_beta: 1.0000e-04\n",
      "Epoch 5087/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 16854.2896 - recon_loss: 1.6650e-04 - KL loss: 203.9684 - beta: 1.0000e-04 - val_loss: 19793.9277 - val_recon_loss: 1.9589e-04 - val_KL loss: 205.1278 - val_beta: 1.0000e-04\n",
      "Epoch 5088/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 16957.2797 - recon_loss: 1.6750e-04 - KL loss: 207.5254 - beta: 1.0000e-04 - val_loss: 19183.4180 - val_recon_loss: 1.8978e-04 - val_KL loss: 205.2921 - val_beta: 1.0000e-04\n",
      "Epoch 5089/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17014.2059 - recon_loss: 1.6807e-04 - KL loss: 207.3984 - beta: 1.0000e-04 - val_loss: 20518.0742 - val_recon_loss: 2.0315e-04 - val_KL loss: 203.2780 - val_beta: 1.0000e-04\n",
      "Epoch 5090/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 16776.4400 - recon_loss: 1.6569e-04 - KL loss: 207.6119 - beta: 1.0000e-04 - val_loss: 18495.0938 - val_recon_loss: 1.8290e-04 - val_KL loss: 205.3650 - val_beta: 1.0000e-04\n",
      "Epoch 5091/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 17100.8149 - recon_loss: 1.6891e-04 - KL loss: 209.5396 - beta: 1.0000e-04 - val_loss: 18776.9102 - val_recon_loss: 1.8569e-04 - val_KL loss: 208.1266 - val_beta: 1.0000e-04\n",
      "Epoch 5092/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 16994.5796 - recon_loss: 1.6786e-04 - KL loss: 208.3878 - beta: 1.0000e-04 - val_loss: 18665.2383 - val_recon_loss: 1.8457e-04 - val_KL loss: 208.5586 - val_beta: 1.0000e-04\n",
      "Epoch 5093/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 16891.2048 - recon_loss: 1.6683e-04 - KL loss: 208.2069 - beta: 1.0000e-04 - val_loss: 18830.7695 - val_recon_loss: 1.8627e-04 - val_KL loss: 204.2406 - val_beta: 1.0000e-04\n",
      "Epoch 5094/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 16807.6974 - recon_loss: 1.6602e-04 - KL loss: 205.2482 - beta: 1.0000e-04 - val_loss: 18982.8984 - val_recon_loss: 1.8779e-04 - val_KL loss: 203.5950 - val_beta: 1.0000e-04\n",
      "Epoch 5095/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 16790.3125 - recon_loss: 1.6584e-04 - KL loss: 206.5193 - beta: 1.0000e-04\n",
      "Epoch 05095: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 16790.2214 - recon_loss: 1.6584e-04 - KL loss: 206.5191 - beta: 1.0000e-04 - val_loss: 19088.9219 - val_recon_loss: 1.8884e-04 - val_KL loss: 204.9632 - val_beta: 1.0000e-04\n",
      "Epoch 5096/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 16617.2163 - recon_loss: 1.6410e-04 - KL loss: 207.2960 - beta: 1.0000e-04 - val_loss: 20185.8086 - val_recon_loss: 1.9982e-04 - val_KL loss: 204.1744 - val_beta: 1.0000e-04\n",
      "Epoch 5097/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 16527.9624 - recon_loss: 1.6321e-04 - KL loss: 206.9290 - beta: 1.0000e-04 - val_loss: 19935.3652 - val_recon_loss: 1.9730e-04 - val_KL loss: 204.8745 - val_beta: 1.0000e-04\n",
      "Epoch 5098/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 16780.5316 - recon_loss: 1.6573e-04 - KL loss: 207.7343 - beta: 1.0000e-04 - val_loss: 19339.6074 - val_recon_loss: 1.9135e-04 - val_KL loss: 204.2815 - val_beta: 1.0000e-04\n",
      "Epoch 5099/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 16732.2751 - recon_loss: 1.6525e-04 - KL loss: 207.5150 - beta: 1.0000e-04 - val_loss: 19388.7090 - val_recon_loss: 1.9184e-04 - val_KL loss: 204.9867 - val_beta: 1.0000e-04\n",
      "Epoch 5100/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 16682.5897 - recon_loss: 1.6476e-04 - KL loss: 206.9725 - beta: 1.0000e-04\n",
      "Epoch 05100: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 16682.5405 - recon_loss: 1.6476e-04 - KL loss: 206.9726 - beta: 1.0000e-04 - val_loss: 19497.3906 - val_recon_loss: 1.9292e-04 - val_KL loss: 205.8213 - val_beta: 1.0000e-04\n",
      "Epoch 5100/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 51000.3376 - recon_loss: 2.0214e-04 - KL loss: 224.5355 - beta: 6.3096e-05 - val_loss: 57096.4648 - val_recon_loss: 2.2631e-04 - val_KL loss: 250.4062 - val_beta: 6.3096e-05\n",
      "Epoch 5101/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 47815.8334 - recon_loss: 1.8934e-04 - KL loss: 255.1903 - beta: 6.3096e-05 - val_loss: 74025.7344 - val_recon_loss: 2.9363e-04 - val_KL loss: 269.4777 - val_beta: 6.3096e-05\n",
      "Epoch 5102/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 52877.6893 - recon_loss: 2.0948e-04 - KL loss: 257.7271 - beta: 6.3096e-05 - val_loss: 56123.0898 - val_recon_loss: 2.2236e-04 - val_KL loss: 268.5095 - val_beta: 6.3096e-05\n",
      "Epoch 5103/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 47986.3962 - recon_loss: 1.8996e-04 - KL loss: 270.5618 - beta: 6.3096e-05 - val_loss: 56139.2227 - val_recon_loss: 2.2244e-04 - val_KL loss: 266.0585 - val_beta: 6.3096e-05\n",
      "Epoch 5104/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 47297.5708 - recon_loss: 1.8724e-04 - KL loss: 264.0569 - beta: 6.3096e-05 - val_loss: 57672.1641 - val_recon_loss: 2.2861e-04 - val_KL loss: 248.4583 - val_beta: 6.3096e-05\n",
      "Epoch 5105/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 49284.3528 - recon_loss: 1.9517e-04 - KL loss: 259.2171 - beta: 6.3096e-05 - val_loss: 55503.1602 - val_recon_loss: 2.1996e-04 - val_KL loss: 252.2749 - val_beta: 6.3096e-05\n",
      "Epoch 5106/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 46970.1193 - recon_loss: 1.8596e-04 - KL loss: 258.5774 - beta: 6.3096e-05 - val_loss: 52073.0859 - val_recon_loss: 2.0627e-04 - val_KL loss: 260.8384 - val_beta: 6.3096e-05\n",
      "Epoch 5107/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 45580.7931 - recon_loss: 1.8041e-04 - KL loss: 263.2232 - beta: 6.3096e-05 - val_loss: 55241.9453 - val_recon_loss: 2.1885e-04 - val_KL loss: 270.0960 - val_beta: 6.3096e-05\n",
      "Epoch 5108/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 46706.7276 - recon_loss: 1.8489e-04 - KL loss: 264.2046 - beta: 6.3096e-05 - val_loss: 49058.4336 - val_recon_loss: 1.9427e-04 - val_KL loss: 259.5250 - val_beta: 6.3096e-05\n",
      "Epoch 5109/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 48091.3570 - recon_loss: 1.9039e-04 - KL loss: 268.1753 - beta: 6.3096e-05 - val_loss: 63676.8438 - val_recon_loss: 2.5238e-04 - val_KL loss: 282.4004 - val_beta: 6.3096e-05\n",
      "Epoch 5110/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 51600.5859 - recon_loss: 2.0434e-04 - KL loss: 273.0602 - beta: 6.3096e-05 - val_loss: 55976.3438 - val_recon_loss: 2.2178e-04 - val_KL loss: 268.0205 - val_beta: 6.3096e-05\n",
      "Epoch 5111/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 47040.8068 - recon_loss: 1.8620e-04 - KL loss: 269.4007 - beta: 6.3096e-05 - val_loss: 57785.3125 - val_recon_loss: 2.2897e-04 - val_KL loss: 269.7251 - val_beta: 6.3096e-05\n",
      "Epoch 5112/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 46514.8093 - recon_loss: 1.8411e-04 - KL loss: 269.2986 - beta: 6.3096e-05 - val_loss: 56332.1250 - val_recon_loss: 2.2315e-04 - val_KL loss: 278.5388 - val_beta: 6.3096e-05\n",
      "Epoch 5113/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 49288.0638 - recon_loss: 1.9510e-04 - KL loss: 279.9999 - beta: 6.3096e-05\n",
      "Epoch 05113: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 49286.6110 - recon_loss: 1.9510e-04 - KL loss: 279.9946 - beta: 6.3096e-05 - val_loss: 51502.7227 - val_recon_loss: 2.0398e-04 - val_KL loss: 266.3971 - val_beta: 6.3096e-05\n",
      "Epoch 5114/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44047.3579 - recon_loss: 1.7428e-04 - KL loss: 268.9719 - beta: 6.3096e-05 - val_loss: 52330.2422 - val_recon_loss: 2.0722e-04 - val_KL loss: 278.5653 - val_beta: 6.3096e-05\n",
      "Epoch 5115/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 43041.6536 - recon_loss: 1.7025e-04 - KL loss: 276.8693 - beta: 6.3096e-05 - val_loss: 49602.9492 - val_recon_loss: 1.9638e-04 - val_KL loss: 275.3712 - val_beta: 6.3096e-05\n",
      "Epoch 5116/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 42748.0083 - recon_loss: 1.6909e-04 - KL loss: 275.2471 - beta: 6.3096e-05 - val_loss: 52309.6719 - val_recon_loss: 2.0715e-04 - val_KL loss: 276.5027 - val_beta: 6.3096e-05\n",
      "Epoch 5117/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 42978.7074 - recon_loss: 1.7000e-04 - KL loss: 275.6307 - beta: 6.3096e-05 - val_loss: 53293.4766 - val_recon_loss: 2.1103e-04 - val_KL loss: 283.9207 - val_beta: 6.3096e-05\n",
      "Epoch 5118/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 42955.4127 - recon_loss: 1.6989e-04 - KL loss: 280.6681 - beta: 6.3096e-05 - val_loss: 48645.1367 - val_recon_loss: 1.9254e-04 - val_KL loss: 281.8185 - val_beta: 6.3096e-05\n",
      "Epoch 5119/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 42290.9220 - recon_loss: 1.6725e-04 - KL loss: 280.8242 - beta: 6.3096e-05 - val_loss: 51094.8320 - val_recon_loss: 2.0229e-04 - val_KL loss: 282.8517 - val_beta: 6.3096e-05\n",
      "Epoch 5120/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 41819.5305 - recon_loss: 1.6538e-04 - KL loss: 278.9765 - beta: 6.3096e-05 - val_loss: 52541.0703 - val_recon_loss: 2.0810e-04 - val_KL loss: 268.7739 - val_beta: 6.3096e-05\n",
      "Epoch 5121/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 42037.9802 - recon_loss: 1.6628e-04 - KL loss: 271.2332 - beta: 6.3096e-05 - val_loss: 51106.6328 - val_recon_loss: 2.0234e-04 - val_KL loss: 280.3868 - val_beta: 6.3096e-05\n",
      "Epoch 5122/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 42254.6053 - recon_loss: 1.6711e-04 - KL loss: 278.1576 - beta: 6.3096e-05 - val_loss: 51433.1914 - val_recon_loss: 2.0366e-04 - val_KL loss: 276.8308 - val_beta: 6.3096e-05\n",
      "Epoch 5123/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 42440.8386 - recon_loss: 1.6786e-04 - KL loss: 277.4307 - beta: 6.3096e-05\n",
      "Epoch 05123: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 42440.0039 - recon_loss: 1.6785e-04 - KL loss: 277.4292 - beta: 6.3096e-05 - val_loss: 49280.0742 - val_recon_loss: 1.9508e-04 - val_KL loss: 279.3079 - val_beta: 6.3096e-05\n",
      "Epoch 5124/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 41617.6695 - recon_loss: 1.6457e-04 - KL loss: 278.3560 - beta: 6.3096e-05 - val_loss: 48857.8984 - val_recon_loss: 1.9340e-04 - val_KL loss: 278.4288 - val_beta: 6.3096e-05\n",
      "Epoch 5125/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 41565.6160 - recon_loss: 1.6438e-04 - KL loss: 275.6187 - beta: 6.3096e-05 - val_loss: 49679.0117 - val_recon_loss: 1.9667e-04 - val_KL loss: 277.5375 - val_beta: 6.3096e-05\n",
      "Epoch 5126/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 41263.2187 - recon_loss: 1.6317e-04 - KL loss: 277.8098 - beta: 6.3096e-05 - val_loss: 49414.4062 - val_recon_loss: 1.9562e-04 - val_KL loss: 277.4206 - val_beta: 6.3096e-05\n",
      "Epoch 5127/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 40673.7804 - recon_loss: 1.6082e-04 - KL loss: 276.7947 - beta: 6.3096e-05 - val_loss: 50533.2734 - val_recon_loss: 2.0007e-04 - val_KL loss: 278.6000 - val_beta: 6.3096e-05\n",
      "Epoch 5128/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 40883.5635 - recon_loss: 1.6165e-04 - KL loss: 278.8750 - beta: 6.3096e-05\n",
      "Epoch 05128: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 40883.7595 - recon_loss: 1.6165e-04 - KL loss: 278.8747 - beta: 6.3096e-05 - val_loss: 53285.5586 - val_recon_loss: 2.1103e-04 - val_KL loss: 278.1619 - val_beta: 6.3096e-05\n",
      "Epoch 5128/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 131388.9518 - recon_loss: 2.0777e-04 - KL loss: 293.2433 - beta: 3.9811e-05 - val_loss: 127246.9922 - val_recon_loss: 2.0116e-04 - val_KL loss: 324.0364 - val_beta: 3.9811e-05\n",
      "Epoch 5129/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 119931.2264 - recon_loss: 1.8955e-04 - KL loss: 330.2943 - beta: 3.9811e-05 - val_loss: 149979.2500 - val_recon_loss: 2.3717e-04 - val_KL loss: 336.7546 - val_beta: 3.9811e-05\n",
      "Epoch 5130/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 120876.8424 - recon_loss: 1.9105e-04 - KL loss: 335.2952 - beta: 3.9811e-05 - val_loss: 126744.9453 - val_recon_loss: 2.0035e-04 - val_KL loss: 335.4465 - val_beta: 3.9811e-05\n",
      "Epoch 5131/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 113283.8482 - recon_loss: 1.7901e-04 - KL loss: 334.5203 - beta: 3.9811e-05 - val_loss: 133987.4375 - val_recon_loss: 2.1181e-04 - val_KL loss: 341.6953 - val_beta: 3.9811e-05\n",
      "Epoch 5132/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 58s 58ms/step - loss: 116616.0184 - recon_loss: 1.8428e-04 - KL loss: 344.3672 - beta: 3.9811e-05 - val_loss: 163688.6719 - val_recon_loss: 2.5883e-04 - val_KL loss: 375.7796 - val_beta: 3.9811e-05\n",
      "Epoch 5133/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 120622.5999 - recon_loss: 1.9062e-04 - KL loss: 350.6085 - beta: 3.9811e-05 - val_loss: 129439.0078 - val_recon_loss: 2.0459e-04 - val_KL loss: 352.0055 - val_beta: 3.9811e-05\n",
      "Epoch 5134/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 116375.8302 - recon_loss: 1.8390e-04 - KL loss: 345.1735 - beta: 3.9811e-05 - val_loss: 134959.3438 - val_recon_loss: 2.1333e-04 - val_KL loss: 359.8524 - val_beta: 3.9811e-05\n",
      "Epoch 5135/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 117743.9585 - recon_loss: 1.8605e-04 - KL loss: 355.3769 - beta: 3.9811e-05\n",
      "Epoch 05135: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 117743.6039 - recon_loss: 1.8605e-04 - KL loss: 355.3750 - beta: 3.9811e-05 - val_loss: 131483.0938 - val_recon_loss: 2.0784e-04 - val_KL loss: 347.8741 - val_beta: 3.9811e-05\n",
      "Epoch 5136/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 111410.5221 - recon_loss: 1.7604e-04 - KL loss: 339.7455 - beta: 3.9811e-05 - val_loss: 122655.5234 - val_recon_loss: 1.9384e-04 - val_KL loss: 353.2189 - val_beta: 3.9811e-05\n",
      "Epoch 5137/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 106088.2767 - recon_loss: 1.6758e-04 - KL loss: 353.6521 - beta: 3.9811e-05 - val_loss: 122007.2734 - val_recon_loss: 1.9280e-04 - val_KL loss: 359.0314 - val_beta: 3.9811e-05\n",
      "Epoch 5138/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 108047.3453 - recon_loss: 1.7068e-04 - KL loss: 356.7693 - beta: 3.9811e-05 - val_loss: 126383.6172 - val_recon_loss: 1.9972e-04 - val_KL loss: 366.9184 - val_beta: 3.9811e-05\n",
      "Epoch 5139/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 107792.2894 - recon_loss: 1.7027e-04 - KL loss: 359.8551 - beta: 3.9811e-05 - val_loss: 130096.6641 - val_recon_loss: 2.0562e-04 - val_KL loss: 359.0940 - val_beta: 3.9811e-05\n",
      "Epoch 5140/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 108582.8617 - recon_loss: 1.7152e-04 - KL loss: 358.5691 - beta: 3.9811e-05 - val_loss: 124010.3438 - val_recon_loss: 1.9597e-04 - val_KL loss: 364.6014 - val_beta: 3.9811e-05\n",
      "Epoch 5141/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 108901.0423 - recon_loss: 1.7203e-04 - KL loss: 359.4568 - beta: 3.9811e-05 - val_loss: 115474.0859 - val_recon_loss: 1.8244e-04 - val_KL loss: 359.4547 - val_beta: 3.9811e-05\n",
      "Epoch 5142/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 109272.6457 - recon_loss: 1.7262e-04 - KL loss: 357.6652 - beta: 3.9811e-05 - val_loss: 117179.5156 - val_recon_loss: 1.8515e-04 - val_KL loss: 359.1980 - val_beta: 3.9811e-05\n",
      "Epoch 5143/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 107842.8324 - recon_loss: 1.7035e-04 - KL loss: 359.6556 - beta: 3.9811e-05 - val_loss: 118017.6641 - val_recon_loss: 1.8647e-04 - val_KL loss: 365.4062 - val_beta: 3.9811e-05\n",
      "Epoch 5144/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 109209.0540 - recon_loss: 1.7251e-04 - KL loss: 362.1663 - beta: 3.9811e-05 - val_loss: 116209.9062 - val_recon_loss: 1.8360e-04 - val_KL loss: 368.7330 - val_beta: 3.9811e-05\n",
      "Epoch 5145/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 109222.3071 - recon_loss: 1.7253e-04 - KL loss: 363.2677 - beta: 3.9811e-05 - val_loss: 117069.9609 - val_recon_loss: 1.8496e-04 - val_KL loss: 367.8133 - val_beta: 3.9811e-05\n",
      "Epoch 5146/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 107325.6170 - recon_loss: 1.6952e-04 - KL loss: 368.0717 - beta: 3.9811e-05\n",
      "Epoch 05146: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 107325.4598 - recon_loss: 1.6952e-04 - KL loss: 368.0734 - beta: 3.9811e-05 - val_loss: 125873.7344 - val_recon_loss: 1.9890e-04 - val_KL loss: 374.6893 - val_beta: 3.9811e-05\n",
      "Epoch 5147/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 104745.2380 - recon_loss: 1.6542e-04 - KL loss: 369.8346 - beta: 3.9811e-05 - val_loss: 115845.8984 - val_recon_loss: 1.8301e-04 - val_KL loss: 374.1174 - val_beta: 3.9811e-05\n",
      "Epoch 5148/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 104224.2283 - recon_loss: 1.6460e-04 - KL loss: 370.6242 - beta: 3.9811e-05 - val_loss: 113867.0703 - val_recon_loss: 1.7988e-04 - val_KL loss: 372.7272 - val_beta: 3.9811e-05\n",
      "Epoch 5149/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 103868.1647 - recon_loss: 1.6404e-04 - KL loss: 368.5413 - beta: 3.9811e-05 - val_loss: 116547.4141 - val_recon_loss: 1.8413e-04 - val_KL loss: 372.0968 - val_beta: 3.9811e-05\n",
      "Epoch 5150/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 102818.1163 - recon_loss: 1.6237e-04 - KL loss: 369.7723 - beta: 3.9811e-05 - val_loss: 114511.0547 - val_recon_loss: 1.8090e-04 - val_KL loss: 373.4926 - val_beta: 3.9811e-05\n",
      "Epoch 5151/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 104065.5021 - recon_loss: 1.6434e-04 - KL loss: 372.1021 - beta: 3.9811e-05 - val_loss: 116081.9219 - val_recon_loss: 1.8339e-04 - val_KL loss: 372.8127 - val_beta: 3.9811e-05\n",
      "Epoch 5152/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 105068.1105 - recon_loss: 1.6593e-04 - KL loss: 371.9724 - beta: 3.9811e-05 - val_loss: 115552.2031 - val_recon_loss: 1.8255e-04 - val_KL loss: 372.6738 - val_beta: 3.9811e-05\n",
      "Epoch 5153/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 103366.3890 - recon_loss: 1.6323e-04 - KL loss: 373.3154 - beta: 3.9811e-05\n",
      "Epoch 05153: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 103366.1609 - recon_loss: 1.6323e-04 - KL loss: 373.3154 - beta: 3.9811e-05 - val_loss: 115288.9844 - val_recon_loss: 1.8213e-04 - val_KL loss: 371.5203 - val_beta: 3.9811e-05\n",
      "Epoch 5154/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 102851.2217 - recon_loss: 1.6242e-04 - KL loss: 370.1696 - beta: 3.9811e-05 - val_loss: 114444.4688 - val_recon_loss: 1.8079e-04 - val_KL loss: 372.0952 - val_beta: 3.9811e-05\n",
      "Epoch 5155/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 101849.9441 - recon_loss: 1.6083e-04 - KL loss: 370.0575 - beta: 3.9811e-05 - val_loss: 114390.2734 - val_recon_loss: 1.8071e-04 - val_KL loss: 372.2602 - val_beta: 3.9811e-05\n",
      "Epoch 5156/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 102405.8691 - recon_loss: 1.6171e-04 - KL loss: 371.7789 - beta: 3.9811e-05 - val_loss: 113745.5312 - val_recon_loss: 1.7968e-04 - val_KL loss: 372.7019 - val_beta: 3.9811e-05\n",
      "Epoch 5157/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 101763.5121 - recon_loss: 1.6070e-04 - KL loss: 370.4999 - beta: 3.9811e-05 - val_loss: 113996.5312 - val_recon_loss: 1.8008e-04 - val_KL loss: 372.3122 - val_beta: 3.9811e-05\n",
      "Epoch 5158/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 101946.5976 - recon_loss: 1.6099e-04 - KL loss: 370.9523 - beta: 3.9811e-05 - val_loss: 113908.8750 - val_recon_loss: 1.7994e-04 - val_KL loss: 372.7099 - val_beta: 3.9811e-05\n",
      "Epoch 5159/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 101691.9771 - recon_loss: 1.6058e-04 - KL loss: 371.0592 - beta: 3.9811e-05 - val_loss: 113593.8281 - val_recon_loss: 1.7944e-04 - val_KL loss: 372.0795 - val_beta: 3.9811e-05\n",
      "Epoch 5160/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 103003.9652 - recon_loss: 1.6266e-04 - KL loss: 370.8299 - beta: 3.9811e-05 - val_loss: 115019.6953 - val_recon_loss: 1.8171e-04 - val_KL loss: 371.4593 - val_beta: 3.9811e-05\n",
      "Epoch 5161/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 101444.8891 - recon_loss: 1.6019e-04 - KL loss: 370.0235 - beta: 3.9811e-05 - val_loss: 114248.5938 - val_recon_loss: 1.8048e-04 - val_KL loss: 371.5999 - val_beta: 3.9811e-05\n",
      "Epoch 5162/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 101501.9344 - recon_loss: 1.6028e-04 - KL loss: 369.3884 - beta: 3.9811e-05 - val_loss: 112693.5000 - val_recon_loss: 1.7802e-04 - val_KL loss: 371.9754 - val_beta: 3.9811e-05\n",
      "Epoch 5163/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 101095.8116 - recon_loss: 1.5964e-04 - KL loss: 369.5415 - beta: 3.9811e-05 - val_loss: 113028.7812 - val_recon_loss: 1.7855e-04 - val_KL loss: 371.6191 - val_beta: 3.9811e-05\n",
      "Epoch 5164/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 100866.8737 - recon_loss: 1.5928e-04 - KL loss: 369.3279 - beta: 3.9811e-05 - val_loss: 113288.9609 - val_recon_loss: 1.7896e-04 - val_KL loss: 371.0180 - val_beta: 3.9811e-05\n",
      "Epoch 5165/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 101298.0838 - recon_loss: 1.5996e-04 - KL loss: 369.0471 - beta: 3.9811e-05 - val_loss: 115325.8281 - val_recon_loss: 1.8219e-04 - val_KL loss: 371.8164 - val_beta: 3.9811e-05\n",
      "Epoch 5166/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 101534.0038 - recon_loss: 1.6033e-04 - KL loss: 370.1209 - beta: 3.9811e-05 - val_loss: 113965.3750 - val_recon_loss: 1.8003e-04 - val_KL loss: 371.2061 - val_beta: 3.9811e-05\n",
      "Epoch 5167/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 101875.1798 - recon_loss: 1.6088e-04 - KL loss: 369.3714 - beta: 3.9811e-05 ETA: 2s - loss: 101894.7371 - rec\n",
      "Epoch 05167: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 101874.6969 - recon_loss: 1.6088e-04 - KL loss: 369.3713 - beta: 3.9811e-05 - val_loss: 113746.9531 - val_recon_loss: 1.7969e-04 - val_KL loss: 371.9476 - val_beta: 3.9811e-05\n",
      "Epoch 5168/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 100741.0706 - recon_loss: 1.5908e-04 - KL loss: 369.1345 - beta: 3.9811e-05 - val_loss: 113879.7344 - val_recon_loss: 1.7990e-04 - val_KL loss: 371.6949 - val_beta: 3.9811e-05\n",
      "Epoch 5169/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 101444.9334 - recon_loss: 1.6019e-04 - KL loss: 369.3275 - beta: 3.9811e-05 - val_loss: 113661.6797 - val_recon_loss: 1.7955e-04 - val_KL loss: 372.0735 - val_beta: 3.9811e-05\n",
      "Epoch 5170/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 100549.6216 - recon_loss: 1.5877e-04 - KL loss: 369.9027 - beta: 3.9811e-05 - val_loss: 113270.6719 - val_recon_loss: 1.7893e-04 - val_KL loss: 372.3739 - val_beta: 3.9811e-05\n",
      "Epoch 5171/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 101099.7177 - recon_loss: 1.5965e-04 - KL loss: 370.2971 - beta: 3.9811e-05 - val_loss: 112944.5547 - val_recon_loss: 1.7841e-04 - val_KL loss: 373.0979 - val_beta: 3.9811e-05\n",
      "Epoch 5172/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 100820.9906 - recon_loss: 1.5920e-04 - KL loss: 370.3164 - beta: 3.9811e-05\n",
      "Epoch 05172: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 100820.6540 - recon_loss: 1.5920e-04 - KL loss: 370.3166 - beta: 3.9811e-05 - val_loss: 112937.7031 - val_recon_loss: 1.7840e-04 - val_KL loss: 372.7244 - val_beta: 3.9811e-05\n",
      "Epoch 5172/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 347901.2759 - recon_loss: 2.1927e-04 - KL loss: 379.0011 - beta: 2.5119e-05 - val_loss: 326071.6875 - val_recon_loss: 2.0548e-04 - val_KL loss: 400.0787 - val_beta: 2.5119e-05\n",
      "Epoch 5173/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 321647.4236 - recon_loss: 2.0270e-04 - KL loss: 397.6159 - beta: 2.5119e-05 - val_loss: 322369.3438 - val_recon_loss: 2.0314e-04 - val_KL loss: 417.5460 - val_beta: 2.5119e-05\n",
      "Epoch 5174/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 296112.0674 - recon_loss: 1.8657e-04 - KL loss: 422.8360 - beta: 2.5119e-05 - val_loss: 312201.6250 - val_recon_loss: 1.9670e-04 - val_KL loss: 446.2316 - val_beta: 2.5119e-05\n",
      "Epoch 5175/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 325164.1695 - recon_loss: 2.0489e-04 - KL loss: 441.5653 - beta: 2.5119e-05 - val_loss: 375291.1875 - val_recon_loss: 2.3650e-04 - val_KL loss: 468.2180 - val_beta: 2.5119e-05\n",
      "Epoch 5176/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 325305.0671 - recon_loss: 2.0497e-04 - KL loss: 452.7582 - beta: 2.5119e-05 - val_loss: 315889.2188 - val_recon_loss: 1.9903e-04 - val_KL loss: 442.9775 - val_beta: 2.5119e-05\n",
      "Epoch 5177/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 292214.9694 - recon_loss: 1.8410e-04 - KL loss: 440.0461 - beta: 2.5119e-05 - val_loss: 341464.8438 - val_recon_loss: 2.1515e-04 - val_KL loss: 475.2670 - val_beta: 2.5119e-05\n",
      "Epoch 5178/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 315570.4583 - recon_loss: 1.9882e-04 - KL loss: 466.0809 - beta: 2.5119e-05 - val_loss: 360315.7188 - val_recon_loss: 2.2704e-04 - val_KL loss: 487.9494 - val_beta: 2.5119e-05\n",
      "Epoch 5179/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 330812.1058 - recon_loss: 2.0844e-04 - KL loss: 463.9940 - beta: 2.5119e-05\n",
      "Epoch 05179: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 330801.8061 - recon_loss: 2.0843e-04 - KL loss: 463.9939 - beta: 2.5119e-05 - val_loss: 327945.4688 - val_recon_loss: 2.0662e-04 - val_KL loss: 470.4923 - val_beta: 2.5119e-05\n",
      "Epoch 5180/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 289014.8180 - recon_loss: 1.8206e-04 - KL loss: 469.4988 - beta: 2.5119e-05 - val_loss: 304723.7188 - val_recon_loss: 1.9197e-04 - val_KL loss: 471.1489 - val_beta: 2.5119e-05\n",
      "Epoch 5181/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 281739.3936 - recon_loss: 1.7747e-04 - KL loss: 469.3984 - beta: 2.5119e-05 - val_loss: 301928.6562 - val_recon_loss: 1.9020e-04 - val_KL loss: 476.6801 - val_beta: 2.5119e-05\n",
      "Epoch 5182/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 286831.7729 - recon_loss: 1.8067e-04 - KL loss: 486.9120 - beta: 2.5119e-05 - val_loss: 308010.0625 - val_recon_loss: 1.9403e-04 - val_KL loss: 497.5109 - val_beta: 2.5119e-05\n",
      "Epoch 5183/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 284977.3870 - recon_loss: 1.7950e-04 - KL loss: 492.1635 - beta: 2.5119e-05 - val_loss: 295465.7188 - val_recon_loss: 1.8612e-04 - val_KL loss: 486.8409 - val_beta: 2.5119e-05\n",
      "Epoch 5184/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 276237.6090 - recon_loss: 1.7399e-04 - KL loss: 480.2551 - beta: 2.5119e-05 - val_loss: 289823.0625 - val_recon_loss: 1.8256e-04 - val_KL loss: 486.4721 - val_beta: 2.5119e-05\n",
      "Epoch 5185/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 286133.7544 - recon_loss: 1.8023e-04 - KL loss: 494.8334 - beta: 2.5119e-05 - val_loss: 301594.5938 - val_recon_loss: 1.8997e-04 - val_KL loss: 506.7066 - val_beta: 2.5119e-05\n",
      "Epoch 5186/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 296834.6609 - recon_loss: 1.8697e-04 - KL loss: 508.4400 - beta: 2.5119e-05 - val_loss: 311088.8125 - val_recon_loss: 1.9596e-04 - val_KL loss: 508.7755 - val_beta: 2.5119e-05\n",
      "Epoch 5187/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 293780.2829 - recon_loss: 1.8505e-04 - KL loss: 501.3339 - beta: 2.5119e-05 - val_loss: 314929.1250 - val_recon_loss: 1.9839e-04 - val_KL loss: 500.9391 - val_beta: 2.5119e-05\n",
      "Epoch 5188/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 58s 58ms/step - loss: 289627.6092 - recon_loss: 1.8243e-04 - KL loss: 496.7443 - beta: 2.5119e-05 - val_loss: 304461.5625 - val_recon_loss: 1.9179e-04 - val_KL loss: 499.2727 - val_beta: 2.5119e-05\n",
      "Epoch 5189/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 289347.3446 - recon_loss: 1.8225e-04 - KL loss: 498.8703 - beta: 2.5119e-05\n",
      "Epoch 05189: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 289352.2010 - recon_loss: 1.8225e-04 - KL loss: 498.8735 - beta: 2.5119e-05 - val_loss: 347131.2188 - val_recon_loss: 2.1870e-04 - val_KL loss: 513.1649 - val_beta: 2.5119e-05\n",
      "Epoch 5190/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 293930.5278 - recon_loss: 1.8514e-04 - KL loss: 510.1799 - beta: 2.5119e-05 - val_loss: 318641.6250 - val_recon_loss: 2.0073e-04 - val_KL loss: 511.3282 - val_beta: 2.5119e-05\n",
      "Epoch 5191/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 289235.0477 - recon_loss: 1.8218e-04 - KL loss: 506.6916 - beta: 2.5119e-05 - val_loss: 303558.0625 - val_recon_loss: 1.9121e-04 - val_KL loss: 508.2346 - val_beta: 2.5119e-05\n",
      "Epoch 5192/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 283827.0605 - recon_loss: 1.7876e-04 - KL loss: 506.7464 - beta: 2.5119e-05 - val_loss: 304227.5625 - val_recon_loss: 1.9164e-04 - val_KL loss: 505.8791 - val_beta: 2.5119e-05\n",
      "Epoch 5193/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 280782.1561 - recon_loss: 1.7685e-04 - KL loss: 501.6949 - beta: 2.5119e-05 - val_loss: 305307.9062 - val_recon_loss: 1.9232e-04 - val_KL loss: 504.7903 - val_beta: 2.5119e-05\n",
      "Epoch 5194/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 280489.5808 - recon_loss: 1.7666e-04 - KL loss: 502.0461 - beta: 2.5119e-05\n",
      "Epoch 05194: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 280490.4904 - recon_loss: 1.7666e-04 - KL loss: 502.0468 - beta: 2.5119e-05 - val_loss: 303338.9688 - val_recon_loss: 1.9107e-04 - val_KL loss: 506.2766 - val_beta: 2.5119e-05\n",
      "Epoch 5194/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 885494.5013 - recon_loss: 2.2230e-04 - KL loss: 503.7706 - beta: 1.5849e-05 - val_loss: 916844.0625 - val_recon_loss: 2.3017e-04 - val_KL loss: 510.2755 - val_beta: 1.5849e-05\n",
      "Epoch 5195/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 874890.0791 - recon_loss: 2.1963e-04 - KL loss: 527.7689 - beta: 1.5849e-05 - val_loss: 829242.3125 - val_recon_loss: 2.0816e-04 - val_KL loss: 547.9093 - val_beta: 1.5849e-05\n",
      "Epoch 5196/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 900140.8809 - recon_loss: 2.2597e-04 - KL loss: 555.3553 - beta: 1.5849e-05 - val_loss: 831270.8125 - val_recon_loss: 2.0867e-04 - val_KL loss: 529.1877 - val_beta: 1.5849e-05\n",
      "Epoch 5197/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 795535.7439 - recon_loss: 1.9969e-04 - KL loss: 541.0718 - beta: 1.5849e-05 - val_loss: 995798.5625 - val_recon_loss: 2.5000e-04 - val_KL loss: 526.9521 - val_beta: 1.5849e-05\n",
      "Epoch 5198/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 803944.1030 - recon_loss: 2.0181e-04 - KL loss: 536.2625 - beta: 1.5849e-05 - val_loss: 802135.9375 - val_recon_loss: 2.0135e-04 - val_KL loss: 544.7723 - val_beta: 1.5849e-05\n",
      "Epoch 5199/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 776312.9925 - recon_loss: 1.9486e-04 - KL loss: 543.0321 - beta: 1.5849e-05 - val_loss: 851355.2500 - val_recon_loss: 2.1371e-04 - val_KL loss: 551.5924 - val_beta: 1.5849e-05\n",
      "Epoch 5200/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 795285.2228 - recon_loss: 1.9962e-04 - KL loss: 569.2912 - beta: 1.5849e-05 - val_loss: 918461.6250 - val_recon_loss: 2.3057e-04 - val_KL loss: 557.4968 - val_beta: 1.5849e-05\n",
      "Epoch 5201/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 838360.7715 - recon_loss: 2.1045e-04 - KL loss: 562.2653 - beta: 1.5849e-05 - val_loss: 943526.3750 - val_recon_loss: 2.3686e-04 - val_KL loss: 560.3953 - val_beta: 1.5849e-05\n",
      "Epoch 5202/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 776361.2979 - recon_loss: 1.9487e-04 - KL loss: 555.6177 - beta: 1.5849e-05 - val_loss: 844436.2500 - val_recon_loss: 2.1197e-04 - val_KL loss: 559.6918 - val_beta: 1.5849e-05\n",
      "Epoch 5203/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 773316.1660 - recon_loss: 1.9410e-04 - KL loss: 573.9660 - beta: 1.5849e-05\n",
      "Epoch 05203: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 773319.4591 - recon_loss: 1.9410e-04 - KL loss: 573.9715 - beta: 1.5849e-05 - val_loss: 884141.3125 - val_recon_loss: 2.2194e-04 - val_KL loss: 565.2936 - val_beta: 1.5849e-05\n",
      "Epoch 5204/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 726077.0288 - recon_loss: 1.8224e-04 - KL loss: 575.7537 - beta: 1.5849e-05 - val_loss: 806693.3750 - val_recon_loss: 2.0249e-04 - val_KL loss: 560.7609 - val_beta: 1.5849e-05\n",
      "Epoch 5205/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 719334.8488 - recon_loss: 1.8054e-04 - KL loss: 581.0393 - beta: 1.5849e-05 - val_loss: 778824.6875 - val_recon_loss: 1.9549e-04 - val_KL loss: 582.1959 - val_beta: 1.5849e-05\n",
      "Epoch 5206/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 721226.9666 - recon_loss: 1.8102e-04 - KL loss: 591.6682 - beta: 1.5849e-05 - val_loss: 770709.2500 - val_recon_loss: 1.9345e-04 - val_KL loss: 581.1085 - val_beta: 1.5849e-05\n",
      "Epoch 5207/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 705262.0844 - recon_loss: 1.7701e-04 - KL loss: 591.2675 - beta: 1.5849e-05 - val_loss: 758507.6250 - val_recon_loss: 1.9038e-04 - val_KL loss: 585.1122 - val_beta: 1.5849e-05\n",
      "Epoch 5208/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 711226.5982 - recon_loss: 1.7850e-04 - KL loss: 600.6285 - beta: 1.5849e-05 - val_loss: 805450.3750 - val_recon_loss: 2.0217e-04 - val_KL loss: 597.6714 - val_beta: 1.5849e-05\n",
      "Epoch 5209/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 721440.3744 - recon_loss: 1.8106e-04 - KL loss: 617.1318 - beta: 1.5849e-05 - val_loss: 777523.9375 - val_recon_loss: 1.9515e-04 - val_KL loss: 602.8556 - val_beta: 1.5849e-05\n",
      "Epoch 5210/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 707936.9622 - recon_loss: 1.7767e-04 - KL loss: 609.0869 - beta: 1.5849e-05 - val_loss: 780008.3125 - val_recon_loss: 1.9578e-04 - val_KL loss: 603.8581 - val_beta: 1.5849e-05\n",
      "Epoch 5211/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 700208.6703 - recon_loss: 1.7573e-04 - KL loss: 608.6117 - beta: 1.5849e-05 - val_loss: 800033.1875 - val_recon_loss: 2.0081e-04 - val_KL loss: 588.5735 - val_beta: 1.5849e-05\n",
      "Epoch 5212/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 707085.3058 - recon_loss: 1.7746e-04 - KL loss: 604.3464 - beta: 1.5849e-05\n",
      "Epoch 05212: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 707091.1829 - recon_loss: 1.7746e-04 - KL loss: 604.3500 - beta: 1.5849e-05 - val_loss: 789005.6250 - val_recon_loss: 1.9804e-04 - val_KL loss: 601.0828 - val_beta: 1.5849e-05\n",
      "Epoch 5213/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 697156.3262 - recon_loss: 1.7496e-04 - KL loss: 609.6934 - beta: 1.5849e-05 - val_loss: 765577.3750 - val_recon_loss: 1.9215e-04 - val_KL loss: 599.2437 - val_beta: 1.5849e-05\n",
      "Epoch 5214/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 687453.8033 - recon_loss: 1.7253e-04 - KL loss: 608.6775 - beta: 1.5849e-05 - val_loss: 763945.1875 - val_recon_loss: 1.9174e-04 - val_KL loss: 601.0669 - val_beta: 1.5849e-05\n",
      "Epoch 5215/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 683830.8140 - recon_loss: 1.7162e-04 - KL loss: 606.1121 - beta: 1.5849e-05 - val_loss: 764131.3750 - val_recon_loss: 1.9179e-04 - val_KL loss: 595.7753 - val_beta: 1.5849e-05\n",
      "Epoch 5216/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 673133.0729 - recon_loss: 1.6893e-04 - KL loss: 600.2643 - beta: 1.5849e-05 - val_loss: 761606.3125 - val_recon_loss: 1.9116e-04 - val_KL loss: 599.3635 - val_beta: 1.5849e-05\n",
      "Epoch 5217/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 676442.6524 - recon_loss: 1.6976e-04 - KL loss: 601.6559 - beta: 1.5849e-05\n",
      "Epoch 05217: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 676439.9425 - recon_loss: 1.6976e-04 - KL loss: 601.6559 - beta: 1.5849e-05 - val_loss: 761667.8125 - val_recon_loss: 1.9117e-04 - val_KL loss: 598.3292 - val_beta: 1.5849e-05\n",
      "Epoch 5217/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2169116.3680 - recon_loss: 2.1685e-04 - KL loss: 591.9475 - beta: 1.0000e-05 - val_loss: 2307975.5000 - val_recon_loss: 2.3074e-04 - val_KL loss: 625.2812 - val_beta: 1.0000e-05\n",
      "Epoch 5218/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1997279.8909 - recon_loss: 1.9967e-04 - KL loss: 604.8103 - beta: 1.0000e-05 - val_loss: 2120653.2500 - val_recon_loss: 2.1201e-04 - val_KL loss: 588.9005 - val_beta: 1.0000e-05\n",
      "Epoch 5219/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1911337.1123 - recon_loss: 1.9107e-04 - KL loss: 601.9874 - beta: 1.0000e-05 - val_loss: 2167353.7500 - val_recon_loss: 2.1667e-04 - val_KL loss: 617.1195 - val_beta: 1.0000e-05\n",
      "Epoch 5220/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1902016.0366 - recon_loss: 1.9014e-04 - KL loss: 611.0838 - beta: 1.0000e-05 - val_loss: 2114593.0000 - val_recon_loss: 2.1140e-04 - val_KL loss: 633.0128 - val_beta: 1.0000e-05\n",
      "Epoch 5221/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1916494.8792 - recon_loss: 1.9159e-04 - KL loss: 623.3234 - beta: 1.0000e-05 - val_loss: 2003344.2500 - val_recon_loss: 2.0027e-04 - val_KL loss: 609.5182 - val_beta: 1.0000e-05\n",
      "Epoch 5222/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1840865.1710 - recon_loss: 1.8402e-04 - KL loss: 619.3240 - beta: 1.0000e-05 - val_loss: 2134194.7500 - val_recon_loss: 2.1336e-04 - val_KL loss: 632.9315 - val_beta: 1.0000e-05\n",
      "Epoch 5223/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1838324.1757 - recon_loss: 1.8377e-04 - KL loss: 630.3818 - beta: 1.0000e-05 - val_loss: 2059031.6250 - val_recon_loss: 2.0584e-04 - val_KL loss: 632.4977 - val_beta: 1.0000e-05\n",
      "Epoch 5224/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1942222.1084 - recon_loss: 1.9416e-04 - KL loss: 638.3490 - beta: 1.0000e-05 - val_loss: 2170967.5000 - val_recon_loss: 2.1703e-04 - val_KL loss: 625.3764 - val_beta: 1.0000e-05\n",
      "Epoch 5225/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1837413.1590 - recon_loss: 1.8368e-04 - KL loss: 632.9061 - beta: 1.0000e-05 - val_loss: 2076647.0000 - val_recon_loss: 2.0760e-04 - val_KL loss: 656.8474 - val_beta: 1.0000e-05\n",
      "Epoch 5226/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1849439.3355 - recon_loss: 1.8488e-04 - KL loss: 649.9498 - beta: 1.0000e-05\n",
      "Epoch 05226: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1849540.4811 - recon_loss: 1.8489e-04 - KL loss: 649.9568 - beta: 1.0000e-05 - val_loss: 2686597.0000 - val_recon_loss: 2.6859e-04 - val_KL loss: 696.3339 - val_beta: 1.0000e-05\n",
      "Epoch 5227/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1950968.8989 - recon_loss: 1.9503e-04 - KL loss: 692.6098 - beta: 1.0000e-05 - val_loss: 2298701.0000 - val_recon_loss: 2.2980e-04 - val_KL loss: 672.2693 - val_beta: 1.0000e-05\n",
      "Epoch 5228/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1804287.7042 - recon_loss: 1.8036e-04 - KL loss: 677.2578 - beta: 1.0000e-05 - val_loss: 2009987.3750 - val_recon_loss: 2.0093e-04 - val_KL loss: 655.3443 - val_beta: 1.0000e-05\n",
      "Epoch 5229/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1717154.7617 - recon_loss: 1.7165e-04 - KL loss: 663.6749 - beta: 1.0000e-05 - val_loss: 2062488.7500 - val_recon_loss: 2.0618e-04 - val_KL loss: 652.2288 - val_beta: 1.0000e-05\n",
      "Epoch 5230/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1690347.1718 - recon_loss: 1.6897e-04 - KL loss: 661.6865 - beta: 1.0000e-05 - val_loss: 2399782.0000 - val_recon_loss: 2.3992e-04 - val_KL loss: 630.1394 - val_beta: 1.0000e-05\n",
      "Epoch 5231/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1667481.4386 - recon_loss: 1.6668e-04 - KL loss: 643.6898 - beta: 1.0000e-05\n",
      "Epoch 05231: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1667492.9966 - recon_loss: 1.6668e-04 - KL loss: 643.7000 - beta: 1.0000e-05 - val_loss: 2114715.0000 - val_recon_loss: 2.1141e-04 - val_KL loss: 657.3647 - val_beta: 1.0000e-05\n",
      "Epoch 5231/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4943154.1973 - recon_loss: 1.9676e-04 - KL loss: 657.7931 - beta: 6.3096e-06 - val_loss: 5372591.0000 - val_recon_loss: 2.1386e-04 - val_KL loss: 631.0713 - val_beta: 6.3096e-06\n",
      "Epoch 5232/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4532082.9890 - recon_loss: 1.8040e-04 - KL loss: 644.2997 - beta: 6.3096e-06 - val_loss: 4933254.5000 - val_recon_loss: 1.9637e-04 - val_KL loss: 649.1428 - val_beta: 6.3096e-06\n",
      "Epoch 5233/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4472927.9321 - recon_loss: 1.7804e-04 - KL loss: 656.8111 - beta: 6.3096e-06 - val_loss: 4982726.5000 - val_recon_loss: 1.9834e-04 - val_KL loss: 662.2615 - val_beta: 6.3096e-06\n",
      "Epoch 5234/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4477169.0649 - recon_loss: 1.7821e-04 - KL loss: 659.8355 - beta: 6.3096e-06 - val_loss: 4967498.0000 - val_recon_loss: 1.9773e-04 - val_KL loss: 691.9603 - val_beta: 6.3096e-06\n",
      "Epoch 5235/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4492398.9795 - recon_loss: 1.7882e-04 - KL loss: 699.0529 - beta: 6.3096e-06 - val_loss: 4900877.0000 - val_recon_loss: 1.9508e-04 - val_KL loss: 699.9568 - val_beta: 6.3096e-06\n",
      "Epoch 5236/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4376208.7153 - recon_loss: 1.7419e-04 - KL loss: 706.9301 - beta: 6.3096e-06 - val_loss: 5120549.5000 - val_recon_loss: 2.0382e-04 - val_KL loss: 701.7198 - val_beta: 6.3096e-06\n",
      "Epoch 5237/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4382385.9805 - recon_loss: 1.7444e-04 - KL loss: 703.3786 - beta: 6.3096e-06 - val_loss: 4951201.0000 - val_recon_loss: 1.9708e-04 - val_KL loss: 682.4095 - val_beta: 6.3096e-06\n",
      "Epoch 5238/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4395263.4578 - recon_loss: 1.7495e-04 - KL loss: 694.4357 - beta: 6.3096e-06 - val_loss: 5088255.5000 - val_recon_loss: 2.0254e-04 - val_KL loss: 686.3501 - val_beta: 6.3096e-06\n",
      "Epoch 5239/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4341882.8669 - recon_loss: 1.7283e-04 - KL loss: 689.7573 - beta: 6.3096e-06 - val_loss: 5561050.5000 - val_recon_loss: 2.2136e-04 - val_KL loss: 712.8870 - val_beta: 6.3096e-06\n",
      "Epoch 5240/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4375228.7800 - recon_loss: 1.7415e-04 - KL loss: 709.0775 - beta: 6.3096e-06\n",
      "Epoch 05240: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4375218.5070 - recon_loss: 1.7415e-04 - KL loss: 709.0697 - beta: 6.3096e-06 - val_loss: 4942321.0000 - val_recon_loss: 1.9673e-04 - val_KL loss: 673.9001 - val_beta: 6.3096e-06\n",
      "Epoch 5241/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4082714.7173 - recon_loss: 1.6251e-04 - KL loss: 677.1804 - beta: 6.3096e-06 - val_loss: 4503666.5000 - val_recon_loss: 1.7927e-04 - val_KL loss: 684.4783 - val_beta: 6.3096e-06\n",
      "Epoch 5242/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 3999318.2128 - recon_loss: 1.5919e-04 - KL loss: 693.2175 - beta: 6.3096e-06 - val_loss: 4444315.0000 - val_recon_loss: 1.7690e-04 - val_KL loss: 690.8353 - val_beta: 6.3096e-06\n",
      "Epoch 5243/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4001070.7707 - recon_loss: 1.5926e-04 - KL loss: 702.6422 - beta: 6.3096e-06 - val_loss: 4356056.0000 - val_recon_loss: 1.7339e-04 - val_KL loss: 701.3138 - val_beta: 6.3096e-06\n",
      "Epoch 5244/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4006166.8267 - recon_loss: 1.5946e-04 - KL loss: 705.7692 - beta: 6.3096e-06 - val_loss: 4534056.0000 - val_recon_loss: 1.8048e-04 - val_KL loss: 713.1585 - val_beta: 6.3096e-06\n",
      "Epoch 5245/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4056844.4378 - recon_loss: 1.6148e-04 - KL loss: 720.9153 - beta: 6.3096e-06 - val_loss: 5101292.5000 - val_recon_loss: 2.0306e-04 - val_KL loss: 705.0042 - val_beta: 6.3096e-06\n",
      "Epoch 5246/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4054746.7103 - recon_loss: 1.6139e-04 - KL loss: 718.6275 - beta: 6.3096e-06 - val_loss: 4625423.5000 - val_recon_loss: 1.8411e-04 - val_KL loss: 716.4733 - val_beta: 6.3096e-06\n",
      "Epoch 5247/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4032726.7273 - recon_loss: 1.6052e-04 - KL loss: 737.0112 - beta: 6.3096e-06 - val_loss: 4363167.0000 - val_recon_loss: 1.7367e-04 - val_KL loss: 722.4567 - val_beta: 6.3096e-06\n",
      "Epoch 5248/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4141693.7377 - recon_loss: 1.6485e-04 - KL loss: 746.0381 - beta: 6.3096e-06\n",
      "Epoch 05248: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4141687.2912 - recon_loss: 1.6485e-04 - KL loss: 746.0383 - beta: 6.3096e-06 - val_loss: 4523613.0000 - val_recon_loss: 1.8006e-04 - val_KL loss: 723.9462 - val_beta: 6.3096e-06\n",
      "Epoch 5249/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4041109.4256 - recon_loss: 1.6085e-04 - KL loss: 740.1937 - beta: 6.3096e-06 - val_loss: 5386176.0000 - val_recon_loss: 2.1440e-04 - val_KL loss: 723.4631 - val_beta: 6.3096e-06\n",
      "Epoch 5250/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3998667.7100 - recon_loss: 1.5916e-04 - KL loss: 740.7462 - beta: 6.3096e-06 - val_loss: 5460172.0000 - val_recon_loss: 2.1734e-04 - val_KL loss: 723.9531 - val_beta: 6.3096e-06\n",
      "Epoch 5251/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 3962853.5617 - recon_loss: 1.5773e-04 - KL loss: 742.3559 - beta: 6.3096e-06 - val_loss: 5269155.0000 - val_recon_loss: 2.0974e-04 - val_KL loss: 725.6946 - val_beta: 6.3096e-06\n",
      "Epoch 5252/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3969816.9515 - recon_loss: 1.5801e-04 - KL loss: 748.2900 - beta: 6.3096e-06 - val_loss: 4552190.0000 - val_recon_loss: 1.8120e-04 - val_KL loss: 735.5474 - val_beta: 6.3096e-06\n",
      "Epoch 5253/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4000045.3800 - recon_loss: 1.5921e-04 - KL loss: 754.4649 - beta: 6.3096e-06\n",
      "Epoch 05253: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4000050.7358 - recon_loss: 1.5921e-04 - KL loss: 754.4657 - beta: 6.3096e-06 - val_loss: 4478392.0000 - val_recon_loss: 1.7826e-04 - val_KL loss: 740.5303 - val_beta: 6.3096e-06\n"
     ]
    }
   ],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0., patience=10, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "# init_epoch=0\n",
    "\n",
    "for beta in betas:\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "#             modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,3e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas=np.concatenate((np.logspace(-1,-5,41)[4:14],\n",
    "                np.flip(np.logspace(-1,-5,41)[10:15]),\n",
    "                np.logspace(-1,-5,41)[9:19],\n",
    "                np.flip(np.logspace(-1,-5,41)[14:19]),\n",
    "                np.logspace(-1,-5,41)[14:24],\n",
    "                np.flip(np.logspace(-1,-5,41)[19:24]),\n",
    "                np.logspace(-1,-5,41)[19:29],\n",
    "                np.flip(np.logspace(-1,-5,41)[25:29]),\n",
    "                np.logspace(-1,-5,41)[24:34]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4112/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3214.7625 - recon_loss: 3.1669e-04 - KL loss: 47.8765 - beta: 3.1623e-04 - val_loss: 3481.2163 - val_recon_loss: 3.4327e-04 - val_KL loss: 48.5623 - val_beta: 3.1623e-04\n",
      "Epoch 4113/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3145.1244 - recon_loss: 3.0952e-04 - KL loss: 49.8910 - beta: 3.1623e-04 - val_loss: 3489.2673 - val_recon_loss: 3.4412e-04 - val_KL loss: 48.0210 - val_beta: 3.1623e-04\n",
      "Epoch 4114/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 3362.2447 - recon_loss: 3.3119e-04 - KL loss: 50.3161 - beta: 3.1623e-04 - val_loss: 3493.7974 - val_recon_loss: 3.4457e-04 - val_KL loss: 48.1338 - val_beta: 3.1623e-04\n",
      "Epoch 4115/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3142.8147 - recon_loss: 3.0939e-04 - KL loss: 48.9474 - beta: 3.1623e-04 - val_loss: 3413.9734 - val_recon_loss: 3.3646e-04 - val_KL loss: 49.3971 - val_beta: 3.1623e-04\n",
      "Epoch 4116/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 3145.8397 - recon_loss: 3.0962e-04 - KL loss: 49.5975 - beta: 3.1623e-04 - val_loss: 3420.0828 - val_recon_loss: 3.3701e-04 - val_KL loss: 49.9585 - val_beta: 3.1623e-04\n",
      "Epoch 4117/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 3152.3173 - recon_loss: 3.1028e-04 - KL loss: 49.5389 - beta: 3.1623e-04 - val_loss: 3359.8547 - val_recon_loss: 3.3120e-04 - val_KL loss: 47.8203 - val_beta: 3.1623e-04\n",
      "Epoch 4118/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 3158.4250 - recon_loss: 3.1091e-04 - KL loss: 49.3639 - beta: 3.1623e-04 - val_loss: 3340.4307 - val_recon_loss: 3.2925e-04 - val_KL loss: 47.9414 - val_beta: 3.1623e-04\n",
      "Epoch 4119/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3108.2366 - recon_loss: 3.0595e-04 - KL loss: 48.7674 - beta: 3.1623e-04 - val_loss: 3303.9111 - val_recon_loss: 3.2563e-04 - val_KL loss: 47.6095 - val_beta: 3.1623e-04\n",
      "Epoch 4120/10000\n",
      "1000/1000 [==============================] - 182s 182ms/step - loss: 3080.6284 - recon_loss: 3.0313e-04 - KL loss: 49.3159 - beta: 3.1623e-04 - val_loss: 3360.4285 - val_recon_loss: 3.3105e-04 - val_KL loss: 49.8847 - val_beta: 3.1623e-04\n",
      "Epoch 4121/10000\n",
      "1000/1000 [==============================] - 184s 184ms/step - loss: 3143.9308 - recon_loss: 3.0931e-04 - KL loss: 50.8800 - beta: 3.1623e-04 - val_loss: 3430.1992 - val_recon_loss: 3.3806e-04 - val_KL loss: 49.6446 - val_beta: 3.1623e-04\n",
      "Epoch 4122/10000\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 3159.4813 - recon_loss: 3.1088e-04 - KL loss: 50.6582 - beta: 3.1623e-04 - val_loss: 3355.1978 - val_recon_loss: 3.3061e-04 - val_KL loss: 49.1358 - val_beta: 3.1623e-04\n",
      "Epoch 4123/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 3071.4704 - recon_loss: 3.0211e-04 - KL loss: 50.3727 - beta: 3.1623e-04 - val_loss: 3287.8972 - val_recon_loss: 3.2391e-04 - val_KL loss: 48.7903 - val_beta: 3.1623e-04\n",
      "Epoch 4124/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3024.2142 - recon_loss: 2.9741e-04 - KL loss: 50.1234 - beta: 3.1623e-04 - val_loss: 3422.9055 - val_recon_loss: 3.3757e-04 - val_KL loss: 47.2308 - val_beta: 3.1623e-04\n",
      "Epoch 4125/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3074.5847 - recon_loss: 3.0250e-04 - KL loss: 49.5788 - beta: 3.1623e-04 - val_loss: 3377.8997 - val_recon_loss: 3.3280e-04 - val_KL loss: 49.8599 - val_beta: 3.1623e-04\n",
      "Epoch 4126/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3124.1303 - recon_loss: 3.0722e-04 - KL loss: 51.9015 - beta: 3.1623e-04 - val_loss: 3403.3904 - val_recon_loss: 3.3516e-04 - val_KL loss: 51.8181 - val_beta: 3.1623e-04\n",
      "Epoch 4127/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3110.5415 - recon_loss: 3.0597e-04 - KL loss: 50.8119 - beta: 3.1623e-04 - val_loss: 3408.5984 - val_recon_loss: 3.3572e-04 - val_KL loss: 51.3505 - val_beta: 3.1623e-04\n",
      "Epoch 4128/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 3058.9419 - recon_loss: 3.0081e-04 - KL loss: 50.8333 - beta: 3.1623e-04- ETA: 4s - loss: 3059.8910\n",
      "Epoch 04128: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 3058.9192 - recon_loss: 3.0081e-04 - KL loss: 50.8327 - beta: 3.1623e-04 - val_loss: 3376.1038 - val_recon_loss: 3.3250e-04 - val_KL loss: 51.1447 - val_beta: 3.1623e-04\n",
      "Epoch 4129/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 3013.9394 - recon_loss: 2.9632e-04 - KL loss: 50.7616 - beta: 3.1623e-04 - val_loss: 3369.3254 - val_recon_loss: 3.3186e-04 - val_KL loss: 50.7080 - val_beta: 3.1623e-04\n",
      "Epoch 4130/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3028.5219 - recon_loss: 2.9774e-04 - KL loss: 51.1221 - beta: 3.1623e-04 - val_loss: 3342.5859 - val_recon_loss: 3.2922e-04 - val_KL loss: 50.4260 - val_beta: 3.1623e-04\n",
      "Epoch 4131/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3040.8160 - recon_loss: 2.9895e-04 - KL loss: 51.3629 - beta: 3.1623e-04 - val_loss: 3443.5803 - val_recon_loss: 3.3936e-04 - val_KL loss: 50.0261 - val_beta: 3.1623e-04\n",
      "Epoch 4132/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 3076.2812 - recon_loss: 3.0246e-04 - KL loss: 51.6544 - beta: 3.1623e-04 - val_loss: 3438.2441 - val_recon_loss: 3.3880e-04 - val_KL loss: 50.2265 - val_beta: 3.1623e-04\n",
      "Epoch 4133/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3076.9475 - recon_loss: 3.0251e-04 - KL loss: 51.8452 - beta: 3.1623e-04- ETA: 0s - loss: 3076.9457 - recon_loss: 3.0251e-04 - KL loss: 51.8453 - beta: 3.1623e-0\n",
      "Epoch 04133: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 3076.9494 - recon_loss: 3.0251e-04 - KL loss: 51.8451 - beta: 3.1623e-04 - val_loss: 3465.1682 - val_recon_loss: 3.4154e-04 - val_KL loss: 49.7299 - val_beta: 3.1623e-04\n",
      "Epoch 4133/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 4911.3780 - recon_loss: 3.0662e-04 - KL loss: 51.8446 - beta: 2.5119e-04 - val_loss: 5634.1738 - val_recon_loss: 3.5224e-04 - val_KL loss: 51.4895 - val_beta: 2.5119e-04\n",
      "Epoch 4134/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 4837.3089 - recon_loss: 3.0182e-04 - KL loss: 53.7392 - beta: 2.5119e-04 - val_loss: 5258.0156 - val_recon_loss: 3.2833e-04 - val_KL loss: 54.3154 - val_beta: 2.5119e-04\n",
      "Epoch 4135/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5006.9804 - recon_loss: 3.1233e-04 - KL loss: 56.8381 - beta: 2.5119e-04 - val_loss: 5477.0210 - val_recon_loss: 3.4205e-04 - val_KL loss: 55.9698 - val_beta: 2.5119e-04\n",
      "Epoch 4136/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5064.0329 - recon_loss: 3.1589e-04 - KL loss: 57.4617 - beta: 2.5119e-04 - val_loss: 5766.4521 - val_recon_loss: 3.6031e-04 - val_KL loss: 55.8901 - val_beta: 2.5119e-04\n",
      "Epoch 4137/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5072.3436 - recon_loss: 3.1639e-04 - KL loss: 57.8915 - beta: 2.5119e-04 - val_loss: 6471.7363 - val_recon_loss: 4.0491e-04 - val_KL loss: 54.3968 - val_beta: 2.5119e-04\n",
      "Epoch 4138/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 5012.9713 - recon_loss: 3.1270e-04 - KL loss: 56.9767 - beta: 2.5119e-04 - val_loss: 5524.4551 - val_recon_loss: 3.4507e-04 - val_KL loss: 55.4444 - val_beta: 2.5119e-04\n",
      "Epoch 4139/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4956.7303 - recon_loss: 3.0916e-04 - KL loss: 56.8742 - beta: 2.5119e-04\n",
      "Epoch 04139: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 4956.7766 - recon_loss: 3.0916e-04 - KL loss: 56.8753 - beta: 2.5119e-04 - val_loss: 6332.7412 - val_recon_loss: 3.9596e-04 - val_KL loss: 57.1697 - val_beta: 2.5119e-04\n",
      "Epoch 4140/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5091.0326 - recon_loss: 3.1745e-04 - KL loss: 59.7563 - beta: 2.5119e-04 - val_loss: 6337.4683 - val_recon_loss: 3.9623e-04 - val_KL loss: 57.7064 - val_beta: 2.5119e-04\n",
      "Epoch 4141/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5018.9446 - recon_loss: 3.1293e-04 - KL loss: 59.3558 - beta: 2.5119e-04 - val_loss: 5434.1826 - val_recon_loss: 3.3932e-04 - val_KL loss: 56.2838 - val_beta: 2.5119e-04\n",
      "Epoch 4142/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5009.0782 - recon_loss: 3.1234e-04 - KL loss: 58.8238 - beta: 2.5119e-04 - val_loss: 5400.3657 - val_recon_loss: 3.3720e-04 - val_KL loss: 56.1107 - val_beta: 2.5119e-04\n",
      "Epoch 4143/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 4910.7327 - recon_loss: 3.0621e-04 - KL loss: 57.5659 - beta: 2.5119e-04 - val_loss: 5332.1074 - val_recon_loss: 3.3291e-04 - val_KL loss: 55.8158 - val_beta: 2.5119e-04\n",
      "Epoch 4144/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 4866.4477 - recon_loss: 3.0344e-04 - KL loss: 57.1745 - beta: 2.5119e-04\n",
      "Epoch 04144: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 4866.4196 - recon_loss: 3.0344e-04 - KL loss: 57.1745 - beta: 2.5119e-04 - val_loss: 5280.1621 - val_recon_loss: 3.2967e-04 - val_KL loss: 55.2343 - val_beta: 2.5119e-04\n",
      "Epoch 4144/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7862.9635 - recon_loss: 3.1067e-04 - KL loss: 59.1928 - beta: 1.9953e-04 - val_loss: 8416.7998 - val_recon_loss: 3.3279e-04 - val_KL loss: 57.4447 - val_beta: 1.9953e-04\n",
      "Epoch 4145/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7768.5892 - recon_loss: 3.0687e-04 - KL loss: 60.4495 - beta: 1.9953e-04 - val_loss: 8786.0713 - val_recon_loss: 3.4738e-04 - val_KL loss: 60.3598 - val_beta: 1.9953e-04\n",
      "Epoch 4146/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 7501.5328 - recon_loss: 2.9620e-04 - KL loss: 61.3009 - beta: 1.9953e-04 - val_loss: 8811.1406 - val_recon_loss: 3.4831e-04 - val_KL loss: 61.9919 - val_beta: 1.9953e-04\n",
      "Epoch 4147/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7433.1270 - recon_loss: 2.9341e-04 - KL loss: 62.9016 - beta: 1.9953e-04 - val_loss: 8359.6025 - val_recon_loss: 3.3037e-04 - val_KL loss: 61.0740 - val_beta: 1.9953e-04\n",
      "Epoch 4148/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7515.2955 - recon_loss: 2.9670e-04 - KL loss: 62.6178 - beta: 1.9953e-04 - val_loss: 8402.9785 - val_recon_loss: 3.3203e-04 - val_KL loss: 62.8403 - val_beta: 1.9953e-04\n",
      "Epoch 4149/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7531.2752 - recon_loss: 2.9729e-04 - KL loss: 63.5718 - beta: 1.9953e-04 - val_loss: 8431.7090 - val_recon_loss: 3.3311e-04 - val_KL loss: 64.3377 - val_beta: 1.9953e-04\n",
      "Epoch 4150/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7500.6593 - recon_loss: 2.9603e-04 - KL loss: 64.7775 - beta: 1.9953e-04 - val_loss: 8359.6094 - val_recon_loss: 3.3019e-04 - val_KL loss: 65.5598 - val_beta: 1.9953e-04\n",
      "Epoch 4151/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7528.8516 - recon_loss: 2.9710e-04 - KL loss: 65.9984 - beta: 1.9953e-04 - val_loss: 8184.5166 - val_recon_loss: 3.2326e-04 - val_KL loss: 64.5148 - val_beta: 1.9953e-04\n",
      "Epoch 4152/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7581.2073 - recon_loss: 2.9920e-04 - KL loss: 65.7560 - beta: 1.9953e-04 - val_loss: 8706.1904 - val_recon_loss: 3.4408e-04 - val_KL loss: 63.3330 - val_beta: 1.9953e-04\n",
      "Epoch 4153/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7509.0201 - recon_loss: 2.9635e-04 - KL loss: 64.9429 - beta: 1.9953e-04 - val_loss: 8366.1709 - val_recon_loss: 3.3047e-04 - val_KL loss: 65.0281 - val_beta: 1.9953e-04\n",
      "Epoch 4154/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7697.9830 - recon_loss: 3.0385e-04 - KL loss: 65.5617 - beta: 1.9953e-04 - val_loss: 8336.8711 - val_recon_loss: 3.2920e-04 - val_KL loss: 67.6574 - val_beta: 1.9953e-04\n",
      "Epoch 4155/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7600.7843 - recon_loss: 2.9986e-04 - KL loss: 68.5179 - beta: 1.9953e-04 - val_loss: 8044.3652 - val_recon_loss: 3.1762e-04 - val_KL loss: 65.9999 - val_beta: 1.9953e-04\n",
      "Epoch 4156/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7580.9475 - recon_loss: 2.9910e-04 - KL loss: 67.8987 - beta: 1.9953e-04 - val_loss: 8523.2979 - val_recon_loss: 3.3662e-04 - val_KL loss: 67.9052 - val_beta: 1.9953e-04\n",
      "Epoch 4157/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7855.8575 - recon_loss: 3.1001e-04 - KL loss: 68.6388 - beta: 1.9953e-04 - val_loss: 8248.4199 - val_recon_loss: 3.2565e-04 - val_KL loss: 68.3725 - val_beta: 1.9953e-04\n",
      "Epoch 4158/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7707.8100 - recon_loss: 3.0414e-04 - KL loss: 68.0856 - beta: 1.9953e-04 - val_loss: 8262.2988 - val_recon_loss: 3.2621e-04 - val_KL loss: 68.1773 - val_beta: 1.9953e-04\n",
      "Epoch 4159/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7545.2140 - recon_loss: 2.9766e-04 - KL loss: 68.3037 - beta: 1.9953e-04 - val_loss: 8796.8730 - val_recon_loss: 3.4748e-04 - val_KL loss: 68.6444 - val_beta: 1.9953e-04\n",
      "Epoch 4160/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7689.9613 - recon_loss: 3.0343e-04 - KL loss: 68.1683 - beta: 1.9953e-04\n",
      "Epoch 04160: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7689.9852 - recon_loss: 3.0343e-04 - KL loss: 68.1687 - beta: 1.9953e-04 - val_loss: 8629.6562 - val_recon_loss: 3.4074e-04 - val_KL loss: 70.6115 - val_beta: 1.9953e-04\n",
      "Epoch 4161/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7767.8507 - recon_loss: 3.0641e-04 - KL loss: 71.2054 - beta: 1.9953e-04 - val_loss: 8315.5000 - val_recon_loss: 3.2820e-04 - val_KL loss: 71.3984 - val_beta: 1.9953e-04\n",
      "Epoch 4162/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7652.6359 - recon_loss: 3.0182e-04 - KL loss: 71.1713 - beta: 1.9953e-04 - val_loss: 8241.3740 - val_recon_loss: 3.2517e-04 - val_KL loss: 73.5202 - val_beta: 1.9953e-04\n",
      "Epoch 4163/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7579.5774 - recon_loss: 2.9894e-04 - KL loss: 70.4242 - beta: 1.9953e-04 - val_loss: 8205.8408 - val_recon_loss: 3.2383e-04 - val_KL loss: 71.4768 - val_beta: 1.9953e-04\n",
      "Epoch 4164/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7534.7666 - recon_loss: 2.9716e-04 - KL loss: 70.3731 - beta: 1.9953e-04 - val_loss: 8184.8564 - val_recon_loss: 3.2303e-04 - val_KL loss: 70.6392 - val_beta: 1.9953e-04\n",
      "Epoch 4165/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7559.6899 - recon_loss: 2.9819e-04 - KL loss: 69.4393 - beta: 1.9953e-04\n",
      "Epoch 04165: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7559.6349 - recon_loss: 2.9819e-04 - KL loss: 69.4387 - beta: 1.9953e-04 - val_loss: 8105.1855 - val_recon_loss: 3.2001e-04 - val_KL loss: 66.8842 - val_beta: 1.9953e-04\n",
      "Epoch 4165/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11993.5417 - recon_loss: 2.9951e-04 - KL loss: 69.7644 - beta: 1.5849e-04 - val_loss: 13314.0762 - val_recon_loss: 3.3242e-04 - val_KL loss: 80.2576 - val_beta: 1.5849e-04\n",
      "Epoch 4166/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 12536.7465 - recon_loss: 3.1291e-04 - KL loss: 79.3921 - beta: 1.5849e-04 - val_loss: 12840.2246 - val_recon_loss: 3.2061e-04 - val_KL loss: 76.3581 - val_beta: 1.5849e-04\n",
      "Epoch 4167/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 12026.2838 - recon_loss: 3.0012e-04 - KL loss: 78.2925 - beta: 1.5849e-04 - val_loss: 12433.4277 - val_recon_loss: 3.1039e-04 - val_KL loss: 76.6271 - val_beta: 1.5849e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4168/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11931.5096 - recon_loss: 2.9770e-04 - KL loss: 79.7670 - beta: 1.5849e-04 - val_loss: 12800.0117 - val_recon_loss: 3.1951e-04 - val_KL loss: 80.1459 - val_beta: 1.5849e-04\n",
      "Epoch 4169/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 12021.0974 - recon_loss: 2.9996e-04 - KL loss: 79.6442 - beta: 1.5849e-04 - val_loss: 12591.1377 - val_recon_loss: 3.1429e-04 - val_KL loss: 79.1946 - val_beta: 1.5849e-04\n",
      "Epoch 4170/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 11776.0613 - recon_loss: 2.9377e-04 - KL loss: 80.7245 - beta: 1.5849e-04 - val_loss: 13568.5762 - val_recon_loss: 3.3884e-04 - val_KL loss: 79.1760 - val_beta: 1.5849e-04\n",
      "Epoch 4171/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11801.3309 - recon_loss: 2.9443e-04 - KL loss: 79.9956 - beta: 1.5849e-04 - val_loss: 13261.5732 - val_recon_loss: 3.3111e-04 - val_KL loss: 79.7848 - val_beta: 1.5849e-04\n",
      "Epoch 4172/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11895.7820 - recon_loss: 2.9676e-04 - KL loss: 81.6455 - beta: 1.5849e-04\n",
      "Epoch 04172: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11895.6753 - recon_loss: 2.9675e-04 - KL loss: 81.6456 - beta: 1.5849e-04 - val_loss: 13214.3564 - val_recon_loss: 3.2993e-04 - val_KL loss: 79.4641 - val_beta: 1.5849e-04\n",
      "Epoch 4173/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 11768.4474 - recon_loss: 2.9354e-04 - KL loss: 82.3679 - beta: 1.5849e-04 - val_loss: 12809.5293 - val_recon_loss: 3.1978e-04 - val_KL loss: 78.7367 - val_beta: 1.5849e-04\n",
      "Epoch 4174/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 11675.8401 - recon_loss: 2.9123e-04 - KL loss: 81.8283 - beta: 1.5849e-04 - val_loss: 13030.8779 - val_recon_loss: 3.2534e-04 - val_KL loss: 78.7239 - val_beta: 1.5849e-04\n",
      "Epoch 4175/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 11759.9101 - recon_loss: 2.9334e-04 - KL loss: 81.8500 - beta: 1.5849e-04 - val_loss: 12843.2119 - val_recon_loss: 3.2062e-04 - val_KL loss: 79.1660 - val_beta: 1.5849e-04\n",
      "Epoch 4176/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11528.0806 - recon_loss: 2.8752e-04 - KL loss: 81.5263 - beta: 1.5849e-04 - val_loss: 12854.2227 - val_recon_loss: 3.2090e-04 - val_KL loss: 79.1604 - val_beta: 1.5849e-04\n",
      "Epoch 4177/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11521.9792 - recon_loss: 2.8737e-04 - KL loss: 81.4447 - beta: 1.5849e-04\n",
      "Epoch 04177: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 11521.9430 - recon_loss: 2.8737e-04 - KL loss: 81.4446 - beta: 1.5849e-04 - val_loss: 12815.7812 - val_recon_loss: 3.1993e-04 - val_KL loss: 79.1997 - val_beta: 1.5849e-04\n",
      "Epoch 4177/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18376.5489 - recon_loss: 2.8994e-04 - KL loss: 82.5979 - beta: 1.2589e-04 - val_loss: 21325.0977 - val_recon_loss: 3.3661e-04 - val_KL loss: 86.3557 - val_beta: 1.2589e-04\n",
      "Epoch 4178/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18525.9582 - recon_loss: 2.9221e-04 - KL loss: 88.6164 - beta: 1.2589e-04 - val_loss: 20533.9941 - val_recon_loss: 3.2402e-04 - val_KL loss: 89.5568 - val_beta: 1.2589e-04\n",
      "Epoch 4179/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18481.7197 - recon_loss: 2.9142e-04 - KL loss: 94.4652 - beta: 1.2589e-04 - val_loss: 20581.6875 - val_recon_loss: 3.2470e-04 - val_KL loss: 94.2778 - val_beta: 1.2589e-04\n",
      "Epoch 4180/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18711.1944 - recon_loss: 2.9498e-04 - KL loss: 98.9653 - beta: 1.2589e-04 - val_loss: 20609.6582 - val_recon_loss: 3.2514e-04 - val_KL loss: 94.6473 - val_beta: 1.2589e-04\n",
      "Epoch 4181/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 18700.3128 - recon_loss: 2.9482e-04 - KL loss: 98.6864 - beta: 1.2589e-04 - val_loss: 21061.1602 - val_recon_loss: 3.3226e-04 - val_KL loss: 97.0583 - val_beta: 1.2589e-04\n",
      "Epoch 4182/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 18741.9908 - recon_loss: 2.9545e-04 - KL loss: 100.4950 - beta: 1.2589e-04 - val_loss: 21585.4238 - val_recon_loss: 3.4052e-04 - val_KL loss: 99.9324 - val_beta: 1.2589e-04\n",
      "Epoch 4183/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18921.9819 - recon_loss: 2.9825e-04 - KL loss: 103.4837 - beta: 1.2589e-04\n",
      "Epoch 04183: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18921.9495 - recon_loss: 2.9825e-04 - KL loss: 103.4837 - beta: 1.2589e-04 - val_loss: 21663.6035 - val_recon_loss: 3.4176e-04 - val_KL loss: 100.2521 - val_beta: 1.2589e-04\n",
      "Epoch 4184/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18655.5026 - recon_loss: 2.9407e-04 - KL loss: 101.1205 - beta: 1.2589e-04 - val_loss: 21631.1523 - val_recon_loss: 3.4130e-04 - val_KL loss: 96.7797 - val_beta: 1.2589e-04\n",
      "Epoch 4185/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 18516.4393 - recon_loss: 2.9187e-04 - KL loss: 100.4475 - beta: 1.2589e-04 - val_loss: 21061.4551 - val_recon_loss: 3.3224e-04 - val_KL loss: 98.2601 - val_beta: 1.2589e-04\n",
      "Epoch 4186/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18147.4237 - recon_loss: 2.8603e-04 - KL loss: 100.3549 - beta: 1.2589e-04 - val_loss: 20936.2090 - val_recon_loss: 3.3028e-04 - val_KL loss: 97.1265 - val_beta: 1.2589e-04\n",
      "Epoch 4187/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 18239.2532 - recon_loss: 2.8748e-04 - KL loss: 100.5499 - beta: 1.2589e-04 - val_loss: 20933.4648 - val_recon_loss: 3.3023e-04 - val_KL loss: 97.3107 - val_beta: 1.2589e-04\n",
      "Epoch 4188/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18243.7481 - recon_loss: 2.8755e-04 - KL loss: 100.2969 - beta: 1.2589e-04\n",
      "Epoch 04188: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18243.6913 - recon_loss: 2.8755e-04 - KL loss: 100.2969 - beta: 1.2589e-04 - val_loss: 20812.3047 - val_recon_loss: 3.2831e-04 - val_KL loss: 97.5668 - val_beta: 1.2589e-04\n",
      "Epoch 4188/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 29365.2892 - recon_loss: 2.9263e-04 - KL loss: 102.7139 - beta: 1.0000e-04 - val_loss: 31296.2754 - val_recon_loss: 3.1192e-04 - val_KL loss: 104.5277 - val_beta: 1.0000e-04\n",
      "Epoch 4189/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 29119.8276 - recon_loss: 2.9014e-04 - KL loss: 106.0307 - beta: 1.0000e-04 - val_loss: 34838.7266 - val_recon_loss: 3.4731e-04 - val_KL loss: 107.9334 - val_beta: 1.0000e-04\n",
      "Epoch 4190/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 29022.8523 - recon_loss: 2.8913e-04 - KL loss: 109.5806 - beta: 1.0000e-04 - val_loss: 33044.4727 - val_recon_loss: 3.2934e-04 - val_KL loss: 110.8057 - val_beta: 1.0000e-04\n",
      "Epoch 4191/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 29526.4835 - recon_loss: 2.9410e-04 - KL loss: 116.1370 - beta: 1.0000e-04 - val_loss: 31915.0195 - val_recon_loss: 3.1802e-04 - val_KL loss: 113.3005 - val_beta: 1.0000e-04\n",
      "Epoch 4192/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28660.8520 - recon_loss: 2.8544e-04 - KL loss: 117.3166 - beta: 1.0000e-04 - val_loss: 32352.9160 - val_recon_loss: 3.2236e-04 - val_KL loss: 116.7152 - val_beta: 1.0000e-04\n",
      "Epoch 4193/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 28653.4397 - recon_loss: 2.8533e-04 - KL loss: 120.2170 - beta: 1.0000e-04\n",
      "Epoch 04193: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28653.4219 - recon_loss: 2.8533e-04 - KL loss: 120.2166 - beta: 1.0000e-04 - val_loss: 31736.0059 - val_recon_loss: 3.1619e-04 - val_KL loss: 117.4643 - val_beta: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4194/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28472.2354 - recon_loss: 2.8353e-04 - KL loss: 119.4161 - beta: 1.0000e-04 - val_loss: 31627.1426 - val_recon_loss: 3.1510e-04 - val_KL loss: 117.4523 - val_beta: 1.0000e-04\n",
      "Epoch 4195/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28345.5114 - recon_loss: 2.8225e-04 - KL loss: 120.1186 - beta: 1.0000e-04 - val_loss: 31278.1582 - val_recon_loss: 3.1160e-04 - val_KL loss: 118.2796 - val_beta: 1.0000e-04\n",
      "Epoch 4196/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 27734.9271 - recon_loss: 2.7615e-04 - KL loss: 120.3836 - beta: 1.0000e-04 - val_loss: 31336.0977 - val_recon_loss: 3.1218e-04 - val_KL loss: 117.7533 - val_beta: 1.0000e-04\n",
      "Epoch 4197/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 28115.9595 - recon_loss: 2.7995e-04 - KL loss: 121.0291 - beta: 1.0000e-04 - val_loss: 31924.7480 - val_recon_loss: 3.1805e-04 - val_KL loss: 120.0895 - val_beta: 1.0000e-04\n",
      "Epoch 4198/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28105.6933 - recon_loss: 2.7985e-04 - KL loss: 120.2327 - beta: 1.0000e-04 - val_loss: 31079.1152 - val_recon_loss: 3.0960e-04 - val_KL loss: 119.1796 - val_beta: 1.0000e-04\n",
      "Epoch 4199/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28190.9552 - recon_loss: 2.8070e-04 - KL loss: 121.2907 - beta: 1.0000e-04 - val_loss: 30886.4668 - val_recon_loss: 3.0768e-04 - val_KL loss: 118.4101 - val_beta: 1.0000e-04\n",
      "Epoch 4200/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 28064.1083 - recon_loss: 2.7944e-04 - KL loss: 120.0921 - beta: 1.0000e-04 - val_loss: 31952.2383 - val_recon_loss: 3.1833e-04 - val_KL loss: 119.0625 - val_beta: 1.0000e-04\n",
      "Epoch 4201/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28171.5383 - recon_loss: 2.8051e-04 - KL loss: 120.1468 - beta: 1.0000e-04 - val_loss: 31111.6094 - val_recon_loss: 3.0993e-04 - val_KL loss: 118.2565 - val_beta: 1.0000e-04\n",
      "Epoch 4202/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28383.2849 - recon_loss: 2.8263e-04 - KL loss: 120.3200 - beta: 1.0000e-04 - val_loss: 31166.4453 - val_recon_loss: 3.1048e-04 - val_KL loss: 118.7905 - val_beta: 1.0000e-04\n",
      "Epoch 4203/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 27911.5302 - recon_loss: 2.7791e-04 - KL loss: 120.9357 - beta: 1.0000e-04 - val_loss: 31043.4434 - val_recon_loss: 3.0924e-04 - val_KL loss: 119.2526 - val_beta: 1.0000e-04\n",
      "Epoch 4204/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 27905.1460 - recon_loss: 2.7784e-04 - KL loss: 120.6858 - beta: 1.0000e-04\n",
      "Epoch 04204: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 27905.1784 - recon_loss: 2.7784e-04 - KL loss: 120.6855 - beta: 1.0000e-04 - val_loss: 31055.8086 - val_recon_loss: 3.0938e-04 - val_KL loss: 118.0156 - val_beta: 1.0000e-04\n",
      "Epoch 4205/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 27957.7953 - recon_loss: 2.7838e-04 - KL loss: 120.0697 - beta: 1.0000e-04 - val_loss: 30969.6953 - val_recon_loss: 3.0852e-04 - val_KL loss: 117.6457 - val_beta: 1.0000e-04\n",
      "Epoch 4206/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 27774.3998 - recon_loss: 2.7654e-04 - KL loss: 120.0086 - beta: 1.0000e-04 - val_loss: 31121.9570 - val_recon_loss: 3.1004e-04 - val_KL loss: 117.9683 - val_beta: 1.0000e-04\n",
      "Epoch 4207/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 27812.0542 - recon_loss: 2.7692e-04 - KL loss: 120.3722 - beta: 1.0000e-04 - val_loss: 31629.6055 - val_recon_loss: 3.1512e-04 - val_KL loss: 117.8340 - val_beta: 1.0000e-04\n",
      "Epoch 4208/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 27863.5651 - recon_loss: 2.7743e-04 - KL loss: 120.2158 - beta: 1.0000e-04 - val_loss: 31734.5488 - val_recon_loss: 3.1617e-04 - val_KL loss: 118.0205 - val_beta: 1.0000e-04\n",
      "Epoch 4209/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 27537.9428 - recon_loss: 2.7418e-04 - KL loss: 120.3771 - beta: 1.0000e-04 - val_loss: 30805.2598 - val_recon_loss: 3.0687e-04 - val_KL loss: 118.2614 - val_beta: 1.0000e-04\n",
      "Epoch 4210/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 27844.2583 - recon_loss: 2.7724e-04 - KL loss: 120.3486 - beta: 1.0000e-04 - val_loss: 30705.7617 - val_recon_loss: 3.0587e-04 - val_KL loss: 118.4404 - val_beta: 1.0000e-04\n",
      "Epoch 4211/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 27739.2046 - recon_loss: 2.7619e-04 - KL loss: 120.5911 - beta: 1.0000e-04 - val_loss: 30748.3340 - val_recon_loss: 3.0630e-04 - val_KL loss: 118.3419 - val_beta: 1.0000e-04\n",
      "Epoch 4212/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 27576.9716 - recon_loss: 2.7456e-04 - KL loss: 120.5178 - beta: 1.0000e-04 - val_loss: 30899.0332 - val_recon_loss: 3.0781e-04 - val_KL loss: 118.2100 - val_beta: 1.0000e-04\n",
      "Epoch 4213/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 27908.6659 - recon_loss: 2.7788e-04 - KL loss: 120.4824 - beta: 1.0000e-04 - val_loss: 31002.8535 - val_recon_loss: 3.0885e-04 - val_KL loss: 118.3489 - val_beta: 1.0000e-04\n",
      "Epoch 4214/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 27536.4604 - recon_loss: 2.7416e-04 - KL loss: 120.5088 - beta: 1.0000e-04 - val_loss: 30981.7754 - val_recon_loss: 3.0863e-04 - val_KL loss: 118.3350 - val_beta: 1.0000e-04\n",
      "Epoch 4215/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 27630.7416 - recon_loss: 2.7510e-04 - KL loss: 120.7455 - beta: 1.0000e-04\n",
      "Epoch 04215: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 27630.8062 - recon_loss: 2.7510e-04 - KL loss: 120.7454 - beta: 1.0000e-04 - val_loss: 31002.9219 - val_recon_loss: 3.0885e-04 - val_KL loss: 118.3408 - val_beta: 1.0000e-04\n",
      "Epoch 4216/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 27882.1425 - recon_loss: 2.7761e-04 - KL loss: 120.8384 - beta: 1.0000e-04 - val_loss: 31080.1582 - val_recon_loss: 3.0962e-04 - val_KL loss: 118.4302 - val_beta: 1.0000e-04\n",
      "Epoch 4217/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 27663.5820 - recon_loss: 2.7543e-04 - KL loss: 120.9451 - beta: 1.0000e-04 - val_loss: 30815.6777 - val_recon_loss: 3.0697e-04 - val_KL loss: 118.6318 - val_beta: 1.0000e-04\n",
      "Epoch 4218/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 27448.6390 - recon_loss: 2.7328e-04 - KL loss: 120.8605 - beta: 1.0000e-04 - val_loss: 30911.3496 - val_recon_loss: 3.0793e-04 - val_KL loss: 118.6675 - val_beta: 1.0000e-04\n",
      "Epoch 4219/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 27594.5120 - recon_loss: 2.7474e-04 - KL loss: 120.9684 - beta: 1.0000e-04 - val_loss: 31101.4746 - val_recon_loss: 3.0983e-04 - val_KL loss: 118.5899 - val_beta: 1.0000e-04\n",
      "Epoch 4220/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 27646.0578 - recon_loss: 2.7525e-04 - KL loss: 121.1207 - beta: 1.0000e-04\n",
      "Epoch 04220: ReduceLROnPlateau reducing learning rate to 9.999999654550589e-08.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 27646.1404 - recon_loss: 2.7525e-04 - KL loss: 121.1208 - beta: 1.0000e-04 - val_loss: 30861.0137 - val_recon_loss: 3.0742e-04 - val_KL loss: 118.6951 - val_beta: 1.0000e-04\n",
      "Epoch 4220/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 46386.6072 - recon_loss: 2.9190e-04 - KL loss: 123.0856 - beta: 7.9433e-05 - val_loss: 53785.4297 - val_recon_loss: 3.3855e-04 - val_KL loss: 128.5318 - val_beta: 7.9433e-05\n",
      "Epoch 4221/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 45664.6650 - recon_loss: 2.8730e-04 - KL loss: 130.5811 - beta: 7.9433e-05 - val_loss: 52532.3672 - val_recon_loss: 3.3062e-04 - val_KL loss: 133.0464 - val_beta: 7.9433e-05\n",
      "Epoch 4222/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 46380.4929 - recon_loss: 2.9179e-04 - KL loss: 135.5615 - beta: 7.9433e-05 - val_loss: 52253.9922 - val_recon_loss: 3.2884e-04 - val_KL loss: 136.4132 - val_beta: 7.9433e-05\n",
      "Epoch 4223/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 45943.9672 - recon_loss: 2.8900e-04 - KL loss: 140.0377 - beta: 7.9433e-05 - val_loss: 53191.7148 - val_recon_loss: 3.3473e-04 - val_KL loss: 140.1049 - val_beta: 7.9433e-05\n",
      "Epoch 4224/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 49391.0957 - recon_loss: 3.1069e-04 - KL loss: 149.9057 - beta: 7.9433e-05 - val_loss: 53300.0156 - val_recon_loss: 3.3534e-04 - val_KL loss: 152.7110 - val_beta: 7.9433e-05\n",
      "Epoch 4225/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 49841.3015 - recon_loss: 3.1346e-04 - KL loss: 161.1877 - beta: 7.9433e-05 - val_loss: 55864.1992 - val_recon_loss: 3.5141e-04 - val_KL loss: 169.0219 - val_beta: 7.9433e-05\n",
      "Epoch 4226/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 49589.7600 - recon_loss: 3.1184e-04 - KL loss: 166.7763 - beta: 7.9433e-05 - val_loss: 56683.7617 - val_recon_loss: 3.5657e-04 - val_KL loss: 171.1498 - val_beta: 7.9433e-05\n",
      "Epoch 4227/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 51406.5313 - recon_loss: 3.2325e-04 - KL loss: 174.7876 - beta: 7.9433e-05\n",
      "Epoch 04227: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 51405.7104 - recon_loss: 3.2325e-04 - KL loss: 174.7867 - beta: 7.9433e-05 - val_loss: 53895.9219 - val_recon_loss: 3.3902e-04 - val_KL loss: 165.6465 - val_beta: 7.9433e-05\n",
      "Epoch 4228/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 47833.3725 - recon_loss: 3.0075e-04 - KL loss: 167.5927 - beta: 7.9433e-05 - val_loss: 52483.7695 - val_recon_loss: 3.3010e-04 - val_KL loss: 166.3680 - val_beta: 7.9433e-05\n",
      "Epoch 4229/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 47863.0710 - recon_loss: 3.0093e-04 - KL loss: 169.0797 - beta: 7.9433e-05 - val_loss: 51779.4570 - val_recon_loss: 3.2564e-04 - val_KL loss: 169.0976 - val_beta: 7.9433e-05\n",
      "Epoch 4230/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 47350.7971 - recon_loss: 2.9769e-04 - KL loss: 170.2698 - beta: 7.9433e-05 - val_loss: 52166.3359 - val_recon_loss: 3.2807e-04 - val_KL loss: 170.3675 - val_beta: 7.9433e-05\n",
      "Epoch 4231/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 48257.9707 - recon_loss: 3.0341e-04 - KL loss: 169.9860 - beta: 7.9433e-05 - val_loss: 51604.6992 - val_recon_loss: 3.2456e-04 - val_KL loss: 164.8409 - val_beta: 7.9433e-05\n",
      "Epoch 4232/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 47150.9745 - recon_loss: 2.9644e-04 - KL loss: 167.9323 - beta: 7.9433e-05 - val_loss: 51986.9531 - val_recon_loss: 3.2696e-04 - val_KL loss: 166.6505 - val_beta: 7.9433e-05\n",
      "Epoch 4233/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 46673.6033 - recon_loss: 2.9343e-04 - KL loss: 167.9435 - beta: 7.9433e-05 - val_loss: 51625.8906 - val_recon_loss: 3.2472e-04 - val_KL loss: 161.9998 - val_beta: 7.9433e-05\n",
      "Epoch 4234/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 45852.2523 - recon_loss: 2.8827e-04 - KL loss: 164.8319 - beta: 7.9433e-05 - val_loss: 51610.6719 - val_recon_loss: 3.2461e-04 - val_KL loss: 162.8022 - val_beta: 7.9433e-05\n",
      "Epoch 4235/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 47268.0134 - recon_loss: 2.9718e-04 - KL loss: 167.5866 - beta: 7.9433e-05 - val_loss: 52766.6250 - val_recon_loss: 3.3188e-04 - val_KL loss: 167.9520 - val_beta: 7.9433e-05\n",
      "Epoch 4236/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 46591.4497 - recon_loss: 2.9290e-04 - KL loss: 170.3477 - beta: 7.9433e-05\n",
      "Epoch 04236: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 46591.9056 - recon_loss: 2.9290e-04 - KL loss: 170.3487 - beta: 7.9433e-05 - val_loss: 53553.6523 - val_recon_loss: 3.3683e-04 - val_KL loss: 169.1072 - val_beta: 7.9433e-05\n",
      "Epoch 4237/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 46981.4971 - recon_loss: 2.9536e-04 - KL loss: 170.7828 - beta: 7.9433e-05 - val_loss: 58225.8789 - val_recon_loss: 3.6631e-04 - val_KL loss: 168.9777 - val_beta: 7.9433e-05\n",
      "Epoch 4238/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 47130.0503 - recon_loss: 2.9629e-04 - KL loss: 170.8327 - beta: 7.9433e-05 - val_loss: 53106.3867 - val_recon_loss: 3.3401e-04 - val_KL loss: 169.1699 - val_beta: 7.9433e-05\n",
      "Epoch 4239/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 46992.3173 - recon_loss: 2.9542e-04 - KL loss: 170.7462 - beta: 7.9433e-05 - val_loss: 52069.9453 - val_recon_loss: 3.2749e-04 - val_KL loss: 165.9845 - val_beta: 7.9433e-05\n",
      "Epoch 4240/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 46814.0671 - recon_loss: 2.9431e-04 - KL loss: 169.2396 - beta: 7.9433e-05 - val_loss: 52265.3008 - val_recon_loss: 3.2872e-04 - val_KL loss: 167.0424 - val_beta: 7.9433e-05\n",
      "Epoch 4241/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 46554.9202 - recon_loss: 2.9267e-04 - KL loss: 169.2931 - beta: 7.9433e-05\n",
      "Epoch 04241: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 46554.6029 - recon_loss: 2.9267e-04 - KL loss: 169.2928 - beta: 7.9433e-05 - val_loss: 52196.1992 - val_recon_loss: 3.2829e-04 - val_KL loss: 166.3788 - val_beta: 7.9433e-05\n",
      "Epoch 4241/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 75357.1160 - recon_loss: 2.9934e-04 - KL loss: 166.3271 - beta: 6.3096e-05 - val_loss: 87589.1797 - val_recon_loss: 3.4805e-04 - val_KL loss: 162.6467 - val_beta: 6.3096e-05\n",
      "Epoch 4242/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 73383.4373 - recon_loss: 2.9148e-04 - KL loss: 167.9747 - beta: 6.3096e-05 - val_loss: 83926.2188 - val_recon_loss: 3.3344e-04 - val_KL loss: 170.1039 - val_beta: 6.3096e-05\n",
      "Epoch 4243/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 73818.6409 - recon_loss: 2.9318e-04 - KL loss: 174.0467 - beta: 6.3096e-05 - val_loss: 82392.3516 - val_recon_loss: 3.2732e-04 - val_KL loss: 172.9589 - val_beta: 6.3096e-05\n",
      "Epoch 4244/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 73911.7131 - recon_loss: 2.9355e-04 - KL loss: 174.5390 - beta: 6.3096e-05 - val_loss: 79350.6797 - val_recon_loss: 3.1521e-04 - val_KL loss: 173.1460 - val_beta: 6.3096e-05\n",
      "Epoch 4245/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 72438.3569 - recon_loss: 2.8768e-04 - KL loss: 175.8813 - beta: 6.3096e-05 - val_loss: 79830.7266 - val_recon_loss: 3.1710e-04 - val_KL loss: 179.5602 - val_beta: 6.3096e-05\n",
      "Epoch 4246/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 74971.2045 - recon_loss: 2.9771e-04 - KL loss: 188.7277 - beta: 6.3096e-05 - val_loss: 81694.9766 - val_recon_loss: 3.2448e-04 - val_KL loss: 188.9241 - val_beta: 6.3096e-05\n",
      "Epoch 4247/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 74270.1953 - recon_loss: 2.9489e-04 - KL loss: 196.5190 - beta: 6.3096e-05 - val_loss: 81951.9062 - val_recon_loss: 3.2548e-04 - val_KL loss: 195.2745 - val_beta: 6.3096e-05\n",
      "Epoch 4248/10000\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 79423.3572 - recon_loss: 3.1536e-04 - KL loss: 209.4322 - beta: 6.3096e-05 - val_loss: 86903.7188 - val_recon_loss: 3.4513e-04 - val_KL loss: 210.3012 - val_beta: 6.3096e-05\n",
      "Epoch 4249/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 76381.4068 - recon_loss: 3.0325e-04 - KL loss: 208.5218 - beta: 6.3096e-05\n",
      "Epoch 04249: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 76380.6749 - recon_loss: 3.0325e-04 - KL loss: 208.5233 - beta: 6.3096e-05 - val_loss: 85057.8438 - val_recon_loss: 3.3779e-04 - val_KL loss: 208.3212 - val_beta: 6.3096e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4250/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 74732.5637 - recon_loss: 2.9668e-04 - KL loss: 209.4495 - beta: 6.3096e-05 - val_loss: 83425.1562 - val_recon_loss: 3.3129e-04 - val_KL loss: 207.9430 - val_beta: 6.3096e-05\n",
      "Epoch 4251/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 74492.9193 - recon_loss: 2.9573e-04 - KL loss: 208.7430 - beta: 6.3096e-05 - val_loss: 84049.9688 - val_recon_loss: 3.3376e-04 - val_KL loss: 213.9288 - val_beta: 6.3096e-05\n",
      "Epoch 4252/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 74948.7746 - recon_loss: 2.9753e-04 - KL loss: 213.5080 - beta: 6.3096e-05 - val_loss: 83002.3594 - val_recon_loss: 3.2960e-04 - val_KL loss: 211.3866 - val_beta: 6.3096e-05\n",
      "Epoch 4253/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 74075.9472 - recon_loss: 2.9406e-04 - KL loss: 211.8587 - beta: 6.3096e-05 - val_loss: 82513.4688 - val_recon_loss: 3.2764e-04 - val_KL loss: 213.3426 - val_beta: 6.3096e-05\n",
      "Epoch 4254/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 75289.4539 - recon_loss: 2.9887e-04 - KL loss: 217.7453 - beta: 6.3096e-05\n",
      "Epoch 04254: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 75290.2741 - recon_loss: 2.9887e-04 - KL loss: 217.7484 - beta: 6.3096e-05 - val_loss: 84198.8359 - val_recon_loss: 3.3432e-04 - val_KL loss: 222.0508 - val_beta: 6.3096e-05\n",
      "Epoch 4254/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 119431.6510 - recon_loss: 2.9945e-04 - KL loss: 216.9142 - beta: 5.0119e-05 - val_loss: 127064.1953 - val_recon_loss: 3.1865e-04 - val_KL loss: 207.3983 - val_beta: 5.0119e-05\n",
      "Epoch 4255/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 116470.6723 - recon_loss: 2.9204e-04 - KL loss: 207.2721 - beta: 5.0119e-05 - val_loss: 126742.4766 - val_recon_loss: 3.1786e-04 - val_KL loss: 199.0617 - val_beta: 5.0119e-05\n",
      "Epoch 4256/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 116901.7884 - recon_loss: 2.9313e-04 - KL loss: 203.5457 - beta: 5.0119e-05 - val_loss: 130221.3359 - val_recon_loss: 3.2659e-04 - val_KL loss: 202.5501 - val_beta: 5.0119e-05\n",
      "Epoch 4257/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 116053.9723 - recon_loss: 2.9099e-04 - KL loss: 207.0471 - beta: 5.0119e-05 - val_loss: 126817.7891 - val_recon_loss: 3.1802e-04 - val_KL loss: 210.1456 - val_beta: 5.0119e-05\n",
      "Epoch 4258/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 113465.0811 - recon_loss: 2.8447e-04 - KL loss: 214.3704 - beta: 5.0119e-05 - val_loss: 122405.9531 - val_recon_loss: 3.0693e-04 - val_KL loss: 214.8597 - val_beta: 5.0119e-05\n",
      "Epoch 4259/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 113093.3304 - recon_loss: 2.8353e-04 - KL loss: 219.0570 - beta: 5.0119e-05 - val_loss: 127847.4531 - val_recon_loss: 3.2059e-04 - val_KL loss: 219.0473 - val_beta: 5.0119e-05\n",
      "Epoch 4260/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 114377.2932 - recon_loss: 2.8675e-04 - KL loss: 220.8673 - beta: 5.0119e-05 - val_loss: 122425.2812 - val_recon_loss: 3.0696e-04 - val_KL loss: 221.6965 - val_beta: 5.0119e-05\n",
      "Epoch 4261/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 112767.0871 - recon_loss: 2.8269e-04 - KL loss: 224.4675 - beta: 5.0119e-05 - val_loss: 123287.8906 - val_recon_loss: 3.0911e-04 - val_KL loss: 230.4802 - val_beta: 5.0119e-05\n",
      "Epoch 4262/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 114632.6255 - recon_loss: 2.8736e-04 - KL loss: 230.6066 - beta: 5.0119e-05 - val_loss: 124670.9922 - val_recon_loss: 3.1259e-04 - val_KL loss: 224.9063 - val_beta: 5.0119e-05\n",
      "Epoch 4263/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 112903.6036 - recon_loss: 2.8303e-04 - KL loss: 227.8196 - beta: 5.0119e-05\n",
      "Epoch 04263: ReduceLROnPlateau reducing learning rate to 3.1622775802825263e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 112903.3890 - recon_loss: 2.8303e-04 - KL loss: 227.8204 - beta: 5.0119e-05 - val_loss: 124007.7188 - val_recon_loss: 3.1092e-04 - val_KL loss: 230.0963 - val_beta: 5.0119e-05\n",
      "Epoch 4264/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 112214.8974 - recon_loss: 2.8128e-04 - KL loss: 233.7475 - beta: 5.0119e-05 - val_loss: 122609.5312 - val_recon_loss: 3.0740e-04 - val_KL loss: 231.6976 - val_beta: 5.0119e-05\n",
      "Epoch 4265/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 110065.1384 - recon_loss: 2.7588e-04 - KL loss: 234.2665 - beta: 5.0119e-05 - val_loss: 118917.3594 - val_recon_loss: 2.9813e-04 - val_KL loss: 229.6350 - val_beta: 5.0119e-05\n",
      "Epoch 4266/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 109383.8555 - recon_loss: 2.7417e-04 - KL loss: 233.8950 - beta: 5.0119e-05 - val_loss: 118414.2422 - val_recon_loss: 2.9687e-04 - val_KL loss: 229.9340 - val_beta: 5.0119e-05\n",
      "Epoch 4267/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 109632.8893 - recon_loss: 2.7480e-04 - KL loss: 234.1048 - beta: 5.0119e-05 - val_loss: 117895.2578 - val_recon_loss: 2.9556e-04 - val_KL loss: 231.4578 - val_beta: 5.0119e-05\n",
      "Epoch 4268/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 110294.7235 - recon_loss: 2.7645e-04 - KL loss: 237.3799 - beta: 5.0119e-05 - val_loss: 121644.3594 - val_recon_loss: 3.0497e-04 - val_KL loss: 234.0930 - val_beta: 5.0119e-05\n",
      "Epoch 4269/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 108859.9046 - recon_loss: 2.7285e-04 - KL loss: 238.0555 - beta: 5.0119e-05 - val_loss: 120819.9922 - val_recon_loss: 3.0290e-04 - val_KL loss: 232.6707 - val_beta: 5.0119e-05\n",
      "Epoch 4270/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 110337.2831 - recon_loss: 2.7656e-04 - KL loss: 237.0388 - beta: 5.0119e-05 - val_loss: 121097.9453 - val_recon_loss: 3.0360e-04 - val_KL loss: 234.2239 - val_beta: 5.0119e-05\n",
      "Epoch 4271/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 109377.7815 - recon_loss: 2.7414e-04 - KL loss: 238.8815 - beta: 5.0119e-05 - val_loss: 118517.1172 - val_recon_loss: 2.9711e-04 - val_KL loss: 234.8071 - val_beta: 5.0119e-05\n",
      "Epoch 4272/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 110415.1633 - recon_loss: 2.7675e-04 - KL loss: 240.7697 - beta: 5.0119e-05\n",
      "Epoch 04272: ReduceLROnPlateau reducing learning rate to 9.99999983430526e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 110414.3561 - recon_loss: 2.7674e-04 - KL loss: 240.7691 - beta: 5.0119e-05 - val_loss: 118775.8359 - val_recon_loss: 2.9776e-04 - val_KL loss: 235.4919 - val_beta: 5.0119e-05\n",
      "Epoch 4273/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 108089.8603 - recon_loss: 2.7091e-04 - KL loss: 239.3681 - beta: 5.0119e-05 - val_loss: 119505.4375 - val_recon_loss: 2.9959e-04 - val_KL loss: 235.4805 - val_beta: 5.0119e-05\n",
      "Epoch 4274/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 108793.5241 - recon_loss: 2.7268e-04 - KL loss: 239.3789 - beta: 5.0119e-05 - val_loss: 122383.7891 - val_recon_loss: 3.0682e-04 - val_KL loss: 235.7778 - val_beta: 5.0119e-05\n",
      "Epoch 4275/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 109039.9807 - recon_loss: 2.7330e-04 - KL loss: 239.0657 - beta: 5.0119e-05 - val_loss: 117913.7969 - val_recon_loss: 2.9560e-04 - val_KL loss: 234.7180 - val_beta: 5.0119e-05\n",
      "Epoch 4276/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 108787.7472 - recon_loss: 2.7266e-04 - KL loss: 238.1907 - beta: 5.0119e-05 - val_loss: 118176.5625 - val_recon_loss: 2.9625e-04 - val_KL loss: 235.4316 - val_beta: 5.0119e-05\n",
      "Epoch 4277/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 108996.6887 - recon_loss: 2.7319e-04 - KL loss: 239.0087 - beta: 5.0119e-05\n",
      "Epoch 04277: ReduceLROnPlateau reducing learning rate to 3.162277652184396e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 108996.2706 - recon_loss: 2.7319e-04 - KL loss: 239.0089 - beta: 5.0119e-05 - val_loss: 118054.3984 - val_recon_loss: 2.9595e-04 - val_KL loss: 235.5609 - val_beta: 5.0119e-05\n"
     ]
    }
   ],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0., patience=10, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "# init_epoch=0\n",
    "\n",
    "for beta in betas:\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "#             modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,1e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2575/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 3.7004 - recon_loss: 0.0044 - KL loss: 1.9349 - beta: 0.0500 - val_loss: 3.6087 - val_recon_loss: 0.0046 - val_KL loss: 1.7682 - val_beta: 0.0500\n",
      "Epoch 2576/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3.7006 - recon_loss: 0.0046 - KL loss: 1.8417 - beta: 0.0500 - val_loss: 3.7933 - val_recon_loss: 0.0050 - val_KL loss: 1.7943 - val_beta: 0.0500\n",
      "Epoch 2577/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3.6894 - recon_loss: 0.0047 - KL loss: 1.8271 - beta: 0.0500 - val_loss: 3.5868 - val_recon_loss: 0.0047 - val_KL loss: 1.7227 - val_beta: 0.0500\n",
      "Epoch 2578/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3.6842 - recon_loss: 0.0047 - KL loss: 1.7910 - beta: 0.0500 - val_loss: 3.7516 - val_recon_loss: 0.0051 - val_KL loss: 1.7216 - val_beta: 0.0500\n",
      "Epoch 2579/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3.6880 - recon_loss: 0.0047 - KL loss: 1.7896 - beta: 0.0500 - val_loss: 3.8333 - val_recon_loss: 0.0053 - val_KL loss: 1.7157 - val_beta: 0.0500\n",
      "Epoch 2580/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 3.6886 - recon_loss: 0.0048 - KL loss: 1.7794 - beta: 0.0500 - val_loss: 3.5379 - val_recon_loss: 0.0044 - val_KL loss: 1.7616 - val_beta: 0.0500\n",
      "Epoch 2581/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3.7016 - recon_loss: 0.0048 - KL loss: 1.7928 - beta: 0.0500 - val_loss: 3.5361 - val_recon_loss: 0.0046 - val_KL loss: 1.7071 - val_beta: 0.0500\n",
      "Epoch 2582/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 3.6893 - recon_loss: 0.0048 - KL loss: 1.7794 - beta: 0.0500 - val_loss: 3.7131 - val_recon_loss: 0.0050 - val_KL loss: 1.7303 - val_beta: 0.0500\n",
      "Epoch 2583/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3.6907 - recon_loss: 0.0048 - KL loss: 1.7763 - beta: 0.0500 - val_loss: 3.4322 - val_recon_loss: 0.0042 - val_KL loss: 1.7575 - val_beta: 0.0500\n",
      "Epoch 2584/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 3.6792 - recon_loss: 0.0048 - KL loss: 1.7538 - beta: 0.0500 - val_loss: 3.6125 - val_recon_loss: 0.0049 - val_KL loss: 1.6713 - val_beta: 0.0500\n",
      "Epoch 2585/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 3.6700 - recon_loss: 0.0048 - KL loss: 1.7551 - beta: 0.0500 - val_loss: 3.6960 - val_recon_loss: 0.0049 - val_KL loss: 1.7380 - val_beta: 0.0500\n",
      "Epoch 2586/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 3.6739 - recon_loss: 0.0048 - KL loss: 1.7736 - beta: 0.0500 - val_loss: 3.7937 - val_recon_loss: 0.0050 - val_KL loss: 1.7816 - val_beta: 0.0500\n",
      "Epoch 2587/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3.6742 - recon_loss: 0.0048 - KL loss: 1.7611 - beta: 0.0500 - val_loss: 3.9111 - val_recon_loss: 0.0055 - val_KL loss: 1.7095 - val_beta: 0.0500\n",
      "Epoch 2588/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3.6774 - recon_loss: 0.0048 - KL loss: 1.7531 - beta: 0.0500\n",
      "Epoch 02588: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 3.6774 - recon_loss: 0.0048 - KL loss: 1.7531 - beta: 0.0500 - val_loss: 3.5451 - val_recon_loss: 0.0046 - val_KL loss: 1.7191 - val_beta: 0.0500\n",
      "Epoch 2589/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3.6695 - recon_loss: 0.0048 - KL loss: 1.7514 - beta: 0.0500 - val_loss: 3.5646 - val_recon_loss: 0.0047 - val_KL loss: 1.6941 - val_beta: 0.0500\n",
      "Epoch 2590/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3.6612 - recon_loss: 0.0048 - KL loss: 1.7458 - beta: 0.0500 - val_loss: 3.7151 - val_recon_loss: 0.0049 - val_KL loss: 1.7446 - val_beta: 0.0500\n",
      "Epoch 2591/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3.6622 - recon_loss: 0.0048 - KL loss: 1.7466 - beta: 0.0500 - val_loss: 3.6580 - val_recon_loss: 0.0049 - val_KL loss: 1.7121 - val_beta: 0.0500\n",
      "Epoch 2592/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 3.6546 - recon_loss: 0.0048 - KL loss: 1.7521 - beta: 0.0500 - val_loss: 3.5361 - val_recon_loss: 0.0044 - val_KL loss: 1.7598 - val_beta: 0.0500\n",
      "Epoch 2593/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3.6445 - recon_loss: 0.0048 - KL loss: 1.7417 - beta: 0.0500\n",
      "Epoch 02593: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 3.6445 - recon_loss: 0.0048 - KL loss: 1.7417 - beta: 0.0500 - val_loss: 3.7683 - val_recon_loss: 0.0051 - val_KL loss: 1.7118 - val_beta: 0.0500\n",
      "Epoch 2593/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 2.9904 - recon_loss: 0.0069 - KL loss: 1.0799 - beta: 0.0600 - val_loss: 2.9616 - val_recon_loss: 0.0086 - val_KL loss: 0.5761 - val_beta: 0.0600\n",
      "Epoch 2594/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2.9290 - recon_loss: 0.0088 - KL loss: 0.4928 - beta: 0.0600 - val_loss: 2.8374 - val_recon_loss: 0.0090 - val_KL loss: 0.3316 - val_beta: 0.0600\n",
      "Epoch 2595/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2.8994 - recon_loss: 0.0092 - KL loss: 0.3484 - beta: 0.0600 - val_loss: 2.7854 - val_recon_loss: 0.0089 - val_KL loss: 0.3270 - val_beta: 0.0600\n",
      "Epoch 2596/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2.8881 - recon_loss: 0.0091 - KL loss: 0.3469 - beta: 0.0600 - val_loss: 2.7956 - val_recon_loss: 0.0089 - val_KL loss: 0.3140 - val_beta: 0.0600\n",
      "Epoch 2597/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2.8803 - recon_loss: 0.0091 - KL loss: 0.3566 - beta: 0.0600 - val_loss: 2.8513 - val_recon_loss: 0.0090 - val_KL loss: 0.3397 - val_beta: 0.0600\n",
      "Epoch 2598/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2.8796 - recon_loss: 0.0091 - KL loss: 0.3656 - beta: 0.0600 - val_loss: 2.8375 - val_recon_loss: 0.0089 - val_KL loss: 0.3643 - val_beta: 0.0600\n",
      "Epoch 2599/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2.8791 - recon_loss: 0.0090 - KL loss: 0.3655 - beta: 0.0600 - val_loss: 2.8997 - val_recon_loss: 0.0091 - val_KL loss: 0.3706 - val_beta: 0.0600\n",
      "Epoch 2600/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.8743 - recon_loss: 0.0090 - KL loss: 0.3763 - beta: 0.0600\n",
      "Epoch 02600: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2.8743 - recon_loss: 0.0090 - KL loss: 0.3763 - beta: 0.0600 - val_loss: 2.8163 - val_recon_loss: 0.0088 - val_KL loss: 0.3605 - val_beta: 0.0600\n",
      "Epoch 2601/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2.8787 - recon_loss: 0.0090 - KL loss: 0.3782 - beta: 0.0600 - val_loss: 2.8570 - val_recon_loss: 0.0090 - val_KL loss: 0.3531 - val_beta: 0.0600\n",
      "Epoch 2602/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2.8725 - recon_loss: 0.0090 - KL loss: 0.3752 - beta: 0.0600 - val_loss: 2.8375 - val_recon_loss: 0.0089 - val_KL loss: 0.3518 - val_beta: 0.0600\n",
      "Epoch 2603/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2.8760 - recon_loss: 0.0090 - KL loss: 0.3785 - beta: 0.0600 - val_loss: 2.7989 - val_recon_loss: 0.0088 - val_KL loss: 0.3556 - val_beta: 0.0600\n",
      "Epoch 2604/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2.8745 - recon_loss: 0.0090 - KL loss: 0.3784 - beta: 0.0600 - val_loss: 2.7810 - val_recon_loss: 0.0087 - val_KL loss: 0.3639 - val_beta: 0.0600\n",
      "Epoch 2605/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2.8744 - recon_loss: 0.0090 - KL loss: 0.3837 - beta: 0.0600 - val_loss: 2.9183 - val_recon_loss: 0.0092 - val_KL loss: 0.3685 - val_beta: 0.0600\n",
      "Epoch 2606/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 2.8760 - recon_loss: 0.0090 - KL loss: 0.3831 - beta: 0.0600 - val_loss: 2.9803 - val_recon_loss: 0.0095 - val_KL loss: 0.3510 - val_beta: 0.0600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2607/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2.8753 - recon_loss: 0.0090 - KL loss: 0.3872 - beta: 0.0600 - val_loss: 2.9588 - val_recon_loss: 0.0093 - val_KL loss: 0.3630 - val_beta: 0.0600\n",
      "Epoch 2608/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2.8778 - recon_loss: 0.0090 - KL loss: 0.3877 - beta: 0.0600 - val_loss: 2.9335 - val_recon_loss: 0.0092 - val_KL loss: 0.3682 - val_beta: 0.0600\n",
      "Epoch 2609/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.8741 - recon_loss: 0.0090 - KL loss: 0.3831 - beta: 0.0600\n",
      "Epoch 02609: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2.8741 - recon_loss: 0.0090 - KL loss: 0.3831 - beta: 0.0600 - val_loss: 2.9134 - val_recon_loss: 0.0092 - val_KL loss: 0.3497 - val_beta: 0.0600\n",
      "Epoch 2610/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 2.8742 - recon_loss: 0.0090 - KL loss: 0.3825 - beta: 0.0600 - val_loss: 2.9365 - val_recon_loss: 0.0093 - val_KL loss: 0.3633 - val_beta: 0.0600\n",
      "Epoch 2611/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2.8779 - recon_loss: 0.0090 - KL loss: 0.3898 - beta: 0.0600 - val_loss: 2.8492 - val_recon_loss: 0.0089 - val_KL loss: 0.3636 - val_beta: 0.0600\n",
      "Epoch 2612/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 2.8752 - recon_loss: 0.0089 - KL loss: 0.3899 - beta: 0.0600 - val_loss: 2.9565 - val_recon_loss: 0.0093 - val_KL loss: 0.3620 - val_beta: 0.0600\n",
      "Epoch 2613/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2.8839 - recon_loss: 0.0090 - KL loss: 0.3929 - beta: 0.0600 - val_loss: 2.8765 - val_recon_loss: 0.0090 - val_KL loss: 0.3634 - val_beta: 0.0600\n",
      "Epoch 2614/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.8762 - recon_loss: 0.0089 - KL loss: 0.3911 - beta: 0.0600\n",
      "Epoch 02614: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 2.8762 - recon_loss: 0.0089 - KL loss: 0.3911 - beta: 0.0600 - val_loss: 2.8793 - val_recon_loss: 0.0091 - val_KL loss: 0.3617 - val_beta: 0.0600\n"
     ]
    }
   ],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0., patience=10, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "# init_epoch=0\n",
    "\n",
    "for beta in [0.05,0.06]:\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,3e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.concatenate((np.logspace(-3,np.log10(4e-2),10),\n",
    "              np.logspace(np.log10(4e-2),-3,10)[1:],\n",
    "              np.logspace(-3,np.log10(4e-2),20)[1:],\n",
    "              np.logspace(np.log10(4e-2),-4,20)[1:],\n",
    "              np.logspace(-4,np.log10(4e-2),30)[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.001),\n",
       " (1, 0.0015066301902946669),\n",
       " (2, 0.0022699345303073466),\n",
       " (3, 0.003419951893353393),\n",
       " (4, 0.005152602771881634),\n",
       " (5, 0.007763066894712855),\n",
       " (6, 0.011696070952851464),\n",
       " (7, 0.017621653605394538),\n",
       " (8, 0.02654931532480229),\n",
       " (9, 0.04000000000000001),\n",
       " (10, 0.02654931532480229),\n",
       " (11, 0.017621653605394538),\n",
       " (12, 0.01169607095285147),\n",
       " (13, 0.007763066894712855),\n",
       " (14, 0.005152602771881634),\n",
       " (15, 0.0034199518933533965),\n",
       " (16, 0.0022699345303073466),\n",
       " (17, 0.0015066301902946669),\n",
       " (18, 0.001),\n",
       " (19, 0.0012142802934538574),\n",
       " (20, 0.0014744766310703877),\n",
       " (21, 0.0017904279162670054),\n",
       " (22, 0.00217408133557268),\n",
       " (23, 0.0026399441221517483),\n",
       " (24, 0.0032056321233482144),\n",
       " (25, 0.0038925359154443817),\n",
       " (26, 0.004726629653685488),\n",
       " (27, 0.005739453242924919),\n",
       " (28, 0.0069693049680835725),\n",
       " (29, 0.008462689681813946),\n",
       " (30, 0.010276077310241976),\n",
       " (31, 0.01247803817183516),\n",
       " (32, 0.01515183585302444),\n",
       " (33, 0.018398575685975204),\n",
       " (34, 0.02234102788309899),\n",
       " (35, 0.027128269893950265),\n",
       " (36, 0.03294132352772139),\n",
       " (37, 0.04000000000000001),\n",
       " (38, 0.029181624545362692),\n",
       " (39, 0.021289180277662856),\n",
       " (40, 0.015531321643532431),\n",
       " (41, 0.01133072992237072),\n",
       " (42, 0.008266227660488224),\n",
       " (43, 0.006030548799871472),\n",
       " (44, 0.0043995302720084214),\n",
       " (45, 0.003209636014342678),\n",
       " (46, 0.0023415598274455587),\n",
       " (47, 0.0017082629933755135),\n",
       " (48, 0.0012462472324355392),\n",
       " (49, 0.0009091879706907812),\n",
       " (50, 0.0006632895500464647),\n",
       " (51, 0.0004838966653579622),\n",
       " (52, 0.00035302227018072657),\n",
       " (53, 0.00025754408361413874),\n",
       " (54, 0.00018788886879768225),\n",
       " (55, 0.00013707256063767186),\n",
       " (56, 0.0001),\n",
       " (57, 0.00012294934136946242),\n",
       " (58, 0.0001511654054318462),\n",
       " (59, 0.00018585687035693247),\n",
       " (60, 0.00022850979799374436),\n",
       " (61, 0.00028095129159799774),\n",
       " (62, 0.00034542776258873645),\n",
       " (63, 0.0004247011590101218),\n",
       " (64, 0.0005221672777914186),\n",
       " (65, 0.0006420012288914004),\n",
       " (66, 0.0007893362825058325),\n",
       " (67, 0.0009704837605311204),\n",
       " (68, 0.0011932033916706047),\n",
       " (69, 0.0014670357112570953),\n",
       " (70, 0.0018037107446454074),\n",
       " (71, 0.002217650480751757),\n",
       " (72, 0.002726586659961005),\n",
       " (73, 0.0033523203402896795),\n",
       " (74, 0.004121655778980683),\n",
       " (75, 0.005067548633773141),\n",
       " (76, 0.006230517668801274),\n",
       " (77, 0.007660380437699151),\n",
       " (78, 0.009418387294546249),\n",
       " (79, 0.011579845146269755),\n",
       " (80, 0.014237343338942327),\n",
       " (81, 0.01750471986373864),\n",
       " (82, 0.02152193778103612),\n",
       " (83, 0.02646108075172943),\n",
       " (84, 0.032533724503492935),\n",
       " (85, 0.04000000000000001)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(betas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2361/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 20.0883 - recon_loss: 5.3191e-04 - KL loss: 11.0240 - beta: 0.0077 - val_loss: 20.3885 - val_recon_loss: 5.7064e-04 - val_KL loss: 10.6640 - val_beta: 0.0077\n",
      "Epoch 2362/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 20.2506 - recon_loss: 5.4874e-04 - KL loss: 10.8995 - beta: 0.0077 - val_loss: 20.1433 - val_recon_loss: 5.5039e-04 - val_KL loss: 10.7640 - val_beta: 0.0077\n",
      "Epoch 2363/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 19.8772 - recon_loss: 5.3506e-04 - KL loss: 10.7591 - beta: 0.0077 - val_loss: 20.0301 - val_recon_loss: 5.4805e-04 - val_KL loss: 10.6906 - val_beta: 0.0077\n",
      "Epoch 2364/10000\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 20.0534 - recon_loss: 5.4818e-04 - KL loss: 10.7118 - beta: 0.0077 - val_loss: 19.8389 - val_recon_loss: 5.4348e-04 - val_KL loss: 10.5774 - val_beta: 0.0077\n",
      "Epoch 2365/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 20.0113 - recon_loss: 5.4637e-04 - KL loss: 10.7005 - beta: 0.0077 - val_loss: 21.2266 - val_recon_loss: 6.1782e-04 - val_KL loss: 10.6982 - val_beta: 0.0077\n",
      "Epoch 2366/10000\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 20.4141 - recon_loss: 5.6834e-04 - KL loss: 10.7290 - beta: 0.0077 - val_loss: 20.2714 - val_recon_loss: 5.8030e-04 - val_KL loss: 10.3824 - val_beta: 0.0077\n",
      "Epoch 2367/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 20.0922 - recon_loss: 5.5387e-04 - KL loss: 10.6537 - beta: 0.0077 - val_loss: 20.0389 - val_recon_loss: 5.6755e-04 - val_KL loss: 10.3672 - val_beta: 0.0077\n",
      "Epoch 2368/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 19.8994 - recon_loss: 5.4378e-04 - KL loss: 10.6328 - beta: 0.0077 - val_loss: 19.8455 - val_recon_loss: 5.4155e-04 - val_KL loss: 10.6168 - val_beta: 0.0077\n",
      "Epoch 2369/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 19.9931 - recon_loss: 5.4742e-04 - KL loss: 10.6645 - beta: 0.0077\n",
      "Epoch 02369: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 19.9932 - recon_loss: 5.4742e-04 - KL loss: 10.6645 - beta: 0.0077 - val_loss: 21.0417 - val_recon_loss: 6.0771e-04 - val_KL loss: 10.6855 - val_beta: 0.0077\n",
      "Epoch 2370/10000\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 19.8962 - recon_loss: 5.4236e-04 - KL loss: 10.6537 - beta: 0.0077 - val_loss: 20.1617 - val_recon_loss: 5.6283e-04 - val_KL loss: 10.5704 - val_beta: 0.0077\n",
      "Epoch 2371/10000\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 19.6886 - recon_loss: 5.2995e-04 - KL loss: 10.6575 - beta: 0.0077 - val_loss: 20.7143 - val_recon_loss: 5.9688e-04 - val_KL loss: 10.5428 - val_beta: 0.0077\n",
      "Epoch 2372/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 19.6840 - recon_loss: 5.2887e-04 - KL loss: 10.6715 - beta: 0.0077 - val_loss: 20.8178 - val_recon_loss: 5.8553e-04 - val_KL loss: 10.8397 - val_beta: 0.0077\n",
      "Epoch 2373/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 19.6207 - recon_loss: 5.2526e-04 - KL loss: 10.6696 - beta: 0.0077 - val_loss: 19.3539 - val_recon_loss: 5.1823e-04 - val_KL loss: 10.5226 - val_beta: 0.0077\n",
      "Epoch 2374/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 19.6389 - recon_loss: 5.2712e-04 - KL loss: 10.6562 - beta: 0.0077 - val_loss: 19.6863 - val_recon_loss: 5.3700e-04 - val_KL loss: 10.5353 - val_beta: 0.0077\n",
      "Epoch 2375/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 19.5403 - recon_loss: 5.2312e-04 - KL loss: 10.6257 - beta: 0.0077 - val_loss: 19.8641 - val_recon_loss: 5.5272e-04 - val_KL loss: 10.4451 - val_beta: 0.0077\n",
      "Epoch 2376/10000\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 19.5520 - recon_loss: 5.2505e-04 - KL loss: 10.6044 - beta: 0.0077 - val_loss: 19.9730 - val_recon_loss: 5.5842e-04 - val_KL loss: 10.4569 - val_beta: 0.0077\n",
      "Epoch 2377/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 19.5631 - recon_loss: 5.2461e-04 - KL loss: 10.6232 - beta: 0.0077 - val_loss: 20.1556 - val_recon_loss: 5.6587e-04 - val_KL loss: 10.5126 - val_beta: 0.0077\n",
      "Epoch 2378/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 19.5903 - recon_loss: 5.2584e-04 - KL loss: 10.6293 - beta: 0.0077- ETA: 2s - loss: 19.5895 - recon_loss: 5.2578e-0\n",
      "Epoch 02378: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 19.5903 - recon_loss: 5.2585e-04 - KL loss: 10.6293 - beta: 0.0077 - val_loss: 19.8501 - val_recon_loss: 5.4627e-04 - val_KL loss: 10.5410 - val_beta: 0.0077\n",
      "Epoch 2379/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 19.5640 - recon_loss: 5.2492e-04 - KL loss: 10.6188 - beta: 0.0077 - val_loss: 19.8228 - val_recon_loss: 5.4355e-04 - val_KL loss: 10.5601 - val_beta: 0.0077\n",
      "Epoch 2380/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 19.4620 - recon_loss: 5.1935e-04 - KL loss: 10.6116 - beta: 0.0077 - val_loss: 19.6718 - val_recon_loss: 5.4038e-04 - val_KL loss: 10.4630 - val_beta: 0.0077\n",
      "Epoch 2381/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 19.4859 - recon_loss: 5.1822e-04 - KL loss: 10.6548 - beta: 0.0077 - val_loss: 19.5864 - val_recon_loss: 5.3462e-04 - val_KL loss: 10.4759 - val_beta: 0.0077\n",
      "Epoch 2382/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 19.4140 - recon_loss: 5.1706e-04 - KL loss: 10.6026 - beta: 0.0077 - val_loss: 19.7962 - val_recon_loss: 5.4691e-04 - val_KL loss: 10.4762 - val_beta: 0.0077\n",
      "Epoch 2383/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 19.4793 - recon_loss: 5.1891e-04 - KL loss: 10.6366 - beta: 0.0077\n",
      "Epoch 02383: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 19.4793 - recon_loss: 5.1891e-04 - KL loss: 10.6366 - beta: 0.0077 - val_loss: 19.5929 - val_recon_loss: 5.3719e-04 - val_KL loss: 10.4386 - val_beta: 0.0077\n",
      "Epoch 2383/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.4234 - recon_loss: 6.1988e-04 - KL loss: 9.4354 - beta: 0.0094 - val_loss: 16.2469 - val_recon_loss: 6.2317e-04 - val_KL loss: 9.2218 - val_beta: 0.0094\n",
      "Epoch 2384/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.4215 - recon_loss: 6.3623e-04 - KL loss: 9.2492 - beta: 0.0094 - val_loss: 17.1136 - val_recon_loss: 7.1044e-04 - val_KL loss: 9.1048 - val_beta: 0.0094\n",
      "Epoch 2385/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.6251 - recon_loss: 6.5497e-04 - KL loss: 9.2415 - beta: 0.0094 - val_loss: 16.8133 - val_recon_loss: 6.9287e-04 - val_KL loss: 9.0025 - val_beta: 0.0094\n",
      "Epoch 2386/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 17.1640 - recon_loss: 7.0268e-04 - KL loss: 9.2426 - beta: 0.0094 - val_loss: 16.5623 - val_recon_loss: 6.3584e-04 - val_KL loss: 9.3944 - val_beta: 0.0094\n",
      "Epoch 2387/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 16.6606 - recon_loss: 6.6728e-04 - KL loss: 9.1382 - beta: 0.0094 - val_loss: 17.0161 - val_recon_loss: 7.0502e-04 - val_KL loss: 9.0683 - val_beta: 0.0094\n",
      "Epoch 2388/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 16.9699 - recon_loss: 6.8377e-04 - KL loss: 9.2616 - beta: 0.0094\n",
      "Epoch 02388: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.9699 - recon_loss: 6.8377e-04 - KL loss: 9.2616 - beta: 0.0094 - val_loss: 16.2755 - val_recon_loss: 6.3646e-04 - val_KL loss: 9.1006 - val_beta: 0.0094\n",
      "Epoch 2389/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.5996 - recon_loss: 6.5429e-04 - KL loss: 9.2236 - beta: 0.0094 - val_loss: 16.1573 - val_recon_loss: 6.2319e-04 - val_KL loss: 9.1319 - val_beta: 0.0094\n",
      "Epoch 2390/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.5438 - recon_loss: 6.5227e-04 - KL loss: 9.1907 - beta: 0.0094 - val_loss: 16.3231 - val_recon_loss: 6.4449e-04 - val_KL loss: 9.0577 - val_beta: 0.0094\n",
      "Epoch 2391/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.4018 - recon_loss: 6.4096e-04 - KL loss: 9.1761 - beta: 0.0094 - val_loss: 16.1671 - val_recon_loss: 6.2478e-04 - val_KL loss: 9.1239 - val_beta: 0.0094\n",
      "Epoch 2392/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.3575 - recon_loss: 6.3711e-04 - KL loss: 9.1752 - beta: 0.0094 - val_loss: 15.8050 - val_recon_loss: 5.8801e-04 - val_KL loss: 9.1763 - val_beta: 0.0094\n",
      "Epoch 2393/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.3030 - recon_loss: 6.3231e-04 - KL loss: 9.1748 - beta: 0.0094 - val_loss: 16.3596 - val_recon_loss: 6.5295e-04 - val_KL loss: 8.9987 - val_beta: 0.0094\n",
      "Epoch 2394/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 16.2949 - recon_loss: 6.3293e-04 - KL loss: 9.1597 - beta: 0.0094 - val_loss: 16.4110 - val_recon_loss: 6.3684e-04 - val_KL loss: 9.2318 - val_beta: 0.0094\n",
      "Epoch 2395/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 16.3028 - recon_loss: 6.3398e-04 - KL loss: 9.1557 - beta: 0.0094 - val_loss: 16.1178 - val_recon_loss: 6.2677e-04 - val_KL loss: 9.0521 - val_beta: 0.0094\n",
      "Epoch 2396/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.2726 - recon_loss: 6.3217e-04 - KL loss: 9.1460 - beta: 0.0094 - val_loss: 16.4437 - val_recon_loss: 6.5735e-04 - val_KL loss: 9.0333 - val_beta: 0.0094\n",
      "Epoch 2397/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 16.2836 - recon_loss: 6.3203e-04 - KL loss: 9.1586 - beta: 0.0094\n",
      "Epoch 02397: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.2835 - recon_loss: 6.3203e-04 - KL loss: 9.1586 - beta: 0.0094 - val_loss: 16.2596 - val_recon_loss: 6.5056e-04 - val_KL loss: 8.9257 - val_beta: 0.0094\n",
      "Epoch 2398/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 16.1354 - recon_loss: 6.2458e-04 - KL loss: 9.0944 - beta: 0.0094 - val_loss: 16.0835 - val_recon_loss: 6.2983e-04 - val_KL loss: 8.9833 - val_beta: 0.0094\n",
      "Epoch 2399/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.1276 - recon_loss: 6.2283e-04 - KL loss: 9.1063 - beta: 0.0094 - val_loss: 15.8144 - val_recon_loss: 6.0447e-04 - val_KL loss: 9.0002 - val_beta: 0.0094\n",
      "Epoch 2400/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.1724 - recon_loss: 6.2500e-04 - KL loss: 9.1267 - beta: 0.0094 - val_loss: 15.5731 - val_recon_loss: 5.8085e-04 - val_KL loss: 9.0250 - val_beta: 0.0094\n",
      "Epoch 2401/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.1306 - recon_loss: 6.2203e-04 - KL loss: 9.1184 - beta: 0.0094 - val_loss: 15.7560 - val_recon_loss: 5.9749e-04 - val_KL loss: 9.0204 - val_beta: 0.0094\n",
      "Epoch 2402/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 16.1589 - recon_loss: 6.2525e-04 - KL loss: 9.1103 - beta: 0.0094 - val_loss: 16.2955 - val_recon_loss: 6.5037e-04 - val_KL loss: 8.9637 - val_beta: 0.0094\n",
      "Epoch 2403/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 16.1182 - recon_loss: 6.2204e-04 - KL loss: 9.1058 - beta: 0.0094 - val_loss: 16.1025 - val_recon_loss: 6.3148e-04 - val_KL loss: 8.9837 - val_beta: 0.0094\n",
      "Epoch 2404/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 16.0683 - recon_loss: 6.1871e-04 - KL loss: 9.0935 - beta: 0.0094 - val_loss: 15.8706 - val_recon_loss: 6.0573e-04 - val_KL loss: 9.0421 - val_beta: 0.0094\n",
      "Epoch 2405/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 16.0994 - recon_loss: 6.1886e-04 - KL loss: 9.1229 - beta: 0.0094\n",
      "Epoch 02405: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.0994 - recon_loss: 6.1886e-04 - KL loss: 9.1229 - beta: 0.0094 - val_loss: 16.2279 - val_recon_loss: 6.4127e-04 - val_KL loss: 8.9987 - val_beta: 0.0094\n",
      "Epoch 2406/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 16.0690 - recon_loss: 6.1687e-04 - KL loss: 9.1149 - beta: 0.0094 - val_loss: 15.8479 - val_recon_loss: 6.0470e-04 - val_KL loss: 9.0309 - val_beta: 0.0094\n",
      "Epoch 2407/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.1394 - recon_loss: 6.2178e-04 - KL loss: 9.1300 - beta: 0.0094 - val_loss: 16.4331 - val_recon_loss: 6.5207e-04 - val_KL loss: 9.0821 - val_beta: 0.0094\n",
      "Epoch 2408/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.0690 - recon_loss: 6.1630e-04 - KL loss: 9.1214 - beta: 0.0094 - val_loss: 16.1405 - val_recon_loss: 6.2985e-04 - val_KL loss: 9.0401 - val_beta: 0.0094\n",
      "Epoch 2409/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.1101 - recon_loss: 6.1924e-04 - KL loss: 9.1293 - beta: 0.0094 - val_loss: 16.2643 - val_recon_loss: 6.4486e-04 - val_KL loss: 8.9947 - val_beta: 0.0094\n",
      "Epoch 2410/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 16.1103 - recon_loss: 6.1908e-04 - KL loss: 9.1313 - beta: 0.0094\n",
      "Epoch 02410: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 16.1103 - recon_loss: 6.1908e-04 - KL loss: 9.1313 - beta: 0.0094 - val_loss: 16.1801 - val_recon_loss: 6.3545e-04 - val_KL loss: 9.0166 - val_beta: 0.0094\n",
      "Epoch 2410/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 13.7812 - recon_loss: 7.6361e-04 - KL loss: 8.0865 - beta: 0.0116 - val_loss: 13.8058 - val_recon_loss: 7.8047e-04 - val_KL loss: 7.9854 - val_beta: 0.0116\n",
      "Epoch 2411/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 13.8116 - recon_loss: 7.9320e-04 - KL loss: 7.8962 - beta: 0.0116 - val_loss: 13.8068 - val_recon_loss: 7.7815e-04 - val_KL loss: 8.0037 - val_beta: 0.0116\n",
      "Epoch 2412/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 14.6255 - recon_loss: 8.9026e-04 - KL loss: 7.9863 - beta: 0.0116 - val_loss: 14.5622 - val_recon_loss: 8.7033e-04 - val_KL loss: 8.0717 - val_beta: 0.0116\n",
      "Epoch 2413/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 14.1222 - recon_loss: 8.3963e-04 - KL loss: 7.8607 - beta: 0.0116 - val_loss: 13.8085 - val_recon_loss: 7.9624e-04 - val_KL loss: 7.8705 - val_beta: 0.0116\n",
      "Epoch 2414/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 14.0574 - recon_loss: 8.3923e-04 - KL loss: 7.7988 - beta: 0.0116 - val_loss: 14.4555 - val_recon_loss: 8.8210e-04 - val_KL loss: 7.8772 - val_beta: 0.0116\n",
      "Epoch 2415/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13.8923 - recon_loss: 8.1731e-04 - KL loss: 7.7972 - beta: 0.0116\n",
      "Epoch 02415: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 13.8924 - recon_loss: 8.1732e-04 - KL loss: 7.7972 - beta: 0.0116 - val_loss: 13.8534 - val_recon_loss: 8.5038e-04 - val_KL loss: 7.5116 - val_beta: 0.0116\n",
      "Epoch 2416/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 13.7341 - recon_loss: 8.0055e-04 - KL loss: 7.7640 - beta: 0.0116 - val_loss: 14.0931 - val_recon_loss: 8.5236e-04 - val_KL loss: 7.7366 - val_beta: 0.0116\n",
      "Epoch 2417/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 13.6182 - recon_loss: 7.8417e-04 - KL loss: 7.7702 - beta: 0.0116 - val_loss: 13.4057 - val_recon_loss: 7.6434e-04 - val_KL loss: 7.7057 - val_beta: 0.0116\n",
      "Epoch 2418/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 13.5835 - recon_loss: 7.7999e-04 - KL loss: 7.7667 - beta: 0.0116 - val_loss: 13.8294 - val_recon_loss: 8.0927e-04 - val_KL loss: 7.7943 - val_beta: 0.0116\n",
      "Epoch 2419/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 13.6851 - recon_loss: 7.8783e-04 - KL loss: 7.8098 - beta: 0.0116 - val_loss: 13.5779 - val_recon_loss: 7.8711e-04 - val_KL loss: 7.7081 - val_beta: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2420/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 13.6726 - recon_loss: 7.8658e-04 - KL loss: 7.8066 - beta: 0.0116 - val_loss: 13.2507 - val_recon_loss: 7.4433e-04 - val_KL loss: 7.6998 - val_beta: 0.0116\n",
      "Epoch 2421/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 13.6387 - recon_loss: 7.8518e-04 - KL loss: 7.7832 - beta: 0.0116 - val_loss: 13.7656 - val_recon_loss: 7.9990e-04 - val_KL loss: 7.8003 - val_beta: 0.0116\n",
      "Epoch 2422/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 13.5733 - recon_loss: 7.7719e-04 - KL loss: 7.7774 - beta: 0.0116 - val_loss: 13.2710 - val_recon_loss: 7.2838e-04 - val_KL loss: 7.8392 - val_beta: 0.0116\n",
      "Epoch 2423/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 13.4816 - recon_loss: 7.7012e-04 - KL loss: 7.7385 - beta: 0.0116 - val_loss: 13.4769 - val_recon_loss: 7.7980e-04 - val_KL loss: 7.6616 - val_beta: 0.0116\n",
      "Epoch 2424/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 13.5719 - recon_loss: 7.7886e-04 - KL loss: 7.7635 - beta: 0.0116 - val_loss: 13.6290 - val_recon_loss: 8.0606e-04 - val_KL loss: 7.6178 - val_beta: 0.0116\n",
      "Epoch 2425/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 13.5532 - recon_loss: 7.7838e-04 - KL loss: 7.7485 - beta: 0.0116 - val_loss: 12.9141 - val_recon_loss: 7.0276e-04 - val_KL loss: 7.6733 - val_beta: 0.0116\n",
      "Epoch 2426/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 13.5439 - recon_loss: 7.7534e-04 - KL loss: 7.7618 - beta: 0.0116 - val_loss: 13.4204 - val_recon_loss: 7.6068e-04 - val_KL loss: 7.7476 - val_beta: 0.0116\n",
      "Epoch 2427/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 13.5235 - recon_loss: 7.7556e-04 - KL loss: 7.7397 - beta: 0.0116 - val_loss: 13.5012 - val_recon_loss: 7.7602e-04 - val_KL loss: 7.7140 - val_beta: 0.0116\n",
      "Epoch 2428/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 13.4578 - recon_loss: 7.6902e-04 - KL loss: 7.7228 - beta: 0.0116 - val_loss: 13.5648 - val_recon_loss: 7.9526e-04 - val_KL loss: 7.6341 - val_beta: 0.0116\n",
      "Epoch 2429/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 13.4712 - recon_loss: 7.7175e-04 - KL loss: 7.7158 - beta: 0.0116 - val_loss: 13.7099 - val_recon_loss: 8.2263e-04 - val_KL loss: 7.5751 - val_beta: 0.0116\n",
      "Epoch 2430/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13.4592 - recon_loss: 7.7347e-04 - KL loss: 7.6910 - beta: 0.0116\n",
      "Epoch 02430: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 13.4593 - recon_loss: 7.7348e-04 - KL loss: 7.6910 - beta: 0.0116 - val_loss: 13.9093 - val_recon_loss: 8.4767e-04 - val_KL loss: 7.5878 - val_beta: 0.0116\n",
      "Epoch 2431/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 13.5110 - recon_loss: 7.7462e-04 - KL loss: 7.7342 - beta: 0.0116 - val_loss: 13.8371 - val_recon_loss: 8.2652e-04 - val_KL loss: 7.6734 - val_beta: 0.0116\n",
      "Epoch 2432/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 13.4693 - recon_loss: 7.7032e-04 - KL loss: 7.7246 - beta: 0.0116 - val_loss: 13.7177 - val_recon_loss: 8.0779e-04 - val_KL loss: 7.6935 - val_beta: 0.0116\n",
      "Epoch 2433/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 13.4971 - recon_loss: 7.7448e-04 - KL loss: 7.7214 - beta: 0.0116 - val_loss: 13.7106 - val_recon_loss: 8.0742e-04 - val_KL loss: 7.6892 - val_beta: 0.0116\n",
      "Epoch 2434/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 13.4964 - recon_loss: 7.7190e-04 - KL loss: 7.7399 - beta: 0.0116 - val_loss: 12.9891 - val_recon_loss: 7.1046e-04 - val_KL loss: 7.6908 - val_beta: 0.0116\n",
      "Epoch 2435/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13.4697 - recon_loss: 7.6906e-04 - KL loss: 7.7345 - beta: 0.0116\n",
      "Epoch 02435: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 13.4697 - recon_loss: 7.6906e-04 - KL loss: 7.7345 - beta: 0.0116 - val_loss: 13.5752 - val_recon_loss: 7.8778e-04 - val_KL loss: 7.7003 - val_beta: 0.0116\n",
      "Epoch 2435/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.4635 - recon_loss: 9.4330e-04 - KL loss: 6.8099 - beta: 0.0142 - val_loss: 11.6225 - val_recon_loss: 0.0010 - val_KL loss: 6.5089 - val_beta: 0.0142\n",
      "Epoch 2436/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.4661 - recon_loss: 9.8040e-04 - KL loss: 6.6294 - beta: 0.0142 - val_loss: 11.6411 - val_recon_loss: 0.0010 - val_KL loss: 6.6841 - val_beta: 0.0142\n",
      "Epoch 2437/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 11.4513 - recon_loss: 9.8536e-04 - KL loss: 6.5902 - beta: 0.0142 - val_loss: 11.4736 - val_recon_loss: 9.7761e-04 - val_KL loss: 6.6507 - val_beta: 0.0142\n",
      "Epoch 2438/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 11.4903 - recon_loss: 9.9773e-04 - KL loss: 6.5681 - beta: 0.0142 - val_loss: 11.3757 - val_recon_loss: 0.0010 - val_KL loss: 6.4316 - val_beta: 0.0142\n",
      "Epoch 2439/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.4557 - recon_loss: 9.9502e-04 - KL loss: 6.5469 - beta: 0.0142 - val_loss: 11.4434 - val_recon_loss: 9.9502e-04 - val_KL loss: 6.5346 - val_beta: 0.0142\n",
      "Epoch 2440/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 11.5017 - recon_loss: 0.0010 - KL loss: 6.5567 - beta: 0.0142 - val_loss: 11.9303 - val_recon_loss: 0.0011 - val_KL loss: 6.5347 - val_beta: 0.0142\n",
      "Epoch 2441/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.5419 - recon_loss: 0.0010 - KL loss: 6.4998 - beta: 0.0142 - val_loss: 11.9165 - val_recon_loss: 0.0011 - val_KL loss: 6.4578 - val_beta: 0.0142\n",
      "Epoch 2442/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 11.4861 - recon_loss: 0.0010 - KL loss: 6.4835 - beta: 0.0142 - val_loss: 11.8311 - val_recon_loss: 0.0011 - val_KL loss: 6.6211 - val_beta: 0.0142\n",
      "Epoch 2443/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.4466 - recon_loss: 0.0010 - KL loss: 6.4906 - beta: 0.0142\n",
      "Epoch 02443: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.4466 - recon_loss: 0.0010 - KL loss: 6.4906 - beta: 0.0142 - val_loss: 11.6795 - val_recon_loss: 0.0011 - val_KL loss: 6.4852 - val_beta: 0.0142\n",
      "Epoch 2444/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 11.4898 - recon_loss: 0.0010 - KL loss: 6.5040 - beta: 0.0142 - val_loss: 11.3739 - val_recon_loss: 9.8316e-04 - val_KL loss: 6.5236 - val_beta: 0.0142\n",
      "Epoch 2445/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.3847 - recon_loss: 9.9264e-04 - KL loss: 6.4877 - beta: 0.0142 - val_loss: 11.4347 - val_recon_loss: 9.9975e-04 - val_KL loss: 6.5026 - val_beta: 0.0142\n",
      "Epoch 2446/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 11.3405 - recon_loss: 9.8464e-04 - KL loss: 6.4829 - beta: 0.0142 - val_loss: 11.0800 - val_recon_loss: 9.3781e-04 - val_KL loss: 6.4535 - val_beta: 0.0142\n",
      "Epoch 2447/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 11.3191 - recon_loss: 9.8278e-04 - KL loss: 6.4707 - beta: 0.0142 - val_loss: 11.2421 - val_recon_loss: 9.5335e-04 - val_KL loss: 6.5389 - val_beta: 0.0142\n",
      "Epoch 2448/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.3975 - recon_loss: 9.9717e-04 - KL loss: 6.4781 - beta: 0.0142 - val_loss: 11.4736 - val_recon_loss: 0.0010 - val_KL loss: 6.3932 - val_beta: 0.0142\n",
      "Epoch 2449/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 11.3096 - recon_loss: 9.8307e-04 - KL loss: 6.4597 - beta: 0.0142 - val_loss: 11.2510 - val_recon_loss: 9.7892e-04 - val_KL loss: 6.4217 - val_beta: 0.0142\n",
      "Epoch 2450/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 11.2672 - recon_loss: 9.7168e-04 - KL loss: 6.4735 - beta: 0.0142 - val_loss: 11.0627 - val_recon_loss: 9.4091e-04 - val_KL loss: 6.4208 - val_beta: 0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2451/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.2501 - recon_loss: 9.7583e-04 - KL loss: 6.4360 - beta: 0.0142 - val_loss: 11.0009 - val_recon_loss: 9.2856e-04 - val_KL loss: 6.4200 - val_beta: 0.0142\n",
      "Epoch 2452/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.2705 - recon_loss: 9.7540e-04 - KL loss: 6.4585 - beta: 0.0142 - val_loss: 10.8707 - val_recon_loss: 8.9824e-04 - val_KL loss: 6.4394 - val_beta: 0.0142\n",
      "Epoch 2453/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.3087 - recon_loss: 9.8209e-04 - KL loss: 6.4637 - beta: 0.0142 - val_loss: 11.2252 - val_recon_loss: 9.7125e-04 - val_KL loss: 6.4337 - val_beta: 0.0142\n",
      "Epoch 2454/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 11.2655 - recon_loss: 9.8180e-04 - KL loss: 6.4219 - beta: 0.0142 - val_loss: 11.0881 - val_recon_loss: 9.5029e-04 - val_KL loss: 6.4000 - val_beta: 0.0142\n",
      "Epoch 2455/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 11.2686 - recon_loss: 9.7682e-04 - KL loss: 6.4496 - beta: 0.0142 - val_loss: 11.2705 - val_recon_loss: 9.8039e-04 - val_KL loss: 6.4339 - val_beta: 0.0142\n",
      "Epoch 2456/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.2976 - recon_loss: 9.8195e-04 - KL loss: 6.4533 - beta: 0.0142 - val_loss: 11.2137 - val_recon_loss: 9.8849e-04 - val_KL loss: 6.3372 - val_beta: 0.0142\n",
      "Epoch 2457/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.2964 - recon_loss: 9.8671e-04 - KL loss: 6.4287 - beta: 0.0142\n",
      "Epoch 02457: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.2965 - recon_loss: 9.8671e-04 - KL loss: 6.4287 - beta: 0.0142 - val_loss: 11.1536 - val_recon_loss: 9.8094e-04 - val_KL loss: 6.3143 - val_beta: 0.0142\n",
      "Epoch 2458/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 11.3150 - recon_loss: 9.8319e-04 - KL loss: 6.4645 - beta: 0.0142 - val_loss: 11.0994 - val_recon_loss: 9.4320e-04 - val_KL loss: 6.4463 - val_beta: 0.0142\n",
      "Epoch 2459/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 11.2756 - recon_loss: 9.7827e-04 - KL loss: 6.4494 - beta: 0.0142 - val_loss: 11.3542 - val_recon_loss: 0.0010 - val_KL loss: 6.4015 - val_beta: 0.0142\n",
      "Epoch 2460/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 11.2722 - recon_loss: 9.7705e-04 - KL loss: 6.4521 - beta: 0.0142 - val_loss: 11.2758 - val_recon_loss: 9.9430e-04 - val_KL loss: 6.3706 - val_beta: 0.0142\n",
      "Epoch 2461/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.2529 - recon_loss: 9.7462e-04 - KL loss: 6.4447 - beta: 0.0142 - val_loss: 10.8793 - val_recon_loss: 9.0363e-04 - val_KL loss: 6.4214 - val_beta: 0.0142\n",
      "Epoch 2462/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.3171 - recon_loss: 9.8268e-04 - KL loss: 6.4692 - beta: 0.0142\n",
      "Epoch 02462: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 11.3171 - recon_loss: 9.8268e-04 - KL loss: 6.4692 - beta: 0.0142 - val_loss: 11.0319 - val_recon_loss: 9.2451e-04 - val_KL loss: 6.4710 - val_beta: 0.0142\n",
      "Epoch 2462/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 9.5371 - recon_loss: 0.0012 - KL loss: 5.6463 - beta: 0.0175 - val_loss: 9.3823 - val_recon_loss: 0.0012 - val_KL loss: 5.4865 - val_beta: 0.0175\n",
      "Epoch 2463/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 9.5725 - recon_loss: 0.0012 - KL loss: 5.5188 - beta: 0.0175 - val_loss: 10.0187 - val_recon_loss: 0.0014 - val_KL loss: 5.4765 - val_beta: 0.0175\n",
      "Epoch 2464/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 9.6914 - recon_loss: 0.0013 - KL loss: 5.4804 - beta: 0.0175 - val_loss: 9.7817 - val_recon_loss: 0.0013 - val_KL loss: 5.5458 - val_beta: 0.0175\n",
      "Epoch 2465/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 9.6849 - recon_loss: 0.0013 - KL loss: 5.4398 - beta: 0.0175 - val_loss: 9.7239 - val_recon_loss: 0.0014 - val_KL loss: 5.2074 - val_beta: 0.0175\n",
      "Epoch 2466/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 9.7052 - recon_loss: 0.0013 - KL loss: 5.3947 - beta: 0.0175 - val_loss: 9.8894 - val_recon_loss: 0.0014 - val_KL loss: 5.2275 - val_beta: 0.0175\n",
      "Epoch 2467/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.6563 - recon_loss: 0.0013 - KL loss: 5.3873 - beta: 0.0175\n",
      "Epoch 02467: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 9.6563 - recon_loss: 0.0013 - KL loss: 5.3873 - beta: 0.0175 - val_loss: 9.5653 - val_recon_loss: 0.0013 - val_KL loss: 5.2530 - val_beta: 0.0175\n",
      "Epoch 2468/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 9.6088 - recon_loss: 0.0013 - KL loss: 5.3498 - beta: 0.0175 - val_loss: 9.8758 - val_recon_loss: 0.0014 - val_KL loss: 5.4008 - val_beta: 0.0175\n",
      "Epoch 2469/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 9.5688 - recon_loss: 0.0013 - KL loss: 5.3676 - beta: 0.0175 - val_loss: 9.5583 - val_recon_loss: 0.0013 - val_KL loss: 5.4056 - val_beta: 0.0175\n",
      "Epoch 2470/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 9.5122 - recon_loss: 0.0013 - KL loss: 5.3761 - beta: 0.0175 - val_loss: 9.4361 - val_recon_loss: 0.0013 - val_KL loss: 5.2911 - val_beta: 0.0175\n",
      "Epoch 2471/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 9.5185 - recon_loss: 0.0013 - KL loss: 5.3697 - beta: 0.0175 - val_loss: 9.2269 - val_recon_loss: 0.0012 - val_KL loss: 5.3462 - val_beta: 0.0175\n",
      "Epoch 2472/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 9.5167 - recon_loss: 0.0013 - KL loss: 5.3462 - beta: 0.0175 - val_loss: 9.4724 - val_recon_loss: 0.0013 - val_KL loss: 5.2436 - val_beta: 0.0175\n",
      "Epoch 2473/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 9.4528 - recon_loss: 0.0013 - KL loss: 5.3505 - beta: 0.0175 - val_loss: 9.5488 - val_recon_loss: 0.0013 - val_KL loss: 5.2721 - val_beta: 0.0175\n",
      "Epoch 2474/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 9.5003 - recon_loss: 0.0013 - KL loss: 5.3447 - beta: 0.0175 - val_loss: 9.1744 - val_recon_loss: 0.0012 - val_KL loss: 5.3266 - val_beta: 0.0175\n",
      "Epoch 2475/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 9.5058 - recon_loss: 0.0013 - KL loss: 5.3830 - beta: 0.0175 - val_loss: 9.6387 - val_recon_loss: 0.0013 - val_KL loss: 5.3221 - val_beta: 0.0175\n",
      "Epoch 2476/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 9.5041 - recon_loss: 0.0013 - KL loss: 5.3963 - beta: 0.0175 - val_loss: 9.8167 - val_recon_loss: 0.0014 - val_KL loss: 5.3686 - val_beta: 0.0175\n",
      "Epoch 2477/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 9.4913 - recon_loss: 0.0013 - KL loss: 5.3801 - beta: 0.0175 - val_loss: 9.5616 - val_recon_loss: 0.0013 - val_KL loss: 5.3054 - val_beta: 0.0175\n",
      "Epoch 2478/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 9.4590 - recon_loss: 0.0013 - KL loss: 5.3540 - beta: 0.0175 - val_loss: 9.5934 - val_recon_loss: 0.0013 - val_KL loss: 5.2936 - val_beta: 0.0175\n",
      "Epoch 2479/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.4580 - recon_loss: 0.0013 - KL loss: 5.3648 - beta: 0.0175\n",
      "Epoch 02479: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 9.4580 - recon_loss: 0.0013 - KL loss: 5.3648 - beta: 0.0175 - val_loss: 9.6055 - val_recon_loss: 0.0013 - val_KL loss: 5.3900 - val_beta: 0.0175\n",
      "Epoch 2480/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 9.4755 - recon_loss: 0.0013 - KL loss: 5.3802 - beta: 0.0175 - val_loss: 9.4108 - val_recon_loss: 0.0013 - val_KL loss: 5.2699 - val_beta: 0.0175\n",
      "Epoch 2481/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 9.4393 - recon_loss: 0.0013 - KL loss: 5.3447 - beta: 0.0175 - val_loss: 9.3906 - val_recon_loss: 0.0013 - val_KL loss: 5.3042 - val_beta: 0.0175\n",
      "Epoch 2482/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 9.4266 - recon_loss: 0.0012 - KL loss: 5.3548 - beta: 0.0175 - val_loss: 9.5392 - val_recon_loss: 0.0013 - val_KL loss: 5.3353 - val_beta: 0.0175\n",
      "Epoch 2483/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 9.4240 - recon_loss: 0.0012 - KL loss: 5.3498 - beta: 0.0175 - val_loss: 9.4208 - val_recon_loss: 0.0013 - val_KL loss: 5.2925 - val_beta: 0.0175\n",
      "Epoch 2484/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.4519 - recon_loss: 0.0013 - KL loss: 5.3535 - beta: 0.0175- ETA: 4s -\n",
      "Epoch 02484: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 9.4518 - recon_loss: 0.0013 - KL loss: 5.3535 - beta: 0.0175 - val_loss: 9.3078 - val_recon_loss: 0.0012 - val_KL loss: 5.3058 - val_beta: 0.0175\n",
      "Epoch 2484/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7.9719 - recon_loss: 0.0015 - KL loss: 4.6709 - beta: 0.0215 - val_loss: 8.0539 - val_recon_loss: 0.0017 - val_KL loss: 4.4760 - val_beta: 0.0215\n",
      "Epoch 2485/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 7.9698 - recon_loss: 0.0016 - KL loss: 4.5207 - beta: 0.0215 - val_loss: 7.8956 - val_recon_loss: 0.0016 - val_KL loss: 4.4656 - val_beta: 0.0215\n",
      "Epoch 2486/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 8.0178 - recon_loss: 0.0017 - KL loss: 4.4384 - beta: 0.0215 - val_loss: 8.2628 - val_recon_loss: 0.0018 - val_KL loss: 4.3853 - val_beta: 0.0215\n",
      "Epoch 2487/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 7.9555 - recon_loss: 0.0016 - KL loss: 4.3970 - beta: 0.0215 - val_loss: 7.9306 - val_recon_loss: 0.0017 - val_KL loss: 4.3102 - val_beta: 0.0215\n",
      "Epoch 2488/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7.9770 - recon_loss: 0.0017 - KL loss: 4.3633 - beta: 0.0215 - val_loss: 7.8287 - val_recon_loss: 0.0017 - val_KL loss: 4.2438 - val_beta: 0.0215\n",
      "Epoch 2489/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7.9573 - recon_loss: 0.0017 - KL loss: 4.3477 - beta: 0.0215 - val_loss: 7.7090 - val_recon_loss: 0.0016 - val_KL loss: 4.2541 - val_beta: 0.0215\n",
      "Epoch 2490/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7.9572 - recon_loss: 0.0017 - KL loss: 4.3549 - beta: 0.0215 - val_loss: 7.5538 - val_recon_loss: 0.0016 - val_KL loss: 4.1958 - val_beta: 0.0215\n",
      "Epoch 2491/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 7.8887 - recon_loss: 0.0017 - KL loss: 4.2985 - beta: 0.0215 - val_loss: 7.7314 - val_recon_loss: 0.0016 - val_KL loss: 4.2222 - val_beta: 0.0215\n",
      "Epoch 2492/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 7.8671 - recon_loss: 0.0017 - KL loss: 4.2606 - beta: 0.0215 - val_loss: 7.8595 - val_recon_loss: 0.0017 - val_KL loss: 4.2533 - val_beta: 0.0215\n",
      "Epoch 2493/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7.9160 - recon_loss: 0.0017 - KL loss: 4.2609 - beta: 0.0215 - val_loss: 7.6736 - val_recon_loss: 0.0016 - val_KL loss: 4.1421 - val_beta: 0.0215\n",
      "Epoch 2494/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7.8461 - recon_loss: 0.0017 - KL loss: 4.1727 - beta: 0.0215 - val_loss: 7.7829 - val_recon_loss: 0.0017 - val_KL loss: 4.1278 - val_beta: 0.0215\n",
      "Epoch 2495/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.8659 - recon_loss: 0.0017 - KL loss: 4.1898 - beta: 0.0215\n",
      "Epoch 02495: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7.8659 - recon_loss: 0.0017 - KL loss: 4.1898 - beta: 0.0215 - val_loss: 7.7084 - val_recon_loss: 0.0017 - val_KL loss: 4.0800 - val_beta: 0.0215\n",
      "Epoch 2496/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7.8743 - recon_loss: 0.0017 - KL loss: 4.1706 - beta: 0.0215 - val_loss: 7.6443 - val_recon_loss: 0.0016 - val_KL loss: 4.1605 - val_beta: 0.0215\n",
      "Epoch 2497/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7.7804 - recon_loss: 0.0017 - KL loss: 4.1719 - beta: 0.0215 - val_loss: 7.6403 - val_recon_loss: 0.0016 - val_KL loss: 4.1077 - val_beta: 0.0215\n",
      "Epoch 2498/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 7.7876 - recon_loss: 0.0017 - KL loss: 4.1849 - beta: 0.0215 - val_loss: 7.4840 - val_recon_loss: 0.0016 - val_KL loss: 4.0813 - val_beta: 0.0215\n",
      "Epoch 2499/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 7.7819 - recon_loss: 0.0017 - KL loss: 4.1816 - beta: 0.0215 - val_loss: 7.5466 - val_recon_loss: 0.0016 - val_KL loss: 4.1100 - val_beta: 0.0215\n",
      "Epoch 2500/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7.7603 - recon_loss: 0.0017 - KL loss: 4.1691 - beta: 0.0215 - val_loss: 7.5791 - val_recon_loss: 0.0016 - val_KL loss: 4.1237 - val_beta: 0.0215\n",
      "Epoch 2501/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7.7235 - recon_loss: 0.0017 - KL loss: 4.1591 - beta: 0.0215 - val_loss: 7.7017 - val_recon_loss: 0.0017 - val_KL loss: 4.0651 - val_beta: 0.0215\n",
      "Epoch 2502/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7.7563 - recon_loss: 0.0017 - KL loss: 4.1656 - beta: 0.0215 - val_loss: 7.6026 - val_recon_loss: 0.0016 - val_KL loss: 4.1054 - val_beta: 0.0215\n",
      "Epoch 2503/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.7563 - recon_loss: 0.0017 - KL loss: 4.1641 - beta: 0.0215\n",
      "Epoch 02503: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 7.7563 - recon_loss: 0.0017 - KL loss: 4.1641 - beta: 0.0215 - val_loss: 7.6578 - val_recon_loss: 0.0017 - val_KL loss: 4.0686 - val_beta: 0.0215\n",
      "Epoch 2504/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 7.7689 - recon_loss: 0.0017 - KL loss: 4.1665 - beta: 0.0215 - val_loss: 7.6487 - val_recon_loss: 0.0016 - val_KL loss: 4.1094 - val_beta: 0.0215\n",
      "Epoch 2505/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 7.7515 - recon_loss: 0.0017 - KL loss: 4.1580 - beta: 0.0215 - val_loss: 7.6419 - val_recon_loss: 0.0016 - val_KL loss: 4.1062 - val_beta: 0.0215\n",
      "Epoch 2506/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 7.7797 - recon_loss: 0.0017 - KL loss: 4.1696 - beta: 0.0215 - val_loss: 7.6339 - val_recon_loss: 0.0016 - val_KL loss: 4.1177 - val_beta: 0.0215\n",
      "Epoch 2507/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 7.7470 - recon_loss: 0.0017 - KL loss: 4.1616 - beta: 0.0215 - val_loss: 7.5540 - val_recon_loss: 0.0016 - val_KL loss: 4.1010 - val_beta: 0.0215\n",
      "Epoch 2508/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.7257 - recon_loss: 0.0017 - KL loss: 4.1575 - beta: 0.0215\n",
      "Epoch 02508: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 7.7257 - recon_loss: 0.0017 - KL loss: 4.1575 - beta: 0.0215 - val_loss: 7.6842 - val_recon_loss: 0.0017 - val_KL loss: 4.0878 - val_beta: 0.0215\n",
      "Epoch 2508/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.5046 - recon_loss: 0.0020 - KL loss: 3.6537 - beta: 0.0265 - val_loss: 6.3388 - val_recon_loss: 0.0019 - val_KL loss: 3.5652 - val_beta: 0.0265\n",
      "Epoch 2509/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 6.4845 - recon_loss: 0.0020 - KL loss: 3.5827 - beta: 0.0265 - val_loss: 6.3149 - val_recon_loss: 0.0019 - val_KL loss: 3.5522 - val_beta: 0.0265\n",
      "Epoch 2510/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 6.4664 - recon_loss: 0.0020 - KL loss: 3.5547 - beta: 0.0265 - val_loss: 6.4744 - val_recon_loss: 0.0020 - val_KL loss: 3.5543 - val_beta: 0.0265\n",
      "Epoch 2511/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.4829 - recon_loss: 0.0021 - KL loss: 3.5316 - beta: 0.0265 - val_loss: 6.5604 - val_recon_loss: 0.0022 - val_KL loss: 3.4718 - val_beta: 0.0265\n",
      "Epoch 2512/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 6.4756 - recon_loss: 0.0021 - KL loss: 3.5302 - beta: 0.0265 - val_loss: 6.4388 - val_recon_loss: 0.0021 - val_KL loss: 3.4606 - val_beta: 0.0265\n",
      "Epoch 2513/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.4798 - recon_loss: 0.0021 - KL loss: 3.5089 - beta: 0.0265 - val_loss: 6.4556 - val_recon_loss: 0.0021 - val_KL loss: 3.5250 - val_beta: 0.0265\n",
      "Epoch 2514/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.4382 - recon_loss: 0.0021 - KL loss: 3.5082 - beta: 0.0265\n",
      "Epoch 02514: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.4382 - recon_loss: 0.0021 - KL loss: 3.5082 - beta: 0.0265 - val_loss: 6.4591 - val_recon_loss: 0.0021 - val_KL loss: 3.5261 - val_beta: 0.0265\n",
      "Epoch 2515/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 6.4565 - recon_loss: 0.0021 - KL loss: 3.5248 - beta: 0.0265 - val_loss: 6.3095 - val_recon_loss: 0.0019 - val_KL loss: 3.5680 - val_beta: 0.0265\n",
      "Epoch 2516/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.4361 - recon_loss: 0.0020 - KL loss: 3.5196 - beta: 0.0265 - val_loss: 6.2715 - val_recon_loss: 0.0019 - val_KL loss: 3.5559 - val_beta: 0.0265\n",
      "Epoch 2517/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 6.4112 - recon_loss: 0.0020 - KL loss: 3.5246 - beta: 0.0265 - val_loss: 6.6234 - val_recon_loss: 0.0022 - val_KL loss: 3.4897 - val_beta: 0.0265\n",
      "Epoch 2518/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 6.4170 - recon_loss: 0.0020 - KL loss: 3.5200 - beta: 0.0265 - val_loss: 6.4668 - val_recon_loss: 0.0021 - val_KL loss: 3.5201 - val_beta: 0.0265\n",
      "Epoch 2519/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.3842 - recon_loss: 0.0020 - KL loss: 3.5183 - beta: 0.0265 - val_loss: 6.2683 - val_recon_loss: 0.0019 - val_KL loss: 3.5146 - val_beta: 0.0265\n",
      "Epoch 2520/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 6.4173 - recon_loss: 0.0020 - KL loss: 3.5317 - beta: 0.0265 - val_loss: 6.4024 - val_recon_loss: 0.0020 - val_KL loss: 3.4795 - val_beta: 0.0265\n",
      "Epoch 2521/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 6.4097 - recon_loss: 0.0020 - KL loss: 3.5232 - beta: 0.0265 - val_loss: 6.8185 - val_recon_loss: 0.0024 - val_KL loss: 3.4269 - val_beta: 0.0265\n",
      "Epoch 2522/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 6.4111 - recon_loss: 0.0020 - KL loss: 3.5183 - beta: 0.0265 - val_loss: 6.2420 - val_recon_loss: 0.0019 - val_KL loss: 3.5242 - val_beta: 0.0265\n",
      "Epoch 2523/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 6.3985 - recon_loss: 0.0020 - KL loss: 3.5198 - beta: 0.0265 - val_loss: 6.1981 - val_recon_loss: 0.0019 - val_KL loss: 3.5200 - val_beta: 0.0265\n",
      "Epoch 2524/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.4005 - recon_loss: 0.0020 - KL loss: 3.5279 - beta: 0.0265 - val_loss: 6.3695 - val_recon_loss: 0.0020 - val_KL loss: 3.4908 - val_beta: 0.0265\n",
      "Epoch 2525/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 6.3921 - recon_loss: 0.0020 - KL loss: 3.5097 - beta: 0.0265 - val_loss: 6.4450 - val_recon_loss: 0.0021 - val_KL loss: 3.4937 - val_beta: 0.0265\n",
      "Epoch 2526/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 6.3916 - recon_loss: 0.0020 - KL loss: 3.5118 - beta: 0.0265 - val_loss: 6.3241 - val_recon_loss: 0.0020 - val_KL loss: 3.5041 - val_beta: 0.0265\n",
      "Epoch 2527/10000\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 6.4039 - recon_loss: 0.0020 - KL loss: 3.5204 - beta: 0.0265 - val_loss: 6.3804 - val_recon_loss: 0.0020 - val_KL loss: 3.4945 - val_beta: 0.0265\n",
      "Epoch 2528/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.4141 - recon_loss: 0.0020 - KL loss: 3.5222 - beta: 0.0265\n",
      "Epoch 02528: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 6.4141 - recon_loss: 0.0020 - KL loss: 3.5222 - beta: 0.0265 - val_loss: 6.4804 - val_recon_loss: 0.0021 - val_KL loss: 3.4668 - val_beta: 0.0265\n",
      "Epoch 2529/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 6.3890 - recon_loss: 0.0020 - KL loss: 3.5100 - beta: 0.0265 - val_loss: 6.1392 - val_recon_loss: 0.0019 - val_KL loss: 3.4856 - val_beta: 0.0265\n",
      "Epoch 2530/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.3798 - recon_loss: 0.0020 - KL loss: 3.5196 - beta: 0.0265 - val_loss: 6.3580 - val_recon_loss: 0.0020 - val_KL loss: 3.4975 - val_beta: 0.0265\n",
      "Epoch 2531/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 6.3858 - recon_loss: 0.0020 - KL loss: 3.5214 - beta: 0.0265 - val_loss: 6.2122 - val_recon_loss: 0.0019 - val_KL loss: 3.5091 - val_beta: 0.0265\n",
      "Epoch 2532/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.3716 - recon_loss: 0.0020 - KL loss: 3.5275 - beta: 0.0265 - val_loss: 6.2297 - val_recon_loss: 0.0019 - val_KL loss: 3.4747 - val_beta: 0.0265\n",
      "Epoch 2533/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.3951 - recon_loss: 0.0020 - KL loss: 3.5174 - beta: 0.0265 - val_loss: 6.3555 - val_recon_loss: 0.0020 - val_KL loss: 3.4749 - val_beta: 0.0265\n",
      "Epoch 2534/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.3822 - recon_loss: 0.0020 - KL loss: 3.5192 - beta: 0.0265\n",
      "Epoch 02534: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.3822 - recon_loss: 0.0020 - KL loss: 3.5192 - beta: 0.0265 - val_loss: 6.4506 - val_recon_loss: 0.0021 - val_KL loss: 3.4797 - val_beta: 0.0265\n",
      "Epoch 2535/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 6.3861 - recon_loss: 0.0020 - KL loss: 3.5180 - beta: 0.0265 - val_loss: 6.4420 - val_recon_loss: 0.0021 - val_KL loss: 3.4872 - val_beta: 0.0265\n",
      "Epoch 2536/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.3691 - recon_loss: 0.0020 - KL loss: 3.5212 - beta: 0.0265 - val_loss: 6.4548 - val_recon_loss: 0.0021 - val_KL loss: 3.4947 - val_beta: 0.0265\n",
      "Epoch 2537/10000\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 6.3775 - recon_loss: 0.0020 - KL loss: 3.5214 - beta: 0.0265 - val_loss: 6.2146 - val_recon_loss: 0.0019 - val_KL loss: 3.4935 - val_beta: 0.0265\n",
      "Epoch 2538/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.3913 - recon_loss: 0.0020 - KL loss: 3.5220 - beta: 0.0265 - val_loss: 6.4395 - val_recon_loss: 0.0021 - val_KL loss: 3.4893 - val_beta: 0.0265\n",
      "Epoch 2539/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.3636 - recon_loss: 0.0020 - KL loss: 3.5176 - beta: 0.0265\n",
      "Epoch 02539: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 6.3636 - recon_loss: 0.0020 - KL loss: 3.5176 - beta: 0.0265 - val_loss: 6.3108 - val_recon_loss: 0.0020 - val_KL loss: 3.4935 - val_beta: 0.0265\n",
      "Epoch 2539/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3602 - recon_loss: 0.0024 - KL loss: 3.0867 - beta: 0.0325 - val_loss: 5.1438 - val_recon_loss: 0.0023 - val_KL loss: 2.9788 - val_beta: 0.0325\n",
      "Epoch 2540/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 5.3840 - recon_loss: 0.0025 - KL loss: 3.0497 - beta: 0.0325 - val_loss: 5.5249 - val_recon_loss: 0.0027 - val_KL loss: 3.0125 - val_beta: 0.0325\n",
      "Epoch 2541/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 5.4012 - recon_loss: 0.0025 - KL loss: 3.0420 - beta: 0.0325 - val_loss: 5.1665 - val_recon_loss: 0.0022 - val_KL loss: 3.0566 - val_beta: 0.0325\n",
      "Epoch 2542/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3885 - recon_loss: 0.0025 - KL loss: 3.0291 - beta: 0.0325 - val_loss: 5.3496 - val_recon_loss: 0.0024 - val_KL loss: 3.0962 - val_beta: 0.0325\n",
      "Epoch 2543/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 5.3778 - recon_loss: 0.0025 - KL loss: 3.0327 - beta: 0.0325 - val_loss: 5.3529 - val_recon_loss: 0.0025 - val_KL loss: 2.9826 - val_beta: 0.0325\n",
      "Epoch 2544/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3984 - recon_loss: 0.0025 - KL loss: 3.0254 - beta: 0.0325\n",
      "Epoch 02544: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3984 - recon_loss: 0.0025 - KL loss: 3.0254 - beta: 0.0325 - val_loss: 5.2532 - val_recon_loss: 0.0024 - val_KL loss: 3.0313 - val_beta: 0.0325\n",
      "Epoch 2545/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3656 - recon_loss: 0.0025 - KL loss: 3.0398 - beta: 0.0325 - val_loss: 5.2541 - val_recon_loss: 0.0024 - val_KL loss: 3.0155 - val_beta: 0.0325\n",
      "Epoch 2546/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 5.3456 - recon_loss: 0.0024 - KL loss: 3.0379 - beta: 0.0325 - val_loss: 5.1198 - val_recon_loss: 0.0022 - val_KL loss: 3.0360 - val_beta: 0.0325\n",
      "Epoch 2547/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3454 - recon_loss: 0.0024 - KL loss: 3.0328 - beta: 0.0325 - val_loss: 5.1164 - val_recon_loss: 0.0022 - val_KL loss: 3.0326 - val_beta: 0.0325\n",
      "Epoch 2548/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3363 - recon_loss: 0.0024 - KL loss: 3.0266 - beta: 0.0325 - val_loss: 5.3833 - val_recon_loss: 0.0025 - val_KL loss: 3.0553 - val_beta: 0.0325\n",
      "Epoch 2549/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3524 - recon_loss: 0.0024 - KL loss: 3.0459 - beta: 0.0325 - val_loss: 5.1694 - val_recon_loss: 0.0023 - val_KL loss: 3.0163 - val_beta: 0.0325\n",
      "Epoch 2550/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3455 - recon_loss: 0.0024 - KL loss: 3.0341 - beta: 0.0325 - val_loss: 5.2743 - val_recon_loss: 0.0024 - val_KL loss: 3.0314 - val_beta: 0.0325\n",
      "Epoch 2551/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3615 - recon_loss: 0.0024 - KL loss: 3.0516 - beta: 0.0325 - val_loss: 5.1994 - val_recon_loss: 0.0023 - val_KL loss: 3.0097 - val_beta: 0.0325\n",
      "Epoch 2552/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 5.3465 - recon_loss: 0.0024 - KL loss: 3.0383 - beta: 0.0325\n",
      "Epoch 02552: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3465 - recon_loss: 0.0024 - KL loss: 3.0383 - beta: 0.0325 - val_loss: 5.2609 - val_recon_loss: 0.0023 - val_KL loss: 3.0596 - val_beta: 0.0325\n",
      "Epoch 2553/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3405 - recon_loss: 0.0024 - KL loss: 3.0420 - beta: 0.0325 - val_loss: 5.1347 - val_recon_loss: 0.0022 - val_KL loss: 3.0245 - val_beta: 0.0325\n",
      "Epoch 2554/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 5.3411 - recon_loss: 0.0024 - KL loss: 3.0451 - beta: 0.0325 - val_loss: 5.0552 - val_recon_loss: 0.0021 - val_KL loss: 3.0333 - val_beta: 0.0325\n",
      "Epoch 2555/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3419 - recon_loss: 0.0024 - KL loss: 3.0370 - beta: 0.0325 - val_loss: 5.4207 - val_recon_loss: 0.0026 - val_KL loss: 3.0082 - val_beta: 0.0325\n",
      "Epoch 2556/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3441 - recon_loss: 0.0024 - KL loss: 3.0414 - beta: 0.0325 - val_loss: 5.0820 - val_recon_loss: 0.0022 - val_KL loss: 2.9923 - val_beta: 0.0325\n",
      "Epoch 2557/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3256 - recon_loss: 0.0024 - KL loss: 3.0360 - beta: 0.0325 - val_loss: 5.3586 - val_recon_loss: 0.0025 - val_KL loss: 3.0122 - val_beta: 0.0325\n",
      "Epoch 2558/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3373 - recon_loss: 0.0024 - KL loss: 3.0409 - beta: 0.0325 - val_loss: 5.1171 - val_recon_loss: 0.0022 - val_KL loss: 3.0138 - val_beta: 0.0325\n",
      "Epoch 2559/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3510 - recon_loss: 0.0024 - KL loss: 3.0480 - beta: 0.0325\n",
      "Epoch 02559: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3510 - recon_loss: 0.0024 - KL loss: 3.0480 - beta: 0.0325 - val_loss: 5.3374 - val_recon_loss: 0.0024 - val_KL loss: 3.0242 - val_beta: 0.0325\n",
      "Epoch 2560/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3352 - recon_loss: 0.0024 - KL loss: 3.0419 - beta: 0.0325 - val_loss: 5.2538 - val_recon_loss: 0.0024 - val_KL loss: 3.0162 - val_beta: 0.0325\n",
      "Epoch 2561/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3311 - recon_loss: 0.0024 - KL loss: 3.0418 - beta: 0.0325 - val_loss: 5.2102 - val_recon_loss: 0.0023 - val_KL loss: 3.0158 - val_beta: 0.0325\n",
      "Epoch 2562/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3353 - recon_loss: 0.0024 - KL loss: 3.0418 - beta: 0.0325 - val_loss: 5.2597 - val_recon_loss: 0.0024 - val_KL loss: 3.0073 - val_beta: 0.0325\n",
      "Epoch 2563/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 5.3331 - recon_loss: 0.0024 - KL loss: 3.0470 - beta: 0.0325 - val_loss: 5.3502 - val_recon_loss: 0.0025 - val_KL loss: 3.0270 - val_beta: 0.0325\n",
      "Epoch 2564/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.3309 - recon_loss: 0.0024 - KL loss: 3.0488 - beta: 0.0325\n",
      "Epoch 02564: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 5.3309 - recon_loss: 0.0024 - KL loss: 3.0488 - beta: 0.0325 - val_loss: 5.2764 - val_recon_loss: 0.0024 - val_KL loss: 3.0263 - val_beta: 0.0325\n",
      "Epoch 2564/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 4.5018 - recon_loss: 0.0031 - KL loss: 2.5788 - beta: 0.0400 - val_loss: 4.5398 - val_recon_loss: 0.0033 - val_KL loss: 2.5035 - val_beta: 0.0400\n",
      "Epoch 2565/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 4.5164 - recon_loss: 0.0032 - KL loss: 2.5257 - beta: 0.0400 - val_loss: 4.1301 - val_recon_loss: 0.0026 - val_KL loss: 2.4843 - val_beta: 0.0400\n",
      "Epoch 2566/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 4.5419 - recon_loss: 0.0033 - KL loss: 2.4903 - beta: 0.0400 - val_loss: 4.3886 - val_recon_loss: 0.0031 - val_KL loss: 2.4379 - val_beta: 0.0400\n",
      "Epoch 2567/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 4.5329 - recon_loss: 0.0033 - KL loss: 2.4890 - beta: 0.0400 - val_loss: 4.4800 - val_recon_loss: 0.0032 - val_KL loss: 2.4923 - val_beta: 0.0400\n",
      "Epoch 2568/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 4.5358 - recon_loss: 0.0033 - KL loss: 2.4763 - beta: 0.0400 - val_loss: 4.4212 - val_recon_loss: 0.0032 - val_KL loss: 2.4492 - val_beta: 0.0400\n",
      "Epoch 2569/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 4.5563 - recon_loss: 0.0034 - KL loss: 2.4494 - beta: 0.0400 - val_loss: 4.6608 - val_recon_loss: 0.0036 - val_KL loss: 2.3880 - val_beta: 0.0400\n",
      "Epoch 2570/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.5234 - recon_loss: 0.0033 - KL loss: 2.4768 - beta: 0.0400\n",
      "Epoch 02570: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 4.5234 - recon_loss: 0.0033 - KL loss: 2.4768 - beta: 0.0400 - val_loss: 4.6134 - val_recon_loss: 0.0035 - val_KL loss: 2.4103 - val_beta: 0.0400\n",
      "Epoch 2571/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 4.5095 - recon_loss: 0.0032 - KL loss: 2.4978 - beta: 0.0400 - val_loss: 4.5548 - val_recon_loss: 0.0033 - val_KL loss: 2.4754 - val_beta: 0.0400\n",
      "Epoch 2572/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 62s 62ms/step - loss: 4.4984 - recon_loss: 0.0032 - KL loss: 2.4864 - beta: 0.0400 - val_loss: 4.5668 - val_recon_loss: 0.0033 - val_KL loss: 2.4968 - val_beta: 0.0400\n",
      "Epoch 2573/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 4.4973 - recon_loss: 0.0032 - KL loss: 2.4828 - beta: 0.0400 - val_loss: 4.6145 - val_recon_loss: 0.0034 - val_KL loss: 2.4768 - val_beta: 0.0400\n",
      "Epoch 2574/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 4.4892 - recon_loss: 0.0032 - KL loss: 2.4977 - beta: 0.0400 - val_loss: 4.2506 - val_recon_loss: 0.0029 - val_KL loss: 2.4503 - val_beta: 0.0400\n",
      "Epoch 2575/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.4840 - recon_loss: 0.0032 - KL loss: 2.4818 - beta: 0.0400\n",
      "Epoch 02575: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 4.4840 - recon_loss: 0.0032 - KL loss: 2.4818 - beta: 0.0400 - val_loss: 4.4456 - val_recon_loss: 0.0032 - val_KL loss: 2.4393 - val_beta: 0.0400\n"
     ]
    }
   ],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0., patience=10, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "# init_epoch=0\n",
    "\n",
    "for beta in betas[77:]:\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,3e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1707.5351 - recon_loss: 0.0015 - KL loss: 200.7291 - beta: 0.0010 - val_loss: 1867.6572 - val_recon_loss: 0.0017 - val_KL loss: 202.4793 - val_beta: 0.0010\n",
      "Epoch 2/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1632.7755 - recon_loss: 0.0014 - KL loss: 199.2798 - beta: 0.0010 - val_loss: 1782.7384 - val_recon_loss: 0.0016 - val_KL loss: 198.2893 - val_beta: 0.0010\n",
      "Epoch 3/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1617.4430 - recon_loss: 0.0014 - KL loss: 194.6418 - beta: 0.0010 - val_loss: 1802.4832 - val_recon_loss: 0.0016 - val_KL loss: 190.1925 - val_beta: 0.0010\n",
      "Epoch 4/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1547.9140 - recon_loss: 0.0014 - KL loss: 190.3291 - beta: 0.0010 - val_loss: 1756.7653 - val_recon_loss: 0.0016 - val_KL loss: 189.1973 - val_beta: 0.0010\n",
      "Epoch 5/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1506.3151 - recon_loss: 0.0013 - KL loss: 187.8589 - beta: 0.0010 - val_loss: 1517.2557 - val_recon_loss: 0.0013 - val_KL loss: 185.5428 - val_beta: 0.0010\n",
      "Epoch 6/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1469.7839 - recon_loss: 0.0013 - KL loss: 184.0648 - beta: 0.0010 - val_loss: 1566.5254 - val_recon_loss: 0.0014 - val_KL loss: 178.5708 - val_beta: 0.0010\n",
      "Epoch 7/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1441.3355 - recon_loss: 0.0013 - KL loss: 180.4224 - beta: 0.0010 - val_loss: 1648.7372 - val_recon_loss: 0.0015 - val_KL loss: 176.4122 - val_beta: 0.0010\n",
      "Epoch 8/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1388.9638 - recon_loss: 0.0012 - KL loss: 177.9396 - beta: 0.0010 - val_loss: 1563.0760 - val_recon_loss: 0.0014 - val_KL loss: 173.8132 - val_beta: 0.0010\n",
      "Epoch 9/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1337.9897 - recon_loss: 0.0012 - KL loss: 176.2059 - beta: 0.0010 - val_loss: 1587.9456 - val_recon_loss: 0.0014 - val_KL loss: 174.9644 - val_beta: 0.0010\n",
      "Epoch 10/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1266.7781 - recon_loss: 0.0011 - KL loss: 174.6709 - beta: 0.0010\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1266.7742 - recon_loss: 0.0011 - KL loss: 174.6702 - beta: 0.0010 - val_loss: 1566.3793 - val_recon_loss: 0.0014 - val_KL loss: 177.7760 - val_beta: 0.0010\n",
      "Epoch 11/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1146.9892 - recon_loss: 9.6797e-04 - KL loss: 179.0175 - beta: 0.0010 - val_loss: 1376.7423 - val_recon_loss: 0.0012 - val_KL loss: 177.8311 - val_beta: 0.0010\n",
      "Epoch 12/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1114.9848 - recon_loss: 9.3370e-04 - KL loss: 181.2801 - beta: 0.0010 - val_loss: 1240.6753 - val_recon_loss: 0.0011 - val_KL loss: 182.5156 - val_beta: 0.0010\n",
      "Epoch 13/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1103.5110 - recon_loss: 9.2108e-04 - KL loss: 182.4263 - beta: 0.0010 - val_loss: 1294.9673 - val_recon_loss: 0.0011 - val_KL loss: 181.8769 - val_beta: 0.0010\n",
      "Epoch 14/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1089.4882 - recon_loss: 9.0773e-04 - KL loss: 181.7627 - beta: 0.0010 - val_loss: 1232.0070 - val_recon_loss: 0.0011 - val_KL loss: 177.7617 - val_beta: 0.0010\n",
      "Epoch 15/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 1086.0977 - recon_loss: 9.0631e-04 - KL loss: 179.7893 - beta: 0.0010 - val_loss: 1379.2510 - val_recon_loss: 0.0012 - val_KL loss: 181.0661 - val_beta: 0.0010\n",
      "Epoch 16/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1058.9741 - recon_loss: 8.7903e-04 - KL loss: 179.9488 - beta: 0.0010 - val_loss: 1288.2688 - val_recon_loss: 0.0011 - val_KL loss: 179.0576 - val_beta: 0.0010\n",
      "Epoch 17/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1046.2712 - recon_loss: 8.6594e-04 - KL loss: 180.3347 - beta: 0.0010 - val_loss: 1243.1650 - val_recon_loss: 0.0011 - val_KL loss: 178.8530 - val_beta: 0.0010\n",
      "Epoch 18/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1049.8253 - recon_loss: 8.7178e-04 - KL loss: 178.0407 - beta: 0.0010 - val_loss: 1263.1212 - val_recon_loss: 0.0011 - val_KL loss: 179.6289 - val_beta: 0.0010\n",
      "Epoch 19/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1030.2281 - recon_loss: 8.5263e-04 - KL loss: 177.5982 - beta: 0.0010 - val_loss: 1172.4443 - val_recon_loss: 9.9769e-04 - val_KL loss: 174.7545 - val_beta: 0.0010\n",
      "Epoch 20/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1015.4135 - recon_loss: 8.3856e-04 - KL loss: 176.8514 - beta: 0.0010 - val_loss: 1296.2305 - val_recon_loss: 0.0011 - val_KL loss: 173.3592 - val_beta: 0.0010\n",
      "Epoch 21/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 994.1613 - recon_loss: 8.1847e-04 - KL loss: 175.6901 - beta: 0.0010 - val_loss: 1149.1772 - val_recon_loss: 9.7434e-04 - val_KL loss: 174.8353 - val_beta: 0.0010\n",
      "Epoch 22/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1001.6325 - recon_loss: 8.2682e-04 - KL loss: 174.8093 - beta: 0.0010 - val_loss: 1244.6891 - val_recon_loss: 0.0011 - val_KL loss: 171.7527 - val_beta: 0.0010\n",
      "Epoch 23/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 991.3949 - recon_loss: 8.1747e-04 - KL loss: 173.9248 - beta: 0.0010 - val_loss: 1265.1768 - val_recon_loss: 0.0011 - val_KL loss: 172.0759 - val_beta: 0.0010\n",
      "Epoch 24/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 978.3572 - recon_loss: 8.0533e-04 - KL loss: 173.0273 - beta: 0.0010 - val_loss: 1250.4453 - val_recon_loss: 0.0011 - val_KL loss: 172.7040 - val_beta: 0.0010\n",
      "Epoch 25/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 952.8663 - recon_loss: 7.8017e-04 - KL loss: 172.6970 - beta: 0.0010 - val_loss: 1175.2283 - val_recon_loss: 0.0010 - val_KL loss: 171.6602 - val_beta: 0.0010\n",
      "Epoch 26/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 957.8950 - recon_loss: 7.8633e-04 - KL loss: 171.5643 - beta: 0.0010\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 957.8918 - recon_loss: 7.8633e-04 - KL loss: 171.5636 - beta: 0.0010 - val_loss: 1263.8568 - val_recon_loss: 0.0011 - val_KL loss: 171.5139 - val_beta: 0.0010\n",
      "Epoch 27/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 908.7875 - recon_loss: 7.3522e-04 - KL loss: 173.5627 - beta: 0.0010 - val_loss: 1149.2405 - val_recon_loss: 9.7459e-04 - val_KL loss: 174.6472 - val_beta: 0.0010\n",
      "Epoch 28/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 901.6085 - recon_loss: 7.2643e-04 - KL loss: 175.1825 - beta: 0.0010 - val_loss: 1118.3549 - val_recon_loss: 9.4357e-04 - val_KL loss: 174.7851 - val_beta: 0.0010\n",
      "Epoch 29/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 898.7787 - recon_loss: 7.2329e-04 - KL loss: 175.4886 - beta: 0.0010 - val_loss: 1093.2889 - val_recon_loss: 9.1741e-04 - val_KL loss: 175.8818 - val_beta: 0.0010\n",
      "Epoch 30/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 903.4567 - recon_loss: 7.2877e-04 - KL loss: 174.6887 - beta: 0.0010 - val_loss: 1192.8550 - val_recon_loss: 0.0010 - val_KL loss: 173.8365 - val_beta: 0.0010\n",
      "Epoch 31/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 898.4153 - recon_loss: 7.2341e-04 - KL loss: 175.0103 - beta: 0.0010 - val_loss: 1130.5327 - val_recon_loss: 9.5622e-04 - val_KL loss: 174.3142 - val_beta: 0.0010\n",
      "Epoch 32/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 889.9340 - recon_loss: 7.1508e-04 - KL loss: 174.8499 - beta: 0.0010 - val_loss: 1075.6235 - val_recon_loss: 9.0254e-04 - val_KL loss: 173.0794 - val_beta: 0.0010\n",
      "Epoch 33/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 887.1965 - recon_loss: 7.1350e-04 - KL loss: 173.6934 - beta: 0.0010 - val_loss: 1133.3893 - val_recon_loss: 9.5807e-04 - val_KL loss: 175.3208 - val_beta: 0.0010\n",
      "Epoch 34/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 887.9975 - recon_loss: 7.1286e-04 - KL loss: 175.1378 - beta: 0.0010 - val_loss: 1149.1617 - val_recon_loss: 9.7568e-04 - val_KL loss: 173.4819 - val_beta: 0.0010\n",
      "Epoch 35/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 877.5017 - recon_loss: 7.0312e-04 - KL loss: 174.3849 - beta: 0.0010 - val_loss: 1131.1646 - val_recon_loss: 9.5957e-04 - val_KL loss: 171.5975 - val_beta: 0.0010\n",
      "Epoch 36/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 883.7820 - recon_loss: 7.0967e-04 - KL loss: 174.1135 - beta: 0.0010 - val_loss: 1190.8569 - val_recon_loss: 0.0010 - val_KL loss: 173.2757 - val_beta: 0.0010\n",
      "Epoch 37/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 880.1304 - recon_loss: 7.0637e-04 - KL loss: 173.7586 - beta: 0.0010\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 880.1302 - recon_loss: 7.0637e-04 - KL loss: 173.7587 - beta: 0.0010 - val_loss: 1167.0806 - val_recon_loss: 9.9478e-04 - val_KL loss: 172.3015 - val_beta: 0.0010\n",
      "Epoch 38/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 855.1614 - recon_loss: 6.8107e-04 - KL loss: 174.0945 - beta: 0.0010 - val_loss: 1100.1252 - val_recon_loss: 9.2617e-04 - val_KL loss: 173.9583 - val_beta: 0.0010\n",
      "Epoch 39/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 859.7346 - recon_loss: 6.8461e-04 - KL loss: 175.1208 - beta: 0.0010 - val_loss: 1105.7524 - val_recon_loss: 9.3161e-04 - val_KL loss: 174.1392 - val_beta: 0.0010\n",
      "Epoch 40/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 860.1825 - recon_loss: 6.8487e-04 - KL loss: 175.3177 - beta: 0.0010 - val_loss: 1076.6134 - val_recon_loss: 9.0220e-04 - val_KL loss: 174.4171 - val_beta: 0.0010\n",
      "Epoch 41/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 845.9509 - recon_loss: 6.7057e-04 - KL loss: 175.3767 - beta: 0.0010 - val_loss: 1144.1093 - val_recon_loss: 9.6912e-04 - val_KL loss: 174.9929 - val_beta: 0.0010\n",
      "Epoch 42/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 854.6415 - recon_loss: 6.7898e-04 - KL loss: 175.6569 - beta: 0.0010\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 854.6427 - recon_loss: 6.7899e-04 - KL loss: 175.6567 - beta: 0.0010 - val_loss: 1118.7378 - val_recon_loss: 9.4528e-04 - val_KL loss: 173.4624 - val_beta: 0.0010\n",
      "Epoch 42/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 525.0570 - recon_loss: 8.8965e-04 - KL loss: 133.1293 - beta: 0.0015 - val_loss: 719.6743 - val_recon_loss: 0.0014 - val_KL loss: 118.0126 - val_beta: 0.0015\n",
      "Epoch 43/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 519.6570 - recon_loss: 9.1862e-04 - KL loss: 114.9671 - beta: 0.0015 - val_loss: 548.4520 - val_recon_loss: 9.9278e-04 - val_KL loss: 111.0902 - val_beta: 0.0015\n",
      "Epoch 44/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 504.7594 - recon_loss: 8.9752e-04 - KL loss: 109.3640 - beta: 0.0015 - val_loss: 577.0840 - val_recon_loss: 0.0011 - val_KL loss: 104.1153 - val_beta: 0.0015\n",
      "Epoch 45/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 503.1977 - recon_loss: 9.0657e-04 - KL loss: 103.8143 - beta: 0.0015 - val_loss: 584.3754 - val_recon_loss: 0.0011 - val_KL loss: 100.0759 - val_beta: 0.0015\n",
      "Epoch 46/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 510.5441 - recon_loss: 9.3153e-04 - KL loss: 100.1680 - beta: 0.0015 - val_loss: 470.1621 - val_recon_loss: 8.4078e-04 - val_KL loss: 99.7620 - val_beta: 0.0015\n",
      "Epoch 47/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 478.7467 - recon_loss: 8.6569e-04 - KL loss: 97.3730 - beta: 0.0015 - val_loss: 521.4086 - val_recon_loss: 9.7052e-04 - val_KL loss: 93.8522 - val_beta: 0.0015\n",
      "Epoch 48/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 487.0999 - recon_loss: 8.9333e-04 - KL loss: 93.5493 - beta: 0.0015 - val_loss: 516.5280 - val_recon_loss: 9.6544e-04 - val_KL loss: 91.2131 - val_beta: 0.0015\n",
      "Epoch 49/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 472.1037 - recon_loss: 8.6426e-04 - KL loss: 91.3610 - beta: 0.0015 - val_loss: 486.9307 - val_recon_loss: 9.0493e-04 - val_KL loss: 88.2736 - val_beta: 0.0015\n",
      "Epoch 50/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 461.0581 - recon_loss: 8.4652e-04 - KL loss: 88.1299 - beta: 0.0015 - val_loss: 544.6113 - val_recon_loss: 0.0010 - val_KL loss: 85.9949 - val_beta: 0.0015\n",
      "Epoch 51/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 455.4621 - recon_loss: 8.3943e-04 - KL loss: 85.6576 - beta: 0.0015 - val_loss: 430.6673 - val_recon_loss: 7.9032e-04 - val_KL loss: 82.4970 - val_beta: 0.0015\n",
      "Epoch 52/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 448.8403 - recon_loss: 8.3067e-04 - KL loss: 82.8958 - beta: 0.0015 - val_loss: 564.9763 - val_recon_loss: 0.0011 - val_KL loss: 82.4225 - val_beta: 0.0015\n",
      "Epoch 53/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 434.3562 - recon_loss: 8.0097e-04 - KL loss: 81.4943 - beta: 0.0015 - val_loss: 419.6401 - val_recon_loss: 7.7184e-04 - val_KL loss: 79.6121 - val_beta: 0.0015\n",
      "Epoch 54/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 436.8013 - recon_loss: 8.1302e-04 - KL loss: 78.6324 - beta: 0.0015 - val_loss: 402.6927 - val_recon_loss: 7.3564e-04 - val_KL loss: 78.6129 - val_beta: 0.0015\n",
      "Epoch 55/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 431.6338 - recon_loss: 8.0555e-04 - KL loss: 76.7575 - beta: 0.0015 - val_loss: 525.7933 - val_recon_loss: 0.0010 - val_KL loss: 76.0135 - val_beta: 0.0015\n",
      "Epoch 56/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 413.5977 - recon_loss: 7.6777e-04 - KL loss: 75.3617 - beta: 0.0015 - val_loss: 370.0892 - val_recon_loss: 6.6654e-04 - val_KL loss: 76.4512 - val_beta: 0.0015\n",
      "Epoch 57/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 410.8998 - recon_loss: 7.6368e-04 - KL loss: 74.4670 - beta: 0.0015 - val_loss: 410.1869 - val_recon_loss: 7.6505e-04 - val_KL loss: 73.1493 - val_beta: 0.0015\n",
      "Epoch 58/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 405.9890 - recon_loss: 7.5678e-04 - KL loss: 72.5968 - beta: 0.0015 - val_loss: 363.0483 - val_recon_loss: 6.6003e-04 - val_KL loss: 72.2759 - val_beta: 0.0015\n",
      "Epoch 59/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 397.8300 - recon_loss: 7.4191e-04 - KL loss: 70.9888 - beta: 0.0015 - val_loss: 388.7527 - val_recon_loss: 7.2183e-04 - val_KL loss: 70.7563 - val_beta: 0.0015\n",
      "Epoch 60/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 397.0444 - recon_loss: 7.4360e-04 - KL loss: 69.4576 - beta: 0.0015 - val_loss: 407.8938 - val_recon_loss: 7.6630e-04 - val_KL loss: 70.3063 - val_beta: 0.0015\n",
      "Epoch 61/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 392.0260 - recon_loss: 7.3350e-04 - KL loss: 68.8866 - beta: 0.0015 - val_loss: 393.6899 - val_recon_loss: 7.4033e-04 - val_KL loss: 67.5436 - val_beta: 0.0015\n",
      "Epoch 62/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 390.0014 - recon_loss: 7.3230e-04 - KL loss: 67.3952 - beta: 0.0015 - val_loss: 346.7543 - val_recon_loss: 6.3855e-04 - val_KL loss: 65.4450 - val_beta: 0.0015\n",
      "Epoch 63/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 376.6014 - recon_loss: 7.0425e-04 - KL loss: 66.3503 - beta: 0.0015 - val_loss: 385.7505 - val_recon_loss: 7.2313e-04 - val_KL loss: 67.1813 - val_beta: 0.0015\n",
      "Epoch 64/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 61s 61ms/step - loss: 378.7051 - recon_loss: 7.1065e-04 - KL loss: 65.6353 - beta: 0.0015 - val_loss: 355.5624 - val_recon_loss: 6.5970e-04 - val_KL loss: 64.9365 - val_beta: 0.0015\n",
      "Epoch 65/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 369.1693 - recon_loss: 6.9217e-04 - KL loss: 64.2402 - beta: 0.0015 - val_loss: 373.2616 - val_recon_loss: 6.9695e-04 - val_KL loss: 66.2258 - val_beta: 0.0015\n",
      "Epoch 66/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 365.8981 - recon_loss: 6.8751e-04 - KL loss: 63.0223 - beta: 0.0015 - val_loss: 479.7426 - val_recon_loss: 9.4227e-04 - val_KL loss: 64.6358 - val_beta: 0.0015\n",
      "Epoch 67/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 360.7818 - recon_loss: 6.7782e-04 - KL loss: 62.1757 - beta: 0.0015\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 360.7848 - recon_loss: 6.7782e-04 - KL loss: 62.1752 - beta: 0.0015 - val_loss: 362.9452 - val_recon_loss: 6.8159e-04 - val_KL loss: 62.6769 - val_beta: 0.0015\n",
      "Epoch 68/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 328.7089 - recon_loss: 6.0495e-04 - KL loss: 62.2052 - beta: 0.0015 - val_loss: 308.5471 - val_recon_loss: 5.5673e-04 - val_KL loss: 63.2853 - val_beta: 0.0015\n",
      "Epoch 69/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 325.7737 - recon_loss: 5.9650e-04 - KL loss: 62.9922 - beta: 0.0015 - val_loss: 311.0443 - val_recon_loss: 5.6181e-04 - val_KL loss: 63.5419 - val_beta: 0.0015\n",
      "Epoch 70/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 321.4838 - recon_loss: 5.8750e-04 - KL loss: 62.6642 - beta: 0.0015 - val_loss: 310.5038 - val_recon_loss: 5.6161e-04 - val_KL loss: 63.0926 - val_beta: 0.0015\n",
      "Epoch 71/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 320.2286 - recon_loss: 5.8606e-04 - KL loss: 62.0450 - beta: 0.0015 - val_loss: 303.0097 - val_recon_loss: 5.4630e-04 - val_KL loss: 62.3398 - val_beta: 0.0015\n",
      "Epoch 72/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 318.5736 - recon_loss: 5.8330e-04 - KL loss: 61.6054 - beta: 0.0015 - val_loss: 297.1146 - val_recon_loss: 5.3326e-04 - val_KL loss: 62.1911 - val_beta: 0.0015\n",
      "Epoch 73/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 319.8486 - recon_loss: 5.8722e-04 - KL loss: 61.1524 - beta: 0.0015 - val_loss: 337.5768 - val_recon_loss: 6.2313e-04 - val_KL loss: 63.0639 - val_beta: 0.0015\n",
      "Epoch 74/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 311.4909 - recon_loss: 5.6767e-04 - KL loss: 61.4092 - beta: 0.0015 - val_loss: 351.9265 - val_recon_loss: 6.6108e-04 - val_KL loss: 60.6924 - val_beta: 0.0015\n",
      "Epoch 75/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 306.2397 - recon_loss: 5.5790e-04 - KL loss: 60.4627 - beta: 0.0015 - val_loss: 314.9598 - val_recon_loss: 5.7467e-04 - val_KL loss: 61.7923 - val_beta: 0.0015\n",
      "Epoch 76/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 308.2218 - recon_loss: 5.6247e-04 - KL loss: 60.4296 - beta: 0.0015 - val_loss: 313.8007 - val_recon_loss: 5.7347e-04 - val_KL loss: 61.1654 - val_beta: 0.0015\n",
      "Epoch 77/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 317.2143 - recon_loss: 5.8189e-04 - KL loss: 60.8656 - beta: 0.0015\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 317.2144 - recon_loss: 5.8189e-04 - KL loss: 60.8655 - beta: 0.0015 - val_loss: 318.6937 - val_recon_loss: 5.8201e-04 - val_KL loss: 62.2949 - val_beta: 0.0015\n",
      "Epoch 78/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 305.1085 - recon_loss: 5.5433e-04 - KL loss: 60.9040 - beta: 0.0015 - val_loss: 301.2269 - val_recon_loss: 5.4196e-04 - val_KL loss: 62.4706 - val_beta: 0.0015\n",
      "Epoch 79/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 298.9141 - recon_loss: 5.4049e-04 - KL loss: 60.8041 - beta: 0.0015 - val_loss: 299.4131 - val_recon_loss: 5.3860e-04 - val_KL loss: 62.1366 - val_beta: 0.0015\n",
      "Epoch 80/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 298.9915 - recon_loss: 5.4090e-04 - KL loss: 60.7047 - beta: 0.0015 - val_loss: 299.3834 - val_recon_loss: 5.3765e-04 - val_KL loss: 62.5242 - val_beta: 0.0015\n",
      "Epoch 81/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 299.0965 - recon_loss: 5.4091e-04 - KL loss: 60.8025 - beta: 0.0015 - val_loss: 291.3498 - val_recon_loss: 5.2148e-04 - val_KL loss: 61.6159 - val_beta: 0.0015\n",
      "Epoch 82/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 295.5450 - recon_loss: 5.3376e-04 - KL loss: 60.3997 - beta: 0.0015 - val_loss: 299.9317 - val_recon_loss: 5.4067e-04 - val_KL loss: 61.7442 - val_beta: 0.0015\n",
      "Epoch 83/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 291.0329 - recon_loss: 5.2433e-04 - KL loss: 60.0426 - beta: 0.0015 - val_loss: 299.3108 - val_recon_loss: 5.3975e-04 - val_KL loss: 61.5296 - val_beta: 0.0015\n",
      "Epoch 84/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 293.1624 - recon_loss: 5.2922e-04 - KL loss: 60.0178 - beta: 0.0015 - val_loss: 286.5388 - val_recon_loss: 5.1143e-04 - val_KL loss: 61.2328 - val_beta: 0.0015\n",
      "Epoch 85/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 296.3522 - recon_loss: 5.3666e-04 - KL loss: 59.9322 - beta: 0.0015 - val_loss: 298.3337 - val_recon_loss: 5.3678e-04 - val_KL loss: 61.8583 - val_beta: 0.0015\n",
      "Epoch 86/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 293.0576 - recon_loss: 5.2943e-04 - KL loss: 59.8204 - beta: 0.0015 - val_loss: 295.6194 - val_recon_loss: 5.3177e-04 - val_KL loss: 61.3526 - val_beta: 0.0015\n",
      "Epoch 87/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 292.9828 - recon_loss: 5.2927e-04 - KL loss: 59.8154 - beta: 0.0015 - val_loss: 281.0598 - val_recon_loss: 4.9812e-04 - val_KL loss: 61.6172 - val_beta: 0.0015\n",
      "Epoch 88/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 287.2571 - recon_loss: 5.1693e-04 - KL loss: 59.5296 - beta: 0.0015 - val_loss: 276.1246 - val_recon_loss: 4.8837e-04 - val_KL loss: 60.9754 - val_beta: 0.0015\n",
      "Epoch 89/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 285.7204 - recon_loss: 5.1345e-04 - KL loss: 59.5265 - beta: 0.0015 - val_loss: 311.6239 - val_recon_loss: 5.6871e-04 - val_KL loss: 61.0844 - val_beta: 0.0015\n",
      "Epoch 90/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 287.4021 - recon_loss: 5.1772e-04 - KL loss: 59.3264 - beta: 0.0015 - val_loss: 285.2994 - val_recon_loss: 5.0806e-04 - val_KL loss: 61.4788 - val_beta: 0.0015\n",
      "Epoch 91/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 288.5868 - recon_loss: 5.2013e-04 - KL loss: 59.4464 - beta: 0.0015 - val_loss: 285.9445 - val_recon_loss: 5.1002e-04 - val_KL loss: 61.2596 - val_beta: 0.0015\n",
      "Epoch 92/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 287.9052 - recon_loss: 5.1859e-04 - KL loss: 59.4430 - beta: 0.0015 - val_loss: 279.2901 - val_recon_loss: 4.9557e-04 - val_KL loss: 60.9731 - val_beta: 0.0015\n",
      "Epoch 93/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 284.6067 - recon_loss: 5.1190e-04 - KL loss: 59.0920 - beta: 0.0015\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 284.6074 - recon_loss: 5.1191e-04 - KL loss: 59.0919 - beta: 0.0015 - val_loss: 277.7505 - val_recon_loss: 4.9192e-04 - val_KL loss: 61.0377 - val_beta: 0.0015\n",
      "Epoch 94/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 283.3554 - recon_loss: 5.0863e-04 - KL loss: 59.2809 - beta: 0.0015 - val_loss: 275.6548 - val_recon_loss: 4.8768e-04 - val_KL loss: 60.8098 - val_beta: 0.0015\n",
      "Epoch 95/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 283.5401 - recon_loss: 5.0925e-04 - KL loss: 59.1955 - beta: 0.0015 - val_loss: 273.6191 - val_recon_loss: 4.8228e-04 - val_KL loss: 61.1564 - val_beta: 0.0015\n",
      "Epoch 96/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 280.8314 - recon_loss: 5.0271e-04 - KL loss: 59.3667 - beta: 0.0015 - val_loss: 281.2482 - val_recon_loss: 4.9889e-04 - val_KL loss: 61.4651 - val_beta: 0.0015\n",
      "Epoch 97/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 280.7108 - recon_loss: 5.0228e-04 - KL loss: 59.4360 - beta: 0.0015 - val_loss: 290.5705 - val_recon_loss: 5.1973e-04 - val_KL loss: 61.6076 - val_beta: 0.0015\n",
      "Epoch 98/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 283.2767 - recon_loss: 5.0768e-04 - KL loss: 59.6242 - beta: 0.0015 - val_loss: 278.1914 - val_recon_loss: 4.9324e-04 - val_KL loss: 60.8972 - val_beta: 0.0015\n",
      "Epoch 99/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 280.8086 - recon_loss: 5.0276e-04 - KL loss: 59.3242 - beta: 0.0015 - val_loss: 275.4988 - val_recon_loss: 4.8657e-04 - val_KL loss: 61.1447 - val_beta: 0.0015\n",
      "Epoch 100/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 278.8438 - recon_loss: 4.9866e-04 - KL loss: 59.1626 - beta: 0.0015\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 278.8450 - recon_loss: 4.9866e-04 - KL loss: 59.1626 - beta: 0.0015 - val_loss: 278.9391 - val_recon_loss: 4.9490e-04 - val_KL loss: 60.9156 - val_beta: 0.0015\n",
      "Epoch 101/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 279.5667 - recon_loss: 5.0042e-04 - KL loss: 59.1119 - beta: 0.0015 - val_loss: 276.8553 - val_recon_loss: 4.8985e-04 - val_KL loss: 61.0554 - val_beta: 0.0015\n",
      "Epoch 102/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 279.8700 - recon_loss: 5.0047e-04 - KL loss: 59.3919 - beta: 0.0015 - val_loss: 279.0773 - val_recon_loss: 4.9449e-04 - val_KL loss: 61.2330 - val_beta: 0.0015\n",
      "Epoch 103/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 277.3197 - recon_loss: 4.9469e-04 - KL loss: 59.3871 - beta: 0.0015 - val_loss: 291.9627 - val_recon_loss: 5.2396e-04 - val_KL loss: 61.1352 - val_beta: 0.0015\n",
      "Epoch 104/10000\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 278.2035 - recon_loss: 4.9691e-04 - KL loss: 59.2944 - beta: 0.0015 - val_loss: 277.0618 - val_recon_loss: 4.9054e-04 - val_KL loss: 60.9591 - val_beta: 0.0015\n",
      "Epoch 105/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 278.1317 - recon_loss: 4.9706e-04 - KL loss: 59.1543 - beta: 0.0015\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 278.1324 - recon_loss: 4.9707e-04 - KL loss: 59.1543 - beta: 0.0015 - val_loss: 276.1658 - val_recon_loss: 4.8832e-04 - val_KL loss: 61.0391 - val_beta: 0.0015\n",
      "Epoch 105/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 171.1746 - recon_loss: 6.3243e-04 - KL loss: 48.4341 - beta: 0.0023 - val_loss: 178.1559 - val_recon_loss: 6.8737e-04 - val_KL loss: 44.7538 - val_beta: 0.0023\n",
      "Epoch 106/10000\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 165.0085 - recon_loss: 6.2613e-04 - KL loss: 43.4922 - beta: 0.0023 - val_loss: 170.4363 - val_recon_loss: 6.5109e-04 - val_KL loss: 44.0757 - val_beta: 0.0023\n",
      "Epoch 107/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 169.7048 - recon_loss: 6.5715e-04 - KL loss: 42.1673 - beta: 0.0023 - val_loss: 164.4833 - val_recon_loss: 6.2693e-04 - val_KL loss: 42.8118 - val_beta: 0.0023\n",
      "Epoch 108/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 169.9301 - recon_loss: 6.6691e-04 - KL loss: 40.4981 - beta: 0.0023 - val_loss: 243.3468 - val_recon_loss: 0.0010 - val_KL loss: 42.3315 - val_beta: 0.0023\n",
      "Epoch 109/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 175.1552 - recon_loss: 6.9556e-04 - KL loss: 40.1629 - beta: 0.0023 - val_loss: 159.8825 - val_recon_loss: 6.1732e-04 - val_KL loss: 40.0760 - val_beta: 0.0023\n",
      "Epoch 110/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 163.1823 - recon_loss: 6.3943e-04 - KL loss: 39.0836 - beta: 0.0023 - val_loss: 157.4550 - val_recon_loss: 6.0820e-04 - val_KL loss: 39.4184 - val_beta: 0.0023\n",
      "Epoch 111/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 163.4044 - recon_loss: 6.4613e-04 - KL loss: 38.0064 - beta: 0.0023 - val_loss: 166.5839 - val_recon_loss: 6.5219e-04 - val_KL loss: 40.0085 - val_beta: 0.0023\n",
      "Epoch 112/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 163.3421 - recon_loss: 6.4782e-04 - KL loss: 37.6148 - beta: 0.0023 - val_loss: 162.9271 - val_recon_loss: 6.4569e-04 - val_KL loss: 37.6137 - val_beta: 0.0023\n",
      "Epoch 113/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 157.3303 - recon_loss: 6.2154e-04 - KL loss: 36.7035 - beta: 0.0023 - val_loss: 152.8516 - val_recon_loss: 6.0127e-04 - val_KL loss: 36.1588 - val_beta: 0.0023\n",
      "Epoch 114/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 161.4611 - recon_loss: 6.4536e-04 - KL loss: 36.2110 - beta: 0.0023 - val_loss: 147.8843 - val_recon_loss: 5.7626e-04 - val_KL loss: 36.0457 - val_beta: 0.0023\n",
      "Epoch 115/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 158.4939 - recon_loss: 6.3329e-04 - KL loss: 35.5873 - beta: 0.0023 - val_loss: 152.6988 - val_recon_loss: 6.0301e-04 - val_KL loss: 35.6692 - val_beta: 0.0023\n",
      "Epoch 116/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 153.4443 - recon_loss: 6.0969e-04 - KL loss: 35.1176 - beta: 0.0023 - val_loss: 163.0041 - val_recon_loss: 6.5941e-04 - val_KL loss: 35.0288 - val_beta: 0.0023\n",
      "Epoch 117/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 151.7032 - recon_loss: 6.0221e-04 - KL loss: 34.8288 - beta: 0.0023 - val_loss: 150.5127 - val_recon_loss: 5.9841e-04 - val_KL loss: 34.3751 - val_beta: 0.0023\n",
      "Epoch 118/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 153.0412 - recon_loss: 6.1286e-04 - KL loss: 34.0996 - beta: 0.0023 - val_loss: 178.3925 - val_recon_loss: 7.4008e-04 - val_KL loss: 34.7601 - val_beta: 0.0023\n",
      "Epoch 119/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 151.3333 - recon_loss: 6.0708e-04 - KL loss: 33.5124 - beta: 0.0023\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 151.3337 - recon_loss: 6.0709e-04 - KL loss: 33.5125 - beta: 0.0023 - val_loss: 172.9493 - val_recon_loss: 7.1860e-04 - val_KL loss: 33.4857 - val_beta: 0.0023\n",
      "Epoch 120/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 143.1882 - recon_loss: 5.6392e-04 - KL loss: 33.7452 - beta: 0.0023 - val_loss: 160.0881 - val_recon_loss: 6.5114e-04 - val_KL loss: 33.7168 - val_beta: 0.0023\n",
      "Epoch 121/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 137.0408 - recon_loss: 5.3161e-04 - KL loss: 33.8673 - beta: 0.0023 - val_loss: 144.9382 - val_recon_loss: 5.7215e-04 - val_KL loss: 33.8976 - val_beta: 0.0023\n",
      "Epoch 122/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 136.6145 - recon_loss: 5.3041e-04 - KL loss: 33.6735 - beta: 0.0023 - val_loss: 125.5923 - val_recon_loss: 4.7436e-04 - val_KL loss: 33.5306 - val_beta: 0.0023\n",
      "Epoch 123/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 134.5688 - recon_loss: 5.2141e-04 - KL loss: 33.3744 - beta: 0.0023 - val_loss: 126.4297 - val_recon_loss: 4.7931e-04 - val_KL loss: 33.4060 - val_beta: 0.0023\n",
      "Epoch 124/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 135.7900 - recon_loss: 5.2874e-04 - KL loss: 33.1738 - beta: 0.0023 - val_loss: 126.8556 - val_recon_loss: 4.8147e-04 - val_KL loss: 33.4144 - val_beta: 0.0023\n",
      "Epoch 125/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 132.1553 - recon_loss: 5.1088e-04 - KL loss: 33.0049 - beta: 0.0023 - val_loss: 155.6138 - val_recon_loss: 6.3125e-04 - val_KL loss: 33.1028 - val_beta: 0.0023\n",
      "Epoch 126/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 132.2864 - recon_loss: 5.1339e-04 - KL loss: 32.6499 - beta: 0.0023 - val_loss: 128.6228 - val_recon_loss: 4.9208e-04 - val_KL loss: 33.1207 - val_beta: 0.0023\n",
      "Epoch 127/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 132.2808 - recon_loss: 5.1412e-04 - KL loss: 32.5015 - beta: 0.0023\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 132.2809 - recon_loss: 5.1412e-04 - KL loss: 32.5015 - beta: 0.0023 - val_loss: 131.6146 - val_recon_loss: 5.0813e-04 - val_KL loss: 32.9982 - val_beta: 0.0023\n",
      "Epoch 128/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 127.7572 - recon_loss: 4.9011e-04 - KL loss: 32.6381 - beta: 0.0023 - val_loss: 125.5420 - val_recon_loss: 4.7675e-04 - val_KL loss: 33.0163 - val_beta: 0.0023\n",
      "Epoch 129/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 127.3532 - recon_loss: 4.8783e-04 - KL loss: 32.6776 - beta: 0.0023 - val_loss: 127.8575 - val_recon_loss: 4.8741e-04 - val_KL loss: 33.2631 - val_beta: 0.0023\n",
      "Epoch 130/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 126.1672 - recon_loss: 4.8183e-04 - KL loss: 32.6554 - beta: 0.0023 - val_loss: 144.9592 - val_recon_loss: 5.7524e-04 - val_KL loss: 33.3190 - val_beta: 0.0023\n",
      "Epoch 131/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 127.0562 - recon_loss: 4.8639e-04 - KL loss: 32.6598 - beta: 0.0023 - val_loss: 127.5631 - val_recon_loss: 4.8696e-04 - val_KL loss: 33.0552 - val_beta: 0.0023\n",
      "Epoch 132/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 127.2541 - recon_loss: 4.8755e-04 - KL loss: 32.6324 - beta: 0.0023 - val_loss: 124.4958 - val_recon_loss: 4.7111e-04 - val_KL loss: 33.0639 - val_beta: 0.0023\n",
      "Epoch 133/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 126.4871 - recon_loss: 4.8452e-04 - KL loss: 32.4535 - beta: 0.0023 - val_loss: 131.7775 - val_recon_loss: 5.0983e-04 - val_KL loss: 32.8311 - val_beta: 0.0023\n",
      "Epoch 134/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 125.5968 - recon_loss: 4.8025e-04 - KL loss: 32.3915 - beta: 0.0023 - val_loss: 123.2193 - val_recon_loss: 4.6427e-04 - val_KL loss: 33.1162 - val_beta: 0.0023\n",
      "Epoch 135/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 125.4889 - recon_loss: 4.7881e-04 - KL loss: 32.5639 - beta: 0.0023 - val_loss: 125.0967 - val_recon_loss: 4.7373e-04 - val_KL loss: 33.1576 - val_beta: 0.0023\n",
      "Epoch 136/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 124.2479 - recon_loss: 4.7317e-04 - KL loss: 32.4175 - beta: 0.0023 - val_loss: 120.3067 - val_recon_loss: 4.5093e-04 - val_KL loss: 32.7908 - val_beta: 0.0023\n",
      "Epoch 137/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 125.3937 - recon_loss: 4.7934e-04 - KL loss: 32.3654 - beta: 0.0023 - val_loss: 129.6252 - val_recon_loss: 4.9775e-04 - val_KL loss: 33.0233 - val_beta: 0.0023\n",
      "Epoch 138/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 125.0604 - recon_loss: 4.7789e-04 - KL loss: 32.3132 - beta: 0.0023 - val_loss: 121.8777 - val_recon_loss: 4.5862e-04 - val_KL loss: 32.8695 - val_beta: 0.0023\n",
      "Epoch 139/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 123.8408 - recon_loss: 4.7222e-04 - KL loss: 32.1948 - beta: 0.0023 - val_loss: 126.8672 - val_recon_loss: 4.8536e-04 - val_KL loss: 32.6709 - val_beta: 0.0023\n",
      "Epoch 140/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 123.9673 - recon_loss: 4.7276e-04 - KL loss: 32.2158 - beta: 0.0023 - val_loss: 126.9581 - val_recon_loss: 4.8471e-04 - val_KL loss: 32.8873 - val_beta: 0.0023\n",
      "Epoch 141/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 123.6029 - recon_loss: 4.7191e-04 - KL loss: 32.0159 - beta: 0.0023\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 123.6029 - recon_loss: 4.7191e-04 - KL loss: 32.0160 - beta: 0.0023 - val_loss: 124.8736 - val_recon_loss: 4.7465e-04 - val_KL loss: 32.7559 - val_beta: 0.0023\n",
      "Epoch 142/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 123.3243 - recon_loss: 4.7006e-04 - KL loss: 32.0968 - beta: 0.0023 - val_loss: 136.3228 - val_recon_loss: 5.3310e-04 - val_KL loss: 32.8596 - val_beta: 0.0023\n",
      "Epoch 143/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 124.9361 - recon_loss: 4.7756e-04 - KL loss: 32.2519 - beta: 0.0023 - val_loss: 131.1913 - val_recon_loss: 5.0644e-04 - val_KL loss: 32.9034 - val_beta: 0.0023\n",
      "Epoch 144/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 122.9985 - recon_loss: 4.6787e-04 - KL loss: 32.1952 - beta: 0.0023 - val_loss: 132.3981 - val_recon_loss: 5.1188e-04 - val_KL loss: 33.0547 - val_beta: 0.0023\n",
      "Epoch 145/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 122.2073 - recon_loss: 4.6329e-04 - KL loss: 32.2929 - beta: 0.0023 - val_loss: 135.1542 - val_recon_loss: 5.2585e-04 - val_KL loss: 33.0989 - val_beta: 0.0023\n",
      "Epoch 146/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 123.6968 - recon_loss: 4.7048e-04 - KL loss: 32.3883 - beta: 0.0023\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 123.6957 - recon_loss: 4.7047e-04 - KL loss: 32.3880 - beta: 0.0023 - val_loss: 132.8634 - val_recon_loss: 5.1498e-04 - val_KL loss: 32.9169 - val_beta: 0.0023\n",
      "Epoch 146/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 74.4983 - recon_loss: 5.5512e-04 - KL loss: 27.0362 - beta: 0.0034 - val_loss: 80.9846 - val_recon_loss: 6.4205e-04 - val_KL loss: 26.0901 - val_beta: 0.0034\n",
      "Epoch 147/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 75.9501 - recon_loss: 5.9912e-04 - KL loss: 24.7259 - beta: 0.0034 - val_loss: 76.5646 - val_recon_loss: 6.0660e-04 - val_KL loss: 24.7013 - val_beta: 0.0034\n",
      "Epoch 148/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 75.0765 - recon_loss: 5.9681e-04 - KL loss: 24.0495 - beta: 0.0034 - val_loss: 86.0545 - val_recon_loss: 7.2991e-04 - val_KL loss: 23.6477 - val_beta: 0.0034\n",
      "Epoch 149/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 74.2473 - recon_loss: 5.9393e-04 - KL loss: 23.4674 - beta: 0.0034 - val_loss: 73.1008 - val_recon_loss: 5.8500e-04 - val_KL loss: 23.0843 - val_beta: 0.0034\n",
      "Epoch 150/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 76.1528 - recon_loss: 6.2117e-04 - KL loss: 23.0433 - beta: 0.0034 - val_loss: 82.6077 - val_recon_loss: 6.9596e-04 - val_KL loss: 23.1043 - val_beta: 0.0034\n",
      "Epoch 151/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 74.9010 - recon_loss: 6.1080e-04 - KL loss: 22.6781 - beta: 0.0034 - val_loss: 73.5478 - val_recon_loss: 5.8493e-04 - val_KL loss: 23.5373 - val_beta: 0.0034\n",
      "Epoch 152/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 73.8398 - recon_loss: 6.0195e-04 - KL loss: 22.3737 - beta: 0.0034 - val_loss: 83.8605 - val_recon_loss: 7.1258e-04 - val_KL loss: 22.9358 - val_beta: 0.0034\n",
      "Epoch 153/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 76.1176 - recon_loss: 6.2750e-04 - KL loss: 22.4671 - beta: 0.0034 - val_loss: 70.2404 - val_recon_loss: 5.6037e-04 - val_KL loss: 22.3292 - val_beta: 0.0034\n",
      "Epoch 154/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 77.0805 - recon_loss: 6.3827e-04 - KL loss: 22.5090 - beta: 0.0034 - val_loss: 76.5970 - val_recon_loss: 6.4207e-04 - val_KL loss: 21.7006 - val_beta: 0.0034\n",
      "Epoch 155/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 74.3642 - recon_loss: 6.1494e-04 - KL loss: 21.7879 - beta: 0.0034 - val_loss: 82.2974 - val_recon_loss: 7.0171e-04 - val_KL loss: 22.3020 - val_beta: 0.0034\n",
      "Epoch 156/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 75.7971 - recon_loss: 6.2864e-04 - KL loss: 22.0491 - beta: 0.0034 - val_loss: 78.8594 - val_recon_loss: 6.6166e-04 - val_KL loss: 22.2881 - val_beta: 0.0034\n",
      "Epoch 157/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 74.6060 - recon_loss: 6.1754e-04 - KL loss: 21.8074 - beta: 0.0034 - val_loss: 72.6007 - val_recon_loss: 5.9625e-04 - val_KL loss: 21.6225 - val_beta: 0.0034\n",
      "Epoch 158/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 72.2838 - recon_loss: 5.9318e-04 - KL loss: 21.5677 - beta: 0.0034\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 72.2863 - recon_loss: 5.9321e-04 - KL loss: 21.5677 - beta: 0.0034 - val_loss: 79.7851 - val_recon_loss: 6.7709e-04 - val_KL loss: 21.8948 - val_beta: 0.0034\n",
      "Epoch 159/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 70.8291 - recon_loss: 5.7373e-04 - KL loss: 21.7755 - beta: 0.0034 - val_loss: 68.5673 - val_recon_loss: 5.5153e-04 - val_KL loss: 21.4123 - val_beta: 0.0034\n",
      "Epoch 160/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 67.8402 - recon_loss: 5.3932e-04 - KL loss: 21.7294 - beta: 0.0034 - val_loss: 67.2260 - val_recon_loss: 5.3426e-04 - val_KL loss: 21.5470 - val_beta: 0.0034\n",
      "Epoch 161/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 67.8397 - recon_loss: 5.4083e-04 - KL loss: 21.5992 - beta: 0.0034 - val_loss: 67.9928 - val_recon_loss: 5.4805e-04 - val_KL loss: 21.1350 - val_beta: 0.0034\n",
      "Epoch 162/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 67.1895 - recon_loss: 5.3555e-04 - KL loss: 21.4005 - beta: 0.0034 - val_loss: 65.7230 - val_recon_loss: 5.1962e-04 - val_KL loss: 21.2960 - val_beta: 0.0034\n",
      "Epoch 163/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 67.9202 - recon_loss: 5.4233e-04 - KL loss: 21.5517 - beta: 0.0034 - val_loss: 82.3785 - val_recon_loss: 7.1456e-04 - val_KL loss: 21.2843 - val_beta: 0.0034\n",
      "Epoch 164/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 67.6622 - recon_loss: 5.4015e-04 - KL loss: 21.4797 - beta: 0.0034 - val_loss: 67.1529 - val_recon_loss: 5.3606e-04 - val_KL loss: 21.3202 - val_beta: 0.0034\n",
      "Epoch 165/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 65.6336 - recon_loss: 5.1751e-04 - KL loss: 21.3873 - beta: 0.0034 - val_loss: 67.0939 - val_recon_loss: 5.3611e-04 - val_KL loss: 21.2570 - val_beta: 0.0034\n",
      "Epoch 166/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 66.2398 - recon_loss: 5.2560e-04 - KL loss: 21.3017 - beta: 0.0034 - val_loss: 68.4110 - val_recon_loss: 5.5273e-04 - val_KL loss: 21.1531 - val_beta: 0.0034\n",
      "Epoch 167/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 65.5681 - recon_loss: 5.1869e-04 - KL loss: 21.2203 - beta: 0.0034\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 65.5681 - recon_loss: 5.1869e-04 - KL loss: 21.2204 - beta: 0.0034 - val_loss: 69.1391 - val_recon_loss: 5.5858e-04 - val_KL loss: 21.3808 - val_beta: 0.0034\n",
      "Epoch 168/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 65.5447 - recon_loss: 5.1937e-04 - KL loss: 21.1392 - beta: 0.0034 - val_loss: 67.4587 - val_recon_loss: 5.3836e-04 - val_KL loss: 21.4298 - val_beta: 0.0034\n",
      "Epoch 169/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 63.8900 - recon_loss: 4.9908e-04 - KL loss: 21.2191 - beta: 0.0034 - val_loss: 63.3240 - val_recon_loss: 4.9262e-04 - val_KL loss: 21.2054 - val_beta: 0.0034\n",
      "Epoch 170/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 64.1517 - recon_loss: 5.0146e-04 - KL loss: 21.2779 - beta: 0.0034 - val_loss: 66.2342 - val_recon_loss: 5.2737e-04 - val_KL loss: 21.1447 - val_beta: 0.0034\n",
      "Epoch 171/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 64.5978 - recon_loss: 5.0755e-04 - KL loss: 21.2031 - beta: 0.0034 - val_loss: 66.8292 - val_recon_loss: 5.3591e-04 - val_KL loss: 21.0099 - val_beta: 0.0034\n",
      "Epoch 172/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 63.3528 - recon_loss: 4.9349e-04 - KL loss: 21.1601 - beta: 0.0034 - val_loss: 64.8512 - val_recon_loss: 5.1197e-04 - val_KL loss: 21.0786 - val_beta: 0.0034\n",
      "Epoch 173/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 63.2485 - recon_loss: 4.9190e-04 - KL loss: 21.1920 - beta: 0.0034 - val_loss: 64.2412 - val_recon_loss: 5.0426e-04 - val_KL loss: 21.1277 - val_beta: 0.0034\n",
      "Epoch 174/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 63.4064 - recon_loss: 4.9286e-04 - KL loss: 21.2674 - beta: 0.0034 - val_loss: 63.1580 - val_recon_loss: 4.9290e-04 - val_KL loss: 21.0154 - val_beta: 0.0034\n",
      "Epoch 175/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 63.1989 - recon_loss: 4.9252e-04 - KL loss: 21.0892 - beta: 0.0034 - val_loss: 63.1373 - val_recon_loss: 4.9281e-04 - val_KL loss: 21.0027 - val_beta: 0.0034\n",
      "Epoch 176/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 63.3677 - recon_loss: 4.9325e-04 - KL loss: 21.1959 - beta: 0.0034 - val_loss: 61.9463 - val_recon_loss: 4.7874e-04 - val_KL loss: 21.0148 - val_beta: 0.0034\n",
      "Epoch 177/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 63.0080 - recon_loss: 4.9065e-04 - KL loss: 21.0584 - beta: 0.0034 - val_loss: 66.9479 - val_recon_loss: 5.3533e-04 - val_KL loss: 21.1776 - val_beta: 0.0034\n",
      "Epoch 178/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 63.2845 - recon_loss: 4.9249e-04 - KL loss: 21.1773 - beta: 0.0034 - val_loss: 63.9121 - val_recon_loss: 4.9975e-04 - val_KL loss: 21.1842 - val_beta: 0.0034\n",
      "Epoch 179/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 62.2038 - recon_loss: 4.8103e-04 - KL loss: 21.0760 - beta: 0.0034 - val_loss: 63.6179 - val_recon_loss: 4.9726e-04 - val_KL loss: 21.1027 - val_beta: 0.0034\n",
      "Epoch 180/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 62.9902 - recon_loss: 4.8983e-04 - KL loss: 21.1106 - beta: 0.0034 - val_loss: 63.8838 - val_recon_loss: 4.9899e-04 - val_KL loss: 21.2208 - val_beta: 0.0034\n",
      "Epoch 181/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 62.7482 - recon_loss: 4.8678e-04 - KL loss: 21.1289 - beta: 0.0034\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 62.7483 - recon_loss: 4.8678e-04 - KL loss: 21.1289 - beta: 0.0034 - val_loss: 66.4337 - val_recon_loss: 5.3097e-04 - val_KL loss: 21.0365 - val_beta: 0.0034\n",
      "Epoch 182/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 62.2050 - recon_loss: 4.8053e-04 - KL loss: 21.1204 - beta: 0.0034 - val_loss: 65.9826 - val_recon_loss: 5.2520e-04 - val_KL loss: 21.0789 - val_beta: 0.0034\n",
      "Epoch 183/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 62.2619 - recon_loss: 4.8103e-04 - KL loss: 21.1348 - beta: 0.0034 - val_loss: 62.2959 - val_recon_loss: 4.8229e-04 - val_KL loss: 21.0611 - val_beta: 0.0034\n",
      "Epoch 184/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 62.0336 - recon_loss: 4.7862e-04 - KL loss: 21.1124 - beta: 0.0034 - val_loss: 66.1890 - val_recon_loss: 5.2700e-04 - val_KL loss: 21.1311 - val_beta: 0.0034\n",
      "Epoch 185/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 61.6276 - recon_loss: 4.7457e-04 - KL loss: 21.0522 - beta: 0.0034 - val_loss: 63.8875 - val_recon_loss: 5.0109e-04 - val_KL loss: 21.0446 - val_beta: 0.0034\n",
      "Epoch 186/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 62.1062 - recon_loss: 4.7995e-04 - KL loss: 21.0708 - beta: 0.0034\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 62.1059 - recon_loss: 4.7995e-04 - KL loss: 21.0708 - beta: 0.0034 - val_loss: 62.6459 - val_recon_loss: 4.8667e-04 - val_KL loss: 21.0362 - val_beta: 0.0034\n",
      "Epoch 186/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 39.3439 - recon_loss: 5.7758e-04 - KL loss: 17.5890 - beta: 0.0052 - val_loss: 41.5595 - val_recon_loss: 6.6456e-04 - val_KL loss: 16.5283 - val_beta: 0.0052\n",
      "Epoch 187/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 39.7858 - recon_loss: 6.1913e-04 - KL loss: 16.4660 - beta: 0.0052 - val_loss: 42.5424 - val_recon_loss: 6.9701e-04 - val_KL loss: 16.2890 - val_beta: 0.0052\n",
      "Epoch 188/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 39.8699 - recon_loss: 6.2645e-04 - KL loss: 16.2741 - beta: 0.0052 - val_loss: 42.5086 - val_recon_loss: 6.8518e-04 - val_KL loss: 16.7009 - val_beta: 0.0052\n",
      "Epoch 189/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 42.2697 - recon_loss: 6.8740e-04 - KL loss: 16.3783 - beta: 0.0052 - val_loss: 45.5201 - val_recon_loss: 7.7599e-04 - val_KL loss: 16.2917 - val_beta: 0.0052\n",
      "Epoch 190/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 41.1202 - recon_loss: 6.6858e-04 - KL loss: 15.9378 - beta: 0.0052 - val_loss: 40.6255 - val_recon_loss: 6.6378e-04 - val_KL loss: 15.6238 - val_beta: 0.0052\n",
      "Epoch 191/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 40.1083 - recon_loss: 6.4683e-04 - KL loss: 15.7448 - beta: 0.0052 - val_loss: 49.8748 - val_recon_loss: 8.8542e-04 - val_KL loss: 16.5248 - val_beta: 0.0052\n",
      "Epoch 192/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 40.8372 - recon_loss: 6.6835e-04 - KL loss: 15.6634 - beta: 0.0052 - val_loss: 39.4603 - val_recon_loss: 6.3392e-04 - val_KL loss: 15.5834 - val_beta: 0.0052\n",
      "Epoch 193/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 39.4553 - recon_loss: 6.3475e-04 - KL loss: 15.5471 - beta: 0.0052 - val_loss: 41.8471 - val_recon_loss: 7.0146e-04 - val_KL loss: 15.4260 - val_beta: 0.0052\n",
      "Epoch 194/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 39.6533 - recon_loss: 6.4235e-04 - KL loss: 15.4589 - beta: 0.0052 - val_loss: 39.3693 - val_recon_loss: 6.4599e-04 - val_KL loss: 15.0375 - val_beta: 0.0052\n",
      "Epoch 195/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 38.6446 - recon_loss: 6.1990e-04 - KL loss: 15.2955 - beta: 0.0052 - val_loss: 40.1166 - val_recon_loss: 6.6889e-04 - val_KL loss: 14.9223 - val_beta: 0.0052\n",
      "Epoch 196/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 39.5779 - recon_loss: 6.4674e-04 - KL loss: 15.2178 - beta: 0.0052 - val_loss: 41.4062 - val_recon_loss: 6.9110e-04 - val_KL loss: 15.3754 - val_beta: 0.0052\n",
      "Epoch 197/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 39.2647 - recon_loss: 6.4041e-04 - KL loss: 15.1430 - beta: 0.0052 - val_loss: 37.7666 - val_recon_loss: 6.1266e-04 - val_KL loss: 14.6903 - val_beta: 0.0052\n",
      "Epoch 198/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 37.7714 - recon_loss: 6.0466e-04 - KL loss: 14.9963 - beta: 0.0052 - val_loss: 39.9724 - val_recon_loss: 6.6018e-04 - val_KL loss: 15.1061 - val_beta: 0.0052\n",
      "Epoch 199/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 38.7567 - recon_loss: 6.3552e-04 - KL loss: 14.8195 - beta: 0.0052 - val_loss: 37.3559 - val_recon_loss: 5.9810e-04 - val_KL loss: 14.8281 - val_beta: 0.0052\n",
      "Epoch 200/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 38.0032 - recon_loss: 6.1698e-04 - KL loss: 14.7642 - beta: 0.0052 - val_loss: 38.6983 - val_recon_loss: 6.4042e-04 - val_KL loss: 14.5765 - val_beta: 0.0052\n",
      "Epoch 201/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 38.2765 - recon_loss: 6.2328e-04 - KL loss: 14.8001 - beta: 0.0052 - val_loss: 38.7586 - val_recon_loss: 6.3438e-04 - val_KL loss: 14.8643 - val_beta: 0.0052\n",
      "Epoch 202/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 37.2485 - recon_loss: 5.9819e-04 - KL loss: 14.7171 - beta: 0.0052 - val_loss: 39.5186 - val_recon_loss: 6.6612e-04 - val_KL loss: 14.4285 - val_beta: 0.0052\n",
      "Epoch 203/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.4587 - recon_loss: 5.8196e-04 - KL loss: 14.5387 - beta: 0.0052 - val_loss: 36.5334 - val_recon_loss: 5.8811e-04 - val_KL loss: 14.3819 - val_beta: 0.0052\n",
      "Epoch 204/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 37.0085 - recon_loss: 5.9629e-04 - KL loss: 14.5488 - beta: 0.0052 - val_loss: 36.9856 - val_recon_loss: 6.0240e-04 - val_KL loss: 14.2959 - val_beta: 0.0052\n",
      "Epoch 205/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 37.2295 - recon_loss: 6.0343e-04 - KL loss: 14.5008 - beta: 0.0052 - val_loss: 38.4649 - val_recon_loss: 6.4417e-04 - val_KL loss: 14.2016 - val_beta: 0.0052\n",
      "Epoch 206/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.9640 - recon_loss: 5.9847e-04 - KL loss: 14.4222 - beta: 0.0052 - val_loss: 40.2887 - val_recon_loss: 6.8773e-04 - val_KL loss: 14.3848 - val_beta: 0.0052\n",
      "Epoch 207/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.4556 - recon_loss: 5.8643e-04 - KL loss: 14.3671 - beta: 0.0052 - val_loss: 39.9323 - val_recon_loss: 6.8788e-04 - val_KL loss: 14.0227 - val_beta: 0.0052\n",
      "Epoch 208/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 35.9530 - recon_loss: 5.7275e-04 - KL loss: 14.3801 - beta: 0.0052\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.9538 - recon_loss: 5.7277e-04 - KL loss: 14.3800 - beta: 0.0052 - val_loss: 37.3812 - val_recon_loss: 6.1214e-04 - val_KL loss: 14.3245 - val_beta: 0.0052\n",
      "Epoch 209/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 35.7835 - recon_loss: 5.6902e-04 - KL loss: 14.3510 - beta: 0.0052 - val_loss: 34.5332 - val_recon_loss: 5.3354e-04 - val_KL loss: 14.4371 - val_beta: 0.0052\n",
      "Epoch 210/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 34.9121 - recon_loss: 5.4741e-04 - KL loss: 14.2936 - beta: 0.0052 - val_loss: 34.8883 - val_recon_loss: 5.4314e-04 - val_KL loss: 14.4305 - val_beta: 0.0052\n",
      "Epoch 211/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 34.5854 - recon_loss: 5.3632e-04 - KL loss: 14.3845 - beta: 0.0052 - val_loss: 38.4312 - val_recon_loss: 6.3932e-04 - val_KL loss: 14.3508 - val_beta: 0.0052\n",
      "Epoch 212/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 34.3305 - recon_loss: 5.3153e-04 - KL loss: 14.3102 - beta: 0.0052 - val_loss: 34.8159 - val_recon_loss: 5.4859e-04 - val_KL loss: 14.1528 - val_beta: 0.0052\n",
      "Epoch 213/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 34.8035 - recon_loss: 5.4364e-04 - KL loss: 14.3270 - beta: 0.0052 - val_loss: 37.7161 - val_recon_loss: 6.2192e-04 - val_KL loss: 14.2912 - val_beta: 0.0052\n",
      "Epoch 214/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 35.7225 - recon_loss: 5.6877e-04 - KL loss: 14.2995 - beta: 0.0052 - val_loss: 34.4067 - val_recon_loss: 5.3385e-04 - val_KL loss: 14.2988 - val_beta: 0.0052\n",
      "Epoch 215/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 34.5305 - recon_loss: 5.3722e-04 - KL loss: 14.2956 - beta: 0.0052 - val_loss: 34.9353 - val_recon_loss: 5.4949e-04 - val_KL loss: 14.2385 - val_beta: 0.0052\n",
      "Epoch 216/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 34.6827 - recon_loss: 5.4052e-04 - KL loss: 14.3234 - beta: 0.0052 - val_loss: 34.8290 - val_recon_loss: 5.4707e-04 - val_KL loss: 14.2233 - val_beta: 0.0052\n",
      "Epoch 217/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 34.0940 - recon_loss: 5.2684e-04 - KL loss: 14.2502 - beta: 0.0052 - val_loss: 35.1538 - val_recon_loss: 5.5660e-04 - val_KL loss: 14.1891 - val_beta: 0.0052\n",
      "Epoch 218/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 34.1733 - recon_loss: 5.2945e-04 - KL loss: 14.2310 - beta: 0.0052 - val_loss: 34.3239 - val_recon_loss: 5.3180e-04 - val_KL loss: 14.2932 - val_beta: 0.0052\n",
      "Epoch 219/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 33.9865 - recon_loss: 5.2595e-04 - KL loss: 14.1761 - beta: 0.0052 - val_loss: 33.3492 - val_recon_loss: 5.0865e-04 - val_KL loss: 14.1904 - val_beta: 0.0052\n",
      "Epoch 220/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33.8695 - recon_loss: 5.2173e-04 - KL loss: 14.2181 - beta: 0.0052 - val_loss: 36.0276 - val_recon_loss: 5.6682e-04 - val_KL loss: 14.6778 - val_beta: 0.0052\n",
      "Epoch 221/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 34.1351 - recon_loss: 5.2943e-04 - KL loss: 14.1936 - beta: 0.0052 - val_loss: 34.8896 - val_recon_loss: 5.4707e-04 - val_KL loss: 14.2837 - val_beta: 0.0052\n",
      "Epoch 222/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 34.2001 - recon_loss: 5.3128e-04 - KL loss: 14.1890 - beta: 0.0052 - val_loss: 33.9489 - val_recon_loss: 5.2831e-04 - val_KL loss: 14.0499 - val_beta: 0.0052\n",
      "Epoch 223/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 34.1026 - recon_loss: 5.2760e-04 - KL loss: 14.2301 - beta: 0.0052 - val_loss: 34.1352 - val_recon_loss: 5.3038e-04 - val_KL loss: 14.1582 - val_beta: 0.0052\n",
      "Epoch 224/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33.7663 - recon_loss: 5.2167e-04 - KL loss: 14.1174 - beta: 0.0052 - val_loss: 33.1845 - val_recon_loss: 5.0592e-04 - val_KL loss: 14.1286 - val_beta: 0.0052\n",
      "Epoch 225/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33.9705 - recon_loss: 5.2464e-04 - KL loss: 14.2095 - beta: 0.0052 - val_loss: 35.2048 - val_recon_loss: 5.6508e-04 - val_KL loss: 13.9207 - val_beta: 0.0052\n",
      "Epoch 226/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 34.1923 - recon_loss: 5.3249e-04 - KL loss: 14.1356 - beta: 0.0052 - val_loss: 33.2748 - val_recon_loss: 5.0747e-04 - val_KL loss: 14.1605 - val_beta: 0.0052\n",
      "Epoch 227/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33.6440 - recon_loss: 5.1796e-04 - KL loss: 14.1344 - beta: 0.0052 - val_loss: 34.1217 - val_recon_loss: 5.2998e-04 - val_KL loss: 14.1595 - val_beta: 0.0052\n",
      "Epoch 228/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33.9548 - recon_loss: 5.2725e-04 - KL loss: 14.0955 - beta: 0.0052 - val_loss: 34.6008 - val_recon_loss: 5.4436e-04 - val_KL loss: 14.0969 - val_beta: 0.0052\n",
      "Epoch 229/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33.7017 - recon_loss: 5.2093e-04 - KL loss: 14.0806 - beta: 0.0052 - val_loss: 32.9999 - val_recon_loss: 5.0854e-04 - val_KL loss: 13.8455 - val_beta: 0.0052\n",
      "Epoch 230/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33.4086 - recon_loss: 5.1327e-04 - KL loss: 14.0759 - beta: 0.0052 - val_loss: 33.5491 - val_recon_loss: 5.1952e-04 - val_KL loss: 13.9812 - val_beta: 0.0052\n",
      "Epoch 231/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33.7343 - recon_loss: 5.2127e-04 - KL loss: 14.1001 - beta: 0.0052 - val_loss: 33.2704 - val_recon_loss: 5.1079e-04 - val_KL loss: 14.0311 - val_beta: 0.0052\n",
      "Epoch 232/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 33.8883 - recon_loss: 5.2632e-04 - KL loss: 14.0643 - beta: 0.0052 - val_loss: 34.6250 - val_recon_loss: 5.3634e-04 - val_KL loss: 14.4234 - val_beta: 0.0052\n",
      "Epoch 233/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33.9840 - recon_loss: 5.2718e-04 - KL loss: 14.1273 - beta: 0.0052 - val_loss: 34.0852 - val_recon_loss: 5.3330e-04 - val_KL loss: 13.9981 - val_beta: 0.0052\n",
      "Epoch 234/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 33.5299 - recon_loss: 5.1667e-04 - KL loss: 14.0690 - beta: 0.0052\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 33.5300 - recon_loss: 5.1668e-04 - KL loss: 14.0690 - beta: 0.0052 - val_loss: 33.8375 - val_recon_loss: 5.2822e-04 - val_KL loss: 13.9417 - val_beta: 0.0052\n",
      "Epoch 235/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33.2669 - recon_loss: 5.0814e-04 - KL loss: 14.1276 - beta: 0.0052 - val_loss: 34.6298 - val_recon_loss: 5.4595e-04 - val_KL loss: 14.0662 - val_beta: 0.0052\n",
      "Epoch 236/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.9918 - recon_loss: 5.0027e-04 - KL loss: 14.1488 - beta: 0.0052 - val_loss: 33.4952 - val_recon_loss: 5.1328e-04 - val_KL loss: 14.1620 - val_beta: 0.0052\n",
      "Epoch 237/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 32.9073 - recon_loss: 4.9977e-04 - KL loss: 14.0829 - beta: 0.0052 - val_loss: 33.0461 - val_recon_loss: 5.0247e-04 - val_KL loss: 14.1200 - val_beta: 0.0052\n",
      "Epoch 238/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.8627 - recon_loss: 4.9809e-04 - KL loss: 14.1016 - beta: 0.0052 - val_loss: 33.8592 - val_recon_loss: 5.2673e-04 - val_KL loss: 14.0194 - val_beta: 0.0052\n",
      "Epoch 239/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 32.9827 - recon_loss: 5.0149e-04 - KL loss: 14.0938 - beta: 0.0052\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.9827 - recon_loss: 5.0149e-04 - KL loss: 14.0938 - beta: 0.0052 - val_loss: 33.6419 - val_recon_loss: 5.2056e-04 - val_KL loss: 14.0347 - val_beta: 0.0052\n",
      "Epoch 239/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.7988 - recon_loss: 6.2161e-04 - KL loss: 11.4842 - beta: 0.0078 - val_loss: 21.8444 - val_recon_loss: 6.6629e-04 - val_KL loss: 10.7884 - val_beta: 0.0078\n",
      "Epoch 240/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.9034 - recon_loss: 6.5975e-04 - KL loss: 10.9560 - beta: 0.0078 - val_loss: 21.6498 - val_recon_loss: 6.5683e-04 - val_KL loss: 10.7507 - val_beta: 0.0078\n",
      "Epoch 241/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 21.9369 - recon_loss: 6.7039e-04 - KL loss: 10.8129 - beta: 0.0078 - val_loss: 22.0736 - val_recon_loss: 6.9268e-04 - val_KL loss: 10.5797 - val_beta: 0.0078\n",
      "Epoch 242/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 22.1571 - recon_loss: 6.8954e-04 - KL loss: 10.7153 - beta: 0.0078 - val_loss: 23.2959 - val_recon_loss: 7.7177e-04 - val_KL loss: 10.4896 - val_beta: 0.0078\n",
      "Epoch 243/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 22.1763 - recon_loss: 6.9314e-04 - KL loss: 10.6749 - beta: 0.0078 - val_loss: 22.0837 - val_recon_loss: 7.0847e-04 - val_KL loss: 10.3278 - val_beta: 0.0078\n",
      "Epoch 244/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.9628 - recon_loss: 6.8323e-04 - KL loss: 10.6258 - beta: 0.0078 - val_loss: 22.1259 - val_recon_loss: 7.0472e-04 - val_KL loss: 10.4323 - val_beta: 0.0078\n",
      "Epoch 245/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.3995 - recon_loss: 7.1299e-04 - KL loss: 10.5686 - beta: 0.0078 - val_loss: 21.5916 - val_recon_loss: 6.7443e-04 - val_KL loss: 10.4005 - val_beta: 0.0078\n",
      "Epoch 246/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.9246 - recon_loss: 6.8574e-04 - KL loss: 10.5459 - beta: 0.0078 - val_loss: 22.4580 - val_recon_loss: 7.1923e-04 - val_KL loss: 10.5236 - val_beta: 0.0078\n",
      "Epoch 247/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.8555 - recon_loss: 6.8363e-04 - KL loss: 10.5118 - beta: 0.0078 - val_loss: 21.9756 - val_recon_loss: 6.8878e-04 - val_KL loss: 10.5465 - val_beta: 0.0078\n",
      "Epoch 248/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.8969 - recon_loss: 6.9019e-04 - KL loss: 10.4444 - beta: 0.0078 - val_loss: 22.3920 - val_recon_loss: 7.3335e-04 - val_KL loss: 10.2233 - val_beta: 0.0078\n",
      "Epoch 249/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.6668 - recon_loss: 6.7918e-04 - KL loss: 10.3969 - beta: 0.0078 - val_loss: 23.0203 - val_recon_loss: 7.5857e-04 - val_KL loss: 10.4332 - val_beta: 0.0078\n",
      "Epoch 250/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.0009 - recon_loss: 6.9692e-04 - KL loss: 10.4367 - beta: 0.0078 - val_loss: 21.3541 - val_recon_loss: 6.6433e-04 - val_KL loss: 10.3306 - val_beta: 0.0078\n",
      "Epoch 251/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 22.2199 - recon_loss: 7.1000e-04 - KL loss: 10.4386 - beta: 0.0078 - val_loss: 21.7373 - val_recon_loss: 6.8497e-04 - val_KL loss: 10.3714 - val_beta: 0.0078\n",
      "Epoch 252/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.6481 - recon_loss: 6.7778e-04 - KL loss: 10.4015 - beta: 0.0078 - val_loss: 23.3101 - val_recon_loss: 7.7134e-04 - val_KL loss: 10.5111 - val_beta: 0.0078\n",
      "Epoch 253/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.9687 - recon_loss: 6.9611e-04 - KL loss: 10.4179 - beta: 0.0078 - val_loss: 23.8209 - val_recon_loss: 8.1316e-04 - val_KL loss: 10.3279 - val_beta: 0.0078\n",
      "Epoch 254/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.0709 - recon_loss: 7.0685e-04 - KL loss: 10.3420 - beta: 0.0078 - val_loss: 21.8335 - val_recon_loss: 6.8454e-04 - val_KL loss: 10.4746 - val_beta: 0.0078\n",
      "Epoch 255/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 22.2567 - recon_loss: 7.1713e-04 - KL loss: 10.3572 - beta: 0.0078\n",
      "Epoch 00255: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.2568 - recon_loss: 7.1713e-04 - KL loss: 10.3572 - beta: 0.0078 - val_loss: 21.6608 - val_recon_loss: 6.9510e-04 - val_KL loss: 10.1269 - val_beta: 0.0078\n",
      "Epoch 256/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.5102 - recon_loss: 6.7247e-04 - KL loss: 10.3516 - beta: 0.0078 - val_loss: 21.5108 - val_recon_loss: 6.7679e-04 - val_KL loss: 10.2806 - val_beta: 0.0078\n",
      "Epoch 257/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.2039 - recon_loss: 6.5111e-04 - KL loss: 10.3999 - beta: 0.0078 - val_loss: 21.3154 - val_recon_loss: 6.7537e-04 - val_KL loss: 10.1088 - val_beta: 0.0078\n",
      "Epoch 258/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.6177 - recon_loss: 6.7366e-04 - KL loss: 10.4395 - beta: 0.0078 - val_loss: 22.5467 - val_recon_loss: 7.3455e-04 - val_KL loss: 10.3581 - val_beta: 0.0078\n",
      "Epoch 259/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.5423 - recon_loss: 6.6652e-04 - KL loss: 10.4825 - beta: 0.0078 - val_loss: 21.7989 - val_recon_loss: 6.9625e-04 - val_KL loss: 10.2458 - val_beta: 0.0078\n",
      "Epoch 260/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.4534 - recon_loss: 6.6512e-04 - KL loss: 10.4169 - beta: 0.0078 - val_loss: 21.9823 - val_recon_loss: 7.1586e-04 - val_KL loss: 10.1038 - val_beta: 0.0078\n",
      "Epoch 261/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.0982 - recon_loss: 6.4666e-04 - KL loss: 10.3680 - beta: 0.0078 - val_loss: 21.3473 - val_recon_loss: 6.7557e-04 - val_KL loss: 10.1374 - val_beta: 0.0078\n",
      "Epoch 262/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 21.1042 - recon_loss: 6.4595e-04 - KL loss: 10.3857 - beta: 0.0078\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.1042 - recon_loss: 6.4596e-04 - KL loss: 10.3856 - beta: 0.0078 - val_loss: 21.4354 - val_recon_loss: 6.7330e-04 - val_KL loss: 10.2632 - val_beta: 0.0078\n",
      "Epoch 263/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.2977 - recon_loss: 6.5232e-04 - KL loss: 10.4737 - beta: 0.0078 - val_loss: 22.3831 - val_recon_loss: 7.2959e-04 - val_KL loss: 10.2768 - val_beta: 0.0078\n",
      "Epoch 264/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.0547 - recon_loss: 6.4061e-04 - KL loss: 10.4248 - beta: 0.0078 - val_loss: 21.3653 - val_recon_loss: 6.7405e-04 - val_KL loss: 10.1806 - val_beta: 0.0078\n",
      "Epoch 265/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.1073 - recon_loss: 6.4190e-04 - KL loss: 10.4560 - beta: 0.0078 - val_loss: 21.3545 - val_recon_loss: 6.7034e-04 - val_KL loss: 10.2314 - val_beta: 0.0078\n",
      "Epoch 266/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.9563 - recon_loss: 6.3238e-04 - KL loss: 10.4631 - beta: 0.0078 - val_loss: 20.8181 - val_recon_loss: 6.4218e-04 - val_KL loss: 10.1622 - val_beta: 0.0078\n",
      "Epoch 267/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.9105 - recon_loss: 6.3265e-04 - KL loss: 10.4127 - beta: 0.0078 - val_loss: 21.4278 - val_recon_loss: 6.7718e-04 - val_KL loss: 10.1912 - val_beta: 0.0078\n",
      "Epoch 268/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.9786 - recon_loss: 6.3652e-04 - KL loss: 10.4166 - beta: 0.0078 - val_loss: 20.8621 - val_recon_loss: 6.4191e-04 - val_KL loss: 10.2107 - val_beta: 0.0078\n",
      "Epoch 269/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.0077 - recon_loss: 6.3616e-04 - KL loss: 10.4517 - beta: 0.0078 - val_loss: 21.5289 - val_recon_loss: 6.7942e-04 - val_KL loss: 10.2551 - val_beta: 0.0078\n",
      "Epoch 270/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.9539 - recon_loss: 6.3510e-04 - KL loss: 10.4156 - beta: 0.0078 - val_loss: 21.8811 - val_recon_loss: 7.0334e-04 - val_KL loss: 10.2104 - val_beta: 0.0078\n",
      "Epoch 271/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 21.0057 - recon_loss: 6.3691e-04 - KL loss: 10.4373 - beta: 0.0078\n",
      "Epoch 00271: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.0057 - recon_loss: 6.3691e-04 - KL loss: 10.4373 - beta: 0.0078 - val_loss: 21.6611 - val_recon_loss: 6.8688e-04 - val_KL loss: 10.2634 - val_beta: 0.0078\n",
      "Epoch 272/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.8614 - recon_loss: 6.2913e-04 - KL loss: 10.4222 - beta: 0.0078 - val_loss: 21.4167 - val_recon_loss: 6.7292e-04 - val_KL loss: 10.2508 - val_beta: 0.0078\n",
      "Epoch 273/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.8126 - recon_loss: 6.2512e-04 - KL loss: 10.4398 - beta: 0.0078 - val_loss: 21.0602 - val_recon_loss: 6.5380e-04 - val_KL loss: 10.2114 - val_beta: 0.0078\n",
      "Epoch 274/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.7426 - recon_loss: 6.2287e-04 - KL loss: 10.4072 - beta: 0.0078 - val_loss: 20.7278 - val_recon_loss: 6.3136e-04 - val_KL loss: 10.2514 - val_beta: 0.0078\n",
      "Epoch 275/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.8735 - recon_loss: 6.2863e-04 - KL loss: 10.4425 - beta: 0.0078 - val_loss: 20.8920 - val_recon_loss: 6.4425e-04 - val_KL loss: 10.2018 - val_beta: 0.0078\n",
      "Epoch 276/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.8229 - recon_loss: 6.2645e-04 - KL loss: 10.4281 - beta: 0.0078 - val_loss: 21.1479 - val_recon_loss: 6.5835e-04 - val_KL loss: 10.2237 - val_beta: 0.0078\n",
      "Epoch 277/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.7516 - recon_loss: 6.2282e-04 - KL loss: 10.4169 - beta: 0.0078 - val_loss: 21.5200 - val_recon_loss: 6.8112e-04 - val_KL loss: 10.2179 - val_beta: 0.0078\n",
      "Epoch 278/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 20.7506 - recon_loss: 6.2331e-04 - KL loss: 10.4078 - beta: 0.0078 - val_loss: 21.0282 - val_recon_loss: 6.5460e-04 - val_KL loss: 10.1663 - val_beta: 0.0078\n",
      "Epoch 279/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 20.7139 - recon_loss: 6.2100e-04 - KL loss: 10.4094 - beta: 0.0078- ETA: 4s - loss\n",
      "Epoch 00279: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 20.7138 - recon_loss: 6.2100e-04 - KL loss: 10.4094 - beta: 0.0078 - val_loss: 21.0219 - val_recon_loss: 6.5215e-04 - val_KL loss: 10.2005 - val_beta: 0.0078\n",
      "Epoch 280/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.6449 - recon_loss: 6.1732e-04 - KL loss: 10.4014 - beta: 0.0078 - val_loss: 20.7144 - val_recon_loss: 6.3244e-04 - val_KL loss: 10.2201 - val_beta: 0.0078\n",
      "Epoch 281/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.6971 - recon_loss: 6.1912e-04 - KL loss: 10.4238 - beta: 0.0078 - val_loss: 20.9872 - val_recon_loss: 6.5012e-04 - val_KL loss: 10.1995 - val_beta: 0.0078\n",
      "Epoch 282/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.8088 - recon_loss: 6.2447e-04 - KL loss: 10.4467 - beta: 0.0078 - val_loss: 20.7077 - val_recon_loss: 6.3310e-04 - val_KL loss: 10.2025 - val_beta: 0.0078\n",
      "Epoch 283/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6502 - recon_loss: 6.1756e-04 - KL loss: 10.4028 - beta: 0.0078 - val_loss: 21.0252 - val_recon_loss: 6.5215e-04 - val_KL loss: 10.2039 - val_beta: 0.0078\n",
      "Epoch 284/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6703 - recon_loss: 6.1742e-04 - KL loss: 10.4252 - beta: 0.0078 - val_loss: 20.9578 - val_recon_loss: 6.4688e-04 - val_KL loss: 10.2239 - val_beta: 0.0078\n",
      "Epoch 285/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6940 - recon_loss: 6.1897e-04 - KL loss: 10.4232 - beta: 0.0078 - val_loss: 21.1338 - val_recon_loss: 6.5830e-04 - val_KL loss: 10.2104 - val_beta: 0.0078\n",
      "Epoch 286/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 20.6992 - recon_loss: 6.1777e-04 - KL loss: 10.4484 - beta: 0.0078 - val_loss: 20.9757 - val_recon_loss: 6.4967e-04 - val_KL loss: 10.1955 - val_beta: 0.0078\n",
      "Epoch 287/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6517 - recon_loss: 6.1889e-04 - KL loss: 10.3822 - beta: 0.0078 - val_loss: 20.6005 - val_recon_loss: 6.2657e-04 - val_KL loss: 10.2037 - val_beta: 0.0078\n",
      "Epoch 288/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6764 - recon_loss: 6.1880e-04 - KL loss: 10.4084 - beta: 0.0078 - val_loss: 20.6360 - val_recon_loss: 6.2885e-04 - val_KL loss: 10.2012 - val_beta: 0.0078\n",
      "Epoch 289/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6821 - recon_loss: 6.1909e-04 - KL loss: 10.4094 - beta: 0.0078 - val_loss: 20.7971 - val_recon_loss: 6.3876e-04 - val_KL loss: 10.1979 - val_beta: 0.0078\n",
      "Epoch 290/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.7555 - recon_loss: 6.2251e-04 - KL loss: 10.4260 - beta: 0.0078 - val_loss: 21.7023 - val_recon_loss: 6.9293e-04 - val_KL loss: 10.2042 - val_beta: 0.0078\n",
      "Epoch 291/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6740 - recon_loss: 6.1778e-04 - KL loss: 10.4229 - beta: 0.0078 - val_loss: 20.7985 - val_recon_loss: 6.3698e-04 - val_KL loss: 10.2289 - val_beta: 0.0078\n",
      "Epoch 292/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 20.6305 - recon_loss: 6.1438e-04 - KL loss: 10.4359 - beta: 0.0078\n",
      "Epoch 00292: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 20.6305 - recon_loss: 6.1438e-04 - KL loss: 10.4359 - beta: 0.0078 - val_loss: 21.1870 - val_recon_loss: 6.6215e-04 - val_KL loss: 10.1998 - val_beta: 0.0078\n",
      "Epoch 293/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.7879 - recon_loss: 6.2381e-04 - KL loss: 10.4368 - beta: 0.0078 - val_loss: 20.9807 - val_recon_loss: 6.4954e-04 - val_KL loss: 10.2026 - val_beta: 0.0078\n",
      "Epoch 294/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.6736 - recon_loss: 6.1766e-04 - KL loss: 10.4247 - beta: 0.0078 - val_loss: 21.0867 - val_recon_loss: 6.5505e-04 - val_KL loss: 10.2173 - val_beta: 0.0078\n",
      "Epoch 295/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6501 - recon_loss: 6.1582e-04 - KL loss: 10.4316 - beta: 0.0078 - val_loss: 20.7866 - val_recon_loss: 6.3707e-04 - val_KL loss: 10.2155 - val_beta: 0.0078\n",
      "Epoch 296/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 20.6273 - recon_loss: 6.1447e-04 - KL loss: 10.4312 - beta: 0.0078 - val_loss: 20.5247 - val_recon_loss: 6.2157e-04 - val_KL loss: 10.2108 - val_beta: 0.0078\n",
      "Epoch 297/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.6469 - recon_loss: 6.1584e-04 - KL loss: 10.4280 - beta: 0.0078 - val_loss: 21.1536 - val_recon_loss: 6.5988e-04 - val_KL loss: 10.2040 - val_beta: 0.0078\n",
      "Epoch 298/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.8092 - recon_loss: 6.2465e-04 - KL loss: 10.4443 - beta: 0.0078 - val_loss: 21.0289 - val_recon_loss: 6.5253e-04 - val_KL loss: 10.2013 - val_beta: 0.0078\n",
      "Epoch 299/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6612 - recon_loss: 6.1830e-04 - KL loss: 10.4016 - beta: 0.0078 - val_loss: 20.8799 - val_recon_loss: 6.4332e-04 - val_KL loss: 10.2050 - val_beta: 0.0078\n",
      "Epoch 300/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.7268 - recon_loss: 6.1987e-04 - KL loss: 10.4411 - beta: 0.0078 - val_loss: 20.4835 - val_recon_loss: 6.1912e-04 - val_KL loss: 10.2102 - val_beta: 0.0078\n",
      "Epoch 301/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6628 - recon_loss: 6.1657e-04 - KL loss: 10.4320 - beta: 0.0078 - val_loss: 21.0975 - val_recon_loss: 6.5613e-04 - val_KL loss: 10.2101 - val_beta: 0.0078\n",
      "Epoch 302/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.6616 - recon_loss: 6.1703e-04 - KL loss: 10.4230 - beta: 0.0078 - val_loss: 20.7914 - val_recon_loss: 6.3846e-04 - val_KL loss: 10.1973 - val_beta: 0.0078\n",
      "Epoch 303/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.7337 - recon_loss: 6.2024e-04 - KL loss: 10.4419 - beta: 0.0078 - val_loss: 21.6548 - val_recon_loss: 6.9008e-04 - val_KL loss: 10.2041 - val_beta: 0.0078\n",
      "Epoch 304/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.7514 - recon_loss: 6.2126e-04 - KL loss: 10.4426 - beta: 0.0078 - val_loss: 21.2613 - val_recon_loss: 6.6614e-04 - val_KL loss: 10.2078 - val_beta: 0.0078\n",
      "Epoch 305/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 20.7340 - recon_loss: 6.2127e-04 - KL loss: 10.4251 - beta: 0.0078\n",
      "Epoch 00305: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.7339 - recon_loss: 6.2127e-04 - KL loss: 10.4251 - beta: 0.0078 - val_loss: 21.2494 - val_recon_loss: 6.6560e-04 - val_KL loss: 10.2048 - val_beta: 0.0078\n",
      "Epoch 306/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.7567 - recon_loss: 6.2124e-04 - KL loss: 10.4482 - beta: 0.0078 - val_loss: 20.7850 - val_recon_loss: 6.3790e-04 - val_KL loss: 10.2002 - val_beta: 0.0078\n",
      "Epoch 307/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.6528 - recon_loss: 6.1725e-04 - KL loss: 10.4105 - beta: 0.0078 - val_loss: 20.7901 - val_recon_loss: 6.3819e-04 - val_KL loss: 10.2004 - val_beta: 0.0078\n",
      "Epoch 308/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.7028 - recon_loss: 6.1938e-04 - KL loss: 10.4251 - beta: 0.0078 - val_loss: 20.2207 - val_recon_loss: 6.0415e-04 - val_KL loss: 10.1958 - val_beta: 0.0078\n",
      "Epoch 309/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.7054 - recon_loss: 6.1976e-04 - KL loss: 10.4216 - beta: 0.0078 - val_loss: 20.9352 - val_recon_loss: 6.4731e-04 - val_KL loss: 10.1941 - val_beta: 0.0078\n",
      "Epoch 310/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.6245 - recon_loss: 6.1493e-04 - KL loss: 10.4208 - beta: 0.0078 - val_loss: 20.9559 - val_recon_loss: 6.4854e-04 - val_KL loss: 10.1945 - val_beta: 0.0078\n",
      "Epoch 311/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6941 - recon_loss: 6.1965e-04 - KL loss: 10.4121 - beta: 0.0078 - val_loss: 21.3106 - val_recon_loss: 6.6982e-04 - val_KL loss: 10.1960 - val_beta: 0.0078\n",
      "Epoch 312/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6487 - recon_loss: 6.1677e-04 - KL loss: 10.4145 - beta: 0.0078 - val_loss: 21.1442 - val_recon_loss: 6.5959e-04 - val_KL loss: 10.1995 - val_beta: 0.0078\n",
      "Epoch 313/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 20.6132 - recon_loss: 6.1494e-04 - KL loss: 10.4094 - beta: 0.0078\n",
      "Epoch 00313: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6133 - recon_loss: 6.1494e-04 - KL loss: 10.4094 - beta: 0.0078 - val_loss: 21.0922 - val_recon_loss: 6.5656e-04 - val_KL loss: 10.1976 - val_beta: 0.0078\n",
      "Epoch 314/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6312 - recon_loss: 6.1620e-04 - KL loss: 10.4064 - beta: 0.0078 - val_loss: 21.0300 - val_recon_loss: 6.5274e-04 - val_KL loss: 10.1989 - val_beta: 0.0078\n",
      "Epoch 315/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.7569 - recon_loss: 6.2166e-04 - KL loss: 10.4415 - beta: 0.0078 - val_loss: 20.9085 - val_recon_loss: 6.4533e-04 - val_KL loss: 10.2004 - val_beta: 0.0078\n",
      "Epoch 316/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.6414 - recon_loss: 6.1601e-04 - KL loss: 10.4198 - beta: 0.0078 - val_loss: 21.1495 - val_recon_loss: 6.5982e-04 - val_KL loss: 10.2009 - val_beta: 0.0078\n",
      "Epoch 317/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.6711 - recon_loss: 6.1810e-04 - KL loss: 10.4147 - beta: 0.0078 - val_loss: 21.2754 - val_recon_loss: 6.6747e-04 - val_KL loss: 10.1998 - val_beta: 0.0078\n",
      "Epoch 318/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20.7754 - recon_loss: 6.2346e-04 - KL loss: 10.4302 - beta: 0.0078 - val_loss: 20.7884 - val_recon_loss: 6.3808e-04 - val_KL loss: 10.2006 - val_beta: 0.0078\n",
      "Epoch 318/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.3904 - recon_loss: 8.3484e-04 - KL loss: 8.2876 - beta: 0.0117 - val_loss: 14.6231 - val_recon_loss: 9.2611e-04 - val_KL loss: 7.8532 - val_beta: 0.0117\n",
      "Epoch 319/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.4205 - recon_loss: 8.8532e-04 - KL loss: 7.9487 - beta: 0.0117 - val_loss: 14.2127 - val_recon_loss: 8.9275e-04 - val_KL loss: 7.6867 - val_beta: 0.0117\n",
      "Epoch 320/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.4500 - recon_loss: 9.0173e-04 - KL loss: 7.8583 - beta: 0.0117 - val_loss: 14.6739 - val_recon_loss: 9.2030e-04 - val_KL loss: 7.9464 - val_beta: 0.0117\n",
      "Epoch 321/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.5348 - recon_loss: 9.1804e-04 - KL loss: 7.8239 - beta: 0.0117 - val_loss: 14.0052 - val_recon_loss: 8.7090e-04 - val_KL loss: 7.6389 - val_beta: 0.0117\n",
      "Epoch 322/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.4100 - recon_loss: 9.1163e-04 - KL loss: 7.7460 - beta: 0.0117 - val_loss: 15.2691 - val_recon_loss: 0.0010 - val_KL loss: 7.6007 - val_beta: 0.0117\n",
      "Epoch 323/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.4758 - recon_loss: 9.2281e-04 - KL loss: 7.7300 - beta: 0.0117 - val_loss: 15.2039 - val_recon_loss: 0.0010 - val_KL loss: 7.8307 - val_beta: 0.0117\n",
      "Epoch 324/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.5968 - recon_loss: 9.4487e-04 - KL loss: 7.6897 - beta: 0.0117 - val_loss: 14.4458 - val_recon_loss: 9.3986e-04 - val_KL loss: 7.5754 - val_beta: 0.0117\n",
      "Epoch 325/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.3814 - recon_loss: 9.2021e-04 - KL loss: 7.6546 - beta: 0.0117 - val_loss: 15.0262 - val_recon_loss: 9.9616e-04 - val_KL loss: 7.7442 - val_beta: 0.0117\n",
      "Epoch 326/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.2730 - recon_loss: 9.0624e-04 - KL loss: 7.6483 - beta: 0.0117\n",
      "Epoch 00326: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.2730 - recon_loss: 9.0624e-04 - KL loss: 7.6483 - beta: 0.0117 - val_loss: 14.7514 - val_recon_loss: 9.9091e-04 - val_KL loss: 7.5078 - val_beta: 0.0117\n",
      "Epoch 327/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.3339 - recon_loss: 9.0729e-04 - KL loss: 7.7015 - beta: 0.0117 - val_loss: 13.8817 - val_recon_loss: 8.4448e-04 - val_KL loss: 7.7086 - val_beta: 0.0117\n",
      "Epoch 328/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.1107 - recon_loss: 8.7824e-04 - KL loss: 7.6908 - beta: 0.0117 - val_loss: 14.6228 - val_recon_loss: 9.4973e-04 - val_KL loss: 7.6802 - val_beta: 0.0117\n",
      "Epoch 329/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.0086 - recon_loss: 8.6849e-04 - KL loss: 7.6598 - beta: 0.0117 - val_loss: 13.9600 - val_recon_loss: 8.6640e-04 - val_KL loss: 7.6266 - val_beta: 0.0117\n",
      "Epoch 330/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.0223 - recon_loss: 8.7214e-04 - KL loss: 7.6469 - beta: 0.0117 - val_loss: 14.1452 - val_recon_loss: 8.8531e-04 - val_KL loss: 7.6736 - val_beta: 0.0117\n",
      "Epoch 331/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.0284 - recon_loss: 8.7058e-04 - KL loss: 7.6644 - beta: 0.0117 - val_loss: 13.7179 - val_recon_loss: 8.4606e-04 - val_KL loss: 7.5332 - val_beta: 0.0117\n",
      "Epoch 332/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.9952 - recon_loss: 8.6949e-04 - KL loss: 7.6392 - beta: 0.0117 - val_loss: 13.9053 - val_recon_loss: 8.6551e-04 - val_KL loss: 7.5784 - val_beta: 0.0117\n",
      "Epoch 333/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.9458 - recon_loss: 8.6581e-04 - KL loss: 7.6167 - beta: 0.0117 - val_loss: 13.7885 - val_recon_loss: 8.4905e-04 - val_KL loss: 7.5819 - val_beta: 0.0117\n",
      "Epoch 334/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.9984 - recon_loss: 8.7009e-04 - KL loss: 7.6380 - beta: 0.0117 - val_loss: 13.5765 - val_recon_loss: 8.3604e-04 - val_KL loss: 7.4651 - val_beta: 0.0117\n",
      "Epoch 335/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.9761 - recon_loss: 8.6634e-04 - KL loss: 7.6431 - beta: 0.0117 - val_loss: 14.0380 - val_recon_loss: 8.7306e-04 - val_KL loss: 7.6559 - val_beta: 0.0117\n",
      "Epoch 336/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.9877 - recon_loss: 8.6745e-04 - KL loss: 7.6466 - beta: 0.0117 - val_loss: 13.6539 - val_recon_loss: 8.3621e-04 - val_KL loss: 7.5411 - val_beta: 0.0117\n",
      "Epoch 337/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.9383 - recon_loss: 8.6177e-04 - KL loss: 7.6387 - beta: 0.0117 - val_loss: 14.0943 - val_recon_loss: 8.9102e-04 - val_KL loss: 7.5809 - val_beta: 0.0117\n",
      "Epoch 338/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.9306 - recon_loss: 8.6239e-04 - KL loss: 7.6265 - beta: 0.0117 - val_loss: 13.6659 - val_recon_loss: 8.4040e-04 - val_KL loss: 7.5225 - val_beta: 0.0117\n",
      "Epoch 339/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13.9435 - recon_loss: 8.6566e-04 - KL loss: 7.6155 - beta: 0.0117\n",
      "Epoch 00339: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.9435 - recon_loss: 8.6566e-04 - KL loss: 7.6155 - beta: 0.0117 - val_loss: 14.2363 - val_recon_loss: 9.1111e-04 - val_KL loss: 7.5760 - val_beta: 0.0117\n",
      "Epoch 340/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.8620 - recon_loss: 8.5386e-04 - KL loss: 7.6202 - beta: 0.0117 - val_loss: 13.5706 - val_recon_loss: 8.2239e-04 - val_KL loss: 7.5589 - val_beta: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.8156 - recon_loss: 8.4726e-04 - KL loss: 7.6220 - beta: 0.0117 - val_loss: 13.9394 - val_recon_loss: 8.7849e-04 - val_KL loss: 7.5176 - val_beta: 0.0117\n",
      "Epoch 342/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.8395 - recon_loss: 8.5140e-04 - KL loss: 7.6157 - beta: 0.0117 - val_loss: 13.7167 - val_recon_loss: 8.3737e-04 - val_KL loss: 7.5955 - val_beta: 0.0117\n",
      "Epoch 343/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.8501 - recon_loss: 8.5172e-04 - KL loss: 7.6240 - beta: 0.0117 - val_loss: 13.9063 - val_recon_loss: 8.7047e-04 - val_KL loss: 7.5431 - val_beta: 0.0117\n",
      "Epoch 344/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.7823 - recon_loss: 8.4647e-04 - KL loss: 7.5945 - beta: 0.0117 - val_loss: 13.9163 - val_recon_loss: 8.7815e-04 - val_KL loss: 7.4970 - val_beta: 0.0117\n",
      "Epoch 345/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.8169 - recon_loss: 8.4866e-04 - KL loss: 7.6131 - beta: 0.0117 - val_loss: 13.4709 - val_recon_loss: 8.0917e-04 - val_KL loss: 7.5558 - val_beta: 0.0117\n",
      "Epoch 346/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.8226 - recon_loss: 8.4890e-04 - KL loss: 7.6172 - beta: 0.0117 - val_loss: 13.6890 - val_recon_loss: 8.4543e-04 - val_KL loss: 7.5089 - val_beta: 0.0117\n",
      "Epoch 347/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.8232 - recon_loss: 8.4668e-04 - KL loss: 7.6339 - beta: 0.0117 - val_loss: 14.0731 - val_recon_loss: 8.8839e-04 - val_KL loss: 7.5789 - val_beta: 0.0117\n",
      "Epoch 348/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.8302 - recon_loss: 8.5099e-04 - KL loss: 7.6094 - beta: 0.0117 - val_loss: 13.5264 - val_recon_loss: 8.2247e-04 - val_KL loss: 7.5141 - val_beta: 0.0117\n",
      "Epoch 349/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.7840 - recon_loss: 8.4367e-04 - KL loss: 7.6167 - beta: 0.0117 - val_loss: 13.8270 - val_recon_loss: 8.6004e-04 - val_KL loss: 7.5401 - val_beta: 0.0117\n",
      "Epoch 350/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13.7828 - recon_loss: 8.4300e-04 - KL loss: 7.6205 - beta: 0.0117\n",
      "Epoch 00350: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.7829 - recon_loss: 8.4300e-04 - KL loss: 7.6205 - beta: 0.0117 - val_loss: 13.9228 - val_recon_loss: 8.7348e-04 - val_KL loss: 7.5376 - val_beta: 0.0117\n",
      "Epoch 351/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.7639 - recon_loss: 8.4054e-04 - KL loss: 7.6195 - beta: 0.0117 - val_loss: 13.8839 - val_recon_loss: 8.6643e-04 - val_KL loss: 7.5503 - val_beta: 0.0117\n",
      "Epoch 352/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.7853 - recon_loss: 8.4277e-04 - KL loss: 7.6246 - beta: 0.0117 - val_loss: 14.0698 - val_recon_loss: 8.9114e-04 - val_KL loss: 7.5555 - val_beta: 0.0117\n",
      "Epoch 353/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.7890 - recon_loss: 8.4394e-04 - KL loss: 7.6198 - beta: 0.0117 - val_loss: 13.7163 - val_recon_loss: 8.4557e-04 - val_KL loss: 7.5351 - val_beta: 0.0117\n",
      "Epoch 354/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.7566 - recon_loss: 8.4014e-04 - KL loss: 7.6151 - beta: 0.0117 - val_loss: 13.7824 - val_recon_loss: 8.5769e-04 - val_KL loss: 7.5126 - val_beta: 0.0117\n",
      "Epoch 355/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13.7393 - recon_loss: 8.3939e-04 - KL loss: 7.6033 - beta: 0.0117\n",
      "Epoch 00355: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.7393 - recon_loss: 8.3939e-04 - KL loss: 7.6033 - beta: 0.0117 - val_loss: 13.6533 - val_recon_loss: 8.3892e-04 - val_KL loss: 7.5208 - val_beta: 0.0117\n",
      "Epoch 355/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.8686 - recon_loss: 0.0012 - KL loss: 5.9230 - beta: 0.0176 - val_loss: 9.6536 - val_recon_loss: 0.0012 - val_KL loss: 5.7232 - val_beta: 0.0176\n",
      "Epoch 356/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.8392 - recon_loss: 0.0013 - KL loss: 5.6710 - beta: 0.0176 - val_loss: 9.4875 - val_recon_loss: 0.0012 - val_KL loss: 5.5968 - val_beta: 0.0176\n",
      "Epoch 357/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.8341 - recon_loss: 0.0013 - KL loss: 5.5913 - beta: 0.0176 - val_loss: 9.6311 - val_recon_loss: 0.0013 - val_KL loss: 5.4662 - val_beta: 0.0176\n",
      "Epoch 358/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.8918 - recon_loss: 0.0014 - KL loss: 5.5342 - beta: 0.0176 - val_loss: 9.8441 - val_recon_loss: 0.0013 - val_KL loss: 5.6495 - val_beta: 0.0176\n",
      "Epoch 359/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.8643 - recon_loss: 0.0013 - KL loss: 5.5275 - beta: 0.0176 - val_loss: 10.0319 - val_recon_loss: 0.0014 - val_KL loss: 5.5627 - val_beta: 0.0176\n",
      "Epoch 360/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.8731 - recon_loss: 0.0014 - KL loss: 5.4888 - beta: 0.0176 - val_loss: 9.5425 - val_recon_loss: 0.0013 - val_KL loss: 5.4228 - val_beta: 0.0176\n",
      "Epoch 361/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 9.8637 - recon_loss: 0.0014 - KL loss: 5.4824 - beta: 0.0176\n",
      "Epoch 00361: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.8636 - recon_loss: 0.0014 - KL loss: 5.4824 - beta: 0.0176 - val_loss: 9.8723 - val_recon_loss: 0.0014 - val_KL loss: 5.4638 - val_beta: 0.0176\n",
      "Epoch 362/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.6900 - recon_loss: 0.0013 - KL loss: 5.4435 - beta: 0.0176 - val_loss: 9.8297 - val_recon_loss: 0.0014 - val_KL loss: 5.4710 - val_beta: 0.0176\n",
      "Epoch 363/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 9.6631 - recon_loss: 0.0013 - KL loss: 5.4463 - beta: 0.0176 - val_loss: 9.9228 - val_recon_loss: 0.0014 - val_KL loss: 5.3305 - val_beta: 0.0176\n",
      "Epoch 364/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 9.7159 - recon_loss: 0.0013 - KL loss: 5.4835 - beta: 0.0176 - val_loss: 9.3946 - val_recon_loss: 0.0012 - val_KL loss: 5.4327 - val_beta: 0.0176\n",
      "Epoch 365/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.6723 - recon_loss: 0.0013 - KL loss: 5.4721 - beta: 0.0176 - val_loss: 9.4789 - val_recon_loss: 0.0013 - val_KL loss: 5.4122 - val_beta: 0.0176\n",
      "Epoch 366/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.6503 - recon_loss: 0.0013 - KL loss: 5.4394 - beta: 0.0176 - val_loss: 9.5410 - val_recon_loss: 0.0013 - val_KL loss: 5.3971 - val_beta: 0.0176\n",
      "Epoch 367/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.6352 - recon_loss: 0.0013 - KL loss: 5.4462 - beta: 0.0176 - val_loss: 9.3998 - val_recon_loss: 0.0012 - val_KL loss: 5.4063 - val_beta: 0.0176\n",
      "Epoch 368/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 9.6404 - recon_loss: 0.0013 - KL loss: 5.4522 - beta: 0.0176 - val_loss: 10.0269 - val_recon_loss: 0.0014 - val_KL loss: 5.4373 - val_beta: 0.0176\n",
      "Epoch 369/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.6582 - recon_loss: 0.0013 - KL loss: 5.4508 - beta: 0.0176 - val_loss: 9.1330 - val_recon_loss: 0.0012 - val_KL loss: 5.4287 - val_beta: 0.0176\n",
      "Epoch 370/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.6202 - recon_loss: 0.0013 - KL loss: 5.4537 - beta: 0.0176 - val_loss: 9.5187 - val_recon_loss: 0.0013 - val_KL loss: 5.4752 - val_beta: 0.0176\n",
      "Epoch 371/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.6439 - recon_loss: 0.0013 - KL loss: 5.4308 - beta: 0.0176 - val_loss: 9.6007 - val_recon_loss: 0.0013 - val_KL loss: 5.4435 - val_beta: 0.0176\n",
      "Epoch 372/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.6246 - recon_loss: 0.0013 - KL loss: 5.4231 - beta: 0.0176 - val_loss: 9.7770 - val_recon_loss: 0.0014 - val_KL loss: 5.3774 - val_beta: 0.0176\n",
      "Epoch 373/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.6067 - recon_loss: 0.0013 - KL loss: 5.4094 - beta: 0.0176 - val_loss: 9.6536 - val_recon_loss: 0.0013 - val_KL loss: 5.4085 - val_beta: 0.0176\n",
      "Epoch 374/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.6327 - recon_loss: 0.0013 - KL loss: 5.4282 - beta: 0.0176\n",
      "Epoch 00374: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.6327 - recon_loss: 0.0013 - KL loss: 5.4282 - beta: 0.0176 - val_loss: 9.5724 - val_recon_loss: 0.0013 - val_KL loss: 5.4483 - val_beta: 0.0176\n",
      "Epoch 375/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.6296 - recon_loss: 0.0013 - KL loss: 5.4426 - beta: 0.0176 - val_loss: 9.3552 - val_recon_loss: 0.0012 - val_KL loss: 5.3623 - val_beta: 0.0176\n",
      "Epoch 376/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.5841 - recon_loss: 0.0013 - KL loss: 5.4278 - beta: 0.0176 - val_loss: 9.4069 - val_recon_loss: 0.0012 - val_KL loss: 5.3995 - val_beta: 0.0176\n",
      "Epoch 377/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.5617 - recon_loss: 0.0013 - KL loss: 5.4238 - beta: 0.0176 - val_loss: 9.7853 - val_recon_loss: 0.0014 - val_KL loss: 5.3909 - val_beta: 0.0176\n",
      "Epoch 378/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.5835 - recon_loss: 0.0013 - KL loss: 5.4215 - beta: 0.0176 - val_loss: 9.6707 - val_recon_loss: 0.0013 - val_KL loss: 5.4125 - val_beta: 0.0176\n",
      "Epoch 379/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.5809 - recon_loss: 0.0013 - KL loss: 5.4286 - beta: 0.0176\n",
      "Epoch 00379: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.5808 - recon_loss: 0.0013 - KL loss: 5.4286 - beta: 0.0176 - val_loss: 9.6363 - val_recon_loss: 0.0013 - val_KL loss: 5.3751 - val_beta: 0.0176\n",
      "Epoch 379/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.8953 - recon_loss: 0.0020 - KL loss: 4.1195 - beta: 0.0265 - val_loss: 6.7141 - val_recon_loss: 0.0020 - val_KL loss: 3.8874 - val_beta: 0.0265\n",
      "Epoch 380/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.8459 - recon_loss: 0.0021 - KL loss: 3.9123 - beta: 0.0265 - val_loss: 6.7596 - val_recon_loss: 0.0021 - val_KL loss: 3.8421 - val_beta: 0.0265\n",
      "Epoch 381/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.8463 - recon_loss: 0.0021 - KL loss: 3.8662 - beta: 0.0265 - val_loss: 7.0333 - val_recon_loss: 0.0023 - val_KL loss: 3.7092 - val_beta: 0.0265\n",
      "Epoch 382/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.8308 - recon_loss: 0.0021 - KL loss: 3.8245 - beta: 0.0265 - val_loss: 6.5229 - val_recon_loss: 0.0019 - val_KL loss: 3.8040 - val_beta: 0.0265\n",
      "Epoch 383/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.8153 - recon_loss: 0.0021 - KL loss: 3.7980 - beta: 0.0265 - val_loss: 6.7165 - val_recon_loss: 0.0021 - val_KL loss: 3.7675 - val_beta: 0.0265\n",
      "Epoch 384/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6.8119 - recon_loss: 0.0021 - KL loss: 3.7781 - beta: 0.0265 - val_loss: 6.5338 - val_recon_loss: 0.0020 - val_KL loss: 3.6480 - val_beta: 0.0265\n",
      "Epoch 385/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7900 - recon_loss: 0.0021 - KL loss: 3.7535 - beta: 0.0265 - val_loss: 6.8742 - val_recon_loss: 0.0022 - val_KL loss: 3.6955 - val_beta: 0.0265\n",
      "Epoch 386/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.8302 - recon_loss: 0.0022 - KL loss: 3.7635 - beta: 0.0265 - val_loss: 6.9595 - val_recon_loss: 0.0021 - val_KL loss: 3.9305 - val_beta: 0.0265\n",
      "Epoch 387/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.8166 - recon_loss: 0.0022 - KL loss: 3.7609 - beta: 0.0265\n",
      "Epoch 00387: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.8166 - recon_loss: 0.0022 - KL loss: 3.7609 - beta: 0.0265 - val_loss: 6.7784 - val_recon_loss: 0.0022 - val_KL loss: 3.6855 - val_beta: 0.0265\n",
      "Epoch 388/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7333 - recon_loss: 0.0021 - KL loss: 3.7422 - beta: 0.0265 - val_loss: 6.7089 - val_recon_loss: 0.0021 - val_KL loss: 3.7246 - val_beta: 0.0265\n",
      "Epoch 389/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7373 - recon_loss: 0.0021 - KL loss: 3.7520 - beta: 0.0265 - val_loss: 6.8223 - val_recon_loss: 0.0022 - val_KL loss: 3.6541 - val_beta: 0.0265\n",
      "Epoch 390/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7268 - recon_loss: 0.0021 - KL loss: 3.7503 - beta: 0.0265 - val_loss: 6.8144 - val_recon_loss: 0.0022 - val_KL loss: 3.6882 - val_beta: 0.0265\n",
      "Epoch 391/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7230 - recon_loss: 0.0021 - KL loss: 3.7469 - beta: 0.0265 - val_loss: 6.6890 - val_recon_loss: 0.0021 - val_KL loss: 3.6955 - val_beta: 0.0265\n",
      "Epoch 392/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.7160 - recon_loss: 0.0021 - KL loss: 3.7577 - beta: 0.0265\n",
      "Epoch 00392: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7160 - recon_loss: 0.0021 - KL loss: 3.7577 - beta: 0.0265 - val_loss: 6.9085 - val_recon_loss: 0.0022 - val_KL loss: 3.7844 - val_beta: 0.0265\n",
      "Epoch 392/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.7547 - recon_loss: 0.0033 - KL loss: 2.6631 - beta: 0.0400 - val_loss: 4.5919 - val_recon_loss: 0.0033 - val_KL loss: 2.5164 - val_beta: 0.0400\n",
      "Epoch 393/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.7065 - recon_loss: 0.0035 - KL loss: 2.4943 - beta: 0.0400 - val_loss: 4.6229 - val_recon_loss: 0.0034 - val_KL loss: 2.5014 - val_beta: 0.0400\n",
      "Epoch 394/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.7082 - recon_loss: 0.0036 - KL loss: 2.4682 - beta: 0.0400 - val_loss: 4.6969 - val_recon_loss: 0.0036 - val_KL loss: 2.4424 - val_beta: 0.0400\n",
      "Epoch 395/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 4.7192 - recon_loss: 0.0036 - KL loss: 2.4666 - beta: 0.0400 - val_loss: 4.6127 - val_recon_loss: 0.0034 - val_KL loss: 2.5187 - val_beta: 0.0400\n",
      "Epoch 396/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.7127 - recon_loss: 0.0036 - KL loss: 2.4610 - beta: 0.0400 - val_loss: 4.7273 - val_recon_loss: 0.0037 - val_KL loss: 2.4369 - val_beta: 0.0400\n",
      "Epoch 397/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 4.7097 - recon_loss: 0.0036 - KL loss: 2.4450 - beta: 0.0400\n",
      "Epoch 00397: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.7097 - recon_loss: 0.0036 - KL loss: 2.4450 - beta: 0.0400 - val_loss: 4.7444 - val_recon_loss: 0.0037 - val_KL loss: 2.4177 - val_beta: 0.0400\n",
      "Epoch 398/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6799 - recon_loss: 0.0036 - KL loss: 2.4511 - beta: 0.0400 - val_loss: 4.6917 - val_recon_loss: 0.0035 - val_KL loss: 2.5222 - val_beta: 0.0400\n",
      "Epoch 399/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6785 - recon_loss: 0.0036 - KL loss: 2.4455 - beta: 0.0400 - val_loss: 5.0117 - val_recon_loss: 0.0041 - val_KL loss: 2.4732 - val_beta: 0.0400\n",
      "Epoch 400/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6815 - recon_loss: 0.0036 - KL loss: 2.4446 - beta: 0.0400 - val_loss: 4.5001 - val_recon_loss: 0.0033 - val_KL loss: 2.4135 - val_beta: 0.0400\n",
      "Epoch 401/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6699 - recon_loss: 0.0036 - KL loss: 2.4428 - beta: 0.0400 - val_loss: 4.8030 - val_recon_loss: 0.0038 - val_KL loss: 2.4000 - val_beta: 0.0400\n",
      "Epoch 402/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6829 - recon_loss: 0.0036 - KL loss: 2.4434 - beta: 0.0400 - val_loss: 4.6780 - val_recon_loss: 0.0036 - val_KL loss: 2.4159 - val_beta: 0.0400\n",
      "Epoch 403/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6736 - recon_loss: 0.0036 - KL loss: 2.4334 - beta: 0.0400 - val_loss: 4.8656 - val_recon_loss: 0.0040 - val_KL loss: 2.3695 - val_beta: 0.0400\n",
      "Epoch 404/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6746 - recon_loss: 0.0036 - KL loss: 2.4417 - beta: 0.0400 - val_loss: 5.0069 - val_recon_loss: 0.0041 - val_KL loss: 2.4148 - val_beta: 0.0400\n",
      "Epoch 405/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 4.6586 - recon_loss: 0.0036 - KL loss: 2.4328 - beta: 0.0400\n",
      "Epoch 00405: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 4.6586 - recon_loss: 0.0036 - KL loss: 2.4328 - beta: 0.0400 - val_loss: 4.6633 - val_recon_loss: 0.0035 - val_KL loss: 2.4635 - val_beta: 0.0400\n",
      "Epoch 406/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6529 - recon_loss: 0.0035 - KL loss: 2.4429 - beta: 0.0400 - val_loss: 4.6741 - val_recon_loss: 0.0036 - val_KL loss: 2.3983 - val_beta: 0.0400\n",
      "Epoch 407/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6429 - recon_loss: 0.0035 - KL loss: 2.4317 - beta: 0.0400 - val_loss: 4.6930 - val_recon_loss: 0.0036 - val_KL loss: 2.4600 - val_beta: 0.0400\n",
      "Epoch 408/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6489 - recon_loss: 0.0035 - KL loss: 2.4332 - beta: 0.0400 - val_loss: 4.6142 - val_recon_loss: 0.0035 - val_KL loss: 2.4420 - val_beta: 0.0400\n",
      "Epoch 409/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6598 - recon_loss: 0.0035 - KL loss: 2.4447 - beta: 0.0400 - val_loss: 4.3905 - val_recon_loss: 0.0031 - val_KL loss: 2.4418 - val_beta: 0.0400\n",
      "Epoch 410/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6706 - recon_loss: 0.0036 - KL loss: 2.4474 - beta: 0.0400 - val_loss: 4.5405 - val_recon_loss: 0.0034 - val_KL loss: 2.4413 - val_beta: 0.0400\n",
      "Epoch 411/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 4.6488 - recon_loss: 0.0035 - KL loss: 2.4333 - beta: 0.0400 - val_loss: 4.5259 - val_recon_loss: 0.0033 - val_KL loss: 2.4586 - val_beta: 0.0400\n",
      "Epoch 412/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6473 - recon_loss: 0.0035 - KL loss: 2.4361 - beta: 0.0400 - val_loss: 4.6952 - val_recon_loss: 0.0035 - val_KL loss: 2.4960 - val_beta: 0.0400\n",
      "Epoch 413/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6424 - recon_loss: 0.0035 - KL loss: 2.4410 - beta: 0.0400 - val_loss: 4.7139 - val_recon_loss: 0.0037 - val_KL loss: 2.3847 - val_beta: 0.0400\n",
      "Epoch 414/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.6597 - recon_loss: 0.0036 - KL loss: 2.4399 - beta: 0.0400\n",
      "Epoch 00414: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6597 - recon_loss: 0.0036 - KL loss: 2.4399 - beta: 0.0400 - val_loss: 4.6745 - val_recon_loss: 0.0036 - val_KL loss: 2.4210 - val_beta: 0.0400\n",
      "Epoch 415/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 4.6524 - recon_loss: 0.0036 - KL loss: 2.4329 - beta: 0.0400 - val_loss: 4.6382 - val_recon_loss: 0.0035 - val_KL loss: 2.4225 - val_beta: 0.0400\n",
      "Epoch 416/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6624 - recon_loss: 0.0036 - KL loss: 2.4402 - beta: 0.0400 - val_loss: 4.8198 - val_recon_loss: 0.0039 - val_KL loss: 2.3982 - val_beta: 0.0400\n",
      "Epoch 417/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6536 - recon_loss: 0.0035 - KL loss: 2.4399 - beta: 0.0400 - val_loss: 4.5452 - val_recon_loss: 0.0035 - val_KL loss: 2.3881 - val_beta: 0.0400\n",
      "Epoch 418/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6464 - recon_loss: 0.0035 - KL loss: 2.4335 - beta: 0.0400 - val_loss: 4.6361 - val_recon_loss: 0.0036 - val_KL loss: 2.4035 - val_beta: 0.0400\n",
      "Epoch 419/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.6426 - recon_loss: 0.0035 - KL loss: 2.4357 - beta: 0.0400\n",
      "Epoch 00419: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6426 - recon_loss: 0.0035 - KL loss: 2.4357 - beta: 0.0400 - val_loss: 4.8631 - val_recon_loss: 0.0039 - val_KL loss: 2.4000 - val_beta: 0.0400\n",
      "Epoch 419/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.8991 - recon_loss: 0.0023 - KL loss: 3.5716 - beta: 0.0265 - val_loss: 6.5481 - val_recon_loss: 0.0020 - val_KL loss: 3.6801 - val_beta: 0.0265\n",
      "Epoch 420/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.7816 - recon_loss: 0.0022 - KL loss: 3.6792 - beta: 0.0265 - val_loss: 6.8361 - val_recon_loss: 0.0023 - val_KL loss: 3.5743 - val_beta: 0.0265\n",
      "Epoch 421/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7661 - recon_loss: 0.0022 - KL loss: 3.6708 - beta: 0.0265 - val_loss: 6.5699 - val_recon_loss: 0.0021 - val_KL loss: 3.6381 - val_beta: 0.0265\n",
      "Epoch 422/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.7569 - recon_loss: 0.0022 - KL loss: 3.6810 - beta: 0.0265 - val_loss: 6.5686 - val_recon_loss: 0.0020 - val_KL loss: 3.7431 - val_beta: 0.0265\n",
      "Epoch 423/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7613 - recon_loss: 0.0022 - KL loss: 3.7070 - beta: 0.0265 - val_loss: 6.7944 - val_recon_loss: 0.0022 - val_KL loss: 3.7434 - val_beta: 0.0265\n",
      "Epoch 424/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7472 - recon_loss: 0.0022 - KL loss: 3.6956 - beta: 0.0265 - val_loss: 6.5297 - val_recon_loss: 0.0020 - val_KL loss: 3.6567 - val_beta: 0.0265\n",
      "Epoch 425/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7400 - recon_loss: 0.0021 - KL loss: 3.7029 - beta: 0.0265 - val_loss: 6.7218 - val_recon_loss: 0.0021 - val_KL loss: 3.6949 - val_beta: 0.0265\n",
      "Epoch 426/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7437 - recon_loss: 0.0021 - KL loss: 3.7154 - beta: 0.0265 - val_loss: 6.6660 - val_recon_loss: 0.0021 - val_KL loss: 3.6866 - val_beta: 0.0265\n",
      "Epoch 427/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7211 - recon_loss: 0.0021 - KL loss: 3.7210 - beta: 0.0265 - val_loss: 6.6837 - val_recon_loss: 0.0020 - val_KL loss: 3.7989 - val_beta: 0.0265\n",
      "Epoch 428/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7512 - recon_loss: 0.0021 - KL loss: 3.7093 - beta: 0.0265 - val_loss: 6.8152 - val_recon_loss: 0.0022 - val_KL loss: 3.6421 - val_beta: 0.0265\n",
      "Epoch 429/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.7459 - recon_loss: 0.0021 - KL loss: 3.7129 - beta: 0.0265\n",
      "Epoch 00429: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.7459 - recon_loss: 0.0021 - KL loss: 3.7129 - beta: 0.0265 - val_loss: 6.5559 - val_recon_loss: 0.0021 - val_KL loss: 3.5961 - val_beta: 0.0265\n",
      "Epoch 430/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6732 - recon_loss: 0.0021 - KL loss: 3.7124 - beta: 0.0265 - val_loss: 6.7022 - val_recon_loss: 0.0022 - val_KL loss: 3.6510 - val_beta: 0.0265\n",
      "Epoch 431/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6726 - recon_loss: 0.0021 - KL loss: 3.7307 - beta: 0.0265 - val_loss: 6.7789 - val_recon_loss: 0.0022 - val_KL loss: 3.6611 - val_beta: 0.0265\n",
      "Epoch 432/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6777 - recon_loss: 0.0021 - KL loss: 3.7122 - beta: 0.0265 - val_loss: 6.5051 - val_recon_loss: 0.0019 - val_KL loss: 3.7930 - val_beta: 0.0265\n",
      "Epoch 433/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6.6621 - recon_loss: 0.0021 - KL loss: 3.7162 - beta: 0.0265 - val_loss: 6.5225 - val_recon_loss: 0.0020 - val_KL loss: 3.6752 - val_beta: 0.0265\n",
      "Epoch 434/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6677 - recon_loss: 0.0021 - KL loss: 3.7070 - beta: 0.0265 - val_loss: 6.5216 - val_recon_loss: 0.0020 - val_KL loss: 3.6978 - val_beta: 0.0265\n",
      "Epoch 435/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6.6761 - recon_loss: 0.0021 - KL loss: 3.7186 - beta: 0.0265 - val_loss: 6.5720 - val_recon_loss: 0.0020 - val_KL loss: 3.7762 - val_beta: 0.0265\n",
      "Epoch 436/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6574 - recon_loss: 0.0021 - KL loss: 3.7102 - beta: 0.0265 - val_loss: 6.7803 - val_recon_loss: 0.0022 - val_KL loss: 3.7125 - val_beta: 0.0265\n",
      "Epoch 437/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.6798 - recon_loss: 0.0021 - KL loss: 3.7338 - beta: 0.0265\n",
      "Epoch 00437: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.6798 - recon_loss: 0.0021 - KL loss: 3.7338 - beta: 0.0265 - val_loss: 6.7002 - val_recon_loss: 0.0021 - val_KL loss: 3.6944 - val_beta: 0.0265\n",
      "Epoch 438/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6619 - recon_loss: 0.0021 - KL loss: 3.7239 - beta: 0.0265 - val_loss: 6.4750 - val_recon_loss: 0.0019 - val_KL loss: 3.7143 - val_beta: 0.0265\n",
      "Epoch 439/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6413 - recon_loss: 0.0021 - KL loss: 3.7212 - beta: 0.0265 - val_loss: 6.7423 - val_recon_loss: 0.0022 - val_KL loss: 3.6874 - val_beta: 0.0265\n",
      "Epoch 440/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6568 - recon_loss: 0.0021 - KL loss: 3.7291 - beta: 0.0265 - val_loss: 6.6855 - val_recon_loss: 0.0021 - val_KL loss: 3.7292 - val_beta: 0.0265\n",
      "Epoch 441/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6354 - recon_loss: 0.0021 - KL loss: 3.7209 - beta: 0.0265 - val_loss: 6.5152 - val_recon_loss: 0.0020 - val_KL loss: 3.7454 - val_beta: 0.0265\n",
      "Epoch 442/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6427 - recon_loss: 0.0021 - KL loss: 3.7306 - beta: 0.0265 - val_loss: 6.2999 - val_recon_loss: 0.0018 - val_KL loss: 3.7329 - val_beta: 0.0265\n",
      "Epoch 443/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6327 - recon_loss: 0.0021 - KL loss: 3.7132 - beta: 0.0265 - val_loss: 6.4623 - val_recon_loss: 0.0019 - val_KL loss: 3.7130 - val_beta: 0.0265\n",
      "Epoch 444/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6616 - recon_loss: 0.0021 - KL loss: 3.7306 - beta: 0.0265 - val_loss: 6.8094 - val_recon_loss: 0.0022 - val_KL loss: 3.6674 - val_beta: 0.0265\n",
      "Epoch 445/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6389 - recon_loss: 0.0021 - KL loss: 3.7113 - beta: 0.0265 - val_loss: 6.6297 - val_recon_loss: 0.0021 - val_KL loss: 3.6956 - val_beta: 0.0265\n",
      "Epoch 446/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6638 - recon_loss: 0.0021 - KL loss: 3.7297 - beta: 0.0265 - val_loss: 6.6283 - val_recon_loss: 0.0020 - val_KL loss: 3.7552 - val_beta: 0.0265\n",
      "Epoch 447/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.6410 - recon_loss: 0.0020 - KL loss: 3.7361 - beta: 0.0265\n",
      "Epoch 00447: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6410 - recon_loss: 0.0020 - KL loss: 3.7361 - beta: 0.0265 - val_loss: 6.3755 - val_recon_loss: 0.0019 - val_KL loss: 3.7312 - val_beta: 0.0265\n",
      "Epoch 448/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6404 - recon_loss: 0.0020 - KL loss: 3.7333 - beta: 0.0265 - val_loss: 6.5571 - val_recon_loss: 0.0020 - val_KL loss: 3.7049 - val_beta: 0.0265\n",
      "Epoch 449/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6.6581 - recon_loss: 0.0021 - KL loss: 3.7330 - beta: 0.0265 - val_loss: 6.5710 - val_recon_loss: 0.0020 - val_KL loss: 3.7123 - val_beta: 0.0265\n",
      "Epoch 450/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6.6387 - recon_loss: 0.0021 - KL loss: 3.7256 - beta: 0.0265 - val_loss: 7.0449 - val_recon_loss: 0.0023 - val_KL loss: 3.7246 - val_beta: 0.0265\n",
      "Epoch 451/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6.6347 - recon_loss: 0.0020 - KL loss: 3.7375 - beta: 0.0265 - val_loss: 6.5372 - val_recon_loss: 0.0020 - val_KL loss: 3.7111 - val_beta: 0.0265\n",
      "Epoch 452/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 6.6326 - recon_loss: 0.0021 - KL loss: 3.7182 - beta: 0.0265\n",
      "Epoch 00452: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6326 - recon_loss: 0.0021 - KL loss: 3.7183 - beta: 0.0265 - val_loss: 6.8258 - val_recon_loss: 0.0022 - val_KL loss: 3.7250 - val_beta: 0.0265\n",
      "Epoch 452/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.9892 - recon_loss: 0.0016 - KL loss: 4.7798 - beta: 0.0176 - val_loss: 9.6004 - val_recon_loss: 0.0015 - val_KL loss: 4.7959 - val_beta: 0.0176\n",
      "Epoch 453/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.8266 - recon_loss: 0.0015 - KL loss: 4.8812 - beta: 0.0176 - val_loss: 9.5123 - val_recon_loss: 0.0014 - val_KL loss: 4.8854 - val_beta: 0.0176\n",
      "Epoch 454/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.7651 - recon_loss: 0.0015 - KL loss: 4.8962 - beta: 0.0176 - val_loss: 9.4728 - val_recon_loss: 0.0014 - val_KL loss: 4.9004 - val_beta: 0.0176\n",
      "Epoch 455/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.8014 - recon_loss: 0.0015 - KL loss: 4.9217 - beta: 0.0176 - val_loss: 9.4309 - val_recon_loss: 0.0014 - val_KL loss: 4.9549 - val_beta: 0.0176\n",
      "Epoch 456/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 9.7763 - recon_loss: 0.0015 - KL loss: 4.9051 - beta: 0.0176 - val_loss: 9.5113 - val_recon_loss: 0.0014 - val_KL loss: 4.9665 - val_beta: 0.0176\n",
      "Epoch 457/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.7516 - recon_loss: 0.0015 - KL loss: 4.9329 - beta: 0.0176 - val_loss: 9.7097 - val_recon_loss: 0.0015 - val_KL loss: 4.8291 - val_beta: 0.0176\n",
      "Epoch 458/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.7832 - recon_loss: 0.0015 - KL loss: 4.9253 - beta: 0.0176 - val_loss: 9.4360 - val_recon_loss: 0.0014 - val_KL loss: 4.8036 - val_beta: 0.0176\n",
      "Epoch 459/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.7540 - recon_loss: 0.0015 - KL loss: 4.9083 - beta: 0.0176 - val_loss: 10.0535 - val_recon_loss: 0.0016 - val_KL loss: 4.8865 - val_beta: 0.0176\n",
      "Epoch 460/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.7248 - recon_loss: 0.0015 - KL loss: 4.9388 - beta: 0.0176\n",
      "Epoch 00460: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 9.7248 - recon_loss: 0.0015 - KL loss: 4.9388 - beta: 0.0176 - val_loss: 9.7738 - val_recon_loss: 0.0015 - val_KL loss: 5.0715 - val_beta: 0.0176\n",
      "Epoch 461/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 9.6568 - recon_loss: 0.0015 - KL loss: 4.9442 - beta: 0.0176 - val_loss: 9.5001 - val_recon_loss: 0.0014 - val_KL loss: 5.0202 - val_beta: 0.0176\n",
      "Epoch 462/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.6034 - recon_loss: 0.0014 - KL loss: 4.9443 - beta: 0.0176 - val_loss: 9.4981 - val_recon_loss: 0.0014 - val_KL loss: 4.8738 - val_beta: 0.0176\n",
      "Epoch 463/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.6392 - recon_loss: 0.0015 - KL loss: 4.9521 - beta: 0.0176 - val_loss: 9.6718 - val_recon_loss: 0.0015 - val_KL loss: 4.8976 - val_beta: 0.0176\n",
      "Epoch 464/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.6497 - recon_loss: 0.0015 - KL loss: 4.9410 - beta: 0.0176 - val_loss: 9.6721 - val_recon_loss: 0.0015 - val_KL loss: 4.8887 - val_beta: 0.0176\n",
      "Epoch 465/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.6370 - recon_loss: 0.0015 - KL loss: 4.9402 - beta: 0.0176\n",
      "Epoch 00465: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.6369 - recon_loss: 0.0015 - KL loss: 4.9402 - beta: 0.0176 - val_loss: 9.7311 - val_recon_loss: 0.0015 - val_KL loss: 4.9116 - val_beta: 0.0176\n",
      "Epoch 465/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.4649 - recon_loss: 0.0013 - KL loss: 6.0359 - beta: 0.0117 - val_loss: 15.7713 - val_recon_loss: 0.0013 - val_KL loss: 6.1873 - val_beta: 0.0117\n",
      "Epoch 466/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.3397 - recon_loss: 0.0013 - KL loss: 6.1363 - beta: 0.0117 - val_loss: 14.8605 - val_recon_loss: 0.0012 - val_KL loss: 6.0886 - val_beta: 0.0117\n",
      "Epoch 467/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.1036 - recon_loss: 0.0012 - KL loss: 6.1279 - beta: 0.0117 - val_loss: 14.6802 - val_recon_loss: 0.0012 - val_KL loss: 6.0910 - val_beta: 0.0117\n",
      "Epoch 468/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.0541 - recon_loss: 0.0012 - KL loss: 6.1583 - beta: 0.0117 - val_loss: 15.1294 - val_recon_loss: 0.0012 - val_KL loss: 6.1306 - val_beta: 0.0117\n",
      "Epoch 469/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.1237 - recon_loss: 0.0012 - KL loss: 6.1773 - beta: 0.0117 - val_loss: 15.5971 - val_recon_loss: 0.0013 - val_KL loss: 6.1240 - val_beta: 0.0117\n",
      "Epoch 470/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.0418 - recon_loss: 0.0012 - KL loss: 6.1578 - beta: 0.0117 - val_loss: 14.9118 - val_recon_loss: 0.0012 - val_KL loss: 6.2086 - val_beta: 0.0117\n",
      "Epoch 471/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.0212 - recon_loss: 0.0012 - KL loss: 6.1644 - beta: 0.0117 - val_loss: 14.6982 - val_recon_loss: 0.0012 - val_KL loss: 6.1195 - val_beta: 0.0117\n",
      "Epoch 472/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.9541 - recon_loss: 0.0012 - KL loss: 6.1726 - beta: 0.0117\n",
      "Epoch 00472: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.9541 - recon_loss: 0.0012 - KL loss: 6.1726 - beta: 0.0117 - val_loss: 14.7474 - val_recon_loss: 0.0012 - val_KL loss: 6.0824 - val_beta: 0.0117\n",
      "Epoch 473/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.7667 - recon_loss: 0.0012 - KL loss: 6.1889 - beta: 0.0117 - val_loss: 14.8194 - val_recon_loss: 0.0012 - val_KL loss: 6.1316 - val_beta: 0.0117\n",
      "Epoch 474/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.7519 - recon_loss: 0.0012 - KL loss: 6.1778 - beta: 0.0117 - val_loss: 14.5683 - val_recon_loss: 0.0011 - val_KL loss: 6.1734 - val_beta: 0.0117\n",
      "Epoch 475/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.7951 - recon_loss: 0.0012 - KL loss: 6.1906 - beta: 0.0117 - val_loss: 14.5991 - val_recon_loss: 0.0012 - val_KL loss: 6.1653 - val_beta: 0.0117\n",
      "Epoch 476/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.8216 - recon_loss: 0.0012 - KL loss: 6.1963 - beta: 0.0117 - val_loss: 14.9926 - val_recon_loss: 0.0012 - val_KL loss: 6.1208 - val_beta: 0.0117\n",
      "Epoch 477/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 14.7303 - recon_loss: 0.0012 - KL loss: 6.1977 - beta: 0.0117 - val_loss: 14.4050 - val_recon_loss: 0.0011 - val_KL loss: 6.2204 - val_beta: 0.0117\n",
      "Epoch 478/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.7415 - recon_loss: 0.0012 - KL loss: 6.2070 - beta: 0.0117 - val_loss: 14.9658 - val_recon_loss: 0.0012 - val_KL loss: 6.1606 - val_beta: 0.0117\n",
      "Epoch 479/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 14.7325 - recon_loss: 0.0012 - KL loss: 6.2073 - beta: 0.0117 - val_loss: 14.7127 - val_recon_loss: 0.0012 - val_KL loss: 6.1730 - val_beta: 0.0117\n",
      "Epoch 480/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.6624 - recon_loss: 0.0012 - KL loss: 6.2009 - beta: 0.0117 - val_loss: 14.5810 - val_recon_loss: 0.0011 - val_KL loss: 6.1887 - val_beta: 0.0117\n",
      "Epoch 481/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.7393 - recon_loss: 0.0012 - KL loss: 6.1968 - beta: 0.0117 - val_loss: 14.6506 - val_recon_loss: 0.0012 - val_KL loss: 6.1712 - val_beta: 0.0117\n",
      "Epoch 482/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.7819 - recon_loss: 0.0012 - KL loss: 6.2146 - beta: 0.0117\n",
      "Epoch 00482: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.7819 - recon_loss: 0.0012 - KL loss: 6.2146 - beta: 0.0117 - val_loss: 14.5416 - val_recon_loss: 0.0011 - val_KL loss: 6.1795 - val_beta: 0.0117\n",
      "Epoch 483/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.7271 - recon_loss: 0.0012 - KL loss: 6.2218 - beta: 0.0117 - val_loss: 14.3087 - val_recon_loss: 0.0011 - val_KL loss: 6.1743 - val_beta: 0.0117\n",
      "Epoch 484/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.7594 - recon_loss: 0.0012 - KL loss: 6.2191 - beta: 0.0117 - val_loss: 14.4889 - val_recon_loss: 0.0011 - val_KL loss: 6.1505 - val_beta: 0.0117\n",
      "Epoch 485/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 14.7532 - recon_loss: 0.0012 - KL loss: 6.2229 - beta: 0.0117 - val_loss: 14.6940 - val_recon_loss: 0.0012 - val_KL loss: 6.1383 - val_beta: 0.0117\n",
      "Epoch 486/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.7027 - recon_loss: 0.0012 - KL loss: 6.2115 - beta: 0.0117 - val_loss: 14.4298 - val_recon_loss: 0.0011 - val_KL loss: 6.1727 - val_beta: 0.0117\n",
      "Epoch 487/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.6959 - recon_loss: 0.0012 - KL loss: 6.2133 - beta: 0.0117 - val_loss: 14.2433 - val_recon_loss: 0.0011 - val_KL loss: 6.1388 - val_beta: 0.0117\n",
      "Epoch 488/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.6864 - recon_loss: 0.0012 - KL loss: 6.2198 - beta: 0.0117 - val_loss: 14.6648 - val_recon_loss: 0.0012 - val_KL loss: 6.1624 - val_beta: 0.0117\n",
      "Epoch 489/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.7084 - recon_loss: 0.0012 - KL loss: 6.2135 - beta: 0.0117 - val_loss: 14.4385 - val_recon_loss: 0.0011 - val_KL loss: 6.1677 - val_beta: 0.0117\n",
      "Epoch 490/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.7836 - recon_loss: 0.0012 - KL loss: 6.2114 - beta: 0.0117 - val_loss: 14.3989 - val_recon_loss: 0.0011 - val_KL loss: 6.1947 - val_beta: 0.0117\n",
      "Epoch 491/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.7307 - recon_loss: 0.0012 - KL loss: 6.2432 - beta: 0.0117 - val_loss: 14.2718 - val_recon_loss: 0.0011 - val_KL loss: 6.1972 - val_beta: 0.0117\n",
      "Epoch 492/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.6226 - recon_loss: 0.0011 - KL loss: 6.2315 - beta: 0.0117\n",
      "Epoch 00492: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.6226 - recon_loss: 0.0011 - KL loss: 6.2315 - beta: 0.0117 - val_loss: 14.7224 - val_recon_loss: 0.0012 - val_KL loss: 6.1726 - val_beta: 0.0117\n",
      "Epoch 493/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.6542 - recon_loss: 0.0012 - KL loss: 6.2213 - beta: 0.0117 - val_loss: 14.3464 - val_recon_loss: 0.0011 - val_KL loss: 6.1849 - val_beta: 0.0117\n",
      "Epoch 494/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.6206 - recon_loss: 0.0011 - KL loss: 6.2230 - beta: 0.0117 - val_loss: 14.6924 - val_recon_loss: 0.0012 - val_KL loss: 6.1747 - val_beta: 0.0117\n",
      "Epoch 495/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.7320 - recon_loss: 0.0012 - KL loss: 6.2233 - beta: 0.0117 - val_loss: 14.3566 - val_recon_loss: 0.0011 - val_KL loss: 6.1788 - val_beta: 0.0117\n",
      "Epoch 496/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.6076 - recon_loss: 0.0011 - KL loss: 6.2247 - beta: 0.0117 - val_loss: 14.6806 - val_recon_loss: 0.0012 - val_KL loss: 6.1933 - val_beta: 0.0117\n",
      "Epoch 497/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.6965 - recon_loss: 0.0012 - KL loss: 6.2368 - beta: 0.0117 - val_loss: 14.1360 - val_recon_loss: 0.0011 - val_KL loss: 6.2006 - val_beta: 0.0117\n",
      "Epoch 498/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.6716 - recon_loss: 0.0012 - KL loss: 6.2256 - beta: 0.0117 - val_loss: 14.3175 - val_recon_loss: 0.0011 - val_KL loss: 6.1634 - val_beta: 0.0117\n",
      "Epoch 499/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.6614 - recon_loss: 0.0012 - KL loss: 6.2143 - beta: 0.0117 - val_loss: 14.2941 - val_recon_loss: 0.0011 - val_KL loss: 6.1687 - val_beta: 0.0117\n",
      "Epoch 500/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.6193 - recon_loss: 0.0011 - KL loss: 6.2206 - beta: 0.0117 - val_loss: 14.2826 - val_recon_loss: 0.0011 - val_KL loss: 6.1794 - val_beta: 0.0117\n",
      "Epoch 501/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.7139 - recon_loss: 0.0012 - KL loss: 6.2305 - beta: 0.0117 - val_loss: 14.3136 - val_recon_loss: 0.0011 - val_KL loss: 6.1863 - val_beta: 0.0117\n",
      "Epoch 502/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.6417 - recon_loss: 0.0012 - KL loss: 6.2317 - beta: 0.0117\n",
      "Epoch 00502: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.6417 - recon_loss: 0.0012 - KL loss: 6.2317 - beta: 0.0117 - val_loss: 14.7638 - val_recon_loss: 0.0012 - val_KL loss: 6.1829 - val_beta: 0.0117\n",
      "Epoch 503/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.6521 - recon_loss: 0.0012 - KL loss: 6.2249 - beta: 0.0117 - val_loss: 14.4754 - val_recon_loss: 0.0011 - val_KL loss: 6.1754 - val_beta: 0.0117\n",
      "Epoch 504/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.6970 - recon_loss: 0.0012 - KL loss: 6.2224 - beta: 0.0117 - val_loss: 14.5020 - val_recon_loss: 0.0011 - val_KL loss: 6.1792 - val_beta: 0.0117\n",
      "Epoch 505/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14.6894 - recon_loss: 0.0012 - KL loss: 6.2287 - beta: 0.0117 - val_loss: 14.6943 - val_recon_loss: 0.0012 - val_KL loss: 6.1716 - val_beta: 0.0117\n",
      "Epoch 506/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.6801 - recon_loss: 0.0012 - KL loss: 6.2214 - beta: 0.0117 - val_loss: 14.6086 - val_recon_loss: 0.0012 - val_KL loss: 6.1853 - val_beta: 0.0117\n",
      "Epoch 507/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 14.5972 - recon_loss: 0.0011 - KL loss: 6.2287 - beta: 0.0117\n",
      "Epoch 00507: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 14.5972 - recon_loss: 0.0011 - KL loss: 6.2287 - beta: 0.0117 - val_loss: 14.5583 - val_recon_loss: 0.0011 - val_KL loss: 6.1910 - val_beta: 0.0117\n",
      "Epoch 507/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25.9784 - recon_loss: 0.0011 - KL loss: 7.3613 - beta: 0.0078 - val_loss: 24.8333 - val_recon_loss: 0.0010 - val_KL loss: 7.5026 - val_beta: 0.0078\n",
      "Epoch 508/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25.4082 - recon_loss: 0.0011 - KL loss: 7.4784 - beta: 0.0078 - val_loss: 25.1879 - val_recon_loss: 0.0011 - val_KL loss: 7.4864 - val_beta: 0.0078\n",
      "Epoch 509/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 25.4329 - recon_loss: 0.0011 - KL loss: 7.4850 - beta: 0.0078 - val_loss: 25.9612 - val_recon_loss: 0.0011 - val_KL loss: 7.6006 - val_beta: 0.0078\n",
      "Epoch 510/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.1313 - recon_loss: 0.0011 - KL loss: 7.5433 - beta: 0.0078 - val_loss: 24.6429 - val_recon_loss: 0.0010 - val_KL loss: 7.5108 - val_beta: 0.0078\n",
      "Epoch 511/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.0142 - recon_loss: 0.0011 - KL loss: 7.5429 - beta: 0.0078 - val_loss: 25.5002 - val_recon_loss: 0.0011 - val_KL loss: 7.4754 - val_beta: 0.0078\n",
      "Epoch 512/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25.5536 - recon_loss: 0.0011 - KL loss: 7.5352 - beta: 0.0078 - val_loss: 25.5102 - val_recon_loss: 0.0011 - val_KL loss: 7.4580 - val_beta: 0.0078\n",
      "Epoch 513/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.9769 - recon_loss: 0.0011 - KL loss: 7.5456 - beta: 0.0078 - val_loss: 25.3416 - val_recon_loss: 0.0011 - val_KL loss: 7.4021 - val_beta: 0.0078\n",
      "Epoch 514/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25.3028 - recon_loss: 0.0011 - KL loss: 7.5348 - beta: 0.0078 - val_loss: 25.8642 - val_recon_loss: 0.0011 - val_KL loss: 7.5971 - val_beta: 0.0078\n",
      "Epoch 515/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 25.2243 - recon_loss: 0.0011 - KL loss: 7.5440 - beta: 0.0078\n",
      "Epoch 00515: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25.2242 - recon_loss: 0.0011 - KL loss: 7.5440 - beta: 0.0078 - val_loss: 25.3060 - val_recon_loss: 0.0011 - val_KL loss: 7.5770 - val_beta: 0.0078\n",
      "Epoch 516/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.9424 - recon_loss: 0.0010 - KL loss: 7.5891 - beta: 0.0078 - val_loss: 24.4266 - val_recon_loss: 0.0010 - val_KL loss: 7.4847 - val_beta: 0.0078\n",
      "Epoch 517/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.9368 - recon_loss: 0.0010 - KL loss: 7.5947 - beta: 0.0078 - val_loss: 24.2794 - val_recon_loss: 0.0010 - val_KL loss: 7.5183 - val_beta: 0.0078\n",
      "Epoch 518/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.7677 - recon_loss: 0.0010 - KL loss: 7.5806 - beta: 0.0078 - val_loss: 24.1182 - val_recon_loss: 0.0010 - val_KL loss: 7.5009 - val_beta: 0.0078\n",
      "Epoch 519/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.6573 - recon_loss: 0.0010 - KL loss: 7.5800 - beta: 0.0078 - val_loss: 24.7065 - val_recon_loss: 0.0010 - val_KL loss: 7.5228 - val_beta: 0.0078\n",
      "Epoch 520/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.5636 - recon_loss: 0.0010 - KL loss: 7.5889 - beta: 0.0078 - val_loss: 25.3778 - val_recon_loss: 0.0011 - val_KL loss: 7.4676 - val_beta: 0.0078\n",
      "Epoch 521/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.7708 - recon_loss: 0.0010 - KL loss: 7.5774 - beta: 0.0078 - val_loss: 25.0769 - val_recon_loss: 0.0011 - val_KL loss: 7.6023 - val_beta: 0.0078\n",
      "Epoch 522/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.5844 - recon_loss: 0.0010 - KL loss: 7.5895 - beta: 0.0078 - val_loss: 25.0664 - val_recon_loss: 0.0011 - val_KL loss: 7.5237 - val_beta: 0.0078\n",
      "Epoch 523/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 24.5032 - recon_loss: 0.0010 - KL loss: 7.5813 - beta: 0.0078\n",
      "Epoch 00523: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.5032 - recon_loss: 0.0010 - KL loss: 7.5813 - beta: 0.0078 - val_loss: 24.3962 - val_recon_loss: 0.0010 - val_KL loss: 7.5492 - val_beta: 0.0078\n",
      "Epoch 524/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.6212 - recon_loss: 0.0010 - KL loss: 7.6188 - beta: 0.0078 - val_loss: 24.2367 - val_recon_loss: 0.0010 - val_KL loss: 7.5208 - val_beta: 0.0078\n",
      "Epoch 525/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.5789 - recon_loss: 0.0010 - KL loss: 7.6027 - beta: 0.0078 - val_loss: 24.4493 - val_recon_loss: 0.0010 - val_KL loss: 7.5327 - val_beta: 0.0078\n",
      "Epoch 526/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.3895 - recon_loss: 0.0010 - KL loss: 7.6067 - beta: 0.0078 - val_loss: 24.3923 - val_recon_loss: 0.0010 - val_KL loss: 7.4993 - val_beta: 0.0078\n",
      "Epoch 527/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.6399 - recon_loss: 0.0010 - KL loss: 7.6081 - beta: 0.0078 - val_loss: 24.2261 - val_recon_loss: 0.0010 - val_KL loss: 7.5550 - val_beta: 0.0078\n",
      "Epoch 528/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.5286 - recon_loss: 0.0010 - KL loss: 7.5934 - beta: 0.0078 - val_loss: 24.0679 - val_recon_loss: 9.9713e-04 - val_KL loss: 7.5222 - val_beta: 0.0078\n",
      "Epoch 529/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.5440 - recon_loss: 0.0010 - KL loss: 7.5947 - beta: 0.0078 - val_loss: 24.7416 - val_recon_loss: 0.0010 - val_KL loss: 7.5700 - val_beta: 0.0078\n",
      "Epoch 530/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.4642 - recon_loss: 0.0010 - KL loss: 7.6128 - beta: 0.0078 - val_loss: 24.3076 - val_recon_loss: 0.0010 - val_KL loss: 7.5181 - val_beta: 0.0078\n",
      "Epoch 531/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.4093 - recon_loss: 0.0010 - KL loss: 7.5964 - beta: 0.0078 - val_loss: 24.2109 - val_recon_loss: 0.0010 - val_KL loss: 7.5394 - val_beta: 0.0078\n",
      "Epoch 532/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.4477 - recon_loss: 0.0010 - KL loss: 7.6063 - beta: 0.0078 - val_loss: 24.0636 - val_recon_loss: 9.9552e-04 - val_KL loss: 7.5447 - val_beta: 0.0078\n",
      "Epoch 533/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.4414 - recon_loss: 0.0010 - KL loss: 7.6121 - beta: 0.0078 - val_loss: 24.5264 - val_recon_loss: 0.0010 - val_KL loss: 7.5453 - val_beta: 0.0078\n",
      "Epoch 534/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.4876 - recon_loss: 0.0010 - KL loss: 7.6068 - beta: 0.0078 - val_loss: 24.2796 - val_recon_loss: 0.0010 - val_KL loss: 7.5837 - val_beta: 0.0078\n",
      "Epoch 535/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.6202 - recon_loss: 0.0010 - KL loss: 7.6225 - beta: 0.0078 - val_loss: 24.2652 - val_recon_loss: 0.0010 - val_KL loss: 7.5738 - val_beta: 0.0078\n",
      "Epoch 536/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.6319 - recon_loss: 0.0010 - KL loss: 7.6296 - beta: 0.0078 - val_loss: 24.5510 - val_recon_loss: 0.0010 - val_KL loss: 7.5242 - val_beta: 0.0078\n",
      "Epoch 537/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 24.7465 - recon_loss: 0.0010 - KL loss: 7.6160 - beta: 0.0078\n",
      "Epoch 00537: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 24.7463 - recon_loss: 0.0010 - KL loss: 7.6160 - beta: 0.0078 - val_loss: 24.2607 - val_recon_loss: 0.0010 - val_KL loss: 7.5067 - val_beta: 0.0078\n",
      "Epoch 538/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.4275 - recon_loss: 0.0010 - KL loss: 7.6100 - beta: 0.0078 - val_loss: 24.2322 - val_recon_loss: 0.0010 - val_KL loss: 7.5558 - val_beta: 0.0078\n",
      "Epoch 539/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.5686 - recon_loss: 0.0010 - KL loss: 7.6257 - beta: 0.0078 - val_loss: 24.1396 - val_recon_loss: 9.9952e-04 - val_KL loss: 7.5542 - val_beta: 0.0078\n",
      "Epoch 540/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.5892 - recon_loss: 0.0010 - KL loss: 7.6231 - beta: 0.0078 - val_loss: 24.2555 - val_recon_loss: 0.0010 - val_KL loss: 7.5533 - val_beta: 0.0078\n",
      "Epoch 541/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.5605 - recon_loss: 0.0010 - KL loss: 7.6259 - beta: 0.0078 - val_loss: 24.3578 - val_recon_loss: 0.0010 - val_KL loss: 7.5318 - val_beta: 0.0078\n",
      "Epoch 542/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 24.4862 - recon_loss: 0.0010 - KL loss: 7.6204 - beta: 0.0078\n",
      "Epoch 00542: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.4863 - recon_loss: 0.0010 - KL loss: 7.6204 - beta: 0.0078 - val_loss: 24.3054 - val_recon_loss: 0.0010 - val_KL loss: 7.5397 - val_beta: 0.0078\n",
      "Epoch 542/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 46.9681 - recon_loss: 0.0010 - KL loss: 8.7577 - beta: 0.0052 - val_loss: 49.3504 - val_recon_loss: 0.0011 - val_KL loss: 9.2524 - val_beta: 0.0052\n",
      "Epoch 543/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 47.1432 - recon_loss: 0.0010 - KL loss: 8.9435 - beta: 0.0052 - val_loss: 45.9369 - val_recon_loss: 9.8098e-04 - val_KL loss: 8.9877 - val_beta: 0.0052\n",
      "Epoch 544/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 47.0426 - recon_loss: 0.0010 - KL loss: 8.9971 - beta: 0.0052 - val_loss: 45.9727 - val_recon_loss: 9.8273e-04 - val_KL loss: 8.9574 - val_beta: 0.0052\n",
      "Epoch 545/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 46.2981 - recon_loss: 9.9051e-04 - KL loss: 8.9897 - beta: 0.0052 - val_loss: 45.4114 - val_recon_loss: 9.6431e-04 - val_KL loss: 9.0901 - val_beta: 0.0052\n",
      "Epoch 546/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 45.7995 - recon_loss: 9.7650e-04 - KL loss: 9.0188 - beta: 0.0052 - val_loss: 45.1378 - val_recon_loss: 9.6138e-04 - val_KL loss: 8.9266 - val_beta: 0.0052\n",
      "Epoch 547/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 46.1725 - recon_loss: 9.8660e-04 - KL loss: 9.0114 - beta: 0.0052 - val_loss: 45.8580 - val_recon_loss: 9.7685e-04 - val_KL loss: 9.0641 - val_beta: 0.0052\n",
      "Epoch 548/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 46.0134 - recon_loss: 9.8215e-04 - KL loss: 9.0199 - beta: 0.0052 - val_loss: 45.0949 - val_recon_loss: 9.5734e-04 - val_KL loss: 9.0358 - val_beta: 0.0052\n",
      "Epoch 549/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 46.0407 - recon_loss: 9.8213e-04 - KL loss: 9.0479 - beta: 0.0052 - val_loss: 47.1650 - val_recon_loss: 0.0010 - val_KL loss: 8.9321 - val_beta: 0.0052\n",
      "Epoch 550/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 46.5178 - recon_loss: 9.9513e-04 - KL loss: 9.0354 - beta: 0.0052 - val_loss: 46.3446 - val_recon_loss: 9.9356e-04 - val_KL loss: 8.9215 - val_beta: 0.0052\n",
      "Epoch 551/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 46.2143 - recon_loss: 9.8637e-04 - KL loss: 9.0618 - beta: 0.0052 - val_loss: 45.4725 - val_recon_loss: 9.7002e-04 - val_KL loss: 8.9361 - val_beta: 0.0052\n",
      "Epoch 552/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 47.2828 - recon_loss: 0.0010 - KL loss: 9.0908 - beta: 0.0052 - val_loss: 49.0488 - val_recon_loss: 0.0011 - val_KL loss: 8.9535 - val_beta: 0.0052\n",
      "Epoch 553/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 46.3583 - recon_loss: 9.8882e-04 - KL loss: 9.1135 - beta: 0.0052\n",
      "Epoch 00553: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 46.3583 - recon_loss: 9.8882e-04 - KL loss: 9.1135 - beta: 0.0052 - val_loss: 46.4468 - val_recon_loss: 9.9603e-04 - val_KL loss: 8.9306 - val_beta: 0.0052\n",
      "Epoch 554/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 46.0892 - recon_loss: 9.8133e-04 - KL loss: 9.1267 - beta: 0.0052 - val_loss: 46.3061 - val_recon_loss: 9.8979e-04 - val_KL loss: 9.0248 - val_beta: 0.0052\n",
      "Epoch 555/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 45.4488 - recon_loss: 9.6344e-04 - KL loss: 9.1601 - beta: 0.0052 - val_loss: 46.7747 - val_recon_loss: 0.0010 - val_KL loss: 9.0889 - val_beta: 0.0052\n",
      "Epoch 556/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 45.0638 - recon_loss: 9.5354e-04 - KL loss: 9.1481 - beta: 0.0052 - val_loss: 46.2373 - val_recon_loss: 9.8418e-04 - val_KL loss: 9.1674 - val_beta: 0.0052\n",
      "Epoch 557/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.7412 - recon_loss: 9.4460e-04 - KL loss: 9.1623 - beta: 0.0052 - val_loss: 45.9024 - val_recon_loss: 9.7837e-04 - val_KL loss: 9.0515 - val_beta: 0.0052\n",
      "Epoch 558/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 45.2625 - recon_loss: 9.5873e-04 - KL loss: 9.1512 - beta: 0.0052 - val_loss: 44.6160 - val_recon_loss: 9.4293e-04 - val_KL loss: 9.0996 - val_beta: 0.0052\n",
      "Epoch 559/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.8936 - recon_loss: 9.4856e-04 - KL loss: 9.1654 - beta: 0.0052 - val_loss: 45.7270 - val_recon_loss: 9.7054e-04 - val_KL loss: 9.1709 - val_beta: 0.0052\n",
      "Epoch 560/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.9764 - recon_loss: 9.5089e-04 - KL loss: 9.1604 - beta: 0.0052 - val_loss: 44.8876 - val_recon_loss: 9.5016e-04 - val_KL loss: 9.0992 - val_beta: 0.0052\n",
      "Epoch 561/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 45.0242 - recon_loss: 9.5235e-04 - KL loss: 9.1533 - beta: 0.0052 - val_loss: 44.2190 - val_recon_loss: 9.3474e-04 - val_KL loss: 9.0111 - val_beta: 0.0052\n",
      "Epoch 562/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.8299 - recon_loss: 9.4690e-04 - KL loss: 9.1643 - beta: 0.0052 - val_loss: 44.5739 - val_recon_loss: 9.4329e-04 - val_KL loss: 9.0440 - val_beta: 0.0052\n",
      "Epoch 563/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 45.1573 - recon_loss: 9.5554e-04 - KL loss: 9.1662 - beta: 0.0052 - val_loss: 44.4891 - val_recon_loss: 9.3973e-04 - val_KL loss: 9.0936 - val_beta: 0.0052\n",
      "Epoch 564/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 45.8573 - recon_loss: 9.7345e-04 - KL loss: 9.1916 - beta: 0.0052 - val_loss: 44.8126 - val_recon_loss: 9.4950e-04 - val_KL loss: 9.0489 - val_beta: 0.0052\n",
      "Epoch 565/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 45.4537 - recon_loss: 9.6294e-04 - KL loss: 9.1838 - beta: 0.0052 - val_loss: 44.7917 - val_recon_loss: 9.4710e-04 - val_KL loss: 9.1183 - val_beta: 0.0052\n",
      "Epoch 566/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 44.9449 - recon_loss: 9.4890e-04 - KL loss: 9.2038 - beta: 0.0052\n",
      "Epoch 00566: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.9449 - recon_loss: 9.4890e-04 - KL loss: 9.2038 - beta: 0.0052 - val_loss: 44.9598 - val_recon_loss: 9.5154e-04 - val_KL loss: 9.1194 - val_beta: 0.0052\n",
      "Epoch 567/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.6938 - recon_loss: 9.4268e-04 - KL loss: 9.1870 - beta: 0.0052 - val_loss: 44.2794 - val_recon_loss: 9.3358e-04 - val_KL loss: 9.1153 - val_beta: 0.0052\n",
      "Epoch 568/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.4587 - recon_loss: 9.3608e-04 - KL loss: 9.2006 - beta: 0.0052 - val_loss: 44.5261 - val_recon_loss: 9.3967e-04 - val_KL loss: 9.1326 - val_beta: 0.0052\n",
      "Epoch 569/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.4426 - recon_loss: 9.3536e-04 - KL loss: 9.2114 - beta: 0.0052 - val_loss: 44.0561 - val_recon_loss: 9.2690e-04 - val_KL loss: 9.1437 - val_beta: 0.0052\n",
      "Epoch 570/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.3752 - recon_loss: 9.3369e-04 - KL loss: 9.2071 - beta: 0.0052 - val_loss: 44.1129 - val_recon_loss: 9.2824e-04 - val_KL loss: 9.1499 - val_beta: 0.0052\n",
      "Epoch 571/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.5645 - recon_loss: 9.3855e-04 - KL loss: 9.2131 - beta: 0.0052 - val_loss: 43.5876 - val_recon_loss: 9.1504e-04 - val_KL loss: 9.1220 - val_beta: 0.0052\n",
      "Epoch 572/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.6758 - recon_loss: 9.4188e-04 - KL loss: 9.1990 - beta: 0.0052 - val_loss: 43.6691 - val_recon_loss: 9.1798e-04 - val_KL loss: 9.0927 - val_beta: 0.0052\n",
      "Epoch 573/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.2485 - recon_loss: 9.3060e-04 - KL loss: 9.1968 - beta: 0.0052 - val_loss: 43.7065 - val_recon_loss: 9.1948e-04 - val_KL loss: 9.0737 - val_beta: 0.0052\n",
      "Epoch 574/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.5674 - recon_loss: 9.3921e-04 - KL loss: 9.1912 - beta: 0.0052 - val_loss: 44.0560 - val_recon_loss: 9.2669e-04 - val_KL loss: 9.1515 - val_beta: 0.0052\n",
      "Epoch 575/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.5661 - recon_loss: 9.3788e-04 - KL loss: 9.2401 - beta: 0.0052 - val_loss: 43.9010 - val_recon_loss: 9.2329e-04 - val_KL loss: 9.1247 - val_beta: 0.0052\n",
      "Epoch 576/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 44.5727 - recon_loss: 9.3876e-04 - KL loss: 9.2136 - beta: 0.0052\n",
      "Epoch 00576: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.5732 - recon_loss: 9.3877e-04 - KL loss: 9.2136 - beta: 0.0052 - val_loss: 43.6753 - val_recon_loss: 9.1780e-04 - val_KL loss: 9.1058 - val_beta: 0.0052\n",
      "Epoch 577/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.8171 - recon_loss: 9.4483e-04 - KL loss: 9.2293 - beta: 0.0052 - val_loss: 43.6732 - val_recon_loss: 9.1720e-04 - val_KL loss: 9.1260 - val_beta: 0.0052\n",
      "Epoch 578/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.6870 - recon_loss: 9.4128e-04 - KL loss: 9.2328 - beta: 0.0052 - val_loss: 43.7184 - val_recon_loss: 9.1789e-04 - val_KL loss: 9.1455 - val_beta: 0.0052\n",
      "Epoch 579/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.2767 - recon_loss: 9.3007e-04 - KL loss: 9.2450 - beta: 0.0052 - val_loss: 43.9480 - val_recon_loss: 9.2387e-04 - val_KL loss: 9.1498 - val_beta: 0.0052\n",
      "Epoch 580/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.5401 - recon_loss: 9.3715e-04 - KL loss: 9.2416 - beta: 0.0052 - val_loss: 43.8559 - val_recon_loss: 9.2200e-04 - val_KL loss: 9.1282 - val_beta: 0.0052\n",
      "Epoch 581/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.8989 - recon_loss: 9.4682e-04 - KL loss: 9.2364 - beta: 0.0052 - val_loss: 43.5381 - val_recon_loss: 9.1292e-04 - val_KL loss: 9.1522 - val_beta: 0.0052\n",
      "Epoch 582/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.4509 - recon_loss: 9.3439e-04 - KL loss: 9.2565 - beta: 0.0052 - val_loss: 43.7831 - val_recon_loss: 9.1964e-04 - val_KL loss: 9.1442 - val_beta: 0.0052\n",
      "Epoch 583/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.7778 - recon_loss: 9.4341e-04 - KL loss: 9.2435 - beta: 0.0052 - val_loss: 43.2815 - val_recon_loss: 9.0611e-04 - val_KL loss: 9.1522 - val_beta: 0.0052\n",
      "Epoch 584/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.4987 - recon_loss: 9.3600e-04 - KL loss: 9.2435 - beta: 0.0052 - val_loss: 43.5626 - val_recon_loss: 9.1399e-04 - val_KL loss: 9.1364 - val_beta: 0.0052\n",
      "Epoch 585/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.4054 - recon_loss: 9.3368e-04 - KL loss: 9.2375 - beta: 0.0052 - val_loss: 43.7091 - val_recon_loss: 9.1799e-04 - val_KL loss: 9.1322 - val_beta: 0.0052\n",
      "Epoch 586/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.7147 - recon_loss: 9.4191e-04 - KL loss: 9.2369 - beta: 0.0052 - val_loss: 43.5590 - val_recon_loss: 9.1418e-04 - val_KL loss: 9.1257 - val_beta: 0.0052\n",
      "Epoch 587/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.8501 - recon_loss: 9.4555e-04 - KL loss: 9.2352 - beta: 0.0052 - val_loss: 43.7688 - val_recon_loss: 9.1932e-04 - val_KL loss: 9.1418 - val_beta: 0.0052\n",
      "Epoch 588/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 44.3546 - recon_loss: 9.3233e-04 - KL loss: 9.2377 - beta: 0.0052\n",
      "Epoch 00588: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.3549 - recon_loss: 9.3234e-04 - KL loss: 9.2377 - beta: 0.0052 - val_loss: 43.3994 - val_recon_loss: 9.0983e-04 - val_KL loss: 9.1301 - val_beta: 0.0052\n",
      "Epoch 589/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 44.5112 - recon_loss: 9.3667e-04 - KL loss: 9.2309 - beta: 0.0052 - val_loss: 44.2008 - val_recon_loss: 9.3097e-04 - val_KL loss: 9.1351 - val_beta: 0.0052\n",
      "Epoch 590/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.3563 - recon_loss: 9.3251e-04 - KL loss: 9.2324 - beta: 0.0052 - val_loss: 43.8196 - val_recon_loss: 9.2059e-04 - val_KL loss: 9.1450 - val_beta: 0.0052\n",
      "Epoch 591/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.4594 - recon_loss: 9.3496e-04 - KL loss: 9.2435 - beta: 0.0052 - val_loss: 43.9586 - val_recon_loss: 9.2444e-04 - val_KL loss: 9.1388 - val_beta: 0.0052\n",
      "Epoch 592/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.4754 - recon_loss: 9.3571e-04 - KL loss: 9.2311 - beta: 0.0052 - val_loss: 43.6395 - val_recon_loss: 9.1603e-04 - val_KL loss: 9.1366 - val_beta: 0.0052\n",
      "Epoch 593/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 44.4716 - recon_loss: 9.3555e-04 - KL loss: 9.2334 - beta: 0.0052\n",
      "Epoch 00593: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.4715 - recon_loss: 9.3555e-04 - KL loss: 9.2334 - beta: 0.0052 - val_loss: 44.0472 - val_recon_loss: 9.2675e-04 - val_KL loss: 9.1404 - val_beta: 0.0052\n",
      "Epoch 593/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 92.7877 - recon_loss: 9.6503e-04 - KL loss: 10.2786 - beta: 0.0034 - val_loss: 90.9809 - val_recon_loss: 9.4233e-04 - val_KL loss: 10.4124 - val_beta: 0.0034\n",
      "Epoch 594/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 90.8435 - recon_loss: 9.3977e-04 - KL loss: 10.4943 - beta: 0.0034 - val_loss: 90.2066 - val_recon_loss: 9.3429e-04 - val_KL loss: 10.3262 - val_beta: 0.0034\n",
      "Epoch 595/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 91.4535 - recon_loss: 9.4652e-04 - KL loss: 10.5271 - beta: 0.0034 - val_loss: 89.8660 - val_recon_loss: 9.2743e-04 - val_KL loss: 10.5720 - val_beta: 0.0034\n",
      "Epoch 596/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 90.2471 - recon_loss: 9.3221e-04 - KL loss: 10.5443 - beta: 0.0034 - val_loss: 89.3569 - val_recon_loss: 9.2201e-04 - val_KL loss: 10.5261 - val_beta: 0.0034\n",
      "Epoch 597/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 89.7420 - recon_loss: 9.2603e-04 - KL loss: 10.5679 - beta: 0.0034 - val_loss: 87.3966 - val_recon_loss: 8.9893e-04 - val_KL loss: 10.5392 - val_beta: 0.0034\n",
      "Epoch 598/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 89.8395 - recon_loss: 9.2608e-04 - KL loss: 10.6608 - beta: 0.0034 - val_loss: 102.9410 - val_recon_loss: 0.0011 - val_KL loss: 10.5407 - val_beta: 0.0034\n",
      "Epoch 599/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 89.0651 - recon_loss: 9.1636e-04 - KL loss: 10.7171 - beta: 0.0034 - val_loss: 90.8882 - val_recon_loss: 9.3869e-04 - val_KL loss: 10.6312 - val_beta: 0.0034\n",
      "Epoch 600/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 88.6462 - recon_loss: 9.1038e-04 - KL loss: 10.8099 - beta: 0.0034 - val_loss: 88.1003 - val_recon_loss: 9.0212e-04 - val_KL loss: 10.9704 - val_beta: 0.0034\n",
      "Epoch 601/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 94.2089 - recon_loss: 9.7201e-04 - KL loss: 11.1029 - beta: 0.0034 - val_loss: 85.6771 - val_recon_loss: 8.7200e-04 - val_KL loss: 11.1219 - val_beta: 0.0034\n",
      "Epoch 602/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 88.2755 - recon_loss: 9.0115e-04 - KL loss: 11.2285 - beta: 0.0034 - val_loss: 89.5641 - val_recon_loss: 9.2146e-04 - val_KL loss: 10.7802 - val_beta: 0.0034\n",
      "Epoch 603/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 88.3172 - recon_loss: 8.9989e-04 - KL loss: 11.3775 - beta: 0.0034 - val_loss: 86.6881 - val_recon_loss: 8.8145e-04 - val_KL loss: 11.3253 - val_beta: 0.0034\n",
      "Epoch 604/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 87.2296 - recon_loss: 8.8420e-04 - KL loss: 11.6313 - beta: 0.0034 - val_loss: 84.5192 - val_recon_loss: 8.5416e-04 - val_KL loss: 11.4896 - val_beta: 0.0034\n",
      "Epoch 605/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 85.6956 - recon_loss: 8.6450e-04 - KL loss: 11.7819 - beta: 0.0034 - val_loss: 83.9075 - val_recon_loss: 8.4465e-04 - val_KL loss: 11.6912 - val_beta: 0.0034\n",
      "Epoch 606/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 83.5954 - recon_loss: 8.3779e-04 - KL loss: 11.9654 - beta: 0.0034 - val_loss: 85.4488 - val_recon_loss: 8.6219e-04 - val_KL loss: 11.7329 - val_beta: 0.0034\n",
      "Epoch 607/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 82.9789 - recon_loss: 8.2855e-04 - KL loss: 12.1386 - beta: 0.0034 - val_loss: 85.1732 - val_recon_loss: 8.5674e-04 - val_KL loss: 11.9228 - val_beta: 0.0034\n",
      "Epoch 608/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 82.8536 - recon_loss: 8.2510e-04 - KL loss: 12.3086 - beta: 0.0034 - val_loss: 85.9250 - val_recon_loss: 8.6493e-04 - val_KL loss: 11.9749 - val_beta: 0.0034\n",
      "Epoch 609/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 87.8163 - recon_loss: 8.8065e-04 - KL loss: 12.5217 - beta: 0.0034 - val_loss: 84.1000 - val_recon_loss: 8.3857e-04 - val_KL loss: 12.4033 - val_beta: 0.0034\n",
      "Epoch 610/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 82.5301 - recon_loss: 8.1832e-04 - KL loss: 12.5650 - beta: 0.0034\n",
      "Epoch 00610: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 82.5314 - recon_loss: 8.1833e-04 - KL loss: 12.5651 - beta: 0.0034 - val_loss: 85.0483 - val_recon_loss: 8.5316e-04 - val_KL loss: 12.1040 - val_beta: 0.0034\n",
      "Epoch 611/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 83.7866 - recon_loss: 8.3142e-04 - KL loss: 12.7010 - beta: 0.0034 - val_loss: 81.9485 - val_recon_loss: 8.0998e-04 - val_KL loss: 12.6966 - val_beta: 0.0034\n",
      "Epoch 612/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 80.7949 - recon_loss: 7.9518e-04 - KL loss: 12.8084 - beta: 0.0034 - val_loss: 80.7454 - val_recon_loss: 7.9397e-04 - val_KL loss: 12.8623 - val_beta: 0.0034\n",
      "Epoch 613/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 80.6267 - recon_loss: 7.9201e-04 - KL loss: 12.9106 - beta: 0.0034 - val_loss: 80.2108 - val_recon_loss: 7.8847e-04 - val_KL loss: 12.7977 - val_beta: 0.0034\n",
      "Epoch 614/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 79.2626 - recon_loss: 7.7536e-04 - KL loss: 12.9706 - beta: 0.0034 - val_loss: 80.6427 - val_recon_loss: 7.9273e-04 - val_KL loss: 12.8653 - val_beta: 0.0034\n",
      "Epoch 615/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 79.5464 - recon_loss: 7.7774e-04 - KL loss: 13.0502 - beta: 0.0034 - val_loss: 80.2205 - val_recon_loss: 7.8599e-04 - val_KL loss: 13.0189 - val_beta: 0.0034\n",
      "Epoch 616/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 78.4278 - recon_loss: 7.6324e-04 - KL loss: 13.1719 - beta: 0.0034 - val_loss: 80.5922 - val_recon_loss: 7.8730e-04 - val_KL loss: 13.2788 - val_beta: 0.0034\n",
      "Epoch 617/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 78.2002 - recon_loss: 7.5951e-04 - KL loss: 13.2632 - beta: 0.0034 - val_loss: 78.1406 - val_recon_loss: 7.5830e-04 - val_KL loss: 13.3065 - val_beta: 0.0034\n",
      "Epoch 618/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 78.1275 - recon_loss: 7.5712e-04 - KL loss: 13.3949 - beta: 0.0034 - val_loss: 78.5284 - val_recon_loss: 7.5836e-04 - val_KL loss: 13.6896 - val_beta: 0.0034\n",
      "Epoch 619/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 77.5315 - recon_loss: 7.4907e-04 - KL loss: 13.4874 - beta: 0.0034 - val_loss: 76.3799 - val_recon_loss: 7.3463e-04 - val_KL loss: 13.5702 - val_beta: 0.0034\n",
      "Epoch 620/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 76.1009 - recon_loss: 7.3122e-04 - KL loss: 13.5824 - beta: 0.0034 - val_loss: 76.6180 - val_recon_loss: 7.3704e-04 - val_KL loss: 13.6016 - val_beta: 0.0034\n",
      "Epoch 621/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 77.2961 - recon_loss: 7.4362e-04 - KL loss: 13.7173 - beta: 0.0034 - val_loss: 75.0000 - val_recon_loss: 7.1591e-04 - val_KL loss: 13.7903 - val_beta: 0.0034\n",
      "Epoch 622/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 76.2966 - recon_loss: 7.3097e-04 - KL loss: 13.7997 - beta: 0.0034 - val_loss: 76.7186 - val_recon_loss: 7.3353e-04 - val_KL loss: 14.0026 - val_beta: 0.0034\n",
      "Epoch 623/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 76.2725 - recon_loss: 7.3010e-04 - KL loss: 13.8498 - beta: 0.0034 - val_loss: 77.5739 - val_recon_loss: 7.4230e-04 - val_KL loss: 14.1079 - val_beta: 0.0034\n",
      "Epoch 624/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 76.0496 - recon_loss: 7.2550e-04 - KL loss: 14.0198 - beta: 0.0034 - val_loss: 75.7976 - val_recon_loss: 7.1776e-04 - val_KL loss: 14.4298 - val_beta: 0.0034\n",
      "Epoch 625/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 78.2820 - recon_loss: 7.4805e-04 - KL loss: 14.3243 - beta: 0.0034 - val_loss: 76.5694 - val_recon_loss: 7.2857e-04 - val_KL loss: 14.2776 - val_beta: 0.0034\n",
      "Epoch 626/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 74.7248 - recon_loss: 7.0921e-04 - KL loss: 14.0878 - beta: 0.0034 - val_loss: 71.4253 - val_recon_loss: 6.6668e-04 - val_KL loss: 14.4247 - val_beta: 0.0034\n",
      "Epoch 627/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 73.2907 - recon_loss: 6.9108e-04 - KL loss: 14.2046 - beta: 0.0034 - val_loss: 75.4591 - val_recon_loss: 7.0876e-04 - val_KL loss: 14.8611 - val_beta: 0.0034\n",
      "Epoch 628/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 74.9521 - recon_loss: 7.0728e-04 - KL loss: 14.4803 - beta: 0.0034 - val_loss: 71.9696 - val_recon_loss: 6.7230e-04 - val_KL loss: 14.4885 - val_beta: 0.0034\n",
      "Epoch 629/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 73.3135 - recon_loss: 6.8875e-04 - KL loss: 14.4262 - beta: 0.0034 - val_loss: 74.3073 - val_recon_loss: 6.9334e-04 - val_KL loss: 15.0274 - val_beta: 0.0034\n",
      "Epoch 630/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 76.1894 - recon_loss: 7.1821e-04 - KL loss: 14.7830 - beta: 0.0034 - val_loss: 77.3301 - val_recon_loss: 7.3098e-04 - val_KL loss: 14.8326 - val_beta: 0.0034\n",
      "Epoch 631/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 73.8469 - recon_loss: 6.9197e-04 - KL loss: 14.6845 - beta: 0.0034\n",
      "Epoch 00631: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 73.8466 - recon_loss: 6.9196e-04 - KL loss: 14.6846 - beta: 0.0034 - val_loss: 74.1162 - val_recon_loss: 6.9032e-04 - val_KL loss: 15.0946 - val_beta: 0.0034\n",
      "Epoch 632/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 73.0255 - recon_loss: 6.8038e-04 - KL loss: 14.8540 - beta: 0.0034 - val_loss: 77.3320 - val_recon_loss: 7.2796e-04 - val_KL loss: 15.0924 - val_beta: 0.0034\n",
      "Epoch 633/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 72.1072 - recon_loss: 6.6911e-04 - KL loss: 14.8989 - beta: 0.0034 - val_loss: 71.0439 - val_recon_loss: 6.5414e-04 - val_KL loss: 15.1158 - val_beta: 0.0034\n",
      "Epoch 634/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 72.1345 - recon_loss: 6.6917e-04 - KL loss: 14.9208 - beta: 0.0034 - val_loss: 71.3336 - val_recon_loss: 6.5776e-04 - val_KL loss: 15.0959 - val_beta: 0.0034\n",
      "Epoch 635/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 72.0038 - recon_loss: 6.6809e-04 - KL loss: 14.8829 - beta: 0.0034 - val_loss: 71.0533 - val_recon_loss: 6.5351e-04 - val_KL loss: 15.1788 - val_beta: 0.0034\n",
      "Epoch 636/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 71.1541 - recon_loss: 6.5839e-04 - KL loss: 14.8627 - beta: 0.0034 - val_loss: 70.1518 - val_recon_loss: 6.4310e-04 - val_KL loss: 15.1675 - val_beta: 0.0034\n",
      "Epoch 637/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 71.6596 - recon_loss: 6.6383e-04 - KL loss: 14.9033 - beta: 0.0034 - val_loss: 69.6533 - val_recon_loss: 6.3934e-04 - val_KL loss: 14.9902 - val_beta: 0.0034\n",
      "Epoch 638/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 70.6545 - recon_loss: 6.5222e-04 - KL loss: 14.8905 - beta: 0.0034 - val_loss: 75.8452 - val_recon_loss: 7.1047e-04 - val_KL loss: 15.1005 - val_beta: 0.0034\n",
      "Epoch 639/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 70.9477 - recon_loss: 6.5501e-04 - KL loss: 14.9450 - beta: 0.0034 - val_loss: 71.3962 - val_recon_loss: 6.5699e-04 - val_KL loss: 15.2241 - val_beta: 0.0034\n",
      "Epoch 640/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 71.0009 - recon_loss: 6.5427e-04 - KL loss: 15.0616 - beta: 0.0034 - val_loss: 70.2476 - val_recon_loss: 6.4126e-04 - val_KL loss: 15.4210 - val_beta: 0.0034\n",
      "Epoch 641/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 70.4074 - recon_loss: 6.4685e-04 - KL loss: 15.1027 - beta: 0.0034 - val_loss: 70.1140 - val_recon_loss: 6.4228e-04 - val_KL loss: 15.1996 - val_beta: 0.0034\n",
      "Epoch 642/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 70.1931 - recon_loss: 6.4524e-04 - KL loss: 15.0256 - beta: 0.0034\n",
      "Epoch 00642: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 70.1930 - recon_loss: 6.4524e-04 - KL loss: 15.0256 - beta: 0.0034 - val_loss: 82.7526 - val_recon_loss: 7.9189e-04 - val_KL loss: 15.0471 - val_beta: 0.0034\n",
      "Epoch 643/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68.9469 - recon_loss: 6.3205e-04 - KL loss: 14.9072 - beta: 0.0034 - val_loss: 68.9270 - val_recon_loss: 6.2977e-04 - val_KL loss: 15.0825 - val_beta: 0.0034\n",
      "Epoch 644/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 69.0250 - recon_loss: 6.3309e-04 - KL loss: 14.8963 - beta: 0.0034 - val_loss: 68.6984 - val_recon_loss: 6.2663e-04 - val_KL loss: 15.1224 - val_beta: 0.0034\n",
      "Epoch 645/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 69.3415 - recon_loss: 6.3609e-04 - KL loss: 14.9569 - beta: 0.0034 - val_loss: 69.5555 - val_recon_loss: 6.3604e-04 - val_KL loss: 15.1749 - val_beta: 0.0034\n",
      "Epoch 646/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68.7608 - recon_loss: 6.2874e-04 - KL loss: 15.0043 - beta: 0.0034 - val_loss: 67.2126 - val_recon_loss: 6.0838e-04 - val_KL loss: 15.1964 - val_beta: 0.0034\n",
      "Epoch 647/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 69.2553 - recon_loss: 6.3423e-04 - KL loss: 15.0293 - beta: 0.0034 - val_loss: 67.9381 - val_recon_loss: 6.1684e-04 - val_KL loss: 15.1994 - val_beta: 0.0034\n",
      "Epoch 648/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 68.8211 - recon_loss: 6.2902e-04 - KL loss: 15.0410 - beta: 0.0034 - val_loss: 68.8703 - val_recon_loss: 6.2763e-04 - val_KL loss: 15.2087 - val_beta: 0.0034\n",
      "Epoch 649/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 69.1879 - recon_loss: 6.3327e-04 - KL loss: 15.0438 - beta: 0.0034 - val_loss: 68.6400 - val_recon_loss: 6.2522e-04 - val_KL loss: 15.1847 - val_beta: 0.0034\n",
      "Epoch 650/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68.4525 - recon_loss: 6.2481e-04 - KL loss: 15.0320 - beta: 0.0034 - val_loss: 69.3541 - val_recon_loss: 6.3301e-04 - val_KL loss: 15.2324 - val_beta: 0.0034\n",
      "Epoch 651/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 69.0542 - recon_loss: 6.3142e-04 - KL loss: 15.0687 - beta: 0.0034\n",
      "Epoch 00651: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 69.0541 - recon_loss: 6.3142e-04 - KL loss: 15.0687 - beta: 0.0034 - val_loss: 67.7851 - val_recon_loss: 6.1446e-04 - val_KL loss: 15.2497 - val_beta: 0.0034\n",
      "Epoch 652/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68.6371 - recon_loss: 6.2654e-04 - KL loss: 15.0683 - beta: 0.0034 - val_loss: 67.7631 - val_recon_loss: 6.1421e-04 - val_KL loss: 15.2486 - val_beta: 0.0034\n",
      "Epoch 653/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68.5635 - recon_loss: 6.2549e-04 - KL loss: 15.0853 - beta: 0.0034 - val_loss: 67.6422 - val_recon_loss: 6.1275e-04 - val_KL loss: 15.2527 - val_beta: 0.0034\n",
      "Epoch 654/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68.6049 - recon_loss: 6.2623e-04 - KL loss: 15.0631 - beta: 0.0034 - val_loss: 68.1197 - val_recon_loss: 6.1841e-04 - val_KL loss: 15.2464 - val_beta: 0.0034\n",
      "Epoch 655/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 68.6662 - recon_loss: 6.2674e-04 - KL loss: 15.0805 - beta: 0.0034 - val_loss: 67.2637 - val_recon_loss: 6.0813e-04 - val_KL loss: 15.2695 - val_beta: 0.0034\n",
      "Epoch 656/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68.7774 - recon_loss: 6.2785e-04 - KL loss: 15.0974 - beta: 0.0034 - val_loss: 66.8663 - val_recon_loss: 6.0361e-04 - val_KL loss: 15.2582 - val_beta: 0.0034\n",
      "Epoch 657/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68.7634 - recon_loss: 6.2796e-04 - KL loss: 15.0737 - beta: 0.0034 - val_loss: 68.5898 - val_recon_loss: 6.2380e-04 - val_KL loss: 15.2554 - val_beta: 0.0034\n",
      "Epoch 658/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 68.9568 - recon_loss: 6.3015e-04 - KL loss: 15.0801 - beta: 0.0034 - val_loss: 68.8610 - val_recon_loss: 6.2682e-04 - val_KL loss: 15.2688 - val_beta: 0.0034\n",
      "Epoch 659/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68.6873 - recon_loss: 6.2663e-04 - KL loss: 15.1114 - beta: 0.0034 - val_loss: 67.3384 - val_recon_loss: 6.0893e-04 - val_KL loss: 15.2757 - val_beta: 0.0034\n",
      "Epoch 660/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68.8165 - recon_loss: 6.2821e-04 - KL loss: 15.1051 - beta: 0.0034 - val_loss: 67.6923 - val_recon_loss: 6.1329e-04 - val_KL loss: 15.2567 - val_beta: 0.0034\n",
      "Epoch 661/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 68.2993 - recon_loss: 6.2190e-04 - KL loss: 15.1275 - beta: 0.0034\n",
      "Epoch 00661: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68.2992 - recon_loss: 6.2190e-04 - KL loss: 15.1274 - beta: 0.0034 - val_loss: 68.6943 - val_recon_loss: 6.2485e-04 - val_KL loss: 15.2705 - val_beta: 0.0034\n",
      "Epoch 662/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68.3399 - recon_loss: 6.2286e-04 - KL loss: 15.0863 - beta: 0.0034 - val_loss: 67.3364 - val_recon_loss: 6.0894e-04 - val_KL loss: 15.2729 - val_beta: 0.0034\n",
      "Epoch 663/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68.3255 - recon_loss: 6.2228e-04 - KL loss: 15.1213 - beta: 0.0034 - val_loss: 67.6513 - val_recon_loss: 6.1261e-04 - val_KL loss: 15.2742 - val_beta: 0.0034\n",
      "Epoch 664/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68.2025 - recon_loss: 6.2119e-04 - KL loss: 15.0912 - beta: 0.0034 - val_loss: 68.2175 - val_recon_loss: 6.1930e-04 - val_KL loss: 15.2678 - val_beta: 0.0034\n",
      "Epoch 665/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 68.7576 - recon_loss: 6.2768e-04 - KL loss: 15.0919 - beta: 0.0034 - val_loss: 66.7636 - val_recon_loss: 6.0226e-04 - val_KL loss: 15.2713 - val_beta: 0.0034\n",
      "Epoch 666/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 67.7226 - recon_loss: 6.1568e-04 - KL loss: 15.0824 - beta: 0.0034 - val_loss: 67.8368 - val_recon_loss: 6.1479e-04 - val_KL loss: 15.2734 - val_beta: 0.0034\n",
      "Epoch 667/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68.7387 - recon_loss: 6.2707e-04 - KL loss: 15.1254 - beta: 0.0034 - val_loss: 67.7129 - val_recon_loss: 6.1340e-04 - val_KL loss: 15.2682 - val_beta: 0.0034\n",
      "Epoch 668/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 68.5893 - recon_loss: 6.2565e-04 - KL loss: 15.0971 - beta: 0.0034 - val_loss: 66.9997 - val_recon_loss: 6.0502e-04 - val_KL loss: 15.2714 - val_beta: 0.0034\n",
      "Epoch 669/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68.7409 - recon_loss: 6.2717e-04 - KL loss: 15.1182 - beta: 0.0034 - val_loss: 68.0492 - val_recon_loss: 6.1727e-04 - val_KL loss: 15.2735 - val_beta: 0.0034\n",
      "Epoch 670/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 68.4010 - recon_loss: 6.2328e-04 - KL loss: 15.1112 - beta: 0.0034\n",
      "Epoch 00670: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68.4011 - recon_loss: 6.2328e-04 - KL loss: 15.1112 - beta: 0.0034 - val_loss: 67.7253 - val_recon_loss: 6.1347e-04 - val_KL loss: 15.2745 - val_beta: 0.0034\n",
      "Epoch 671/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68.0856 - recon_loss: 6.1975e-04 - KL loss: 15.0978 - beta: 0.0034 - val_loss: 68.1069 - val_recon_loss: 6.1791e-04 - val_KL loss: 15.2766 - val_beta: 0.0034\n",
      "Epoch 672/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68.5981 - recon_loss: 6.2514e-04 - KL loss: 15.1490 - beta: 0.0034 - val_loss: 67.0156 - val_recon_loss: 6.0517e-04 - val_KL loss: 15.2742 - val_beta: 0.0034\n",
      "Epoch 673/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 68.0420 - recon_loss: 6.1928e-04 - KL loss: 15.0943 - beta: 0.0034 - val_loss: 68.0119 - val_recon_loss: 6.1683e-04 - val_KL loss: 15.2738 - val_beta: 0.0034\n",
      "Epoch 674/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68.4605 - recon_loss: 6.2392e-04 - KL loss: 15.1164 - beta: 0.0034 - val_loss: 67.0382 - val_recon_loss: 6.0543e-04 - val_KL loss: 15.2745 - val_beta: 0.0034\n",
      "Epoch 675/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 68.6852 - recon_loss: 6.2660e-04 - KL loss: 15.1120 - beta: 0.0034\n",
      "Epoch 00675: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 68.6849 - recon_loss: 6.2659e-04 - KL loss: 15.1120 - beta: 0.0034 - val_loss: 67.8624 - val_recon_loss: 6.1511e-04 - val_KL loss: 15.2713 - val_beta: 0.0034\n",
      "Epoch 675/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 154.4005 - recon_loss: 7.0773e-04 - KL loss: 17.0458 - beta: 0.0023 - val_loss: 156.9417 - val_recon_loss: 7.1105e-04 - val_KL loss: 18.9441 - val_beta: 0.0023\n",
      "Epoch 676/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 139.2686 - recon_loss: 6.2517e-04 - KL loss: 17.9379 - beta: 0.0023 - val_loss: 141.6041 - val_recon_loss: 6.3476e-04 - val_KL loss: 18.4112 - val_beta: 0.0023\n",
      "Epoch 677/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 135.6956 - recon_loss: 6.0425e-04 - KL loss: 18.4244 - beta: 0.0023 - val_loss: 140.6085 - val_recon_loss: 6.2744e-04 - val_KL loss: 18.8373 - val_beta: 0.0023\n",
      "Epoch 678/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 131.7831 - recon_loss: 5.8271e-04 - KL loss: 18.6927 - beta: 0.0023 - val_loss: 132.8747 - val_recon_loss: 5.8766e-04 - val_KL loss: 18.8241 - val_beta: 0.0023\n",
      "Epoch 679/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 127.6276 - recon_loss: 5.5886e-04 - KL loss: 19.1658 - beta: 0.0023 - val_loss: 124.9588 - val_recon_loss: 5.4575e-04 - val_KL loss: 19.0424 - val_beta: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 680/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 123.1221 - recon_loss: 5.3563e-04 - KL loss: 19.1679 - beta: 0.0023 - val_loss: 121.9591 - val_recon_loss: 5.2937e-04 - val_KL loss: 19.2214 - val_beta: 0.0023\n",
      "Epoch 681/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 122.0891 - recon_loss: 5.2870e-04 - KL loss: 19.4803 - beta: 0.0023 - val_loss: 121.9406 - val_recon_loss: 5.2735e-04 - val_KL loss: 19.5948 - val_beta: 0.0023\n",
      "Epoch 682/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 122.7634 - recon_loss: 5.3192e-04 - KL loss: 19.5297 - beta: 0.0023 - val_loss: 130.7259 - val_recon_loss: 5.7380e-04 - val_KL loss: 19.3639 - val_beta: 0.0023\n",
      "Epoch 683/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 118.8278 - recon_loss: 5.1264e-04 - KL loss: 19.3355 - beta: 0.0023 - val_loss: 126.0919 - val_recon_loss: 5.5052e-04 - val_KL loss: 19.2496 - val_beta: 0.0023\n",
      "Epoch 684/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 115.4048 - recon_loss: 4.9461e-04 - KL loss: 19.4133 - beta: 0.0023 - val_loss: 121.2679 - val_recon_loss: 5.2467e-04 - val_KL loss: 19.4422 - val_beta: 0.0023\n",
      "Epoch 685/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 120.0692 - recon_loss: 5.1696e-04 - KL loss: 19.7388 - beta: 0.0023 - val_loss: 131.1468 - val_recon_loss: 5.6972e-04 - val_KL loss: 20.5767 - val_beta: 0.0023\n",
      "Epoch 686/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 123.0721 - recon_loss: 5.3147e-04 - KL loss: 19.9258 - beta: 0.0023 - val_loss: 120.9287 - val_recon_loss: 5.1730e-04 - val_KL loss: 20.5337 - val_beta: 0.0023\n",
      "Epoch 687/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 124.6564 - recon_loss: 5.3944e-04 - KL loss: 19.9645 - beta: 0.0023 - val_loss: 122.4774 - val_recon_loss: 5.2747e-04 - val_KL loss: 20.1074 - val_beta: 0.0023\n",
      "Epoch 688/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 115.1930 - recon_loss: 4.9210e-04 - KL loss: 19.6878 - beta: 0.0023 - val_loss: 123.0645 - val_recon_loss: 5.3059e-04 - val_KL loss: 20.0901 - val_beta: 0.0023\n",
      "Epoch 689/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 117.7245 - recon_loss: 5.0428e-04 - KL loss: 19.8561 - beta: 0.0023 - val_loss: 123.6100 - val_recon_loss: 5.3477e-04 - val_KL loss: 19.8237 - val_beta: 0.0023\n",
      "Epoch 690/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 115.7504 - recon_loss: 4.9506e-04 - KL loss: 19.6704 - beta: 0.0023 - val_loss: 116.1138 - val_recon_loss: 4.9461e-04 - val_KL loss: 20.1224 - val_beta: 0.0023\n",
      "Epoch 691/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 112.9950 - recon_loss: 4.8024e-04 - KL loss: 19.7915 - beta: 0.0023 - val_loss: 117.0695 - val_recon_loss: 5.0282e-04 - val_KL loss: 19.4830 - val_beta: 0.0023\n",
      "Epoch 692/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 116.7104 - recon_loss: 4.9976e-04 - KL loss: 19.7182 - beta: 0.0023 - val_loss: 119.0968 - val_recon_loss: 5.1071e-04 - val_KL loss: 19.9803 - val_beta: 0.0023\n",
      "Epoch 693/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 113.2118 - recon_loss: 4.8257e-04 - KL loss: 19.5571 - beta: 0.0023 - val_loss: 121.3035 - val_recon_loss: 5.2212e-04 - val_KL loss: 19.9720 - val_beta: 0.0023\n",
      "Epoch 694/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 115.8647 - recon_loss: 4.9712e-04 - KL loss: 19.3861 - beta: 0.0023 - val_loss: 114.2059 - val_recon_loss: 4.8789e-04 - val_KL loss: 19.5175 - val_beta: 0.0023\n",
      "Epoch 695/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 112.8106 - recon_loss: 4.8021e-04 - KL loss: 19.6125 - beta: 0.0023 - val_loss: 116.9894 - val_recon_loss: 4.9930e-04 - val_KL loss: 20.0867 - val_beta: 0.0023\n",
      "Epoch 696/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 116.0355 - recon_loss: 4.9543e-04 - KL loss: 19.8831 - beta: 0.0023 - val_loss: 108.1907 - val_recon_loss: 4.5538e-04 - val_KL loss: 19.8116 - val_beta: 0.0023\n",
      "Epoch 697/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 111.8886 - recon_loss: 4.7584e-04 - KL loss: 19.5394 - beta: 0.0023 - val_loss: 116.1729 - val_recon_loss: 4.9373e-04 - val_KL loss: 20.3515 - val_beta: 0.0023\n",
      "Epoch 698/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 108.6120 - recon_loss: 4.5907e-04 - KL loss: 19.5179 - beta: 0.0023 - val_loss: 117.4522 - val_recon_loss: 5.0564e-04 - val_KL loss: 19.3199 - val_beta: 0.0023\n",
      "Epoch 699/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 109.9499 - recon_loss: 4.6571e-04 - KL loss: 19.5666 - beta: 0.0023 - val_loss: 115.4896 - val_recon_loss: 4.9286e-04 - val_KL loss: 19.8374 - val_beta: 0.0023\n",
      "Epoch 700/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 109.9144 - recon_loss: 4.6477e-04 - KL loss: 19.7126 - beta: 0.0023 - val_loss: 118.4558 - val_recon_loss: 5.0866e-04 - val_KL loss: 19.7374 - val_beta: 0.0023\n",
      "Epoch 701/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 113.1200 - recon_loss: 4.8117e-04 - KL loss: 19.7357 - beta: 0.0023\n",
      "Epoch 00701: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 113.1178 - recon_loss: 4.8116e-04 - KL loss: 19.7357 - beta: 0.0023 - val_loss: 110.6365 - val_recon_loss: 4.6982e-04 - val_KL loss: 19.4555 - val_beta: 0.0023\n",
      "Epoch 702/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 103.8254 - recon_loss: 4.3323e-04 - KL loss: 19.7460 - beta: 0.0023 - val_loss: 105.2908 - val_recon_loss: 4.4039e-04 - val_KL loss: 19.8223 - val_beta: 0.0023\n",
      "Epoch 703/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 101.5804 - recon_loss: 4.2147e-04 - KL loss: 19.7822 - beta: 0.0023 - val_loss: 108.1962 - val_recon_loss: 4.5390e-04 - val_KL loss: 20.1052 - val_beta: 0.0023\n",
      "Epoch 704/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 103.1647 - recon_loss: 4.2852e-04 - KL loss: 19.9981 - beta: 0.0023 - val_loss: 106.0034 - val_recon_loss: 4.4198e-04 - val_KL loss: 20.2262 - val_beta: 0.0023\n",
      "Epoch 705/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 102.2500 - recon_loss: 4.2405e-04 - KL loss: 19.9516 - beta: 0.0023 - val_loss: 109.2541 - val_recon_loss: 4.6068e-04 - val_KL loss: 19.8472 - val_beta: 0.0023\n",
      "Epoch 706/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 102.6580 - recon_loss: 4.2650e-04 - KL loss: 19.8836 - beta: 0.0023 - val_loss: 112.8146 - val_recon_loss: 4.7978e-04 - val_KL loss: 19.7002 - val_beta: 0.0023\n",
      "Epoch 707/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 101.4631 - recon_loss: 4.2098e-04 - KL loss: 19.7599 - beta: 0.0023\n",
      "Epoch 00707: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 101.4631 - recon_loss: 4.2098e-04 - KL loss: 19.7600 - beta: 0.0023 - val_loss: 107.5374 - val_recon_loss: 4.5061e-04 - val_KL loss: 20.0844 - val_beta: 0.0023\n",
      "Epoch 708/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 100.4480 - recon_loss: 4.1431e-04 - KL loss: 20.0393 - beta: 0.0023 - val_loss: 105.7654 - val_recon_loss: 4.4201e-04 - val_KL loss: 19.9809 - val_beta: 0.0023\n",
      "Epoch 709/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 101.2415 - recon_loss: 4.1817e-04 - KL loss: 20.0854 - beta: 0.0023 - val_loss: 104.8403 - val_recon_loss: 4.3754e-04 - val_KL loss: 19.9248 - val_beta: 0.0023\n",
      "Epoch 710/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 98.9825 - recon_loss: 4.0719e-04 - KL loss: 19.9570 - beta: 0.0023 - val_loss: 104.7842 - val_recon_loss: 4.3753e-04 - val_KL loss: 19.8703 - val_beta: 0.0023\n",
      "Epoch 711/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 98.6997 - recon_loss: 4.0576e-04 - KL loss: 19.9509 - beta: 0.0023 - val_loss: 104.0859 - val_recon_loss: 4.3333e-04 - val_KL loss: 19.9869 - val_beta: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 712/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 99.5259 - recon_loss: 4.1010e-04 - KL loss: 19.9354 - beta: 0.0023 - val_loss: 104.9633 - val_recon_loss: 4.3842e-04 - val_KL loss: 19.8754 - val_beta: 0.0023\n",
      "Epoch 713/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 99.3771 - recon_loss: 4.0968e-04 - KL loss: 19.8685 - beta: 0.0023 - val_loss: 106.2727 - val_recon_loss: 4.4469e-04 - val_KL loss: 19.9679 - val_beta: 0.0023\n",
      "Epoch 714/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 98.1037 - recon_loss: 4.0315e-04 - KL loss: 19.8610 - beta: 0.0023 - val_loss: 103.8895 - val_recon_loss: 4.3254e-04 - val_KL loss: 19.9433 - val_beta: 0.0023\n",
      "Epoch 715/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 97.8951 - recon_loss: 4.0211e-04 - KL loss: 19.8546 - beta: 0.0023 - val_loss: 102.6106 - val_recon_loss: 4.2583e-04 - val_KL loss: 19.9674 - val_beta: 0.0023\n",
      "Epoch 716/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 97.4333 - recon_loss: 3.9960e-04 - KL loss: 19.8807 - beta: 0.0023 - val_loss: 103.2570 - val_recon_loss: 4.2911e-04 - val_KL loss: 19.9764 - val_beta: 0.0023\n",
      "Epoch 717/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 98.4995 - recon_loss: 4.0499e-04 - KL loss: 19.8999 - beta: 0.0023 - val_loss: 102.1312 - val_recon_loss: 4.2372e-04 - val_KL loss: 19.8976 - val_beta: 0.0023\n",
      "Epoch 718/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 97.5626 - recon_loss: 4.0023e-04 - KL loss: 19.8865 - beta: 0.0023 - val_loss: 107.0407 - val_recon_loss: 4.4886e-04 - val_KL loss: 19.9271 - val_beta: 0.0023\n",
      "Epoch 719/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 98.3554 - recon_loss: 4.0420e-04 - KL loss: 19.9098 - beta: 0.0023 - val_loss: 104.9872 - val_recon_loss: 4.3856e-04 - val_KL loss: 19.8738 - val_beta: 0.0023\n",
      "Epoch 720/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 97.8510 - recon_loss: 4.0162e-04 - KL loss: 19.9063 - beta: 0.0023 - val_loss: 103.4022 - val_recon_loss: 4.3022e-04 - val_KL loss: 19.9069 - val_beta: 0.0023\n",
      "Epoch 721/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 97.6140 - recon_loss: 4.0061e-04 - KL loss: 19.8657 - beta: 0.0023 - val_loss: 105.5212 - val_recon_loss: 4.4112e-04 - val_KL loss: 19.9093 - val_beta: 0.0023\n",
      "Epoch 722/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 97.8157 - recon_loss: 4.0163e-04 - KL loss: 19.8688 - beta: 0.0023 - val_loss: 101.4172 - val_recon_loss: 4.1997e-04 - val_KL loss: 19.9108 - val_beta: 0.0023\n",
      "Epoch 723/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 97.2851 - recon_loss: 3.9910e-04 - KL loss: 19.8295 - beta: 0.0023 - val_loss: 101.0850 - val_recon_loss: 4.1846e-04 - val_KL loss: 19.8708 - val_beta: 0.0023\n",
      "Epoch 724/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 97.0478 - recon_loss: 3.9771e-04 - KL loss: 19.8623 - beta: 0.0023 - val_loss: 104.4102 - val_recon_loss: 4.3507e-04 - val_KL loss: 19.9726 - val_beta: 0.0023\n",
      "Epoch 725/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 98.2356 - recon_loss: 4.0315e-04 - KL loss: 19.9934 - beta: 0.0023 - val_loss: 106.1884 - val_recon_loss: 4.4401e-04 - val_KL loss: 20.0162 - val_beta: 0.0023\n",
      "Epoch 726/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 98.0534 - recon_loss: 4.0253e-04 - KL loss: 19.9326 - beta: 0.0023 - val_loss: 105.3814 - val_recon_loss: 4.4038e-04 - val_KL loss: 19.9141 - val_beta: 0.0023\n",
      "Epoch 727/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 97.1506 - recon_loss: 3.9806e-04 - KL loss: 19.8969 - beta: 0.0023 - val_loss: 104.7709 - val_recon_loss: 4.3639e-04 - val_KL loss: 20.0786 - val_beta: 0.0023\n",
      "Epoch 728/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 97.0522 - recon_loss: 3.9729e-04 - KL loss: 19.9466 - beta: 0.0023\n",
      "Epoch 00728: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 97.0521 - recon_loss: 3.9729e-04 - KL loss: 19.9466 - beta: 0.0023 - val_loss: 102.9268 - val_recon_loss: 4.2723e-04 - val_KL loss: 20.0114 - val_beta: 0.0023\n",
      "Epoch 729/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 96.5924 - recon_loss: 3.9503e-04 - KL loss: 19.9263 - beta: 0.0023 - val_loss: 101.7683 - val_recon_loss: 4.2131e-04 - val_KL loss: 20.0013 - val_beta: 0.0023\n",
      "Epoch 730/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 96.5015 - recon_loss: 3.9452e-04 - KL loss: 19.9352 - beta: 0.0023 - val_loss: 101.9446 - val_recon_loss: 4.2208e-04 - val_KL loss: 20.0278 - val_beta: 0.0023\n",
      "Epoch 731/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 96.0553 - recon_loss: 3.9213e-04 - KL loss: 19.9522 - beta: 0.0023 - val_loss: 101.1045 - val_recon_loss: 4.1762e-04 - val_KL loss: 20.0534 - val_beta: 0.0023\n",
      "Epoch 732/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 96.8600 - recon_loss: 3.9612e-04 - KL loss: 19.9819 - beta: 0.0023 - val_loss: 102.7562 - val_recon_loss: 4.2613e-04 - val_KL loss: 20.0543 - val_beta: 0.0023\n",
      "Epoch 733/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 95.8563 - recon_loss: 3.9099e-04 - KL loss: 19.9741 - beta: 0.0023 - val_loss: 101.0650 - val_recon_loss: 4.1742e-04 - val_KL loss: 20.0529 - val_beta: 0.0023\n",
      "Epoch 734/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 96.8860 - recon_loss: 3.9630e-04 - KL loss: 19.9728 - beta: 0.0023 - val_loss: 105.4410 - val_recon_loss: 4.4006e-04 - val_KL loss: 20.0355 - val_beta: 0.0023\n",
      "Epoch 735/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 97.0367 - recon_loss: 3.9705e-04 - KL loss: 19.9792 - beta: 0.0023 - val_loss: 103.8338 - val_recon_loss: 4.3145e-04 - val_KL loss: 20.1000 - val_beta: 0.0023\n",
      "Epoch 736/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 96.4510 - recon_loss: 3.9395e-04 - KL loss: 19.9943 - beta: 0.0023 - val_loss: 102.5347 - val_recon_loss: 4.2502e-04 - val_KL loss: 20.0484 - val_beta: 0.0023\n",
      "Epoch 737/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 96.4735 - recon_loss: 3.9422e-04 - KL loss: 19.9645 - beta: 0.0023 - val_loss: 102.6466 - val_recon_loss: 4.2533e-04 - val_KL loss: 20.0993 - val_beta: 0.0023\n",
      "Epoch 738/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 95.5615 - recon_loss: 3.8954e-04 - KL loss: 19.9612 - beta: 0.0023\n",
      "Epoch 00738: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 95.5616 - recon_loss: 3.8954e-04 - KL loss: 19.9612 - beta: 0.0023 - val_loss: 105.4982 - val_recon_loss: 4.4038e-04 - val_KL loss: 20.0300 - val_beta: 0.0023\n",
      "Epoch 739/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 96.1144 - recon_loss: 3.9246e-04 - KL loss: 19.9468 - beta: 0.0023 - val_loss: 104.9667 - val_recon_loss: 4.3777e-04 - val_KL loss: 20.0065 - val_beta: 0.0023\n",
      "Epoch 740/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 95.9179 - recon_loss: 3.9157e-04 - KL loss: 19.9243 - beta: 0.0023 - val_loss: 104.7391 - val_recon_loss: 4.3657e-04 - val_KL loss: 20.0106 - val_beta: 0.0023\n",
      "Epoch 741/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 95.5821 - recon_loss: 3.8979e-04 - KL loss: 19.9338 - beta: 0.0023 - val_loss: 106.8717 - val_recon_loss: 4.4747e-04 - val_KL loss: 20.0291 - val_beta: 0.0023\n",
      "Epoch 742/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 95.8183 - recon_loss: 3.9088e-04 - KL loss: 19.9584 - beta: 0.0023 - val_loss: 105.6239 - val_recon_loss: 4.4095e-04 - val_KL loss: 20.0458 - val_beta: 0.0023\n",
      "Epoch 743/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 95.7432 - recon_loss: 3.9041e-04 - KL loss: 19.9736 - beta: 0.0023\n",
      "Epoch 00743: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 95.7439 - recon_loss: 3.9041e-04 - KL loss: 19.9736 - beta: 0.0023 - val_loss: 101.8223 - val_recon_loss: 4.2119e-04 - val_KL loss: 20.0783 - val_beta: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 743/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 231.4534 - recon_loss: 4.7618e-04 - KL loss: 21.6784 - beta: 0.0015 - val_loss: 238.9371 - val_recon_loss: 4.9199e-04 - val_KL loss: 22.1934 - val_beta: 0.0015\n",
      "Epoch 744/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 218.8108 - recon_loss: 4.4598e-04 - KL loss: 22.3402 - beta: 0.0015 - val_loss: 270.5798 - val_recon_loss: 5.6346e-04 - val_KL loss: 22.3520 - val_beta: 0.0015\n",
      "Epoch 745/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 219.6174 - recon_loss: 4.4785e-04 - KL loss: 22.3205 - beta: 0.0015 - val_loss: 233.9498 - val_recon_loss: 4.8137e-04 - val_KL loss: 21.8870 - val_beta: 0.0015\n",
      "Epoch 746/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 205.4047 - recon_loss: 4.1568e-04 - KL loss: 22.2825 - beta: 0.0015 - val_loss: 293.3954 - val_recon_loss: 6.1330e-04 - val_KL loss: 23.2135 - val_beta: 0.0015\n",
      "Epoch 747/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 227.5769 - recon_loss: 4.6477e-04 - KL loss: 22.8247 - beta: 0.0015 - val_loss: 239.1476 - val_recon_loss: 4.9153e-04 - val_KL loss: 22.6091 - val_beta: 0.0015\n",
      "Epoch 748/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 216.3933 - recon_loss: 4.3953e-04 - KL loss: 22.7616 - beta: 0.0015 - val_loss: 217.4492 - val_recon_loss: 4.4233e-04 - val_KL loss: 22.5840 - val_beta: 0.0015\n",
      "Epoch 749/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 219.1570 - recon_loss: 4.4556e-04 - KL loss: 22.8701 - beta: 0.0015 - val_loss: 230.8563 - val_recon_loss: 4.7272e-04 - val_KL loss: 22.6037 - val_beta: 0.0015\n",
      "Epoch 750/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 214.8470 - recon_loss: 4.3657e-04 - KL loss: 22.5195 - beta: 0.0015 - val_loss: 242.5425 - val_recon_loss: 4.9923e-04 - val_KL loss: 22.6107 - val_beta: 0.0015\n",
      "Epoch 751/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 214.9005 - recon_loss: 4.3622e-04 - KL loss: 22.7287 - beta: 0.0015 - val_loss: 240.5069 - val_recon_loss: 4.9445e-04 - val_KL loss: 22.6814 - val_beta: 0.0015\n",
      "Epoch 752/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 207.8552 - recon_loss: 4.2005e-04 - KL loss: 22.8075 - beta: 0.0015 - val_loss: 237.5644 - val_recon_loss: 4.8889e-04 - val_KL loss: 22.1885 - val_beta: 0.0015\n",
      "Epoch 753/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 214.2495 - recon_loss: 4.3498e-04 - KL loss: 22.6213 - beta: 0.0015\n",
      "Epoch 00753: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 214.2488 - recon_loss: 4.3498e-04 - KL loss: 22.6214 - beta: 0.0015 - val_loss: 226.0350 - val_recon_loss: 4.6252e-04 - val_KL loss: 22.2743 - val_beta: 0.0015\n",
      "Epoch 754/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 203.1631 - recon_loss: 4.0981e-04 - KL loss: 22.6243 - beta: 0.0015 - val_loss: 235.2554 - val_recon_loss: 4.8409e-04 - val_KL loss: 21.9932 - val_beta: 0.0015\n",
      "Epoch 755/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 201.3580 - recon_loss: 4.0544e-04 - KL loss: 22.7457 - beta: 0.0015 - val_loss: 225.1692 - val_recon_loss: 4.5980e-04 - val_KL loss: 22.6082 - val_beta: 0.0015\n",
      "Epoch 756/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 203.1124 - recon_loss: 4.0918e-04 - KL loss: 22.8524 - beta: 0.0015 - val_loss: 222.6571 - val_recon_loss: 4.5373e-04 - val_KL loss: 22.7707 - val_beta: 0.0015\n",
      "Epoch 757/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 199.6724 - recon_loss: 4.0117e-04 - KL loss: 22.9410 - beta: 0.0015 - val_loss: 225.0118 - val_recon_loss: 4.5986e-04 - val_KL loss: 22.4259 - val_beta: 0.0015\n",
      "Epoch 758/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 195.7498 - recon_loss: 3.9272e-04 - KL loss: 22.7423 - beta: 0.0015\n",
      "Epoch 00758: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 195.7509 - recon_loss: 3.9272e-04 - KL loss: 22.7424 - beta: 0.0015 - val_loss: 222.6965 - val_recon_loss: 4.5307e-04 - val_KL loss: 23.1001 - val_beta: 0.0015\n",
      "Epoch 758/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 494.6128 - recon_loss: 4.6902e-04 - KL loss: 25.5963 - beta: 0.0010 - val_loss: 535.9770 - val_recon_loss: 5.0712e-04 - val_KL loss: 28.8569 - val_beta: 0.0010\n",
      "Epoch 759/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 479.3621 - recon_loss: 4.5346e-04 - KL loss: 25.9003 - beta: 0.0010 - val_loss: 493.9228 - val_recon_loss: 4.6850e-04 - val_KL loss: 25.4255 - val_beta: 0.0010\n",
      "Epoch 760/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 441.1624 - recon_loss: 4.1559e-04 - KL loss: 25.5716 - beta: 0.0010 - val_loss: 521.5477 - val_recon_loss: 4.9632e-04 - val_KL loss: 25.2253 - val_beta: 0.0010\n",
      "Epoch 761/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 437.8110 - recon_loss: 4.1208e-04 - KL loss: 25.7322 - beta: 0.0010 - val_loss: 543.5405 - val_recon_loss: 5.1818e-04 - val_KL loss: 25.3576 - val_beta: 0.0010\n",
      "Epoch 762/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 476.5361 - recon_loss: 4.4946e-04 - KL loss: 27.0759 - beta: 0.0010 - val_loss: 485.3014 - val_recon_loss: 4.5960e-04 - val_KL loss: 25.7007 - val_beta: 0.0010\n",
      "Epoch 763/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 440.3431 - recon_loss: 4.1493e-04 - KL loss: 25.4084 - beta: 0.0010 - val_loss: 476.5759 - val_recon_loss: 4.5065e-04 - val_KL loss: 25.9246 - val_beta: 0.0010\n",
      "Epoch 764/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 432.1123 - recon_loss: 4.0608e-04 - KL loss: 26.0332 - beta: 0.0010 - val_loss: 483.5906 - val_recon_loss: 4.5766e-04 - val_KL loss: 25.9349 - val_beta: 0.0010\n",
      "Epoch 765/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 411.3952 - recon_loss: 3.8550e-04 - KL loss: 25.8943 - beta: 0.0010 - val_loss: 455.3206 - val_recon_loss: 4.2979e-04 - val_KL loss: 25.5281 - val_beta: 0.0010\n",
      "Epoch 766/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 424.5854 - recon_loss: 3.9870e-04 - KL loss: 25.8842 - beta: 0.0010 - val_loss: 508.1642 - val_recon_loss: 4.8252e-04 - val_KL loss: 25.6406 - val_beta: 0.0010\n",
      "Epoch 767/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 432.4539 - recon_loss: 4.0666e-04 - KL loss: 25.7920 - beta: 0.0010 - val_loss: 472.6949 - val_recon_loss: 4.4559e-04 - val_KL loss: 27.1021 - val_beta: 0.0010\n",
      "Epoch 768/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 438.6962 - recon_loss: 4.1229e-04 - KL loss: 26.4042 - beta: 0.0010 - val_loss: 445.6924 - val_recon_loss: 4.1968e-04 - val_KL loss: 26.0130 - val_beta: 0.0010\n",
      "Epoch 769/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 438.6265 - recon_loss: 4.1285e-04 - KL loss: 25.7772 - beta: 0.0010 - val_loss: 502.6737 - val_recon_loss: 4.7741e-04 - val_KL loss: 25.2673 - val_beta: 0.0010\n",
      "Epoch 770/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 428.7851 - recon_loss: 4.0308e-04 - KL loss: 25.7084 - beta: 0.0010 - val_loss: 446.2589 - val_recon_loss: 4.2044e-04 - val_KL loss: 25.8208 - val_beta: 0.0010\n",
      "Epoch 771/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 423.5987 - recon_loss: 3.9718e-04 - KL loss: 26.4191 - beta: 0.0010 - val_loss: 464.3135 - val_recon_loss: 4.3874e-04 - val_KL loss: 25.5687 - val_beta: 0.0010\n",
      "Epoch 772/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 412.8179 - recon_loss: 3.8687e-04 - KL loss: 25.9530 - beta: 0.0010 - val_loss: 499.2371 - val_recon_loss: 4.7387e-04 - val_KL loss: 25.3666 - val_beta: 0.0010\n",
      "Epoch 773/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 423.9974 - recon_loss: 3.9815e-04 - KL loss: 25.8504 - beta: 0.0010\n",
      "Epoch 00773: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 423.9963 - recon_loss: 3.9815e-04 - KL loss: 25.8504 - beta: 0.0010 - val_loss: 465.7532 - val_recon_loss: 4.4000e-04 - val_KL loss: 25.7577 - val_beta: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 774/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 394.2145 - recon_loss: 3.6816e-04 - KL loss: 26.0514 - beta: 0.0010 - val_loss: 448.9914 - val_recon_loss: 4.2287e-04 - val_KL loss: 26.1186 - val_beta: 0.0010\n",
      "Epoch 775/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 391.6433 - recon_loss: 3.6537e-04 - KL loss: 26.2744 - beta: 0.0010 - val_loss: 451.5765 - val_recon_loss: 4.2552e-04 - val_KL loss: 26.0547 - val_beta: 0.0010\n",
      "Epoch 776/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 384.5154 - recon_loss: 3.5831e-04 - KL loss: 26.2042 - beta: 0.0010 - val_loss: 464.3600 - val_recon_loss: 4.3777e-04 - val_KL loss: 26.5942 - val_beta: 0.0010\n",
      "Epoch 777/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 386.2449 - recon_loss: 3.5994e-04 - KL loss: 26.3055 - beta: 0.0010 - val_loss: 449.2844 - val_recon_loss: 4.2321e-04 - val_KL loss: 26.0781 - val_beta: 0.0010\n",
      "Epoch 778/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 385.1425 - recon_loss: 3.5878e-04 - KL loss: 26.3591 - beta: 0.0010\n",
      "Epoch 00778: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 385.1424 - recon_loss: 3.5878e-04 - KL loss: 26.3591 - beta: 0.0010 - val_loss: 457.6888 - val_recon_loss: 4.3105e-04 - val_KL loss: 26.6414 - val_beta: 0.0010\n",
      "Epoch 778/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 276.0314 - recon_loss: 3.6971e-04 - KL loss: 25.2937 - beta: 0.0012 - val_loss: 315.4677 - val_recon_loss: 4.2991e-04 - val_KL loss: 23.8995 - val_beta: 0.0012\n",
      "Epoch 779/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 287.0189 - recon_loss: 3.8699e-04 - KL loss: 24.5621 - beta: 0.0012 - val_loss: 306.7109 - val_recon_loss: 4.1681e-04 - val_KL loss: 24.0247 - val_beta: 0.0012\n",
      "Epoch 780/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 287.5071 - recon_loss: 3.8769e-04 - KL loss: 24.5698 - beta: 0.0012 - val_loss: 343.6422 - val_recon_loss: 4.7146e-04 - val_KL loss: 23.8923 - val_beta: 0.0012\n",
      "Epoch 781/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 299.9699 - recon_loss: 4.0650e-04 - KL loss: 24.2815 - beta: 0.0012 - val_loss: 301.8099 - val_recon_loss: 4.0910e-04 - val_KL loss: 24.3544 - val_beta: 0.0012\n",
      "Epoch 782/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 286.4973 - recon_loss: 3.8621e-04 - KL loss: 24.5659 - beta: 0.0012 - val_loss: 287.1674 - val_recon_loss: 3.8768e-04 - val_KL loss: 24.2412 - val_beta: 0.0012\n",
      "Epoch 783/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 275.2852 - recon_loss: 3.6983e-04 - KL loss: 24.4663 - beta: 0.0012 - val_loss: 357.0788 - val_recon_loss: 4.9105e-04 - val_KL loss: 24.0446 - val_beta: 0.0012\n",
      "Epoch 784/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 297.8900 - recon_loss: 4.0283e-04 - KL loss: 24.6856 - beta: 0.0012 - val_loss: 428.2897 - val_recon_loss: 5.9191e-04 - val_KL loss: 26.8522 - val_beta: 0.0012\n",
      "Epoch 785/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 348.1549 - recon_loss: 4.7550e-04 - KL loss: 25.6691 - beta: 0.0012 - val_loss: 321.9110 - val_recon_loss: 4.3821e-04 - val_KL loss: 24.7167 - val_beta: 0.0012\n",
      "Epoch 786/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 313.1063 - recon_loss: 4.2426e-04 - KL loss: 25.3671 - beta: 0.0012 - val_loss: 334.9192 - val_recon_loss: 4.5816e-04 - val_KL loss: 24.1947 - val_beta: 0.0012\n",
      "Epoch 787/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 295.8455 - recon_loss: 3.9988e-04 - KL loss: 24.6428 - beta: 0.0012\n",
      "Epoch 00787: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 295.8400 - recon_loss: 3.9987e-04 - KL loss: 24.6428 - beta: 0.0012 - val_loss: 318.1720 - val_recon_loss: 4.3314e-04 - val_KL loss: 24.4114 - val_beta: 0.0012\n",
      "Epoch 788/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 278.3161 - recon_loss: 3.7363e-04 - KL loss: 24.9172 - beta: 0.0012 - val_loss: 306.0242 - val_recon_loss: 4.1494e-04 - val_KL loss: 24.6113 - val_beta: 0.0012\n",
      "Epoch 789/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 273.3304 - recon_loss: 3.6621e-04 - KL loss: 24.9643 - beta: 0.0012 - val_loss: 308.8057 - val_recon_loss: 4.1910e-04 - val_KL loss: 24.5702 - val_beta: 0.0012\n",
      "Epoch 790/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 272.3662 - recon_loss: 3.6492e-04 - KL loss: 24.8774 - beta: 0.0012 - val_loss: 295.0429 - val_recon_loss: 3.9888e-04 - val_KL loss: 24.5208 - val_beta: 0.0012\n",
      "Epoch 791/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 272.3575 - recon_loss: 3.6490e-04 - KL loss: 24.8783 - beta: 0.0012 - val_loss: 292.7312 - val_recon_loss: 3.9533e-04 - val_KL loss: 24.6134 - val_beta: 0.0012\n",
      "Epoch 792/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 266.7634 - recon_loss: 3.5664e-04 - KL loss: 24.8879 - beta: 0.0012\n",
      "Epoch 00792: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 266.7629 - recon_loss: 3.5664e-04 - KL loss: 24.8879 - beta: 0.0012 - val_loss: 295.3886 - val_recon_loss: 3.9877e-04 - val_KL loss: 24.9411 - val_beta: 0.0012\n",
      "Epoch 792/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 193.8787 - recon_loss: 3.6992e-04 - KL loss: 23.7267 - beta: 0.0015 - val_loss: 212.3092 - val_recon_loss: 4.1213e-04 - val_KL loss: 22.7426 - val_beta: 0.0015\n",
      "Epoch 793/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 197.3886 - recon_loss: 3.7850e-04 - KL loss: 23.2912 - beta: 0.0015 - val_loss: 219.6289 - val_recon_loss: 4.2696e-04 - val_KL loss: 23.2430 - val_beta: 0.0015\n",
      "Epoch 794/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 205.8448 - recon_loss: 3.9660e-04 - KL loss: 23.4238 - beta: 0.0015 - val_loss: 235.9730 - val_recon_loss: 4.6204e-04 - val_KL loss: 23.4514 - val_beta: 0.0015\n",
      "Epoch 795/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 206.1221 - recon_loss: 3.9719e-04 - KL loss: 23.4277 - beta: 0.0015 - val_loss: 213.4008 - val_recon_loss: 4.1396e-04 - val_KL loss: 22.9939 - val_beta: 0.0015\n",
      "Epoch 796/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 198.5111 - recon_loss: 3.8129e-04 - KL loss: 23.1322 - beta: 0.0015 - val_loss: 246.6409 - val_recon_loss: 4.8502e-04 - val_KL loss: 23.5479 - val_beta: 0.0015\n",
      "Epoch 797/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 199.0391 - recon_loss: 3.8284e-04 - KL loss: 22.9476 - beta: 0.0015\n",
      "Epoch 00797: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 199.0393 - recon_loss: 3.8284e-04 - KL loss: 22.9476 - beta: 0.0015 - val_loss: 212.8983 - val_recon_loss: 4.1293e-04 - val_KL loss: 22.9669 - val_beta: 0.0015\n",
      "Epoch 798/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 189.0632 - recon_loss: 3.6076e-04 - KL loss: 23.1275 - beta: 0.0015 - val_loss: 199.5048 - val_recon_loss: 3.8314e-04 - val_KL loss: 23.2744 - val_beta: 0.0015\n",
      "Epoch 799/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 192.5350 - recon_loss: 3.6778e-04 - KL loss: 23.3678 - beta: 0.0015 - val_loss: 196.7371 - val_recon_loss: 3.7652e-04 - val_KL loss: 23.5516 - val_beta: 0.0015\n",
      "Epoch 800/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 190.1228 - recon_loss: 3.6265e-04 - KL loss: 23.3185 - beta: 0.0015 - val_loss: 199.7761 - val_recon_loss: 3.8362e-04 - val_KL loss: 23.3241 - val_beta: 0.0015\n",
      "Epoch 801/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 191.3328 - recon_loss: 3.6504e-04 - KL loss: 23.4254 - beta: 0.0015 - val_loss: 196.8371 - val_recon_loss: 3.7738e-04 - val_KL loss: 23.2537 - val_beta: 0.0015\n",
      "Epoch 802/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 189.3304 - recon_loss: 3.6091e-04 - KL loss: 23.3266 - beta: 0.0015 - val_loss: 217.3576 - val_recon_loss: 4.2217e-04 - val_KL loss: 23.1731 - val_beta: 0.0015\n",
      "Epoch 803/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 185.7801 - recon_loss: 3.5305e-04 - KL loss: 23.3884 - beta: 0.0015 - val_loss: 198.5758 - val_recon_loss: 3.8097e-04 - val_KL loss: 23.3443 - val_beta: 0.0015\n",
      "Epoch 804/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 183.3343 - recon_loss: 3.4766e-04 - KL loss: 23.4236 - beta: 0.0015\n",
      "Epoch 00804: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 183.3346 - recon_loss: 3.4766e-04 - KL loss: 23.4236 - beta: 0.0015 - val_loss: 207.5816 - val_recon_loss: 4.0086e-04 - val_KL loss: 23.2024 - val_beta: 0.0015\n",
      "Epoch 805/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 183.4742 - recon_loss: 3.4788e-04 - KL loss: 23.4634 - beta: 0.0015 - val_loss: 195.3296 - val_recon_loss: 3.7410e-04 - val_KL loss: 23.2578 - val_beta: 0.0015\n",
      "Epoch 806/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 182.7716 - recon_loss: 3.4634e-04 - KL loss: 23.4661 - beta: 0.0015 - val_loss: 190.6575 - val_recon_loss: 3.6356e-04 - val_KL loss: 23.4350 - val_beta: 0.0015\n",
      "Epoch 807/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 182.5599 - recon_loss: 3.4583e-04 - KL loss: 23.4904 - beta: 0.0015 - val_loss: 194.5893 - val_recon_loss: 3.7202e-04 - val_KL loss: 23.4727 - val_beta: 0.0015\n",
      "Epoch 808/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 182.6061 - recon_loss: 3.4564e-04 - KL loss: 23.6235 - beta: 0.0015 - val_loss: 195.6119 - val_recon_loss: 3.7449e-04 - val_KL loss: 23.3585 - val_beta: 0.0015\n",
      "Epoch 809/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 179.7979 - recon_loss: 3.3968e-04 - KL loss: 23.5583 - beta: 0.0015 - val_loss: 199.3476 - val_recon_loss: 3.8241e-04 - val_KL loss: 23.4544 - val_beta: 0.0015\n",
      "Epoch 810/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 181.9913 - recon_loss: 3.4439e-04 - KL loss: 23.5846 - beta: 0.0015 - val_loss: 204.4826 - val_recon_loss: 3.9329e-04 - val_KL loss: 23.5854 - val_beta: 0.0015\n",
      "Epoch 811/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 183.1943 - recon_loss: 3.4677e-04 - KL loss: 23.6907 - beta: 0.0015\n",
      "Epoch 00811: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 183.1937 - recon_loss: 3.4677e-04 - KL loss: 23.6906 - beta: 0.0015 - val_loss: 194.1190 - val_recon_loss: 3.7161e-04 - val_KL loss: 23.1907 - val_beta: 0.0015\n",
      "Epoch 812/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 181.8271 - recon_loss: 3.4434e-04 - KL loss: 23.4425 - beta: 0.0015 - val_loss: 191.3775 - val_recon_loss: 3.6534e-04 - val_KL loss: 23.3346 - val_beta: 0.0015\n",
      "Epoch 813/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 179.7322 - recon_loss: 3.3972e-04 - KL loss: 23.4735 - beta: 0.0015 - val_loss: 194.0202 - val_recon_loss: 3.7099e-04 - val_KL loss: 23.3768 - val_beta: 0.0015\n",
      "Epoch 814/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 180.4786 - recon_loss: 3.4119e-04 - KL loss: 23.5433 - beta: 0.0015 - val_loss: 193.6992 - val_recon_loss: 3.7022e-04 - val_KL loss: 23.4090 - val_beta: 0.0015\n",
      "Epoch 815/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 181.3058 - recon_loss: 3.4305e-04 - KL loss: 23.5159 - beta: 0.0015 - val_loss: 193.9979 - val_recon_loss: 3.7090e-04 - val_KL loss: 23.3956 - val_beta: 0.0015\n",
      "Epoch 816/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 182.0300 - recon_loss: 3.4450e-04 - KL loss: 23.5701 - beta: 0.0015\n",
      "Epoch 00816: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 182.0303 - recon_loss: 3.4451e-04 - KL loss: 23.5701 - beta: 0.0015 - val_loss: 194.4473 - val_recon_loss: 3.7191e-04 - val_KL loss: 23.3816 - val_beta: 0.0015\n",
      "Epoch 816/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 148.7675 - recon_loss: 4.0654e-04 - KL loss: 21.9466 - beta: 0.0018 - val_loss: 148.5752 - val_recon_loss: 4.0767e-04 - val_KL loss: 21.4035 - val_beta: 0.0018\n",
      "Epoch 817/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 142.5576 - recon_loss: 3.8763e-04 - KL loss: 21.6368 - beta: 0.0018 - val_loss: 161.4402 - val_recon_loss: 4.4935e-04 - val_KL loss: 21.2660 - val_beta: 0.0018\n",
      "Epoch 818/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 145.2515 - recon_loss: 3.9649e-04 - KL loss: 21.5661 - beta: 0.0018 - val_loss: 148.5462 - val_recon_loss: 4.0733e-04 - val_KL loss: 21.4800 - val_beta: 0.0018\n",
      "Epoch 819/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 143.5949 - recon_loss: 3.9087e-04 - KL loss: 21.6628 - beta: 0.0018 - val_loss: 153.3532 - val_recon_loss: 4.2569e-04 - val_KL loss: 20.5589 - val_beta: 0.0018\n",
      "Epoch 820/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 139.5386 - recon_loss: 3.7861e-04 - KL loss: 21.4317 - beta: 0.0018 - val_loss: 151.0073 - val_recon_loss: 4.1510e-04 - val_KL loss: 21.5161 - val_beta: 0.0018\n",
      "Epoch 821/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 150.8325 - recon_loss: 4.1487e-04 - KL loss: 21.4143 - beta: 0.0018 - val_loss: 142.5927 - val_recon_loss: 3.8910e-04 - val_KL loss: 21.2121 - val_beta: 0.0018\n",
      "Epoch 822/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 138.5715 - recon_loss: 3.7511e-04 - KL loss: 21.5544 - beta: 0.0018 - val_loss: 160.9237 - val_recon_loss: 4.4852e-04 - val_KL loss: 21.0089 - val_beta: 0.0018\n",
      "Epoch 823/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 138.0093 - recon_loss: 3.7377e-04 - KL loss: 21.4117 - beta: 0.0018 - val_loss: 145.8358 - val_recon_loss: 3.9820e-04 - val_KL loss: 21.6174 - val_beta: 0.0018\n",
      "Epoch 824/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 136.7883 - recon_loss: 3.6973e-04 - KL loss: 21.4517 - beta: 0.0018 - val_loss: 148.3473 - val_recon_loss: 4.0754e-04 - val_KL loss: 21.2152 - val_beta: 0.0018\n",
      "Epoch 825/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 142.5318 - recon_loss: 3.8837e-04 - KL loss: 21.3785 - beta: 0.0018 - val_loss: 147.7500 - val_recon_loss: 4.0624e-04 - val_KL loss: 21.0223 - val_beta: 0.0018\n",
      "Epoch 826/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 145.4380 - recon_loss: 3.9787e-04 - KL loss: 21.3231 - beta: 0.0018\n",
      "Epoch 00826: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 145.4391 - recon_loss: 3.9787e-04 - KL loss: 21.3231 - beta: 0.0018 - val_loss: 159.7725 - val_recon_loss: 4.4336e-04 - val_KL loss: 21.4648 - val_beta: 0.0018\n",
      "Epoch 827/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 143.6812 - recon_loss: 3.9131e-04 - KL loss: 21.6121 - beta: 0.0018 - val_loss: 147.9346 - val_recon_loss: 4.0598e-04 - val_KL loss: 21.2883 - val_beta: 0.0018\n",
      "Epoch 828/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 138.2248 - recon_loss: 3.7354e-04 - KL loss: 21.6997 - beta: 0.0018 - val_loss: 147.8368 - val_recon_loss: 4.0544e-04 - val_KL loss: 21.3599 - val_beta: 0.0018\n",
      "Epoch 829/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 138.5207 - recon_loss: 3.7473e-04 - KL loss: 21.6237 - beta: 0.0018 - val_loss: 143.2980 - val_recon_loss: 3.9048e-04 - val_KL loss: 21.4878 - val_beta: 0.0018\n",
      "Epoch 830/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 140.9325 - recon_loss: 3.8185e-04 - KL loss: 21.8136 - beta: 0.0018 - val_loss: 157.1326 - val_recon_loss: 4.3405e-04 - val_KL loss: 21.7295 - val_beta: 0.0018\n",
      "Epoch 831/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999/1000 [============================>.] - ETA: 0s - loss: 139.3449 - recon_loss: 3.7720e-04 - KL loss: 21.6760 - beta: 0.0018\n",
      "Epoch 00831: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 139.3435 - recon_loss: 3.7720e-04 - KL loss: 21.6761 - beta: 0.0018 - val_loss: 151.3808 - val_recon_loss: 4.1576e-04 - val_KL loss: 21.6835 - val_beta: 0.0018\n",
      "Epoch 831/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 104.5889 - recon_loss: 3.9739e-04 - KL loss: 20.5138 - beta: 0.0022 - val_loss: 100.5508 - val_recon_loss: 3.8090e-04 - val_KL loss: 19.9639 - val_beta: 0.0022\n",
      "Epoch 832/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 100.3019 - recon_loss: 3.7918e-04 - KL loss: 20.0788 - beta: 0.0022 - val_loss: 100.6646 - val_recon_loss: 3.8215e-04 - val_KL loss: 19.8149 - val_beta: 0.0022\n",
      "Epoch 833/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 101.5496 - recon_loss: 3.8529e-04 - KL loss: 20.0340 - beta: 0.0022 - val_loss: 102.5649 - val_recon_loss: 3.9057e-04 - val_KL loss: 19.9325 - val_beta: 0.0022\n",
      "Epoch 834/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 102.9059 - recon_loss: 3.9169e-04 - KL loss: 20.0367 - beta: 0.0022 - val_loss: 103.5433 - val_recon_loss: 3.9571e-04 - val_KL loss: 19.8241 - val_beta: 0.0022\n",
      "Epoch 835/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 102.6713 - recon_loss: 3.9060e-04 - KL loss: 20.0330 - beta: 0.0022 - val_loss: 130.5809 - val_recon_loss: 5.2324e-04 - val_KL loss: 19.8803 - val_beta: 0.0022\n",
      "Epoch 836/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 107.6587 - recon_loss: 4.1298e-04 - KL loss: 20.2850 - beta: 0.0022\n",
      "Epoch 00836: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 107.6596 - recon_loss: 4.1299e-04 - KL loss: 20.2850 - beta: 0.0022 - val_loss: 115.6270 - val_recon_loss: 4.5059e-04 - val_KL loss: 20.2969 - val_beta: 0.0022\n",
      "Epoch 837/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 102.5537 - recon_loss: 3.8806e-04 - KL loss: 20.4537 - beta: 0.0022 - val_loss: 107.5208 - val_recon_loss: 4.1307e-04 - val_KL loss: 20.1286 - val_beta: 0.0022\n",
      "Epoch 838/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 99.7705 - recon_loss: 3.7547e-04 - KL loss: 20.3328 - beta: 0.0022 - val_loss: 103.8417 - val_recon_loss: 3.9624e-04 - val_KL loss: 20.0099 - val_beta: 0.0022\n",
      "Epoch 839/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 98.5919 - recon_loss: 3.7001e-04 - KL loss: 20.3092 - beta: 0.0022 - val_loss: 101.2365 - val_recon_loss: 3.8484e-04 - val_KL loss: 19.8169 - val_beta: 0.0022\n",
      "Epoch 840/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 97.6520 - recon_loss: 3.6586e-04 - KL loss: 20.2476 - beta: 0.0022 - val_loss: 104.9376 - val_recon_loss: 4.0233e-04 - val_KL loss: 19.8185 - val_beta: 0.0022\n",
      "Epoch 841/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 96.6427 - recon_loss: 3.6104e-04 - KL loss: 20.2591 - beta: 0.002 - ETA: 0s - loss: 96.6424 - recon_loss: 3.6104e-04 - KL loss: 20.2590 - beta: 0.0022\n",
      "Epoch 00841: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 96.6420 - recon_loss: 3.6103e-04 - KL loss: 20.2590 - beta: 0.0022 - val_loss: 111.4686 - val_recon_loss: 4.3335e-04 - val_KL loss: 19.7865 - val_beta: 0.0022\n",
      "Epoch 841/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 76.1775 - recon_loss: 3.9922e-04 - KL loss: 18.8950 - beta: 0.0026 - val_loss: 77.3945 - val_recon_loss: 4.1177e-04 - val_KL loss: 18.3104 - val_beta: 0.0026\n",
      "Epoch 842/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 74.6310 - recon_loss: 3.9103e-04 - KL loss: 18.5229 - beta: 0.0026 - val_loss: 79.6318 - val_recon_loss: 4.2776e-04 - val_KL loss: 18.2536 - val_beta: 0.0026\n",
      "Epoch 843/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 75.3374 - recon_loss: 3.9669e-04 - KL loss: 18.4174 - beta: 0.0026 - val_loss: 79.9731 - val_recon_loss: 4.3109e-04 - val_KL loss: 18.1177 - val_beta: 0.0026\n",
      "Epoch 844/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 74.3847 - recon_loss: 3.8996e-04 - KL loss: 18.4306 - beta: 0.0026 - val_loss: 82.8288 - val_recon_loss: 4.4922e-04 - val_KL loss: 18.3720 - val_beta: 0.0026\n",
      "Epoch 845/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 75.1008 - recon_loss: 3.9494e-04 - KL loss: 18.4321 - beta: 0.0026 - val_loss: 78.8200 - val_recon_loss: 4.2401e-04 - val_KL loss: 17.9804 - val_beta: 0.0026\n",
      "Epoch 846/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 76.5322 - recon_loss: 4.0489e-04 - KL loss: 18.4363 - beta: 0.0026\n",
      "Epoch 00846: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 76.5353 - recon_loss: 4.0491e-04 - KL loss: 18.4364 - beta: 0.0026 - val_loss: 81.7192 - val_recon_loss: 4.4211e-04 - val_KL loss: 18.2819 - val_beta: 0.0026\n",
      "Epoch 847/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 76.6701 - recon_loss: 4.0460e-04 - KL loss: 18.6160 - beta: 0.0026 - val_loss: 80.4857 - val_recon_loss: 4.3269e-04 - val_KL loss: 18.4002 - val_beta: 0.0026\n",
      "Epoch 848/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 74.7637 - recon_loss: 3.9104e-04 - KL loss: 18.6553 - beta: 0.0026 - val_loss: 76.6502 - val_recon_loss: 4.0527e-04 - val_KL loss: 18.4995 - val_beta: 0.0026\n",
      "Epoch 849/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 73.4979 - recon_loss: 3.8230e-04 - KL loss: 18.6425 - beta: 0.0026 - val_loss: 77.1157 - val_recon_loss: 4.0931e-04 - val_KL loss: 18.3856 - val_beta: 0.0026\n",
      "Epoch 850/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 71.6664 - recon_loss: 3.7008e-04 - KL loss: 18.5647 - beta: 0.0026 - val_loss: 78.4554 - val_recon_loss: 4.1864e-04 - val_KL loss: 18.3866 - val_beta: 0.0026\n",
      "Epoch 851/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 71.7646 - recon_loss: 3.7060e-04 - KL loss: 18.5882 - beta: 0.0026 - val_loss: 73.8463 - val_recon_loss: 3.8695e-04 - val_KL loss: 18.3246 - val_beta: 0.0026\n",
      "Epoch 852/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 71.9917 - recon_loss: 3.7201e-04 - KL loss: 18.6139 - beta: 0.0026 - val_loss: 73.5509 - val_recon_loss: 3.8441e-04 - val_KL loss: 18.3931 - val_beta: 0.0026\n",
      "Epoch 853/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 71.7383 - recon_loss: 3.7012e-04 - KL loss: 18.6306 - beta: 0.0026 - val_loss: 79.6478 - val_recon_loss: 4.2674e-04 - val_KL loss: 18.4158 - val_beta: 0.0026\n",
      "Epoch 854/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 71.4888 - recon_loss: 3.6847e-04 - KL loss: 18.6180 - beta: 0.0026 - val_loss: 72.9679 - val_recon_loss: 3.8004e-04 - val_KL loss: 18.4379 - val_beta: 0.0026\n",
      "Epoch 855/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 71.6282 - recon_loss: 3.6908e-04 - KL loss: 18.6706 - beta: 0.0026 - val_loss: 73.0256 - val_recon_loss: 3.8159e-04 - val_KL loss: 18.2721 - val_beta: 0.0026\n",
      "Epoch 856/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 73.2801 - recon_loss: 3.8038e-04 - KL loss: 18.7006 - beta: 0.0026 - val_loss: 73.4441 - val_recon_loss: 3.8200e-04 - val_KL loss: 18.6317 - val_beta: 0.0026\n",
      "Epoch 857/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 73.0430 - recon_loss: 3.7824e-04 - KL loss: 18.7707 - beta: 0.0026 - val_loss: 73.9786 - val_recon_loss: 3.8606e-04 - val_KL loss: 18.5844 - val_beta: 0.0026\n",
      "Epoch 858/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 72.2867 - recon_loss: 3.7341e-04 - KL loss: 18.7073 - beta: 0.0026 - val_loss: 74.3838 - val_recon_loss: 3.8820e-04 - val_KL loss: 18.6829 - val_beta: 0.0026\n",
      "Epoch 859/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 73.6863 - recon_loss: 3.8171e-04 - KL loss: 18.9159 - beta: 0.0026\n",
      "Epoch 00859: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 73.6868 - recon_loss: 3.8172e-04 - KL loss: 18.9159 - beta: 0.0026 - val_loss: 75.0823 - val_recon_loss: 3.9416e-04 - val_KL loss: 18.5260 - val_beta: 0.0026\n",
      "Epoch 860/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 71.8999 - recon_loss: 3.7072e-04 - KL loss: 18.7069 - beta: 0.0026 - val_loss: 75.7696 - val_recon_loss: 3.9801e-04 - val_KL loss: 18.6599 - val_beta: 0.0026\n",
      "Epoch 861/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 71.9314 - recon_loss: 3.7022e-04 - KL loss: 18.8104 - beta: 0.0026 - val_loss: 74.6042 - val_recon_loss: 3.8862e-04 - val_KL loss: 18.8424 - val_beta: 0.0026\n",
      "Epoch 862/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 71.1199 - recon_loss: 3.6426e-04 - KL loss: 18.8532 - beta: 0.0026 - val_loss: 74.2786 - val_recon_loss: 3.8718e-04 - val_KL loss: 18.7231 - val_beta: 0.0026\n",
      "Epoch 863/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 71.3211 - recon_loss: 3.6545e-04 - KL loss: 18.8839 - beta: 0.0026 - val_loss: 76.6901 - val_recon_loss: 4.0432e-04 - val_KL loss: 18.6757 - val_beta: 0.0026\n",
      "Epoch 864/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 72.0706 - recon_loss: 3.7147e-04 - KL loss: 18.7703 - beta: 0.0026- ETA: 5s \n",
      "Epoch 00864: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 72.0702 - recon_loss: 3.7146e-04 - KL loss: 18.7702 - beta: 0.0026 - val_loss: 73.7907 - val_recon_loss: 3.8410e-04 - val_KL loss: 18.6772 - val_beta: 0.0026\n",
      "Epoch 864/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 55.5202 - recon_loss: 3.9170e-04 - KL loss: 17.4027 - beta: 0.0032 - val_loss: 58.9923 - val_recon_loss: 4.3086e-04 - val_KL loss: 17.0635 - val_beta: 0.0032\n",
      "Epoch 865/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 56.2820 - recon_loss: 4.0335e-04 - KL loss: 17.0303 - beta: 0.0032 - val_loss: 57.7099 - val_recon_loss: 4.1996e-04 - val_KL loss: 16.8420 - val_beta: 0.0032\n",
      "Epoch 866/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 56.8121 - recon_loss: 4.0936e-04 - KL loss: 16.9759 - beta: 0.0032 - val_loss: 60.1700 - val_recon_loss: 4.4183e-04 - val_KL loss: 17.1736 - val_beta: 0.0032\n",
      "Epoch 867/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 57.2351 - recon_loss: 4.1302e-04 - KL loss: 17.0429 - beta: 0.0032 - val_loss: 60.0270 - val_recon_loss: 4.4571e-04 - val_KL loss: 16.6538 - val_beta: 0.0032\n",
      "Epoch 868/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 57.0609 - recon_loss: 4.1223e-04 - KL loss: 16.9450 - beta: 0.0032 - val_loss: 59.2513 - val_recon_loss: 4.3527e-04 - val_KL loss: 16.8939 - val_beta: 0.0032\n",
      "Epoch 869/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 61.6485 - recon_loss: 4.5609e-04 - KL loss: 17.2648 - beta: 0.0032 - val_loss: 74.0425 - val_recon_loss: 5.7813e-04 - val_KL loss: 17.7829 - val_beta: 0.0032\n",
      "Epoch 870/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 64.3060 - recon_loss: 4.7838e-04 - KL loss: 17.7528 - beta: 0.0032\n",
      "Epoch 00870: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 64.3040 - recon_loss: 4.7837e-04 - KL loss: 17.7526 - beta: 0.0032 - val_loss: 65.0733 - val_recon_loss: 4.9624e-04 - val_KL loss: 16.7823 - val_beta: 0.0032\n",
      "Epoch 871/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 57.9323 - recon_loss: 4.1797e-04 - KL loss: 17.2584 - beta: 0.0032 - val_loss: 64.2138 - val_recon_loss: 4.8637e-04 - val_KL loss: 16.8834 - val_beta: 0.0032\n",
      "Epoch 872/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 57.4307 - recon_loss: 4.1223e-04 - KL loss: 17.3156 - beta: 0.0032 - val_loss: 63.9149 - val_recon_loss: 4.8088e-04 - val_KL loss: 17.1189 - val_beta: 0.0032\n",
      "Epoch 873/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 57.5906 - recon_loss: 4.1181e-04 - KL loss: 17.5164 - beta: 0.0032 - val_loss: 62.5488 - val_recon_loss: 4.6634e-04 - val_KL loss: 17.1679 - val_beta: 0.0032\n",
      "Epoch 874/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 56.6231 - recon_loss: 4.0293e-04 - KL loss: 17.4123 - beta: 0.0032 - val_loss: 60.1027 - val_recon_loss: 4.4282e-04 - val_KL loss: 17.0101 - val_beta: 0.0032\n",
      "Epoch 875/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 56.2379 - recon_loss: 4.0088e-04 - KL loss: 17.2266 - beta: 0.0032\n",
      "Epoch 00875: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 56.2389 - recon_loss: 4.0089e-04 - KL loss: 17.2267 - beta: 0.0032 - val_loss: 60.2613 - val_recon_loss: 4.4518e-04 - val_KL loss: 16.9389 - val_beta: 0.0032\n",
      "Epoch 875/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.5659 - recon_loss: 4.3173e-04 - KL loss: 16.0720 - beta: 0.0039 - val_loss: 46.3880 - val_recon_loss: 4.7094e-04 - val_KL loss: 15.3064 - val_beta: 0.0039\n",
      "Epoch 876/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.8600 - recon_loss: 4.4044e-04 - KL loss: 15.7914 - beta: 0.0039 - val_loss: 45.2582 - val_recon_loss: 4.5252e-04 - val_KL loss: 15.3925 - val_beta: 0.0039\n",
      "Epoch 877/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 45.0599 - recon_loss: 4.4586e-04 - KL loss: 15.6339 - beta: 0.0039 - val_loss: 50.8635 - val_recon_loss: 5.3574e-04 - val_KL loss: 15.5053 - val_beta: 0.0039\n",
      "Epoch 878/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 46.6847 - recon_loss: 4.6931e-04 - KL loss: 15.7111 - beta: 0.0039 - val_loss: 46.6702 - val_recon_loss: 4.7749e-04 - val_KL loss: 15.1565 - val_beta: 0.0039\n",
      "Epoch 879/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 44.2705 - recon_loss: 4.3568e-04 - KL loss: 15.5160 - beta: 0.0039 - val_loss: 47.5635 - val_recon_loss: 4.8724e-04 - val_KL loss: 15.4066 - val_beta: 0.0039\n",
      "Epoch 880/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.5361 - recon_loss: 4.4002e-04 - KL loss: 15.4956 - beta: 0.0039 - val_loss: 45.4193 - val_recon_loss: 4.6293e-04 - val_KL loss: 14.8665 - val_beta: 0.0039\n",
      "Epoch 881/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 46.1099 - recon_loss: 4.6487e-04 - KL loss: 15.4293 - beta: 0.0039\n",
      "Epoch 00881: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 46.1099 - recon_loss: 4.6487e-04 - KL loss: 15.4293 - beta: 0.0039 - val_loss: 48.4658 - val_recon_loss: 5.0471e-04 - val_KL loss: 15.1559 - val_beta: 0.0039\n",
      "Epoch 882/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 42.9710 - recon_loss: 4.1732e-04 - KL loss: 15.4282 - beta: 0.0039 - val_loss: 43.5846 - val_recon_loss: 4.3019e-04 - val_KL loss: 15.1926 - val_beta: 0.0039\n",
      "Epoch 883/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 42.2327 - recon_loss: 4.0630e-04 - KL loss: 15.4178 - beta: 0.0039 - val_loss: 49.0239 - val_recon_loss: 5.1078e-04 - val_KL loss: 15.3135 - val_beta: 0.0039\n",
      "Epoch 884/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 42.1417 - recon_loss: 4.0400e-04 - KL loss: 15.4786 - beta: 0.0039 - val_loss: 43.0728 - val_recon_loss: 4.2150e-04 - val_KL loss: 15.2542 - val_beta: 0.0039\n",
      "Epoch 885/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 42.0033 - recon_loss: 4.0186e-04 - KL loss: 15.4811 - beta: 0.0039 - val_loss: 44.3716 - val_recon_loss: 4.4190e-04 - val_KL loss: 15.2071 - val_beta: 0.0039\n",
      "Epoch 886/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 42.0909 - recon_loss: 4.0397e-04 - KL loss: 15.4298 - beta: 0.0039 - val_loss: 47.3135 - val_recon_loss: 4.8331e-04 - val_KL loss: 15.4158 - val_beta: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 887/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 42.6729 - recon_loss: 4.1189e-04 - KL loss: 15.4890 - beta: 0.0039 - val_loss: 46.1739 - val_recon_loss: 4.6698e-04 - val_KL loss: 15.3538 - val_beta: 0.0039\n",
      "Epoch 888/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 42.4580 - recon_loss: 4.0879e-04 - KL loss: 15.4786 - beta: 0.0039 - val_loss: 47.7786 - val_recon_loss: 4.9384e-04 - val_KL loss: 15.1861 - val_beta: 0.0039\n",
      "Epoch 889/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 42.3071 - recon_loss: 4.0763e-04 - KL loss: 15.4040 - beta: 0.0039\n",
      "Epoch 00889: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 42.3069 - recon_loss: 4.0763e-04 - KL loss: 15.4040 - beta: 0.0039 - val_loss: 44.3783 - val_recon_loss: 4.4422e-04 - val_KL loss: 15.0606 - val_beta: 0.0039\n",
      "Epoch 890/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 41.8023 - recon_loss: 3.9935e-04 - KL loss: 15.4458 - beta: 0.0039 - val_loss: 42.8475 - val_recon_loss: 4.1856e-04 - val_KL loss: 15.2231 - val_beta: 0.0039\n",
      "Epoch 891/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 41.7543 - recon_loss: 3.9802e-04 - KL loss: 15.4854 - beta: 0.0039 - val_loss: 44.0679 - val_recon_loss: 4.3900e-04 - val_KL loss: 15.0944 - val_beta: 0.0039\n",
      "Epoch 892/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 41.5012 - recon_loss: 3.9449e-04 - KL loss: 15.4658 - beta: 0.0039 - val_loss: 43.5125 - val_recon_loss: 4.3009e-04 - val_KL loss: 15.1270 - val_beta: 0.0039\n",
      "Epoch 893/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 41.3942 - recon_loss: 3.9353e-04 - KL loss: 15.4217 - beta: 0.0039 - val_loss: 42.0194 - val_recon_loss: 4.0771e-04 - val_KL loss: 15.1113 - val_beta: 0.0039\n",
      "Epoch 894/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 41.2718 - recon_loss: 3.9208e-04 - KL loss: 15.3951 - beta: 0.0039 - val_loss: 42.0915 - val_recon_loss: 4.0865e-04 - val_KL loss: 15.1209 - val_beta: 0.0039\n",
      "Epoch 895/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 41.1156 - recon_loss: 3.8882e-04 - KL loss: 15.4543 - beta: 0.0039 - val_loss: 42.0162 - val_recon_loss: 4.0716e-04 - val_KL loss: 15.1445 - val_beta: 0.0039\n",
      "Epoch 896/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 41.1063 - recon_loss: 3.8859e-04 - KL loss: 15.4599 - beta: 0.0039 - val_loss: 42.7040 - val_recon_loss: 4.1703e-04 - val_KL loss: 15.1808 - val_beta: 0.0039\n",
      "Epoch 897/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 41.3158 - recon_loss: 3.9163e-04 - KL loss: 15.4686 - beta: 0.0039 - val_loss: 46.0504 - val_recon_loss: 4.6712e-04 - val_KL loss: 15.2212 - val_beta: 0.0039\n",
      "Epoch 898/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 41.0048 - recon_loss: 3.8624e-04 - KL loss: 15.5138 - beta: 0.0039 - val_loss: 45.3952 - val_recon_loss: 4.5818e-04 - val_KL loss: 15.1558 - val_beta: 0.0039\n",
      "Epoch 899/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 41.2910 - recon_loss: 3.9114e-04 - KL loss: 15.4765 - beta: 0.0039 - val_loss: 45.4111 - val_recon_loss: 4.5816e-04 - val_KL loss: 15.1734 - val_beta: 0.0039\n",
      "Epoch 900/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 40.9686 - recon_loss: 3.8572e-04 - KL loss: 15.5118 - beta: 0.0039\n",
      "Epoch 00900: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 40.9686 - recon_loss: 3.8572e-04 - KL loss: 15.5118 - beta: 0.0039 - val_loss: 44.2058 - val_recon_loss: 4.4001e-04 - val_KL loss: 15.1658 - val_beta: 0.0039\n",
      "Epoch 901/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 40.8809 - recon_loss: 3.8565e-04 - KL loss: 15.4288 - beta: 0.0039 - val_loss: 43.5743 - val_recon_loss: 4.3030e-04 - val_KL loss: 15.1751 - val_beta: 0.0039\n",
      "Epoch 902/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 40.9448 - recon_loss: 3.8625e-04 - KL loss: 15.4529 - beta: 0.0039 - val_loss: 43.8913 - val_recon_loss: 4.3475e-04 - val_KL loss: 15.1987 - val_beta: 0.0039\n",
      "Epoch 903/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 40.9526 - recon_loss: 3.8584e-04 - KL loss: 15.4875 - beta: 0.0039 - val_loss: 43.6027 - val_recon_loss: 4.3054e-04 - val_KL loss: 15.1878 - val_beta: 0.0039\n",
      "Epoch 904/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 40.7830 - recon_loss: 3.8321e-04 - KL loss: 15.4916 - beta: 0.0039 - val_loss: 43.7243 - val_recon_loss: 4.3147e-04 - val_KL loss: 15.2480 - val_beta: 0.0039\n",
      "Epoch 905/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 40.6991 - recon_loss: 3.8198e-04 - KL loss: 15.4893 - beta: 0.0039\n",
      "Epoch 00905: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 40.6992 - recon_loss: 3.8198e-04 - KL loss: 15.4892 - beta: 0.0039 - val_loss: 44.0238 - val_recon_loss: 4.3748e-04 - val_KL loss: 15.1510 - val_beta: 0.0039\n",
      "Epoch 905/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33.4139 - recon_loss: 4.3026e-04 - KL loss: 14.1551 - beta: 0.0047 - val_loss: 33.7726 - val_recon_loss: 4.4833e-04 - val_KL loss: 13.7050 - val_beta: 0.0047\n",
      "Epoch 906/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 34.1274 - recon_loss: 4.5057e-04 - KL loss: 13.9597 - beta: 0.0047 - val_loss: 35.6284 - val_recon_loss: 4.9181e-04 - val_KL loss: 13.6148 - val_beta: 0.0047\n",
      "Epoch 907/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.3245 - recon_loss: 4.9936e-04 - KL loss: 13.9729 - beta: 0.0047 - val_loss: 35.4392 - val_recon_loss: 4.8979e-04 - val_KL loss: 13.5157 - val_beta: 0.0047\n",
      "Epoch 908/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 34.9336 - recon_loss: 4.6858e-04 - KL loss: 13.9598 - beta: 0.0047 - val_loss: 35.5863 - val_recon_loss: 4.8792e-04 - val_KL loss: 13.7467 - val_beta: 0.0047\n",
      "Epoch 909/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 35.2932 - recon_loss: 4.7463e-04 - KL loss: 14.0486 - beta: 0.0047 - val_loss: 34.5690 - val_recon_loss: 4.7043e-04 - val_KL loss: 13.5124 - val_beta: 0.0047\n",
      "Epoch 910/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 34.0120 - recon_loss: 4.5023e-04 - KL loss: 13.8594 - beta: 0.0047\n",
      "Epoch 00910: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 34.0122 - recon_loss: 4.5023e-04 - KL loss: 13.8594 - beta: 0.0047 - val_loss: 37.1872 - val_recon_loss: 5.2249e-04 - val_KL loss: 13.8001 - val_beta: 0.0047\n",
      "Epoch 911/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 35.2076 - recon_loss: 4.6866e-04 - KL loss: 14.2302 - beta: 0.0047 - val_loss: 35.2310 - val_recon_loss: 4.7617e-04 - val_KL loss: 13.9173 - val_beta: 0.0047\n",
      "Epoch 912/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 33.6444 - recon_loss: 4.3709e-04 - KL loss: 14.0799 - beta: 0.0047 - val_loss: 34.8453 - val_recon_loss: 4.6989e-04 - val_KL loss: 13.8125 - val_beta: 0.0047\n",
      "Epoch 913/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33.4430 - recon_loss: 4.3216e-04 - KL loss: 14.0993 - beta: 0.0047 - val_loss: 33.7810 - val_recon_loss: 4.5269e-04 - val_KL loss: 13.5184 - val_beta: 0.0047\n",
      "Epoch 914/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33.1680 - recon_loss: 4.2853e-04 - KL loss: 13.9865 - beta: 0.0047 - val_loss: 33.4149 - val_recon_loss: 4.4377e-04 - val_KL loss: 13.5512 - val_beta: 0.0047\n",
      "Epoch 915/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.9185 - recon_loss: 4.2392e-04 - KL loss: 13.9436 - beta: 0.0047 - val_loss: 33.9711 - val_recon_loss: 4.5548e-04 - val_KL loss: 13.5833 - val_beta: 0.0047\n",
      "Epoch 916/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.8912 - recon_loss: 4.2351e-04 - KL loss: 13.9344 - beta: 0.0047 - val_loss: 34.0102 - val_recon_loss: 4.5643e-04 - val_KL loss: 13.5802 - val_beta: 0.0047\n",
      "Epoch 917/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.7240 - recon_loss: 4.2008e-04 - KL loss: 13.9210 - beta: 0.0047 - val_loss: 33.9946 - val_recon_loss: 4.5245e-04 - val_KL loss: 13.7427 - val_beta: 0.0047\n",
      "Epoch 918/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.7374 - recon_loss: 4.1978e-04 - KL loss: 13.9476 - beta: 0.0047 - val_loss: 34.0450 - val_recon_loss: 4.5665e-04 - val_KL loss: 13.6052 - val_beta: 0.0047\n",
      "Epoch 919/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 32.7170 - recon_loss: 4.1977e-04 - KL loss: 13.9279 - beta: 0.0047\n",
      "Epoch 00919: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.7169 - recon_loss: 4.1977e-04 - KL loss: 13.9279 - beta: 0.0047 - val_loss: 33.6135 - val_recon_loss: 4.4625e-04 - val_KL loss: 13.6393 - val_beta: 0.0047\n",
      "Epoch 920/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.4490 - recon_loss: 4.1302e-04 - KL loss: 13.9620 - beta: 0.0047 - val_loss: 34.6289 - val_recon_loss: 4.6784e-04 - val_KL loss: 13.6881 - val_beta: 0.0047\n",
      "Epoch 921/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.4042 - recon_loss: 4.1259e-04 - KL loss: 13.9364 - beta: 0.0047 - val_loss: 33.8328 - val_recon_loss: 4.5112e-04 - val_KL loss: 13.6401 - val_beta: 0.0047\n",
      "Epoch 922/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.3295 - recon_loss: 4.1141e-04 - KL loss: 13.9147 - beta: 0.0047 - val_loss: 34.3647 - val_recon_loss: 4.6056e-04 - val_KL loss: 13.7496 - val_beta: 0.0047\n",
      "Epoch 923/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.4876 - recon_loss: 4.1318e-04 - KL loss: 13.9934 - beta: 0.0047 - val_loss: 34.1246 - val_recon_loss: 4.5755e-04 - val_KL loss: 13.6446 - val_beta: 0.0047\n",
      "Epoch 924/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 32.2520 - recon_loss: 4.0893e-04 - KL loss: 13.9480 - beta: 0.0047 - val_loss: 32.9483 - val_recon_loss: 4.3111e-04 - val_KL loss: 13.6514 - val_beta: 0.0047\n",
      "Epoch 925/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.4851 - recon_loss: 4.1335e-04 - KL loss: 13.9832 - beta: 0.0047 - val_loss: 33.2340 - val_recon_loss: 4.3554e-04 - val_KL loss: 13.7390 - val_beta: 0.0047\n",
      "Epoch 926/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.4456 - recon_loss: 4.1144e-04 - KL loss: 14.0292 - beta: 0.0047 - val_loss: 34.2470 - val_recon_loss: 4.6111e-04 - val_KL loss: 13.6075 - val_beta: 0.0047\n",
      "Epoch 927/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.0700 - recon_loss: 4.0530e-04 - KL loss: 13.9285 - beta: 0.0047 - val_loss: 33.2868 - val_recon_loss: 4.3989e-04 - val_KL loss: 13.5970 - val_beta: 0.0047\n",
      "Epoch 928/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.2355 - recon_loss: 4.0854e-04 - KL loss: 13.9492 - beta: 0.0047 - val_loss: 35.4488 - val_recon_loss: 4.8808e-04 - val_KL loss: 13.6021 - val_beta: 0.0047\n",
      "Epoch 929/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 32.3195 - recon_loss: 4.1104e-04 - KL loss: 13.9210 - beta: 0.0047\n",
      "Epoch 00929: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.3195 - recon_loss: 4.1104e-04 - KL loss: 13.9210 - beta: 0.0047 - val_loss: 33.3199 - val_recon_loss: 4.3991e-04 - val_KL loss: 13.6292 - val_beta: 0.0047\n",
      "Epoch 930/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.3824 - recon_loss: 4.1113e-04 - KL loss: 13.9801 - beta: 0.0047 - val_loss: 33.2115 - val_recon_loss: 4.3539e-04 - val_KL loss: 13.7233 - val_beta: 0.0047\n",
      "Epoch 931/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 32.2970 - recon_loss: 4.0858e-04 - KL loss: 14.0088 - beta: 0.0047 - val_loss: 35.2814 - val_recon_loss: 4.8233e-04 - val_KL loss: 13.6919 - val_beta: 0.0047\n",
      "Epoch 932/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.2701 - recon_loss: 4.0928e-04 - KL loss: 13.9504 - beta: 0.0047 - val_loss: 33.1875 - val_recon_loss: 4.3502e-04 - val_KL loss: 13.7157 - val_beta: 0.0047\n",
      "Epoch 933/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32.1350 - recon_loss: 4.0571e-04 - KL loss: 13.9751 - beta: 0.0047 - val_loss: 34.1847 - val_recon_loss: 4.5689e-04 - val_KL loss: 13.7339 - val_beta: 0.0047\n",
      "Epoch 934/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31.9037 - recon_loss: 4.0118e-04 - KL loss: 13.9464 - beta: 0.0047\n",
      "Epoch 00934: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 31.9038 - recon_loss: 4.0119e-04 - KL loss: 13.9464 - beta: 0.0047 - val_loss: 33.7469 - val_recon_loss: 4.4649e-04 - val_KL loss: 13.7615 - val_beta: 0.0047\n",
      "Epoch 934/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.7841 - recon_loss: 4.6583e-04 - KL loss: 12.6430 - beta: 0.0057 - val_loss: 27.7124 - val_recon_loss: 5.1797e-04 - val_KL loss: 11.9885 - val_beta: 0.0057\n",
      "Epoch 935/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28.2999 - recon_loss: 5.1292e-04 - KL loss: 12.7292 - beta: 0.0057 - val_loss: 30.0846 - val_recon_loss: 5.7133e-04 - val_KL loss: 12.7407 - val_beta: 0.0057\n",
      "Epoch 936/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28.9053 - recon_loss: 5.2762e-04 - KL loss: 12.8884 - beta: 0.0057 - val_loss: 31.0312 - val_recon_loss: 5.9346e-04 - val_KL loss: 13.0156 - val_beta: 0.0057\n",
      "Epoch 937/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 29.4319 - recon_loss: 5.4510e-04 - KL loss: 12.8842 - beta: 0.0057 - val_loss: 30.5570 - val_recon_loss: 5.9538e-04 - val_KL loss: 12.4830 - val_beta: 0.0057\n",
      "Epoch 938/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28.5649 - recon_loss: 5.2137e-04 - KL loss: 12.7376 - beta: 0.0057 - val_loss: 27.8484 - val_recon_loss: 5.1420e-04 - val_KL loss: 12.2389 - val_beta: 0.0057\n",
      "Epoch 939/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 27.9937 - recon_loss: 5.0876e-04 - KL loss: 12.5493 - beta: 0.0057\n",
      "Epoch 00939: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 27.9937 - recon_loss: 5.0876e-04 - KL loss: 12.5493 - beta: 0.0057 - val_loss: 28.1905 - val_recon_loss: 5.2092e-04 - val_KL loss: 12.3769 - val_beta: 0.0057\n",
      "Epoch 940/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 27.4801 - recon_loss: 4.9305e-04 - KL loss: 12.5125 - beta: 0.0057 - val_loss: 28.4783 - val_recon_loss: 5.3473e-04 - val_KL loss: 12.2456 - val_beta: 0.0057\n",
      "Epoch 941/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.7806 - recon_loss: 4.7183e-04 - KL loss: 12.4573 - beta: 0.0057 - val_loss: 28.5729 - val_recon_loss: 5.4094e-04 - val_KL loss: 12.1516 - val_beta: 0.0057\n",
      "Epoch 942/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.5950 - recon_loss: 4.6579e-04 - KL loss: 12.4549 - beta: 0.0057 - val_loss: 27.6492 - val_recon_loss: 5.0479e-04 - val_KL loss: 12.3254 - val_beta: 0.0057\n",
      "Epoch 943/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 26.8033 - recon_loss: 4.7116e-04 - KL loss: 12.5003 - beta: 0.0057 - val_loss: 28.6541 - val_recon_loss: 5.4441e-04 - val_KL loss: 12.1275 - val_beta: 0.0057\n",
      "Epoch 944/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.5155 - recon_loss: 4.6403e-04 - KL loss: 12.4290 - beta: 0.0057 - val_loss: 26.8015 - val_recon_loss: 4.7941e-04 - val_KL loss: 12.2480 - val_beta: 0.0057\n",
      "Epoch 945/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.6017 - recon_loss: 4.6638e-04 - KL loss: 12.4438 - beta: 0.0057 - val_loss: 27.2761 - val_recon_loss: 4.9763e-04 - val_KL loss: 12.1695 - val_beta: 0.0057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 946/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.3714 - recon_loss: 4.5840e-04 - KL loss: 12.4556 - beta: 0.0057 - val_loss: 26.3813 - val_recon_loss: 4.6807e-04 - val_KL loss: 12.1720 - val_beta: 0.0057\n",
      "Epoch 947/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.5082 - recon_loss: 4.6287e-04 - KL loss: 12.4568 - beta: 0.0057 - val_loss: 28.4679 - val_recon_loss: 5.3647e-04 - val_KL loss: 12.1823 - val_beta: 0.0057\n",
      "Epoch 948/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.3494 - recon_loss: 4.5931e-04 - KL loss: 12.4061 - beta: 0.0057 - val_loss: 28.6103 - val_recon_loss: 5.4404e-04 - val_KL loss: 12.0950 - val_beta: 0.0057\n",
      "Epoch 949/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.4502 - recon_loss: 4.6128e-04 - KL loss: 12.4470 - beta: 0.0057 - val_loss: 27.9471 - val_recon_loss: 5.2021e-04 - val_KL loss: 12.1551 - val_beta: 0.0057\n",
      "Epoch 950/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.3661 - recon_loss: 4.5893e-04 - KL loss: 12.4344 - beta: 0.0057 - val_loss: 28.0462 - val_recon_loss: 5.2146e-04 - val_KL loss: 12.2162 - val_beta: 0.0057\n",
      "Epoch 951/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 26.4852 - recon_loss: 4.6133e-04 - KL loss: 12.4806 - beta: 0.0057\n",
      "Epoch 00951: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.4851 - recon_loss: 4.6133e-04 - KL loss: 12.4806 - beta: 0.0057 - val_loss: 26.7667 - val_recon_loss: 4.7971e-04 - val_KL loss: 12.2041 - val_beta: 0.0057\n",
      "Epoch 952/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.2037 - recon_loss: 4.5243e-04 - KL loss: 12.4694 - beta: 0.0057 - val_loss: 27.0738 - val_recon_loss: 4.8862e-04 - val_KL loss: 12.2408 - val_beta: 0.0057\n",
      "Epoch 953/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.1766 - recon_loss: 4.5072e-04 - KL loss: 12.4943 - beta: 0.0057 - val_loss: 27.7174 - val_recon_loss: 5.1100e-04 - val_KL loss: 12.2049 - val_beta: 0.0057\n",
      "Epoch 954/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.1850 - recon_loss: 4.5150e-04 - KL loss: 12.4788 - beta: 0.0057 - val_loss: 27.2030 - val_recon_loss: 4.9322e-04 - val_KL loss: 12.2303 - val_beta: 0.0057\n",
      "Epoch 955/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 26.2820 - recon_loss: 4.5330e-04 - KL loss: 12.5211 - beta: 0.0057 - val_loss: 28.0730 - val_recon_loss: 5.2104e-04 - val_KL loss: 12.2556 - val_beta: 0.0057\n",
      "Epoch 956/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 26.2845 - recon_loss: 4.5405e-04 - KL loss: 12.5008 - beta: 0.0057\n",
      "Epoch 00956: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 26.2844 - recon_loss: 4.5405e-04 - KL loss: 12.5008 - beta: 0.0057 - val_loss: 27.4617 - val_recon_loss: 5.0301e-04 - val_KL loss: 12.1919 - val_beta: 0.0057\n",
      "Epoch 956/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.0903 - recon_loss: 5.2296e-04 - KL loss: 11.3235 - beta: 0.0070 - val_loss: 22.9805 - val_recon_loss: 5.8604e-04 - val_KL loss: 10.9149 - val_beta: 0.0070\n",
      "Epoch 957/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.9958 - recon_loss: 5.6434e-04 - KL loss: 11.3770 - beta: 0.0070 - val_loss: 23.9726 - val_recon_loss: 6.3319e-04 - val_KL loss: 10.9364 - val_beta: 0.0070\n",
      "Epoch 958/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.6743 - recon_loss: 5.5884e-04 - KL loss: 11.1687 - beta: 0.0070 - val_loss: 23.1335 - val_recon_loss: 6.0272e-04 - val_KL loss: 10.7245 - val_beta: 0.0070\n",
      "Epoch 959/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 23.5450 - recon_loss: 5.9751e-04 - KL loss: 11.2433 - beta: 0.0070 - val_loss: 23.6963 - val_recon_loss: 6.2082e-04 - val_KL loss: 10.9146 - val_beta: 0.0070\n",
      "Epoch 960/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23.0479 - recon_loss: 5.7545e-04 - KL loss: 11.2003 - beta: 0.0070 - val_loss: 24.1512 - val_recon_loss: 6.3039e-04 - val_KL loss: 11.1724 - val_beta: 0.0070\n",
      "Epoch 961/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.8893 - recon_loss: 5.6702e-04 - KL loss: 11.2154 - beta: 0.0070 - val_loss: 22.8305 - val_recon_loss: 5.8086e-04 - val_KL loss: 10.8715 - val_beta: 0.0070\n",
      "Epoch 962/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.4354 - recon_loss: 5.5173e-04 - KL loss: 11.0761 - beta: 0.0070 - val_loss: 23.0335 - val_recon_loss: 5.9290e-04 - val_KL loss: 10.8266 - val_beta: 0.0070\n",
      "Epoch 963/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.6582 - recon_loss: 5.5988e-04 - KL loss: 11.1312 - beta: 0.0070 - val_loss: 23.6792 - val_recon_loss: 6.1025e-04 - val_KL loss: 11.1150 - val_beta: 0.0070\n",
      "Epoch 964/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23.7416 - recon_loss: 6.0769e-04 - KL loss: 11.2303 - beta: 0.0070 - val_loss: 26.0679 - val_recon_loss: 7.3023e-04 - val_KL loss: 11.0337 - val_beta: 0.0070\n",
      "Epoch 965/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 23.0190 - recon_loss: 5.8100e-04 - KL loss: 11.0572 - beta: 0.0070 - val_loss: 24.5186 - val_recon_loss: 6.6093e-04 - val_KL loss: 10.9112 - val_beta: 0.0070\n",
      "Epoch 966/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 22.6707 - recon_loss: 5.6461e-04 - KL loss: 11.0464 - beta: 0.0070\n",
      "Epoch 00966: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 22.6707 - recon_loss: 5.6461e-04 - KL loss: 11.0463 - beta: 0.0070 - val_loss: 23.3762 - val_recon_loss: 6.1510e-04 - val_KL loss: 10.7124 - val_beta: 0.0070\n",
      "Epoch 967/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.5175 - recon_loss: 5.5816e-04 - KL loss: 11.0259 - beta: 0.0070 - val_loss: 22.2813 - val_recon_loss: 5.5763e-04 - val_KL loss: 10.8006 - val_beta: 0.0070\n",
      "Epoch 968/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.9912 - recon_loss: 5.3184e-04 - KL loss: 11.0416 - beta: 0.0070 - val_loss: 22.1664 - val_recon_loss: 5.5719e-04 - val_KL loss: 10.6947 - val_beta: 0.0070\n",
      "Epoch 969/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.9406 - recon_loss: 5.2722e-04 - KL loss: 11.0860 - beta: 0.0070 - val_loss: 23.0871 - val_recon_loss: 5.9414e-04 - val_KL loss: 10.8548 - val_beta: 0.0070\n",
      "Epoch 970/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 22.0261 - recon_loss: 5.3240e-04 - KL loss: 11.0647 - beta: 0.0070 - val_loss: 23.3289 - val_recon_loss: 6.0312e-04 - val_KL loss: 10.9116 - val_beta: 0.0070\n",
      "Epoch 971/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.9083 - recon_loss: 5.2692e-04 - KL loss: 11.0600 - beta: 0.0070 - val_loss: 22.2464 - val_recon_loss: 5.5562e-04 - val_KL loss: 10.8072 - val_beta: 0.0070\n",
      "Epoch 972/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.8064 - recon_loss: 5.2136e-04 - KL loss: 11.0724 - beta: 0.0070 - val_loss: 21.8292 - val_recon_loss: 5.3450e-04 - val_KL loss: 10.8247 - val_beta: 0.0070\n",
      "Epoch 973/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 21.8192 - recon_loss: 5.2120e-04 - KL loss: 11.0886 - beta: 0.0070 - val_loss: 22.2717 - val_recon_loss: 5.6253e-04 - val_KL loss: 10.6903 - val_beta: 0.0070\n",
      "Epoch 974/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.7691 - recon_loss: 5.2049e-04 - KL loss: 11.0531 - beta: 0.0070 - val_loss: 22.2616 - val_recon_loss: 5.6312e-04 - val_KL loss: 10.6679 - val_beta: 0.0070\n",
      "Epoch 975/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.9129 - recon_loss: 5.2616e-04 - KL loss: 11.0801 - beta: 0.0070 - val_loss: 21.8955 - val_recon_loss: 5.4198e-04 - val_KL loss: 10.7370 - val_beta: 0.0070\n",
      "Epoch 976/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.7760 - recon_loss: 5.2076e-04 - KL loss: 11.0544 - beta: 0.0070 - val_loss: 23.1341 - val_recon_loss: 5.9812e-04 - val_KL loss: 10.8197 - val_beta: 0.0070\n",
      "Epoch 977/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 21.8953 - recon_loss: 5.2631e-04 - KL loss: 11.0594 - beta: 0.0070\n",
      "Epoch 00977: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.8953 - recon_loss: 5.2632e-04 - KL loss: 11.0594 - beta: 0.0070 - val_loss: 21.8777 - val_recon_loss: 5.3868e-04 - val_KL loss: 10.7872 - val_beta: 0.0070\n",
      "Epoch 978/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.6570 - recon_loss: 5.1582e-04 - KL loss: 11.0372 - beta: 0.0070 - val_loss: 22.9128 - val_recon_loss: 5.8713e-04 - val_KL loss: 10.8248 - val_beta: 0.0070\n",
      "Epoch 979/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.5384 - recon_loss: 5.0980e-04 - KL loss: 11.0425 - beta: 0.0070 - val_loss: 21.7093 - val_recon_loss: 5.3088e-04 - val_KL loss: 10.7793 - val_beta: 0.0070\n",
      "Epoch 980/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.5644 - recon_loss: 5.1104e-04 - KL loss: 11.0429 - beta: 0.0070 - val_loss: 22.2232 - val_recon_loss: 5.5930e-04 - val_KL loss: 10.7083 - val_beta: 0.0070\n",
      "Epoch 981/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.5957 - recon_loss: 5.1250e-04 - KL loss: 11.0441 - beta: 0.0070 - val_loss: 21.9575 - val_recon_loss: 5.4419e-04 - val_KL loss: 10.7535 - val_beta: 0.0070\n",
      "Epoch 982/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.5219 - recon_loss: 5.0890e-04 - KL loss: 11.0444 - beta: 0.0070 - val_loss: 21.8163 - val_recon_loss: 5.3519e-04 - val_KL loss: 10.7975 - val_beta: 0.0070\n",
      "Epoch 983/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.5175 - recon_loss: 5.0840e-04 - KL loss: 11.0504 - beta: 0.0070 - val_loss: 22.1015 - val_recon_loss: 5.4616e-04 - val_KL loss: 10.8571 - val_beta: 0.0070\n",
      "Epoch 984/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 21.4701 - recon_loss: 5.0441e-04 - KL loss: 11.0850 - beta: 0.0070\n",
      "Epoch 00984: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 21.4701 - recon_loss: 5.0442e-04 - KL loss: 11.0850 - beta: 0.0070 - val_loss: 22.8476 - val_recon_loss: 5.8107e-04 - val_KL loss: 10.8843 - val_beta: 0.0070\n",
      "Epoch 985/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.4738 - recon_loss: 5.0645e-04 - KL loss: 11.0468 - beta: 0.0070 - val_loss: 22.1977 - val_recon_loss: 5.5348e-04 - val_KL loss: 10.8026 - val_beta: 0.0070\n",
      "Epoch 986/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.4574 - recon_loss: 5.0603e-04 - KL loss: 11.0392 - beta: 0.0070 - val_loss: 22.3679 - val_recon_loss: 5.6037e-04 - val_KL loss: 10.8308 - val_beta: 0.0070\n",
      "Epoch 987/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.5256 - recon_loss: 5.0776e-04 - KL loss: 11.0716 - beta: 0.0070 - val_loss: 21.6636 - val_recon_loss: 5.2719e-04 - val_KL loss: 10.8097 - val_beta: 0.0070\n",
      "Epoch 988/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.4637 - recon_loss: 5.0519e-04 - KL loss: 11.0628 - beta: 0.0070 - val_loss: 21.6431 - val_recon_loss: 5.2654e-04 - val_KL loss: 10.8025 - val_beta: 0.0070\n",
      "Epoch 989/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.3564 - recon_loss: 5.0147e-04 - KL loss: 11.0319 - beta: 0.0070 - val_loss: 22.2802 - val_recon_loss: 5.5873e-04 - val_KL loss: 10.7769 - val_beta: 0.0070\n",
      "Epoch 990/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.3666 - recon_loss: 5.0165e-04 - KL loss: 11.0386 - beta: 0.0070 - val_loss: 21.9263 - val_recon_loss: 5.4172e-04 - val_KL loss: 10.7731 - val_beta: 0.0070\n",
      "Epoch 991/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.3913 - recon_loss: 5.0320e-04 - KL loss: 11.0313 - beta: 0.0070 - val_loss: 21.2696 - val_recon_loss: 5.0935e-04 - val_KL loss: 10.7831 - val_beta: 0.0070\n",
      "Epoch 992/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.3745 - recon_loss: 5.0146e-04 - KL loss: 11.0503 - beta: 0.0070 - val_loss: 21.6517 - val_recon_loss: 5.2749e-04 - val_KL loss: 10.7915 - val_beta: 0.0070\n",
      "Epoch 993/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.3736 - recon_loss: 5.0277e-04 - KL loss: 11.0224 - beta: 0.0070 - val_loss: 21.9955 - val_recon_loss: 5.4564e-04 - val_KL loss: 10.7616 - val_beta: 0.0070\n",
      "Epoch 994/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.3376 - recon_loss: 5.0199e-04 - KL loss: 11.0024 - beta: 0.0070 - val_loss: 21.5738 - val_recon_loss: 5.2381e-04 - val_KL loss: 10.7893 - val_beta: 0.0070\n",
      "Epoch 995/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.4567 - recon_loss: 5.0426e-04 - KL loss: 11.0749 - beta: 0.0070 - val_loss: 22.0973 - val_recon_loss: 5.5040e-04 - val_KL loss: 10.7655 - val_beta: 0.0070\n",
      "Epoch 996/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 21.5226 - recon_loss: 5.0859e-04 - KL loss: 11.0516 - beta: 0.0070\n",
      "Epoch 00996: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.5225 - recon_loss: 5.0858e-04 - KL loss: 11.0516 - beta: 0.0070 - val_loss: 22.2139 - val_recon_loss: 5.5440e-04 - val_KL loss: 10.7997 - val_beta: 0.0070\n",
      "Epoch 997/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.4065 - recon_loss: 5.0382e-04 - KL loss: 11.0337 - beta: 0.0070 - val_loss: 23.1215 - val_recon_loss: 5.9882e-04 - val_KL loss: 10.7927 - val_beta: 0.0070\n",
      "Epoch 998/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.3924 - recon_loss: 5.0436e-04 - KL loss: 11.0084 - beta: 0.0070 - val_loss: 22.6811 - val_recon_loss: 5.7642e-04 - val_KL loss: 10.8137 - val_beta: 0.0070\n",
      "Epoch 999/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.3670 - recon_loss: 5.0154e-04 - KL loss: 11.0411 - beta: 0.0070 - val_loss: 22.3559 - val_recon_loss: 5.6055e-04 - val_KL loss: 10.8151 - val_beta: 0.0070\n",
      "Epoch 1000/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21.3156 - recon_loss: 5.0011e-04 - KL loss: 11.0192 - beta: 0.0070 - val_loss: 22.1783 - val_recon_loss: 5.5281e-04 - val_KL loss: 10.7969 - val_beta: 0.0070\n",
      "Epoch 1001/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 21.4524 - recon_loss: 5.0579e-04 - KL loss: 11.0391 - beta: 0.0070\n",
      "Epoch 01001: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21.4524 - recon_loss: 5.0579e-04 - KL loss: 11.0391 - beta: 0.0070 - val_loss: 22.3272 - val_recon_loss: 5.5986e-04 - val_KL loss: 10.8006 - val_beta: 0.0070\n",
      "Epoch 1001/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18.2119 - recon_loss: 5.9197e-04 - KL loss: 9.9461 - beta: 0.0085 - val_loss: 17.9682 - val_recon_loss: 6.0203e-04 - val_KL loss: 9.5619 - val_beta: 0.0085\n",
      "Epoch 1002/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18.4854 - recon_loss: 6.2160e-04 - KL loss: 9.8059 - beta: 0.0085 - val_loss: 19.1972 - val_recon_loss: 6.8782e-04 - val_KL loss: 9.5930 - val_beta: 0.0085\n",
      "Epoch 1003/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18.7035 - recon_loss: 6.4383e-04 - KL loss: 9.7136 - beta: 0.0085 - val_loss: 17.9345 - val_recon_loss: 6.0533e-04 - val_KL loss: 9.4822 - val_beta: 0.0085\n",
      "Epoch 1004/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 19.1225 - recon_loss: 6.7285e-04 - KL loss: 9.7274 - beta: 0.0085 - val_loss: 18.4542 - val_recon_loss: 6.3703e-04 - val_KL loss: 9.5592 - val_beta: 0.0085\n",
      "Epoch 1005/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18.4610 - recon_loss: 6.3176e-04 - KL loss: 9.6395 - beta: 0.0085 - val_loss: 18.9201 - val_recon_loss: 6.7622e-04 - val_KL loss: 9.4779 - val_beta: 0.0085\n",
      "Epoch 1006/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18.6294 - recon_loss: 6.4417e-04 - KL loss: 9.6347 - beta: 0.0085 - val_loss: 18.3163 - val_recon_loss: 6.2928e-04 - val_KL loss: 9.5295 - val_beta: 0.0085\n",
      "Epoch 1007/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18.7083 - recon_loss: 6.5409e-04 - KL loss: 9.5751 - beta: 0.0085 - val_loss: 17.7962 - val_recon_loss: 5.9647e-04 - val_KL loss: 9.4676 - val_beta: 0.0085\n",
      "Epoch 1008/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18.5926 - recon_loss: 6.4638e-04 - KL loss: 9.5671 - beta: 0.0085 - val_loss: 18.4384 - val_recon_loss: 6.4877e-04 - val_KL loss: 9.3795 - val_beta: 0.0085\n",
      "Epoch 1009/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18.8337 - recon_loss: 6.6335e-04 - KL loss: 9.5713 - beta: 0.0085 - val_loss: 22.3754 - val_recon_loss: 9.3599e-04 - val_KL loss: 9.3061 - val_beta: 0.0085\n",
      "Epoch 1010/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 21.9209 - recon_loss: 8.7216e-04 - KL loss: 9.7427 - beta: 0.0085 - val_loss: 18.4494 - val_recon_loss: 6.5232e-04 - val_KL loss: 9.3411 - val_beta: 0.0085\n",
      "Epoch 1011/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20.0380 - recon_loss: 7.4100e-04 - KL loss: 9.6914 - beta: 0.0085 - val_loss: 18.8584 - val_recon_loss: 6.8338e-04 - val_KL loss: 9.3162 - val_beta: 0.0085\n",
      "Epoch 1012/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 19.4291 - recon_loss: 7.0524e-04 - KL loss: 9.5818 - beta: 0.0085\n",
      "Epoch 01012: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 19.4290 - recon_loss: 7.0523e-04 - KL loss: 9.5818 - beta: 0.0085 - val_loss: 18.8270 - val_recon_loss: 6.7174e-04 - val_KL loss: 9.4474 - val_beta: 0.0085\n",
      "Epoch 1013/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18.7553 - recon_loss: 6.5336e-04 - KL loss: 9.6323 - beta: 0.0085 - val_loss: 18.3899 - val_recon_loss: 6.3789e-04 - val_KL loss: 9.4830 - val_beta: 0.0085\n",
      "Epoch 1014/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18.4779 - recon_loss: 6.3701e-04 - KL loss: 9.5833 - beta: 0.0085 - val_loss: 17.8777 - val_recon_loss: 6.0037e-04 - val_KL loss: 9.4947 - val_beta: 0.0085\n",
      "Epoch 1015/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 18.3861 - recon_loss: 6.2943e-04 - KL loss: 9.5972 - beta: 0.0085 - val_loss: 18.1585 - val_recon_loss: 6.2565e-04 - val_KL loss: 9.4224 - val_beta: 0.0085\n",
      "Epoch 1016/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18.4133 - recon_loss: 6.3272e-04 - KL loss: 9.5785 - beta: 0.0085 - val_loss: 17.7310 - val_recon_loss: 5.9882e-04 - val_KL loss: 9.3696 - val_beta: 0.0085\n",
      "Epoch 1017/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18.1860 - recon_loss: 6.1854e-04 - KL loss: 9.5493 - beta: 0.0085 - val_loss: 17.5044 - val_recon_loss: 5.7195e-04 - val_KL loss: 9.5182 - val_beta: 0.0085\n",
      "Epoch 1018/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18.2035 - recon_loss: 6.1920e-04 - KL loss: 9.5574 - beta: 0.0085 - val_loss: 17.7355 - val_recon_loss: 5.9391e-04 - val_KL loss: 9.4428 - val_beta: 0.0085\n",
      "Epoch 1019/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18.1998 - recon_loss: 6.1796e-04 - KL loss: 9.5711 - beta: 0.0085 - val_loss: 17.8053 - val_recon_loss: 6.0152e-04 - val_KL loss: 9.4062 - val_beta: 0.0085\n",
      "Epoch 1020/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18.1129 - recon_loss: 6.1155e-04 - KL loss: 9.5736 - beta: 0.0085 - val_loss: 17.5210 - val_recon_loss: 5.7386e-04 - val_KL loss: 9.5081 - val_beta: 0.0085\n",
      "Epoch 1021/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18.0924 - recon_loss: 6.1008e-04 - KL loss: 9.5738 - beta: 0.0085 - val_loss: 17.8089 - val_recon_loss: 5.9899e-04 - val_KL loss: 9.4451 - val_beta: 0.0085\n",
      "Epoch 1022/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18.0461 - recon_loss: 6.0560e-04 - KL loss: 9.5900 - beta: 0.0085\n",
      "Epoch 01022: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18.0461 - recon_loss: 6.0560e-04 - KL loss: 9.5900 - beta: 0.0085 - val_loss: 17.7838 - val_recon_loss: 6.0172e-04 - val_KL loss: 9.3819 - val_beta: 0.0085\n",
      "Epoch 1023/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17.9897 - recon_loss: 6.0260e-04 - KL loss: 9.5755 - beta: 0.0085 - val_loss: 17.6596 - val_recon_loss: 5.9005e-04 - val_KL loss: 9.4207 - val_beta: 0.0085\n",
      "Epoch 1024/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17.9483 - recon_loss: 5.9896e-04 - KL loss: 9.5849 - beta: 0.0085 - val_loss: 17.8015 - val_recon_loss: 6.0012e-04 - val_KL loss: 9.4220 - val_beta: 0.0085\n",
      "Epoch 1025/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17.9195 - recon_loss: 5.9632e-04 - KL loss: 9.5930 - beta: 0.0085 - val_loss: 17.4562 - val_recon_loss: 5.7811e-04 - val_KL loss: 9.3840 - val_beta: 0.0085\n",
      "Epoch 1026/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17.9099 - recon_loss: 5.9496e-04 - KL loss: 9.6023 - beta: 0.0085 - val_loss: 18.2800 - val_recon_loss: 6.3404e-04 - val_KL loss: 9.4267 - val_beta: 0.0085\n",
      "Epoch 1027/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17.9343 - recon_loss: 5.9659e-04 - KL loss: 9.6041 - beta: 0.0085 - val_loss: 17.9980 - val_recon_loss: 6.1326e-04 - val_KL loss: 9.4349 - val_beta: 0.0085\n",
      "Epoch 1028/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17.8827 - recon_loss: 5.9478e-04 - KL loss: 9.5777 - beta: 0.0085 - val_loss: 17.6077 - val_recon_loss: 5.8889e-04 - val_KL loss: 9.3849 - val_beta: 0.0085\n",
      "Epoch 1029/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17.8538 - recon_loss: 5.9188e-04 - KL loss: 9.5893 - beta: 0.0085 - val_loss: 17.7183 - val_recon_loss: 5.9525e-04 - val_KL loss: 9.4068 - val_beta: 0.0085\n",
      "Epoch 1030/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17.8884 - recon_loss: 5.9419e-04 - KL loss: 9.5917 - beta: 0.0085 ETA: 0s - loss: 17.8884 - recon_loss: 5.9419e-04 - KL los\n",
      "Epoch 01030: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17.8884 - recon_loss: 5.9419e-04 - KL loss: 9.5917 - beta: 0.0085 - val_loss: 17.6020 - val_recon_loss: 5.8603e-04 - val_KL loss: 9.4192 - val_beta: 0.0085\n",
      "Epoch 1031/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17.8626 - recon_loss: 5.9262e-04 - KL loss: 9.5877 - beta: 0.0085 - val_loss: 17.9030 - val_recon_loss: 6.0813e-04 - val_KL loss: 9.4116 - val_beta: 0.0085\n",
      "Epoch 1032/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17.8504 - recon_loss: 5.9162e-04 - KL loss: 9.5896 - beta: 0.0085 - val_loss: 17.3364 - val_recon_loss: 5.6705e-04 - val_KL loss: 9.4187 - val_beta: 0.0085\n",
      "Epoch 1033/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17.8143 - recon_loss: 5.8998e-04 - KL loss: 9.5763 - beta: 0.0085 - val_loss: 17.4749 - val_recon_loss: 5.7676e-04 - val_KL loss: 9.4214 - val_beta: 0.0085\n",
      "Epoch 1034/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17.8424 - recon_loss: 5.9099e-04 - KL loss: 9.5903 - beta: 0.0085 - val_loss: 17.7174 - val_recon_loss: 5.9432e-04 - val_KL loss: 9.4189 - val_beta: 0.0085\n",
      "Epoch 1035/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17.7689 - recon_loss: 5.8741e-04 - KL loss: 9.5669 - beta: 0.0085 - val_loss: 17.5801 - val_recon_loss: 5.8625e-04 - val_KL loss: 9.3942 - val_beta: 0.0085\n",
      "Epoch 1036/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17.8764 - recon_loss: 5.9381e-04 - KL loss: 9.5849 - beta: 0.0085 - val_loss: 17.6680 - val_recon_loss: 5.9162e-04 - val_KL loss: 9.4072 - val_beta: 0.0085\n",
      "Epoch 1037/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17.8056 - recon_loss: 5.8933e-04 - KL loss: 9.5768 - beta: 0.0085\n",
      "Epoch 01037: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 17.8057 - recon_loss: 5.8933e-04 - KL loss: 9.5768 - beta: 0.0085 - val_loss: 17.7538 - val_recon_loss: 5.9535e-04 - val_KL loss: 9.4409 - val_beta: 0.0085\n",
      "Epoch 1038/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17.7999 - recon_loss: 5.8764e-04 - KL loss: 9.5947 - beta: 0.0085 - val_loss: 17.4014 - val_recon_loss: 5.7216e-04 - val_KL loss: 9.4123 - val_beta: 0.0085\n",
      "Epoch 1039/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17.6773 - recon_loss: 5.8109e-04 - KL loss: 9.5634 - beta: 0.0085 - val_loss: 17.5485 - val_recon_loss: 5.8367e-04 - val_KL loss: 9.3987 - val_beta: 0.0085\n",
      "Epoch 1040/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17.8347 - recon_loss: 5.9162e-04 - KL loss: 9.5738 - beta: 0.0085 - val_loss: 17.8020 - val_recon_loss: 6.0126e-04 - val_KL loss: 9.4066 - val_beta: 0.0085\n",
      "Epoch 1041/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17.7958 - recon_loss: 5.8856e-04 - KL loss: 9.5776 - beta: 0.0085 - val_loss: 17.6813 - val_recon_loss: 5.9265e-04 - val_KL loss: 9.4061 - val_beta: 0.0085\n",
      "Epoch 1042/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17.8440 - recon_loss: 5.9151e-04 - KL loss: 9.5846 - beta: 0.0085\n",
      "Epoch 01042: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17.8439 - recon_loss: 5.9151e-04 - KL loss: 9.5846 - beta: 0.0085 - val_loss: 17.4746 - val_recon_loss: 5.7766e-04 - val_KL loss: 9.4086 - val_beta: 0.0085\n",
      "Epoch 1042/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 15.1975 - recon_loss: 6.9704e-04 - KL loss: 8.5967 - beta: 0.0103 - val_loss: 15.2397 - val_recon_loss: 7.3957e-04 - val_KL loss: 8.2361 - val_beta: 0.0103\n",
      "Epoch 1043/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.2057 - recon_loss: 7.1623e-04 - KL loss: 8.4231 - beta: 0.0103 - val_loss: 15.0260 - val_recon_loss: 7.0901e-04 - val_KL loss: 8.3118 - val_beta: 0.0103\n",
      "Epoch 1044/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.2555 - recon_loss: 7.2647e-04 - KL loss: 8.3759 - beta: 0.0103 - val_loss: 15.2153 - val_recon_loss: 7.3309e-04 - val_KL loss: 8.2730 - val_beta: 0.0103\n",
      "Epoch 1045/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.2632 - recon_loss: 7.2752e-04 - KL loss: 8.3736 - beta: 0.0103 - val_loss: 15.5324 - val_recon_loss: 7.6416e-04 - val_KL loss: 8.2959 - val_beta: 0.0103\n",
      "Epoch 1046/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.2512 - recon_loss: 7.2669e-04 - KL loss: 8.3695 - beta: 0.0103 - val_loss: 15.3840 - val_recon_loss: 7.4363e-04 - val_KL loss: 8.3419 - val_beta: 0.0103\n",
      "Epoch 1047/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.5481 - recon_loss: 7.6192e-04 - KL loss: 8.3327 - beta: 0.0103 - val_loss: 15.2732 - val_recon_loss: 7.5886e-04 - val_KL loss: 8.0869 - val_beta: 0.0103\n",
      "Epoch 1048/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 15.4955 - recon_loss: 7.5785e-04 - KL loss: 8.3187 - beta: 0.0103\n",
      "Epoch 01048: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.4966 - recon_loss: 7.5797e-04 - KL loss: 8.3187 - beta: 0.0103 - val_loss: 16.8953 - val_recon_loss: 9.3178e-04 - val_KL loss: 8.0715 - val_beta: 0.0103\n",
      "Epoch 1049/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 16.2099 - recon_loss: 8.2839e-04 - KL loss: 8.3651 - beta: 0.0103 - val_loss: 15.3981 - val_recon_loss: 7.4793e-04 - val_KL loss: 8.3153 - val_beta: 0.0103\n",
      "Epoch 1050/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.8578 - recon_loss: 7.8884e-04 - KL loss: 8.3875 - beta: 0.0103 - val_loss: 15.3700 - val_recon_loss: 7.4292e-04 - val_KL loss: 8.3346 - val_beta: 0.0103\n",
      "Epoch 1051/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.8276 - recon_loss: 7.8821e-04 - KL loss: 8.3634 - beta: 0.0103 - val_loss: 16.6479 - val_recon_loss: 8.8676e-04 - val_KL loss: 8.2504 - val_beta: 0.0103\n",
      "Epoch 1052/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.8783 - recon_loss: 7.8876e-04 - KL loss: 8.4087 - beta: 0.0103 - val_loss: 15.1778 - val_recon_loss: 7.2941e-04 - val_KL loss: 8.2703 - val_beta: 0.0103\n",
      "Epoch 1053/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 15.6186 - recon_loss: 7.6669e-04 - KL loss: 8.3581 - beta: 0.0103\n",
      "Epoch 01053: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.6186 - recon_loss: 7.6669e-04 - KL loss: 8.3581 - beta: 0.0103 - val_loss: 15.2528 - val_recon_loss: 7.4427e-04 - val_KL loss: 8.2046 - val_beta: 0.0103\n",
      "Epoch 1053/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 13.1839 - recon_loss: 8.8946e-04 - KL loss: 7.4713 - beta: 0.0125 - val_loss: 12.9264 - val_recon_loss: 8.7811e-04 - val_KL loss: 7.2867 - val_beta: 0.0125\n",
      "Epoch 1054/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.2617 - recon_loss: 9.2049e-04 - KL loss: 7.3499 - beta: 0.0125 - val_loss: 13.3675 - val_recon_loss: 9.4552e-04 - val_KL loss: 7.2948 - val_beta: 0.0125\n",
      "Epoch 1055/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.3289 - recon_loss: 9.4320e-04 - KL loss: 7.2711 - beta: 0.0125 - val_loss: 13.1266 - val_recon_loss: 9.1202e-04 - val_KL loss: 7.2691 - val_beta: 0.0125\n",
      "Epoch 1056/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.0645 - recon_loss: 9.0907e-04 - KL loss: 7.2260 - beta: 0.0125 - val_loss: 13.0400 - val_recon_loss: 9.2085e-04 - val_KL loss: 7.1258 - val_beta: 0.0125\n",
      "Epoch 1057/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.2839 - recon_loss: 9.4725e-04 - KL loss: 7.2001 - beta: 0.0125 - val_loss: 12.8711 - val_recon_loss: 9.0248e-04 - val_KL loss: 7.0749 - val_beta: 0.0125\n",
      "Epoch 1058/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 12.9394 - recon_loss: 8.9984e-04 - KL loss: 7.1601 - beta: 0.0125 - val_loss: 12.8935 - val_recon_loss: 9.0486e-04 - val_KL loss: 7.0820 - val_beta: 0.0125\n",
      "Epoch 1059/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.2031 - recon_loss: 9.3529e-04 - KL loss: 7.1962 - beta: 0.0125 - val_loss: 13.7891 - val_recon_loss: 0.0010 - val_KL loss: 7.2790 - val_beta: 0.0125\n",
      "Epoch 1060/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.0228 - recon_loss: 9.0974e-04 - KL loss: 7.1799 - beta: 0.0125 - val_loss: 12.8687 - val_recon_loss: 8.8902e-04 - val_KL loss: 7.1590 - val_beta: 0.0125\n",
      "Epoch 1061/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.0655 - recon_loss: 9.2097e-04 - KL loss: 7.1506 - beta: 0.0125 - val_loss: 13.1999 - val_recon_loss: 9.5166e-04 - val_KL loss: 7.0878 - val_beta: 0.0125\n",
      "Epoch 1062/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.1762 - recon_loss: 9.4026e-04 - KL loss: 7.1374 - beta: 0.0125 - val_loss: 12.5985 - val_recon_loss: 8.5408e-04 - val_KL loss: 7.1131 - val_beta: 0.0125\n",
      "Epoch 1063/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.1097 - recon_loss: 9.3200e-04 - KL loss: 7.1239 - beta: 0.0125 - val_loss: 13.1535 - val_recon_loss: 9.4002e-04 - val_KL loss: 7.1162 - val_beta: 0.0125\n",
      "Epoch 1064/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.3532 - recon_loss: 9.6320e-04 - KL loss: 7.1669 - beta: 0.0125 - val_loss: 12.5239 - val_recon_loss: 8.3056e-04 - val_KL loss: 7.1895 - val_beta: 0.0125\n",
      "Epoch 1065/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.0752 - recon_loss: 9.2542e-04 - KL loss: 7.1316 - beta: 0.0125 - val_loss: 12.8042 - val_recon_loss: 8.6230e-04 - val_KL loss: 7.2660 - val_beta: 0.0125\n",
      "Epoch 1066/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.0686 - recon_loss: 9.2707e-04 - KL loss: 7.1145 - beta: 0.0125 - val_loss: 13.0507 - val_recon_loss: 9.0835e-04 - val_KL loss: 7.2168 - val_beta: 0.0125\n",
      "Epoch 1067/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 13.0447 - recon_loss: 9.2170e-04 - KL loss: 7.1251 - beta: 0.0125 - val_loss: 14.0235 - val_recon_loss: 0.0011 - val_KL loss: 7.1813 - val_beta: 0.0125\n",
      "Epoch 1068/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13.1714 - recon_loss: 9.4464e-04 - KL loss: 7.1044 - beta: 0.0125 - val_loss: 12.5733 - val_recon_loss: 8.7292e-04 - val_KL loss: 6.9669 - val_beta: 0.0125\n",
      "Epoch 1069/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13.2125 - recon_loss: 9.5045e-04 - KL loss: 7.1082 - beta: 0.0125\n",
      "Epoch 01069: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13.2125 - recon_loss: 9.5044e-04 - KL loss: 7.1082 - beta: 0.0125 - val_loss: 12.8101 - val_recon_loss: 8.6419e-04 - val_KL loss: 7.2598 - val_beta: 0.0125\n",
      "Epoch 1070/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 12.9448 - recon_loss: 9.0802e-04 - KL loss: 7.1130 - beta: 0.0125 - val_loss: 12.3597 - val_recon_loss: 8.2516e-04 - val_KL loss: 7.0601 - val_beta: 0.0125\n",
      "Epoch 1071/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12.8872 - recon_loss: 8.9730e-04 - KL loss: 7.1243 - beta: 0.0125 - val_loss: 12.5599 - val_recon_loss: 8.5083e-04 - val_KL loss: 7.0953 - val_beta: 0.0125\n",
      "Epoch 1072/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 12.7915 - recon_loss: 8.8379e-04 - KL loss: 7.1153 - beta: 0.0125 - val_loss: 12.3972 - val_recon_loss: 8.2917e-04 - val_KL loss: 7.0718 - val_beta: 0.0125\n",
      "Epoch 1073/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 12.7630 - recon_loss: 8.8483e-04 - KL loss: 7.0801 - beta: 0.0125 - val_loss: 12.6116 - val_recon_loss: 8.5607e-04 - val_KL loss: 7.1135 - val_beta: 0.0125\n",
      "Epoch 1074/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 12.7948 - recon_loss: 8.8276e-04 - KL loss: 7.1252 - beta: 0.0125 - val_loss: 12.5173 - val_recon_loss: 8.3938e-04 - val_KL loss: 7.1263 - val_beta: 0.0125\n",
      "Epoch 1075/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 12.7781 - recon_loss: 8.8203e-04 - KL loss: 7.1132 - beta: 0.0125\n",
      "Epoch 01075: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12.7781 - recon_loss: 8.8203e-04 - KL loss: 7.1132 - beta: 0.0125 - val_loss: 12.4982 - val_recon_loss: 8.3698e-04 - val_KL loss: 7.1227 - val_beta: 0.0125\n",
      "Epoch 1076/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12.7347 - recon_loss: 8.7352e-04 - KL loss: 7.1245 - beta: 0.0125 - val_loss: 12.1958 - val_recon_loss: 7.8499e-04 - val_KL loss: 7.1542 - val_beta: 0.0125\n",
      "Epoch 1077/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12.8054 - recon_loss: 8.7724e-04 - KL loss: 7.1713 - beta: 0.0125 - val_loss: 12.3230 - val_recon_loss: 8.1558e-04 - val_KL loss: 7.0849 - val_beta: 0.0125\n",
      "Epoch 1078/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 12.7392 - recon_loss: 8.7230e-04 - KL loss: 7.1369 - beta: 0.0125 - val_loss: 12.4048 - val_recon_loss: 8.2429e-04 - val_KL loss: 7.1107 - val_beta: 0.0125\n",
      "Epoch 1079/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 12.7727 - recon_loss: 8.7703e-04 - KL loss: 7.1400 - beta: 0.0125 - val_loss: 12.2966 - val_recon_loss: 8.0596e-04 - val_KL loss: 7.1203 - val_beta: 0.0125\n",
      "Epoch 1080/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12.7291 - recon_loss: 8.6940e-04 - KL loss: 7.1453 - beta: 0.0125 - val_loss: 12.5261 - val_recon_loss: 8.4446e-04 - val_KL loss: 7.1025 - val_beta: 0.0125\n",
      "Epoch 1081/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 12.7352 - recon_loss: 8.7337e-04 - KL loss: 7.1259 - beta: 0.0125\n",
      "Epoch 01081: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12.7351 - recon_loss: 8.7336e-04 - KL loss: 7.1259 - beta: 0.0125 - val_loss: 12.7786 - val_recon_loss: 8.8684e-04 - val_KL loss: 7.0829 - val_beta: 0.0125\n",
      "Epoch 1082/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12.6830 - recon_loss: 8.6596e-04 - KL loss: 7.1213 - beta: 0.0125 - val_loss: 12.3547 - val_recon_loss: 8.1744e-04 - val_KL loss: 7.1046 - val_beta: 0.0125\n",
      "Epoch 1083/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12.7115 - recon_loss: 8.6761e-04 - KL loss: 7.1392 - beta: 0.0125 - val_loss: 12.2352 - val_recon_loss: 8.0044e-04 - val_KL loss: 7.0943 - val_beta: 0.0125\n",
      "Epoch 1084/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 12.7418 - recon_loss: 8.7115e-04 - KL loss: 7.1468 - beta: 0.0125 - val_loss: 12.3281 - val_recon_loss: 8.1259e-04 - val_KL loss: 7.1092 - val_beta: 0.0125\n",
      "Epoch 1085/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 12.6560 - recon_loss: 8.6090e-04 - KL loss: 7.1268 - beta: 0.0125 - val_loss: 12.4583 - val_recon_loss: 8.3474e-04 - val_KL loss: 7.0971 - val_beta: 0.0125\n",
      "Epoch 1086/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.6382 - recon_loss: 8.5891e-04 - KL loss: 7.1218 - beta: 0.0125\n",
      "Epoch 01086: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12.6382 - recon_loss: 8.5891e-04 - KL loss: 7.1218 - beta: 0.0125 - val_loss: 12.3114 - val_recon_loss: 8.1115e-04 - val_KL loss: 7.1017 - val_beta: 0.0125\n",
      "Epoch 1086/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.0167 - recon_loss: 0.0011 - KL loss: 6.4082 - beta: 0.0152 - val_loss: 10.4356 - val_recon_loss: 9.6008e-04 - val_KL loss: 6.2537 - val_beta: 0.0152\n",
      "Epoch 1087/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.0385 - recon_loss: 0.0011 - KL loss: 6.2195 - beta: 0.0152 - val_loss: 10.6080 - val_recon_loss: 0.0010 - val_KL loss: 6.1309 - val_beta: 0.0152\n",
      "Epoch 1088/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.1127 - recon_loss: 0.0011 - KL loss: 6.2034 - beta: 0.0152 - val_loss: 10.9200 - val_recon_loss: 0.0011 - val_KL loss: 6.1859 - val_beta: 0.0152\n",
      "Epoch 1089/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.0421 - recon_loss: 0.0011 - KL loss: 6.1809 - beta: 0.0152 - val_loss: 10.7736 - val_recon_loss: 0.0010 - val_KL loss: 6.3463 - val_beta: 0.0152\n",
      "Epoch 1090/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.0731 - recon_loss: 0.0011 - KL loss: 6.1613 - beta: 0.0152 - val_loss: 11.4773 - val_recon_loss: 0.0012 - val_KL loss: 6.1768 - val_beta: 0.0152\n",
      "Epoch 1091/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.2579 - recon_loss: 0.0012 - KL loss: 6.1792 - beta: 0.0152\n",
      "Epoch 01091: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.2579 - recon_loss: 0.0012 - KL loss: 6.1792 - beta: 0.0152 - val_loss: 11.2755 - val_recon_loss: 0.0012 - val_KL loss: 6.2252 - val_beta: 0.0152\n",
      "Epoch 1092/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.0289 - recon_loss: 0.0011 - KL loss: 6.1658 - beta: 0.0152 - val_loss: 10.7987 - val_recon_loss: 0.0010 - val_KL loss: 6.2384 - val_beta: 0.0152\n",
      "Epoch 1093/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8818 - recon_loss: 0.0011 - KL loss: 6.1562 - beta: 0.0152 - val_loss: 10.7123 - val_recon_loss: 0.0010 - val_KL loss: 6.1858 - val_beta: 0.0152\n",
      "Epoch 1094/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8829 - recon_loss: 0.0011 - KL loss: 6.1656 - beta: 0.0152 - val_loss: 10.4338 - val_recon_loss: 9.9722e-04 - val_KL loss: 6.0901 - val_beta: 0.0152\n",
      "Epoch 1095/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10.8613 - recon_loss: 0.0011 - KL loss: 6.1588 - beta: 0.0152 - val_loss: 10.9901 - val_recon_loss: 0.0011 - val_KL loss: 6.1265 - val_beta: 0.0152\n",
      "Epoch 1096/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10.8453 - recon_loss: 0.0011 - KL loss: 6.1495 - beta: 0.0152 - val_loss: 10.4146 - val_recon_loss: 9.6760e-04 - val_KL loss: 6.1999 - val_beta: 0.0152\n",
      "Epoch 1097/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8489 - recon_loss: 0.0011 - KL loss: 6.1556 - beta: 0.0152 - val_loss: 10.5617 - val_recon_loss: 0.0010 - val_KL loss: 6.1225 - val_beta: 0.0152\n",
      "Epoch 1098/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8277 - recon_loss: 0.0011 - KL loss: 6.1542 - beta: 0.0152 - val_loss: 10.2427 - val_recon_loss: 9.4976e-04 - val_KL loss: 6.1057 - val_beta: 0.0152\n",
      "Epoch 1099/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8399 - recon_loss: 0.0011 - KL loss: 6.1534 - beta: 0.0152 - val_loss: 11.1018 - val_recon_loss: 0.0011 - val_KL loss: 6.1433 - val_beta: 0.0152\n",
      "Epoch 1100/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10.8825 - recon_loss: 0.0011 - KL loss: 6.1674 - beta: 0.0152 - val_loss: 11.0461 - val_recon_loss: 0.0011 - val_KL loss: 6.1227 - val_beta: 0.0152\n",
      "Epoch 1101/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8437 - recon_loss: 0.0011 - KL loss: 6.1396 - beta: 0.0152 - val_loss: 10.6809 - val_recon_loss: 0.0010 - val_KL loss: 6.1498 - val_beta: 0.0152\n",
      "Epoch 1102/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8786 - recon_loss: 0.0011 - KL loss: 6.1704 - beta: 0.0152 - val_loss: 11.0905 - val_recon_loss: 0.0011 - val_KL loss: 6.1142 - val_beta: 0.0152\n",
      "Epoch 1103/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 10.8876 - recon_loss: 0.0011 - KL loss: 6.1697 - beta: 0.0152\n",
      "Epoch 01103: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10.8876 - recon_loss: 0.0011 - KL loss: 6.1697 - beta: 0.0152 - val_loss: 11.3514 - val_recon_loss: 0.0012 - val_KL loss: 6.0652 - val_beta: 0.0152\n",
      "Epoch 1104/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8701 - recon_loss: 0.0011 - KL loss: 6.1606 - beta: 0.0152 - val_loss: 10.7163 - val_recon_loss: 0.0011 - val_KL loss: 6.0719 - val_beta: 0.0152\n",
      "Epoch 1105/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8287 - recon_loss: 0.0011 - KL loss: 6.1661 - beta: 0.0152 - val_loss: 11.0878 - val_recon_loss: 0.0011 - val_KL loss: 6.1375 - val_beta: 0.0152\n",
      "Epoch 1106/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10.8400 - recon_loss: 0.0011 - KL loss: 6.1831 - beta: 0.0152 - val_loss: 11.2408 - val_recon_loss: 0.0012 - val_KL loss: 6.1110 - val_beta: 0.0152\n",
      "Epoch 1107/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8421 - recon_loss: 0.0011 - KL loss: 6.1791 - beta: 0.0152 - val_loss: 10.8476 - val_recon_loss: 0.0011 - val_KL loss: 6.1019 - val_beta: 0.0152\n",
      "Epoch 1108/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.8214 - recon_loss: 0.0011 - KL loss: 6.1631 - beta: 0.0152\n",
      "Epoch 01108: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8214 - recon_loss: 0.0011 - KL loss: 6.1631 - beta: 0.0152 - val_loss: 10.9588 - val_recon_loss: 0.0011 - val_KL loss: 6.1438 - val_beta: 0.0152\n",
      "Epoch 1108/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.2936 - recon_loss: 0.0013 - KL loss: 5.5067 - beta: 0.0184 - val_loss: 9.1751 - val_recon_loss: 0.0013 - val_KL loss: 5.4127 - val_beta: 0.0184\n",
      "Epoch 1109/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.3446 - recon_loss: 0.0013 - KL loss: 5.3635 - beta: 0.0184 - val_loss: 9.3478 - val_recon_loss: 0.0013 - val_KL loss: 5.3969 - val_beta: 0.0184\n",
      "Epoch 1110/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.4325 - recon_loss: 0.0014 - KL loss: 5.2829 - beta: 0.0184 - val_loss: 8.9865 - val_recon_loss: 0.0012 - val_KL loss: 5.3845 - val_beta: 0.0184\n",
      "Epoch 1111/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.4212 - recon_loss: 0.0014 - KL loss: 5.3006 - beta: 0.0184 - val_loss: 9.3548 - val_recon_loss: 0.0014 - val_KL loss: 5.2450 - val_beta: 0.0184\n",
      "Epoch 1112/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.3127 - recon_loss: 0.0014 - KL loss: 5.2497 - beta: 0.0184 - val_loss: 9.1875 - val_recon_loss: 0.0013 - val_KL loss: 5.3890 - val_beta: 0.0184\n",
      "Epoch 1113/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.3969 - recon_loss: 0.0014 - KL loss: 5.2345 - beta: 0.0184 - val_loss: 9.1086 - val_recon_loss: 0.0013 - val_KL loss: 5.2952 - val_beta: 0.0184\n",
      "Epoch 1114/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.2698 - recon_loss: 0.0014 - KL loss: 5.2110 - beta: 0.0184 - val_loss: 9.2765 - val_recon_loss: 0.0014 - val_KL loss: 5.2283 - val_beta: 0.0184\n",
      "Epoch 1115/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.2828 - recon_loss: 0.0014 - KL loss: 5.2018 - beta: 0.0184\n",
      "Epoch 01115: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.2828 - recon_loss: 0.0014 - KL loss: 5.2018 - beta: 0.0184 - val_loss: 9.0583 - val_recon_loss: 0.0013 - val_KL loss: 5.2640 - val_beta: 0.0184\n",
      "Epoch 1116/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.1520 - recon_loss: 0.0013 - KL loss: 5.1828 - beta: 0.0184 - val_loss: 8.9736 - val_recon_loss: 0.0013 - val_KL loss: 5.2326 - val_beta: 0.0184\n",
      "Epoch 1117/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.1670 - recon_loss: 0.0013 - KL loss: 5.1857 - beta: 0.0184 - val_loss: 9.0625 - val_recon_loss: 0.0013 - val_KL loss: 5.3115 - val_beta: 0.0184\n",
      "Epoch 1118/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.1629 - recon_loss: 0.0013 - KL loss: 5.1954 - beta: 0.0184 - val_loss: 9.3258 - val_recon_loss: 0.0014 - val_KL loss: 5.1958 - val_beta: 0.0184\n",
      "Epoch 1119/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.1798 - recon_loss: 0.0013 - KL loss: 5.1950 - beta: 0.0184 - val_loss: 9.5936 - val_recon_loss: 0.0015 - val_KL loss: 5.1843 - val_beta: 0.0184\n",
      "Epoch 1120/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.3134 - recon_loss: 0.0014 - KL loss: 5.2235 - beta: 0.0184 - val_loss: 9.7216 - val_recon_loss: 0.0015 - val_KL loss: 5.2617 - val_beta: 0.0184\n",
      "Epoch 1121/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.2551 - recon_loss: 0.0014 - KL loss: 5.2282 - beta: 0.0184\n",
      "Epoch 01121: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.2550 - recon_loss: 0.0014 - KL loss: 5.2282 - beta: 0.0184 - val_loss: 9.0087 - val_recon_loss: 0.0013 - val_KL loss: 5.1525 - val_beta: 0.0184\n",
      "Epoch 1122/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.1774 - recon_loss: 0.0013 - KL loss: 5.1975 - beta: 0.0184 - val_loss: 8.9880 - val_recon_loss: 0.0013 - val_KL loss: 5.2173 - val_beta: 0.0184\n",
      "Epoch 1123/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 9.1773 - recon_loss: 0.0013 - KL loss: 5.2142 - beta: 0.0184 - val_loss: 8.8946 - val_recon_loss: 0.0012 - val_KL loss: 5.2399 - val_beta: 0.0184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1124/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.1641 - recon_loss: 0.0013 - KL loss: 5.2159 - beta: 0.0184 - val_loss: 8.8850 - val_recon_loss: 0.0012 - val_KL loss: 5.2135 - val_beta: 0.0184\n",
      "Epoch 1125/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.1291 - recon_loss: 0.0013 - KL loss: 5.2065 - beta: 0.0184 - val_loss: 8.7524 - val_recon_loss: 0.0012 - val_KL loss: 5.2254 - val_beta: 0.0184\n",
      "Epoch 1126/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.1494 - recon_loss: 0.0013 - KL loss: 5.2229 - beta: 0.0184 - val_loss: 9.0715 - val_recon_loss: 0.0013 - val_KL loss: 5.2400 - val_beta: 0.0184\n",
      "Epoch 1127/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.1426 - recon_loss: 0.0013 - KL loss: 5.2125 - beta: 0.0184 - val_loss: 8.8616 - val_recon_loss: 0.0012 - val_KL loss: 5.2277 - val_beta: 0.0184\n",
      "Epoch 1128/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.1259 - recon_loss: 0.0013 - KL loss: 5.2101 - beta: 0.0184 - val_loss: 8.9066 - val_recon_loss: 0.0012 - val_KL loss: 5.2578 - val_beta: 0.0184\n",
      "Epoch 1129/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.1317 - recon_loss: 0.0013 - KL loss: 5.2182 - beta: 0.0184 - val_loss: 8.9713 - val_recon_loss: 0.0013 - val_KL loss: 5.2502 - val_beta: 0.0184\n",
      "Epoch 1130/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.1385 - recon_loss: 0.0013 - KL loss: 5.2131 - beta: 0.0184\n",
      "Epoch 01130: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.1385 - recon_loss: 0.0013 - KL loss: 5.2131 - beta: 0.0184 - val_loss: 8.9535 - val_recon_loss: 0.0013 - val_KL loss: 5.2142 - val_beta: 0.0184\n",
      "Epoch 1131/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.1032 - recon_loss: 0.0013 - KL loss: 5.1937 - beta: 0.0184 - val_loss: 9.2347 - val_recon_loss: 0.0014 - val_KL loss: 5.2260 - val_beta: 0.0184\n",
      "Epoch 1132/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.1345 - recon_loss: 0.0013 - KL loss: 5.2080 - beta: 0.0184 - val_loss: 9.1007 - val_recon_loss: 0.0013 - val_KL loss: 5.2130 - val_beta: 0.0184\n",
      "Epoch 1133/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9.1197 - recon_loss: 0.0013 - KL loss: 5.2047 - beta: 0.0184 - val_loss: 8.8934 - val_recon_loss: 0.0012 - val_KL loss: 5.2261 - val_beta: 0.0184\n",
      "Epoch 1134/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.1125 - recon_loss: 0.0013 - KL loss: 5.1937 - beta: 0.0184 - val_loss: 9.3520 - val_recon_loss: 0.0014 - val_KL loss: 5.2266 - val_beta: 0.0184\n",
      "Epoch 1135/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9.1018 - recon_loss: 0.0013 - KL loss: 5.2030 - beta: 0.0184\n",
      "Epoch 01135: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9.1018 - recon_loss: 0.0013 - KL loss: 5.2030 - beta: 0.0184 - val_loss: 9.0303 - val_recon_loss: 0.0013 - val_KL loss: 5.2350 - val_beta: 0.0184\n",
      "Epoch 1135/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7.8412 - recon_loss: 0.0016 - KL loss: 4.6168 - beta: 0.0223 - val_loss: 7.8239 - val_recon_loss: 0.0017 - val_KL loss: 4.4617 - val_beta: 0.0223\n",
      "Epoch 1136/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7.8416 - recon_loss: 0.0017 - KL loss: 4.4524 - beta: 0.0223 - val_loss: 7.7977 - val_recon_loss: 0.0018 - val_KL loss: 4.2624 - val_beta: 0.0223\n",
      "Epoch 1137/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7.8212 - recon_loss: 0.0017 - KL loss: 4.4133 - beta: 0.0223 - val_loss: 7.3964 - val_recon_loss: 0.0015 - val_KL loss: 4.3631 - val_beta: 0.0223\n",
      "Epoch 1138/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7.8191 - recon_loss: 0.0017 - KL loss: 4.3765 - beta: 0.0223 - val_loss: 7.9288 - val_recon_loss: 0.0018 - val_KL loss: 4.3793 - val_beta: 0.0223\n",
      "Epoch 1139/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7.8469 - recon_loss: 0.0017 - KL loss: 4.3720 - beta: 0.0223 - val_loss: 7.8734 - val_recon_loss: 0.0018 - val_KL loss: 4.3421 - val_beta: 0.0223\n",
      "Epoch 1140/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7.8356 - recon_loss: 0.0017 - KL loss: 4.3494 - beta: 0.0223 - val_loss: 8.0638 - val_recon_loss: 0.0019 - val_KL loss: 4.3426 - val_beta: 0.0223\n",
      "Epoch 1141/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7.8571 - recon_loss: 0.0018 - KL loss: 4.3282 - beta: 0.0223 - val_loss: 8.0184 - val_recon_loss: 0.0018 - val_KL loss: 4.3397 - val_beta: 0.0223\n",
      "Epoch 1142/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.8143 - recon_loss: 0.0017 - KL loss: 4.3201 - beta: 0.0223\n",
      "Epoch 01142: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7.8143 - recon_loss: 0.0017 - KL loss: 4.3201 - beta: 0.0223 - val_loss: 7.5175 - val_recon_loss: 0.0016 - val_KL loss: 4.2176 - val_beta: 0.0223\n",
      "Epoch 1143/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 7.7696 - recon_loss: 0.0017 - KL loss: 4.3242 - beta: 0.0223 - val_loss: 7.6924 - val_recon_loss: 0.0017 - val_KL loss: 4.3168 - val_beta: 0.0223\n",
      "Epoch 1144/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7.7349 - recon_loss: 0.0017 - KL loss: 4.3468 - beta: 0.0223 - val_loss: 7.6542 - val_recon_loss: 0.0017 - val_KL loss: 4.3064 - val_beta: 0.0223\n",
      "Epoch 1145/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7.7716 - recon_loss: 0.0017 - KL loss: 4.3367 - beta: 0.0223 - val_loss: 7.6359 - val_recon_loss: 0.0017 - val_KL loss: 4.2826 - val_beta: 0.0223\n",
      "Epoch 1146/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7.7350 - recon_loss: 0.0017 - KL loss: 4.3212 - beta: 0.0223 - val_loss: 7.4109 - val_recon_loss: 0.0016 - val_KL loss: 4.2904 - val_beta: 0.0223\n",
      "Epoch 1147/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.7512 - recon_loss: 0.0017 - KL loss: 4.3194 - beta: 0.0223\n",
      "Epoch 01147: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7.7512 - recon_loss: 0.0017 - KL loss: 4.3194 - beta: 0.0223 - val_loss: 7.7147 - val_recon_loss: 0.0017 - val_KL loss: 4.2862 - val_beta: 0.0223\n",
      "Epoch 1147/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6020 - recon_loss: 0.0020 - KL loss: 3.8316 - beta: 0.0271 - val_loss: 6.8994 - val_recon_loss: 0.0024 - val_KL loss: 3.6284 - val_beta: 0.0271\n",
      "Epoch 1148/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6.6129 - recon_loss: 0.0021 - KL loss: 3.7304 - beta: 0.0271 - val_loss: 6.6484 - val_recon_loss: 0.0022 - val_KL loss: 3.6946 - val_beta: 0.0271\n",
      "Epoch 1149/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6109 - recon_loss: 0.0021 - KL loss: 3.7187 - beta: 0.0271 - val_loss: 6.5246 - val_recon_loss: 0.0021 - val_KL loss: 3.6787 - val_beta: 0.0271\n",
      "Epoch 1150/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6308 - recon_loss: 0.0021 - KL loss: 3.7164 - beta: 0.0271 - val_loss: 6.5289 - val_recon_loss: 0.0021 - val_KL loss: 3.7276 - val_beta: 0.0271\n",
      "Epoch 1151/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.5683 - recon_loss: 0.0021 - KL loss: 3.6892 - beta: 0.0271 - val_loss: 6.3626 - val_recon_loss: 0.0020 - val_KL loss: 3.6373 - val_beta: 0.0271\n",
      "Epoch 1152/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5880 - recon_loss: 0.0021 - KL loss: 3.6954 - beta: 0.0271 - val_loss: 6.4781 - val_recon_loss: 0.0021 - val_KL loss: 3.5673 - val_beta: 0.0271\n",
      "Epoch 1153/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5912 - recon_loss: 0.0021 - KL loss: 3.6801 - beta: 0.0271 - val_loss: 6.5266 - val_recon_loss: 0.0021 - val_KL loss: 3.6690 - val_beta: 0.0271\n",
      "Epoch 1154/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6045 - recon_loss: 0.0021 - KL loss: 3.6941 - beta: 0.0271 - val_loss: 6.4701 - val_recon_loss: 0.0020 - val_KL loss: 3.6870 - val_beta: 0.0271\n",
      "Epoch 1155/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6.6520 - recon_loss: 0.0022 - KL loss: 3.6891 - beta: 0.0271 - val_loss: 6.6115 - val_recon_loss: 0.0021 - val_KL loss: 3.7412 - val_beta: 0.0271\n",
      "Epoch 1156/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.6518 - recon_loss: 0.0022 - KL loss: 3.6802 - beta: 0.0271\n",
      "Epoch 01156: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.6518 - recon_loss: 0.0022 - KL loss: 3.6802 - beta: 0.0271 - val_loss: 6.5818 - val_recon_loss: 0.0021 - val_KL loss: 3.6785 - val_beta: 0.0271\n",
      "Epoch 1157/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6.5681 - recon_loss: 0.0021 - KL loss: 3.6907 - beta: 0.0271 - val_loss: 6.4074 - val_recon_loss: 0.0020 - val_KL loss: 3.6549 - val_beta: 0.0271\n",
      "Epoch 1158/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5654 - recon_loss: 0.0021 - KL loss: 3.6923 - beta: 0.0271 - val_loss: 6.5287 - val_recon_loss: 0.0021 - val_KL loss: 3.6578 - val_beta: 0.0271\n",
      "Epoch 1159/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5541 - recon_loss: 0.0021 - KL loss: 3.6887 - beta: 0.0271 - val_loss: 6.5874 - val_recon_loss: 0.0022 - val_KL loss: 3.6110 - val_beta: 0.0271\n",
      "Epoch 1160/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5307 - recon_loss: 0.0021 - KL loss: 3.6582 - beta: 0.0271 - val_loss: 6.2884 - val_recon_loss: 0.0020 - val_KL loss: 3.6116 - val_beta: 0.0271\n",
      "Epoch 1161/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6.5418 - recon_loss: 0.0021 - KL loss: 3.6703 - beta: 0.0271 - val_loss: 6.4240 - val_recon_loss: 0.0021 - val_KL loss: 3.6093 - val_beta: 0.0271\n",
      "Epoch 1162/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5218 - recon_loss: 0.0021 - KL loss: 3.6700 - beta: 0.0271 - val_loss: 6.6764 - val_recon_loss: 0.0023 - val_KL loss: 3.5861 - val_beta: 0.0271\n",
      "Epoch 1163/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5378 - recon_loss: 0.0021 - KL loss: 3.6751 - beta: 0.0271 - val_loss: 6.3983 - val_recon_loss: 0.0020 - val_KL loss: 3.6137 - val_beta: 0.0271\n",
      "Epoch 1164/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.5304 - recon_loss: 0.0021 - KL loss: 3.6676 - beta: 0.0271 - val_loss: 6.1239 - val_recon_loss: 0.0018 - val_KL loss: 3.6235 - val_beta: 0.0271\n",
      "Epoch 1165/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5178 - recon_loss: 0.0021 - KL loss: 3.6748 - beta: 0.0271 - val_loss: 6.5086 - val_recon_loss: 0.0021 - val_KL loss: 3.6785 - val_beta: 0.0271\n",
      "Epoch 1166/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5242 - recon_loss: 0.0021 - KL loss: 3.6623 - beta: 0.0271 - val_loss: 6.4825 - val_recon_loss: 0.0021 - val_KL loss: 3.6495 - val_beta: 0.0271\n",
      "Epoch 1167/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5148 - recon_loss: 0.0021 - KL loss: 3.6748 - beta: 0.0271 - val_loss: 6.6028 - val_recon_loss: 0.0022 - val_KL loss: 3.6204 - val_beta: 0.0271\n",
      "Epoch 1168/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5391 - recon_loss: 0.0021 - KL loss: 3.6701 - beta: 0.0271 - val_loss: 6.5137 - val_recon_loss: 0.0021 - val_KL loss: 3.6761 - val_beta: 0.0271\n",
      "Epoch 1169/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 6.5106 - recon_loss: 0.0021 - KL loss: 3.6671 - beta: 0.0271\n",
      "Epoch 01169: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5106 - recon_loss: 0.0021 - KL loss: 3.6671 - beta: 0.0271 - val_loss: 6.3083 - val_recon_loss: 0.0020 - val_KL loss: 3.6155 - val_beta: 0.0271\n",
      "Epoch 1170/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5073 - recon_loss: 0.0021 - KL loss: 3.6849 - beta: 0.0271 - val_loss: 6.5935 - val_recon_loss: 0.0022 - val_KL loss: 3.6231 - val_beta: 0.0271\n",
      "Epoch 1171/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.4864 - recon_loss: 0.0021 - KL loss: 3.6729 - beta: 0.0271 - val_loss: 6.5149 - val_recon_loss: 0.0021 - val_KL loss: 3.6354 - val_beta: 0.0271\n",
      "Epoch 1172/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.4941 - recon_loss: 0.0021 - KL loss: 3.6738 - beta: 0.0271 - val_loss: 6.1898 - val_recon_loss: 0.0019 - val_KL loss: 3.6409 - val_beta: 0.0271\n",
      "Epoch 1173/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.5008 - recon_loss: 0.0021 - KL loss: 3.6712 - beta: 0.0271 - val_loss: 6.5574 - val_recon_loss: 0.0022 - val_KL loss: 3.6323 - val_beta: 0.0271\n",
      "Epoch 1174/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.4934 - recon_loss: 0.0021 - KL loss: 3.6660 - beta: 0.0271\n",
      "Epoch 01174: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.4934 - recon_loss: 0.0021 - KL loss: 3.6660 - beta: 0.0271 - val_loss: 6.8560 - val_recon_loss: 0.0023 - val_KL loss: 3.6952 - val_beta: 0.0271\n",
      "Epoch 1174/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5762 - recon_loss: 0.0026 - KL loss: 3.1963 - beta: 0.0329 - val_loss: 5.4354 - val_recon_loss: 0.0026 - val_KL loss: 3.0581 - val_beta: 0.0329\n",
      "Epoch 1175/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5.5567 - recon_loss: 0.0026 - KL loss: 3.1152 - beta: 0.0329 - val_loss: 5.5399 - val_recon_loss: 0.0027 - val_KL loss: 3.0804 - val_beta: 0.0329\n",
      "Epoch 1176/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5732 - recon_loss: 0.0027 - KL loss: 3.1028 - beta: 0.0329 - val_loss: 5.3198 - val_recon_loss: 0.0025 - val_KL loss: 3.0287 - val_beta: 0.0329\n",
      "Epoch 1177/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5.5658 - recon_loss: 0.0027 - KL loss: 3.0841 - beta: 0.0329 - val_loss: 5.2727 - val_recon_loss: 0.0025 - val_KL loss: 3.0140 - val_beta: 0.0329\n",
      "Epoch 1178/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5934 - recon_loss: 0.0027 - KL loss: 3.0724 - beta: 0.0329 - val_loss: 5.5061 - val_recon_loss: 0.0027 - val_KL loss: 2.9940 - val_beta: 0.0329\n",
      "Epoch 1179/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5.5631 - recon_loss: 0.0027 - KL loss: 3.0664 - beta: 0.0329 - val_loss: 5.3467 - val_recon_loss: 0.0025 - val_KL loss: 3.0137 - val_beta: 0.0329\n",
      "Epoch 1180/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5661 - recon_loss: 0.0027 - KL loss: 3.0717 - beta: 0.0329 - val_loss: 5.5695 - val_recon_loss: 0.0027 - val_KL loss: 3.0373 - val_beta: 0.0329\n",
      "Epoch 1181/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5.5765 - recon_loss: 0.0027 - KL loss: 3.0810 - beta: 0.0329 - val_loss: 5.5836 - val_recon_loss: 0.0028 - val_KL loss: 3.0246 - val_beta: 0.0329\n",
      "Epoch 1182/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.5802 - recon_loss: 0.0027 - KL loss: 3.0539 - beta: 0.0329\n",
      "Epoch 01182: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5.5802 - recon_loss: 0.0027 - KL loss: 3.0539 - beta: 0.0329 - val_loss: 5.4075 - val_recon_loss: 0.0025 - val_KL loss: 3.1216 - val_beta: 0.0329\n",
      "Epoch 1183/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5535 - recon_loss: 0.0027 - KL loss: 3.0745 - beta: 0.0329 - val_loss: 5.3762 - val_recon_loss: 0.0026 - val_KL loss: 3.0221 - val_beta: 0.0329\n",
      "Epoch 1184/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5491 - recon_loss: 0.0027 - KL loss: 3.0663 - beta: 0.0329 - val_loss: 5.5898 - val_recon_loss: 0.0028 - val_KL loss: 3.0415 - val_beta: 0.0329\n",
      "Epoch 1185/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5.5392 - recon_loss: 0.0027 - KL loss: 3.0684 - beta: 0.0329 - val_loss: 5.4286 - val_recon_loss: 0.0026 - val_KL loss: 3.0501 - val_beta: 0.0329\n",
      "Epoch 1186/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5.5544 - recon_loss: 0.0027 - KL loss: 3.0872 - beta: 0.0329 - val_loss: 5.8663 - val_recon_loss: 0.0031 - val_KL loss: 3.0389 - val_beta: 0.0329\n",
      "Epoch 1187/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5.5524 - recon_loss: 0.0027 - KL loss: 3.0723 - beta: 0.0329 - val_loss: 5.2303 - val_recon_loss: 0.0024 - val_KL loss: 3.0645 - val_beta: 0.0329\n",
      "Epoch 1188/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5.5327 - recon_loss: 0.0027 - KL loss: 3.0606 - beta: 0.0329 - val_loss: 5.5796 - val_recon_loss: 0.0028 - val_KL loss: 2.9980 - val_beta: 0.0329\n",
      "Epoch 1189/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5320 - recon_loss: 0.0027 - KL loss: 3.0663 - beta: 0.0329 - val_loss: 5.3075 - val_recon_loss: 0.0025 - val_KL loss: 3.0354 - val_beta: 0.0329\n",
      "Epoch 1190/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5116 - recon_loss: 0.0027 - KL loss: 3.0598 - beta: 0.0329 - val_loss: 5.5298 - val_recon_loss: 0.0027 - val_KL loss: 3.0693 - val_beta: 0.0329\n",
      "Epoch 1191/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5.5240 - recon_loss: 0.0027 - KL loss: 3.0643 - beta: 0.0329 - val_loss: 5.3109 - val_recon_loss: 0.0024 - val_KL loss: 3.0781 - val_beta: 0.0329\n",
      "Epoch 1192/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 5.5435 - recon_loss: 0.0027 - KL loss: 3.0842 - beta: 0.0329\n",
      "Epoch 01192: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5435 - recon_loss: 0.0027 - KL loss: 3.0842 - beta: 0.0329 - val_loss: 5.2436 - val_recon_loss: 0.0024 - val_KL loss: 3.0312 - val_beta: 0.0329\n",
      "Epoch 1193/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5457 - recon_loss: 0.0027 - KL loss: 3.0799 - beta: 0.0329 - val_loss: 5.1257 - val_recon_loss: 0.0023 - val_KL loss: 3.0444 - val_beta: 0.0329\n",
      "Epoch 1194/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5.5288 - recon_loss: 0.0027 - KL loss: 3.0711 - beta: 0.0329 - val_loss: 5.2906 - val_recon_loss: 0.0025 - val_KL loss: 3.0316 - val_beta: 0.0329\n",
      "Epoch 1195/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5.5290 - recon_loss: 0.0027 - KL loss: 3.0676 - beta: 0.0329 - val_loss: 5.6336 - val_recon_loss: 0.0028 - val_KL loss: 3.0187 - val_beta: 0.0329\n",
      "Epoch 1196/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5216 - recon_loss: 0.0027 - KL loss: 3.0542 - beta: 0.0329 - val_loss: 5.5550 - val_recon_loss: 0.0027 - val_KL loss: 3.0585 - val_beta: 0.0329\n",
      "Epoch 1197/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5234 - recon_loss: 0.0027 - KL loss: 3.0648 - beta: 0.0329 - val_loss: 5.9202 - val_recon_loss: 0.0032 - val_KL loss: 2.9880 - val_beta: 0.0329\n",
      "Epoch 1198/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.5354 - recon_loss: 0.0027 - KL loss: 3.0665 - beta: 0.0329\n",
      "Epoch 01198: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5.5354 - recon_loss: 0.0027 - KL loss: 3.0665 - beta: 0.0329 - val_loss: 5.5055 - val_recon_loss: 0.0027 - val_KL loss: 3.0411 - val_beta: 0.0329\n",
      "Epoch 1199/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5170 - recon_loss: 0.0027 - KL loss: 3.0735 - beta: 0.0329 - val_loss: 5.5379 - val_recon_loss: 0.0027 - val_KL loss: 3.0181 - val_beta: 0.0329\n",
      "Epoch 1200/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5.5085 - recon_loss: 0.0027 - KL loss: 3.0525 - beta: 0.0329 - val_loss: 5.7067 - val_recon_loss: 0.0029 - val_KL loss: 3.0246 - val_beta: 0.0329\n",
      "Epoch 1201/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5.5338 - recon_loss: 0.0027 - KL loss: 3.0648 - beta: 0.0329 - val_loss: 5.6024 - val_recon_loss: 0.0028 - val_KL loss: 3.0415 - val_beta: 0.0329\n",
      "Epoch 1202/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5.5313 - recon_loss: 0.0027 - KL loss: 3.0735 - beta: 0.0329 - val_loss: 5.4043 - val_recon_loss: 0.0026 - val_KL loss: 3.0379 - val_beta: 0.0329\n",
      "Epoch 1203/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.5162 - recon_loss: 0.0027 - KL loss: 3.0699 - beta: 0.0329\n",
      "Epoch 01203: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.5162 - recon_loss: 0.0027 - KL loss: 3.0699 - beta: 0.0329 - val_loss: 5.3062 - val_recon_loss: 0.0025 - val_KL loss: 3.0220 - val_beta: 0.0329\n",
      "Epoch 1203/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6840 - recon_loss: 0.0034 - KL loss: 2.5563 - beta: 0.0400 - val_loss: 4.5003 - val_recon_loss: 0.0033 - val_KL loss: 2.4295 - val_beta: 0.0400\n",
      "Epoch 1204/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6853 - recon_loss: 0.0035 - KL loss: 2.4734 - beta: 0.0400 - val_loss: 4.7529 - val_recon_loss: 0.0037 - val_KL loss: 2.4514 - val_beta: 0.0400\n",
      "Epoch 1205/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6702 - recon_loss: 0.0036 - KL loss: 2.4398 - beta: 0.0400 - val_loss: 4.7370 - val_recon_loss: 0.0038 - val_KL loss: 2.3727 - val_beta: 0.0400\n",
      "Epoch 1206/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6632 - recon_loss: 0.0036 - KL loss: 2.4256 - beta: 0.0400 - val_loss: 4.5567 - val_recon_loss: 0.0035 - val_KL loss: 2.3457 - val_beta: 0.0400\n",
      "Epoch 1207/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6584 - recon_loss: 0.0036 - KL loss: 2.4069 - beta: 0.0400 - val_loss: 4.5395 - val_recon_loss: 0.0035 - val_KL loss: 2.3477 - val_beta: 0.0400\n",
      "Epoch 1208/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.6718 - recon_loss: 0.0036 - KL loss: 2.4018 - beta: 0.0400\n",
      "Epoch 01208: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6718 - recon_loss: 0.0036 - KL loss: 2.4018 - beta: 0.0400 - val_loss: 4.6755 - val_recon_loss: 0.0038 - val_KL loss: 2.3155 - val_beta: 0.0400\n",
      "Epoch 1209/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6421 - recon_loss: 0.0036 - KL loss: 2.4093 - beta: 0.0400 - val_loss: 4.6443 - val_recon_loss: 0.0037 - val_KL loss: 2.3517 - val_beta: 0.0400\n",
      "Epoch 1210/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6457 - recon_loss: 0.0036 - KL loss: 2.4220 - beta: 0.0400 - val_loss: 4.4002 - val_recon_loss: 0.0033 - val_KL loss: 2.3508 - val_beta: 0.0400\n",
      "Epoch 1211/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6252 - recon_loss: 0.0035 - KL loss: 2.4208 - beta: 0.0400 - val_loss: 4.5202 - val_recon_loss: 0.0034 - val_KL loss: 2.3867 - val_beta: 0.0400\n",
      "Epoch 1212/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6273 - recon_loss: 0.0035 - KL loss: 2.4137 - beta: 0.0400 - val_loss: 4.7266 - val_recon_loss: 0.0037 - val_KL loss: 2.3894 - val_beta: 0.0400\n",
      "Epoch 1213/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6149 - recon_loss: 0.0035 - KL loss: 2.4127 - beta: 0.0400 - val_loss: 4.5912 - val_recon_loss: 0.0036 - val_KL loss: 2.3671 - val_beta: 0.0400\n",
      "Epoch 1214/10000\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 4.6302 - recon_loss: 0.0035 - KL loss: 2.4209 - beta: 0.0400 - val_loss: 4.4711 - val_recon_loss: 0.0033 - val_KL loss: 2.4009 - val_beta: 0.0400\n",
      "Epoch 1215/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.6213 - recon_loss: 0.0035 - KL loss: 2.4159 - beta: 0.0400\n",
      "Epoch 01215: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 4.6213 - recon_loss: 0.0035 - KL loss: 2.4159 - beta: 0.0400 - val_loss: 4.5967 - val_recon_loss: 0.0035 - val_KL loss: 2.3844 - val_beta: 0.0400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1216/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6301 - recon_loss: 0.0035 - KL loss: 2.4277 - beta: 0.0400 - val_loss: 4.4154 - val_recon_loss: 0.0033 - val_KL loss: 2.3727 - val_beta: 0.0400\n",
      "Epoch 1217/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6135 - recon_loss: 0.0035 - KL loss: 2.4217 - beta: 0.0400 - val_loss: 4.4533 - val_recon_loss: 0.0033 - val_KL loss: 2.3814 - val_beta: 0.0400\n",
      "Epoch 1218/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6260 - recon_loss: 0.0035 - KL loss: 2.4347 - beta: 0.0400 - val_loss: 4.4940 - val_recon_loss: 0.0034 - val_KL loss: 2.3654 - val_beta: 0.0400\n",
      "Epoch 1219/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4.6147 - recon_loss: 0.0035 - KL loss: 2.4268 - beta: 0.0400 - val_loss: 4.6789 - val_recon_loss: 0.0037 - val_KL loss: 2.3540 - val_beta: 0.0400\n",
      "Epoch 1220/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.6133 - recon_loss: 0.0035 - KL loss: 2.4144 - beta: 0.0400\n",
      "Epoch 01220: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4.6133 - recon_loss: 0.0035 - KL loss: 2.4144 - beta: 0.0400 - val_loss: 4.6047 - val_recon_loss: 0.0035 - val_KL loss: 2.3927 - val_beta: 0.0400\n",
      "Epoch 1220/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.2640 - recon_loss: 0.0026 - KL loss: 3.2173 - beta: 0.0292 - val_loss: 6.1401 - val_recon_loss: 0.0024 - val_KL loss: 3.2722 - val_beta: 0.0292\n",
      "Epoch 1221/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.2123 - recon_loss: 0.0025 - KL loss: 3.3120 - beta: 0.0292 - val_loss: 5.8922 - val_recon_loss: 0.0022 - val_KL loss: 3.2596 - val_beta: 0.0292\n",
      "Epoch 1222/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.1957 - recon_loss: 0.0024 - KL loss: 3.3431 - beta: 0.0292 - val_loss: 6.0563 - val_recon_loss: 0.0024 - val_KL loss: 3.2692 - val_beta: 0.0292\n",
      "Epoch 1223/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.1441 - recon_loss: 0.0024 - KL loss: 3.3297 - beta: 0.0292 - val_loss: 6.0595 - val_recon_loss: 0.0023 - val_KL loss: 3.3605 - val_beta: 0.0292\n",
      "Epoch 1224/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.1442 - recon_loss: 0.0024 - KL loss: 3.3319 - beta: 0.0292 - val_loss: 6.1369 - val_recon_loss: 0.0024 - val_KL loss: 3.3716 - val_beta: 0.0292\n",
      "Epoch 1225/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6.1548 - recon_loss: 0.0024 - KL loss: 3.3428 - beta: 0.0292 - val_loss: 6.0968 - val_recon_loss: 0.0025 - val_KL loss: 3.1893 - val_beta: 0.0292\n",
      "Epoch 1226/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 6.1460 - recon_loss: 0.0024 - KL loss: 3.3132 - beta: 0.0292\n",
      "Epoch 01226: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.1460 - recon_loss: 0.0024 - KL loss: 3.3132 - beta: 0.0292 - val_loss: 6.0206 - val_recon_loss: 0.0023 - val_KL loss: 3.2839 - val_beta: 0.0292\n",
      "Epoch 1227/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.0859 - recon_loss: 0.0024 - KL loss: 3.3237 - beta: 0.0292 - val_loss: 6.0251 - val_recon_loss: 0.0023 - val_KL loss: 3.3210 - val_beta: 0.0292\n",
      "Epoch 1228/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.0732 - recon_loss: 0.0023 - KL loss: 3.3268 - beta: 0.0292 - val_loss: 6.1388 - val_recon_loss: 0.0024 - val_KL loss: 3.3051 - val_beta: 0.0292\n",
      "Epoch 1229/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.0377 - recon_loss: 0.0023 - KL loss: 3.3033 - beta: 0.0292 - val_loss: 6.0456 - val_recon_loss: 0.0024 - val_KL loss: 3.2154 - val_beta: 0.0292\n",
      "Epoch 1230/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.0470 - recon_loss: 0.0023 - KL loss: 3.3105 - beta: 0.0292 - val_loss: 5.8186 - val_recon_loss: 0.0022 - val_KL loss: 3.2562 - val_beta: 0.0292\n",
      "Epoch 1231/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.0318 - recon_loss: 0.0023 - KL loss: 3.2994 - beta: 0.0292 - val_loss: 5.8978 - val_recon_loss: 0.0022 - val_KL loss: 3.3120 - val_beta: 0.0292\n",
      "Epoch 1232/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.0284 - recon_loss: 0.0023 - KL loss: 3.3042 - beta: 0.0292 - val_loss: 5.9329 - val_recon_loss: 0.0022 - val_KL loss: 3.3166 - val_beta: 0.0292\n",
      "Epoch 1233/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.0223 - recon_loss: 0.0023 - KL loss: 3.3025 - beta: 0.0292 - val_loss: 5.8427 - val_recon_loss: 0.0022 - val_KL loss: 3.2674 - val_beta: 0.0292\n",
      "Epoch 1234/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6.0065 - recon_loss: 0.0023 - KL loss: 3.2934 - beta: 0.0292 - val_loss: 6.0159 - val_recon_loss: 0.0024 - val_KL loss: 3.2385 - val_beta: 0.0292\n",
      "Epoch 1235/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 6.0161 - recon_loss: 0.0023 - KL loss: 3.2788 - beta: 0.0292\n",
      "Epoch 01235: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 6.0160 - recon_loss: 0.0023 - KL loss: 3.2788 - beta: 0.0292 - val_loss: 5.9054 - val_recon_loss: 0.0023 - val_KL loss: 3.2612 - val_beta: 0.0292\n",
      "Epoch 1236/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.9777 - recon_loss: 0.0023 - KL loss: 3.2838 - beta: 0.0292 - val_loss: 5.8376 - val_recon_loss: 0.0022 - val_KL loss: 3.2493 - val_beta: 0.0292\n",
      "Epoch 1237/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 5.9725 - recon_loss: 0.0023 - KL loss: 3.2811 - beta: 0.0292 - val_loss: 6.0157 - val_recon_loss: 0.0024 - val_KL loss: 3.2337 - val_beta: 0.0292\n",
      "Epoch 1238/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.9833 - recon_loss: 0.0023 - KL loss: 3.2748 - beta: 0.0292 - val_loss: 6.1662 - val_recon_loss: 0.0025 - val_KL loss: 3.2308 - val_beta: 0.0292\n",
      "Epoch 1239/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.9729 - recon_loss: 0.0023 - KL loss: 3.2659 - beta: 0.0292 - val_loss: 6.2067 - val_recon_loss: 0.0025 - val_KL loss: 3.2315 - val_beta: 0.0292\n",
      "Epoch 1240/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.9505 - recon_loss: 0.0023 - KL loss: 3.2716 - beta: 0.0292\n",
      "Epoch 01240: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5.9505 - recon_loss: 0.0023 - KL loss: 3.2716 - beta: 0.0292 - val_loss: 5.9008 - val_recon_loss: 0.0023 - val_KL loss: 3.2134 - val_beta: 0.0292\n",
      "Epoch 1240/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 8.1986 - recon_loss: 0.0019 - KL loss: 3.9798 - beta: 0.0213 - val_loss: 8.2050 - val_recon_loss: 0.0019 - val_KL loss: 4.1148 - val_beta: 0.0213\n",
      "Epoch 1241/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 8.1715 - recon_loss: 0.0019 - KL loss: 4.0789 - beta: 0.0213 - val_loss: 7.7874 - val_recon_loss: 0.0017 - val_KL loss: 4.0344 - val_beta: 0.0213\n",
      "Epoch 1242/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 8.1984 - recon_loss: 0.0018 - KL loss: 4.1198 - beta: 0.0213 - val_loss: 7.8378 - val_recon_loss: 0.0017 - val_KL loss: 4.1479 - val_beta: 0.0213\n",
      "Epoch 1243/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 8.1376 - recon_loss: 0.0018 - KL loss: 4.1276 - beta: 0.0213 - val_loss: 7.9671 - val_recon_loss: 0.0017 - val_KL loss: 4.2030 - val_beta: 0.0213\n",
      "Epoch 1244/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 8.2673 - recon_loss: 0.0018 - KL loss: 4.2105 - beta: 0.0213 - val_loss: 8.6035 - val_recon_loss: 0.0020 - val_KL loss: 4.2352 - val_beta: 0.0213\n",
      "Epoch 1245/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 8.4747 - recon_loss: 0.0019 - KL loss: 4.2914 - beta: 0.0213 - val_loss: 8.3994 - val_recon_loss: 0.0019 - val_KL loss: 4.1150 - val_beta: 0.0213\n",
      "Epoch 1246/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.4458 - recon_loss: 0.0019 - KL loss: 4.2733 - beta: 0.0213\n",
      "Epoch 01246: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 8.4458 - recon_loss: 0.0019 - KL loss: 4.2733 - beta: 0.0213 - val_loss: 7.9332 - val_recon_loss: 0.0017 - val_KL loss: 4.0867 - val_beta: 0.0213\n",
      "Epoch 1247/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 8.1808 - recon_loss: 0.0018 - KL loss: 4.2247 - beta: 0.0213 - val_loss: 7.9763 - val_recon_loss: 0.0017 - val_KL loss: 4.2311 - val_beta: 0.0213\n",
      "Epoch 1248/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 8.2027 - recon_loss: 0.0018 - KL loss: 4.2391 - beta: 0.0213 - val_loss: 8.2863 - val_recon_loss: 0.0019 - val_KL loss: 4.1731 - val_beta: 0.0213\n",
      "Epoch 1249/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 8.1903 - recon_loss: 0.0018 - KL loss: 4.2419 - beta: 0.0213 - val_loss: 8.4676 - val_recon_loss: 0.0020 - val_KL loss: 4.1569 - val_beta: 0.0213\n",
      "Epoch 1250/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 8.1733 - recon_loss: 0.0018 - KL loss: 4.2463 - beta: 0.0213 - val_loss: 7.9864 - val_recon_loss: 0.0017 - val_KL loss: 4.1815 - val_beta: 0.0213\n",
      "Epoch 1251/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.1681 - recon_loss: 0.0018 - KL loss: 4.2415 - beta: 0.0213\n",
      "Epoch 01251: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 8.1681 - recon_loss: 0.0018 - KL loss: 4.2415 - beta: 0.0213 - val_loss: 8.0097 - val_recon_loss: 0.0017 - val_KL loss: 4.1996 - val_beta: 0.0213\n",
      "Epoch 1251/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.9845 - recon_loss: 0.0017 - KL loss: 5.1151 - beta: 0.0155 - val_loss: 11.3925 - val_recon_loss: 0.0015 - val_KL loss: 4.9707 - val_beta: 0.0155\n",
      "Epoch 1252/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 11.4887 - recon_loss: 0.0016 - KL loss: 5.0528 - beta: 0.0155 - val_loss: 11.2033 - val_recon_loss: 0.0015 - val_KL loss: 4.9835 - val_beta: 0.0155\n",
      "Epoch 1253/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.3631 - recon_loss: 0.0015 - KL loss: 5.0539 - beta: 0.0155 - val_loss: 11.0519 - val_recon_loss: 0.0014 - val_KL loss: 5.0760 - val_beta: 0.0155\n",
      "Epoch 1254/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.2097 - recon_loss: 0.0015 - KL loss: 5.1280 - beta: 0.0155 - val_loss: 10.8381 - val_recon_loss: 0.0014 - val_KL loss: 5.0165 - val_beta: 0.0155\n",
      "Epoch 1255/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.2441 - recon_loss: 0.0015 - KL loss: 5.0878 - beta: 0.0155 - val_loss: 10.9397 - val_recon_loss: 0.0014 - val_KL loss: 5.0443 - val_beta: 0.0155\n",
      "Epoch 1256/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.2636 - recon_loss: 0.0015 - KL loss: 5.1341 - beta: 0.0155 - val_loss: 10.7484 - val_recon_loss: 0.0014 - val_KL loss: 5.1292 - val_beta: 0.0155\n",
      "Epoch 1257/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11.4036 - recon_loss: 0.0015 - KL loss: 5.1889 - beta: 0.0155 - val_loss: 10.8584 - val_recon_loss: 0.0014 - val_KL loss: 5.1353 - val_beta: 0.0155\n",
      "Epoch 1258/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.2189 - recon_loss: 0.0015 - KL loss: 5.1004 - beta: 0.0155 - val_loss: 11.0560 - val_recon_loss: 0.0015 - val_KL loss: 5.0142 - val_beta: 0.0155\n",
      "Epoch 1259/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11.2042 - recon_loss: 0.0015 - KL loss: 5.0778 - beta: 0.0155 - val_loss: 10.9707 - val_recon_loss: 0.0014 - val_KL loss: 5.0556 - val_beta: 0.0155\n",
      "Epoch 1260/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.1475 - recon_loss: 0.0015 - KL loss: 5.1345 - beta: 0.0155 - val_loss: 10.5623 - val_recon_loss: 0.0013 - val_KL loss: 5.0906 - val_beta: 0.0155\n",
      "Epoch 1261/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 11.2368 - recon_loss: 0.0015 - KL loss: 5.0947 - beta: 0.0155 - val_loss: 10.9019 - val_recon_loss: 0.0014 - val_KL loss: 5.0195 - val_beta: 0.0155\n",
      "Epoch 1262/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11.1491 - recon_loss: 0.0015 - KL loss: 5.0919 - beta: 0.0155 - val_loss: 10.9751 - val_recon_loss: 0.0014 - val_KL loss: 5.3613 - val_beta: 0.0155\n",
      "Epoch 1263/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.6570 - recon_loss: 0.0015 - KL loss: 5.2810 - beta: 0.0155 - val_loss: 11.9123 - val_recon_loss: 0.0016 - val_KL loss: 5.3642 - val_beta: 0.0155\n",
      "Epoch 1264/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.5230 - recon_loss: 0.0015 - KL loss: 5.2560 - beta: 0.0155 - val_loss: 11.4148 - val_recon_loss: 0.0015 - val_KL loss: 5.2177 - val_beta: 0.0155\n",
      "Epoch 1265/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.4307 - recon_loss: 0.0015 - KL loss: 5.2713 - beta: 0.0155\n",
      "Epoch 01265: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.4306 - recon_loss: 0.0015 - KL loss: 5.2713 - beta: 0.0155 - val_loss: 10.7158 - val_recon_loss: 0.0013 - val_KL loss: 5.1659 - val_beta: 0.0155\n",
      "Epoch 1266/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.1443 - recon_loss: 0.0014 - KL loss: 5.2391 - beta: 0.0155 - val_loss: 10.4869 - val_recon_loss: 0.0013 - val_KL loss: 5.1763 - val_beta: 0.0155\n",
      "Epoch 1267/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.1710 - recon_loss: 0.0014 - KL loss: 5.2478 - beta: 0.0155 - val_loss: 10.8791 - val_recon_loss: 0.0014 - val_KL loss: 5.1687 - val_beta: 0.0155\n",
      "Epoch 1268/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.1329 - recon_loss: 0.0014 - KL loss: 5.1987 - beta: 0.0155 - val_loss: 10.8042 - val_recon_loss: 0.0014 - val_KL loss: 5.1236 - val_beta: 0.0155\n",
      "Epoch 1269/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.0410 - recon_loss: 0.0014 - KL loss: 5.1622 - beta: 0.0155 - val_loss: 10.9639 - val_recon_loss: 0.0014 - val_KL loss: 5.1874 - val_beta: 0.0155\n",
      "Epoch 1270/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 11.0131 - recon_loss: 0.0014 - KL loss: 5.1973 - beta: 0.0155 - val_loss: 10.5648 - val_recon_loss: 0.0013 - val_KL loss: 5.1582 - val_beta: 0.0155\n",
      "Epoch 1271/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.0076 - recon_loss: 0.0014 - KL loss: 5.1790 - beta: 0.0155\n",
      "Epoch 01271: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11.0077 - recon_loss: 0.0014 - KL loss: 5.1790 - beta: 0.0155 - val_loss: 10.5586 - val_recon_loss: 0.0013 - val_KL loss: 5.1488 - val_beta: 0.0155\n",
      "Epoch 1272/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 10.9686 - recon_loss: 0.0014 - KL loss: 5.1840 - beta: 0.0155 - val_loss: 11.2308 - val_recon_loss: 0.0015 - val_KL loss: 5.1488 - val_beta: 0.0155\n",
      "Epoch 1273/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.9769 - recon_loss: 0.0014 - KL loss: 5.1669 - beta: 0.0155 - val_loss: 10.4351 - val_recon_loss: 0.0013 - val_KL loss: 5.1776 - val_beta: 0.0155\n",
      "Epoch 1274/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.9261 - recon_loss: 0.0014 - KL loss: 5.1740 - beta: 0.0155 - val_loss: 10.9273 - val_recon_loss: 0.0014 - val_KL loss: 5.1317 - val_beta: 0.0155\n",
      "Epoch 1275/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 11.0178 - recon_loss: 0.0014 - KL loss: 5.1769 - beta: 0.0155 - val_loss: 10.6918 - val_recon_loss: 0.0013 - val_KL loss: 5.1498 - val_beta: 0.0155\n",
      "Epoch 1276/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.9167 - recon_loss: 0.0014 - KL loss: 5.1816 - beta: 0.0155 - val_loss: 11.3195 - val_recon_loss: 0.0015 - val_KL loss: 5.1182 - val_beta: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1277/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10.9178 - recon_loss: 0.0014 - KL loss: 5.1674 - beta: 0.0155 - val_loss: 10.4279 - val_recon_loss: 0.0013 - val_KL loss: 5.1464 - val_beta: 0.0155\n",
      "Epoch 1278/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.9077 - recon_loss: 0.0014 - KL loss: 5.1859 - beta: 0.0155 - val_loss: 10.5814 - val_recon_loss: 0.0013 - val_KL loss: 5.1175 - val_beta: 0.0155\n",
      "Epoch 1279/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.9518 - recon_loss: 0.0014 - KL loss: 5.1691 - beta: 0.0155 - val_loss: 10.3873 - val_recon_loss: 0.0013 - val_KL loss: 5.1308 - val_beta: 0.0155\n",
      "Epoch 1280/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.9433 - recon_loss: 0.0014 - KL loss: 5.1687 - beta: 0.0155 - val_loss: 10.5176 - val_recon_loss: 0.0013 - val_KL loss: 5.0991 - val_beta: 0.0155\n",
      "Epoch 1281/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10.9150 - recon_loss: 0.0014 - KL loss: 5.1601 - beta: 0.0155 - val_loss: 10.3954 - val_recon_loss: 0.0013 - val_KL loss: 5.1170 - val_beta: 0.0155\n",
      "Epoch 1282/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10.9492 - recon_loss: 0.0014 - KL loss: 5.1750 - beta: 0.0155 - val_loss: 10.5725 - val_recon_loss: 0.0013 - val_KL loss: 5.1523 - val_beta: 0.0155\n",
      "Epoch 1283/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.9284 - recon_loss: 0.0014 - KL loss: 5.1900 - beta: 0.0155 - val_loss: 10.6810 - val_recon_loss: 0.0013 - val_KL loss: 5.1297 - val_beta: 0.0155\n",
      "Epoch 1284/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.9231 - recon_loss: 0.0014 - KL loss: 5.1803 - beta: 0.0155\n",
      "Epoch 01284: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.9231 - recon_loss: 0.0014 - KL loss: 5.1803 - beta: 0.0155 - val_loss: 10.6294 - val_recon_loss: 0.0013 - val_KL loss: 5.1249 - val_beta: 0.0155\n",
      "Epoch 1285/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.9309 - recon_loss: 0.0014 - KL loss: 5.1718 - beta: 0.0155 - val_loss: 10.3794 - val_recon_loss: 0.0013 - val_KL loss: 5.1382 - val_beta: 0.0155\n",
      "Epoch 1286/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8880 - recon_loss: 0.0014 - KL loss: 5.1787 - beta: 0.0155 - val_loss: 10.4301 - val_recon_loss: 0.0013 - val_KL loss: 5.1247 - val_beta: 0.0155\n",
      "Epoch 1287/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10.8566 - recon_loss: 0.0014 - KL loss: 5.1706 - beta: 0.0155 - val_loss: 10.4815 - val_recon_loss: 0.0013 - val_KL loss: 5.1323 - val_beta: 0.0155\n",
      "Epoch 1288/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10.9437 - recon_loss: 0.0014 - KL loss: 5.1790 - beta: 0.0155 - val_loss: 10.4914 - val_recon_loss: 0.0013 - val_KL loss: 5.1300 - val_beta: 0.0155\n",
      "Epoch 1289/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.9032 - recon_loss: 0.0014 - KL loss: 5.1696 - beta: 0.0155 - val_loss: 10.3472 - val_recon_loss: 0.0013 - val_KL loss: 5.1294 - val_beta: 0.0155\n",
      "Epoch 1290/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10.8788 - recon_loss: 0.0014 - KL loss: 5.1705 - beta: 0.0155 - val_loss: 10.6331 - val_recon_loss: 0.0013 - val_KL loss: 5.1341 - val_beta: 0.0155\n",
      "Epoch 1291/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8970 - recon_loss: 0.0014 - KL loss: 5.1765 - beta: 0.0155 - val_loss: 10.5867 - val_recon_loss: 0.0013 - val_KL loss: 5.1415 - val_beta: 0.0155\n",
      "Epoch 1292/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8677 - recon_loss: 0.0014 - KL loss: 5.1700 - beta: 0.0155 - val_loss: 11.4990 - val_recon_loss: 0.0015 - val_KL loss: 5.1177 - val_beta: 0.0155\n",
      "Epoch 1293/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8795 - recon_loss: 0.0014 - KL loss: 5.1700 - beta: 0.0155 - val_loss: 10.4003 - val_recon_loss: 0.0013 - val_KL loss: 5.1011 - val_beta: 0.0155\n",
      "Epoch 1294/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.8873 - recon_loss: 0.0014 - KL loss: 5.1495 - beta: 0.0155\n",
      "Epoch 01294: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10.8873 - recon_loss: 0.0014 - KL loss: 5.1495 - beta: 0.0155 - val_loss: 10.7156 - val_recon_loss: 0.0014 - val_KL loss: 5.0909 - val_beta: 0.0155\n",
      "Epoch 1295/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8864 - recon_loss: 0.0014 - KL loss: 5.1509 - beta: 0.0155 - val_loss: 10.4117 - val_recon_loss: 0.0013 - val_KL loss: 5.1167 - val_beta: 0.0155\n",
      "Epoch 1296/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8725 - recon_loss: 0.0014 - KL loss: 5.1663 - beta: 0.0155 - val_loss: 10.3245 - val_recon_loss: 0.0013 - val_KL loss: 5.1177 - val_beta: 0.0155\n",
      "Epoch 1297/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8708 - recon_loss: 0.0014 - KL loss: 5.1661 - beta: 0.0155 - val_loss: 10.7086 - val_recon_loss: 0.0014 - val_KL loss: 5.1115 - val_beta: 0.0155\n",
      "Epoch 1298/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10.8692 - recon_loss: 0.0014 - KL loss: 5.1676 - beta: 0.0155 - val_loss: 10.7890 - val_recon_loss: 0.0014 - val_KL loss: 5.1111 - val_beta: 0.0155\n",
      "Epoch 1299/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8647 - recon_loss: 0.0014 - KL loss: 5.1701 - beta: 0.0155 - val_loss: 10.7558 - val_recon_loss: 0.0014 - val_KL loss: 5.1110 - val_beta: 0.0155\n",
      "Epoch 1300/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8880 - recon_loss: 0.0014 - KL loss: 5.1612 - beta: 0.0155 - val_loss: 10.4521 - val_recon_loss: 0.0013 - val_KL loss: 5.1037 - val_beta: 0.0155\n",
      "Epoch 1301/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.8963 - recon_loss: 0.0014 - KL loss: 5.1602 - beta: 0.0155\n",
      "Epoch 01301: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8963 - recon_loss: 0.0014 - KL loss: 5.1602 - beta: 0.0155 - val_loss: 10.6207 - val_recon_loss: 0.0013 - val_KL loss: 5.1100 - val_beta: 0.0155\n",
      "Epoch 1302/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8285 - recon_loss: 0.0014 - KL loss: 5.1673 - beta: 0.0155 - val_loss: 10.7276 - val_recon_loss: 0.0014 - val_KL loss: 5.1100 - val_beta: 0.0155\n",
      "Epoch 1303/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8534 - recon_loss: 0.0014 - KL loss: 5.1676 - beta: 0.0155 - val_loss: 10.4004 - val_recon_loss: 0.0013 - val_KL loss: 5.1089 - val_beta: 0.0155\n",
      "Epoch 1304/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 10.8456 - recon_loss: 0.0014 - KL loss: 5.1627 - beta: 0.0155 - val_loss: 10.5923 - val_recon_loss: 0.0013 - val_KL loss: 5.1054 - val_beta: 0.0155\n",
      "Epoch 1305/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8767 - recon_loss: 0.0014 - KL loss: 5.1614 - beta: 0.0155 - val_loss: 10.4168 - val_recon_loss: 0.0013 - val_KL loss: 5.1082 - val_beta: 0.0155\n",
      "Epoch 1306/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.8767 - recon_loss: 0.0014 - KL loss: 5.1665 - beta: 0.0155\n",
      "Epoch 01306: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10.8767 - recon_loss: 0.0014 - KL loss: 5.1665 - beta: 0.0155 - val_loss: 10.8222 - val_recon_loss: 0.0014 - val_KL loss: 5.1092 - val_beta: 0.0155\n",
      "Epoch 1306/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 16.0726 - recon_loss: 0.0013 - KL loss: 5.9781 - beta: 0.0113 - val_loss: 16.0122 - val_recon_loss: 0.0013 - val_KL loss: 6.0376 - val_beta: 0.0113\n",
      "Epoch 1307/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 16.0984 - recon_loss: 0.0013 - KL loss: 6.0513 - beta: 0.0113 - val_loss: 15.3034 - val_recon_loss: 0.0012 - val_KL loss: 5.9973 - val_beta: 0.0113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1308/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.8431 - recon_loss: 0.0013 - KL loss: 6.0280 - beta: 0.0113 - val_loss: 15.7150 - val_recon_loss: 0.0013 - val_KL loss: 5.9308 - val_beta: 0.0113\n",
      "Epoch 1309/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.7787 - recon_loss: 0.0012 - KL loss: 6.0482 - beta: 0.0113 - val_loss: 15.5103 - val_recon_loss: 0.0012 - val_KL loss: 6.0116 - val_beta: 0.0113\n",
      "Epoch 1310/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.7820 - recon_loss: 0.0012 - KL loss: 6.0686 - beta: 0.0113 - val_loss: 15.7260 - val_recon_loss: 0.0012 - val_KL loss: 6.0426 - val_beta: 0.0113\n",
      "Epoch 1311/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.7840 - recon_loss: 0.0012 - KL loss: 6.0763 - beta: 0.0113 - val_loss: 15.8522 - val_recon_loss: 0.0013 - val_KL loss: 5.9481 - val_beta: 0.0113\n",
      "Epoch 1312/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 15.6869 - recon_loss: 0.0012 - KL loss: 6.0689 - beta: 0.0113\n",
      "Epoch 01312: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.6869 - recon_loss: 0.0012 - KL loss: 6.0689 - beta: 0.0113 - val_loss: 15.7180 - val_recon_loss: 0.0012 - val_KL loss: 5.9826 - val_beta: 0.0113\n",
      "Epoch 1313/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.5069 - recon_loss: 0.0012 - KL loss: 6.0865 - beta: 0.0113 - val_loss: 15.0592 - val_recon_loss: 0.0012 - val_KL loss: 5.9837 - val_beta: 0.0113\n",
      "Epoch 1314/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.4428 - recon_loss: 0.0012 - KL loss: 6.0846 - beta: 0.0113 - val_loss: 14.9295 - val_recon_loss: 0.0011 - val_KL loss: 6.0304 - val_beta: 0.0113\n",
      "Epoch 1315/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.4753 - recon_loss: 0.0012 - KL loss: 6.0866 - beta: 0.0113 - val_loss: 15.2399 - val_recon_loss: 0.0012 - val_KL loss: 6.1153 - val_beta: 0.0113\n",
      "Epoch 1316/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.4172 - recon_loss: 0.0012 - KL loss: 6.0955 - beta: 0.0113 - val_loss: 15.3623 - val_recon_loss: 0.0012 - val_KL loss: 6.0719 - val_beta: 0.0113\n",
      "Epoch 1317/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.6196 - recon_loss: 0.0012 - KL loss: 6.0835 - beta: 0.0113 - val_loss: 15.2877 - val_recon_loss: 0.0012 - val_KL loss: 6.0538 - val_beta: 0.0113\n",
      "Epoch 1318/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.4876 - recon_loss: 0.0012 - KL loss: 6.0965 - beta: 0.0113 - val_loss: 15.2397 - val_recon_loss: 0.0012 - val_KL loss: 6.0874 - val_beta: 0.0113\n",
      "Epoch 1319/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 15.4882 - recon_loss: 0.0012 - KL loss: 6.0830 - beta: 0.0113\n",
      "Epoch 01319: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.4882 - recon_loss: 0.0012 - KL loss: 6.0830 - beta: 0.0113 - val_loss: 15.1834 - val_recon_loss: 0.0012 - val_KL loss: 6.0609 - val_beta: 0.0113\n",
      "Epoch 1320/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.5019 - recon_loss: 0.0012 - KL loss: 6.1195 - beta: 0.0113 - val_loss: 15.4952 - val_recon_loss: 0.0012 - val_KL loss: 6.1078 - val_beta: 0.0113\n",
      "Epoch 1321/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.4939 - recon_loss: 0.0012 - KL loss: 6.1121 - beta: 0.0113 - val_loss: 15.3865 - val_recon_loss: 0.0012 - val_KL loss: 6.0607 - val_beta: 0.0113\n",
      "Epoch 1322/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15.3758 - recon_loss: 0.0012 - KL loss: 6.0934 - beta: 0.0113 - val_loss: 15.4576 - val_recon_loss: 0.0012 - val_KL loss: 6.0875 - val_beta: 0.0113\n",
      "Epoch 1323/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.4320 - recon_loss: 0.0012 - KL loss: 6.1068 - beta: 0.0113 - val_loss: 15.2640 - val_recon_loss: 0.0012 - val_KL loss: 6.0447 - val_beta: 0.0113\n",
      "Epoch 1324/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 15.4112 - recon_loss: 0.0012 - KL loss: 6.1072 - beta: 0.0113\n",
      "Epoch 01324: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15.4112 - recon_loss: 0.0012 - KL loss: 6.1071 - beta: 0.0113 - val_loss: 15.0418 - val_recon_loss: 0.0012 - val_KL loss: 6.0495 - val_beta: 0.0113\n",
      "Epoch 1324/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23.7587 - recon_loss: 0.0011 - KL loss: 7.0016 - beta: 0.0083 - val_loss: 23.4562 - val_recon_loss: 0.0011 - val_KL loss: 7.2980 - val_beta: 0.0083\n",
      "Epoch 1325/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 23.7416 - recon_loss: 0.0011 - KL loss: 7.1562 - beta: 0.0083 - val_loss: 23.6430 - val_recon_loss: 0.0011 - val_KL loss: 7.2009 - val_beta: 0.0083\n",
      "Epoch 1326/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23.2333 - recon_loss: 0.0011 - KL loss: 7.1520 - beta: 0.0083 - val_loss: 23.3870 - val_recon_loss: 0.0011 - val_KL loss: 7.1551 - val_beta: 0.0083\n",
      "Epoch 1327/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23.0880 - recon_loss: 0.0011 - KL loss: 7.1845 - beta: 0.0083 - val_loss: 22.7568 - val_recon_loss: 0.0011 - val_KL loss: 7.0031 - val_beta: 0.0083\n",
      "Epoch 1328/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 23.3232 - recon_loss: 0.0011 - KL loss: 7.1700 - beta: 0.0083 - val_loss: 23.1033 - val_recon_loss: 0.0011 - val_KL loss: 7.1487 - val_beta: 0.0083\n",
      "Epoch 1329/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23.3094 - recon_loss: 0.0011 - KL loss: 7.1847 - beta: 0.0083 - val_loss: 22.7141 - val_recon_loss: 0.0011 - val_KL loss: 7.0355 - val_beta: 0.0083\n",
      "Epoch 1330/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23.1212 - recon_loss: 0.0011 - KL loss: 7.1545 - beta: 0.0083 - val_loss: 23.1803 - val_recon_loss: 0.0011 - val_KL loss: 7.1686 - val_beta: 0.0083\n",
      "Epoch 1331/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23.2691 - recon_loss: 0.0011 - KL loss: 7.2091 - beta: 0.0083 - val_loss: 22.8792 - val_recon_loss: 0.0011 - val_KL loss: 7.1507 - val_beta: 0.0083\n",
      "Epoch 1332/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23.0047 - recon_loss: 0.0011 - KL loss: 7.1940 - beta: 0.0083 - val_loss: 22.5769 - val_recon_loss: 0.0011 - val_KL loss: 7.1572 - val_beta: 0.0083\n",
      "Epoch 1333/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 23.1565 - recon_loss: 0.0011 - KL loss: 7.2007 - beta: 0.0083 - val_loss: 22.4689 - val_recon_loss: 0.0010 - val_KL loss: 7.1051 - val_beta: 0.0083\n",
      "Epoch 1334/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23.1434 - recon_loss: 0.0011 - KL loss: 7.2120 - beta: 0.0083 - val_loss: 23.1161 - val_recon_loss: 0.0011 - val_KL loss: 6.9733 - val_beta: 0.0083\n",
      "Epoch 1335/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 23.6348 - recon_loss: 0.0011 - KL loss: 7.2421 - beta: 0.0083 - val_loss: 23.7918 - val_recon_loss: 0.0011 - val_KL loss: 7.4087 - val_beta: 0.0083\n",
      "Epoch 1336/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 25.1337 - recon_loss: 0.0012 - KL loss: 7.4750 - beta: 0.0083 - val_loss: 22.9690 - val_recon_loss: 0.0011 - val_KL loss: 7.3606 - val_beta: 0.0083\n",
      "Epoch 1337/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23.4164 - recon_loss: 0.0011 - KL loss: 7.2761 - beta: 0.0083 - val_loss: 22.8318 - val_recon_loss: 0.0011 - val_KL loss: 7.2687 - val_beta: 0.0083\n",
      "Epoch 1338/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23.4953 - recon_loss: 0.0011 - KL loss: 7.2787 - beta: 0.0083 - val_loss: 22.3393 - val_recon_loss: 0.0010 - val_KL loss: 7.2862 - val_beta: 0.0083\n",
      "Epoch 1339/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 23.5248 - recon_loss: 0.0011 - KL loss: 7.2831 - beta: 0.0083 - val_loss: 22.9120 - val_recon_loss: 0.0011 - val_KL loss: 7.2161 - val_beta: 0.0083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1340/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 23.2112 - recon_loss: 0.0011 - KL loss: 7.2192 - beta: 0.0083 - val_loss: 22.6805 - val_recon_loss: 0.0011 - val_KL loss: 7.1991 - val_beta: 0.0083\n",
      "Epoch 1341/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 22.9487 - recon_loss: 0.0011 - KL loss: 7.2229 - beta: 0.0083 - val_loss: 22.8016 - val_recon_loss: 0.0011 - val_KL loss: 7.2084 - val_beta: 0.0083\n",
      "Epoch 1342/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 23.0976 - recon_loss: 0.0011 - KL loss: 7.2381 - beta: 0.0083 - val_loss: 23.0673 - val_recon_loss: 0.0011 - val_KL loss: 7.3030 - val_beta: 0.0083\n",
      "Epoch 1343/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 23.1968 - recon_loss: 0.0011 - KL loss: 7.2355 - beta: 0.0083\n",
      "Epoch 01343: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 23.1968 - recon_loss: 0.0011 - KL loss: 7.2355 - beta: 0.0083 - val_loss: 22.5859 - val_recon_loss: 0.0010 - val_KL loss: 7.2638 - val_beta: 0.0083\n",
      "Epoch 1344/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 22.8409 - recon_loss: 0.0011 - KL loss: 7.2514 - beta: 0.0083 - val_loss: 22.5042 - val_recon_loss: 0.0010 - val_KL loss: 7.2168 - val_beta: 0.0083\n",
      "Epoch 1345/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 22.7976 - recon_loss: 0.0011 - KL loss: 7.2668 - beta: 0.0083 - val_loss: 22.6011 - val_recon_loss: 0.0011 - val_KL loss: 7.1760 - val_beta: 0.0083\n",
      "Epoch 1346/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.6365 - recon_loss: 0.0011 - KL loss: 7.2477 - beta: 0.0083 - val_loss: 22.6896 - val_recon_loss: 0.0011 - val_KL loss: 7.2080 - val_beta: 0.0083\n",
      "Epoch 1347/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.7931 - recon_loss: 0.0011 - KL loss: 7.2608 - beta: 0.0083 - val_loss: 22.0621 - val_recon_loss: 0.0010 - val_KL loss: 7.2150 - val_beta: 0.0083\n",
      "Epoch 1348/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.7362 - recon_loss: 0.0011 - KL loss: 7.2573 - beta: 0.0083 - val_loss: 22.0539 - val_recon_loss: 0.0010 - val_KL loss: 7.2148 - val_beta: 0.0083\n",
      "Epoch 1349/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.6206 - recon_loss: 0.0010 - KL loss: 7.2583 - beta: 0.0083 - val_loss: 22.4448 - val_recon_loss: 0.0010 - val_KL loss: 7.2346 - val_beta: 0.0083\n",
      "Epoch 1350/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.7053 - recon_loss: 0.0011 - KL loss: 7.2607 - beta: 0.0083 - val_loss: 22.6281 - val_recon_loss: 0.0011 - val_KL loss: 7.2113 - val_beta: 0.0083\n",
      "Epoch 1351/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 22.4545 - recon_loss: 0.0010 - KL loss: 7.2695 - beta: 0.0083 - val_loss: 22.6217 - val_recon_loss: 0.0011 - val_KL loss: 7.2001 - val_beta: 0.0083\n",
      "Epoch 1352/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 22.6942 - recon_loss: 0.0011 - KL loss: 7.2653 - beta: 0.0083 - val_loss: 22.4710 - val_recon_loss: 0.0010 - val_KL loss: 7.2586 - val_beta: 0.0083\n",
      "Epoch 1353/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 22.8729 - recon_loss: 0.0011 - KL loss: 7.2921 - beta: 0.0083\n",
      "Epoch 01353: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.8727 - recon_loss: 0.0011 - KL loss: 7.2921 - beta: 0.0083 - val_loss: 22.3999 - val_recon_loss: 0.0010 - val_KL loss: 7.2043 - val_beta: 0.0083\n",
      "Epoch 1354/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.7053 - recon_loss: 0.0011 - KL loss: 7.2883 - beta: 0.0083 - val_loss: 22.6452 - val_recon_loss: 0.0011 - val_KL loss: 7.2291 - val_beta: 0.0083\n",
      "Epoch 1355/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.5527 - recon_loss: 0.0010 - KL loss: 7.2946 - beta: 0.0083 - val_loss: 22.5777 - val_recon_loss: 0.0010 - val_KL loss: 7.2508 - val_beta: 0.0083\n",
      "Epoch 1356/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 22.5990 - recon_loss: 0.0010 - KL loss: 7.2873 - beta: 0.0083 - val_loss: 22.6134 - val_recon_loss: 0.0010 - val_KL loss: 7.2563 - val_beta: 0.0083\n",
      "Epoch 1357/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 22.5903 - recon_loss: 0.0010 - KL loss: 7.3021 - beta: 0.0083 - val_loss: 22.8367 - val_recon_loss: 0.0011 - val_KL loss: 7.2435 - val_beta: 0.0083\n",
      "Epoch 1358/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 22.7357 - recon_loss: 0.0011 - KL loss: 7.3188 - beta: 0.0083 ETA: 0s - loss: 22.7359 - recon_loss: 0.0011 - KL loss: 7.3189 - beta: 0.00\n",
      "Epoch 01358: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 22.7355 - recon_loss: 0.0011 - KL loss: 7.3188 - beta: 0.0083 - val_loss: 24.5490 - val_recon_loss: 0.0012 - val_KL loss: 7.2030 - val_beta: 0.0083\n",
      "Epoch 1358/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.7667 - recon_loss: 0.0010 - KL loss: 8.1819 - beta: 0.0060 - val_loss: 36.4318 - val_recon_loss: 0.0010 - val_KL loss: 8.2322 - val_beta: 0.0060\n",
      "Epoch 1359/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.5156 - recon_loss: 0.0010 - KL loss: 8.3253 - beta: 0.0060 - val_loss: 36.6678 - val_recon_loss: 0.0010 - val_KL loss: 8.3139 - val_beta: 0.0060\n",
      "Epoch 1360/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.4412 - recon_loss: 0.0010 - KL loss: 8.3479 - beta: 0.0060 - val_loss: 35.6413 - val_recon_loss: 9.9244e-04 - val_KL loss: 8.3520 - val_beta: 0.0060\n",
      "Epoch 1361/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.5746 - recon_loss: 0.0010 - KL loss: 8.3511 - beta: 0.0060 - val_loss: 38.9400 - val_recon_loss: 0.0011 - val_KL loss: 8.3096 - val_beta: 0.0060\n",
      "Epoch 1362/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.9831 - recon_loss: 0.0010 - KL loss: 8.4562 - beta: 0.0060 - val_loss: 38.0453 - val_recon_loss: 0.0011 - val_KL loss: 8.7277 - val_beta: 0.0060\n",
      "Epoch 1363/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 38.8875 - recon_loss: 0.0011 - KL loss: 8.6280 - beta: 0.0060 - val_loss: 35.5965 - val_recon_loss: 9.9195e-04 - val_KL loss: 8.3209 - val_beta: 0.0060\n",
      "Epoch 1364/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.7673 - recon_loss: 0.0010 - KL loss: 8.3422 - beta: 0.0060 - val_loss: 35.2174 - val_recon_loss: 9.7570e-04 - val_KL loss: 8.3885 - val_beta: 0.0060\n",
      "Epoch 1365/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.7080 - recon_loss: 0.0010 - KL loss: 8.4551 - beta: 0.0060 - val_loss: 35.9614 - val_recon_loss: 0.0010 - val_KL loss: 8.2949 - val_beta: 0.0060\n",
      "Epoch 1366/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.4922 - recon_loss: 0.0010 - KL loss: 8.4350 - beta: 0.0060 - val_loss: 36.0245 - val_recon_loss: 0.0010 - val_KL loss: 8.4211 - val_beta: 0.0060\n",
      "Epoch 1367/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 37.2176 - recon_loss: 0.0010 - KL loss: 8.4694 - beta: 0.0060 - val_loss: 35.6788 - val_recon_loss: 9.9642e-04 - val_KL loss: 8.2803 - val_beta: 0.0060\n",
      "Epoch 1368/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.5592 - recon_loss: 0.0010 - KL loss: 8.4504 - beta: 0.0060 - val_loss: 35.6123 - val_recon_loss: 9.9235e-04 - val_KL loss: 8.3256 - val_beta: 0.0060\n",
      "Epoch 1369/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 36.3769 - recon_loss: 0.0010 - KL loss: 8.4046 - beta: 0.0060\n",
      "Epoch 01369: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.3773 - recon_loss: 0.0010 - KL loss: 8.4048 - beta: 0.0060 - val_loss: 37.2342 - val_recon_loss: 0.0010 - val_KL loss: 8.7433 - val_beta: 0.0060\n",
      "Epoch 1370/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 37.7270 - recon_loss: 0.0011 - KL loss: 8.7975 - beta: 0.0060 - val_loss: 36.8809 - val_recon_loss: 0.0010 - val_KL loss: 8.8637 - val_beta: 0.0060\n",
      "Epoch 1371/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.7041 - recon_loss: 0.0010 - KL loss: 8.7329 - beta: 0.0060 - val_loss: 35.8483 - val_recon_loss: 9.9241e-04 - val_KL loss: 8.5600 - val_beta: 0.0060\n",
      "Epoch 1372/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.7057 - recon_loss: 0.0010 - KL loss: 8.7457 - beta: 0.0060 - val_loss: 37.6066 - val_recon_loss: 0.0011 - val_KL loss: 8.7280 - val_beta: 0.0060\n",
      "Epoch 1373/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.6580 - recon_loss: 0.0010 - KL loss: 8.7411 - beta: 0.0060 - val_loss: 37.0547 - val_recon_loss: 0.0010 - val_KL loss: 8.7302 - val_beta: 0.0060\n",
      "Epoch 1374/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 36.6132 - recon_loss: 0.0010 - KL loss: 8.7493 - beta: 0.0060\n",
      "Epoch 01374: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.6130 - recon_loss: 0.0010 - KL loss: 8.7493 - beta: 0.0060 - val_loss: 35.2995 - val_recon_loss: 9.6770e-04 - val_KL loss: 8.6906 - val_beta: 0.0060\n",
      "Epoch 1374/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 62.5283 - recon_loss: 0.0010 - KL loss: 9.5698 - beta: 0.0044 - val_loss: 59.9035 - val_recon_loss: 9.7537e-04 - val_KL loss: 9.5121 - val_beta: 0.0044\n",
      "Epoch 1375/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 62.3381 - recon_loss: 0.0010 - KL loss: 9.6961 - beta: 0.0044 - val_loss: 57.7959 - val_recon_loss: 9.3237e-04 - val_KL loss: 9.6260 - val_beta: 0.0044\n",
      "Epoch 1376/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 61.9196 - recon_loss: 0.0010 - KL loss: 9.6976 - beta: 0.0044 - val_loss: 59.7185 - val_recon_loss: 9.6684e-04 - val_KL loss: 9.7680 - val_beta: 0.0044\n",
      "Epoch 1377/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 62.1214 - recon_loss: 0.0010 - KL loss: 9.9283 - beta: 0.0044 - val_loss: 59.5802 - val_recon_loss: 9.6046e-04 - val_KL loss: 9.9591 - val_beta: 0.0044\n",
      "Epoch 1378/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 61.8140 - recon_loss: 0.0010 - KL loss: 9.9018 - beta: 0.0044 - val_loss: 58.0722 - val_recon_loss: 9.3526e-04 - val_KL loss: 9.7529 - val_beta: 0.0044\n",
      "Epoch 1379/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 61.9329 - recon_loss: 0.0010 - KL loss: 9.8413 - beta: 0.0044 - val_loss: 62.2125 - val_recon_loss: 0.0010 - val_KL loss: 10.2092 - val_beta: 0.0044\n",
      "Epoch 1380/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 62.7456 - recon_loss: 0.0010 - KL loss: 10.0137 - beta: 0.0044\n",
      "Epoch 01380: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 62.7459 - recon_loss: 0.0010 - KL loss: 10.0137 - beta: 0.0044 - val_loss: 60.1961 - val_recon_loss: 9.6933e-04 - val_KL loss: 10.1165 - val_beta: 0.0044\n",
      "Epoch 1381/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 61.7191 - recon_loss: 0.0010 - KL loss: 10.0153 - beta: 0.0044 - val_loss: 58.6822 - val_recon_loss: 9.3920e-04 - val_KL loss: 10.1592 - val_beta: 0.0044\n",
      "Epoch 1382/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 60.3247 - recon_loss: 9.7218e-04 - KL loss: 10.0981 - beta: 0.0044 - val_loss: 58.7006 - val_recon_loss: 9.3512e-04 - val_KL loss: 10.3887 - val_beta: 0.0044\n",
      "Epoch 1383/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 60.6426 - recon_loss: 9.7783e-04 - KL loss: 10.1241 - beta: 0.0044 - val_loss: 58.3028 - val_recon_loss: 9.2847e-04 - val_KL loss: 10.3345 - val_beta: 0.0044\n",
      "Epoch 1384/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 60.8958 - recon_loss: 9.8204e-04 - KL loss: 10.1596 - beta: 0.0044 - val_loss: 61.1434 - val_recon_loss: 9.8425e-04 - val_KL loss: 10.2933 - val_beta: 0.0044\n",
      "Epoch 1385/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 60.5605 - recon_loss: 9.7663e-04 - KL loss: 10.1037 - beta: 0.0044\n",
      "Epoch 01385: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 60.5604 - recon_loss: 9.7663e-04 - KL loss: 10.1037 - beta: 0.0044 - val_loss: 57.9029 - val_recon_loss: 9.1886e-04 - val_KL loss: 10.4309 - val_beta: 0.0044\n",
      "Epoch 1385/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 109.1318 - recon_loss: 0.0010 - KL loss: 10.8596 - beta: 0.0032 - val_loss: 104.4315 - val_recon_loss: 9.6280e-04 - val_KL loss: 10.9720 - val_beta: 0.0032\n",
      "Epoch 1386/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 110.2877 - recon_loss: 0.0010 - KL loss: 10.9734 - beta: 0.0032 - val_loss: 100.9881 - val_recon_loss: 9.2846e-04 - val_KL loss: 10.8616 - val_beta: 0.0032\n",
      "Epoch 1387/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 109.1799 - recon_loss: 0.0010 - KL loss: 10.9583 - beta: 0.0032 - val_loss: 100.3991 - val_recon_loss: 9.2163e-04 - val_KL loss: 10.9360 - val_beta: 0.0032\n",
      "Epoch 1388/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 108.4533 - recon_loss: 0.0010 - KL loss: 10.9750 - beta: 0.0032 - val_loss: 104.3027 - val_recon_loss: 9.6088e-04 - val_KL loss: 11.0298 - val_beta: 0.0032\n",
      "Epoch 1389/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 107.7206 - recon_loss: 9.9539e-04 - KL loss: 11.0969 - beta: 0.0032 - val_loss: 108.4425 - val_recon_loss: 0.0010 - val_KL loss: 11.0383 - val_beta: 0.0032\n",
      "Epoch 1390/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 107.3247 - recon_loss: 9.9363e-04 - KL loss: 10.8721 - beta: 0.0032 - val_loss: 103.8799 - val_recon_loss: 9.5834e-04 - val_KL loss: 10.8534 - val_beta: 0.0032\n",
      "Epoch 1391/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 106.6712 - recon_loss: 9.8622e-04 - KL loss: 10.9382 - beta: 0.0032 - val_loss: 106.8620 - val_recon_loss: 9.8903e-04 - val_KL loss: 10.8558 - val_beta: 0.0032\n",
      "Epoch 1392/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 105.3915 - recon_loss: 9.7309e-04 - KL loss: 10.9327 - beta: 0.0032\n",
      "Epoch 01392: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 105.3914 - recon_loss: 9.7309e-04 - KL loss: 10.9327 - beta: 0.0032 - val_loss: 102.9391 - val_recon_loss: 9.4865e-04 - val_KL loss: 10.8526 - val_beta: 0.0032\n",
      "Epoch 1393/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 105.2277 - recon_loss: 9.7017e-04 - KL loss: 11.0522 - beta: 0.0032 - val_loss: 102.4801 - val_recon_loss: 9.4197e-04 - val_KL loss: 11.0421 - val_beta: 0.0032\n",
      "Epoch 1394/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 103.3059 - recon_loss: 9.4972e-04 - KL loss: 11.1159 - beta: 0.0032 - val_loss: 105.0370 - val_recon_loss: 9.6836e-04 - val_KL loss: 11.0377 - val_beta: 0.0032\n",
      "Epoch 1395/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 102.8938 - recon_loss: 9.4630e-04 - KL loss: 11.0355 - beta: 0.0032 - val_loss: 108.2126 - val_recon_loss: 0.0010 - val_KL loss: 10.9642 - val_beta: 0.0032\n",
      "Epoch 1396/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 103.4969 - recon_loss: 9.5157e-04 - KL loss: 11.1273 - beta: 0.0032 - val_loss: 105.5895 - val_recon_loss: 9.7334e-04 - val_KL loss: 11.1063 - val_beta: 0.0032\n",
      "Epoch 1397/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 104.0547 - recon_loss: 9.5664e-04 - KL loss: 11.1930 - beta: 0.0032\n",
      "Epoch 01397: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 104.0540 - recon_loss: 9.5663e-04 - KL loss: 11.1930 - beta: 0.0032 - val_loss: 104.3521 - val_recon_loss: 9.5926e-04 - val_KL loss: 11.2359 - val_beta: 0.0032\n",
      "Epoch 1397/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 186.0062 - recon_loss: 9.5267e-04 - KL loss: 12.2535 - beta: 0.0023 - val_loss: 184.0242 - val_recon_loss: 9.3688e-04 - val_KL loss: 13.1506 - val_beta: 0.0023\n",
      "Epoch 1398/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 185.1555 - recon_loss: 9.4202e-04 - KL loss: 13.3444 - beta: 0.0023 - val_loss: 171.6133 - val_recon_loss: 8.6561e-04 - val_KL loss: 13.7397 - val_beta: 0.0023\n",
      "Epoch 1399/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 180.7033 - recon_loss: 9.1564e-04 - KL loss: 13.7041 - beta: 0.0023 - val_loss: 167.4557 - val_recon_loss: 8.4077e-04 - val_KL loss: 14.1109 - val_beta: 0.0023\n",
      "Epoch 1400/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 182.8327 - recon_loss: 9.2415e-04 - KL loss: 14.2814 - beta: 0.0023 - val_loss: 197.1953 - val_recon_loss: 9.9710e-04 - val_KL loss: 15.3396 - val_beta: 0.0023\n",
      "Epoch 1401/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 190.2203 - recon_loss: 9.5983e-04 - KL loss: 15.1621 - beta: 0.0023 - val_loss: 163.9685 - val_recon_loss: 8.1816e-04 - val_KL loss: 14.7489 - val_beta: 0.0023\n",
      "Epoch 1402/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 179.8843 - recon_loss: 9.0366e-04 - KL loss: 15.0695 - beta: 0.0023 - val_loss: 182.2126 - val_recon_loss: 9.1338e-04 - val_KL loss: 15.6265 - val_beta: 0.0023\n",
      "Epoch 1403/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 180.4455 - recon_loss: 9.0359e-04 - KL loss: 15.6447 - beta: 0.0023 - val_loss: 167.0094 - val_recon_loss: 8.3184e-04 - val_KL loss: 15.2947 - val_beta: 0.0023\n",
      "Epoch 1404/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 173.1158 - recon_loss: 8.6535e-04 - KL loss: 15.2893 - beta: 0.0023 - val_loss: 161.2847 - val_recon_loss: 8.0033e-04 - val_KL loss: 15.3172 - val_beta: 0.0023\n",
      "Epoch 1405/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 168.5849 - recon_loss: 8.4183e-04 - KL loss: 15.0468 - beta: 0.0023 - val_loss: 162.3811 - val_recon_loss: 8.0701e-04 - val_KL loss: 15.1944 - val_beta: 0.0023\n",
      "Epoch 1406/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 170.0112 - recon_loss: 8.4788e-04 - KL loss: 15.3695 - beta: 0.0023 - val_loss: 170.8564 - val_recon_loss: 8.5348e-04 - val_KL loss: 15.1940 - val_beta: 0.0023\n",
      "Epoch 1407/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 168.9954 - recon_loss: 8.4208e-04 - KL loss: 15.4123 - beta: 0.0023 - val_loss: 163.0659 - val_recon_loss: 8.0941e-04 - val_KL loss: 15.4415 - val_beta: 0.0023\n",
      "Epoch 1408/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 170.4908 - recon_loss: 8.4999e-04 - KL loss: 15.4648 - beta: 0.0023 - val_loss: 180.4444 - val_recon_loss: 9.0614e-04 - val_KL loss: 15.1773 - val_beta: 0.0023\n",
      "Epoch 1409/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 169.8398 - recon_loss: 8.4938e-04 - KL loss: 14.9253 - beta: 0.0023 - val_loss: 152.5210 - val_recon_loss: 7.5559e-04 - val_KL loss: 14.7118 - val_beta: 0.0023\n",
      "Epoch 1410/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 163.1563 - recon_loss: 8.1262e-04 - KL loss: 14.9464 - beta: 0.0023 - val_loss: 160.8517 - val_recon_loss: 8.0040e-04 - val_KL loss: 14.8707 - val_beta: 0.0023\n",
      "Epoch 1411/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 160.2246 - recon_loss: 7.9617e-04 - KL loss: 15.0143 - beta: 0.0023 - val_loss: 149.9058 - val_recon_loss: 7.3972e-04 - val_KL loss: 14.9928 - val_beta: 0.0023\n",
      "Epoch 1412/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 159.8681 - recon_loss: 7.9350e-04 - KL loss: 15.1453 - beta: 0.0023 - val_loss: 150.3772 - val_recon_loss: 7.4084e-04 - val_KL loss: 15.2588 - val_beta: 0.0023\n",
      "Epoch 1413/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 155.0579 - recon_loss: 7.6400e-04 - KL loss: 15.7152 - beta: 0.0023 - val_loss: 149.8706 - val_recon_loss: 7.3495e-04 - val_KL loss: 15.8265 - val_beta: 0.0023\n",
      "Epoch 1414/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 154.2919 - recon_loss: 7.5614e-04 - KL loss: 16.3826 - beta: 0.0023 - val_loss: 151.7681 - val_recon_loss: 7.4668e-04 - val_KL loss: 15.5841 - val_beta: 0.0023\n",
      "Epoch 1415/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 149.6375 - recon_loss: 7.3130e-04 - KL loss: 16.2592 - beta: 0.0023 - val_loss: 149.0514 - val_recon_loss: 7.3005e-04 - val_KL loss: 15.9016 - val_beta: 0.0023\n",
      "Epoch 1416/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 147.5725 - recon_loss: 7.1803e-04 - KL loss: 16.6154 - beta: 0.0023 - val_loss: 154.7712 - val_recon_loss: 7.5826e-04 - val_KL loss: 16.4763 - val_beta: 0.0023\n",
      "Epoch 1417/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 150.4775 - recon_loss: 7.3095e-04 - KL loss: 17.1629 - beta: 0.0023 - val_loss: 156.2243 - val_recon_loss: 7.6133e-04 - val_KL loss: 17.3695 - val_beta: 0.0023\n",
      "Epoch 1418/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 147.9643 - recon_loss: 7.1337e-04 - KL loss: 17.8556 - beta: 0.0023 - val_loss: 147.3544 - val_recon_loss: 7.1127e-04 - val_KL loss: 17.6297 - val_beta: 0.0023\n",
      "Epoch 1419/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 141.3580 - recon_loss: 6.7450e-04 - KL loss: 18.3399 - beta: 0.0023 - val_loss: 144.8427 - val_recon_loss: 6.9541e-04 - val_KL loss: 18.0110 - val_beta: 0.0023\n",
      "Epoch 1420/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 144.0689 - recon_loss: 6.8671e-04 - KL loss: 18.8233 - beta: 0.0023 - val_loss: 136.0589 - val_recon_loss: 6.4592e-04 - val_KL loss: 18.2521 - val_beta: 0.0023\n",
      "Epoch 1421/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 133.1345 - recon_loss: 6.2378e-04 - KL loss: 19.3661 - beta: 0.0023 - val_loss: 128.3517 - val_recon_loss: 5.9939e-04 - val_KL loss: 19.0310 - val_beta: 0.0023\n",
      "Epoch 1422/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 128.4642 - recon_loss: 5.9623e-04 - KL loss: 19.7206 - beta: 0.0023 - val_loss: 138.4441 - val_recon_loss: 6.5686e-04 - val_KL loss: 18.6428 - val_beta: 0.0023\n",
      "Epoch 1423/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 132.1978 - recon_loss: 6.1698e-04 - KL loss: 19.6705 - beta: 0.0023 - val_loss: 130.7181 - val_recon_loss: 6.1097e-04 - val_KL loss: 19.2856 - val_beta: 0.0023\n",
      "Epoch 1424/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 127.0650 - recon_loss: 5.8718e-04 - KL loss: 19.9714 - beta: 0.0023 - val_loss: 133.8808 - val_recon_loss: 6.2746e-04 - val_KL loss: 19.4410 - val_beta: 0.0023\n",
      "Epoch 1425/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 126.0648 - recon_loss: 5.8188e-04 - KL loss: 19.9390 - beta: 0.0023 - val_loss: 123.2855 - val_recon_loss: 5.6898e-04 - val_KL loss: 19.5111 - val_beta: 0.0023\n",
      "Epoch 1426/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 122.0103 - recon_loss: 5.5808e-04 - KL loss: 20.2241 - beta: 0.0023 - val_loss: 149.1797 - val_recon_loss: 7.0331e-04 - val_KL loss: 20.9069 - val_beta: 0.0023\n",
      "Epoch 1427/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 131.4739 - recon_loss: 6.0788e-04 - KL loss: 20.6059 - beta: 0.0023 - val_loss: 128.4701 - val_recon_loss: 5.9598e-04 - val_KL loss: 19.7722 - val_beta: 0.0023\n",
      "Epoch 1428/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 119.3132 - recon_loss: 5.4287e-04 - KL loss: 20.3014 - beta: 0.0023 - val_loss: 124.2120 - val_recon_loss: 5.7036e-04 - val_KL loss: 20.1867 - val_beta: 0.0023\n",
      "Epoch 1429/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 126.9505 - recon_loss: 5.8178e-04 - KL loss: 20.8433 - beta: 0.0023 - val_loss: 128.1028 - val_recon_loss: 5.9581e-04 - val_KL loss: 19.4365 - val_beta: 0.0023\n",
      "Epoch 1430/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 152.5525 - recon_loss: 7.2242e-04 - KL loss: 20.7940 - beta: 0.0023 - val_loss: 123.1893 - val_recon_loss: 5.6797e-04 - val_KL loss: 19.5998 - val_beta: 0.0023\n",
      "Epoch 1431/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 119.3152 - recon_loss: 5.4244e-04 - KL loss: 20.3830 - beta: 0.0023 - val_loss: 133.2393 - val_recon_loss: 6.2067e-04 - val_KL loss: 20.0386 - val_beta: 0.0023\n",
      "Epoch 1432/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 118.0542 - recon_loss: 5.3505e-04 - KL loss: 20.4695 - beta: 0.0023 - val_loss: 115.7788 - val_recon_loss: 5.2816e-04 - val_KL loss: 19.4505 - val_beta: 0.0023\n",
      "Epoch 1433/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 113.5560 - recon_loss: 5.1069e-04 - KL loss: 20.4132 - beta: 0.0023 - val_loss: 116.2320 - val_recon_loss: 5.3129e-04 - val_KL loss: 19.3324 - val_beta: 0.0023\n",
      "Epoch 1434/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 116.6516 - recon_loss: 5.2799e-04 - KL loss: 20.3548 - beta: 0.0023 - val_loss: 131.6120 - val_recon_loss: 6.0969e-04 - val_KL loss: 20.4143 - val_beta: 0.0023\n",
      "Epoch 1435/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 116.5096 - recon_loss: 5.2678e-04 - KL loss: 20.4322 - beta: 0.0023 - val_loss: 137.8127 - val_recon_loss: 6.4890e-04 - val_KL loss: 19.4622 - val_beta: 0.0023\n",
      "Epoch 1436/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 113.4264 - recon_loss: 5.1120e-04 - KL loss: 20.1916 - beta: 0.0023 - val_loss: 115.6027 - val_recon_loss: 5.2677e-04 - val_KL loss: 19.5270 - val_beta: 0.0023\n",
      "Epoch 1437/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 113.3105 - recon_loss: 5.1099e-04 - KL loss: 20.1144 - beta: 0.0023 - val_loss: 118.0649 - val_recon_loss: 5.4348e-04 - val_KL loss: 18.9429 - val_beta: 0.0023\n",
      "Epoch 1438/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 114.0938 - recon_loss: 5.1472e-04 - KL loss: 20.2172 - beta: 0.0023 - val_loss: 116.0234 - val_recon_loss: 5.2874e-04 - val_KL loss: 19.5886 - val_beta: 0.0023\n",
      "Epoch 1439/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 111.4456 - recon_loss: 4.9978e-04 - KL loss: 20.2928 - beta: 0.0023 - val_loss: 115.5278 - val_recon_loss: 5.2683e-04 - val_KL loss: 19.4414 - val_beta: 0.0023\n",
      "Epoch 1440/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 111.4593 - recon_loss: 4.9997e-04 - KL loss: 20.2720 - beta: 0.0023 - val_loss: 114.1607 - val_recon_loss: 5.2133e-04 - val_KL loss: 19.0782 - val_beta: 0.0023\n",
      "Epoch 1441/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 108.5804 - recon_loss: 4.8553e-04 - KL loss: 20.0275 - beta: 0.0023 - val_loss: 112.6791 - val_recon_loss: 5.0971e-04 - val_KL loss: 19.7150 - val_beta: 0.0023\n",
      "Epoch 1442/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 110.8539 - recon_loss: 4.9772e-04 - KL loss: 20.0775 - beta: 0.0023 - val_loss: 115.3951 - val_recon_loss: 5.2460e-04 - val_KL loss: 19.7162 - val_beta: 0.0023\n",
      "Epoch 1443/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 113.4392 - recon_loss: 5.1109e-04 - KL loss: 20.2236 - beta: 0.0023 - val_loss: 112.7681 - val_recon_loss: 5.1148e-04 - val_KL loss: 19.4822 - val_beta: 0.0023\n",
      "Epoch 1444/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 118.8165 - recon_loss: 5.3974e-04 - KL loss: 20.3768 - beta: 0.0023 - val_loss: 132.1420 - val_recon_loss: 6.1491e-04 - val_KL loss: 19.9912 - val_beta: 0.0023\n",
      "Epoch 1445/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 133.0582 - recon_loss: 6.1379e-04 - KL loss: 21.1129 - beta: 0.0023 - val_loss: 128.7779 - val_recon_loss: 5.9547e-04 - val_KL loss: 20.1734 - val_beta: 0.0023\n",
      "Epoch 1446/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 123.9914 - recon_loss: 5.6360e-04 - KL loss: 21.1989 - beta: 0.0023\n",
      "Epoch 01446: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 123.9883 - recon_loss: 5.6359e-04 - KL loss: 21.1986 - beta: 0.0023 - val_loss: 118.0602 - val_recon_loss: 5.3720e-04 - val_KL loss: 20.0826 - val_beta: 0.0023\n",
      "Epoch 1447/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 112.2493 - recon_loss: 5.0186e-04 - KL loss: 20.7167 - beta: 0.0023 - val_loss: 119.1542 - val_recon_loss: 5.4207e-04 - val_KL loss: 20.2882 - val_beta: 0.0023\n",
      "Epoch 1448/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 111.0765 - recon_loss: 4.9484e-04 - KL loss: 20.8249 - beta: 0.0023 - val_loss: 116.2073 - val_recon_loss: 5.2467e-04 - val_KL loss: 20.5161 - val_beta: 0.0023\n",
      "Epoch 1449/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 109.1081 - recon_loss: 4.8458e-04 - KL loss: 20.7275 - beta: 0.0023 - val_loss: 111.3919 - val_recon_loss: 5.0211e-04 - val_KL loss: 19.8145 - val_beta: 0.0023\n",
      "Epoch 1450/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 107.5426 - recon_loss: 4.7794e-04 - KL loss: 20.3734 - beta: 0.0023 - val_loss: 114.1751 - val_recon_loss: 5.1631e-04 - val_KL loss: 20.0076 - val_beta: 0.0023\n",
      "Epoch 1451/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 108.3390 - recon_loss: 4.8175e-04 - KL loss: 20.4746 - beta: 0.0023 - val_loss: 110.1597 - val_recon_loss: 4.9751e-04 - val_KL loss: 19.4209 - val_beta: 0.0023\n",
      "Epoch 1452/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 107.0733 - recon_loss: 4.7459e-04 - KL loss: 20.5159 - beta: 0.0023 - val_loss: 110.4603 - val_recon_loss: 4.9794e-04 - val_KL loss: 19.6431 - val_beta: 0.0023\n",
      "Epoch 1453/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 105.6414 - recon_loss: 4.6694e-04 - KL loss: 20.4781 - beta: 0.0023 - val_loss: 109.1657 - val_recon_loss: 4.8981e-04 - val_KL loss: 19.8310 - val_beta: 0.0023\n",
      "Epoch 1454/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 104.4427 - recon_loss: 4.6016e-04 - KL loss: 20.5159 - beta: 0.0023 - val_loss: 106.2216 - val_recon_loss: 4.7291e-04 - val_KL loss: 19.9701 - val_beta: 0.0023\n",
      "Epoch 1455/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 104.9188 - recon_loss: 4.6223e-04 - KL loss: 20.6150 - beta: 0.0023 - val_loss: 113.3112 - val_recon_loss: 5.1049e-04 - val_KL loss: 20.2060 - val_beta: 0.0023\n",
      "Epoch 1456/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 106.0629 - recon_loss: 4.6839e-04 - KL loss: 20.6357 - beta: 0.0023 - val_loss: 110.9439 - val_recon_loss: 4.9798e-04 - val_KL loss: 20.1201 - val_beta: 0.0023\n",
      "Epoch 1457/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 104.9342 - recon_loss: 4.6222e-04 - KL loss: 20.6313 - beta: 0.0023 - val_loss: 109.4982 - val_recon_loss: 4.8919e-04 - val_KL loss: 20.2765 - val_beta: 0.0023\n",
      "Epoch 1458/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 104.4002 - recon_loss: 4.5833e-04 - KL loss: 20.8068 - beta: 0.0023 - val_loss: 106.4897 - val_recon_loss: 4.7594e-04 - val_KL loss: 19.6844 - val_beta: 0.0023\n",
      "Epoch 1459/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 103.6681 - recon_loss: 4.5546e-04 - KL loss: 20.5999 - beta: 0.0023\n",
      "Epoch 01459: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 103.6702 - recon_loss: 4.5547e-04 - KL loss: 20.6001 - beta: 0.0023 - val_loss: 112.7228 - val_recon_loss: 5.0720e-04 - val_KL loss: 20.2169 - val_beta: 0.0023\n",
      "Epoch 1460/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 105.7419 - recon_loss: 4.6429e-04 - KL loss: 21.0626 - beta: 0.0023 - val_loss: 109.7811 - val_recon_loss: 4.9104e-04 - val_KL loss: 20.2227 - val_beta: 0.0023\n",
      "Epoch 1461/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 104.9298 - recon_loss: 4.6083e-04 - KL loss: 20.8805 - beta: 0.0023 - val_loss: 114.5774 - val_recon_loss: 5.1693e-04 - val_KL loss: 20.2978 - val_beta: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1462/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 103.8604 - recon_loss: 4.5474e-04 - KL loss: 20.9234 - beta: 0.0023 - val_loss: 109.8509 - val_recon_loss: 4.9283e-04 - val_KL loss: 19.9666 - val_beta: 0.0023\n",
      "Epoch 1463/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 102.4804 - recon_loss: 4.4857e-04 - KL loss: 20.6676 - beta: 0.0023 - val_loss: 107.0551 - val_recon_loss: 4.7697e-04 - val_KL loss: 20.0637 - val_beta: 0.0023\n",
      "Epoch 1464/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 102.7753 - recon_loss: 4.4983e-04 - KL loss: 20.7333 - beta: 0.0023 - val_loss: 105.9816 - val_recon_loss: 4.7078e-04 - val_KL loss: 20.1178 - val_beta: 0.0023\n",
      "Epoch 1465/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 103.1008 - recon_loss: 4.5112e-04 - KL loss: 20.8235 - beta: 0.0023 - val_loss: 108.3186 - val_recon_loss: 4.8404e-04 - val_KL loss: 20.0371 - val_beta: 0.0023\n",
      "Epoch 1466/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 102.2213 - recon_loss: 4.4648e-04 - KL loss: 20.7909 - beta: 0.0023 - val_loss: 109.1023 - val_recon_loss: 4.8782e-04 - val_KL loss: 20.1316 - val_beta: 0.0023\n",
      "Epoch 1467/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 102.1643 - recon_loss: 4.4614e-04 - KL loss: 20.7943 - beta: 0.0023 - val_loss: 107.5872 - val_recon_loss: 4.7967e-04 - val_KL loss: 20.1030 - val_beta: 0.0023\n",
      "Epoch 1468/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 102.8246 - recon_loss: 4.4971e-04 - KL loss: 20.8035 - beta: 0.0023 - val_loss: 104.6050 - val_recon_loss: 4.6373e-04 - val_KL loss: 20.0269 - val_beta: 0.0023\n",
      "Epoch 1469/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 101.3756 - recon_loss: 4.4224e-04 - KL loss: 20.7173 - beta: 0.0023 - val_loss: 110.5136 - val_recon_loss: 4.9628e-04 - val_KL loss: 19.9988 - val_beta: 0.0023\n",
      "Epoch 1470/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 102.8479 - recon_loss: 4.5002e-04 - KL loss: 20.7706 - beta: 0.0023 - val_loss: 109.4794 - val_recon_loss: 4.9057e-04 - val_KL loss: 20.0075 - val_beta: 0.0023\n",
      "Epoch 1471/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 101.3338 - recon_loss: 4.4160e-04 - KL loss: 20.7926 - beta: 0.0023 - val_loss: 104.3403 - val_recon_loss: 4.6196e-04 - val_KL loss: 20.0856 - val_beta: 0.0023\n",
      "Epoch 1472/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 101.2103 - recon_loss: 4.4047e-04 - KL loss: 20.8754 - beta: 0.0023 - val_loss: 103.0812 - val_recon_loss: 4.5582e-04 - val_KL loss: 19.9465 - val_beta: 0.0023\n",
      "Epoch 1473/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 101.3457 - recon_loss: 4.4158e-04 - KL loss: 20.8082 - beta: 0.0023 - val_loss: 106.4539 - val_recon_loss: 4.7388e-04 - val_KL loss: 20.0261 - val_beta: 0.0023\n",
      "Epoch 1474/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 102.4788 - recon_loss: 4.4782e-04 - KL loss: 20.8028 - beta: 0.0023 - val_loss: 107.1396 - val_recon_loss: 4.7675e-04 - val_KL loss: 20.1876 - val_beta: 0.0023\n",
      "Epoch 1475/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 102.0395 - recon_loss: 4.4411e-04 - KL loss: 21.0413 - beta: 0.0023 - val_loss: 106.0965 - val_recon_loss: 4.7012e-04 - val_KL loss: 20.3539 - val_beta: 0.0023\n",
      "Epoch 1476/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 100.8932 - recon_loss: 4.3830e-04 - KL loss: 20.9540 - beta: 0.0023 - val_loss: 108.6244 - val_recon_loss: 4.8534e-04 - val_KL loss: 20.1059 - val_beta: 0.0023\n",
      "Epoch 1477/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 101.4863 - recon_loss: 4.4219e-04 - KL loss: 20.8376 - beta: 0.0023\n",
      "Epoch 01477: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 101.4861 - recon_loss: 4.4219e-04 - KL loss: 20.8374 - beta: 0.0023 - val_loss: 109.0397 - val_recon_loss: 4.8864e-04 - val_KL loss: 19.9197 - val_beta: 0.0023\n",
      "Epoch 1478/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 100.7120 - recon_loss: 4.3863e-04 - KL loss: 20.7126 - beta: 0.0023 - val_loss: 105.7916 - val_recon_loss: 4.7001e-04 - val_KL loss: 20.0687 - val_beta: 0.0023\n",
      "Epoch 1479/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 100.6601 - recon_loss: 4.3769e-04 - KL loss: 20.8316 - beta: 0.0023 - val_loss: 107.5197 - val_recon_loss: 4.7938e-04 - val_KL loss: 20.0883 - val_beta: 0.0023\n",
      "Epoch 1480/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 99.9284 - recon_loss: 4.3421e-04 - KL loss: 20.7356 - beta: 0.0023 - val_loss: 107.6945 - val_recon_loss: 4.8028e-04 - val_KL loss: 20.0982 - val_beta: 0.0023\n",
      "Epoch 1481/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 100.1289 - recon_loss: 4.3500e-04 - KL loss: 20.7917 - beta: 0.0023 - val_loss: 107.9974 - val_recon_loss: 4.8170e-04 - val_KL loss: 20.1430 - val_beta: 0.0023\n",
      "Epoch 1482/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 99.8561 - recon_loss: 4.3371e-04 - KL loss: 20.7539 - beta: 0.0023\n",
      "Epoch 01482: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 99.8563 - recon_loss: 4.3371e-04 - KL loss: 20.7539 - beta: 0.0023 - val_loss: 107.7152 - val_recon_loss: 4.8042e-04 - val_KL loss: 20.0945 - val_beta: 0.0023\n",
      "Epoch 1482/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 196.4488 - recon_loss: 5.0599e-04 - KL loss: 23.0553 - beta: 0.0017 - val_loss: 237.7096 - val_recon_loss: 6.2125e-04 - val_KL loss: 24.8189 - val_beta: 0.0017\n",
      "Epoch 1483/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 200.7613 - recon_loss: 5.1539e-04 - KL loss: 24.1456 - beta: 0.0017 - val_loss: 228.7667 - val_recon_loss: 5.9669e-04 - val_KL loss: 24.2908 - val_beta: 0.0017\n",
      "Epoch 1484/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 191.8503 - recon_loss: 4.9035e-04 - KL loss: 23.8159 - beta: 0.0017 - val_loss: 194.4936 - val_recon_loss: 4.9590e-04 - val_KL loss: 24.5574 - val_beta: 0.0017\n",
      "Epoch 1485/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 190.4120 - recon_loss: 4.8443e-04 - KL loss: 24.4058 - beta: 0.0017 - val_loss: 184.0775 - val_recon_loss: 4.6804e-04 - val_KL loss: 23.6897 - val_beta: 0.0017\n",
      "Epoch 1486/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 178.0441 - recon_loss: 4.4934e-04 - KL loss: 24.0641 - beta: 0.0017 - val_loss: 195.0079 - val_recon_loss: 4.9979e-04 - val_KL loss: 23.7396 - val_beta: 0.0017\n",
      "Epoch 1487/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 178.0517 - recon_loss: 4.4929e-04 - KL loss: 24.0869 - beta: 0.0017 - val_loss: 208.2464 - val_recon_loss: 5.3963e-04 - val_KL loss: 23.3246 - val_beta: 0.0017\n",
      "Epoch 1488/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 179.3009 - recon_loss: 4.5296e-04 - KL loss: 24.0784 - beta: 0.0017 - val_loss: 186.6312 - val_recon_loss: 4.7517e-04 - val_KL loss: 23.7978 - val_beta: 0.0017\n",
      "Epoch 1489/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 184.7443 - recon_loss: 4.6896e-04 - KL loss: 24.0411 - beta: 0.0017 - val_loss: 186.9885 - val_recon_loss: 4.7722e-04 - val_KL loss: 23.4546 - val_beta: 0.0017\n",
      "Epoch 1490/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 174.0929 - recon_loss: 4.3927e-04 - KL loss: 23.5617 - beta: 0.0017 - val_loss: 178.8423 - val_recon_loss: 4.5207e-04 - val_KL loss: 23.9276 - val_beta: 0.0017\n",
      "Epoch 1491/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 173.5145 - recon_loss: 4.3781e-04 - KL loss: 23.4841 - beta: 0.0017 - val_loss: 186.8184 - val_recon_loss: 4.7679e-04 - val_KL loss: 23.4318 - val_beta: 0.0017\n",
      "Epoch 1492/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 169.0011 - recon_loss: 4.2517e-04 - KL loss: 23.3023 - beta: 0.0017 - val_loss: 184.1002 - val_recon_loss: 4.6917e-04 - val_KL loss: 23.3250 - val_beta: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1493/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 174.3480 - recon_loss: 4.4075e-04 - KL loss: 23.3102 - beta: 0.0017 - val_loss: 195.8368 - val_recon_loss: 5.0455e-04 - val_KL loss: 22.9376 - val_beta: 0.0017\n",
      "Epoch 1494/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 172.7366 - recon_loss: 4.3763e-04 - KL loss: 22.7683 - beta: 0.0017 - val_loss: 185.1922 - val_recon_loss: 4.7530e-04 - val_KL loss: 22.3154 - val_beta: 0.0017\n",
      "Epoch 1495/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 175.5455 - recon_loss: 4.4581e-04 - KL loss: 22.7751 - beta: 0.0017\n",
      "Epoch 01495: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 175.5498 - recon_loss: 4.4582e-04 - KL loss: 22.7753 - beta: 0.0017 - val_loss: 183.5324 - val_recon_loss: 4.7003e-04 - val_KL loss: 22.4604 - val_beta: 0.0017\n",
      "Epoch 1496/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 171.0885 - recon_loss: 4.3217e-04 - KL loss: 22.9904 - beta: 0.0017 - val_loss: 182.0421 - val_recon_loss: 4.6534e-04 - val_KL loss: 22.5793 - val_beta: 0.0017\n",
      "Epoch 1497/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 165.7756 - recon_loss: 4.1677e-04 - KL loss: 22.9560 - beta: 0.0017 - val_loss: 173.3392 - val_recon_loss: 4.3933e-04 - val_KL loss: 22.7900 - val_beta: 0.0017\n",
      "Epoch 1498/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 162.0840 - recon_loss: 4.0598e-04 - KL loss: 22.9617 - beta: 0.0017 - val_loss: 176.8898 - val_recon_loss: 4.4678e-04 - val_KL loss: 23.7869 - val_beta: 0.0017\n",
      "Epoch 1499/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 166.4684 - recon_loss: 4.1786e-04 - KL loss: 23.2759 - beta: 0.0017 - val_loss: 170.9162 - val_recon_loss: 4.3167e-04 - val_KL loss: 22.9910 - val_beta: 0.0017\n",
      "Epoch 1500/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 159.4575 - recon_loss: 3.9816e-04 - KL loss: 23.0149 - beta: 0.0017 - val_loss: 170.6936 - val_recon_loss: 4.3261e-04 - val_KL loss: 22.4448 - val_beta: 0.0017\n",
      "Epoch 1501/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 160.2131 - recon_loss: 4.0096e-04 - KL loss: 22.8101 - beta: 0.0017 - val_loss: 180.9347 - val_recon_loss: 4.6346e-04 - val_KL loss: 22.1151 - val_beta: 0.0017\n",
      "Epoch 1502/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 156.6290 - recon_loss: 3.9131e-04 - KL loss: 22.5341 - beta: 0.0017 - val_loss: 171.0633 - val_recon_loss: 4.3421e-04 - val_KL loss: 22.2680 - val_beta: 0.0017\n",
      "Epoch 1503/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 158.4206 - recon_loss: 3.9646e-04 - KL loss: 22.5613 - beta: 0.0017 - val_loss: 169.5750 - val_recon_loss: 4.3050e-04 - val_KL loss: 22.0500 - val_beta: 0.0017\n",
      "Epoch 1504/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 156.8340 - recon_loss: 3.9212e-04 - KL loss: 22.4608 - beta: 0.0017 - val_loss: 177.4564 - val_recon_loss: 4.5307e-04 - val_KL loss: 22.1979 - val_beta: 0.0017\n",
      "Epoch 1505/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 157.0444 - recon_loss: 3.9250e-04 - KL loss: 22.5413 - beta: 0.0017 - val_loss: 187.0415 - val_recon_loss: 4.8129e-04 - val_KL loss: 22.1109 - val_beta: 0.0017\n",
      "Epoch 1506/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 158.1408 - recon_loss: 3.9568e-04 - KL loss: 22.5472 - beta: 0.0017 - val_loss: 169.4226 - val_recon_loss: 4.2995e-04 - val_KL loss: 22.0877 - val_beta: 0.0017\n",
      "Epoch 1507/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 155.4373 - recon_loss: 3.8781e-04 - KL loss: 22.5415 - beta: 0.0017 - val_loss: 166.2698 - val_recon_loss: 4.2143e-04 - val_KL loss: 21.8544 - val_beta: 0.0017\n",
      "Epoch 1508/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 155.0944 - recon_loss: 3.8771e-04 - KL loss: 22.2319 - beta: 0.0017 - val_loss: 171.2923 - val_recon_loss: 4.3579e-04 - val_KL loss: 21.9539 - val_beta: 0.0017\n",
      "Epoch 1509/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 155.4072 - recon_loss: 3.8844e-04 - KL loss: 22.2945 - beta: 0.0017 - val_loss: 161.2945 - val_recon_loss: 4.0622e-04 - val_KL loss: 22.0893 - val_beta: 0.0017\n",
      "Epoch 1510/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 154.6610 - recon_loss: 3.8577e-04 - KL loss: 22.4650 - beta: 0.0017 - val_loss: 179.1366 - val_recon_loss: 4.5824e-04 - val_KL loss: 22.1065 - val_beta: 0.0017\n",
      "Epoch 1511/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 159.8007 - recon_loss: 4.0091e-04 - KL loss: 22.4166 - beta: 0.0017 - val_loss: 175.1540 - val_recon_loss: 4.4687e-04 - val_KL loss: 22.0187 - val_beta: 0.0017\n",
      "Epoch 1512/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 156.5961 - recon_loss: 3.9187e-04 - KL loss: 22.3088 - beta: 0.0017 - val_loss: 171.9813 - val_recon_loss: 4.3760e-04 - val_KL loss: 22.0239 - val_beta: 0.0017\n",
      "Epoch 1513/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 153.2029 - recon_loss: 3.8223e-04 - KL loss: 22.2186 - beta: 0.0017 - val_loss: 179.2076 - val_recon_loss: 4.5894e-04 - val_KL loss: 21.9375 - val_beta: 0.0017\n",
      "Epoch 1514/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 152.2923 - recon_loss: 3.7994e-04 - KL loss: 22.0932 - beta: 0.0017\n",
      "Epoch 01514: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 152.2931 - recon_loss: 3.7994e-04 - KL loss: 22.0933 - beta: 0.0017 - val_loss: 164.3223 - val_recon_loss: 4.1550e-04 - val_KL loss: 21.9382 - val_beta: 0.0017\n",
      "Epoch 1515/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 152.3723 - recon_loss: 3.7988e-04 - KL loss: 22.1933 - beta: 0.0017 - val_loss: 164.6765 - val_recon_loss: 4.1605e-04 - val_KL loss: 22.1022 - val_beta: 0.0017\n",
      "Epoch 1516/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 152.4987 - recon_loss: 3.7985e-04 - KL loss: 22.3328 - beta: 0.0017 - val_loss: 165.9328 - val_recon_loss: 4.1990e-04 - val_KL loss: 22.0393 - val_beta: 0.0017\n",
      "Epoch 1517/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 150.0340 - recon_loss: 3.7283e-04 - KL loss: 22.2710 - beta: 0.0017 - val_loss: 165.1187 - val_recon_loss: 4.1739e-04 - val_KL loss: 22.0880 - val_beta: 0.0017\n",
      "Epoch 1518/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 152.4098 - recon_loss: 3.7964e-04 - KL loss: 22.3146 - beta: 0.0017 - val_loss: 163.8549 - val_recon_loss: 4.1396e-04 - val_KL loss: 21.9984 - val_beta: 0.0017\n",
      "Epoch 1519/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 150.9018 - recon_loss: 3.7523e-04 - KL loss: 22.3179 - beta: 0.0017\n",
      "Epoch 01519: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 150.9023 - recon_loss: 3.7523e-04 - KL loss: 22.3179 - beta: 0.0017 - val_loss: 162.3598 - val_recon_loss: 4.0946e-04 - val_KL loss: 22.0461 - val_beta: 0.0017\n",
      "Epoch 1519/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 297.2448 - recon_loss: 4.2492e-04 - KL loss: 23.6527 - beta: 0.0012 - val_loss: 329.1261 - val_recon_loss: 4.7428e-04 - val_KL loss: 23.7576 - val_beta: 0.0012\n",
      "Epoch 1520/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 289.5922 - recon_loss: 4.1185e-04 - KL loss: 24.4202 - beta: 0.0012 - val_loss: 302.3127 - val_recon_loss: 4.3109e-04 - val_KL loss: 24.7537 - val_beta: 0.0012\n",
      "Epoch 1521/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 285.3342 - recon_loss: 4.0474e-04 - KL loss: 24.7408 - beta: 0.0012 - val_loss: 331.2005 - val_recon_loss: 4.7715e-04 - val_KL loss: 23.9843 - val_beta: 0.0012\n",
      "Epoch 1522/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 288.8321 - recon_loss: 4.1035e-04 - KL loss: 24.6228 - beta: 0.0012 - val_loss: 353.7527 - val_recon_loss: 5.0986e-04 - val_KL loss: 25.4759 - val_beta: 0.0012\n",
      "Epoch 1523/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 313.2609 - recon_loss: 4.4712e-04 - KL loss: 25.3769 - beta: 0.0012 - val_loss: 306.0459 - val_recon_loss: 4.3628e-04 - val_KL loss: 25.1407 - val_beta: 0.0012\n",
      "Epoch 1524/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 292.0704 - recon_loss: 4.1455e-04 - KL loss: 25.1567 - beta: 0.0012 - val_loss: 295.3900 - val_recon_loss: 4.1963e-04 - val_KL loss: 25.2063 - val_beta: 0.0012\n",
      "Epoch 1525/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 278.3572 - recon_loss: 3.9353e-04 - KL loss: 24.9790 - beta: 0.0012 - val_loss: 289.9779 - val_recon_loss: 4.1187e-04 - val_KL loss: 24.7908 - val_beta: 0.0012\n",
      "Epoch 1526/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 285.7958 - recon_loss: 4.0536e-04 - KL loss: 24.8030 - beta: 0.0012 - val_loss: 319.8951 - val_recon_loss: 4.5858e-04 - val_KL loss: 24.6325 - val_beta: 0.0012\n",
      "Epoch 1527/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 282.0965 - recon_loss: 3.9958e-04 - KL loss: 24.8205 - beta: 0.0012 - val_loss: 307.7008 - val_recon_loss: 4.3995e-04 - val_KL loss: 24.4353 - val_beta: 0.0012\n",
      "Epoch 1528/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 281.4557 - recon_loss: 3.9902e-04 - KL loss: 24.5444 - beta: 0.0012 - val_loss: 302.9829 - val_recon_loss: 4.3300e-04 - val_KL loss: 24.1907 - val_beta: 0.0012\n",
      "Epoch 1529/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 283.8143 - recon_loss: 4.0261e-04 - KL loss: 24.5927 - beta: 0.0012 - val_loss: 334.6768 - val_recon_loss: 4.8144e-04 - val_KL loss: 24.6945 - val_beta: 0.0012\n",
      "Epoch 1530/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 289.9380 - recon_loss: 4.1115e-04 - KL loss: 25.2121 - beta: 0.0012\n",
      "Epoch 01530: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 289.9325 - recon_loss: 4.1115e-04 - KL loss: 25.2122 - beta: 0.0012 - val_loss: 316.6167 - val_recon_loss: 4.5178e-04 - val_KL loss: 25.7362 - val_beta: 0.0012\n",
      "Epoch 1531/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 273.9555 - recon_loss: 3.8600e-04 - KL loss: 25.4246 - beta: 0.0012 - val_loss: 288.0398 - val_recon_loss: 4.0734e-04 - val_KL loss: 25.7683 - val_beta: 0.0012\n",
      "Epoch 1532/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 270.6609 - recon_loss: 3.8075e-04 - KL loss: 25.5107 - beta: 0.0012 - val_loss: 290.8864 - val_recon_loss: 4.1224e-04 - val_KL loss: 25.4637 - val_beta: 0.0012\n",
      "Epoch 1533/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 264.4658 - recon_loss: 3.7140e-04 - KL loss: 25.3376 - beta: 0.0012 - val_loss: 286.4132 - val_recon_loss: 4.0545e-04 - val_KL loss: 25.3570 - val_beta: 0.0012\n",
      "Epoch 1534/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 262.2536 - recon_loss: 3.6818e-04 - KL loss: 25.1947 - beta: 0.0012 - val_loss: 300.2871 - val_recon_loss: 4.2754e-04 - val_KL loss: 25.0120 - val_beta: 0.0012\n",
      "Epoch 1535/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 266.4645 - recon_loss: 3.7461e-04 - KL loss: 25.2683 - beta: 0.0012 - val_loss: 325.4624 - val_recon_loss: 4.6647e-04 - val_KL loss: 25.1181 - val_beta: 0.0012\n",
      "Epoch 1536/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 267.1002 - recon_loss: 3.7566e-04 - KL loss: 25.2293 - beta: 0.0012 - val_loss: 314.6776 - val_recon_loss: 4.4974e-04 - val_KL loss: 25.1070 - val_beta: 0.0012\n",
      "Epoch 1537/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 262.6689 - recon_loss: 3.6872e-04 - KL loss: 25.2636 - beta: 0.0012 - val_loss: 289.0307 - val_recon_loss: 4.1039e-04 - val_KL loss: 24.8001 - val_beta: 0.0012\n",
      "Epoch 1538/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 265.8048 - recon_loss: 3.7362e-04 - KL loss: 25.2484 - beta: 0.0012 - val_loss: 282.4837 - val_recon_loss: 4.0063e-04 - val_KL loss: 24.5343 - val_beta: 0.0012\n",
      "Epoch 1539/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 260.3635 - recon_loss: 3.6542e-04 - KL loss: 25.0831 - beta: 0.0012 - val_loss: 312.5005 - val_recon_loss: 4.4666e-04 - val_KL loss: 24.9140 - val_beta: 0.0012\n",
      "Epoch 1540/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 259.8178 - recon_loss: 3.6462e-04 - KL loss: 25.0533 - beta: 0.0012 - val_loss: 292.0392 - val_recon_loss: 4.1469e-04 - val_KL loss: 25.0371 - val_beta: 0.0012\n",
      "Epoch 1541/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 260.2867 - recon_loss: 3.6530e-04 - KL loss: 25.0818 - beta: 0.0012 - val_loss: 292.8482 - val_recon_loss: 4.1588e-04 - val_KL loss: 25.0800 - val_beta: 0.0012\n",
      "Epoch 1542/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 262.2649 - recon_loss: 3.6850e-04 - KL loss: 25.0004 - beta: 0.0012 - val_loss: 292.4259 - val_recon_loss: 4.1549e-04 - val_KL loss: 24.9097 - val_beta: 0.0012\n",
      "Epoch 1543/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 260.4526 - recon_loss: 3.6553e-04 - KL loss: 25.1043 - beta: 0.0012\n",
      "Epoch 01543: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 260.4527 - recon_loss: 3.6553e-04 - KL loss: 25.1042 - beta: 0.0012 - val_loss: 286.3438 - val_recon_loss: 4.0650e-04 - val_KL loss: 24.6162 - val_beta: 0.0012\n",
      "Epoch 1544/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 260.6634 - recon_loss: 3.6579e-04 - KL loss: 25.1463 - beta: 0.0012 - val_loss: 274.9985 - val_recon_loss: 3.8861e-04 - val_KL loss: 24.7869 - val_beta: 0.0012\n",
      "Epoch 1545/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 257.3899 - recon_loss: 3.6065e-04 - KL loss: 25.1836 - beta: 0.0012 - val_loss: 273.7572 - val_recon_loss: 3.8656e-04 - val_KL loss: 24.8675 - val_beta: 0.0012\n",
      "Epoch 1546/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 253.9035 - recon_loss: 3.5537e-04 - KL loss: 25.0947 - beta: 0.0012 - val_loss: 275.9512 - val_recon_loss: 3.9012e-04 - val_KL loss: 24.7689 - val_beta: 0.0012\n",
      "Epoch 1547/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 256.8541 - recon_loss: 3.5984e-04 - KL loss: 25.1664 - beta: 0.0012 - val_loss: 278.2532 - val_recon_loss: 3.9340e-04 - val_KL loss: 24.9592 - val_beta: 0.0012\n",
      "Epoch 1548/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 254.9852 - recon_loss: 3.5682e-04 - KL loss: 25.2444 - beta: 0.0012 - val_loss: 280.5975 - val_recon_loss: 3.9743e-04 - val_KL loss: 24.7086 - val_beta: 0.0012\n",
      "Epoch 1549/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 255.4554 - recon_loss: 3.5776e-04 - KL loss: 25.1062 - beta: 0.0012 - val_loss: 280.0605 - val_recon_loss: 3.9654e-04 - val_KL loss: 24.7409 - val_beta: 0.0012\n",
      "Epoch 1550/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 256.1091 - recon_loss: 3.5877e-04 - KL loss: 25.1140 - beta: 0.0012\n",
      "Epoch 01550: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 256.1086 - recon_loss: 3.5876e-04 - KL loss: 25.1140 - beta: 0.0012 - val_loss: 274.4963 - val_recon_loss: 3.8782e-04 - val_KL loss: 24.7968 - val_beta: 0.0012\n",
      "Epoch 1551/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 254.4884 - recon_loss: 3.5610e-04 - KL loss: 25.2129 - beta: 0.0012 - val_loss: 276.1455 - val_recon_loss: 3.9025e-04 - val_KL loss: 24.8797 - val_beta: 0.0012\n",
      "Epoch 1552/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 254.9919 - recon_loss: 3.5681e-04 - KL loss: 25.2575 - beta: 0.0012 - val_loss: 274.6676 - val_recon_loss: 3.8795e-04 - val_KL loss: 24.8794 - val_beta: 0.0012\n",
      "Epoch 1553/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 255.6623 - recon_loss: 3.5789e-04 - KL loss: 25.2321 - beta: 0.0012 - val_loss: 275.5864 - val_recon_loss: 3.8917e-04 - val_KL loss: 25.0178 - val_beta: 0.0012\n",
      "Epoch 1554/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 249.6047 - recon_loss: 3.4839e-04 - KL loss: 25.2925 - beta: 0.0012 - val_loss: 273.4301 - val_recon_loss: 3.8585e-04 - val_KL loss: 24.9961 - val_beta: 0.0012\n",
      "Epoch 1555/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 254.2555 - recon_loss: 3.5562e-04 - KL loss: 25.2875 - beta: 0.0012 - val_loss: 274.1970 - val_recon_loss: 3.8709e-04 - val_KL loss: 24.9665 - val_beta: 0.0012\n",
      "Epoch 1556/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 253.1657 - recon_loss: 3.5393e-04 - KL loss: 25.2841 - beta: 0.0012 - val_loss: 276.0605 - val_recon_loss: 3.8996e-04 - val_KL loss: 24.9783 - val_beta: 0.0012\n",
      "Epoch 1557/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 253.7733 - recon_loss: 3.5488e-04 - KL loss: 25.2780 - beta: 0.0012 - val_loss: 272.5750 - val_recon_loss: 3.8465e-04 - val_KL loss: 24.9118 - val_beta: 0.0012\n",
      "Epoch 1558/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 253.0269 - recon_loss: 3.5378e-04 - KL loss: 25.2419 - beta: 0.0012 - val_loss: 275.7105 - val_recon_loss: 3.8962e-04 - val_KL loss: 24.8508 - val_beta: 0.0012\n",
      "Epoch 1559/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 254.5130 - recon_loss: 3.5612e-04 - KL loss: 25.2189 - beta: 0.0012 - val_loss: 274.6837 - val_recon_loss: 3.8796e-04 - val_KL loss: 24.8908 - val_beta: 0.0012\n",
      "Epoch 1560/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 252.7948 - recon_loss: 3.5346e-04 - KL loss: 25.2173 - beta: 0.0012 - val_loss: 273.6256 - val_recon_loss: 3.8634e-04 - val_KL loss: 24.8743 - val_beta: 0.0012\n",
      "Epoch 1561/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 255.1739 - recon_loss: 3.5715e-04 - KL loss: 25.2187 - beta: 0.0012 - val_loss: 271.3297 - val_recon_loss: 3.8273e-04 - val_KL loss: 24.9025 - val_beta: 0.0012\n",
      "Epoch 1562/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 253.4144 - recon_loss: 3.5439e-04 - KL loss: 25.2372 - beta: 0.0012 - val_loss: 273.0411 - val_recon_loss: 3.8538e-04 - val_KL loss: 24.9088 - val_beta: 0.0012\n",
      "Epoch 1563/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 251.1859 - recon_loss: 3.5099e-04 - KL loss: 25.1946 - beta: 0.0012 - val_loss: 272.2057 - val_recon_loss: 3.8410e-04 - val_KL loss: 24.9011 - val_beta: 0.0012\n",
      "Epoch 1564/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 251.6686 - recon_loss: 3.5167e-04 - KL loss: 25.2394 - beta: 0.0012 - val_loss: 275.0182 - val_recon_loss: 3.8840e-04 - val_KL loss: 24.9413 - val_beta: 0.0012\n",
      "Epoch 1565/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 251.4825 - recon_loss: 3.5143e-04 - KL loss: 25.2099 - beta: 0.0012 - val_loss: 274.1203 - val_recon_loss: 3.8703e-04 - val_KL loss: 24.9255 - val_beta: 0.0012\n",
      "Epoch 1566/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 252.3092 - recon_loss: 3.5272e-04 - KL loss: 25.2086 - beta: 0.0012\n",
      "Epoch 01566: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 252.3085 - recon_loss: 3.5272e-04 - KL loss: 25.2086 - beta: 0.0012 - val_loss: 274.6205 - val_recon_loss: 3.8780e-04 - val_KL loss: 24.9286 - val_beta: 0.0012\n",
      "Epoch 1567/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 251.9914 - recon_loss: 3.5221e-04 - KL loss: 25.2187 - beta: 0.0012 - val_loss: 275.2864 - val_recon_loss: 3.8888e-04 - val_KL loss: 24.9010 - val_beta: 0.0012\n",
      "Epoch 1568/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 252.9905 - recon_loss: 3.5377e-04 - KL loss: 25.2110 - beta: 0.0012 - val_loss: 270.1014 - val_recon_loss: 3.8079e-04 - val_KL loss: 24.9279 - val_beta: 0.0012\n",
      "Epoch 1569/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 249.5615 - recon_loss: 3.4848e-04 - KL loss: 25.1914 - beta: 0.0012 - val_loss: 270.7254 - val_recon_loss: 3.8176e-04 - val_KL loss: 24.9255 - val_beta: 0.0012\n",
      "Epoch 1570/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 253.4763 - recon_loss: 3.5456e-04 - KL loss: 25.1896 - beta: 0.0012 - val_loss: 275.3913 - val_recon_loss: 3.8897e-04 - val_KL loss: 24.9485 - val_beta: 0.0012\n",
      "Epoch 1571/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 251.1457 - recon_loss: 3.5088e-04 - KL loss: 25.2284 - beta: 0.0012 - val_loss: 273.5292 - val_recon_loss: 3.8609e-04 - val_KL loss: 24.9427 - val_beta: 0.0012\n",
      "Epoch 1572/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 249.8324 - recon_loss: 3.4886e-04 - KL loss: 25.2136 - beta: 0.0012 - val_loss: 271.7415 - val_recon_loss: 3.8331e-04 - val_KL loss: 24.9408 - val_beta: 0.0012\n",
      "Epoch 1573/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 251.7778 - recon_loss: 3.5186e-04 - KL loss: 25.2289 - beta: 0.0012\n",
      "Epoch 01573: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 251.7780 - recon_loss: 3.5186e-04 - KL loss: 25.2289 - beta: 0.0012 - val_loss: 271.7644 - val_recon_loss: 3.8334e-04 - val_KL loss: 24.9492 - val_beta: 0.0012\n",
      "Epoch 1574/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 254.0646 - recon_loss: 3.5538e-04 - KL loss: 25.2505 - beta: 0.0012 - val_loss: 273.0597 - val_recon_loss: 3.8534e-04 - val_KL loss: 24.9527 - val_beta: 0.0012\n",
      "Epoch 1575/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 251.5560 - recon_loss: 3.5151e-04 - KL loss: 25.2314 - beta: 0.0012 - val_loss: 272.8148 - val_recon_loss: 3.8497e-04 - val_KL loss: 24.9495 - val_beta: 0.0012\n",
      "Epoch 1576/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 250.7189 - recon_loss: 3.5023e-04 - KL loss: 25.2221 - beta: 0.0012 - val_loss: 270.3731 - val_recon_loss: 3.8119e-04 - val_KL loss: 24.9393 - val_beta: 0.0012\n",
      "Epoch 1577/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 251.2436 - recon_loss: 3.5106e-04 - KL loss: 25.2132 - beta: 0.0012 - val_loss: 270.6669 - val_recon_loss: 3.8164e-04 - val_KL loss: 24.9420 - val_beta: 0.0012\n",
      "Epoch 1578/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 251.8570 - recon_loss: 3.5201e-04 - KL loss: 25.2133 - beta: 0.0012\n",
      "Epoch 01578: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 251.8564 - recon_loss: 3.5201e-04 - KL loss: 25.2133 - beta: 0.0012 - val_loss: 273.6906 - val_recon_loss: 3.8633e-04 - val_KL loss: 24.9462 - val_beta: 0.0012\n",
      "Epoch 1578/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 512.8141 - recon_loss: 4.0231e-04 - KL loss: 26.1282 - beta: 9.0919e-04 - val_loss: 588.0291 - val_recon_loss: 4.6428e-04 - val_KL loss: 26.3711 - val_beta: 9.0919e-04\n",
      "Epoch 1579/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 494.7262 - recon_loss: 3.8688e-04 - KL loss: 26.7051 - beta: 9.0919e-04 - val_loss: 575.1516 - val_recon_loss: 4.5364e-04 - val_KL loss: 26.3639 - val_beta: 9.0919e-04\n",
      "Epoch 1580/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 491.0826 - recon_loss: 3.8376e-04 - KL loss: 26.8274 - beta: 9.0919e-04 - val_loss: 540.9210 - val_recon_loss: 4.2519e-04 - val_KL loss: 26.5503 - val_beta: 9.0919e-04\n",
      "Epoch 1581/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 493.1017 - recon_loss: 3.8534e-04 - KL loss: 26.9393 - beta: 9.0919e-04 - val_loss: 542.4920 - val_recon_loss: 4.2630e-04 - val_KL loss: 26.7803 - val_beta: 9.0919e-04\n",
      "Epoch 1582/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 488.8062 - recon_loss: 3.8172e-04 - KL loss: 27.0293 - beta: 9.0919e-04 - val_loss: 623.3958 - val_recon_loss: 4.9256e-04 - val_KL loss: 27.5303 - val_beta: 9.0919e-04\n",
      "Epoch 1583/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 522.4501 - recon_loss: 4.0940e-04 - KL loss: 27.1814 - beta: 9.0919e-04 - val_loss: 554.3009 - val_recon_loss: 4.3587e-04 - val_KL loss: 27.0064 - val_beta: 9.0919e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1584/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 493.1338 - recon_loss: 3.8505e-04 - KL loss: 27.3253 - beta: 9.0919e-04 - val_loss: 532.0554 - val_recon_loss: 4.1646e-04 - val_KL loss: 28.2459 - val_beta: 9.0919e-04\n",
      "Epoch 1585/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 496.1985 - recon_loss: 3.8733e-04 - KL loss: 27.6257 - beta: 9.0919e-04 - val_loss: 610.7014 - val_recon_loss: 4.8256e-04 - val_KL loss: 26.9247 - val_beta: 9.0919e-04\n",
      "Epoch 1586/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 500.6208 - recon_loss: 3.9136e-04 - KL loss: 27.1745 - beta: 9.0919e-04 - val_loss: 536.6343 - val_recon_loss: 4.2190e-04 - val_KL loss: 26.2429 - val_beta: 9.0919e-04\n",
      "Epoch 1587/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 479.6544 - recon_loss: 3.7418e-04 - KL loss: 26.9944 - beta: 9.0919e-04 - val_loss: 537.2187 - val_recon_loss: 4.2218e-04 - val_KL loss: 26.4898 - val_beta: 9.0919e-04\n",
      "Epoch 1588/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 489.7480 - recon_loss: 3.8258e-04 - KL loss: 26.9309 - beta: 9.0919e-04 - val_loss: 524.5934 - val_recon_loss: 4.1181e-04 - val_KL loss: 26.4101 - val_beta: 9.0919e-04\n",
      "Epoch 1589/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 480.6422 - recon_loss: 3.7501e-04 - KL loss: 26.9725 - beta: 9.0919e-04 - val_loss: 532.9486 - val_recon_loss: 4.1863e-04 - val_KL loss: 26.5164 - val_beta: 9.0919e-04\n",
      "Epoch 1590/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 474.4637 - recon_loss: 3.6997e-04 - KL loss: 26.8962 - beta: 9.0919e-04 - val_loss: 508.5353 - val_recon_loss: 3.9821e-04 - val_KL loss: 26.8045 - val_beta: 9.0919e-04\n",
      "Epoch 1591/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 479.8180 - recon_loss: 3.7419e-04 - KL loss: 27.1474 - beta: 9.0919e-04 - val_loss: 516.4053 - val_recon_loss: 4.0483e-04 - val_KL loss: 26.6703 - val_beta: 9.0919e-04\n",
      "Epoch 1592/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 556.2176 - recon_loss: 4.3686e-04 - KL loss: 27.7291 - beta: 9.0919e-04 - val_loss: 513.5772 - val_recon_loss: 4.0255e-04 - val_KL loss: 26.5969 - val_beta: 9.0919e-04\n",
      "Epoch 1593/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 491.1410 - recon_loss: 3.8350e-04 - KL loss: 27.2085 - beta: 9.0919e-04 - val_loss: 596.6671 - val_recon_loss: 4.7152e-04 - val_KL loss: 26.2460 - val_beta: 9.0919e-04\n",
      "Epoch 1594/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 552.6618 - recon_loss: 4.3413e-04 - KL loss: 27.4750 - beta: 9.0919e-04 - val_loss: 555.5668 - val_recon_loss: 4.3753e-04 - val_KL loss: 26.2702 - val_beta: 9.0919e-04\n",
      "Epoch 1595/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 497.9344 - recon_loss: 3.8921e-04 - KL loss: 27.0969 - beta: 9.0919e-04\n",
      "Epoch 01595: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 497.9398 - recon_loss: 3.8921e-04 - KL loss: 27.0970 - beta: 9.0919e-04 - val_loss: 607.1131 - val_recon_loss: 4.7925e-04 - val_KL loss: 27.3453 - val_beta: 9.0919e-04\n",
      "Epoch 1596/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 493.4441 - recon_loss: 3.8505e-04 - KL loss: 27.6328 - beta: 9.0919e-04 - val_loss: 571.0269 - val_recon_loss: 4.4934e-04 - val_KL loss: 27.4410 - val_beta: 9.0919e-04\n",
      "Epoch 1597/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 489.0470 - recon_loss: 3.8149e-04 - KL loss: 27.5434 - beta: 9.0919e-04 - val_loss: 605.3886 - val_recon_loss: 4.7770e-04 - val_KL loss: 27.4914 - val_beta: 9.0919e-04\n",
      "Epoch 1598/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 503.2131 - recon_loss: 3.9289e-04 - KL loss: 27.9132 - beta: 9.0919e-04 - val_loss: 605.0333 - val_recon_loss: 4.7691e-04 - val_KL loss: 28.0909 - val_beta: 9.0919e-04\n",
      "Epoch 1599/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 507.7335 - recon_loss: 3.9663e-04 - KL loss: 27.9128 - beta: 9.0919e-04 - val_loss: 593.3410 - val_recon_loss: 4.6737e-04 - val_KL loss: 27.9422 - val_beta: 9.0919e-04\n",
      "Epoch 1600/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 509.7334 - recon_loss: 3.9813e-04 - KL loss: 28.0932 - beta: 9.0919e-04\n",
      "Epoch 01600: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 509.7264 - recon_loss: 3.9813e-04 - KL loss: 28.0931 - beta: 9.0919e-04 - val_loss: 675.9207 - val_recon_loss: 5.3599e-04 - val_KL loss: 27.5122 - val_beta: 9.0919e-04\n",
      "Epoch 1600/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 1053.7027 - recon_loss: 4.5045e-04 - KL loss: 29.8328 - beta: 6.6329e-04 - val_loss: 1071.8865 - val_recon_loss: 4.5791e-04 - val_KL loss: 31.0627 - val_beta: 6.6329e-04\n",
      "Epoch 1601/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1124.3442 - recon_loss: 4.8077e-04 - KL loss: 31.5717 - beta: 6.6329e-04 - val_loss: 1055.5984 - val_recon_loss: 4.5002e-04 - val_KL loss: 32.7141 - val_beta: 6.6329e-04\n",
      "Epoch 1602/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1115.0855 - recon_loss: 4.7594e-04 - KL loss: 33.2769 - beta: 6.6329e-04 - val_loss: 1142.1934 - val_recon_loss: 4.8893e-04 - val_KL loss: 30.8642 - val_beta: 6.6329e-04\n",
      "Epoch 1603/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1039.1318 - recon_loss: 4.4306e-04 - KL loss: 32.0644 - beta: 6.6329e-04 - val_loss: 1115.9525 - val_recon_loss: 4.7704e-04 - val_KL loss: 31.6485 - val_beta: 6.6329e-04\n",
      "Epoch 1604/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 996.8362 - recon_loss: 4.2448e-04 - KL loss: 32.0067 - beta: 6.6329e-04 - val_loss: 1065.7266 - val_recon_loss: 4.5547e-04 - val_KL loss: 30.4624 - val_beta: 6.6329e-04\n",
      "Epoch 1605/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 954.0481 - recon_loss: 4.0600e-04 - KL loss: 31.2130 - beta: 6.6329e-04 - val_loss: 1098.2206 - val_recon_loss: 4.6945e-04 - val_KL loss: 31.1689 - val_beta: 6.6329e-04\n",
      "Epoch 1606/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 953.9324 - recon_loss: 4.0595e-04 - KL loss: 31.2248 - beta: 6.6329e-04\n",
      "Epoch 01606: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 953.9282 - recon_loss: 4.0595e-04 - KL loss: 31.2248 - beta: 6.6329e-04 - val_loss: 1068.3944 - val_recon_loss: 4.5685e-04 - val_KL loss: 29.9965 - val_beta: 6.6329e-04\n",
      "Epoch 1607/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 902.5788 - recon_loss: 3.8347e-04 - KL loss: 30.9535 - beta: 6.6329e-04 - val_loss: 1011.6684 - val_recon_loss: 4.3147e-04 - val_KL loss: 30.9572 - val_beta: 6.6329e-04\n",
      "Epoch 1608/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 892.1841 - recon_loss: 3.7877e-04 - KL loss: 31.2620 - beta: 6.6329e-04 - val_loss: 993.3294 - val_recon_loss: 4.2373e-04 - val_KL loss: 30.2117 - val_beta: 6.6329e-04\n",
      "Epoch 1609/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 891.4661 - recon_loss: 3.7849e-04 - KL loss: 31.1634 - beta: 6.6329e-04 - val_loss: 991.4485 - val_recon_loss: 4.2275e-04 - val_KL loss: 30.5451 - val_beta: 6.6329e-04\n",
      "Epoch 1610/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 877.1765 - recon_loss: 3.7225e-04 - KL loss: 31.0577 - beta: 6.6329e-04 - val_loss: 992.3285 - val_recon_loss: 4.2330e-04 - val_KL loss: 30.1793 - val_beta: 6.6329e-04\n",
      "Epoch 1611/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 876.1317 - recon_loss: 3.7188e-04 - KL loss: 30.8549 - beta: 6.6329e-04 - val_loss: 977.9637 - val_recon_loss: 4.1680e-04 - val_KL loss: 30.5935 - val_beta: 6.6329e-04\n",
      "Epoch 1612/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 887.8223 - recon_loss: 3.7683e-04 - KL loss: 31.3080 - beta: 6.6329e-04 - val_loss: 999.3729 - val_recon_loss: 4.2626e-04 - val_KL loss: 30.5041 - val_beta: 6.6329e-04\n",
      "Epoch 1613/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 877.5940 - recon_loss: 3.7238e-04 - KL loss: 31.1927 - beta: 6.6329e-04 - val_loss: 995.2332 - val_recon_loss: 4.2439e-04 - val_KL loss: 30.5975 - val_beta: 6.6329e-04\n",
      "Epoch 1614/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 862.4711 - recon_loss: 3.6561e-04 - KL loss: 31.4604 - beta: 6.6329e-04 - val_loss: 1061.0066 - val_recon_loss: 4.5288e-04 - val_KL loss: 31.6281 - val_beta: 6.6329e-04\n",
      "Epoch 1615/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 875.9895 - recon_loss: 3.7138e-04 - KL loss: 31.8488 - beta: 6.6329e-04 - val_loss: 1031.1849 - val_recon_loss: 4.4007e-04 - val_KL loss: 30.9296 - val_beta: 6.6329e-04\n",
      "Epoch 1616/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 877.8081 - recon_loss: 3.7215e-04 - KL loss: 31.9206 - beta: 6.6329e-04 - val_loss: 973.6067 - val_recon_loss: 4.1475e-04 - val_KL loss: 30.9030 - val_beta: 6.6329e-04\n",
      "Epoch 1617/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 887.1857 - recon_loss: 3.7630e-04 - KL loss: 31.8786 - beta: 6.6329e-04 - val_loss: 1045.5670 - val_recon_loss: 4.4634e-04 - val_KL loss: 31.0534 - val_beta: 6.6329e-04\n",
      "Epoch 1618/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 876.7684 - recon_loss: 3.7192e-04 - KL loss: 31.3956 - beta: 6.6329e-04 - val_loss: 1028.2264 - val_recon_loss: 4.3877e-04 - val_KL loss: 30.9133 - val_beta: 6.6329e-04\n",
      "Epoch 1619/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 887.6435 - recon_loss: 3.7679e-04 - KL loss: 31.2207 - beta: 6.6329e-04 - val_loss: 998.0549 - val_recon_loss: 4.2540e-04 - val_KL loss: 31.1369 - val_beta: 6.6329e-04\n",
      "Epoch 1620/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 869.4813 - recon_loss: 3.6857e-04 - KL loss: 31.7374 - beta: 6.6329e-04 - val_loss: 1019.1844 - val_recon_loss: 4.3475e-04 - val_KL loss: 31.0161 - val_beta: 6.6329e-04\n",
      "Epoch 1621/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 876.3195 - recon_loss: 3.7159e-04 - KL loss: 31.6966 - beta: 6.6329e-04 - val_loss: 966.6691 - val_recon_loss: 4.1200e-04 - val_KL loss: 30.2002 - val_beta: 6.6329e-04\n",
      "Epoch 1622/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 858.8729 - recon_loss: 3.6416e-04 - KL loss: 31.1534 - beta: 6.6329e-04 - val_loss: 1041.2955 - val_recon_loss: 4.4427e-04 - val_KL loss: 31.4922 - val_beta: 6.6329e-04\n",
      "Epoch 1623/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 879.8050 - recon_loss: 3.7292e-04 - KL loss: 32.1656 - beta: 6.6329e-04 - val_loss: 1039.7275 - val_recon_loss: 4.4347e-04 - val_KL loss: 31.7378 - val_beta: 6.6329e-04\n",
      "Epoch 1624/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 898.5581 - recon_loss: 3.8106e-04 - KL loss: 32.4249 - beta: 6.6329e-04 - val_loss: 993.0597 - val_recon_loss: 4.2304e-04 - val_KL loss: 31.5066 - val_beta: 6.6329e-04\n",
      "Epoch 1625/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 873.6250 - recon_loss: 3.7034e-04 - KL loss: 31.8531 - beta: 6.6329e-04 - val_loss: 1037.9657 - val_recon_loss: 4.4304e-04 - val_KL loss: 30.9495 - val_beta: 6.6329e-04\n",
      "Epoch 1626/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 864.3327 - recon_loss: 3.6631e-04 - KL loss: 31.7244 - beta: 6.6329e-04\n",
      "Epoch 01626: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 864.3291 - recon_loss: 3.6631e-04 - KL loss: 31.7244 - beta: 6.6329e-04 - val_loss: 1083.6183 - val_recon_loss: 4.6321e-04 - val_KL loss: 30.7651 - val_beta: 6.6329e-04\n",
      "Epoch 1627/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 860.6727 - recon_loss: 3.6489e-04 - KL loss: 31.2937 - beta: 6.6329e-04 - val_loss: 1012.2844 - val_recon_loss: 4.3192e-04 - val_KL loss: 30.5430 - val_beta: 6.6329e-04\n",
      "Epoch 1628/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 835.7760 - recon_loss: 3.5386e-04 - KL loss: 31.4515 - beta: 6.6329e-04 - val_loss: 1044.1583 - val_recon_loss: 4.4582e-04 - val_KL loss: 30.8121 - val_beta: 6.6329e-04\n",
      "Epoch 1629/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 840.0350 - recon_loss: 3.5571e-04 - KL loss: 31.5145 - beta: 6.6329e-04 - val_loss: 1019.2486 - val_recon_loss: 4.3450e-04 - val_KL loss: 31.6359 - val_beta: 6.6329e-04\n",
      "Epoch 1630/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 840.4994 - recon_loss: 3.5580e-04 - KL loss: 31.7698 - beta: 6.6329e-04 - val_loss: 1023.8190 - val_recon_loss: 4.3630e-04 - val_KL loss: 32.1152 - val_beta: 6.6329e-04\n",
      "Epoch 1631/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 848.8188 - recon_loss: 3.5937e-04 - KL loss: 31.9850 - beta: 6.6329e-04\n",
      "Epoch 01631: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 848.8145 - recon_loss: 3.5937e-04 - KL loss: 31.9849 - beta: 6.6329e-04 - val_loss: 1067.3315 - val_recon_loss: 4.5566e-04 - val_KL loss: 31.6370 - val_beta: 6.6329e-04\n",
      "Epoch 1631/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1773.6668 - recon_loss: 4.0756e-04 - KL loss: 33.0980 - beta: 4.8390e-04 - val_loss: 2239.6282 - val_recon_loss: 5.1575e-04 - val_KL loss: 37.0384 - val_beta: 4.8390e-04\n",
      "Epoch 1632/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1814.3221 - recon_loss: 4.1633e-04 - KL loss: 36.3248 - beta: 4.8390e-04 - val_loss: 2484.6340 - val_recon_loss: 5.7297e-04 - val_KL loss: 37.6606 - val_beta: 4.8390e-04\n",
      "Epoch 1633/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1800.3625 - recon_loss: 4.1300e-04 - KL loss: 36.5916 - beta: 4.8390e-04 - val_loss: 1930.4167 - val_recon_loss: 4.4357e-04 - val_KL loss: 36.0923 - val_beta: 4.8390e-04\n",
      "Epoch 1634/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1888.4248 - recon_loss: 4.3319e-04 - KL loss: 38.3987 - beta: 4.8390e-04 - val_loss: 2187.4946 - val_recon_loss: 5.0328e-04 - val_KL loss: 38.1617 - val_beta: 4.8390e-04\n",
      "Epoch 1635/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1954.0465 - recon_loss: 4.4830e-04 - KL loss: 39.4953 - beta: 4.8390e-04 - val_loss: 1943.8607 - val_recon_loss: 4.4677e-04 - val_KL loss: 35.8491 - val_beta: 4.8390e-04\n",
      "Epoch 1636/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1748.6927 - recon_loss: 4.0063e-04 - KL loss: 37.7416 - beta: 4.8390e-04 - val_loss: 1850.4805 - val_recon_loss: 4.2472e-04 - val_KL loss: 36.6671 - val_beta: 4.8390e-04\n",
      "Epoch 1637/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1727.4918 - recon_loss: 3.9601e-04 - KL loss: 36.2858 - beta: 4.8390e-04 - val_loss: 2074.0879 - val_recon_loss: 4.7642e-04 - val_KL loss: 39.4530 - val_beta: 4.8390e-04\n",
      "Epoch 1638/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1794.9505 - recon_loss: 4.1135e-04 - KL loss: 38.2351 - beta: 4.8390e-04 - val_loss: 2465.2078 - val_recon_loss: 5.6763e-04 - val_KL loss: 41.0748 - val_beta: 4.8390e-04\n",
      "Epoch 1639/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1962.4958 - recon_loss: 4.5023e-04 - KL loss: 39.7365 - beta: 4.8390e-04 - val_loss: 2215.2566 - val_recon_loss: 5.0937e-04 - val_KL loss: 39.8953 - val_beta: 4.8390e-04\n",
      "Epoch 1640/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1798.4664 - recon_loss: 4.1202e-04 - KL loss: 38.8906 - beta: 4.8390e-04 - val_loss: 2073.1208 - val_recon_loss: 4.7757e-04 - val_KL loss: 33.6012 - val_beta: 4.8390e-04\n",
      "Epoch 1641/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1685.7169 - recon_loss: 3.8612e-04 - KL loss: 36.7095 - beta: 4.8390e-04\n",
      "Epoch 01641: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1685.7021 - recon_loss: 3.8612e-04 - KL loss: 36.7098 - beta: 4.8390e-04 - val_loss: 1956.9460 - val_recon_loss: 4.4984e-04 - val_KL loss: 35.8308 - val_beta: 4.8390e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1642/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1607.7197 - recon_loss: 3.6789e-04 - KL loss: 36.5981 - beta: 4.8390e-04 - val_loss: 1999.4504 - val_recon_loss: 4.5994e-04 - val_KL loss: 35.1972 - val_beta: 4.8390e-04\n",
      "Epoch 1643/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1623.8593 - recon_loss: 3.7185e-04 - KL loss: 35.8290 - beta: 4.8390e-04 - val_loss: 1961.0308 - val_recon_loss: 4.5091e-04 - val_KL loss: 35.3458 - val_beta: 4.8390e-04\n",
      "Epoch 1644/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1570.8081 - recon_loss: 3.5926e-04 - KL loss: 36.5511 - beta: 4.8390e-04 - val_loss: 1819.8687 - val_recon_loss: 4.1777e-04 - val_KL loss: 35.7098 - val_beta: 4.8390e-04\n",
      "Epoch 1645/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1582.5632 - recon_loss: 3.6193e-04 - KL loss: 36.8793 - beta: 4.8390e-04 - val_loss: 1825.6893 - val_recon_loss: 4.1906e-04 - val_KL loss: 36.0247 - val_beta: 4.8390e-04\n",
      "Epoch 1646/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1562.0401 - recon_loss: 3.5715e-04 - KL loss: 36.7641 - beta: 4.8390e-04 - val_loss: 1846.3171 - val_recon_loss: 4.2406e-04 - val_KL loss: 35.2886 - val_beta: 4.8390e-04\n",
      "Epoch 1647/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1565.2870 - recon_loss: 3.5797e-04 - KL loss: 36.5319 - beta: 4.8390e-04 - val_loss: 1813.0737 - val_recon_loss: 4.1586e-04 - val_KL loss: 37.0933 - val_beta: 4.8390e-04\n",
      "Epoch 1648/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1591.6638 - recon_loss: 3.6393e-04 - KL loss: 37.4593 - beta: 4.8390e-04 - val_loss: 1803.5188 - val_recon_loss: 4.1399e-04 - val_KL loss: 35.4957 - val_beta: 4.8390e-04\n",
      "Epoch 1649/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1547.0164 - recon_loss: 3.5376e-04 - KL loss: 36.2191 - beta: 4.8390e-04 - val_loss: 1841.1145 - val_recon_loss: 4.2277e-04 - val_KL loss: 35.6005 - val_beta: 4.8390e-04\n",
      "Epoch 1650/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1535.9844 - recon_loss: 3.5111e-04 - KL loss: 36.5000 - beta: 4.8390e-04 - val_loss: 1850.4896 - val_recon_loss: 4.2495e-04 - val_KL loss: 35.6920 - val_beta: 4.8390e-04\n",
      "Epoch 1651/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1552.5513 - recon_loss: 3.5506e-04 - KL loss: 36.1966 - beta: 4.8390e-04 - val_loss: 1827.2893 - val_recon_loss: 4.1949e-04 - val_KL loss: 35.8116 - val_beta: 4.8390e-04\n",
      "Epoch 1652/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1548.9733 - recon_loss: 3.5408e-04 - KL loss: 36.8366 - beta: 4.8390e-04 - val_loss: 1924.2095 - val_recon_loss: 4.4229e-04 - val_KL loss: 35.3493 - val_beta: 4.8390e-04\n",
      "Epoch 1653/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1529.9679 - recon_loss: 3.4978e-04 - KL loss: 36.1968 - beta: 4.8390e-04\n",
      "Epoch 01653: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1529.9714 - recon_loss: 3.4978e-04 - KL loss: 36.1968 - beta: 4.8390e-04 - val_loss: 1870.7467 - val_recon_loss: 4.2964e-04 - val_KL loss: 35.8919 - val_beta: 4.8390e-04\n",
      "Epoch 1654/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1507.8348 - recon_loss: 3.4455e-04 - KL loss: 36.3926 - beta: 4.8390e-04 - val_loss: 1852.1969 - val_recon_loss: 4.2538e-04 - val_KL loss: 35.5654 - val_beta: 4.8390e-04\n",
      "Epoch 1655/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1514.8113 - recon_loss: 3.4617e-04 - KL loss: 36.4316 - beta: 4.8390e-04 - val_loss: 1824.3331 - val_recon_loss: 4.1874e-04 - val_KL loss: 36.0192 - val_beta: 4.8390e-04\n",
      "Epoch 1656/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1504.0179 - recon_loss: 3.4366e-04 - KL loss: 36.3458 - beta: 4.8390e-04 - val_loss: 1817.7180 - val_recon_loss: 4.1724e-04 - val_KL loss: 35.8161 - val_beta: 4.8390e-04\n",
      "Epoch 1657/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1505.6975 - recon_loss: 3.4405e-04 - KL loss: 36.3880 - beta: 4.8390e-04 - val_loss: 1870.2561 - val_recon_loss: 4.2964e-04 - val_KL loss: 35.4231 - val_beta: 4.8390e-04\n",
      "Epoch 1658/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1490.6991 - recon_loss: 3.4059e-04 - KL loss: 36.1368 - beta: 4.8390e-04\n",
      "Epoch 01658: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1490.6939 - recon_loss: 3.4059e-04 - KL loss: 36.1369 - beta: 4.8390e-04 - val_loss: 1835.8484 - val_recon_loss: 4.2141e-04 - val_KL loss: 36.1337 - val_beta: 4.8390e-04\n",
      "Epoch 1658/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3231.2233 - recon_loss: 3.9775e-04 - KL loss: 39.6344 - beta: 3.5302e-04 - val_loss: 3332.4617 - val_recon_loss: 4.1033e-04 - val_KL loss: 39.9422 - val_beta: 3.5302e-04\n",
      "Epoch 1659/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3010.8862 - recon_loss: 3.7013e-04 - KL loss: 40.9178 - beta: 3.5302e-04 - val_loss: 3465.3511 - val_recon_loss: 4.2668e-04 - val_KL loss: 41.6099 - val_beta: 3.5302e-04\n",
      "Epoch 1660/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 3126.1399 - recon_loss: 3.8454e-04 - KL loss: 40.5484 - beta: 3.5302e-04 - val_loss: 3711.6875 - val_recon_loss: 4.5749e-04 - val_KL loss: 40.7211 - val_beta: 3.5302e-04\n",
      "Epoch 1661/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3003.7685 - recon_loss: 3.6922e-04 - KL loss: 41.0951 - beta: 3.5302e-04 - val_loss: 3644.9043 - val_recon_loss: 4.4917e-04 - val_KL loss: 40.7323 - val_beta: 3.5302e-04\n",
      "Epoch 1662/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3107.2038 - recon_loss: 3.8211e-04 - KL loss: 41.1565 - beta: 3.5302e-04 - val_loss: 3249.7656 - val_recon_loss: 3.9996e-04 - val_KL loss: 40.4321 - val_beta: 3.5302e-04\n",
      "Epoch 1663/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3017.5182 - recon_loss: 3.7088e-04 - KL loss: 41.5387 - beta: 3.5302e-04 - val_loss: 3179.2483 - val_recon_loss: 3.9109e-04 - val_KL loss: 41.1409 - val_beta: 3.5302e-04\n",
      "Epoch 1664/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3061.7296 - recon_loss: 3.7633e-04 - KL loss: 42.0214 - beta: 3.5302e-04 - val_loss: 3268.0369 - val_recon_loss: 4.0201e-04 - val_KL loss: 42.2604 - val_beta: 3.5302e-04\n",
      "Epoch 1665/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3084.5592 - recon_loss: 3.7916e-04 - KL loss: 42.1191 - beta: 3.5302e-04 - val_loss: 3748.6792 - val_recon_loss: 4.6157e-04 - val_KL loss: 44.9893 - val_beta: 3.5302e-04\n",
      "Epoch 1666/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3332.2679 - recon_loss: 4.0960e-04 - KL loss: 45.6065 - beta: 3.5302e-04 - val_loss: 3392.6099 - val_recon_loss: 4.1730e-04 - val_KL loss: 44.1587 - val_beta: 3.5302e-04\n",
      "Epoch 1667/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3068.9554 - recon_loss: 3.7702e-04 - KL loss: 43.7530 - beta: 3.5302e-04 - val_loss: 3356.7507 - val_recon_loss: 4.1282e-04 - val_KL loss: 44.2797 - val_beta: 3.5302e-04\n",
      "Epoch 1668/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3174.3254 - recon_loss: 3.9005e-04 - KL loss: 44.5288 - beta: 3.5302e-04\n",
      "Epoch 01668: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 3174.3378 - recon_loss: 3.9005e-04 - KL loss: 44.5291 - beta: 3.5302e-04 - val_loss: 3486.6597 - val_recon_loss: 4.2887e-04 - val_KL loss: 45.4017 - val_beta: 3.5302e-04\n",
      "Epoch 1669/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2971.6987 - recon_loss: 3.6480e-04 - KL loss: 44.4824 - beta: 3.5302e-04 - val_loss: 3327.6543 - val_recon_loss: 4.0887e-04 - val_KL loss: 46.8515 - val_beta: 3.5302e-04\n",
      "Epoch 1670/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2878.9513 - recon_loss: 3.5323e-04 - KL loss: 44.5719 - beta: 3.5302e-04 - val_loss: 3211.5564 - val_recon_loss: 3.9481e-04 - val_KL loss: 43.5580 - val_beta: 3.5302e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1671/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2887.6325 - recon_loss: 3.5439e-04 - KL loss: 44.0044 - beta: 3.5302e-04 - val_loss: 3307.7856 - val_recon_loss: 4.0673e-04 - val_KL loss: 44.1132 - val_beta: 3.5302e-04\n",
      "Epoch 1672/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 2913.2448 - recon_loss: 3.5756e-04 - KL loss: 44.1402 - beta: 3.5302e-04 - val_loss: 3295.6033 - val_recon_loss: 4.0522e-04 - val_KL loss: 44.0629 - val_beta: 3.5302e-04\n",
      "Epoch 1673/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 2880.7918 - recon_loss: 3.5354e-04 - KL loss: 43.9763 - beta: 3.5302e-04\n",
      "Epoch 01673: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2880.8368 - recon_loss: 3.5354e-04 - KL loss: 43.9767 - beta: 3.5302e-04 - val_loss: 3179.5247 - val_recon_loss: 3.9065e-04 - val_KL loss: 44.9075 - val_beta: 3.5302e-04\n",
      "Epoch 1673/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6234.1361 - recon_loss: 4.1005e-04 - KL loss: 52.0869 - beta: 2.5754e-04 - val_loss: 7265.0176 - val_recon_loss: 4.7741e-04 - val_KL loss: 67.4550 - val_beta: 2.5754e-04\n",
      "Epoch 1674/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 6300.0394 - recon_loss: 4.1375e-04 - KL loss: 62.2461 - beta: 2.5754e-04 - val_loss: 6638.3188 - val_recon_loss: 4.3654e-04 - val_KL loss: 56.8227 - val_beta: 2.5754e-04\n",
      "Epoch 1675/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5885.4551 - recon_loss: 3.8651e-04 - KL loss: 58.3392 - beta: 2.5754e-04 - val_loss: 7456.6665 - val_recon_loss: 4.9035e-04 - val_KL loss: 63.9931 - val_beta: 2.5754e-04\n",
      "Epoch 1676/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6076.9008 - recon_loss: 3.9896e-04 - KL loss: 62.0667 - beta: 2.5754e-04 - val_loss: 6365.0317 - val_recon_loss: 4.1836e-04 - val_KL loss: 57.6528 - val_beta: 2.5754e-04\n",
      "Epoch 1677/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5694.1154 - recon_loss: 3.7375e-04 - KL loss: 59.3623 - beta: 2.5754e-04 - val_loss: 6709.6040 - val_recon_loss: 4.4113e-04 - val_KL loss: 58.9421 - val_beta: 2.5754e-04\n",
      "Epoch 1678/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 6001.8156 - recon_loss: 3.9418e-04 - KL loss: 59.0286 - beta: 2.5754e-04 - val_loss: 6721.6392 - val_recon_loss: 4.4205e-04 - val_KL loss: 57.0985 - val_beta: 2.5754e-04\n",
      "Epoch 1679/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5659.4098 - recon_loss: 3.7140e-04 - KL loss: 60.0716 - beta: 2.5754e-04 - val_loss: 6529.3760 - val_recon_loss: 4.2898e-04 - val_KL loss: 61.9319 - val_beta: 2.5754e-04\n",
      "Epoch 1680/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5623.4467 - recon_loss: 3.6891e-04 - KL loss: 61.6270 - beta: 2.5754e-04 - val_loss: 6831.1943 - val_recon_loss: 4.4885e-04 - val_KL loss: 64.1741 - val_beta: 2.5754e-04\n",
      "Epoch 1681/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5732.5804 - recon_loss: 3.7614e-04 - KL loss: 61.7352 - beta: 2.5754e-04 - val_loss: 5951.5845 - val_recon_loss: 3.9067e-04 - val_KL loss: 61.7601 - val_beta: 2.5754e-04\n",
      "Epoch 1682/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5687.4292 - recon_loss: 3.7302e-04 - KL loss: 63.6200 - beta: 2.5754e-04 - val_loss: 6071.0298 - val_recon_loss: 3.9853e-04 - val_KL loss: 62.7096 - val_beta: 2.5754e-04\n",
      "Epoch 1683/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5830.2770 - recon_loss: 3.8244e-04 - KL loss: 64.4008 - beta: 2.5754e-04 - val_loss: 6788.2847 - val_recon_loss: 4.4587e-04 - val_KL loss: 66.1696 - val_beta: 2.5754e-04\n",
      "Epoch 1684/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5963.5696 - recon_loss: 3.9126e-04 - KL loss: 64.7484 - beta: 2.5754e-04 - val_loss: 6279.8110 - val_recon_loss: 4.1210e-04 - val_KL loss: 66.8823 - val_beta: 2.5754e-04\n",
      "Epoch 1685/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5739.0457 - recon_loss: 3.7621e-04 - KL loss: 67.1635 - beta: 2.5754e-04 - val_loss: 6700.9136 - val_recon_loss: 4.4000e-04 - val_KL loss: 67.2492 - val_beta: 2.5754e-04\n",
      "Epoch 1686/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5719.4462 - recon_loss: 3.7488e-04 - KL loss: 67.6146 - beta: 2.5754e-04\n",
      "Epoch 01686: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5719.4183 - recon_loss: 3.7488e-04 - KL loss: 67.6142 - beta: 2.5754e-04 - val_loss: 6449.7920 - val_recon_loss: 4.2346e-04 - val_KL loss: 65.6053 - val_beta: 2.5754e-04\n",
      "Epoch 1687/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5417.0373 - recon_loss: 3.5492e-04 - KL loss: 66.1817 - beta: 2.5754e-04 - val_loss: 5963.8149 - val_recon_loss: 3.9119e-04 - val_KL loss: 66.0820 - val_beta: 2.5754e-04\n",
      "Epoch 1688/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5342.6720 - recon_loss: 3.4990e-04 - KL loss: 67.4359 - beta: 2.5754e-04 - val_loss: 5706.6880 - val_recon_loss: 3.7413e-04 - val_KL loss: 66.1152 - val_beta: 2.5754e-04\n",
      "Epoch 1689/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5317.7088 - recon_loss: 3.4825e-04 - KL loss: 67.3369 - beta: 2.5754e-04 - val_loss: 5709.6265 - val_recon_loss: 3.7432e-04 - val_KL loss: 66.1836 - val_beta: 2.5754e-04\n",
      "Epoch 1690/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5260.2735 - recon_loss: 3.4450e-04 - KL loss: 66.4333 - beta: 2.5754e-04 - val_loss: 5849.3506 - val_recon_loss: 3.8382e-04 - val_KL loss: 62.7403 - val_beta: 2.5754e-04\n",
      "Epoch 1691/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5159.4501 - recon_loss: 3.3789e-04 - KL loss: 65.3010 - beta: 2.5754e-04 - val_loss: 6408.2134 - val_recon_loss: 4.2076e-04 - val_KL loss: 64.7157 - val_beta: 2.5754e-04\n",
      "Epoch 1692/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5179.3413 - recon_loss: 3.3919e-04 - KL loss: 65.6419 - beta: 2.5754e-04 - val_loss: 5832.6890 - val_recon_loss: 3.8246e-04 - val_KL loss: 66.6497 - val_beta: 2.5754e-04\n",
      "Epoch 1693/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5098.6879 - recon_loss: 3.3383e-04 - KL loss: 65.7675 - beta: 2.5754e-04\n",
      "Epoch 01693: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5098.6942 - recon_loss: 3.3383e-04 - KL loss: 65.7672 - beta: 2.5754e-04 - val_loss: 6168.1558 - val_recon_loss: 4.0483e-04 - val_KL loss: 64.7337 - val_beta: 2.5754e-04\n",
      "Epoch 1694/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5092.5023 - recon_loss: 3.3347e-04 - KL loss: 65.0596 - beta: 2.5754e-04 - val_loss: 6085.8076 - val_recon_loss: 3.9929e-04 - val_KL loss: 65.9405 - val_beta: 2.5754e-04\n",
      "Epoch 1695/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5041.6848 - recon_loss: 3.3009e-04 - KL loss: 65.0495 - beta: 2.5754e-04 - val_loss: 5800.1460 - val_recon_loss: 3.8045e-04 - val_KL loss: 64.3186 - val_beta: 2.5754e-04\n",
      "Epoch 1696/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5015.6913 - recon_loss: 3.2834e-04 - KL loss: 65.4784 - beta: 2.5754e-04 - val_loss: 5920.3003 - val_recon_loss: 3.8836e-04 - val_KL loss: 65.2372 - val_beta: 2.5754e-04\n",
      "Epoch 1697/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5009.5777 - recon_loss: 3.2793e-04 - KL loss: 65.6167 - beta: 2.5754e-04 - val_loss: 5746.0938 - val_recon_loss: 3.7673e-04 - val_KL loss: 66.4116 - val_beta: 2.5754e-04\n",
      "Epoch 1698/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 5026.7337 - recon_loss: 3.2904e-04 - KL loss: 65.9366 - beta: 2.5754e-04\n",
      "Epoch 01698: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5026.7636 - recon_loss: 3.2905e-04 - KL loss: 65.9367 - beta: 2.5754e-04 - val_loss: 5890.2412 - val_recon_loss: 3.8634e-04 - val_KL loss: 65.5903 - val_beta: 2.5754e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1698/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 11027.7267 - recon_loss: 3.8674e-04 - KL loss: 72.5482 - beta: 1.8789e-04 - val_loss: 11708.9922 - val_recon_loss: 4.1034e-04 - val_KL loss: 85.2820 - val_beta: 1.8789e-04\n",
      "Epoch 1699/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10453.2739 - recon_loss: 3.6598e-04 - KL loss: 86.2354 - beta: 1.8789e-04 - val_loss: 12050.0264 - val_recon_loss: 4.2233e-04 - val_KL loss: 86.8592 - val_beta: 1.8789e-04\n",
      "Epoch 1700/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10424.2698 - recon_loss: 3.6486e-04 - KL loss: 88.9874 - beta: 1.8789e-04 - val_loss: 10626.8730 - val_recon_loss: 3.7206e-04 - val_KL loss: 87.7337 - val_beta: 1.8789e-04\n",
      "Epoch 1701/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10481.3761 - recon_loss: 3.6674e-04 - KL loss: 92.7470 - beta: 1.8789e-04 - val_loss: 12272.2705 - val_recon_loss: 4.2979e-04 - val_KL loss: 97.5611 - val_beta: 1.8789e-04\n",
      "Epoch 1702/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11356.4387 - recon_loss: 3.9734e-04 - KL loss: 100.9167 - beta: 1.8789e-04 - val_loss: 13484.4629 - val_recon_loss: 4.7245e-04 - val_KL loss: 101.3239 - val_beta: 1.8789e-04\n",
      "Epoch 1703/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11004.7859 - recon_loss: 3.8489e-04 - KL loss: 102.2057 - beta: 1.8789e-04 - val_loss: 12889.0879 - val_recon_loss: 4.5145e-04 - val_KL loss: 101.0639 - val_beta: 1.8789e-04\n",
      "Epoch 1704/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10642.6003 - recon_loss: 3.7207e-04 - KL loss: 103.0220 - beta: 1.8789e-04 - val_loss: 12184.8398 - val_recon_loss: 4.2670e-04 - val_KL loss: 97.8685 - val_beta: 1.8789e-04\n",
      "Epoch 1705/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 10513.0558 - recon_loss: 3.6754e-04 - KL loss: 101.7262 - beta: 1.8789e-04\n",
      "Epoch 01705: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10513.2925 - recon_loss: 3.6755e-04 - KL loss: 101.7304 - beta: 1.8789e-04 - val_loss: 12559.5557 - val_recon_loss: 4.3984e-04 - val_KL loss: 100.3938 - val_beta: 1.8789e-04\n",
      "Epoch 1706/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10129.5276 - recon_loss: 3.5394e-04 - KL loss: 103.5372 - beta: 1.8789e-04 - val_loss: 11004.4746 - val_recon_loss: 3.8487e-04 - val_KL loss: 102.3485 - val_beta: 1.8789e-04\n",
      "Epoch 1707/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9800.4292 - recon_loss: 3.4231e-04 - KL loss: 103.8719 - beta: 1.8789e-04 - val_loss: 11296.0615 - val_recon_loss: 3.9519e-04 - val_KL loss: 101.6506 - val_beta: 1.8789e-04\n",
      "Epoch 1708/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 9586.1546 - recon_loss: 3.3476e-04 - KL loss: 103.4165 - beta: 1.8789e-04 - val_loss: 10989.0283 - val_recon_loss: 3.8436e-04 - val_KL loss: 101.3120 - val_beta: 1.8789e-04\n",
      "Epoch 1709/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 9543.5448 - recon_loss: 3.3327e-04 - KL loss: 102.9371 - beta: 1.8789e-04 - val_loss: 11377.2676 - val_recon_loss: 3.9808e-04 - val_KL loss: 100.8729 - val_beta: 1.8789e-04\n",
      "Epoch 1710/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9504.4984 - recon_loss: 3.3191e-04 - KL loss: 102.4828 - beta: 1.8789e-04\n",
      "Epoch 01710: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 9504.5789 - recon_loss: 3.3192e-04 - KL loss: 102.4831 - beta: 1.8789e-04 - val_loss: 11321.3555 - val_recon_loss: 3.9611e-04 - val_KL loss: 100.7246 - val_beta: 1.8789e-04\n",
      "Epoch 1710/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 19561.4858 - recon_loss: 3.6548e-04 - KL loss: 109.7234 - beta: 1.3707e-04 - val_loss: 21078.3496 - val_recon_loss: 3.9376e-04 - val_KL loss: 121.1840 - val_beta: 1.3707e-04\n",
      "Epoch 1711/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18891.1153 - recon_loss: 3.5261e-04 - KL loss: 124.4374 - beta: 1.3707e-04 - val_loss: 27855.1699 - val_recon_loss: 5.2074e-04 - val_KL loss: 140.0333 - val_beta: 1.3707e-04\n",
      "Epoch 1712/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 21035.2459 - recon_loss: 3.9257e-04 - KL loss: 141.6263 - beta: 1.3707e-04 - val_loss: 22541.7793 - val_recon_loss: 4.2104e-04 - val_KL loss: 132.7399 - val_beta: 1.3707e-04\n",
      "Epoch 1713/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 19268.3032 - recon_loss: 3.5936e-04 - KL loss: 141.8912 - beta: 1.3707e-04 - val_loss: 21384.1367 - val_recon_loss: 3.9928e-04 - val_KL loss: 133.5165 - val_beta: 1.3707e-04\n",
      "Epoch 1714/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18910.6009 - recon_loss: 3.5263e-04 - KL loss: 142.8010 - beta: 1.3707e-04 - val_loss: 21825.9180 - val_recon_loss: 4.0747e-04 - val_KL loss: 139.0968 - val_beta: 1.3707e-04\n",
      "Epoch 1715/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18295.0149 - recon_loss: 3.4109e-04 - KL loss: 141.0032 - beta: 1.3707e-04 - val_loss: 20620.8945 - val_recon_loss: 3.8490e-04 - val_KL loss: 135.6138 - val_beta: 1.3707e-04\n",
      "Epoch 1716/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18230.3615 - recon_loss: 3.3991e-04 - KL loss: 139.4891 - beta: 1.3707e-04 - val_loss: 23512.9551 - val_recon_loss: 4.3907e-04 - val_KL loss: 144.1313 - val_beta: 1.3707e-04\n",
      "Epoch 1717/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18663.3742 - recon_loss: 3.4794e-04 - KL loss: 145.0242 - beta: 1.3707e-04 - val_loss: 19619.5039 - val_recon_loss: 3.6598e-04 - val_KL loss: 141.0634 - val_beta: 1.3707e-04\n",
      "Epoch 1718/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18684.2389 - recon_loss: 3.4834e-04 - KL loss: 144.4648 - beta: 1.3707e-04 - val_loss: 21244.1348 - val_recon_loss: 3.9645e-04 - val_KL loss: 144.1529 - val_beta: 1.3707e-04\n",
      "Epoch 1719/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18453.9730 - recon_loss: 3.4399e-04 - KL loss: 145.6123 - beta: 1.3707e-04 - val_loss: 20194.7598 - val_recon_loss: 3.7672e-04 - val_KL loss: 144.6831 - val_beta: 1.3707e-04\n",
      "Epoch 1720/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18020.9188 - recon_loss: 3.3584e-04 - KL loss: 146.5161 - beta: 1.3707e-04 - val_loss: 19854.7168 - val_recon_loss: 3.7033e-04 - val_KL loss: 144.4138 - val_beta: 1.3707e-04\n",
      "Epoch 1721/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18032.1554 - recon_loss: 3.3613e-04 - KL loss: 142.3050 - beta: 1.3707e-04 - val_loss: 20714.2715 - val_recon_loss: 3.8648e-04 - val_KL loss: 144.7298 - val_beta: 1.3707e-04\n",
      "Epoch 1722/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18230.6187 - recon_loss: 3.3967e-04 - KL loss: 152.4966 - beta: 1.3707e-04\n",
      "Epoch 01722: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18230.8015 - recon_loss: 3.3967e-04 - KL loss: 152.4973 - beta: 1.3707e-04 - val_loss: 19829.0645 - val_recon_loss: 3.6980e-04 - val_KL loss: 147.3610 - val_beta: 1.3707e-04\n",
      "Epoch 1723/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17267.0896 - recon_loss: 3.2165e-04 - KL loss: 148.1643 - beta: 1.3707e-04 - val_loss: 18558.8711 - val_recon_loss: 3.4592e-04 - val_KL loss: 147.8773 - val_beta: 1.3707e-04\n",
      "Epoch 1724/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17214.6908 - recon_loss: 3.2064e-04 - KL loss: 149.1101 - beta: 1.3707e-04 - val_loss: 19626.4629 - val_recon_loss: 3.6592e-04 - val_KL loss: 151.3737 - val_beta: 1.3707e-04\n",
      "Epoch 1725/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 16873.1869 - recon_loss: 3.1417e-04 - KL loss: 152.3784 - beta: 1.3707e-04 - val_loss: 20116.4023 - val_recon_loss: 3.7524e-04 - val_KL loss: 144.8273 - val_beta: 1.3707e-04\n",
      "Epoch 1726/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 16585.8314 - recon_loss: 3.0883e-04 - KL loss: 149.0229 - beta: 1.3707e-04 - val_loss: 20004.7246 - val_recon_loss: 3.7308e-04 - val_KL loss: 148.4634 - val_beta: 1.3707e-04\n",
      "Epoch 1727/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 16714.3134 - recon_loss: 3.1122e-04 - KL loss: 150.0696 - beta: 1.3707e-04 - val_loss: 18095.4648 - val_recon_loss: 3.3722e-04 - val_KL loss: 147.5736 - val_beta: 1.3707e-04\n",
      "Epoch 1728/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 16814.2925 - recon_loss: 3.1312e-04 - KL loss: 149.1771 - beta: 1.3707e-04 - val_loss: 18371.3066 - val_recon_loss: 3.4243e-04 - val_KL loss: 146.0820 - val_beta: 1.3707e-04\n",
      "Epoch 1729/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 16880.4107 - recon_loss: 3.1438e-04 - KL loss: 148.3050 - beta: 1.3707e-04 - val_loss: 17888.1406 - val_recon_loss: 3.3332e-04 - val_KL loss: 148.0946 - val_beta: 1.3707e-04\n",
      "Epoch 1730/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 16790.7591 - recon_loss: 3.1266e-04 - KL loss: 149.9831 - beta: 1.3707e-04 - val_loss: 18084.1152 - val_recon_loss: 3.3702e-04 - val_KL loss: 146.9666 - val_beta: 1.3707e-04\n",
      "Epoch 1731/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 16644.2597 - recon_loss: 3.0992e-04 - KL loss: 149.6402 - beta: 1.3707e-04 - val_loss: 17898.2773 - val_recon_loss: 3.3347e-04 - val_KL loss: 150.2476 - val_beta: 1.3707e-04\n",
      "Epoch 1732/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 16799.9513 - recon_loss: 3.1281e-04 - KL loss: 151.1317 - beta: 1.3707e-04 - val_loss: 18051.9160 - val_recon_loss: 3.3641e-04 - val_KL loss: 147.1550 - val_beta: 1.3707e-04\n",
      "Epoch 1733/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 16461.7870 - recon_loss: 3.0644e-04 - KL loss: 152.3585 - beta: 1.3707e-04 - val_loss: 18835.0410 - val_recon_loss: 3.5110e-04 - val_KL loss: 148.3992 - val_beta: 1.3707e-04\n",
      "Epoch 1734/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 16552.6026 - recon_loss: 3.0813e-04 - KL loss: 152.7524 - beta: 1.3707e-04\n",
      "Epoch 01734: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 16552.3870 - recon_loss: 3.0813e-04 - KL loss: 152.7523 - beta: 1.3707e-04 - val_loss: 18906.7656 - val_recon_loss: 3.5244e-04 - val_KL loss: 148.8062 - val_beta: 1.3707e-04\n",
      "Epoch 1735/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 16016.5683 - recon_loss: 2.9808e-04 - KL loss: 151.7243 - beta: 1.3707e-04 - val_loss: 18066.3516 - val_recon_loss: 3.3666e-04 - val_KL loss: 148.5285 - val_beta: 1.3707e-04\n",
      "Epoch 1736/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 16094.9354 - recon_loss: 2.9953e-04 - KL loss: 152.8048 - beta: 1.3707e-04 - val_loss: 17732.1035 - val_recon_loss: 3.3034e-04 - val_KL loss: 150.6199 - val_beta: 1.3707e-04\n",
      "Epoch 1737/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 16090.0898 - recon_loss: 2.9944e-04 - KL loss: 153.2708 - beta: 1.3707e-04 - val_loss: 18252.1055 - val_recon_loss: 3.4007e-04 - val_KL loss: 152.6381 - val_beta: 1.3707e-04\n",
      "Epoch 1738/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 16145.3100 - recon_loss: 3.0045e-04 - KL loss: 154.6297 - beta: 1.3707e-04 - val_loss: 18108.1328 - val_recon_loss: 3.3737e-04 - val_KL loss: 152.1960 - val_beta: 1.3707e-04\n",
      "Epoch 1739/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 16049.1642 - recon_loss: 2.9865e-04 - KL loss: 154.3336 - beta: 1.3707e-04 - val_loss: 18301.0352 - val_recon_loss: 3.4101e-04 - val_KL loss: 151.6493 - val_beta: 1.3707e-04\n",
      "Epoch 1740/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 15898.9399 - recon_loss: 2.9583e-04 - KL loss: 154.1374 - beta: 1.3707e-04 - val_loss: 18011.0469 - val_recon_loss: 3.3554e-04 - val_KL loss: 152.4461 - val_beta: 1.3707e-04\n",
      "Epoch 1741/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 15913.0323 - recon_loss: 2.9608e-04 - KL loss: 155.0149 - beta: 1.3707e-04\n",
      "Epoch 01741: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15913.1155 - recon_loss: 2.9608e-04 - KL loss: 155.0147 - beta: 1.3707e-04 - val_loss: 17928.8047 - val_recon_loss: 3.3398e-04 - val_KL loss: 153.6408 - val_beta: 1.3707e-04\n",
      "Epoch 1742/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15808.8657 - recon_loss: 2.9411e-04 - KL loss: 155.5816 - beta: 1.3707e-04 - val_loss: 17943.8379 - val_recon_loss: 3.3425e-04 - val_KL loss: 154.2283 - val_beta: 1.3707e-04\n",
      "Epoch 1743/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15857.6828 - recon_loss: 2.9502e-04 - KL loss: 155.9083 - beta: 1.3707e-04 - val_loss: 17986.9961 - val_recon_loss: 3.3506e-04 - val_KL loss: 153.9898 - val_beta: 1.3707e-04\n",
      "Epoch 1744/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 15734.8447 - recon_loss: 2.9272e-04 - KL loss: 155.2465 - beta: 1.3707e-04 - val_loss: 17752.8477 - val_recon_loss: 3.3065e-04 - val_KL loss: 154.6731 - val_beta: 1.3707e-04\n",
      "Epoch 1745/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15849.6019 - recon_loss: 2.9487e-04 - KL loss: 155.5597 - beta: 1.3707e-04 - val_loss: 18234.2480 - val_recon_loss: 3.3971e-04 - val_KL loss: 153.7423 - val_beta: 1.3707e-04\n",
      "Epoch 1746/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 15834.8549 - recon_loss: 2.9460e-04 - KL loss: 155.4071 - beta: 1.3707e-04\n",
      "Epoch 01746: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 15834.7841 - recon_loss: 2.9460e-04 - KL loss: 155.4070 - beta: 1.3707e-04 - val_loss: 17852.6973 - val_recon_loss: 3.3255e-04 - val_KL loss: 153.2924 - val_beta: 1.3707e-04\n",
      "Epoch 1746/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 35370.7115 - recon_loss: 3.5205e-04 - KL loss: 165.8553 - beta: 1.0000e-04 - val_loss: 35247.8164 - val_recon_loss: 3.5075e-04 - val_KL loss: 172.8070 - val_beta: 1.0000e-04\n",
      "Epoch 1747/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 33471.9597 - recon_loss: 3.3293e-04 - KL loss: 178.5899 - beta: 1.0000e-04 - val_loss: 33302.9258 - val_recon_loss: 3.3122e-04 - val_KL loss: 180.5993 - val_beta: 1.0000e-04\n",
      "Epoch 1748/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 32765.1699 - recon_loss: 3.2584e-04 - KL loss: 180.8753 - beta: 1.0000e-04 - val_loss: 35481.0664 - val_recon_loss: 3.5293e-04 - val_KL loss: 187.8756 - val_beta: 1.0000e-04\n",
      "Epoch 1749/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36575.3952 - recon_loss: 3.6370e-04 - KL loss: 205.2480 - beta: 1.0000e-04 - val_loss: 35399.2109 - val_recon_loss: 3.5199e-04 - val_KL loss: 200.6747 - val_beta: 1.0000e-04\n",
      "Epoch 1750/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33700.5673 - recon_loss: 3.3490e-04 - KL loss: 211.0003 - beta: 1.0000e-04 - val_loss: 37819.6758 - val_recon_loss: 3.7614e-04 - val_KL loss: 205.1904 - val_beta: 1.0000e-04\n",
      "Epoch 1751/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32487.3155 - recon_loss: 3.2277e-04 - KL loss: 210.4266 - beta: 1.0000e-04 - val_loss: 33160.7617 - val_recon_loss: 3.2962e-04 - val_KL loss: 199.1423 - val_beta: 1.0000e-04\n",
      "Epoch 1752/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 31861.6729 - recon_loss: 3.1655e-04 - KL loss: 206.4606 - beta: 1.0000e-04 - val_loss: 34774.7812 - val_recon_loss: 3.4572e-04 - val_KL loss: 202.5880 - val_beta: 1.0000e-04\n",
      "Epoch 1753/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 32403.8871 - recon_loss: 3.2198e-04 - KL loss: 205.4487 - beta: 1.0000e-04 - val_loss: 38145.6484 - val_recon_loss: 3.7947e-04 - val_KL loss: 198.8275 - val_beta: 1.0000e-04\n",
      "Epoch 1754/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 31708.6362 - recon_loss: 3.1505e-04 - KL loss: 203.8023 - beta: 1.0000e-04 - val_loss: 33439.2266 - val_recon_loss: 3.3234e-04 - val_KL loss: 205.2681 - val_beta: 1.0000e-04\n",
      "Epoch 1755/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32275.3648 - recon_loss: 3.2063e-04 - KL loss: 211.9314 - beta: 1.0000e-04 - val_loss: 34611.1484 - val_recon_loss: 3.4406e-04 - val_KL loss: 205.0559 - val_beta: 1.0000e-04\n",
      "Epoch 1756/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 32410.6088 - recon_loss: 3.2200e-04 - KL loss: 210.1890 - beta: 1.0000e-04\n",
      "Epoch 01756: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 32410.4209 - recon_loss: 3.2200e-04 - KL loss: 210.1917 - beta: 1.0000e-04 - val_loss: 51501.9180 - val_recon_loss: 5.1278e-04 - val_KL loss: 223.4740 - val_beta: 1.0000e-04\n",
      "Epoch 1757/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 33967.9607 - recon_loss: 3.3741e-04 - KL loss: 227.0690 - beta: 1.0000e-04 - val_loss: 34950.2148 - val_recon_loss: 3.4730e-04 - val_KL loss: 220.3421 - val_beta: 1.0000e-04\n",
      "Epoch 1758/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 30449.4449 - recon_loss: 3.0223e-04 - KL loss: 226.5954 - beta: 1.0000e-04 - val_loss: 34749.8594 - val_recon_loss: 3.4532e-04 - val_KL loss: 217.7079 - val_beta: 1.0000e-04\n",
      "Epoch 1759/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 29845.2983 - recon_loss: 2.9624e-04 - KL loss: 221.0901 - beta: 1.0000e-04 - val_loss: 31941.6211 - val_recon_loss: 3.1729e-04 - val_KL loss: 212.6849 - val_beta: 1.0000e-04\n",
      "Epoch 1760/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 29635.2008 - recon_loss: 2.9416e-04 - KL loss: 219.3282 - beta: 1.0000e-04 - val_loss: 30819.6699 - val_recon_loss: 3.0603e-04 - val_KL loss: 216.4941 - val_beta: 1.0000e-04\n",
      "Epoch 1761/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 29167.0841 - recon_loss: 2.8947e-04 - KL loss: 219.8965 - beta: 1.0000e-04 - val_loss: 33376.7578 - val_recon_loss: 3.3159e-04 - val_KL loss: 218.0643 - val_beta: 1.0000e-04\n",
      "Epoch 1762/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 29459.0362 - recon_loss: 2.9239e-04 - KL loss: 219.8127 - beta: 1.0000e-04 - val_loss: 32699.7090 - val_recon_loss: 3.2480e-04 - val_KL loss: 220.0965 - val_beta: 1.0000e-04\n",
      "Epoch 1763/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 29112.4513 - recon_loss: 2.8891e-04 - KL loss: 221.5614 - beta: 1.0000e-04 - val_loss: 31514.5352 - val_recon_loss: 3.1293e-04 - val_KL loss: 221.9997 - val_beta: 1.0000e-04\n",
      "Epoch 1764/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 29554.3073 - recon_loss: 2.9330e-04 - KL loss: 224.0865 - beta: 1.0000e-04 - val_loss: 32410.6953 - val_recon_loss: 3.2187e-04 - val_KL loss: 223.3112 - val_beta: 1.0000e-04\n",
      "Epoch 1765/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 30243.6999 - recon_loss: 3.0017e-04 - KL loss: 226.6243 - beta: 1.0000e-04\n",
      "Epoch 01765: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 30243.5391 - recon_loss: 3.0017e-04 - KL loss: 226.6232 - beta: 1.0000e-04 - val_loss: 31384.1914 - val_recon_loss: 3.1166e-04 - val_KL loss: 218.1792 - val_beta: 1.0000e-04\n",
      "Epoch 1766/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 29020.9049 - recon_loss: 2.8800e-04 - KL loss: 221.1280 - beta: 1.0000e-04 - val_loss: 31030.1973 - val_recon_loss: 3.0807e-04 - val_KL loss: 222.7322 - val_beta: 1.0000e-04\n",
      "Epoch 1767/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28898.5613 - recon_loss: 2.8674e-04 - KL loss: 224.7860 - beta: 1.0000e-04 - val_loss: 30546.6641 - val_recon_loss: 3.0324e-04 - val_KL loss: 222.4844 - val_beta: 1.0000e-04\n",
      "Epoch 1768/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 28701.0609 - recon_loss: 2.8476e-04 - KL loss: 224.7787 - beta: 1.0000e-04 - val_loss: 30676.3555 - val_recon_loss: 3.0452e-04 - val_KL loss: 224.0485 - val_beta: 1.0000e-04\n",
      "Epoch 1769/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 29104.1228 - recon_loss: 2.8879e-04 - KL loss: 225.3179 - beta: 1.0000e-04 - val_loss: 30517.0781 - val_recon_loss: 3.0293e-04 - val_KL loss: 224.2696 - val_beta: 1.0000e-04\n",
      "Epoch 1770/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 28811.4964 - recon_loss: 2.8585e-04 - KL loss: 226.3222 - beta: 1.0000e-04 - val_loss: 30769.5176 - val_recon_loss: 3.0544e-04 - val_KL loss: 225.7168 - val_beta: 1.0000e-04\n",
      "Epoch 1771/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 28676.9269 - recon_loss: 2.8450e-04 - KL loss: 227.2447 - beta: 1.0000e-04 - val_loss: 30372.3672 - val_recon_loss: 3.0151e-04 - val_KL loss: 221.3345 - val_beta: 1.0000e-04\n",
      "Epoch 1772/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28503.5124 - recon_loss: 2.8279e-04 - KL loss: 224.3679 - beta: 1.0000e-04 - val_loss: 30361.3203 - val_recon_loss: 3.0140e-04 - val_KL loss: 221.7987 - val_beta: 1.0000e-04\n",
      "Epoch 1773/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28653.1403 - recon_loss: 2.8427e-04 - KL loss: 226.1778 - beta: 1.0000e-04 - val_loss: 31501.6680 - val_recon_loss: 3.1278e-04 - val_KL loss: 223.2600 - val_beta: 1.0000e-04\n",
      "Epoch 1774/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 28484.5091 - recon_loss: 2.8259e-04 - KL loss: 225.1942 - beta: 1.0000e-04 - val_loss: 30497.3223 - val_recon_loss: 3.0273e-04 - val_KL loss: 224.7315 - val_beta: 1.0000e-04\n",
      "Epoch 1775/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 28612.1377 - recon_loss: 2.8385e-04 - KL loss: 227.1725 - beta: 1.0000e-04 - val_loss: 29982.5059 - val_recon_loss: 2.9757e-04 - val_KL loss: 225.2373 - val_beta: 1.0000e-04\n",
      "Epoch 1776/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 28597.6479 - recon_loss: 2.8370e-04 - KL loss: 227.3786 - beta: 1.0000e-04 - val_loss: 29760.6973 - val_recon_loss: 2.9535e-04 - val_KL loss: 225.4557 - val_beta: 1.0000e-04\n",
      "Epoch 1777/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28399.5613 - recon_loss: 2.8171e-04 - KL loss: 228.2166 - beta: 1.0000e-04 - val_loss: 30065.7539 - val_recon_loss: 2.9838e-04 - val_KL loss: 227.7384 - val_beta: 1.0000e-04\n",
      "Epoch 1778/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28298.6916 - recon_loss: 2.8070e-04 - KL loss: 229.1836 - beta: 1.0000e-04 - val_loss: 29529.0371 - val_recon_loss: 2.9303e-04 - val_KL loss: 226.4747 - val_beta: 1.0000e-04\n",
      "Epoch 1779/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 28459.5971 - recon_loss: 2.8231e-04 - KL loss: 229.0771 - beta: 1.0000e-04 - val_loss: 29949.0059 - val_recon_loss: 2.9722e-04 - val_KL loss: 227.1821 - val_beta: 1.0000e-04\n",
      "Epoch 1780/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 28204.2301 - recon_loss: 2.7975e-04 - KL loss: 229.4845 - beta: 1.0000e-04 - val_loss: 30081.5137 - val_recon_loss: 2.9853e-04 - val_KL loss: 228.4899 - val_beta: 1.0000e-04\n",
      "Epoch 1781/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 28375.9792 - recon_loss: 2.8147e-04 - KL loss: 229.4655 - beta: 1.0000e-04 - val_loss: 32130.7520 - val_recon_loss: 3.1904e-04 - val_KL loss: 226.3732 - val_beta: 1.0000e-04\n",
      "Epoch 1782/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 28435.2183 - recon_loss: 2.8206e-04 - KL loss: 229.4786 - beta: 1.0000e-04 - val_loss: 31325.6270 - val_recon_loss: 3.1098e-04 - val_KL loss: 227.9552 - val_beta: 1.0000e-04\n",
      "Epoch 1783/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 28544.0329 - recon_loss: 2.8314e-04 - KL loss: 230.0707 - beta: 1.0000e-04\n",
      "Epoch 01783: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28544.0070 - recon_loss: 2.8314e-04 - KL loss: 230.0688 - beta: 1.0000e-04 - val_loss: 32224.6914 - val_recon_loss: 3.1998e-04 - val_KL loss: 226.3410 - val_beta: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1784/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 28304.6433 - recon_loss: 2.8075e-04 - KL loss: 229.7491 - beta: 1.0000e-04 - val_loss: 31641.1621 - val_recon_loss: 3.1414e-04 - val_KL loss: 227.1078 - val_beta: 1.0000e-04\n",
      "Epoch 1785/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 28305.6721 - recon_loss: 2.8076e-04 - KL loss: 230.0474 - beta: 1.0000e-04 - val_loss: 31257.4707 - val_recon_loss: 3.1031e-04 - val_KL loss: 226.6351 - val_beta: 1.0000e-04\n",
      "Epoch 1786/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 28180.5451 - recon_loss: 2.7950e-04 - KL loss: 230.1514 - beta: 1.0000e-04 - val_loss: 31255.8262 - val_recon_loss: 3.1029e-04 - val_KL loss: 227.1339 - val_beta: 1.0000e-04\n",
      "Epoch 1787/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 27978.7635 - recon_loss: 2.7748e-04 - KL loss: 230.4532 - beta: 1.0000e-04 - val_loss: 31161.2480 - val_recon_loss: 3.0934e-04 - val_KL loss: 227.0728 - val_beta: 1.0000e-04\n",
      "Epoch 1788/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 27860.0397 - recon_loss: 2.7630e-04 - KL loss: 230.1846 - beta: 1.0000e-04\n",
      "Epoch 01788: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 27860.1755 - recon_loss: 2.7630e-04 - KL loss: 230.1851 - beta: 1.0000e-04 - val_loss: 30981.3301 - val_recon_loss: 3.0753e-04 - val_KL loss: 228.2623 - val_beta: 1.0000e-04\n",
      "Epoch 1788/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20330.4961 - recon_loss: 3.0401e-04 - KL loss: 219.3497 - beta: 1.2295e-04 - val_loss: 22579.7090 - val_recon_loss: 3.3827e-04 - val_KL loss: 202.4194 - val_beta: 1.2295e-04\n",
      "Epoch 1789/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20197.1127 - recon_loss: 3.0223e-04 - KL loss: 203.9080 - beta: 1.2295e-04 - val_loss: 20414.7949 - val_recon_loss: 3.0560e-04 - val_KL loss: 198.2832 - val_beta: 1.2295e-04\n",
      "Epoch 1790/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20339.1071 - recon_loss: 3.0443e-04 - KL loss: 200.1799 - beta: 1.2295e-04 - val_loss: 20729.0859 - val_recon_loss: 3.1036e-04 - val_KL loss: 197.9292 - val_beta: 1.2295e-04\n",
      "Epoch 1791/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20601.2596 - recon_loss: 3.0837e-04 - KL loss: 201.9955 - beta: 1.2295e-04 - val_loss: 20206.0664 - val_recon_loss: 3.0252e-04 - val_KL loss: 193.5339 - val_beta: 1.2295e-04\n",
      "Epoch 1792/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20176.6185 - recon_loss: 3.0204e-04 - KL loss: 196.1785 - beta: 1.2295e-04 - val_loss: 20823.4141 - val_recon_loss: 3.1185e-04 - val_KL loss: 193.7257 - val_beta: 1.2295e-04\n",
      "Epoch 1793/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20602.2264 - recon_loss: 3.0842e-04 - KL loss: 199.4765 - beta: 1.2295e-04 - val_loss: 20787.6426 - val_recon_loss: 3.1120e-04 - val_KL loss: 200.8287 - val_beta: 1.2295e-04\n",
      "Epoch 1794/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20039.1065 - recon_loss: 2.9988e-04 - KL loss: 201.2610 - beta: 1.2295e-04 - val_loss: 19982.6055 - val_recon_loss: 2.9910e-04 - val_KL loss: 196.3543 - val_beta: 1.2295e-04\n",
      "Epoch 1795/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20124.0214 - recon_loss: 3.0120e-04 - KL loss: 198.5252 - beta: 1.2295e-04 - val_loss: 22696.6719 - val_recon_loss: 3.4002e-04 - val_KL loss: 203.2783 - val_beta: 1.2295e-04\n",
      "Epoch 1796/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20978.9492 - recon_loss: 3.1400e-04 - KL loss: 206.9253 - beta: 1.2295e-04 - val_loss: 23209.3516 - val_recon_loss: 3.4777e-04 - val_KL loss: 203.6414 - val_beta: 1.2295e-04\n",
      "Epoch 1797/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 20954.3874 - recon_loss: 3.1363e-04 - KL loss: 206.6221 - beta: 1.2295e-04 - val_loss: 22447.9844 - val_recon_loss: 3.3630e-04 - val_KL loss: 200.8716 - val_beta: 1.2295e-04\n",
      "Epoch 1798/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 21315.1013 - recon_loss: 3.1907e-04 - KL loss: 207.8174 - beta: 1.2295e-04 - val_loss: 22507.2480 - val_recon_loss: 3.3720e-04 - val_KL loss: 200.3597 - val_beta: 1.2295e-04\n",
      "Epoch 1799/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 20556.7311 - recon_loss: 3.0769e-04 - KL loss: 202.4525 - beta: 1.2295e-04\n",
      "Epoch 01799: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 20557.1933 - recon_loss: 3.0769e-04 - KL loss: 202.4609 - beta: 1.2295e-04 - val_loss: 21023.8066 - val_recon_loss: 3.1466e-04 - val_KL loss: 208.1478 - val_beta: 1.2295e-04\n",
      "Epoch 1800/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 20055.0962 - recon_loss: 2.9994e-04 - KL loss: 213.5603 - beta: 1.2295e-04 - val_loss: 21110.5410 - val_recon_loss: 3.1600e-04 - val_KL loss: 206.0141 - val_beta: 1.2295e-04\n",
      "Epoch 1801/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 19507.0671 - recon_loss: 2.9172e-04 - KL loss: 209.2857 - beta: 1.2295e-04 - val_loss: 22058.1191 - val_recon_loss: 3.3033e-04 - val_KL loss: 205.8050 - val_beta: 1.2295e-04\n",
      "Epoch 1802/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 19137.2861 - recon_loss: 2.8611e-04 - KL loss: 210.4834 - beta: 1.2295e-04 - val_loss: 21657.7070 - val_recon_loss: 3.2435e-04 - val_KL loss: 201.3441 - val_beta: 1.2295e-04\n",
      "Epoch 1803/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18677.4994 - recon_loss: 2.7919e-04 - KL loss: 208.5596 - beta: 1.2295e-04 - val_loss: 19907.0508 - val_recon_loss: 2.9782e-04 - val_KL loss: 205.4926 - val_beta: 1.2295e-04\n",
      "Epoch 1804/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18687.5800 - recon_loss: 2.7933e-04 - KL loss: 209.3637 - beta: 1.2295e-04 - val_loss: 19689.0332 - val_recon_loss: 2.9451e-04 - val_KL loss: 206.4812 - val_beta: 1.2295e-04\n",
      "Epoch 1805/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18651.2911 - recon_loss: 2.7880e-04 - KL loss: 207.7533 - beta: 1.2295e-04 - val_loss: 19970.6641 - val_recon_loss: 2.9882e-04 - val_KL loss: 202.7832 - val_beta: 1.2295e-04\n",
      "Epoch 1806/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18461.3396 - recon_loss: 2.7592e-04 - KL loss: 208.7222 - beta: 1.2295e-04 - val_loss: 18966.4590 - val_recon_loss: 2.8361e-04 - val_KL loss: 204.5995 - val_beta: 1.2295e-04\n",
      "Epoch 1807/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18570.5441 - recon_loss: 2.7757e-04 - KL loss: 208.3701 - beta: 1.2295e-04 - val_loss: 19151.3965 - val_recon_loss: 2.8639e-04 - val_KL loss: 205.6825 - val_beta: 1.2295e-04\n",
      "Epoch 1808/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18383.8950 - recon_loss: 2.7477e-04 - KL loss: 207.4302 - beta: 1.2295e-04 - val_loss: 19158.1797 - val_recon_loss: 2.8651e-04 - val_KL loss: 204.6935 - val_beta: 1.2295e-04\n",
      "Epoch 1809/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18616.3343 - recon_loss: 2.7825e-04 - KL loss: 209.4328 - beta: 1.2295e-04 - val_loss: 18821.3359 - val_recon_loss: 2.8143e-04 - val_KL loss: 204.1507 - val_beta: 1.2295e-04\n",
      "Epoch 1810/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18051.5208 - recon_loss: 2.6974e-04 - KL loss: 207.1945 - beta: 1.2295e-04 - val_loss: 18479.0898 - val_recon_loss: 2.7624e-04 - val_KL loss: 205.0397 - val_beta: 1.2295e-04\n",
      "Epoch 1811/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17861.8305 - recon_loss: 2.6685e-04 - KL loss: 208.9381 - beta: 1.2295e-04 - val_loss: 19157.8926 - val_recon_loss: 2.8649e-04 - val_KL loss: 206.0759 - val_beta: 1.2295e-04\n",
      "Epoch 1812/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18106.0924 - recon_loss: 2.7055e-04 - KL loss: 208.4135 - beta: 1.2295e-04 - val_loss: 18494.4102 - val_recon_loss: 2.7646e-04 - val_KL loss: 205.8059 - val_beta: 1.2295e-04\n",
      "Epoch 1813/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 18230.6037 - recon_loss: 2.7239e-04 - KL loss: 211.0049 - beta: 1.2295e-04 - val_loss: 18650.3711 - val_recon_loss: 2.7875e-04 - val_KL loss: 210.6236 - val_beta: 1.2295e-04\n",
      "Epoch 1814/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18394.1817 - recon_loss: 2.7486e-04 - KL loss: 211.5954 - beta: 1.2295e-04 - val_loss: 19971.0547 - val_recon_loss: 2.9875e-04 - val_KL loss: 207.7012 - val_beta: 1.2295e-04\n",
      "Epoch 1815/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18401.6605 - recon_loss: 2.7499e-04 - KL loss: 210.1903 - beta: 1.2295e-04\n",
      "Epoch 01815: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 18401.5623 - recon_loss: 2.7499e-04 - KL loss: 210.1895 - beta: 1.2295e-04 - val_loss: 19215.8594 - val_recon_loss: 2.8739e-04 - val_KL loss: 204.1864 - val_beta: 1.2295e-04\n",
      "Epoch 1816/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17948.6209 - recon_loss: 2.6815e-04 - KL loss: 209.8403 - beta: 1.2295e-04 - val_loss: 18683.6621 - val_recon_loss: 2.7927e-04 - val_KL loss: 209.1973 - val_beta: 1.2295e-04\n",
      "Epoch 1817/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17743.3569 - recon_loss: 2.6501e-04 - KL loss: 211.9361 - beta: 1.2295e-04 - val_loss: 18872.5430 - val_recon_loss: 2.8211e-04 - val_KL loss: 210.5047 - val_beta: 1.2295e-04\n",
      "Epoch 1818/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17649.8462 - recon_loss: 2.6359e-04 - KL loss: 212.7398 - beta: 1.2295e-04 - val_loss: 18367.4199 - val_recon_loss: 2.7449e-04 - val_KL loss: 209.1320 - val_beta: 1.2295e-04\n",
      "Epoch 1819/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17820.4182 - recon_loss: 2.6617e-04 - KL loss: 212.2309 - beta: 1.2295e-04 - val_loss: 18692.7695 - val_recon_loss: 2.7938e-04 - val_KL loss: 210.7805 - val_beta: 1.2295e-04\n",
      "Epoch 1820/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17645.2458 - recon_loss: 2.6350e-04 - KL loss: 214.2131 - beta: 1.2295e-04 - val_loss: 18758.1152 - val_recon_loss: 2.8035e-04 - val_KL loss: 212.2145 - val_beta: 1.2295e-04\n",
      "Epoch 1821/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17747.3327 - recon_loss: 2.6503e-04 - KL loss: 214.7901 - beta: 1.2295e-04 - val_loss: 18501.7031 - val_recon_loss: 2.7650e-04 - val_KL loss: 210.6937 - val_beta: 1.2295e-04\n",
      "Epoch 1822/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17588.7374 - recon_loss: 2.6265e-04 - KL loss: 213.8670 - beta: 1.2295e-04 - val_loss: 18324.7891 - val_recon_loss: 2.7384e-04 - val_KL loss: 209.4439 - val_beta: 1.2295e-04\n",
      "Epoch 1823/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17581.3614 - recon_loss: 2.6254e-04 - KL loss: 213.3888 - beta: 1.2295e-04 - val_loss: 18577.8711 - val_recon_loss: 2.7766e-04 - val_KL loss: 209.7419 - val_beta: 1.2295e-04\n",
      "Epoch 1824/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17660.7600 - recon_loss: 2.6375e-04 - KL loss: 213.1248 - beta: 1.2295e-04 - val_loss: 17847.3789 - val_recon_loss: 2.6660e-04 - val_KL loss: 210.7614 - val_beta: 1.2295e-04\n",
      "Epoch 1825/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17752.1018 - recon_loss: 2.6510e-04 - KL loss: 214.7719 - beta: 1.2295e-04 - val_loss: 18105.5391 - val_recon_loss: 2.7050e-04 - val_KL loss: 210.9467 - val_beta: 1.2295e-04\n",
      "Epoch 1826/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17544.5963 - recon_loss: 2.6199e-04 - KL loss: 213.3947 - beta: 1.2295e-04 - val_loss: 17980.3672 - val_recon_loss: 2.6860e-04 - val_KL loss: 212.0083 - val_beta: 1.2295e-04\n",
      "Epoch 1827/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17466.2857 - recon_loss: 2.6079e-04 - KL loss: 214.3415 - beta: 1.2295e-04 - val_loss: 18014.6543 - val_recon_loss: 2.6913e-04 - val_KL loss: 210.9247 - val_beta: 1.2295e-04\n",
      "Epoch 1828/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17474.5123 - recon_loss: 2.6093e-04 - KL loss: 213.5501 - beta: 1.2295e-04 - val_loss: 18261.5332 - val_recon_loss: 2.7286e-04 - val_KL loss: 211.3443 - val_beta: 1.2295e-04\n",
      "Epoch 1829/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 17436.1078 - recon_loss: 2.6034e-04 - KL loss: 213.9903 - beta: 1.2295e-04\n",
      "Epoch 01829: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 17436.0451 - recon_loss: 2.6034e-04 - KL loss: 213.9892 - beta: 1.2295e-04 - val_loss: 18231.3242 - val_recon_loss: 2.7239e-04 - val_KL loss: 211.9789 - val_beta: 1.2295e-04\n",
      "Epoch 1830/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 17323.1041 - recon_loss: 2.5863e-04 - KL loss: 214.3202 - beta: 1.2295e-04 - val_loss: 17947.9609 - val_recon_loss: 2.6809e-04 - val_KL loss: 213.1501 - val_beta: 1.2295e-04\n",
      "Epoch 1831/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17352.6763 - recon_loss: 2.5906e-04 - KL loss: 214.9413 - beta: 1.2295e-04 - val_loss: 17946.5215 - val_recon_loss: 2.6808e-04 - val_KL loss: 211.9725 - val_beta: 1.2295e-04\n",
      "Epoch 1832/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17343.6147 - recon_loss: 2.5894e-04 - KL loss: 214.1106 - beta: 1.2295e-04 - val_loss: 18019.6348 - val_recon_loss: 2.6919e-04 - val_KL loss: 211.8453 - val_beta: 1.2295e-04\n",
      "Epoch 1833/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17315.2347 - recon_loss: 2.5851e-04 - KL loss: 214.0817 - beta: 1.2295e-04 - val_loss: 18030.9785 - val_recon_loss: 2.6937e-04 - val_KL loss: 211.7401 - val_beta: 1.2295e-04\n",
      "Epoch 1834/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17456.4878 - recon_loss: 2.6064e-04 - KL loss: 214.6758 - beta: 1.2295e-04\n",
      "Epoch 01834: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 17456.4403 - recon_loss: 2.6064e-04 - KL loss: 214.6756 - beta: 1.2295e-04 - val_loss: 18671.4434 - val_recon_loss: 2.7904e-04 - val_KL loss: 212.0029 - val_beta: 1.2295e-04\n",
      "Epoch 1834/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12778.6613 - recon_loss: 2.8737e-04 - KL loss: 203.0048 - beta: 1.5117e-04 - val_loss: 13177.0371 - val_recon_loss: 2.9678e-04 - val_KL loss: 189.5685 - val_beta: 1.5117e-04\n",
      "Epoch 1835/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13019.2310 - recon_loss: 2.9306e-04 - KL loss: 194.4332 - beta: 1.5117e-04 - val_loss: 14506.7578 - val_recon_loss: 3.2691e-04 - val_KL loss: 200.5328 - val_beta: 1.5117e-04\n",
      "Epoch 1836/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13390.9963 - recon_loss: 3.0140e-04 - KL loss: 201.3259 - beta: 1.5117e-04 - val_loss: 14044.1602 - val_recon_loss: 3.1663e-04 - val_KL loss: 188.0728 - val_beta: 1.5117e-04\n",
      "Epoch 1837/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13189.8917 - recon_loss: 2.9702e-04 - KL loss: 191.7228 - beta: 1.5117e-04 - val_loss: 15778.1328 - val_recon_loss: 3.5617e-04 - val_KL loss: 191.5843 - val_beta: 1.5117e-04\n",
      "Epoch 1838/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 13189.7714 - recon_loss: 2.9710e-04 - KL loss: 188.1291 - beta: 1.5117e-04 - val_loss: 12805.5225 - val_recon_loss: 2.8860e-04 - val_KL loss: 176.0022 - val_beta: 1.5117e-04\n",
      "Epoch 1839/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 12587.1897 - recon_loss: 2.8347e-04 - KL loss: 181.8404 - beta: 1.5117e-04 - val_loss: 12965.0371 - val_recon_loss: 2.9212e-04 - val_KL loss: 181.4872 - val_beta: 1.5117e-04\n",
      "Epoch 1840/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12978.5432 - recon_loss: 2.9240e-04 - KL loss: 182.7708 - beta: 1.5117e-04 - val_loss: 13509.0156 - val_recon_loss: 3.0460e-04 - val_KL loss: 179.2946 - val_beta: 1.5117e-04\n",
      "Epoch 1841/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 12526.4660 - recon_loss: 2.8204e-04 - KL loss: 183.9828 - beta: 1.5117e-04 - val_loss: 17583.7930 - val_recon_loss: 3.9721e-04 - val_KL loss: 201.0668 - val_beta: 1.5117e-04\n",
      "Epoch 1842/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 14122.0300 - recon_loss: 3.1825e-04 - KL loss: 194.7723 - beta: 1.5117e-04 - val_loss: 14102.4658 - val_recon_loss: 3.1795e-04 - val_KL loss: 188.2262 - val_beta: 1.5117e-04\n",
      "Epoch 1843/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 13573.0349 - recon_loss: 3.0595e-04 - KL loss: 184.1417 - beta: 1.5117e-04\n",
      "Epoch 01843: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 13572.7140 - recon_loss: 3.0594e-04 - KL loss: 184.1413 - beta: 1.5117e-04 - val_loss: 13747.3516 - val_recon_loss: 3.0994e-04 - val_KL loss: 183.9106 - val_beta: 1.5117e-04\n",
      "Epoch 1844/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12448.7245 - recon_loss: 2.8024e-04 - KL loss: 184.9755 - beta: 1.5117e-04 - val_loss: 12978.5469 - val_recon_loss: 2.9228e-04 - val_KL loss: 187.6919 - val_beta: 1.5117e-04\n",
      "Epoch 1845/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12189.5334 - recon_loss: 2.7423e-04 - KL loss: 188.6747 - beta: 1.5117e-04 - val_loss: 13781.0293 - val_recon_loss: 3.1055e-04 - val_KL loss: 190.8866 - val_beta: 1.5117e-04\n",
      "Epoch 1846/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12282.3291 - recon_loss: 2.7629e-04 - KL loss: 191.5454 - beta: 1.5117e-04 - val_loss: 13205.1719 - val_recon_loss: 2.9743e-04 - val_KL loss: 189.1874 - val_beta: 1.5117e-04\n",
      "Epoch 1847/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12059.1620 - recon_loss: 2.7119e-04 - KL loss: 191.3862 - beta: 1.5117e-04 - val_loss: 13232.0146 - val_recon_loss: 2.9807e-04 - val_KL loss: 187.8284 - val_beta: 1.5117e-04\n",
      "Epoch 1848/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11857.5572 - recon_loss: 2.6661e-04 - KL loss: 190.2274 - beta: 1.5117e-04 - val_loss: 12474.4062 - val_recon_loss: 2.8070e-04 - val_KL loss: 190.3373 - val_beta: 1.5117e-04\n",
      "Epoch 1849/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11976.4321 - recon_loss: 2.6931e-04 - KL loss: 191.0537 - beta: 1.5117e-04 - val_loss: 12427.1367 - val_recon_loss: 2.7953e-04 - val_KL loss: 194.3690 - val_beta: 1.5117e-04\n",
      "Epoch 1850/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11691.9412 - recon_loss: 2.6286e-04 - KL loss: 188.7202 - beta: 1.5117e-04 - val_loss: 13060.7305 - val_recon_loss: 2.9399e-04 - val_KL loss: 195.2062 - val_beta: 1.5117e-04\n",
      "Epoch 1851/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 12172.7704 - recon_loss: 2.7380e-04 - KL loss: 190.8007 - beta: 1.5117e-04 - val_loss: 12782.7061 - val_recon_loss: 2.8777e-04 - val_KL loss: 189.2910 - val_beta: 1.5117e-04\n",
      "Epoch 1852/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11791.5724 - recon_loss: 2.6514e-04 - KL loss: 188.3903 - beta: 1.5117e-04 - val_loss: 13119.2363 - val_recon_loss: 2.9537e-04 - val_KL loss: 193.2367 - val_beta: 1.5117e-04\n",
      "Epoch 1853/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11803.9044 - recon_loss: 2.6537e-04 - KL loss: 190.9032 - beta: 1.5117e-04 - val_loss: 12673.4844 - val_recon_loss: 2.8538e-04 - val_KL loss: 184.9079 - val_beta: 1.5117e-04\n",
      "Epoch 1854/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11769.4112 - recon_loss: 2.6468e-04 - KL loss: 186.3703 - beta: 1.5117e-04 - val_loss: 12070.7354 - val_recon_loss: 2.7148e-04 - val_KL loss: 190.1140 - val_beta: 1.5117e-04\n",
      "Epoch 1855/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11538.6897 - recon_loss: 2.5935e-04 - KL loss: 189.0537 - beta: 1.5117e-04 - val_loss: 11485.1670 - val_recon_loss: 2.5822e-04 - val_KL loss: 184.8415 - val_beta: 1.5117e-04\n",
      "Epoch 1856/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11576.6708 - recon_loss: 2.6024e-04 - KL loss: 188.1572 - beta: 1.5117e-04 - val_loss: 12113.5088 - val_recon_loss: 2.7252e-04 - val_KL loss: 187.7113 - val_beta: 1.5117e-04\n",
      "Epoch 1857/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11463.0788 - recon_loss: 2.5763e-04 - KL loss: 188.6045 - beta: 1.5117e-04 - val_loss: 11408.7900 - val_recon_loss: 2.5637e-04 - val_KL loss: 189.6472 - val_beta: 1.5117e-04\n",
      "Epoch 1858/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11485.8235 - recon_loss: 2.5811e-04 - KL loss: 190.3217 - beta: 1.5117e-04 - val_loss: 11909.5195 - val_recon_loss: 2.6787e-04 - val_KL loss: 186.8804 - val_beta: 1.5117e-04\n",
      "Epoch 1859/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11494.5188 - recon_loss: 2.5833e-04 - KL loss: 189.5412 - beta: 1.5117e-04 - val_loss: 11781.1162 - val_recon_loss: 2.6488e-04 - val_KL loss: 189.5428 - val_beta: 1.5117e-04\n",
      "Epoch 1860/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11361.6600 - recon_loss: 2.5534e-04 - KL loss: 187.5201 - beta: 1.5117e-04 - val_loss: 12353.1904 - val_recon_loss: 2.7785e-04 - val_KL loss: 193.8541 - val_beta: 1.5117e-04\n",
      "Epoch 1861/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11475.8935 - recon_loss: 2.5788e-04 - KL loss: 190.5634 - beta: 1.5117e-04 - val_loss: 12405.1094 - val_recon_loss: 2.7914e-04 - val_KL loss: 189.3878 - val_beta: 1.5117e-04\n",
      "Epoch 1862/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11582.4288 - recon_loss: 2.6036e-04 - KL loss: 188.4230 - beta: 1.5117e-04\n",
      "Epoch 01862: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11582.3677 - recon_loss: 2.6036e-04 - KL loss: 188.4228 - beta: 1.5117e-04 - val_loss: 11665.5508 - val_recon_loss: 2.6223e-04 - val_KL loss: 189.7297 - val_beta: 1.5117e-04\n",
      "Epoch 1863/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11159.2950 - recon_loss: 2.5070e-04 - KL loss: 188.1664 - beta: 1.5117e-04 - val_loss: 11314.9170 - val_recon_loss: 2.5415e-04 - val_KL loss: 192.6875 - val_beta: 1.5117e-04\n",
      "Epoch 1864/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11135.8151 - recon_loss: 2.5013e-04 - KL loss: 189.4599 - beta: 1.5117e-04 - val_loss: 11247.9805 - val_recon_loss: 2.5268e-04 - val_KL loss: 190.0884 - val_beta: 1.5117e-04\n",
      "Epoch 1865/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 11227.7178 - recon_loss: 2.5222e-04 - KL loss: 190.1808 - beta: 1.5117e-04 - val_loss: 11146.2705 - val_recon_loss: 2.5033e-04 - val_KL loss: 191.1721 - val_beta: 1.5117e-04\n",
      "Epoch 1866/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11044.1942 - recon_loss: 2.4802e-04 - KL loss: 190.2593 - beta: 1.5117e-04 - val_loss: 11229.9795 - val_recon_loss: 2.5229e-04 - val_KL loss: 189.4681 - val_beta: 1.5117e-04\n",
      "Epoch 1867/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11055.9003 - recon_loss: 2.4829e-04 - KL loss: 190.3918 - beta: 1.5117e-04 - val_loss: 11108.2041 - val_recon_loss: 2.4950e-04 - val_KL loss: 189.7911 - val_beta: 1.5117e-04\n",
      "Epoch 1868/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11148.1842 - recon_loss: 2.5042e-04 - KL loss: 189.5074 - beta: 1.5117e-04 - val_loss: 11120.0830 - val_recon_loss: 2.4979e-04 - val_KL loss: 188.9463 - val_beta: 1.5117e-04\n",
      "Epoch 1869/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11114.1407 - recon_loss: 2.4962e-04 - KL loss: 190.4436 - beta: 1.5117e-04 - val_loss: 11235.0234 - val_recon_loss: 2.5238e-04 - val_KL loss: 190.3731 - val_beta: 1.5117e-04\n",
      "Epoch 1870/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11136.9250 - recon_loss: 2.5012e-04 - KL loss: 191.3496 - beta: 1.5117e-04 - val_loss: 11091.7529 - val_recon_loss: 2.4910e-04 - val_KL loss: 190.7941 - val_beta: 1.5117e-04\n",
      "Epoch 1871/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 11045.2520 - recon_loss: 2.4801e-04 - KL loss: 191.8680 - beta: 1.5117e-04 - val_loss: 11171.1699 - val_recon_loss: 2.5094e-04 - val_KL loss: 189.6398 - val_beta: 1.5117e-04\n",
      "Epoch 1872/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11136.8142 - recon_loss: 2.5013e-04 - KL loss: 190.8152 - beta: 1.5117e-04 - val_loss: 11699.5449 - val_recon_loss: 2.6301e-04 - val_KL loss: 189.7173 - val_beta: 1.5117e-04\n",
      "Epoch 1873/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11093.1893 - recon_loss: 2.4914e-04 - KL loss: 190.5144 - beta: 1.5117e-04 - val_loss: 11984.9932 - val_recon_loss: 2.6953e-04 - val_KL loss: 189.9988 - val_beta: 1.5117e-04\n",
      "Epoch 1874/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10992.9436 - recon_loss: 2.4684e-04 - KL loss: 190.9865 - beta: 1.5117e-04 - val_loss: 10966.6055 - val_recon_loss: 2.4627e-04 - val_KL loss: 189.3516 - val_beta: 1.5117e-04\n",
      "Epoch 1875/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11029.3820 - recon_loss: 2.4768e-04 - KL loss: 190.5263 - beta: 1.5117e-04 - val_loss: 10827.9873 - val_recon_loss: 2.4312e-04 - val_KL loss: 188.6698 - val_beta: 1.5117e-04\n",
      "Epoch 1876/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11106.3430 - recon_loss: 2.4941e-04 - KL loss: 191.5349 - beta: 1.5117e-04 - val_loss: 10807.8096 - val_recon_loss: 2.4261e-04 - val_KL loss: 190.9492 - val_beta: 1.5117e-04\n",
      "Epoch 1877/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 10990.1615 - recon_loss: 2.4674e-04 - KL loss: 192.4214 - beta: 1.5117e-04 - val_loss: 11114.6953 - val_recon_loss: 2.4951e-04 - val_KL loss: 195.8478 - val_beta: 1.5117e-04\n",
      "Epoch 1878/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 11102.2635 - recon_loss: 2.4925e-04 - KL loss: 194.6740 - beta: 1.5117e-04 - val_loss: 10953.0020 - val_recon_loss: 2.4590e-04 - val_KL loss: 191.8021 - val_beta: 1.5117e-04\n",
      "Epoch 1879/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11155.8412 - recon_loss: 2.5049e-04 - KL loss: 193.8722 - beta: 1.5117e-04 - val_loss: 11157.3428 - val_recon_loss: 2.5053e-04 - val_KL loss: 193.6552 - val_beta: 1.5117e-04\n",
      "Epoch 1880/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 11165.1202 - recon_loss: 2.5072e-04 - KL loss: 192.9455 - beta: 1.5117e-04 - val_loss: 11068.8682 - val_recon_loss: 2.4854e-04 - val_KL loss: 192.5191 - val_beta: 1.5117e-04\n",
      "Epoch 1881/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11066.7929 - recon_loss: 2.4851e-04 - KL loss: 191.4610 - beta: 1.5117e-04\n",
      "Epoch 01881: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 11066.6869 - recon_loss: 2.4851e-04 - KL loss: 191.4608 - beta: 1.5117e-04 - val_loss: 11040.3379 - val_recon_loss: 2.4794e-04 - val_KL loss: 190.1400 - val_beta: 1.5117e-04\n",
      "Epoch 1882/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10993.2982 - recon_loss: 2.4682e-04 - KL loss: 191.9692 - beta: 1.5117e-04 - val_loss: 10928.2754 - val_recon_loss: 2.4539e-04 - val_KL loss: 189.7471 - val_beta: 1.5117e-04\n",
      "Epoch 1883/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10992.2120 - recon_loss: 2.4680e-04 - KL loss: 191.7354 - beta: 1.5117e-04 - val_loss: 11038.4180 - val_recon_loss: 2.4787e-04 - val_KL loss: 191.2609 - val_beta: 1.5117e-04\n",
      "Epoch 1884/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10926.1913 - recon_loss: 2.4528e-04 - KL loss: 192.2970 - beta: 1.5117e-04 - val_loss: 10951.0840 - val_recon_loss: 2.4589e-04 - val_KL loss: 190.6144 - val_beta: 1.5117e-04\n",
      "Epoch 1885/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 10964.0574 - recon_loss: 2.4616e-04 - KL loss: 191.7890 - beta: 1.5117e-04 - val_loss: 10944.6113 - val_recon_loss: 2.4574e-04 - val_KL loss: 190.6306 - val_beta: 1.5117e-04\n",
      "Epoch 1886/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10953.5458 - recon_loss: 2.4591e-04 - KL loss: 192.0263 - beta: 1.5117e-04\n",
      "Epoch 01886: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 10953.5784 - recon_loss: 2.4591e-04 - KL loss: 192.0263 - beta: 1.5117e-04 - val_loss: 10972.8994 - val_recon_loss: 2.4639e-04 - val_KL loss: 190.4243 - val_beta: 1.5117e-04\n",
      "Epoch 1886/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 8013.4545 - recon_loss: 2.7051e-04 - KL loss: 182.2599 - beta: 1.8586e-04 - val_loss: 7884.4160 - val_recon_loss: 2.6645e-04 - val_KL loss: 170.6536 - val_beta: 1.8586e-04\n",
      "Epoch 1887/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7983.3586 - recon_loss: 2.6993e-04 - KL loss: 169.0342 - beta: 1.8586e-04 - val_loss: 9541.1084 - val_recon_loss: 3.2371e-04 - val_KL loss: 169.8158 - val_beta: 1.8586e-04\n",
      "Epoch 1888/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 8342.5626 - recon_loss: 2.8237e-04 - KL loss: 167.9486 - beta: 1.8586e-04 - val_loss: 8398.3584 - val_recon_loss: 2.8440e-04 - val_KL loss: 164.9457 - val_beta: 1.8586e-04\n",
      "Epoch 1889/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 8035.2509 - recon_loss: 2.7191e-04 - KL loss: 163.5041 - beta: 1.8586e-04 - val_loss: 8357.7148 - val_recon_loss: 2.8301e-04 - val_KL loss: 164.7267 - val_beta: 1.8586e-04\n",
      "Epoch 1890/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7961.0375 - recon_loss: 2.6932e-04 - KL loss: 164.3756 - beta: 1.8586e-04 - val_loss: 8929.0928 - val_recon_loss: 3.0287e-04 - val_KL loss: 161.0304 - val_beta: 1.8586e-04\n",
      "Epoch 1891/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7954.2835 - recon_loss: 2.6912e-04 - KL loss: 163.2195 - beta: 1.8586e-04\n",
      "Epoch 01891: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7954.3538 - recon_loss: 2.6913e-04 - KL loss: 163.2204 - beta: 1.8586e-04 - val_loss: 8964.6348 - val_recon_loss: 3.0420e-04 - val_KL loss: 158.0223 - val_beta: 1.8586e-04\n",
      "Epoch 1892/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7861.2740 - recon_loss: 2.6590e-04 - KL loss: 163.5254 - beta: 1.8586e-04 - val_loss: 8001.3579 - val_recon_loss: 2.7068e-04 - val_KL loss: 165.3239 - val_beta: 1.8586e-04\n",
      "Epoch 1893/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7622.2416 - recon_loss: 2.5751e-04 - KL loss: 167.3798 - beta: 1.8586e-04 - val_loss: 8208.4707 - val_recon_loss: 2.7789e-04 - val_KL loss: 163.7880 - val_beta: 1.8586e-04\n",
      "Epoch 1894/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7510.2182 - recon_loss: 2.5372e-04 - KL loss: 165.1991 - beta: 1.8586e-04 - val_loss: 8458.0977 - val_recon_loss: 2.8623e-04 - val_KL loss: 171.9707 - val_beta: 1.8586e-04\n",
      "Epoch 1895/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7690.6252 - recon_loss: 2.5983e-04 - KL loss: 168.6406 - beta: 1.8586e-04 - val_loss: 8094.4746 - val_recon_loss: 2.7385e-04 - val_KL loss: 166.7096 - val_beta: 1.8586e-04\n",
      "Epoch 1896/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7516.6289 - recon_loss: 2.5396e-04 - KL loss: 164.6030 - beta: 1.8586e-04 - val_loss: 7863.7622 - val_recon_loss: 2.6586e-04 - val_KL loss: 167.3009 - val_beta: 1.8586e-04\n",
      "Epoch 1897/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7569.7900 - recon_loss: 2.5563e-04 - KL loss: 169.4566 - beta: 1.8586e-04 - val_loss: 7857.3896 - val_recon_loss: 2.6572e-04 - val_KL loss: 164.7967 - val_beta: 1.8586e-04\n",
      "Epoch 1898/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7493.2307 - recon_loss: 2.5307e-04 - KL loss: 166.9339 - beta: 1.8586e-04 - val_loss: 8006.0449 - val_recon_loss: 2.7074e-04 - val_KL loss: 168.2246 - val_beta: 1.8586e-04\n",
      "Epoch 1899/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7458.6596 - recon_loss: 2.5188e-04 - KL loss: 166.8676 - beta: 1.8586e-04 - val_loss: 8201.8379 - val_recon_loss: 2.7763e-04 - val_KL loss: 164.4528 - val_beta: 1.8586e-04\n",
      "Epoch 1900/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7398.0388 - recon_loss: 2.4981e-04 - KL loss: 166.2433 - beta: 1.8586e-04 - val_loss: 8317.5850 - val_recon_loss: 2.8169e-04 - val_KL loss: 162.8485 - val_beta: 1.8586e-04\n",
      "Epoch 1901/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7462.8948 - recon_loss: 2.5207e-04 - KL loss: 165.6322 - beta: 1.8586e-04 - val_loss: 7901.7441 - val_recon_loss: 2.6732e-04 - val_KL loss: 162.9332 - val_beta: 1.8586e-04\n",
      "Epoch 1902/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7386.1484 - recon_loss: 2.4945e-04 - KL loss: 164.6028 - beta: 1.8586e-04\n",
      "Epoch 01902: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7386.1172 - recon_loss: 2.4945e-04 - KL loss: 164.6025 - beta: 1.8586e-04 - val_loss: 7950.4561 - val_recon_loss: 2.6907e-04 - val_KL loss: 161.0114 - val_beta: 1.8586e-04\n",
      "Epoch 1903/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7299.4630 - recon_loss: 2.4649e-04 - KL loss: 163.5934 - beta: 1.8586e-04 - val_loss: 8098.9170 - val_recon_loss: 2.7412e-04 - val_KL loss: 163.2568 - val_beta: 1.8586e-04\n",
      "Epoch 1904/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7268.6831 - recon_loss: 2.4538e-04 - KL loss: 165.0625 - beta: 1.8586e-04 - val_loss: 8035.0801 - val_recon_loss: 2.7184e-04 - val_KL loss: 165.4813 - val_beta: 1.8586e-04\n",
      "Epoch 1905/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7159.9292 - recon_loss: 2.4159e-04 - KL loss: 166.0341 - beta: 1.8586e-04 - val_loss: 8194.2686 - val_recon_loss: 2.7738e-04 - val_KL loss: 164.1436 - val_beta: 1.8586e-04\n",
      "Epoch 1906/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 7151.2101 - recon_loss: 2.4129e-04 - KL loss: 165.8614 - beta: 1.8586e-04 - val_loss: 8085.8345 - val_recon_loss: 2.7360e-04 - val_KL loss: 165.1023 - val_beta: 1.8586e-04\n",
      "Epoch 1907/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 7163.3150 - recon_loss: 2.4167e-04 - KL loss: 167.1636 - beta: 1.8586e-04\n",
      "Epoch 01907: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 7163.2649 - recon_loss: 2.4166e-04 - KL loss: 167.1638 - beta: 1.8586e-04 - val_loss: 7871.4214 - val_recon_loss: 2.6614e-04 - val_KL loss: 166.8258 - val_beta: 1.8586e-04\n",
      "Epoch 1907/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5172.2705 - recon_loss: 2.6188e-04 - KL loss: 157.1073 - beta: 2.2851e-04 - val_loss: 5476.1470 - val_recon_loss: 2.7848e-04 - val_KL loss: 143.0654 - val_beta: 2.2851e-04\n",
      "Epoch 1908/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5209.6762 - recon_loss: 2.6432e-04 - KL loss: 147.6899 - beta: 2.2851e-04 - val_loss: 6070.4443 - val_recon_loss: 3.0886e-04 - val_KL loss: 155.5309 - val_beta: 2.2851e-04\n",
      "Epoch 1909/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5504.6512 - recon_loss: 2.7963e-04 - KL loss: 149.4251 - beta: 2.2851e-04 - val_loss: 6778.7319 - val_recon_loss: 3.4627e-04 - val_KL loss: 147.3045 - val_beta: 2.2851e-04\n",
      "Epoch 1910/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5798.4011 - recon_loss: 2.9485e-04 - KL loss: 151.7715 - beta: 2.2851e-04 - val_loss: 6536.1299 - val_recon_loss: 3.3327e-04 - val_KL loss: 153.7662 - val_beta: 2.2851e-04\n",
      "Epoch 1911/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5577.8901 - recon_loss: 2.8352e-04 - KL loss: 148.1892 - beta: 2.2851e-04 - val_loss: 6421.8086 - val_recon_loss: 3.2754e-04 - val_KL loss: 149.0440 - val_beta: 2.2851e-04\n",
      "Epoch 1912/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 5450.4208 - recon_loss: 2.7696e-04 - KL loss: 146.2938 - beta: 2.2851e-04\n",
      "Epoch 01912: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5450.4986 - recon_loss: 2.7697e-04 - KL loss: 146.2955 - beta: 2.2851e-04 - val_loss: 6681.8022 - val_recon_loss: 3.4064e-04 - val_KL loss: 158.1476 - val_beta: 2.2851e-04\n",
      "Epoch 1913/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 5468.8828 - recon_loss: 2.7766e-04 - KL loss: 151.3643 - beta: 2.2851e-04 - val_loss: 5412.2173 - val_recon_loss: 2.7478e-04 - val_KL loss: 149.9600 - val_beta: 2.2851e-04\n",
      "Epoch 1914/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5124.0320 - recon_loss: 2.5985e-04 - KL loss: 147.6534 - beta: 2.2851e-04 - val_loss: 5443.4409 - val_recon_loss: 2.7636e-04 - val_KL loss: 150.9414 - val_beta: 2.2851e-04\n",
      "Epoch 1915/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 5144.6322 - recon_loss: 2.6086e-04 - KL loss: 148.9235 - beta: 2.2851e-04 - val_loss: 5269.9834 - val_recon_loss: 2.6756e-04 - val_KL loss: 146.0206 - val_beta: 2.2851e-04\n",
      "Epoch 1916/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5038.5764 - recon_loss: 2.5550e-04 - KL loss: 145.5221 - beta: 2.2851e-04 - val_loss: 5558.2515 - val_recon_loss: 2.8254e-04 - val_KL loss: 147.4374 - val_beta: 2.2851e-04\n",
      "Epoch 1917/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 5003.9826 - recon_loss: 2.5369e-04 - KL loss: 145.6451 - beta: 2.2851e-04 - val_loss: 5085.3994 - val_recon_loss: 2.5787e-04 - val_KL loss: 147.0081 - val_beta: 2.2851e-04\n",
      "Epoch 1918/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4982.5223 - recon_loss: 2.5258e-04 - KL loss: 145.2900 - beta: 2.2851e-04 - val_loss: 5707.2417 - val_recon_loss: 2.9020e-04 - val_KL loss: 149.6761 - val_beta: 2.2851e-04\n",
      "Epoch 1919/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4972.6518 - recon_loss: 2.5200e-04 - KL loss: 146.5426 - beta: 2.2851e-04 - val_loss: 5646.8848 - val_recon_loss: 2.8722e-04 - val_KL loss: 146.3572 - val_beta: 2.2851e-04\n",
      "Epoch 1920/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 4983.0887 - recon_loss: 2.5262e-04 - KL loss: 145.1965 - beta: 2.2851e-04 - val_loss: 5502.2080 - val_recon_loss: 2.7966e-04 - val_KL loss: 146.4554 - val_beta: 2.2851e-04\n",
      "Epoch 1921/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 4985.7396 - recon_loss: 2.5276e-04 - KL loss: 145.0993 - beta: 2.2851e-04 - val_loss: 5464.6431 - val_recon_loss: 2.7775e-04 - val_KL loss: 145.5228 - val_beta: 2.2851e-04\n",
      "Epoch 1922/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 4938.4427 - recon_loss: 2.5028e-04 - KL loss: 145.2850 - beta: 2.2851e-04\n",
      "Epoch 01922: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 4938.3927 - recon_loss: 2.5028e-04 - KL loss: 145.2862 - beta: 2.2851e-04 - val_loss: 5283.2769 - val_recon_loss: 2.6822e-04 - val_KL loss: 146.5540 - val_beta: 2.2851e-04\n",
      "Epoch 1923/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 4875.9082 - recon_loss: 2.4703e-04 - KL loss: 144.9556 - beta: 2.2851e-04 - val_loss: 5130.7524 - val_recon_loss: 2.6034e-04 - val_KL loss: 144.9436 - val_beta: 2.2851e-04\n",
      "Epoch 1924/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4819.2813 - recon_loss: 2.4408e-04 - KL loss: 144.9798 - beta: 2.2851e-04 - val_loss: 5303.8516 - val_recon_loss: 2.6939e-04 - val_KL loss: 144.7965 - val_beta: 2.2851e-04\n",
      "Epoch 1925/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 4800.1580 - recon_loss: 2.4304e-04 - KL loss: 145.6388 - beta: 2.2851e-04 - val_loss: 5184.0498 - val_recon_loss: 2.6323e-04 - val_KL loss: 142.8606 - val_beta: 2.2851e-04\n",
      "Epoch 1926/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 4849.4336 - recon_loss: 2.4562e-04 - KL loss: 145.5521 - beta: 2.2851e-04 - val_loss: 5398.3975 - val_recon_loss: 2.7421e-04 - val_KL loss: 147.1065 - val_beta: 2.2851e-04\n",
      "Epoch 1927/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4795.7710 - recon_loss: 2.4271e-04 - KL loss: 147.7362 - beta: 2.2851e-04\n",
      "Epoch 01927: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 4795.7627 - recon_loss: 2.4270e-04 - KL loss: 147.7360 - beta: 2.2851e-04 - val_loss: 5173.6313 - val_recon_loss: 2.6243e-04 - val_KL loss: 147.8046 - val_beta: 2.2851e-04\n",
      "Epoch 1927/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 3445.6478 - recon_loss: 2.6114e-04 - KL loss: 137.3212 - beta: 2.8095e-04 - val_loss: 3653.9141 - val_recon_loss: 2.7836e-04 - val_KL loss: 127.4188 - val_beta: 2.8095e-04\n",
      "Epoch 1928/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 3427.3237 - recon_loss: 2.6051e-04 - KL loss: 126.9727 - beta: 2.8095e-04 - val_loss: 4071.7397 - val_recon_loss: 3.1162e-04 - val_KL loss: 123.8609 - val_beta: 2.8095e-04\n",
      "Epoch 1929/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 3434.6448 - recon_loss: 2.6122e-04 - KL loss: 125.2617 - beta: 2.8095e-04 - val_loss: 4105.3901 - val_recon_loss: 3.1445e-04 - val_KL loss: 121.6514 - val_beta: 2.8095e-04\n",
      "Epoch 1930/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 3580.4382 - recon_loss: 2.7272e-04 - KL loss: 125.4368 - beta: 2.8095e-04 - val_loss: 5312.1509 - val_recon_loss: 4.0908e-04 - val_KL loss: 129.5711 - val_beta: 2.8095e-04\n",
      "Epoch 1931/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 3885.1376 - recon_loss: 2.9641e-04 - KL loss: 129.9708 - beta: 2.8095e-04 - val_loss: 3712.2026 - val_recon_loss: 2.8335e-04 - val_KL loss: 122.5354 - val_beta: 2.8095e-04\n",
      "Epoch 1932/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3599.3436 - recon_loss: 2.7408e-04 - KL loss: 127.0100 - beta: 2.8095e-04\n",
      "Epoch 01932: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 3599.4751 - recon_loss: 2.7409e-04 - KL loss: 127.0147 - beta: 2.8095e-04 - val_loss: 4734.9570 - val_recon_loss: 3.6254e-04 - val_KL loss: 141.9951 - val_beta: 2.8095e-04\n",
      "Epoch 1933/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 3846.4313 - recon_loss: 2.9258e-04 - KL loss: 139.7432 - beta: 2.8095e-04 - val_loss: 4740.8301 - val_recon_loss: 3.6354e-04 - val_KL loss: 135.2200 - val_beta: 2.8095e-04\n",
      "Epoch 1934/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 3628.6925 - recon_loss: 2.7576e-04 - KL loss: 135.0675 - beta: 2.8095e-04 - val_loss: 4260.0776 - val_recon_loss: 3.2550e-04 - val_KL loss: 136.3932 - val_beta: 2.8095e-04\n",
      "Epoch 1935/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 3580.9334 - recon_loss: 2.7206e-04 - KL loss: 134.2879 - beta: 2.8095e-04 - val_loss: 3803.1145 - val_recon_loss: 2.9004e-04 - val_KL loss: 128.6851 - val_beta: 2.8095e-04\n",
      "Epoch 1936/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 3397.5817 - recon_loss: 2.5796e-04 - KL loss: 129.5027 - beta: 2.8095e-04 - val_loss: 4010.7378 - val_recon_loss: 3.0646e-04 - val_KL loss: 128.2238 - val_beta: 2.8095e-04\n",
      "Epoch 1937/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 3404.4756 - recon_loss: 2.5845e-04 - KL loss: 130.2309 - beta: 2.8095e-04\n",
      "Epoch 01937: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 3404.4449 - recon_loss: 2.5845e-04 - KL loss: 130.2320 - beta: 2.8095e-04 - val_loss: 3742.3086 - val_recon_loss: 2.8526e-04 - val_KL loss: 128.3562 - val_beta: 2.8095e-04\n",
      "Epoch 1937/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2319.0032 - recon_loss: 2.6240e-04 - KL loss: 119.8670 - beta: 3.4543e-04 - val_loss: 2584.4785 - val_recon_loss: 2.9512e-04 - val_KL loss: 111.1076 - val_beta: 3.4543e-04\n",
      "Epoch 1938/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2396.8367 - recon_loss: 2.7246e-04 - KL loss: 113.3725 - beta: 3.4543e-04 - val_loss: 2421.4219 - val_recon_loss: 2.7605e-04 - val_KL loss: 107.9089 - val_beta: 3.4543e-04\n",
      "Epoch 1939/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2580.8393 - recon_loss: 2.9423e-04 - KL loss: 114.9193 - beta: 3.4543e-04 - val_loss: 2660.9778 - val_recon_loss: 3.0457e-04 - val_KL loss: 108.4310 - val_beta: 3.4543e-04\n",
      "Epoch 1940/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2377.4813 - recon_loss: 2.7074e-04 - KL loss: 108.4431 - beta: 3.4543e-04 - val_loss: 2471.0781 - val_recon_loss: 2.8202e-04 - val_KL loss: 107.4861 - val_beta: 3.4543e-04\n",
      "Epoch 1941/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2385.1638 - recon_loss: 2.7152e-04 - KL loss: 109.6222 - beta: 3.4543e-04 - val_loss: 2441.3049 - val_recon_loss: 2.7823e-04 - val_KL loss: 109.4886 - val_beta: 3.4543e-04\n",
      "Epoch 1942/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2287.4944 - recon_loss: 2.6037e-04 - KL loss: 105.3998 - beta: 3.4543e-04 - val_loss: 2599.1387 - val_recon_loss: 2.9837e-04 - val_KL loss: 98.5669 - val_beta: 3.4543e-04\n",
      "Epoch 1943/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2294.0199 - recon_loss: 2.6156e-04 - KL loss: 101.9280 - beta: 3.4543e-04 - val_loss: 2300.8528 - val_recon_loss: 2.6197e-04 - val_KL loss: 105.3029 - val_beta: 3.4543e-04\n",
      "Epoch 1944/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2386.3327 - recon_loss: 2.7231e-04 - KL loss: 104.1859 - beta: 3.4543e-04 - val_loss: 3251.0422 - val_recon_loss: 3.7378e-04 - val_KL loss: 118.4840 - val_beta: 3.4543e-04\n",
      "Epoch 1945/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2617.7180 - recon_loss: 2.9915e-04 - KL loss: 110.6088 - beta: 3.4543e-04 - val_loss: 2353.6946 - val_recon_loss: 2.6830e-04 - val_KL loss: 105.1273 - val_beta: 3.4543e-04\n",
      "Epoch 1946/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2334.8002 - recon_loss: 2.6606e-04 - KL loss: 105.0263 - beta: 3.4543e-04 - val_loss: 2430.3765 - val_recon_loss: 2.7795e-04 - val_KL loss: 100.9665 - val_beta: 3.4543e-04\n",
      "Epoch 1947/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2326.1108 - recon_loss: 2.6530e-04 - KL loss: 102.6807 - beta: 3.4543e-04 - val_loss: 2338.4688 - val_recon_loss: 2.6695e-04 - val_KL loss: 101.2159 - val_beta: 3.4543e-04\n",
      "Epoch 1948/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2306.6467 - recon_loss: 2.6319e-04 - KL loss: 100.8911 - beta: 3.4543e-04\n",
      "Epoch 01948: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2306.6779 - recon_loss: 2.6319e-04 - KL loss: 100.8924 - beta: 3.4543e-04 - val_loss: 2702.8726 - val_recon_loss: 3.1055e-04 - val_KL loss: 100.2066 - val_beta: 3.4543e-04\n",
      "Epoch 1949/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2292.5225 - recon_loss: 2.6117e-04 - KL loss: 103.6960 - beta: 3.4543e-04 - val_loss: 2422.8655 - val_recon_loss: 2.7666e-04 - val_KL loss: 104.2231 - val_beta: 3.4543e-04\n",
      "Epoch 1950/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2172.2987 - recon_loss: 2.4705e-04 - KL loss: 101.8177 - beta: 3.4543e-04 - val_loss: 2340.9473 - val_recon_loss: 2.6707e-04 - val_KL loss: 102.7183 - val_beta: 3.4543e-04\n",
      "Epoch 1951/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 2143.5582 - recon_loss: 2.4354e-04 - KL loss: 102.5321 - beta: 3.4543e-04 - val_loss: 2359.4143 - val_recon_loss: 2.6929e-04 - val_KL loss: 102.5825 - val_beta: 3.4543e-04\n",
      "Epoch 1952/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2139.3024 - recon_loss: 2.4297e-04 - KL loss: 103.0257 - beta: 3.4543e-04 - val_loss: 2354.7803 - val_recon_loss: 2.6873e-04 - val_KL loss: 102.5722 - val_beta: 3.4543e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1953/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2125.7736 - recon_loss: 2.4137e-04 - KL loss: 102.8596 - beta: 3.4543e-04\n",
      "Epoch 01953: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 2125.7728 - recon_loss: 2.4137e-04 - KL loss: 102.8596 - beta: 3.4543e-04 - val_loss: 2338.6885 - val_recon_loss: 2.6655e-04 - val_KL loss: 104.7633 - val_beta: 3.4543e-04\n",
      "Epoch 1953/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 1484.3257 - recon_loss: 2.5033e-04 - KL loss: 96.4427 - beta: 4.2470e-04 - val_loss: 1623.1440 - val_recon_loss: 2.7617e-04 - val_KL loss: 92.0323 - val_beta: 4.2470e-04\n",
      "Epoch 1954/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1469.7196 - recon_loss: 2.4853e-04 - KL loss: 91.8212 - beta: 4.2470e-04 - val_loss: 1535.0591 - val_recon_loss: 2.6095e-04 - val_KL loss: 88.3292 - val_beta: 4.2470e-04\n",
      "Epoch 1955/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1505.0961 - recon_loss: 2.5542e-04 - KL loss: 89.0268 - beta: 4.2470e-04 - val_loss: 1712.6554 - val_recon_loss: 2.9349e-04 - val_KL loss: 85.5023 - val_beta: 4.2470e-04\n",
      "Epoch 1956/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1513.2757 - recon_loss: 2.5722e-04 - KL loss: 87.2295 - beta: 4.2470e-04 - val_loss: 1562.0087 - val_recon_loss: 2.6591e-04 - val_KL loss: 87.7774 - val_beta: 4.2470e-04\n",
      "Epoch 1957/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1528.2813 - recon_loss: 2.5981e-04 - KL loss: 87.8666 - beta: 4.2470e-04 - val_loss: 1569.1716 - val_recon_loss: 2.6741e-04 - val_KL loss: 86.6230 - val_beta: 4.2470e-04\n",
      "Epoch 1958/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1505.8866 - recon_loss: 2.5588e-04 - KL loss: 87.2785 - beta: 4.2470e-04 - val_loss: 1554.5447 - val_recon_loss: 2.6501e-04 - val_KL loss: 85.2863 - val_beta: 4.2470e-04\n",
      "Epoch 1959/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 1494.2460 - recon_loss: 2.5386e-04 - KL loss: 86.8137 - beta: 4.2470e-04\n",
      "Epoch 01959: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1494.2279 - recon_loss: 2.5386e-04 - KL loss: 86.8132 - beta: 4.2470e-04 - val_loss: 1696.5476 - val_recon_loss: 2.8996e-04 - val_KL loss: 88.9566 - val_beta: 4.2470e-04\n",
      "Epoch 1960/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1432.0582 - recon_loss: 2.4256e-04 - KL loss: 87.2891 - beta: 4.2470e-04 - val_loss: 1508.5269 - val_recon_loss: 2.5640e-04 - val_KL loss: 87.0126 - val_beta: 4.2470e-04\n",
      "Epoch 1961/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1419.1525 - recon_loss: 2.4022e-04 - KL loss: 87.3509 - beta: 4.2470e-04 - val_loss: 1626.7565 - val_recon_loss: 2.7701e-04 - val_KL loss: 90.9665 - val_beta: 4.2470e-04\n",
      "Epoch 1962/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1451.1808 - recon_loss: 2.4578e-04 - KL loss: 88.5713 - beta: 4.2470e-04 - val_loss: 1473.6754 - val_recon_loss: 2.5023e-04 - val_KL loss: 86.3892 - val_beta: 4.2470e-04\n",
      "Epoch 1963/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1411.0604 - recon_loss: 2.3889e-04 - KL loss: 86.6353 - beta: 4.2470e-04 - val_loss: 1547.6146 - val_recon_loss: 2.6351e-04 - val_KL loss: 86.6777 - val_beta: 4.2470e-04\n",
      "Epoch 1964/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1407.4728 - recon_loss: 2.3842e-04 - KL loss: 85.6534 - beta: 4.2470e-04 - val_loss: 1484.7552 - val_recon_loss: 2.5218e-04 - val_KL loss: 86.6168 - val_beta: 4.2470e-04\n",
      "Epoch 1965/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1398.1642 - recon_loss: 2.3667e-04 - KL loss: 86.0238 - beta: 4.2470e-04 - val_loss: 1474.0874 - val_recon_loss: 2.5057e-04 - val_KL loss: 84.8700 - val_beta: 4.2470e-04\n",
      "Epoch 1966/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1384.9985 - recon_loss: 2.3423e-04 - KL loss: 86.4118 - beta: 4.2470e-04 - val_loss: 1449.6036 - val_recon_loss: 2.4577e-04 - val_KL loss: 87.0497 - val_beta: 4.2470e-04\n",
      "Epoch 1967/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1413.4113 - recon_loss: 2.3956e-04 - KL loss: 85.2626 - beta: 4.2470e-04 - val_loss: 1546.3079 - val_recon_loss: 2.6346e-04 - val_KL loss: 85.6775 - val_beta: 4.2470e-04\n",
      "Epoch 1968/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1404.5188 - recon_loss: 2.3788e-04 - KL loss: 85.6827 - beta: 4.2470e-04 - val_loss: 1443.8090 - val_recon_loss: 2.4472e-04 - val_KL loss: 87.0299 - val_beta: 4.2470e-04\n",
      "Epoch 1969/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1378.1250 - recon_loss: 2.3309e-04 - KL loss: 85.8717 - beta: 4.2470e-04 - val_loss: 1519.0703 - val_recon_loss: 2.5827e-04 - val_KL loss: 87.2102 - val_beta: 4.2470e-04\n",
      "Epoch 1970/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1400.6882 - recon_loss: 2.3712e-04 - KL loss: 86.0435 - beta: 4.2470e-04 - val_loss: 1493.4517 - val_recon_loss: 2.5391e-04 - val_KL loss: 85.7253 - val_beta: 4.2470e-04\n",
      "Epoch 1971/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1396.2882 - recon_loss: 2.3641e-04 - KL loss: 85.6098 - beta: 4.2470e-04 - val_loss: 1447.7937 - val_recon_loss: 2.4595e-04 - val_KL loss: 84.2391 - val_beta: 4.2470e-04\n",
      "Epoch 1972/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1390.5959 - recon_loss: 2.3531e-04 - KL loss: 86.0082 - beta: 4.2470e-04 - val_loss: 1429.3165 - val_recon_loss: 2.4219e-04 - val_KL loss: 86.6118 - val_beta: 4.2470e-04\n",
      "Epoch 1973/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1379.8467 - recon_loss: 2.3348e-04 - KL loss: 85.4228 - beta: 4.2470e-04 - val_loss: 1404.0046 - val_recon_loss: 2.3779e-04 - val_KL loss: 85.6709 - val_beta: 4.2470e-04\n",
      "Epoch 1974/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1370.2844 - recon_loss: 2.3165e-04 - KL loss: 85.9608 - beta: 4.2470e-04 - val_loss: 1452.8906 - val_recon_loss: 2.4661e-04 - val_KL loss: 85.6764 - val_beta: 4.2470e-04\n",
      "Epoch 1975/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1371.8672 - recon_loss: 2.3205e-04 - KL loss: 85.3403 - beta: 4.2470e-04 - val_loss: 1452.3320 - val_recon_loss: 2.4666e-04 - val_KL loss: 84.8161 - val_beta: 4.2470e-04\n",
      "Epoch 1976/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1381.9230 - recon_loss: 2.3381e-04 - KL loss: 85.6764 - beta: 4.2470e-04 - val_loss: 1485.6937 - val_recon_loss: 2.5258e-04 - val_KL loss: 85.3339 - val_beta: 4.2470e-04\n",
      "Epoch 1977/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1391.4239 - recon_loss: 2.3550e-04 - KL loss: 85.7865 - beta: 4.2470e-04 - val_loss: 1469.3323 - val_recon_loss: 2.4996e-04 - val_KL loss: 83.5344 - val_beta: 4.2470e-04\n",
      "Epoch 1978/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1383.5557 - recon_loss: 2.3409e-04 - KL loss: 85.7108 - beta: 4.2470e-04\n",
      "Epoch 01978: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1383.5482 - recon_loss: 2.3409e-04 - KL loss: 85.7111 - beta: 4.2470e-04 - val_loss: 1545.1406 - val_recon_loss: 2.6336e-04 - val_KL loss: 85.0136 - val_beta: 4.2470e-04\n",
      "Epoch 1979/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1354.2692 - recon_loss: 2.2877e-04 - KL loss: 85.9215 - beta: 4.2470e-04 - val_loss: 1452.7859 - val_recon_loss: 2.4656e-04 - val_KL loss: 85.8006 - val_beta: 4.2470e-04\n",
      "Epoch 1980/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1358.6118 - recon_loss: 2.2948e-04 - KL loss: 86.3327 - beta: 4.2470e-04 - val_loss: 1561.2264 - val_recon_loss: 2.6611e-04 - val_KL loss: 85.8603 - val_beta: 4.2470e-04\n",
      "Epoch 1981/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1350.5174 - recon_loss: 2.2802e-04 - KL loss: 86.3600 - beta: 4.2470e-04 - val_loss: 1529.2864 - val_recon_loss: 2.6043e-04 - val_KL loss: 85.4321 - val_beta: 4.2470e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1982/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1348.6981 - recon_loss: 2.2772e-04 - KL loss: 86.1748 - beta: 4.2470e-04 - val_loss: 1445.8298 - val_recon_loss: 2.4523e-04 - val_KL loss: 86.2386 - val_beta: 4.2470e-04\n",
      "Epoch 1983/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1338.8158 - recon_loss: 2.2593e-04 - KL loss: 86.2471 - beta: 4.2470e-04\n",
      "Epoch 01983: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 1338.8207 - recon_loss: 2.2593e-04 - KL loss: 86.2473 - beta: 4.2470e-04 - val_loss: 1509.1836 - val_recon_loss: 2.5670e-04 - val_KL loss: 85.9957 - val_beta: 4.2470e-04\n",
      "Epoch 1983/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 967.2092 - recon_loss: 2.4180e-04 - KL loss: 80.3764 - beta: 5.2217e-04 - val_loss: 1103.3788 - val_recon_loss: 2.8023e-04 - val_KL loss: 75.6107 - val_beta: 5.2217e-04\n",
      "Epoch 1984/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 991.1866 - recon_loss: 2.4963e-04 - KL loss: 75.6380 - beta: 5.2217e-04 - val_loss: 1013.8001 - val_recon_loss: 2.5604e-04 - val_KL loss: 74.7511 - val_beta: 5.2217e-04\n",
      "Epoch 1985/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 968.8014 - recon_loss: 2.4361e-04 - KL loss: 75.3302 - beta: 5.2217e-04 - val_loss: 1100.2743 - val_recon_loss: 2.7904e-04 - val_KL loss: 76.8662 - val_beta: 5.2217e-04\n",
      "Epoch 1986/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1006.4899 - recon_loss: 2.5411e-04 - KL loss: 74.5007 - beta: 5.2217e-04 - val_loss: 1048.7399 - val_recon_loss: 2.6581e-04 - val_KL loss: 73.8674 - val_beta: 5.2217e-04\n",
      "Epoch 1987/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 978.7599 - recon_loss: 2.4675e-04 - KL loss: 73.7955 - beta: 5.2217e-04 - val_loss: 1032.3201 - val_recon_loss: 2.6171e-04 - val_KL loss: 72.4777 - val_beta: 5.2217e-04\n",
      "Epoch 1988/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1003.3551 - recon_loss: 2.5317e-04 - KL loss: 74.8346 - beta: 5.2217e-04 - val_loss: 1085.1018 - val_recon_loss: 2.7551e-04 - val_KL loss: 74.6468 - val_beta: 5.2217e-04\n",
      "Epoch 1989/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1005.0853 - recon_loss: 2.5406e-04 - KL loss: 73.3023 - beta: 5.2217e-04\n",
      "Epoch 01989: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 1005.0784 - recon_loss: 2.5406e-04 - KL loss: 73.3019 - beta: 5.2217e-04 - val_loss: 1023.6686 - val_recon_loss: 2.5945e-04 - val_KL loss: 72.1166 - val_beta: 5.2217e-04\n",
      "Epoch 1990/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 937.4767 - recon_loss: 2.3549e-04 - KL loss: 73.7786 - beta: 5.2217e-04 - val_loss: 983.2303 - val_recon_loss: 2.4828e-04 - val_KL loss: 72.6274 - val_beta: 5.2217e-04\n",
      "Epoch 1991/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 926.7787 - recon_loss: 2.3267e-04 - KL loss: 73.4263 - beta: 5.2217e-04 - val_loss: 990.3691 - val_recon_loss: 2.4997e-04 - val_KL loss: 73.5636 - val_beta: 5.2217e-04\n",
      "Epoch 1992/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 944.8737 - recon_loss: 2.3740e-04 - KL loss: 74.1918 - beta: 5.2217e-04 - val_loss: 1042.4835 - val_recon_loss: 2.6404e-04 - val_KL loss: 74.1061 - val_beta: 5.2217e-04\n",
      "Epoch 1993/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 943.7237 - recon_loss: 2.3713e-04 - KL loss: 74.0324 - beta: 5.2217e-04 - val_loss: 1041.1570 - val_recon_loss: 2.6367e-04 - val_KL loss: 74.1378 - val_beta: 5.2217e-04\n",
      "Epoch 1994/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 933.3173 - recon_loss: 2.3475e-04 - KL loss: 72.3478 - beta: 5.2217e-04 - val_loss: 1001.3311 - val_recon_loss: 2.5329e-04 - val_KL loss: 72.3841 - val_beta: 5.2217e-04\n",
      "Epoch 1995/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 914.4616 - recon_loss: 2.2943e-04 - KL loss: 72.9937 - beta: 5.2217e-04\n",
      "Epoch 01995: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 914.4676 - recon_loss: 2.2944e-04 - KL loss: 72.9939 - beta: 5.2217e-04 - val_loss: 1000.9846 - val_recon_loss: 2.5287e-04 - val_KL loss: 73.5524 - val_beta: 5.2217e-04\n",
      "Epoch 1996/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 911.7384 - recon_loss: 2.2843e-04 - KL loss: 73.9438 - beta: 5.2217e-04 - val_loss: 979.2986 - val_recon_loss: 2.4702e-04 - val_KL loss: 73.3451 - val_beta: 5.2217e-04\n",
      "Epoch 1997/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 906.3527 - recon_loss: 2.2713e-04 - KL loss: 73.3367 - beta: 5.2217e-04 - val_loss: 975.2579 - val_recon_loss: 2.4590e-04 - val_KL loss: 73.3838 - val_beta: 5.2217e-04\n",
      "Epoch 1998/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 913.6837 - recon_loss: 2.2904e-04 - KL loss: 73.6597 - beta: 5.2217e-04 - val_loss: 1015.8408 - val_recon_loss: 2.5678e-04 - val_KL loss: 74.0895 - val_beta: 5.2217e-04\n",
      "Epoch 1999/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 896.0301 - recon_loss: 2.2418e-04 - KL loss: 73.8388 - beta: 5.2217e-04 - val_loss: 995.1826 - val_recon_loss: 2.5143e-04 - val_KL loss: 73.0468 - val_beta: 5.2217e-04\n",
      "Epoch 2000/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 904.1742 - recon_loss: 2.2647e-04 - KL loss: 73.5796 - beta: 5.2217e-04 - val_loss: 941.9141 - val_recon_loss: 2.3691e-04 - val_KL loss: 73.0150 - val_beta: 5.2217e-04\n",
      "Epoch 2001/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 903.8268 - recon_loss: 2.2659e-04 - KL loss: 72.7714 - beta: 5.2217e-04 - val_loss: 953.5574 - val_recon_loss: 2.4021e-04 - val_KL loss: 72.5548 - val_beta: 5.2217e-04\n",
      "Epoch 2002/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 903.2319 - recon_loss: 2.2624e-04 - KL loss: 73.4634 - beta: 5.2217e-04 - val_loss: 966.5071 - val_recon_loss: 2.4350e-04 - val_KL loss: 73.4524 - val_beta: 5.2217e-04\n",
      "Epoch 2003/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 892.1515 - recon_loss: 2.2322e-04 - KL loss: 73.4753 - beta: 5.2217e-04 - val_loss: 991.0787 - val_recon_loss: 2.5040e-04 - val_KL loss: 72.7078 - val_beta: 5.2217e-04\n",
      "Epoch 2004/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 894.8196 - recon_loss: 2.2398e-04 - KL loss: 73.3477 - beta: 5.2217e-04 - val_loss: 963.8596 - val_recon_loss: 2.4290e-04 - val_KL loss: 73.0195 - val_beta: 5.2217e-04\n",
      "Epoch 2005/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 899.6518 - recon_loss: 2.2535e-04 - KL loss: 73.1725 - beta: 5.2217e-04 ETA: 0s - loss: 899.6919 - recon_loss: 2.2536e-04 - KL loss: 73.1737 - be\n",
      "Epoch 02005: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 899.6449 - recon_loss: 2.2534e-04 - KL loss: 73.1723 - beta: 5.2217e-04 - val_loss: 1039.5137 - val_recon_loss: 2.6358e-04 - val_KL loss: 72.8287 - val_beta: 5.2217e-04\n",
      "Epoch 2006/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 900.3907 - recon_loss: 2.2548e-04 - KL loss: 73.4409 - beta: 5.2217e-04 - val_loss: 1005.0599 - val_recon_loss: 2.5428e-04 - val_KL loss: 72.4755 - val_beta: 5.2217e-04\n",
      "Epoch 2007/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 888.3299 - recon_loss: 2.2228e-04 - KL loss: 73.0884 - beta: 5.2217e-04 - val_loss: 958.9970 - val_recon_loss: 2.4177e-04 - val_KL loss: 72.2764 - val_beta: 5.2217e-04\n",
      "Epoch 2008/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 885.1248 - recon_loss: 2.2148e-04 - KL loss: 72.8381 - beta: 5.2217e-04 - val_loss: 1001.6418 - val_recon_loss: 2.5333e-04 - val_KL loss: 72.5423 - val_beta: 5.2217e-04\n",
      "Epoch 2009/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 893.3898 - recon_loss: 2.2365e-04 - KL loss: 73.1458 - beta: 5.2217e-04 - val_loss: 984.8415 - val_recon_loss: 2.4878e-04 - val_KL loss: 72.4285 - val_beta: 5.2217e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2010/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 894.7151 - recon_loss: 2.2397e-04 - KL loss: 73.2794 - beta: 5.2217e-04\n",
      "Epoch 02010: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 894.7108 - recon_loss: 2.2397e-04 - KL loss: 73.2793 - beta: 5.2217e-04 - val_loss: 971.5280 - val_recon_loss: 2.4511e-04 - val_KL loss: 72.5550 - val_beta: 5.2217e-04\n",
      "Epoch 2010/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 671.5541 - recon_loss: 2.4861e-04 - KL loss: 68.3644 - beta: 6.4200e-04 - val_loss: 883.4980 - val_recon_loss: 3.3656e-04 - val_KL loss: 66.9239 - val_beta: 6.4200e-04\n",
      "Epoch 2011/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 721.4273 - recon_loss: 2.6978e-04 - KL loss: 66.8865 - beta: 6.4200e-04 - val_loss: 813.3517 - val_recon_loss: 3.0869e-04 - val_KL loss: 64.4075 - val_beta: 6.4200e-04\n",
      "Epoch 2012/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 700.0295 - recon_loss: 2.6124e-04 - KL loss: 66.1983 - beta: 6.4200e-04 - val_loss: 891.3729 - val_recon_loss: 3.3869e-04 - val_KL loss: 69.6406 - val_beta: 6.4200e-04\n",
      "Epoch 2013/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 789.5176 - recon_loss: 2.9604e-04 - KL loss: 71.2551 - beta: 6.4200e-04 - val_loss: 844.5642 - val_recon_loss: 3.2084e-04 - val_KL loss: 66.1405 - val_beta: 6.4200e-04\n",
      "Epoch 2014/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 716.3871 - recon_loss: 2.6759e-04 - KL loss: 67.1627 - beta: 6.4200e-04 - val_loss: 827.7257 - val_recon_loss: 3.1410e-04 - val_KL loss: 65.6430 - val_beta: 6.4200e-04\n",
      "Epoch 2015/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 691.8173 - recon_loss: 2.5844e-04 - KL loss: 64.7857 - beta: 6.4200e-04 - val_loss: 830.3995 - val_recon_loss: 3.1611e-04 - val_KL loss: 63.4536 - val_beta: 6.4200e-04\n",
      "Epoch 2016/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 739.7895 - recon_loss: 2.7828e-04 - KL loss: 64.6263 - beta: 6.4200e-04\n",
      "Epoch 02016: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 739.7871 - recon_loss: 2.7828e-04 - KL loss: 64.6254 - beta: 6.4200e-04 - val_loss: 832.7117 - val_recon_loss: 3.1894e-04 - val_KL loss: 58.8987 - val_beta: 6.4200e-04\n",
      "Epoch 2017/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 673.6449 - recon_loss: 2.5252e-04 - KL loss: 60.9694 - beta: 6.4200e-04 - val_loss: 732.2328 - val_recon_loss: 2.7588e-04 - val_KL loss: 62.8851 - val_beta: 6.4200e-04\n",
      "Epoch 2018/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 652.7596 - recon_loss: 2.4356e-04 - KL loss: 61.8414 - beta: 6.4200e-04 - val_loss: 669.1495 - val_recon_loss: 2.5020e-04 - val_KL loss: 62.1205 - val_beta: 6.4200e-04\n",
      "Epoch 2019/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 644.6464 - recon_loss: 2.4012e-04 - KL loss: 62.0538 - beta: 6.4200e-04 - val_loss: 669.3052 - val_recon_loss: 2.5045e-04 - val_KL loss: 61.6576 - val_beta: 6.4200e-04\n",
      "Epoch 2020/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 640.4411 - recon_loss: 2.3861e-04 - KL loss: 61.5252 - beta: 6.4200e-04 - val_loss: 688.2863 - val_recon_loss: 2.5786e-04 - val_KL loss: 62.6696 - val_beta: 6.4200e-04\n",
      "Epoch 2021/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 644.8450 - recon_loss: 2.4015e-04 - KL loss: 62.1917 - beta: 6.4200e-04 - val_loss: 663.2335 - val_recon_loss: 2.4800e-04 - val_KL loss: 61.5283 - val_beta: 6.4200e-04\n",
      "Epoch 2022/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 631.8066 - recon_loss: 2.3500e-04 - KL loss: 61.6455 - beta: 6.4200e-04 - val_loss: 658.0370 - val_recon_loss: 2.4580e-04 - val_KL loss: 61.6792 - val_beta: 6.4200e-04\n",
      "Epoch 2023/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 630.9934 - recon_loss: 2.3475e-04 - KL loss: 61.4442 - beta: 6.4200e-04 - val_loss: 658.4507 - val_recon_loss: 2.4648e-04 - val_KL loss: 60.4405 - val_beta: 6.4200e-04\n",
      "Epoch 2024/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 634.8790 - recon_loss: 2.3648e-04 - KL loss: 61.1213 - beta: 6.4200e-04 - val_loss: 651.8427 - val_recon_loss: 2.4388e-04 - val_KL loss: 60.1489 - val_beta: 6.4200e-04\n",
      "Epoch 2025/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 631.8841 - recon_loss: 2.3501e-04 - KL loss: 61.6997 - beta: 6.4200e-04 - val_loss: 644.5892 - val_recon_loss: 2.4051e-04 - val_KL loss: 61.0666 - val_beta: 6.4200e-04\n",
      "Epoch 2026/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 629.9645 - recon_loss: 2.3463e-04 - KL loss: 60.7071 - beta: 6.4200e-04 - val_loss: 691.7591 - val_recon_loss: 2.6034e-04 - val_KL loss: 60.1225 - val_beta: 6.4200e-04\n",
      "Epoch 2027/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 628.4370 - recon_loss: 2.3415e-04 - KL loss: 60.3405 - beta: 6.4200e-04 - val_loss: 665.9630 - val_recon_loss: 2.4869e-04 - val_KL loss: 62.5809 - val_beta: 6.4200e-04\n",
      "Epoch 2028/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 645.5221 - recon_loss: 2.4071e-04 - KL loss: 61.5176 - beta: 6.4200e-04 - val_loss: 679.8584 - val_recon_loss: 2.5531e-04 - val_KL loss: 60.4162 - val_beta: 6.4200e-04\n",
      "Epoch 2029/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 631.7260 - recon_loss: 2.3549e-04 - KL loss: 60.3856 - beta: 6.4200e-04 - val_loss: 653.7232 - val_recon_loss: 2.4470e-04 - val_KL loss: 60.0223 - val_beta: 6.4200e-04\n",
      "Epoch 2030/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 618.8542 - recon_loss: 2.3009e-04 - KL loss: 60.5996 - beta: 6.4200e-04 - val_loss: 619.7620 - val_recon_loss: 2.3022e-04 - val_KL loss: 61.1927 - val_beta: 6.4200e-04\n",
      "Epoch 2031/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 634.5968 - recon_loss: 2.3603e-04 - KL loss: 61.9274 - beta: 6.4200e-04 - val_loss: 635.2448 - val_recon_loss: 2.3675e-04 - val_KL loss: 60.8500 - val_beta: 6.4200e-04\n",
      "Epoch 2032/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 624.7744 - recon_loss: 2.3246e-04 - KL loss: 60.7811 - beta: 6.4200e-04 - val_loss: 628.3226 - val_recon_loss: 2.3413e-04 - val_KL loss: 60.2833 - val_beta: 6.4200e-04\n",
      "Epoch 2033/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 625.7965 - recon_loss: 2.3278e-04 - KL loss: 61.0206 - beta: 6.4200e-04 - val_loss: 669.6553 - val_recon_loss: 2.5119e-04 - val_KL loss: 60.2120 - val_beta: 6.4200e-04\n",
      "Epoch 2034/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 614.3027 - recon_loss: 2.2830e-04 - KL loss: 60.4038 - beta: 6.4200e-04 - val_loss: 626.2562 - val_recon_loss: 2.3340e-04 - val_KL loss: 59.9739 - val_beta: 6.4200e-04\n",
      "Epoch 2035/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 616.7895 - recon_loss: 2.2936e-04 - KL loss: 60.3119 - beta: 6.4200e-04\n",
      "Epoch 02035: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 616.7897 - recon_loss: 2.2936e-04 - KL loss: 60.3121 - beta: 6.4200e-04 - val_loss: 630.2524 - val_recon_loss: 2.3489e-04 - val_KL loss: 60.3543 - val_beta: 6.4200e-04\n",
      "Epoch 2036/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 603.9854 - recon_loss: 2.2392e-04 - KL loss: 60.7142 - beta: 6.4200e-04 - val_loss: 631.5441 - val_recon_loss: 2.3530e-04 - val_KL loss: 60.6586 - val_beta: 6.4200e-04\n",
      "Epoch 2037/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 608.8339 - recon_loss: 2.2586e-04 - KL loss: 60.8482 - beta: 6.4200e-04 - val_loss: 621.1700 - val_recon_loss: 2.3097e-04 - val_KL loss: 60.7896 - val_beta: 6.4200e-04\n",
      "Epoch 2038/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 605.4194 - recon_loss: 2.2446e-04 - KL loss: 60.8331 - beta: 6.4200e-04 - val_loss: 616.2094 - val_recon_loss: 2.2909e-04 - val_KL loss: 60.3813 - val_beta: 6.4200e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2039/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 606.7377 - recon_loss: 2.2510e-04 - KL loss: 60.5946 - beta: 6.4200e-04 - val_loss: 613.5389 - val_recon_loss: 2.2814e-04 - val_KL loss: 60.0207 - val_beta: 6.4200e-04\n",
      "Epoch 2040/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 602.9439 - recon_loss: 2.2359e-04 - KL loss: 60.4600 - beta: 6.4200e-04 - val_loss: 621.3095 - val_recon_loss: 2.3131e-04 - val_KL loss: 60.1045 - val_beta: 6.4200e-04\n",
      "Epoch 2041/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 598.6868 - recon_loss: 2.2181e-04 - KL loss: 60.5287 - beta: 6.4200e-04 - val_loss: 610.0280 - val_recon_loss: 2.2668e-04 - val_KL loss: 60.0490 - val_beta: 6.4200e-04\n",
      "Epoch 2042/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 610.5555 - recon_loss: 2.2670e-04 - KL loss: 60.5259 - beta: 6.4200e-04 - val_loss: 605.5878 - val_recon_loss: 2.2480e-04 - val_KL loss: 60.1737 - val_beta: 6.4200e-04\n",
      "Epoch 2043/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 598.9457 - recon_loss: 2.2188e-04 - KL loss: 60.6266 - beta: 6.4200e-04 - val_loss: 603.1813 - val_recon_loss: 2.2363e-04 - val_KL loss: 60.6166 - val_beta: 6.4200e-04\n",
      "Epoch 2044/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 605.6510 - recon_loss: 2.2463e-04 - KL loss: 60.6617 - beta: 6.4200e-04 - val_loss: 610.9745 - val_recon_loss: 2.2677e-04 - val_KL loss: 60.7767 - val_beta: 6.4200e-04\n",
      "Epoch 2045/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 600.1195 - recon_loss: 2.2220e-04 - KL loss: 61.0115 - beta: 6.4200e-04 - val_loss: 611.8819 - val_recon_loss: 2.2705e-04 - val_KL loss: 61.0204 - val_beta: 6.4200e-04\n",
      "Epoch 2046/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 598.1662 - recon_loss: 2.2141e-04 - KL loss: 60.9708 - beta: 6.4200e-04 - val_loss: 610.4225 - val_recon_loss: 2.2645e-04 - val_KL loss: 61.0141 - val_beta: 6.4200e-04\n",
      "Epoch 2047/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 603.5259 - recon_loss: 2.2357e-04 - KL loss: 61.1075 - beta: 6.4200e-04 - val_loss: 609.4118 - val_recon_loss: 2.2613e-04 - val_KL loss: 60.7784 - val_beta: 6.4200e-04\n",
      "Epoch 2048/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 605.0404 - recon_loss: 2.2429e-04 - KL loss: 60.8603 - beta: 6.4200e-04 ETA: 0s - loss: 605.0628 - recon_loss: 2.2430e-04 - KL loss: 60.8619 - beta\n",
      "Epoch 02048: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 605.0353 - recon_loss: 2.2429e-04 - KL loss: 60.8599 - beta: 6.4200e-04 - val_loss: 625.6660 - val_recon_loss: 2.3307e-04 - val_KL loss: 60.1872 - val_beta: 6.4200e-04\n",
      "Epoch 2049/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 598.8014 - recon_loss: 2.2191e-04 - KL loss: 60.4029 - beta: 6.4200e-04 - val_loss: 618.3704 - val_recon_loss: 2.2959e-04 - val_KL loss: 61.3257 - val_beta: 6.4200e-04\n",
      "Epoch 2050/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 599.3711 - recon_loss: 2.2196e-04 - KL loss: 60.8602 - beta: 6.4200e-04 - val_loss: 611.7270 - val_recon_loss: 2.2701e-04 - val_KL loss: 60.9473 - val_beta: 6.4200e-04\n",
      "Epoch 2051/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 595.2656 - recon_loss: 2.2021e-04 - KL loss: 60.9860 - beta: 6.4200e-04 - val_loss: 622.8306 - val_recon_loss: 2.3160e-04 - val_KL loss: 60.9254 - val_beta: 6.4200e-04\n",
      "Epoch 2052/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 593.5576 - recon_loss: 2.1952e-04 - KL loss: 60.9482 - beta: 6.4200e-04 - val_loss: 613.6921 - val_recon_loss: 2.2803e-04 - val_KL loss: 60.4382 - val_beta: 6.4200e-04\n",
      "Epoch 2053/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 594.6403 - recon_loss: 2.2009e-04 - KL loss: 60.6544 - beta: 6.4200e-04\n",
      "Epoch 02053: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 594.6412 - recon_loss: 2.2009e-04 - KL loss: 60.6545 - beta: 6.4200e-04 - val_loss: 609.5894 - val_recon_loss: 2.2613e-04 - val_KL loss: 60.9395 - val_beta: 6.4200e-04\n",
      "Epoch 2053/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 441.4794 - recon_loss: 2.3990e-04 - KL loss: 56.4360 - beta: 7.8934e-04 - val_loss: 471.1489 - val_recon_loss: 2.6011e-04 - val_KL loss: 53.6665 - val_beta: 7.8934e-04\n",
      "Epoch 2054/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 460.7850 - recon_loss: 2.5377e-04 - KL loss: 53.4907 - beta: 7.8934e-04 - val_loss: 454.5560 - val_recon_loss: 2.5036e-04 - val_KL loss: 52.7198 - val_beta: 7.8934e-04\n",
      "Epoch 2055/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 466.8388 - recon_loss: 2.5774e-04 - KL loss: 53.1624 - beta: 7.8934e-04 - val_loss: 545.1135 - val_recon_loss: 3.0616e-04 - val_KL loss: 53.7220 - val_beta: 7.8934e-04\n",
      "Epoch 2056/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 471.6375 - recon_loss: 2.6061e-04 - KL loss: 53.3586 - beta: 7.8934e-04 - val_loss: 567.4275 - val_recon_loss: 3.2020e-04 - val_KL loss: 53.4992 - val_beta: 7.8934e-04\n",
      "Epoch 2057/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 485.6409 - recon_loss: 2.6865e-04 - KL loss: 54.4524 - beta: 7.8934e-04 - val_loss: 490.3069 - val_recon_loss: 2.7270e-04 - val_KL loss: 52.6189 - val_beta: 7.8934e-04\n",
      "Epoch 2058/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 467.7759 - recon_loss: 2.5847e-04 - KL loss: 52.9305 - beta: 7.8934e-04 - val_loss: 465.8530 - val_recon_loss: 2.5854e-04 - val_KL loss: 50.8904 - val_beta: 7.8934e-04\n",
      "Epoch 2059/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 452.8806 - recon_loss: 2.4976e-04 - KL loss: 52.0120 - beta: 7.8934e-04\n",
      "Epoch 02059: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 452.8940 - recon_loss: 2.4977e-04 - KL loss: 52.0130 - beta: 7.8934e-04 - val_loss: 503.9466 - val_recon_loss: 2.8156e-04 - val_KL loss: 52.0471 - val_beta: 7.8934e-04\n",
      "Epoch 2060/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 439.4171 - recon_loss: 2.4068e-04 - KL loss: 53.1239 - beta: 7.8934e-04 - val_loss: 520.0833 - val_recon_loss: 2.9103e-04 - val_KL loss: 52.9731 - val_beta: 7.8934e-04\n",
      "Epoch 2061/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 428.5488 - recon_loss: 2.3429e-04 - KL loss: 52.5161 - beta: 7.8934e-04 - val_loss: 453.1608 - val_recon_loss: 2.4990e-04 - val_KL loss: 52.0764 - val_beta: 7.8934e-04\n",
      "Epoch 2062/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 429.1937 - recon_loss: 2.3503e-04 - KL loss: 51.9734 - beta: 7.8934e-04 - val_loss: 432.2984 - val_recon_loss: 2.3734e-04 - val_KL loss: 51.3744 - val_beta: 7.8934e-04\n",
      "Epoch 2063/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 420.0736 - recon_loss: 2.2939e-04 - KL loss: 51.9081 - beta: 7.8934e-04 - val_loss: 428.6320 - val_recon_loss: 2.3446e-04 - val_KL loss: 52.3241 - val_beta: 7.8934e-04\n",
      "Epoch 2064/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 419.1311 - recon_loss: 2.2866e-04 - KL loss: 52.1362 - beta: 7.8934e-04 - val_loss: 439.3380 - val_recon_loss: 2.4160e-04 - val_KL loss: 51.5681 - val_beta: 7.8934e-04\n",
      "Epoch 2065/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 424.8148 - recon_loss: 2.3228e-04 - KL loss: 52.0107 - beta: 7.8934e-04 - val_loss: 448.2979 - val_recon_loss: 2.4726e-04 - val_KL loss: 51.4398 - val_beta: 7.8934e-04\n",
      "Epoch 2066/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 421.6691 - recon_loss: 2.3030e-04 - KL loss: 52.0425 - beta: 7.8934e-04 - val_loss: 463.6056 - val_recon_loss: 2.5585e-04 - val_KL loss: 52.9667 - val_beta: 7.8934e-04\n",
      "Epoch 2067/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 421.3798 - recon_loss: 2.3014e-04 - KL loss: 52.0003 - beta: 7.8934e-04 - val_loss: 455.2685 - val_recon_loss: 2.5123e-04 - val_KL loss: 52.0503 - val_beta: 7.8934e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2068/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 419.0322 - recon_loss: 2.2869e-04 - KL loss: 51.9871 - beta: 7.8934e-04\n",
      "Epoch 02068: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 419.0307 - recon_loss: 2.2869e-04 - KL loss: 51.9870 - beta: 7.8934e-04 - val_loss: 445.6371 - val_recon_loss: 2.4577e-04 - val_KL loss: 51.1806 - val_beta: 7.8934e-04\n",
      "Epoch 2069/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 414.2454 - recon_loss: 2.2589e-04 - KL loss: 51.6923 - beta: 7.8934e-04 - val_loss: 478.1470 - val_recon_loss: 2.6511e-04 - val_KL loss: 52.6443 - val_beta: 7.8934e-04\n",
      "Epoch 2070/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 412.1105 - recon_loss: 2.2433e-04 - KL loss: 52.0634 - beta: 7.8934e-04 - val_loss: 414.8862 - val_recon_loss: 2.2630e-04 - val_KL loss: 51.6794 - val_beta: 7.8934e-04\n",
      "Epoch 2071/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 410.6930 - recon_loss: 2.2350e-04 - KL loss: 51.9774 - beta: 7.8934e-04 - val_loss: 429.9258 - val_recon_loss: 2.3534e-04 - val_KL loss: 52.1992 - val_beta: 7.8934e-04\n",
      "Epoch 2072/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 409.2284 - recon_loss: 2.2264e-04 - KL loss: 51.8940 - beta: 7.8934e-04 - val_loss: 422.9400 - val_recon_loss: 2.3081e-04 - val_KL loss: 52.4854 - val_beta: 7.8934e-04\n",
      "Epoch 2073/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 405.9559 - recon_loss: 2.2065e-04 - KL loss: 51.8120 - beta: 7.8934e-04 - val_loss: 423.2522 - val_recon_loss: 2.3172e-04 - val_KL loss: 51.3386 - val_beta: 7.8934e-04\n",
      "Epoch 2074/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 412.5202 - recon_loss: 2.2479e-04 - KL loss: 51.7344 - beta: 7.8934e-04 - val_loss: 424.1054 - val_recon_loss: 2.3204e-04 - val_KL loss: 51.6875 - val_beta: 7.8934e-04\n",
      "Epoch 2075/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 405.9117 - recon_loss: 2.2066e-04 - KL loss: 51.7553 - beta: 7.8934e-04\n",
      "Epoch 02075: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 405.9125 - recon_loss: 2.2066e-04 - KL loss: 51.7554 - beta: 7.8934e-04 - val_loss: 435.8511 - val_recon_loss: 2.3930e-04 - val_KL loss: 51.7692 - val_beta: 7.8934e-04\n",
      "Epoch 2076/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 411.2182 - recon_loss: 2.2380e-04 - KL loss: 52.0137 - beta: 7.8934e-04 - val_loss: 428.4477 - val_recon_loss: 2.3467e-04 - val_KL loss: 51.8004 - val_beta: 7.8934e-04\n",
      "Epoch 2077/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 406.0205 - recon_loss: 2.2065e-04 - KL loss: 51.8707 - beta: 7.8934e-04 - val_loss: 419.4860 - val_recon_loss: 2.2923e-04 - val_KL loss: 51.5786 - val_beta: 7.8934e-04\n",
      "Epoch 2078/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 409.0683 - recon_loss: 2.2246e-04 - KL loss: 52.0211 - beta: 7.8934e-04 - val_loss: 417.0303 - val_recon_loss: 2.2756e-04 - val_KL loss: 51.7894 - val_beta: 7.8934e-04\n",
      "Epoch 2079/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 404.1731 - recon_loss: 2.1950e-04 - KL loss: 51.8750 - beta: 7.8934e-04 - val_loss: 428.0745 - val_recon_loss: 2.3455e-04 - val_KL loss: 51.6192 - val_beta: 7.8934e-04\n",
      "Epoch 2080/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 405.5275 - recon_loss: 2.2041e-04 - KL loss: 51.7689 - beta: 7.8934e-04\n",
      "Epoch 02080: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 405.5298 - recon_loss: 2.2041e-04 - KL loss: 51.7690 - beta: 7.8934e-04 - val_loss: 420.2778 - val_recon_loss: 2.2972e-04 - val_KL loss: 51.5803 - val_beta: 7.8934e-04\n",
      "Epoch 2080/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 306.9198 - recon_loss: 2.4396e-04 - KL loss: 47.8984 - beta: 9.7048e-04 - val_loss: 314.7930 - val_recon_loss: 2.5310e-04 - val_KL loss: 46.0648 - val_beta: 9.7048e-04\n",
      "Epoch 2081/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 308.9649 - recon_loss: 2.4773e-04 - KL loss: 45.9383 - beta: 9.7048e-04 - val_loss: 333.9068 - val_recon_loss: 2.7075e-04 - val_KL loss: 46.4389 - val_beta: 9.7048e-04\n",
      "Epoch 2082/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 320.2750 - recon_loss: 2.5850e-04 - KL loss: 45.8117 - beta: 9.7048e-04 - val_loss: 420.1098 - val_recon_loss: 3.4950e-04 - val_KL loss: 49.0238 - val_beta: 9.7048e-04\n",
      "Epoch 2083/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 332.5480 - recon_loss: 2.6962e-04 - KL loss: 46.2727 - beta: 9.7048e-04 - val_loss: 346.1312 - val_recon_loss: 2.8345e-04 - val_KL loss: 45.1800 - val_beta: 9.7048e-04\n",
      "Epoch 2084/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 313.7809 - recon_loss: 2.5339e-04 - KL loss: 44.7384 - beta: 9.7048e-04 - val_loss: 355.6623 - val_recon_loss: 2.9048e-04 - val_KL loss: 47.2427 - val_beta: 9.7048e-04\n",
      "Epoch 2085/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 322.5096 - recon_loss: 2.6124e-04 - KL loss: 45.1351 - beta: 9.7048e-04\n",
      "Epoch 02085: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 322.5036 - recon_loss: 2.6124e-04 - KL loss: 45.1341 - beta: 9.7048e-04 - val_loss: 351.1559 - val_recon_loss: 2.8820e-04 - val_KL loss: 45.1620 - val_beta: 9.7048e-04\n",
      "Epoch 2086/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 315.1160 - recon_loss: 2.5423e-04 - KL loss: 45.1896 - beta: 9.7048e-04 - val_loss: 332.0012 - val_recon_loss: 2.6996e-04 - val_KL loss: 45.3750 - val_beta: 9.7048e-04\n",
      "Epoch 2087/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 299.5683 - recon_loss: 2.3997e-04 - KL loss: 44.7743 - beta: 9.7048e-04 - val_loss: 351.4257 - val_recon_loss: 2.8886e-04 - val_KL loss: 44.7264 - val_beta: 9.7048e-04\n",
      "Epoch 2088/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 297.9763 - recon_loss: 2.3834e-04 - KL loss: 44.9216 - beta: 9.7048e-04 - val_loss: 315.8793 - val_recon_loss: 2.5596e-04 - val_KL loss: 44.1146 - val_beta: 9.7048e-04\n",
      "Epoch 2089/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 294.0164 - recon_loss: 2.3482e-04 - KL loss: 44.6909 - beta: 9.7048e-04 - val_loss: 322.5238 - val_recon_loss: 2.6121e-04 - val_KL loss: 45.1824 - val_beta: 9.7048e-04\n",
      "Epoch 2090/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 294.9545 - recon_loss: 2.3564e-04 - KL loss: 44.7611 - beta: 9.7048e-04 - val_loss: 305.2435 - val_recon_loss: 2.4568e-04 - val_KL loss: 44.3953 - val_beta: 9.7048e-04\n",
      "Epoch 2091/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 291.9892 - recon_loss: 2.3333e-04 - KL loss: 44.2489 - beta: 9.7048e-04 - val_loss: 305.5656 - val_recon_loss: 2.4667e-04 - val_KL loss: 43.6592 - val_beta: 9.7048e-04\n",
      "Epoch 2092/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 293.1025 - recon_loss: 2.3460e-04 - KL loss: 44.0163 - beta: 9.7048e-04 - val_loss: 293.7581 - val_recon_loss: 2.3698e-04 - val_KL loss: 42.1458 - val_beta: 9.7048e-04\n",
      "Epoch 2093/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 292.8260 - recon_loss: 2.3501e-04 - KL loss: 43.3009 - beta: 9.7048e-04 - val_loss: 295.6318 - val_recon_loss: 2.3832e-04 - val_KL loss: 42.5910 - val_beta: 9.7048e-04\n",
      "Epoch 2094/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 296.3673 - recon_loss: 2.3849e-04 - KL loss: 43.1483 - beta: 9.7048e-04 - val_loss: 306.0511 - val_recon_loss: 2.4739e-04 - val_KL loss: 43.3821 - val_beta: 9.7048e-04\n",
      "Epoch 2095/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 295.4027 - recon_loss: 2.3778e-04 - KL loss: 42.9426 - beta: 9.7048e-04 - val_loss: 289.1039 - val_recon_loss: 2.3155e-04 - val_KL loss: 43.2580 - val_beta: 9.7048e-04\n",
      "Epoch 2096/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 289.0877 - recon_loss: 2.3158e-04 - KL loss: 43.2108 - beta: 9.7048e-04 - val_loss: 287.0504 - val_recon_loss: 2.3007e-04 - val_KL loss: 42.7768 - val_beta: 9.7048e-04\n",
      "Epoch 2097/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 290.0703 - recon_loss: 2.3249e-04 - KL loss: 43.2249 - beta: 9.7048e-04 - val_loss: 299.6321 - val_recon_loss: 2.4182e-04 - val_KL loss: 42.8801 - val_beta: 9.7048e-04\n",
      "Epoch 2098/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 295.3551 - recon_loss: 2.3719e-04 - KL loss: 43.5156 - beta: 9.7048e-04 - val_loss: 299.8981 - val_recon_loss: 2.4181e-04 - val_KL loss: 43.1593 - val_beta: 9.7048e-04\n",
      "Epoch 2099/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 286.8072 - recon_loss: 2.2937e-04 - KL loss: 43.2682 - beta: 9.7048e-04 - val_loss: 295.2222 - val_recon_loss: 2.3813e-04 - val_KL loss: 42.3879 - val_beta: 9.7048e-04\n",
      "Epoch 2100/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 288.3956 - recon_loss: 2.3108e-04 - KL loss: 43.0474 - beta: 9.7048e-04 - val_loss: 302.8926 - val_recon_loss: 2.4537e-04 - val_KL loss: 42.3651 - val_beta: 9.7048e-04\n",
      "Epoch 2101/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 286.6625 - recon_loss: 2.2948e-04 - KL loss: 43.0113 - beta: 9.7048e-04\n",
      "Epoch 02101: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 286.6644 - recon_loss: 2.2948e-04 - KL loss: 43.0115 - beta: 9.7048e-04 - val_loss: 305.3318 - val_recon_loss: 2.4765e-04 - val_KL loss: 42.3878 - val_beta: 9.7048e-04\n",
      "Epoch 2102/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 289.3687 - recon_loss: 2.3185e-04 - KL loss: 43.1979 - beta: 9.7048e-04 - val_loss: 293.5805 - val_recon_loss: 2.3511e-04 - val_KL loss: 43.9556 - val_beta: 9.7048e-04\n",
      "Epoch 2103/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 284.1955 - recon_loss: 2.2674e-04 - KL loss: 43.4490 - beta: 9.7048e-04 - val_loss: 294.7577 - val_recon_loss: 2.3645e-04 - val_KL loss: 43.7113 - val_beta: 9.7048e-04\n",
      "Epoch 2104/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 283.8969 - recon_loss: 2.2653e-04 - KL loss: 43.3791 - beta: 9.7048e-04 - val_loss: 293.5081 - val_recon_loss: 2.3569e-04 - val_KL loss: 43.2592 - val_beta: 9.7048e-04\n",
      "Epoch 2105/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 282.9220 - recon_loss: 2.2575e-04 - KL loss: 43.2332 - beta: 9.7048e-04 - val_loss: 291.4309 - val_recon_loss: 2.3376e-04 - val_KL loss: 43.2392 - val_beta: 9.7048e-04\n",
      "Epoch 2106/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 284.3459 - recon_loss: 2.2684e-04 - KL loss: 43.4980 - beta: 9.7048e-04\n",
      "Epoch 02106: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 284.3450 - recon_loss: 2.2684e-04 - KL loss: 43.4980 - beta: 9.7048e-04 - val_loss: 290.1634 - val_recon_loss: 2.3230e-04 - val_KL loss: 43.5156 - val_beta: 9.7048e-04\n",
      "Epoch 2106/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 212.2906 - recon_loss: 2.4502e-04 - KL loss: 40.1938 - beta: 0.0012 - val_loss: 273.3621 - val_recon_loss: 3.2910e-04 - val_KL loss: 42.2081 - val_beta: 0.0012\n",
      "Epoch 2107/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 229.1859 - recon_loss: 2.7078e-04 - KL loss: 38.9946 - beta: 0.0012 - val_loss: 233.4137 - val_recon_loss: 2.8049e-04 - val_KL loss: 36.4063 - val_beta: 0.0012\n",
      "Epoch 2108/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 214.2310 - recon_loss: 2.5037e-04 - KL loss: 38.3781 - beta: 0.0012 - val_loss: 227.4236 - val_recon_loss: 2.6717e-04 - val_KL loss: 39.7725 - val_beta: 0.0012\n",
      "Epoch 2109/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 218.0280 - recon_loss: 2.5562e-04 - KL loss: 38.4848 - beta: 0.0012 - val_loss: 241.7346 - val_recon_loss: 2.8946e-04 - val_KL loss: 38.4237 - val_beta: 0.0012\n",
      "Epoch 2110/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 235.2527 - recon_loss: 2.8076e-04 - KL loss: 38.0546 - beta: 0.0012 - val_loss: 218.2933 - val_recon_loss: 2.5753e-04 - val_KL loss: 37.4086 - val_beta: 0.0012\n",
      "Epoch 2111/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 224.6925 - recon_loss: 2.6588e-04 - KL loss: 37.9413 - beta: 0.0012 - val_loss: 234.7446 - val_recon_loss: 2.8069e-04 - val_KL loss: 37.5969 - val_beta: 0.0012\n",
      "Epoch 2112/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 219.6203 - recon_loss: 2.5912e-04 - KL loss: 37.6204 - beta: 0.0012 - val_loss: 237.9570 - val_recon_loss: 2.8552e-04 - val_KL loss: 37.4154 - val_beta: 0.0012\n",
      "Epoch 2113/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 224.7110 - recon_loss: 2.6587e-04 - KL loss: 37.9725 - beta: 0.0012 - val_loss: 241.1627 - val_recon_loss: 2.8969e-04 - val_KL loss: 37.6919 - val_beta: 0.0012\n",
      "Epoch 2114/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 239.1981 - recon_loss: 2.8498e-04 - KL loss: 39.0314 - beta: 0.0012 - val_loss: 276.5092 - val_recon_loss: 3.3652e-04 - val_KL loss: 40.1461 - val_beta: 0.0012\n",
      "Epoch 2115/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 244.0379 - recon_loss: 2.9132e-04 - KL loss: 39.4216 - beta: 0.0012\n",
      "Epoch 02115: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 244.0371 - recon_loss: 2.9132e-04 - KL loss: 39.4216 - beta: 0.0012 - val_loss: 260.8202 - val_recon_loss: 3.1586e-04 - val_KL loss: 38.9678 - val_beta: 0.0012\n",
      "Epoch 2116/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 226.5676 - recon_loss: 2.6766e-04 - KL loss: 38.5666 - beta: 0.0012 - val_loss: 238.2328 - val_recon_loss: 2.8364e-04 - val_KL loss: 39.0090 - val_beta: 0.0012\n",
      "Epoch 2117/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 217.0701 - recon_loss: 2.5430e-04 - KL loss: 38.4525 - beta: 0.0012 - val_loss: 246.2007 - val_recon_loss: 2.9561e-04 - val_KL loss: 38.5729 - val_beta: 0.0012\n",
      "Epoch 2118/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 215.1599 - recon_loss: 2.5237e-04 - KL loss: 37.9037 - beta: 0.0012 - val_loss: 229.8888 - val_recon_loss: 2.7458e-04 - val_KL loss: 37.0330 - val_beta: 0.0012\n",
      "Epoch 2119/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 210.0974 - recon_loss: 2.4557e-04 - KL loss: 37.6140 - beta: 0.0012 - val_loss: 234.9191 - val_recon_loss: 2.8157e-04 - val_KL loss: 37.1511 - val_beta: 0.0012\n",
      "Epoch 2120/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 212.0825 - recon_loss: 2.4838e-04 - KL loss: 37.6285 - beta: 0.0012\n",
      "Epoch 02120: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 212.0849 - recon_loss: 2.4838e-04 - KL loss: 37.6287 - beta: 0.0012 - val_loss: 253.0858 - val_recon_loss: 3.0727e-04 - val_KL loss: 37.2664 - val_beta: 0.0012\n",
      "Epoch 2120/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 153.5814 - recon_loss: 2.5460e-04 - KL loss: 35.2853 - beta: 0.0015 - val_loss: 191.3153 - val_recon_loss: 3.3680e-04 - val_KL loss: 34.8228 - val_beta: 0.0015\n",
      "Epoch 2121/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 161.6857 - recon_loss: 2.7289e-04 - KL loss: 34.8901 - beta: 0.0015 - val_loss: 177.3004 - val_recon_loss: 3.0694e-04 - val_KL loss: 34.6839 - val_beta: 0.0015\n",
      "Epoch 2122/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 166.6201 - recon_loss: 2.8349e-04 - KL loss: 34.8970 - beta: 0.0015 - val_loss: 186.7707 - val_recon_loss: 3.3021e-04 - val_KL loss: 33.3409 - val_beta: 0.0015\n",
      "Epoch 2123/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 168.8372 - recon_loss: 2.8901e-04 - KL loss: 34.5504 - beta: 0.0015 - val_loss: 188.4032 - val_recon_loss: 3.3417e-04 - val_KL loss: 33.1344 - val_beta: 0.0015\n",
      "Epoch 2124/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 158.1741 - recon_loss: 2.6910e-04 - KL loss: 33.1409 - beta: 0.0015 - val_loss: 172.6181 - val_recon_loss: 3.0025e-04 - val_KL loss: 33.1100 - val_beta: 0.0015\n",
      "Epoch 2125/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 156.5068 - recon_loss: 2.6480e-04 - KL loss: 33.4692 - beta: 0.0015 - val_loss: 168.2354 - val_recon_loss: 2.9299e-04 - val_KL loss: 32.1015 - val_beta: 0.0015\n",
      "Epoch 2126/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 158.5197 - recon_loss: 2.6969e-04 - KL loss: 33.2122 - beta: 0.0015 - val_loss: 162.7173 - val_recon_loss: 2.7932e-04 - val_KL loss: 32.9317 - val_beta: 0.0015\n",
      "Epoch 2127/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 159.7819 - recon_loss: 2.7283e-04 - KL loss: 33.0139 - beta: 0.0015 - val_loss: 155.5022 - val_recon_loss: 2.6576e-04 - val_KL loss: 32.0184 - val_beta: 0.0015\n",
      "Epoch 2128/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 153.7319 - recon_loss: 2.6047e-04 - KL loss: 32.7080 - beta: 0.0015 - val_loss: 156.5967 - val_recon_loss: 2.6933e-04 - val_KL loss: 31.4528 - val_beta: 0.0015\n",
      "Epoch 2129/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 151.4945 - recon_loss: 2.5666e-04 - KL loss: 32.2401 - beta: 0.0015 - val_loss: 162.4326 - val_recon_loss: 2.8099e-04 - val_KL loss: 31.8721 - val_beta: 0.0015\n",
      "Epoch 2130/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 151.2232 - recon_loss: 2.5675e-04 - KL loss: 31.9254 - beta: 0.0015 - val_loss: 164.5035 - val_recon_loss: 2.8458e-04 - val_KL loss: 32.2763 - val_beta: 0.0015\n",
      "Epoch 2131/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 155.5286 - recon_loss: 2.6501e-04 - KL loss: 32.3952 - beta: 0.0015 - val_loss: 163.9198 - val_recon_loss: 2.8329e-04 - val_KL loss: 32.2917 - val_beta: 0.0015\n",
      "Epoch 2132/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 152.7681 - recon_loss: 2.5928e-04 - KL loss: 32.2963 - beta: 0.0015\n",
      "Epoch 02132: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 152.7684 - recon_loss: 2.5928e-04 - KL loss: 32.2963 - beta: 0.0015 - val_loss: 170.3371 - val_recon_loss: 2.9819e-04 - val_KL loss: 31.7837 - val_beta: 0.0015\n",
      "Epoch 2133/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 145.3788 - recon_loss: 2.4407e-04 - KL loss: 31.9743 - beta: 0.0015 - val_loss: 153.9165 - val_recon_loss: 2.6307e-04 - val_KL loss: 31.6836 - val_beta: 0.0015\n",
      "Epoch 2134/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 143.9411 - recon_loss: 2.4091e-04 - KL loss: 32.0022 - beta: 0.0015 - val_loss: 158.9200 - val_recon_loss: 2.7320e-04 - val_KL loss: 31.9784 - val_beta: 0.0015\n",
      "Epoch 2135/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 142.4086 - recon_loss: 2.3732e-04 - KL loss: 32.1387 - beta: 0.0015 - val_loss: 152.4795 - val_recon_loss: 2.5924e-04 - val_KL loss: 32.0272 - val_beta: 0.0015\n",
      "Epoch 2136/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 143.5076 - recon_loss: 2.3999e-04 - KL loss: 31.9998 - beta: 0.0015 - val_loss: 153.6441 - val_recon_loss: 2.6167e-04 - val_KL loss: 32.0597 - val_beta: 0.0015\n",
      "Epoch 2137/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 143.7617 - recon_loss: 2.4078e-04 - KL loss: 31.8863 - beta: 0.0015 - val_loss: 154.5166 - val_recon_loss: 2.6467e-04 - val_KL loss: 31.5378 - val_beta: 0.0015\n",
      "Epoch 2138/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 144.3229 - recon_loss: 2.4173e-04 - KL loss: 32.0045 - beta: 0.0015 - val_loss: 148.6165 - val_recon_loss: 2.5107e-04 - val_KL loss: 31.9582 - val_beta: 0.0015\n",
      "Epoch 2139/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 142.5472 - recon_loss: 2.3711e-04 - KL loss: 32.3781 - beta: 0.0015 - val_loss: 148.9700 - val_recon_loss: 2.5125e-04 - val_KL loss: 32.2264 - val_beta: 0.0015\n",
      "Epoch 2140/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 145.6292 - recon_loss: 2.4333e-04 - KL loss: 32.5662 - beta: 0.0015 - val_loss: 162.8497 - val_recon_loss: 2.8163e-04 - val_KL loss: 31.9949 - val_beta: 0.0015\n",
      "Epoch 2141/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 142.1249 - recon_loss: 2.3689e-04 - KL loss: 32.0576 - beta: 0.0015 - val_loss: 150.9082 - val_recon_loss: 2.5623e-04 - val_KL loss: 31.8533 - val_beta: 0.0015\n",
      "Epoch 2142/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 141.5461 - recon_loss: 2.3555e-04 - KL loss: 32.0979 - beta: 0.0015 - val_loss: 160.4704 - val_recon_loss: 2.7428e-04 - val_KL loss: 33.0264 - val_beta: 0.0015\n",
      "Epoch 2143/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 148.3977 - recon_loss: 2.5058e-04 - KL loss: 31.9660 - beta: 0.0015\n",
      "Epoch 02143: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 148.3956 - recon_loss: 2.5058e-04 - KL loss: 31.9660 - beta: 0.0015 - val_loss: 152.2291 - val_recon_loss: 2.5851e-04 - val_KL loss: 32.1138 - val_beta: 0.0015\n",
      "Epoch 2144/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 140.2553 - recon_loss: 2.3324e-04 - KL loss: 31.8803 - beta: 0.0015 - val_loss: 151.2322 - val_recon_loss: 2.5732e-04 - val_KL loss: 31.6689 - val_beta: 0.0015\n",
      "Epoch 2145/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 139.9054 - recon_loss: 2.3277e-04 - KL loss: 31.7525 - beta: 0.0015 - val_loss: 151.5372 - val_recon_loss: 2.5780e-04 - val_KL loss: 31.7546 - val_beta: 0.0015\n",
      "Epoch 2146/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 140.2495 - recon_loss: 2.3297e-04 - KL loss: 32.0041 - beta: 0.0015 - val_loss: 153.3094 - val_recon_loss: 2.6184e-04 - val_KL loss: 31.6490 - val_beta: 0.0015\n",
      "Epoch 2147/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 138.2861 - recon_loss: 2.2889e-04 - KL loss: 31.9334 - beta: 0.0015 - val_loss: 147.3538 - val_recon_loss: 2.4854e-04 - val_KL loss: 31.8723 - val_beta: 0.0015\n",
      "Epoch 2148/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 139.3053 - recon_loss: 2.3106e-04 - KL loss: 31.9446 - beta: 0.0015 - val_loss: 148.4518 - val_recon_loss: 2.5123e-04 - val_KL loss: 31.7181 - val_beta: 0.0015\n",
      "Epoch 2149/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 140.2765 - recon_loss: 2.3292e-04 - KL loss: 32.0512 - beta: 0.0015 - val_loss: 151.1905 - val_recon_loss: 2.5725e-04 - val_KL loss: 31.6605 - val_beta: 0.0015\n",
      "Epoch 2150/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 137.9962 - recon_loss: 2.2824e-04 - KL loss: 31.9458 - beta: 0.0015 - val_loss: 149.4046 - val_recon_loss: 2.5355e-04 - val_KL loss: 31.5950 - val_beta: 0.0015\n",
      "Epoch 2151/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 138.1751 - recon_loss: 2.2829e-04 - KL loss: 32.1005 - beta: 0.0015 - val_loss: 147.3778 - val_recon_loss: 2.4873e-04 - val_KL loss: 31.8056 - val_beta: 0.0015\n",
      "Epoch 2152/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 139.3678 - recon_loss: 2.3109e-04 - KL loss: 31.9914 - beta: 0.0015\n",
      "Epoch 02152: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 139.3677 - recon_loss: 2.3109e-04 - KL loss: 31.9915 - beta: 0.0015 - val_loss: 147.5368 - val_recon_loss: 2.4866e-04 - val_KL loss: 31.9977 - val_beta: 0.0015\n",
      "Epoch 2153/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 137.2491 - recon_loss: 2.2648e-04 - KL loss: 32.0182 - beta: 0.0015 - val_loss: 149.0290 - val_recon_loss: 2.5210e-04 - val_KL loss: 31.8939 - val_beta: 0.0015\n",
      "Epoch 2154/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 138.4206 - recon_loss: 2.2903e-04 - KL loss: 32.0036 - beta: 0.0015 - val_loss: 146.1028 - val_recon_loss: 2.4597e-04 - val_KL loss: 31.8139 - val_beta: 0.0015\n",
      "Epoch 2155/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 137.1494 - recon_loss: 2.2628e-04 - KL loss: 32.0106 - beta: 0.0015 - val_loss: 145.8327 - val_recon_loss: 2.4470e-04 - val_KL loss: 32.1353 - val_beta: 0.0015\n",
      "Epoch 2156/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 138.6799 - recon_loss: 2.2954e-04 - KL loss: 32.0245 - beta: 0.0015 - val_loss: 145.7807 - val_recon_loss: 2.4525e-04 - val_KL loss: 31.8255 - val_beta: 0.0015\n",
      "Epoch 2157/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 137.0712 - recon_loss: 2.2619e-04 - KL loss: 31.9715 - beta: 0.0015 - val_loss: 148.0444 - val_recon_loss: 2.5007e-04 - val_KL loss: 31.8506 - val_beta: 0.0015\n",
      "Epoch 2158/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 138.7074 - recon_loss: 2.2962e-04 - KL loss: 32.0186 - beta: 0.0015 - val_loss: 149.3170 - val_recon_loss: 2.5189e-04 - val_KL loss: 32.2791 - val_beta: 0.0015\n",
      "Epoch 2159/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 138.1463 - recon_loss: 2.2831e-04 - KL loss: 32.0617 - beta: 0.0015 - val_loss: 147.0474 - val_recon_loss: 2.4743e-04 - val_KL loss: 32.0825 - val_beta: 0.0015\n",
      "Epoch 2160/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 138.7181 - recon_loss: 2.2939e-04 - KL loss: 32.1321 - beta: 0.0015 - val_loss: 146.5484 - val_recon_loss: 2.4686e-04 - val_KL loss: 31.8452 - val_beta: 0.0015\n",
      "Epoch 2161/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 136.0195 - recon_loss: 2.2391e-04 - KL loss: 31.9821 - beta: 0.0015 - val_loss: 145.4445 - val_recon_loss: 2.4444e-04 - val_KL loss: 31.8652 - val_beta: 0.0015\n",
      "Epoch 2162/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 137.1415 - recon_loss: 2.2615e-04 - KL loss: 32.0614 - beta: 0.0015 - val_loss: 144.7056 - val_recon_loss: 2.4250e-04 - val_KL loss: 32.0313 - val_beta: 0.0015\n",
      "Epoch 2163/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 138.7133 - recon_loss: 2.2969e-04 - KL loss: 31.9892 - beta: 0.0015 - val_loss: 145.7376 - val_recon_loss: 2.4541e-04 - val_KL loss: 31.7104 - val_beta: 0.0015\n",
      "Epoch 2164/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 138.1692 - recon_loss: 2.2852e-04 - KL loss: 31.9884 - beta: 0.0015 - val_loss: 146.1945 - val_recon_loss: 2.4638e-04 - val_KL loss: 31.7146 - val_beta: 0.0015\n",
      "Epoch 2165/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 137.1399 - recon_loss: 2.2622e-04 - KL loss: 32.0282 - beta: 0.0015 - val_loss: 146.4136 - val_recon_loss: 2.4671e-04 - val_KL loss: 31.7814 - val_beta: 0.0015\n",
      "Epoch 2166/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 138.4547 - recon_loss: 2.2895e-04 - KL loss: 32.0765 - beta: 0.0015 - val_loss: 147.6987 - val_recon_loss: 2.4948e-04 - val_KL loss: 31.7788 - val_beta: 0.0015\n",
      "Epoch 2167/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 137.3280 - recon_loss: 2.2660e-04 - KL loss: 32.0388 - beta: 0.0015\n",
      "Epoch 02167: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 137.3279 - recon_loss: 2.2660e-04 - KL loss: 32.0387 - beta: 0.0015 - val_loss: 147.9201 - val_recon_loss: 2.4988e-04 - val_KL loss: 31.8153 - val_beta: 0.0015\n",
      "Epoch 2168/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 137.4661 - recon_loss: 2.2703e-04 - KL loss: 31.9778 - beta: 0.0015 - val_loss: 148.0270 - val_recon_loss: 2.5020e-04 - val_KL loss: 31.7757 - val_beta: 0.0015\n",
      "Epoch 2169/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 137.8515 - recon_loss: 2.2772e-04 - KL loss: 32.0423 - beta: 0.0015 - val_loss: 145.6639 - val_recon_loss: 2.4492e-04 - val_KL loss: 31.8615 - val_beta: 0.0015\n",
      "Epoch 2170/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 137.8521 - recon_loss: 2.2760e-04 - KL loss: 32.1015 - beta: 0.0015 - val_loss: 144.8401 - val_recon_loss: 2.4324e-04 - val_KL loss: 31.8185 - val_beta: 0.0015\n",
      "Epoch 2171/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 136.5671 - recon_loss: 2.2492e-04 - KL loss: 32.0613 - beta: 0.0015 - val_loss: 148.7006 - val_recon_loss: 2.5166e-04 - val_KL loss: 31.7683 - val_beta: 0.0015\n",
      "Epoch 2172/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 136.4231 - recon_loss: 2.2469e-04 - KL loss: 32.0222 - beta: 0.0015\n",
      "Epoch 02172: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 136.4234 - recon_loss: 2.2469e-04 - KL loss: 32.0222 - beta: 0.0015 - val_loss: 145.4389 - val_recon_loss: 2.4473e-04 - val_KL loss: 31.7277 - val_beta: 0.0015\n",
      "Epoch 2172/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 107.1036 - recon_loss: 2.5273e-04 - KL loss: 29.4222 - beta: 0.0018 - val_loss: 125.7567 - val_recon_loss: 3.1348e-04 - val_KL loss: 29.4005 - val_beta: 0.0018\n",
      "Epoch 2173/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 118.2585 - recon_loss: 2.8762e-04 - KL loss: 29.8532 - beta: 0.0018 - val_loss: 131.9849 - val_recon_loss: 3.3598e-04 - val_KL loss: 28.7144 - val_beta: 0.0018\n",
      "Epoch 2174/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 109.8807 - recon_loss: 2.6375e-04 - KL loss: 28.8106 - beta: 0.0018 - val_loss: 122.2729 - val_recon_loss: 3.0492e-04 - val_KL loss: 28.5476 - val_beta: 0.0018\n",
      "Epoch 2175/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 108.8424 - recon_loss: 2.6085e-04 - KL loss: 28.6641 - beta: 0.0018 - val_loss: 121.9009 - val_recon_loss: 3.0376e-04 - val_KL loss: 28.5332 - val_beta: 0.0018\n",
      "Epoch 2176/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 109.9634 - recon_loss: 2.6473e-04 - KL loss: 28.5912 - beta: 0.0018 - val_loss: 115.1448 - val_recon_loss: 2.8314e-04 - val_KL loss: 28.1146 - val_beta: 0.0018\n",
      "Epoch 2177/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 110.1734 - recon_loss: 2.6490e-04 - KL loss: 28.7514 - beta: 0.0018 - val_loss: 114.1211 - val_recon_loss: 2.8060e-04 - val_KL loss: 27.8737 - val_beta: 0.0018\n",
      "Epoch 2178/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 110.3056 - recon_loss: 2.6650e-04 - KL loss: 28.3906 - beta: 0.0018 - val_loss: 119.0915 - val_recon_loss: 2.9728e-04 - val_KL loss: 27.7142 - val_beta: 0.0018\n",
      "Epoch 2179/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 110.1690 - recon_loss: 2.6665e-04 - KL loss: 28.2074 - beta: 0.0018 - val_loss: 137.6138 - val_recon_loss: 3.5586e-04 - val_KL loss: 28.2307 - val_beta: 0.0018\n",
      "Epoch 2180/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 112.1584 - recon_loss: 2.7277e-04 - KL loss: 28.3158 - beta: 0.0018 - val_loss: 126.8084 - val_recon_loss: 3.1889e-04 - val_KL loss: 28.7910 - val_beta: 0.0018\n",
      "Epoch 2181/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 109.1068 - recon_loss: 2.6313e-04 - KL loss: 28.2272 - beta: 0.0018 - val_loss: 141.8041 - val_recon_loss: 3.7101e-04 - val_KL loss: 27.7669 - val_beta: 0.0018\n",
      "Epoch 2182/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 112.1001 - recon_loss: 2.7266e-04 - KL loss: 28.2910 - beta: 0.0018\n",
      "Epoch 02182: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 112.0972 - recon_loss: 2.7265e-04 - KL loss: 28.2911 - beta: 0.0018 - val_loss: 118.3575 - val_recon_loss: 2.9405e-04 - val_KL loss: 27.9737 - val_beta: 0.0018\n",
      "Epoch 2183/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 108.0646 - recon_loss: 2.5895e-04 - KL loss: 28.4710 - beta: 0.0018 - val_loss: 116.7545 - val_recon_loss: 2.8748e-04 - val_KL loss: 28.3902 - val_beta: 0.0018\n",
      "Epoch 2184/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 61s 61ms/step - loss: 106.6569 - recon_loss: 2.5404e-04 - KL loss: 28.5727 - beta: 0.0018 - val_loss: 112.6638 - val_recon_loss: 2.7468e-04 - val_KL loss: 28.2337 - val_beta: 0.0018\n",
      "Epoch 2185/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 104.3410 - recon_loss: 2.4712e-04 - KL loss: 28.3842 - beta: 0.0018 - val_loss: 113.2681 - val_recon_loss: 2.7736e-04 - val_KL loss: 28.0161 - val_beta: 0.0018\n",
      "Epoch 2186/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 103.5550 - recon_loss: 2.4507e-04 - KL loss: 28.2269 - beta: 0.0018 - val_loss: 110.3814 - val_recon_loss: 2.6847e-04 - val_KL loss: 27.8594 - val_beta: 0.0018\n",
      "Epoch 2187/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 104.1958 - recon_loss: 2.4696e-04 - KL loss: 28.2868 - beta: 0.0018 - val_loss: 110.2060 - val_recon_loss: 2.6682e-04 - val_KL loss: 28.1921 - val_beta: 0.0018\n",
      "Epoch 2188/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 103.7956 - recon_loss: 2.4600e-04 - KL loss: 28.1820 - beta: 0.0018 - val_loss: 111.3139 - val_recon_loss: 2.6990e-04 - val_KL loss: 28.3554 - val_beta: 0.0018\n",
      "Epoch 2189/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 102.4423 - recon_loss: 2.4180e-04 - KL loss: 28.1192 - beta: 0.0018 - val_loss: 104.3838 - val_recon_loss: 2.4834e-04 - val_KL loss: 28.0503 - val_beta: 0.0018\n",
      "Epoch 2190/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 102.3026 - recon_loss: 2.4165e-04 - KL loss: 28.0269 - beta: 0.0018 - val_loss: 106.9341 - val_recon_loss: 2.5749e-04 - val_KL loss: 27.7888 - val_beta: 0.0018\n",
      "Epoch 2191/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 102.9554 - recon_loss: 2.4360e-04 - KL loss: 28.0793 - beta: 0.0018 - val_loss: 107.0811 - val_recon_loss: 2.5810e-04 - val_KL loss: 27.7482 - val_beta: 0.0018\n",
      "Epoch 2192/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 103.4178 - recon_loss: 2.4573e-04 - KL loss: 27.8871 - beta: 0.0018 - val_loss: 105.5124 - val_recon_loss: 2.5432e-04 - val_KL loss: 27.3399 - val_beta: 0.0018\n",
      "Epoch 2193/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 103.7428 - recon_loss: 2.4699e-04 - KL loss: 27.8254 - beta: 0.0018 - val_loss: 103.7046 - val_recon_loss: 2.4748e-04 - val_KL loss: 27.6373 - val_beta: 0.0018\n",
      "Epoch 2194/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 103.1005 - recon_loss: 2.4496e-04 - KL loss: 27.8054 - beta: 0.0018 - val_loss: 105.2559 - val_recon_loss: 2.5289e-04 - val_KL loss: 27.5246 - val_beta: 0.0018\n",
      "Epoch 2195/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 101.8394 - recon_loss: 2.4087e-04 - KL loss: 27.8012 - beta: 0.0018 - val_loss: 105.6208 - val_recon_loss: 2.5452e-04 - val_KL loss: 27.3876 - val_beta: 0.0018\n",
      "Epoch 2196/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 101.4345 - recon_loss: 2.3965e-04 - KL loss: 27.7713 - beta: 0.0018 - val_loss: 104.0840 - val_recon_loss: 2.4927e-04 - val_KL loss: 27.4635 - val_beta: 0.0018\n",
      "Epoch 2197/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 101.6103 - recon_loss: 2.4008e-04 - KL loss: 27.8176 - beta: 0.0018 - val_loss: 102.8365 - val_recon_loss: 2.4373e-04 - val_KL loss: 27.9197 - val_beta: 0.0018\n",
      "Epoch 2198/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 103.4245 - recon_loss: 2.4552e-04 - KL loss: 27.9568 - beta: 0.0018 - val_loss: 121.4047 - val_recon_loss: 3.0609e-04 - val_KL loss: 27.3221 - val_beta: 0.0018\n",
      "Epoch 2199/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 103.5479 - recon_loss: 2.4631e-04 - KL loss: 27.8384 - beta: 0.0018 - val_loss: 112.1135 - val_recon_loss: 2.7357e-04 - val_KL loss: 28.0263 - val_beta: 0.0018\n",
      "Epoch 2200/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 105.0117 - recon_loss: 2.5003e-04 - KL loss: 28.1606 - beta: 0.0018 - val_loss: 109.4135 - val_recon_loss: 2.6489e-04 - val_KL loss: 27.9944 - val_beta: 0.0018\n",
      "Epoch 2201/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 103.4205 - recon_loss: 2.4496e-04 - KL loss: 28.1261 - beta: 0.0018 - val_loss: 109.7745 - val_recon_loss: 2.6701e-04 - val_KL loss: 27.7024 - val_beta: 0.0018\n",
      "Epoch 2202/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 102.2211 - recon_loss: 2.4150e-04 - KL loss: 27.9916 - beta: 0.0018\n",
      "Epoch 02202: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 102.2206 - recon_loss: 2.4150e-04 - KL loss: 27.9915 - beta: 0.0018 - val_loss: 106.2010 - val_recon_loss: 2.5614e-04 - val_KL loss: 27.4698 - val_beta: 0.0018\n",
      "Epoch 2203/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 100.3032 - recon_loss: 2.3546e-04 - KL loss: 27.9278 - beta: 0.0018 - val_loss: 105.4605 - val_recon_loss: 2.5295e-04 - val_KL loss: 27.7098 - val_beta: 0.0018\n",
      "Epoch 2204/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 100.0799 - recon_loss: 2.3475e-04 - KL loss: 27.9252 - beta: 0.0018 - val_loss: 107.0343 - val_recon_loss: 2.5687e-04 - val_KL loss: 28.0792 - val_beta: 0.0018\n",
      "Epoch 2205/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 99.6175 - recon_loss: 2.3317e-04 - KL loss: 27.9460 - beta: 0.0018 - val_loss: 107.2388 - val_recon_loss: 2.5844e-04 - val_KL loss: 27.8025 - val_beta: 0.0018\n",
      "Epoch 2206/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 99.7752 - recon_loss: 2.3380e-04 - KL loss: 27.9109 - beta: 0.0018 - val_loss: 105.2265 - val_recon_loss: 2.5206e-04 - val_KL loss: 27.7512 - val_beta: 0.0018\n",
      "Epoch 2207/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 99.8651 - recon_loss: 2.3400e-04 - KL loss: 27.9394 - beta: 0.0018\n",
      "Epoch 02207: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 99.8655 - recon_loss: 2.3400e-04 - KL loss: 27.9394 - beta: 0.0018 - val_loss: 105.8130 - val_recon_loss: 2.5448e-04 - val_KL loss: 27.5924 - val_beta: 0.0018\n",
      "Epoch 2207/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 77.8487 - recon_loss: 2.5691e-04 - KL loss: 25.6097 - beta: 0.0022 - val_loss: 83.3956 - val_recon_loss: 2.8618e-04 - val_KL loss: 25.2045 - val_beta: 0.0022\n",
      "Epoch 2208/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 78.2636 - recon_loss: 2.6186e-04 - KL loss: 25.0183 - beta: 0.0022 - val_loss: 101.1167 - val_recon_loss: 3.7481e-04 - val_KL loss: 24.9039 - val_beta: 0.0022\n",
      "Epoch 2209/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 89.7267 - recon_loss: 3.1457e-04 - KL loss: 25.7631 - beta: 0.0022 - val_loss: 86.1824 - val_recon_loss: 3.0030e-04 - val_KL loss: 25.1212 - val_beta: 0.0022\n",
      "Epoch 2210/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 83.4272 - recon_loss: 2.8614e-04 - KL loss: 25.2447 - beta: 0.0022 - val_loss: 82.2799 - val_recon_loss: 2.8453e-04 - val_KL loss: 24.4243 - val_beta: 0.0022\n",
      "Epoch 2211/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 80.5449 - recon_loss: 2.7400e-04 - KL loss: 24.8312 - beta: 0.0022 - val_loss: 84.5512 - val_recon_loss: 2.9328e-04 - val_KL loss: 24.9170 - val_beta: 0.0022\n",
      "Epoch 2212/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 83.8285 - recon_loss: 2.8871e-04 - KL loss: 25.1239 - beta: 0.0022 - val_loss: 89.2177 - val_recon_loss: 3.1862e-04 - val_KL loss: 24.4318 - val_beta: 0.0022\n",
      "Epoch 2213/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 83.2206 - recon_loss: 2.8737e-04 - KL loss: 24.7871 - beta: 0.0022 - val_loss: 94.7490 - val_recon_loss: 3.4889e-04 - val_KL loss: 23.8066 - val_beta: 0.0022\n",
      "Epoch 2214/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 82.9439 - recon_loss: 2.8694e-04 - KL loss: 24.5995 - beta: 0.0022 - val_loss: 87.2323 - val_recon_loss: 3.0994e-04 - val_KL loss: 24.2103 - val_beta: 0.0022\n",
      "Epoch 2215/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 80.5108 - recon_loss: 2.7542e-04 - KL loss: 24.5087 - beta: 0.0022\n",
      "Epoch 02215: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 80.5101 - recon_loss: 2.7541e-04 - KL loss: 24.5087 - beta: 0.0022 - val_loss: 88.8043 - val_recon_loss: 3.1809e-04 - val_KL loss: 24.1259 - val_beta: 0.0022\n",
      "Epoch 2216/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 76.7549 - recon_loss: 2.5657e-04 - KL loss: 24.5843 - beta: 0.0022 - val_loss: 85.4988 - val_recon_loss: 3.0064e-04 - val_KL loss: 24.3676 - val_beta: 0.0022\n",
      "Epoch 2217/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 76.7721 - recon_loss: 2.5650e-04 - KL loss: 24.6170 - beta: 0.0022 - val_loss: 81.5208 - val_recon_loss: 2.8204e-04 - val_KL loss: 24.1724 - val_beta: 0.0022\n",
      "Epoch 2218/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 76.1724 - recon_loss: 2.5397e-04 - KL loss: 24.5315 - beta: 0.0022 - val_loss: 84.4082 - val_recon_loss: 2.9493e-04 - val_KL loss: 24.4376 - val_beta: 0.0022\n",
      "Epoch 2219/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 76.2420 - recon_loss: 2.5438e-04 - KL loss: 24.5170 - beta: 0.0022 - val_loss: 79.2079 - val_recon_loss: 2.7077e-04 - val_KL loss: 24.1502 - val_beta: 0.0022oss: 2.5441e-04 - KL loss: 24.5165 - b\n",
      "Epoch 2220/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 75.5967 - recon_loss: 2.5096e-04 - KL loss: 24.5671 - beta: 0.0022 - val_loss: 78.6230 - val_recon_loss: 2.6763e-04 - val_KL loss: 24.2049 - val_beta: 0.0022\n",
      "Epoch 2221/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 75.4575 - recon_loss: 2.5090e-04 - KL loss: 24.4412 - beta: 0.0022 - val_loss: 79.3772 - val_recon_loss: 2.7032e-04 - val_KL loss: 24.4106 - val_beta: 0.0022\n",
      "Epoch 2222/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 75.2566 - recon_loss: 2.4963e-04 - KL loss: 24.4981 - beta: 0.0022 - val_loss: 77.7932 - val_recon_loss: 2.6345e-04 - val_KL loss: 24.2246 - val_beta: 0.0022\n",
      "Epoch 2223/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 75.8924 - recon_loss: 2.5232e-04 - KL loss: 24.5860 - beta: 0.0022 - val_loss: 79.1862 - val_recon_loss: 2.7056e-04 - val_KL loss: 24.1723 - val_beta: 0.0022\n",
      "Epoch 2224/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 75.3945 - recon_loss: 2.5033e-04 - KL loss: 24.4936 - beta: 0.0022 - val_loss: 77.6218 - val_recon_loss: 2.6299e-04 - val_KL loss: 24.1462 - val_beta: 0.0022\n",
      "Epoch 2225/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 74.9611 - recon_loss: 2.4858e-04 - KL loss: 24.4165 - beta: 0.0022 - val_loss: 80.9170 - val_recon_loss: 2.7817e-04 - val_KL loss: 24.3552 - val_beta: 0.0022\n",
      "Epoch 2226/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 75.3353 - recon_loss: 2.5037e-04 - KL loss: 24.4268 - beta: 0.0022 - val_loss: 78.7805 - val_recon_loss: 2.6796e-04 - val_KL loss: 24.2938 - val_beta: 0.0022\n",
      "Epoch 2227/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 75.5671 - recon_loss: 2.5123e-04 - KL loss: 24.4834 - beta: 0.0022 - val_loss: 77.9670 - val_recon_loss: 2.6317e-04 - val_KL loss: 24.4542 - val_beta: 0.0022\n",
      "Epoch 2228/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 74.4539 - recon_loss: 2.4563e-04 - KL loss: 24.5090 - beta: 0.0022 - val_loss: 79.8859 - val_recon_loss: 2.7304e-04 - val_KL loss: 24.3666 - val_beta: 0.0022\n",
      "Epoch 2229/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 75.4438 - recon_loss: 2.5023e-04 - KL loss: 24.5633 - beta: 0.0022\n",
      "Epoch 02229: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 75.4436 - recon_loss: 2.5023e-04 - KL loss: 24.5633 - beta: 0.0022 - val_loss: 83.8813 - val_recon_loss: 2.9363e-04 - val_KL loss: 24.1768 - val_beta: 0.0022\n",
      "Epoch 2230/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 74.6659 - recon_loss: 2.4683e-04 - KL loss: 24.4765 - beta: 0.0022 - val_loss: 90.7689 - val_recon_loss: 3.2593e-04 - val_KL loss: 24.4959 - val_beta: 0.0022\n",
      "Epoch 2231/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 74.1618 - recon_loss: 2.4369e-04 - KL loss: 24.6101 - beta: 0.0022 - val_loss: 78.7150 - val_recon_loss: 2.6599e-04 - val_KL loss: 24.6307 - val_beta: 0.0022\n",
      "Epoch 2232/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 74.3246 - recon_loss: 2.4409e-04 - KL loss: 24.6921 - beta: 0.0022 - val_loss: 92.3488 - val_recon_loss: 3.3363e-04 - val_KL loss: 24.5107 - val_beta: 0.0022\n",
      "Epoch 2233/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 74.1297 - recon_loss: 2.4336e-04 - KL loss: 24.6465 - beta: 0.0022 - val_loss: 81.8917 - val_recon_loss: 2.8255e-04 - val_KL loss: 24.4393 - val_beta: 0.0022\n",
      "Epoch 2234/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 74.3915 - recon_loss: 2.4477e-04 - KL loss: 24.6218 - beta: 0.0022\n",
      "Epoch 02234: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 74.3910 - recon_loss: 2.4476e-04 - KL loss: 24.6218 - beta: 0.0022 - val_loss: 83.0947 - val_recon_loss: 2.8932e-04 - val_KL loss: 24.2659 - val_beta: 0.0022\n",
      "Epoch 2234/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 58.5289 - recon_loss: 2.6840e-04 - KL loss: 22.4265 - beta: 0.0027 - val_loss: 64.6785 - val_recon_loss: 3.1789e-04 - val_KL loss: 21.9183 - val_beta: 0.0027\n",
      "Epoch 2235/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 59.4398 - recon_loss: 2.7793e-04 - KL loss: 22.0544 - beta: 0.0027 - val_loss: 63.4450 - val_recon_loss: 3.1095e-04 - val_KL loss: 21.6187 - val_beta: 0.0027\n",
      "Epoch 2236/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 60.0869 - recon_loss: 2.8362e-04 - KL loss: 21.9367 - beta: 0.0027 - val_loss: 62.8336 - val_recon_loss: 3.0647e-04 - val_KL loss: 21.6103 - val_beta: 0.0027\n",
      "Epoch 2237/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 60.2918 - recon_loss: 2.8501e-04 - KL loss: 21.9544 - beta: 0.0027 - val_loss: 65.7729 - val_recon_loss: 3.2844e-04 - val_KL loss: 21.5941 - val_beta: 0.0027\n",
      "Epoch 2238/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 59.5306 - recon_loss: 2.8130e-04 - KL loss: 21.6927 - beta: 0.0027 - val_loss: 62.4730 - val_recon_loss: 3.0387e-04 - val_KL loss: 21.5983 - val_beta: 0.0027\n",
      "Epoch 2239/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 62.4546 - recon_loss: 3.0077e-04 - KL loss: 21.9979 - beta: 0.0027 - val_loss: 67.0673 - val_recon_loss: 3.3933e-04 - val_KL loss: 21.4235 - val_beta: 0.0027\n",
      "Epoch 2240/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 63.3839 - recon_loss: 3.0897e-04 - KL loss: 21.8240 - beta: 0.0027 - val_loss: 64.3140 - val_recon_loss: 3.2048e-04 - val_KL loss: 21.2054 - val_beta: 0.0027\n",
      "Epoch 2241/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 60.1587 - recon_loss: 2.8657e-04 - KL loss: 21.6115 - beta: 0.0027 - val_loss: 63.2348 - val_recon_loss: 3.1317e-04 - val_KL loss: 21.1090 - val_beta: 0.0027\n",
      "Epoch 2242/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 60.1941 - recon_loss: 2.8697e-04 - KL loss: 21.5929 - beta: 0.0027 - val_loss: 65.0918 - val_recon_loss: 3.2559e-04 - val_KL loss: 21.2960 - val_beta: 0.0027\n",
      "Epoch 2243/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 60.4912 - recon_loss: 2.8910e-04 - KL loss: 21.6042 - beta: 0.0027\n",
      "Epoch 02243: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 60.4922 - recon_loss: 2.8910e-04 - KL loss: 21.6042 - beta: 0.0027 - val_loss: 62.5577 - val_recon_loss: 3.0552e-04 - val_KL loss: 21.4610 - val_beta: 0.0027\n",
      "Epoch 2244/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 58.9397 - recon_loss: 2.7726e-04 - KL loss: 21.6448 - beta: 0.0027 - val_loss: 61.4894 - val_recon_loss: 2.9663e-04 - val_KL loss: 21.5896 - val_beta: 0.0027\n",
      "Epoch 2245/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 58.1749 - recon_loss: 2.7169e-04 - KL loss: 21.6292 - beta: 0.0027 - val_loss: 61.9362 - val_recon_loss: 3.0011e-04 - val_KL loss: 21.5675 - val_beta: 0.0027\n",
      "Epoch 2246/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 58.0682 - recon_loss: 2.7065e-04 - KL loss: 21.6625 - beta: 0.0027 - val_loss: 58.6392 - val_recon_loss: 2.7545e-04 - val_KL loss: 21.5884 - val_beta: 0.0027\n",
      "Epoch 2247/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 57.6612 - recon_loss: 2.6806e-04 - KL loss: 21.6035 - beta: 0.0027 - val_loss: 59.3672 - val_recon_loss: 2.8032e-04 - val_KL loss: 21.6605 - val_beta: 0.0027\n",
      "Epoch 2248/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 57.8739 - recon_loss: 2.6862e-04 - KL loss: 21.7419 - beta: 0.0027 - val_loss: 62.3438 - val_recon_loss: 3.0093e-04 - val_KL loss: 21.8651 - val_beta: 0.0027\n",
      "Epoch 2249/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 59.4122 - recon_loss: 2.7897e-04 - KL loss: 21.8876 - beta: 0.0027 - val_loss: 62.6062 - val_recon_loss: 3.0298e-04 - val_KL loss: 21.8522 - val_beta: 0.0027\n",
      "Epoch 2250/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 58.3556 - recon_loss: 2.7246e-04 - KL loss: 21.7062 - beta: 0.0027 - val_loss: 62.7492 - val_recon_loss: 3.0467e-04 - val_KL loss: 21.7680 - val_beta: 0.0027\n",
      "Epoch 2251/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 59.2769 - recon_loss: 2.7819e-04 - KL loss: 21.8567 - beta: 0.0027\n",
      "Epoch 02251: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 59.2766 - recon_loss: 2.7819e-04 - KL loss: 21.8566 - beta: 0.0027 - val_loss: 61.8552 - val_recon_loss: 2.9693e-04 - val_KL loss: 21.9143 - val_beta: 0.0027\n",
      "Epoch 2252/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 57.8038 - recon_loss: 2.6739e-04 - KL loss: 21.8365 - beta: 0.0027 - val_loss: 60.5466 - val_recon_loss: 2.8735e-04 - val_KL loss: 21.8944 - val_beta: 0.0027\n",
      "Epoch 2253/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 58.1181 - recon_loss: 2.6956e-04 - KL loss: 21.8592 - beta: 0.0027 - val_loss: 61.3409 - val_recon_loss: 2.9383e-04 - val_KL loss: 21.8170 - val_beta: 0.0027\n",
      "Epoch 2254/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 57.9381 - recon_loss: 2.6872e-04 - KL loss: 21.7918 - beta: 0.0027 - val_loss: 61.2945 - val_recon_loss: 2.9384e-04 - val_KL loss: 21.7693 - val_beta: 0.0027\n",
      "Epoch 2255/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 57.4932 - recon_loss: 2.6567e-04 - KL loss: 21.7579 - beta: 0.0027 - val_loss: 62.3877 - val_recon_loss: 3.0278e-04 - val_KL loss: 21.6601 - val_beta: 0.0027\n",
      "Epoch 2256/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 57.3729 - recon_loss: 2.6462e-04 - KL loss: 21.7790 - beta: 0.0027\n",
      "Epoch 02256: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 57.3728 - recon_loss: 2.6461e-04 - KL loss: 21.7790 - beta: 0.0027 - val_loss: 62.8599 - val_recon_loss: 3.0573e-04 - val_KL loss: 21.7351 - val_beta: 0.0027\n",
      "Epoch 2256/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 46.6082 - recon_loss: 3.0185e-04 - KL loss: 19.7488 - beta: 0.0034 - val_loss: 52.5963 - val_recon_loss: 3.7162e-04 - val_KL loss: 19.5287 - val_beta: 0.0034\n",
      "Epoch 2257/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 47.7868 - recon_loss: 3.1863e-04 - KL loss: 19.4344 - beta: 0.0034 - val_loss: 50.5149 - val_recon_loss: 3.4920e-04 - val_KL loss: 19.4422 - val_beta: 0.0034\n",
      "Epoch 2258/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 48.0991 - recon_loss: 3.2407e-04 - KL loss: 19.2623 - beta: 0.0034 - val_loss: 49.3865 - val_recon_loss: 3.4423e-04 - val_KL loss: 18.7557 - val_beta: 0.0034\n",
      "Epoch 2259/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 48.5365 - recon_loss: 3.2989e-04 - KL loss: 19.1822 - beta: 0.0034 - val_loss: 48.7929 - val_recon_loss: 3.3280e-04 - val_KL loss: 19.1794 - val_beta: 0.0034\n",
      "Epoch 2260/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 47.3735 - recon_loss: 3.1692e-04 - KL loss: 19.1724 - beta: 0.0034 - val_loss: 49.1775 - val_recon_loss: 3.3840e-04 - val_KL loss: 19.0655 - val_beta: 0.0034\n",
      "Epoch 2261/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 48.3532 - recon_loss: 3.2842e-04 - KL loss: 19.1290 - beta: 0.0034 - val_loss: 51.2169 - val_recon_loss: 3.6392e-04 - val_KL loss: 18.8343 - val_beta: 0.0034\n",
      "Epoch 2262/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 49.4508 - recon_loss: 3.4353e-04 - KL loss: 18.8823 - beta: 0.0034 - val_loss: 51.8011 - val_recon_loss: 3.6794e-04 - val_KL loss: 19.0609 - val_beta: 0.0034\n",
      "Epoch 2263/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 49.8518 - recon_loss: 3.4711e-04 - KL loss: 18.9645 - beta: 0.0034 - val_loss: 50.9779 - val_recon_loss: 3.6498e-04 - val_KL loss: 18.5011 - val_beta: 0.0034\n",
      "Epoch 2264/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 50.7670 - recon_loss: 3.5651e-04 - KL loss: 19.0436 - beta: 0.0034 - val_loss: 48.2995 - val_recon_loss: 3.2991e-04 - val_KL loss: 18.9430 - val_beta: 0.0034\n",
      "Epoch 2265/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 49.3235 - recon_loss: 3.3841e-04 - KL loss: 19.2109 - beta: 0.0034 - val_loss: 50.2970 - val_recon_loss: 3.4914e-04 - val_KL loss: 19.2289 - val_beta: 0.0034\n",
      "Epoch 2266/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 49.6959 - recon_loss: 3.4098e-04 - KL loss: 19.3542 - beta: 0.0034 - val_loss: 51.4727 - val_recon_loss: 3.5605e-04 - val_KL loss: 19.7905 - val_beta: 0.0034\n",
      "Epoch 2267/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 52.0134 - recon_loss: 3.6142e-04 - KL loss: 19.8528 - beta: 0.0034 - val_loss: 50.6688 - val_recon_loss: 3.4950e-04 - val_KL loss: 19.5695 - val_beta: 0.0034\n",
      "Epoch 2268/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 49.6676 - recon_loss: 3.3896e-04 - KL loss: 19.5059 - beta: 0.0034 - val_loss: 54.0553 - val_recon_loss: 3.9222e-04 - val_KL loss: 19.1543 - val_beta: 0.0034\n",
      "Epoch 2269/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 50.2880 - recon_loss: 3.4596e-04 - KL loss: 19.5029 - beta: 0.0034\n",
      "Epoch 02269: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 50.2874 - recon_loss: 3.4596e-04 - KL loss: 19.5028 - beta: 0.0034 - val_loss: 50.7587 - val_recon_loss: 3.4573e-04 - val_KL loss: 19.9948 - val_beta: 0.0034\n",
      "Epoch 2270/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 46.8315 - recon_loss: 3.0941e-04 - KL loss: 19.2989 - beta: 0.0034 - val_loss: 49.4849 - val_recon_loss: 3.4517e-04 - val_KL loss: 18.7708 - val_beta: 0.0034\n",
      "Epoch 2271/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 46.1791 - recon_loss: 3.0418e-04 - KL loss: 19.1117 - beta: 0.0034 - val_loss: 46.8727 - val_recon_loss: 3.1511e-04 - val_KL loss: 18.8330 - val_beta: 0.0034\n",
      "Epoch 2272/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 45.8509 - recon_loss: 3.0039e-04 - KL loss: 19.1212 - beta: 0.0034 - val_loss: 46.4101 - val_recon_loss: 3.0905e-04 - val_KL loss: 18.9099 - val_beta: 0.0034\n",
      "Epoch 2273/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 45.5985 - recon_loss: 2.9742e-04 - KL loss: 19.1328 - beta: 0.0034 - val_loss: 47.1079 - val_recon_loss: 3.1713e-04 - val_KL loss: 18.8884 - val_beta: 0.0034\n",
      "Epoch 2274/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 45.6014 - recon_loss: 2.9741e-04 - KL loss: 19.1365 - beta: 0.0034 - val_loss: 44.6173 - val_recon_loss: 2.9080e-04 - val_KL loss: 18.7409 - val_beta: 0.0034\n",
      "Epoch 2275/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 45.5729 - recon_loss: 2.9730e-04 - KL loss: 19.1183 - beta: 0.0034 - val_loss: 47.8462 - val_recon_loss: 3.2887e-04 - val_KL loss: 18.5818 - val_beta: 0.0034\n",
      "Epoch 2276/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 45.2867 - recon_loss: 2.9476e-04 - KL loss: 19.0584 - beta: 0.0034 - val_loss: 46.4143 - val_recon_loss: 3.0718e-04 - val_KL loss: 19.0804 - val_beta: 0.0034\n",
      "Epoch 2277/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 45.8520 - recon_loss: 3.0020e-04 - KL loss: 19.1394 - beta: 0.0034 - val_loss: 46.4469 - val_recon_loss: 3.0797e-04 - val_KL loss: 19.0429 - val_beta: 0.0034\n",
      "Epoch 2278/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 46.0348 - recon_loss: 3.0068e-04 - KL loss: 19.2794 - beta: 0.0034 - val_loss: 46.5697 - val_recon_loss: 3.0697e-04 - val_KL loss: 19.2549 - val_beta: 0.0034\n",
      "Epoch 2279/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 45.5811 - recon_loss: 2.9646e-04 - KL loss: 19.2009 - beta: 0.0034\n",
      "Epoch 02279: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 45.5813 - recon_loss: 2.9646e-04 - KL loss: 19.2009 - beta: 0.0034 - val_loss: 46.8641 - val_recon_loss: 3.1209e-04 - val_KL loss: 19.0931 - val_beta: 0.0034\n",
      "Epoch 2280/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 45.9427 - recon_loss: 2.9873e-04 - KL loss: 19.3605 - beta: 0.0034 - val_loss: 47.0380 - val_recon_loss: 3.1443e-04 - val_KL loss: 19.0592 - val_beta: 0.0034\n",
      "Epoch 2281/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 45.2703 - recon_loss: 2.9185e-04 - KL loss: 19.3008 - beta: 0.0034 - val_loss: 46.8672 - val_recon_loss: 3.1350e-04 - val_KL loss: 18.9706 - val_beta: 0.0034\n",
      "Epoch 2282/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 45.1303 - recon_loss: 2.9077e-04 - KL loss: 19.2563 - beta: 0.0034 - val_loss: 46.0593 - val_recon_loss: 3.0538e-04 - val_KL loss: 18.8857 - val_beta: 0.0034\n",
      "Epoch 2283/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.8707 - recon_loss: 2.8886e-04 - KL loss: 19.1671 - beta: 0.0034 - val_loss: 46.1366 - val_recon_loss: 3.0556e-04 - val_KL loss: 18.9468 - val_beta: 0.0034\n",
      "Epoch 2284/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 44.9243 - recon_loss: 2.8937e-04 - KL loss: 19.1750 - beta: 0.0034\n",
      "Epoch 02284: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 44.9244 - recon_loss: 2.8937e-04 - KL loss: 19.1750 - beta: 0.0034 - val_loss: 45.3019 - val_recon_loss: 2.9594e-04 - val_KL loss: 18.9678 - val_beta: 0.0034\n",
      "Epoch 2284/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.9646 - recon_loss: 3.3492e-04 - KL loss: 17.2493 - beta: 0.0041 - val_loss: 38.0688 - val_recon_loss: 3.6160e-04 - val_KL loss: 16.7833 - val_beta: 0.0041\n",
      "Epoch 2285/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 38.2147 - recon_loss: 3.5881e-04 - KL loss: 17.0935 - beta: 0.0041 - val_loss: 37.8384 - val_recon_loss: 3.5558e-04 - val_KL loss: 16.9069 - val_beta: 0.0041\n",
      "Epoch 2286/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 37.5997 - recon_loss: 3.5066e-04 - KL loss: 16.9582 - beta: 0.0041 - val_loss: 37.7785 - val_recon_loss: 3.6026e-04 - val_KL loss: 16.5716 - val_beta: 0.0041\n",
      "Epoch 2287/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 37.1826 - recon_loss: 3.4550e-04 - KL loss: 16.8447 - beta: 0.0041 - val_loss: 37.6976 - val_recon_loss: 3.5849e-04 - val_KL loss: 16.5949 - val_beta: 0.0041\n",
      "Epoch 2288/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.7636 - recon_loss: 3.4039e-04 - KL loss: 16.7267 - beta: 0.0041 - val_loss: 37.9096 - val_recon_loss: 3.6122e-04 - val_KL loss: 16.6461 - val_beta: 0.0041\n",
      "Epoch 2289/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 38.7851 - recon_loss: 3.6994e-04 - KL loss: 17.0085 - beta: 0.0041 - val_loss: 39.2604 - val_recon_loss: 3.8524e-04 - val_KL loss: 16.5830 - val_beta: 0.0041\n",
      "Epoch 2290/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 38.2470 - recon_loss: 3.6340e-04 - KL loss: 16.8554 - beta: 0.0041 - val_loss: 37.7862 - val_recon_loss: 3.5740e-04 - val_KL loss: 16.7476 - val_beta: 0.0041\n",
      "Epoch 2291/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 37.4417 - recon_loss: 3.5238e-04 - KL loss: 16.6991 - beta: 0.0041 - val_loss: 38.6969 - val_recon_loss: 3.8572e-04 - val_KL loss: 15.9915 - val_beta: 0.0041\n",
      "Epoch 2292/10000\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 38.0935 - recon_loss: 3.6178e-04 - KL loss: 16.7971 - beta: 0.0041\n",
      "Epoch 02292: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 38.0933 - recon_loss: 3.6178e-04 - KL loss: 16.7970 - beta: 0.0041 - val_loss: 37.9045 - val_recon_loss: 3.6458e-04 - val_KL loss: 16.4437 - val_beta: 0.0041\n",
      "Epoch 2293/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 37.3682 - recon_loss: 3.4995e-04 - KL loss: 16.7687 - beta: 0.0041 - val_loss: 36.8922 - val_recon_loss: 3.4458e-04 - val_KL loss: 16.6086 - val_beta: 0.0041\n",
      "Epoch 2294/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.6163 - recon_loss: 3.3730e-04 - KL loss: 16.7612 - beta: 0.0041 - val_loss: 38.2103 - val_recon_loss: 3.6869e-04 - val_KL loss: 16.5076 - val_beta: 0.0041\n",
      "Epoch 2295/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.5371 - recon_loss: 3.3663e-04 - KL loss: 16.7216 - beta: 0.0041 - val_loss: 36.6663 - val_recon_loss: 3.4393e-04 - val_KL loss: 16.4208 - val_beta: 0.0041\n",
      "Epoch 2296/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.3535 - recon_loss: 3.3307e-04 - KL loss: 16.7476 - beta: 0.0041 - val_loss: 39.3341 - val_recon_loss: 3.9108e-04 - val_KL loss: 16.3133 - val_beta: 0.0041\n",
      "Epoch 2297/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.2268 - recon_loss: 3.3158e-04 - KL loss: 16.7084 - beta: 0.0041 - val_loss: 36.1052 - val_recon_loss: 3.3337e-04 - val_KL loss: 16.4814 - val_beta: 0.0041\n",
      "Epoch 2298/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.4209 - recon_loss: 3.3367e-04 - KL loss: 16.7793 - beta: 0.0041 - val_loss: 36.5598 - val_recon_loss: 3.4221e-04 - val_KL loss: 16.4155 - val_beta: 0.0041\n",
      "Epoch 2299/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 35.7844 - recon_loss: 3.2494e-04 - KL loss: 16.6567 - beta: 0.0041 - val_loss: 36.3853 - val_recon_loss: 3.3934e-04 - val_KL loss: 16.4101 - val_beta: 0.0041\n",
      "Epoch 2300/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.8655 - recon_loss: 3.2554e-04 - KL loss: 16.7029 - beta: 0.0041 - val_loss: 36.1874 - val_recon_loss: 3.3794e-04 - val_KL loss: 16.2943 - val_beta: 0.0041\n",
      "Epoch 2301/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.0479 - recon_loss: 3.2847e-04 - KL loss: 16.7124 - beta: 0.0041 - val_loss: 35.7727 - val_recon_loss: 3.2701e-04 - val_KL loss: 16.5231 - val_beta: 0.0041\n",
      "Epoch 2302/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 35.9176 - recon_loss: 3.2646e-04 - KL loss: 16.7007 - beta: 0.0041 - val_loss: 36.2565 - val_recon_loss: 3.3638e-04 - val_KL loss: 16.4553 - val_beta: 0.0041\n",
      "Epoch 2303/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.0228 - recon_loss: 3.2861e-04 - KL loss: 16.6793 - beta: 0.0041 - val_loss: 36.0895 - val_recon_loss: 3.3299e-04 - val_KL loss: 16.4879 - val_beta: 0.0041\n",
      "Epoch 2304/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.0337 - recon_loss: 3.2690e-04 - KL loss: 16.7904 - beta: 0.0041 - val_loss: 36.2960 - val_recon_loss: 3.3689e-04 - val_KL loss: 16.4651 - val_beta: 0.0041\n",
      "Epoch 2305/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.3047 - recon_loss: 3.3133e-04 - KL loss: 16.8010 - beta: 0.0041 - val_loss: 36.4013 - val_recon_loss: 3.4269e-04 - val_KL loss: 16.2288 - val_beta: 0.0041\n",
      "Epoch 2306/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 36.0336 - recon_loss: 3.2831e-04 - KL loss: 16.7074 - beta: 0.0041\n",
      "Epoch 02306: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.0338 - recon_loss: 3.2832e-04 - KL loss: 16.7075 - beta: 0.0041 - val_loss: 36.2813 - val_recon_loss: 3.3340e-04 - val_KL loss: 16.6555 - val_beta: 0.0041\n",
      "Epoch 2307/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 36.1827 - recon_loss: 3.2829e-04 - KL loss: 16.8577 - beta: 0.0041 - val_loss: 35.9238 - val_recon_loss: 3.2982e-04 - val_KL loss: 16.5087 - val_beta: 0.0041\n",
      "Epoch 2308/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.9704 - recon_loss: 3.2532e-04 - KL loss: 16.8201 - beta: 0.0041 - val_loss: 35.8594 - val_recon_loss: 3.3095e-04 - val_KL loss: 16.3781 - val_beta: 0.0041\n",
      "Epoch 2309/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.9620 - recon_loss: 3.2664e-04 - KL loss: 16.7344 - beta: 0.0041 - val_loss: 35.4997 - val_recon_loss: 3.2196e-04 - val_KL loss: 16.5473 - val_beta: 0.0041\n",
      "Epoch 2310/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.6940 - recon_loss: 3.2251e-04 - KL loss: 16.7092 - beta: 0.0041 - val_loss: 35.7965 - val_recon_loss: 3.2594e-04 - val_KL loss: 16.6103 - val_beta: 0.0041\n",
      "Epoch 2311/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.8183 - recon_loss: 3.2423e-04 - KL loss: 16.7326 - beta: 0.0041 - val_loss: 35.4124 - val_recon_loss: 3.2200e-04 - val_KL loss: 16.4577 - val_beta: 0.0041\n",
      "Epoch 2312/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.9172 - recon_loss: 3.2506e-04 - KL loss: 16.7828 - beta: 0.0041 - val_loss: 36.3730 - val_recon_loss: 3.3694e-04 - val_KL loss: 16.5389 - val_beta: 0.0041\n",
      "Epoch 2313/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 36.1418 - recon_loss: 3.2848e-04 - KL loss: 16.8056 - beta: 0.0041 - val_loss: 35.5368 - val_recon_loss: 3.2617e-04 - val_KL loss: 16.3368 - val_beta: 0.0041\n",
      "Epoch 2314/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.8537 - recon_loss: 3.2587e-04 - KL loss: 16.6711 - beta: 0.0041 - val_loss: 35.7972 - val_recon_loss: 3.2890e-04 - val_KL loss: 16.4367 - val_beta: 0.0041\n",
      "Epoch 2315/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 35.4299 - recon_loss: 3.1868e-04 - KL loss: 16.6708 - beta: 0.0041 - val_loss: 35.2101 - val_recon_loss: 3.1705e-04 - val_KL loss: 16.5467 - val_beta: 0.0041\n",
      "Epoch 2316/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 35.7650 - recon_loss: 3.2272e-04 - KL loss: 16.7681 - beta: 0.0041 - val_loss: 35.3095 - val_recon_loss: 3.2076e-04 - val_KL loss: 16.4278 - val_beta: 0.0041\n",
      "Epoch 2317/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.6638 - recon_loss: 3.2189e-04 - KL loss: 16.7156 - beta: 0.0041 - val_loss: 35.3508 - val_recon_loss: 3.2065e-04 - val_KL loss: 16.4756 - val_beta: 0.0041\n",
      "Epoch 2318/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.7595 - recon_loss: 3.2286e-04 - KL loss: 16.7542 - beta: 0.0041 - val_loss: 35.5492 - val_recon_loss: 3.2023e-04 - val_KL loss: 16.6988 - val_beta: 0.0041\n",
      "Epoch 2319/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.9157 - recon_loss: 3.2486e-04 - KL loss: 16.7927 - beta: 0.0041 - val_loss: 36.2245 - val_recon_loss: 3.3660e-04 - val_KL loss: 16.4107 - val_beta: 0.0041\n",
      "Epoch 2320/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.5479 - recon_loss: 3.2212e-04 - KL loss: 16.5865 - beta: 0.0041 - val_loss: 35.0623 - val_recon_loss: 3.1474e-04 - val_KL loss: 16.5352 - val_beta: 0.0041\n",
      "Epoch 2321/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.5052 - recon_loss: 3.1921e-04 - KL loss: 16.7149 - beta: 0.0041 - val_loss: 35.9240 - val_recon_loss: 3.3276e-04 - val_KL loss: 16.3359 - val_beta: 0.0041\n",
      "Epoch 2322/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.5255 - recon_loss: 3.2057e-04 - KL loss: 16.6550 - beta: 0.0041 - val_loss: 35.6179 - val_recon_loss: 3.2709e-04 - val_KL loss: 16.3639 - val_beta: 0.0041\n",
      "Epoch 2323/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.4740 - recon_loss: 3.1979e-04 - KL loss: 16.6499 - beta: 0.0041 - val_loss: 34.4627 - val_recon_loss: 3.0664e-04 - val_KL loss: 16.4122 - val_beta: 0.0041\n",
      "Epoch 2324/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 35.2869 - recon_loss: 3.1666e-04 - KL loss: 16.6468 - beta: 0.0041 - val_loss: 35.8644 - val_recon_loss: 3.2976e-04 - val_KL loss: 16.4534 - val_beta: 0.0041\n",
      "Epoch 2325/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.3283 - recon_loss: 3.1679e-04 - KL loss: 16.6803 - beta: 0.0041 - val_loss: 35.5244 - val_recon_loss: 3.2457e-04 - val_KL loss: 16.4188 - val_beta: 0.0041\n",
      "Epoch 2326/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.5079 - recon_loss: 3.2041e-04 - KL loss: 16.6472 - beta: 0.0041 - val_loss: 35.5116 - val_recon_loss: 3.2485e-04 - val_KL loss: 16.3893 - val_beta: 0.0041\n",
      "Epoch 2327/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.4124 - recon_loss: 3.1899e-04 - KL loss: 16.6348 - beta: 0.0041 - val_loss: 35.5964 - val_recon_loss: 3.2589e-04 - val_KL loss: 16.4128 - val_beta: 0.0041\n",
      "Epoch 2328/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 35.3726 - recon_loss: 3.1843e-04 - KL loss: 16.6285 - beta: 0.0041\n",
      "Epoch 02328: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 35.3725 - recon_loss: 3.1842e-04 - KL loss: 16.6284 - beta: 0.0041 - val_loss: 35.2348 - val_recon_loss: 3.2155e-04 - val_KL loss: 16.3065 - val_beta: 0.0041\n",
      "Epoch 2329/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 35.1491 - recon_loss: 3.1484e-04 - KL loss: 16.6161 - beta: 0.0041 - val_loss: 36.4113 - val_recon_loss: 3.3919e-04 - val_KL loss: 16.4451 - val_beta: 0.0041\n",
      "Epoch 2330/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.1969 - recon_loss: 3.1474e-04 - KL loss: 16.6695 - beta: 0.0041 - val_loss: 35.4543 - val_recon_loss: 3.2265e-04 - val_KL loss: 16.4615 - val_beta: 0.0041\n",
      "Epoch 2331/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 35.2198 - recon_loss: 3.1534e-04 - KL loss: 16.6573 - beta: 0.0041 - val_loss: 35.7074 - val_recon_loss: 3.2810e-04 - val_KL loss: 16.3938 - val_beta: 0.0041\n",
      "Epoch 2332/10000\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 35.3105 - recon_loss: 3.1666e-04 - KL loss: 16.6702 - beta: 0.0041 - val_loss: 36.1630 - val_recon_loss: 3.3447e-04 - val_KL loss: 16.4743 - val_beta: 0.0041\n",
      "Epoch 2333/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 35.1803 - recon_loss: 3.1439e-04 - KL loss: 16.6739 - beta: 0.0041- ETA: 3s - loss: 35.1813 - recon_loss: 3.1439\n",
      "Epoch 02333: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 35.1803 - recon_loss: 3.1439e-04 - KL loss: 16.6739 - beta: 0.0041 - val_loss: 35.7053 - val_recon_loss: 3.2730e-04 - val_KL loss: 16.4388 - val_beta: 0.0041\n",
      "Epoch 2333/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 29.2243 - recon_loss: 3.6574e-04 - KL loss: 14.9823 - beta: 0.0051 - val_loss: 32.9106 - val_recon_loss: 4.7554e-04 - val_KL loss: 14.3926 - val_beta: 0.0051\n",
      "Epoch 2334/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 30.8962 - recon_loss: 4.1621e-04 - KL loss: 14.6888 - beta: 0.0051 - val_loss: 29.8597 - val_recon_loss: 3.9924e-04 - val_KL loss: 14.3128 - val_beta: 0.0051\n",
      "Epoch 2335/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 29.7362 - recon_loss: 3.8757e-04 - KL loss: 14.6438 - beta: 0.0051 - val_loss: 30.0316 - val_recon_loss: 3.9923e-04 - val_KL loss: 14.4854 - val_beta: 0.0051\n",
      "Epoch 2336/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 29.5833 - recon_loss: 3.8589e-04 - KL loss: 14.5566 - beta: 0.0051 - val_loss: 30.2216 - val_recon_loss: 4.0392e-04 - val_KL loss: 14.4928 - val_beta: 0.0051\n",
      "Epoch 2337/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 30.0579 - recon_loss: 3.9923e-04 - KL loss: 14.5116 - beta: 0.0051 - val_loss: 32.4755 - val_recon_loss: 4.5930e-04 - val_KL loss: 14.5902 - val_beta: 0.0051\n",
      "Epoch 2338/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 31.3946 - recon_loss: 4.3256e-04 - KL loss: 14.5503 - beta: 0.0051 - val_loss: 33.1147 - val_recon_loss: 4.8613e-04 - val_KL loss: 14.1845 - val_beta: 0.0051\n",
      "Epoch 2339/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31.0438 - recon_loss: 4.2454e-04 - KL loss: 14.5118 - beta: 0.0051\n",
      "Epoch 02339: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 31.0439 - recon_loss: 4.2454e-04 - KL loss: 14.5118 - beta: 0.0051 - val_loss: 30.6372 - val_recon_loss: 4.1168e-04 - val_KL loss: 14.6060 - val_beta: 0.0051\n",
      "Epoch 2340/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 30.1464 - recon_loss: 4.0049e-04 - KL loss: 14.5512 - beta: 0.0051 - val_loss: 31.0220 - val_recon_loss: 4.2668e-04 - val_KL loss: 14.4070 - val_beta: 0.0051\n",
      "Epoch 2341/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 30.5529 - recon_loss: 4.0951e-04 - KL loss: 14.6061 - beta: 0.0051 - val_loss: 30.3354 - val_recon_loss: 4.0814e-04 - val_KL loss: 14.4423 - val_beta: 0.0051\n",
      "Epoch 2342/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 29.9010 - recon_loss: 3.9448e-04 - KL loss: 14.5397 - beta: 0.0051 - val_loss: 30.8396 - val_recon_loss: 4.2429e-04 - val_KL loss: 14.3175 - val_beta: 0.0051\n",
      "Epoch 2343/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 30.1197 - recon_loss: 3.9962e-04 - KL loss: 14.5582 - beta: 0.0051 - val_loss: 30.2468 - val_recon_loss: 4.0836e-04 - val_KL loss: 14.3450 - val_beta: 0.0051\n",
      "Epoch 2344/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 29.8479 - recon_loss: 3.9384e-04 - KL loss: 14.5117 - beta: 0.0051\n",
      "Epoch 02344: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 29.8479 - recon_loss: 3.9383e-04 - KL loss: 14.5117 - beta: 0.0051 - val_loss: 30.1258 - val_recon_loss: 4.0709e-04 - val_KL loss: 14.2735 - val_beta: 0.0051\n",
      "Epoch 2344/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.8068 - recon_loss: 4.5453e-04 - KL loss: 13.0979 - beta: 0.0062 - val_loss: 24.1070 - val_recon_loss: 4.4596e-04 - val_KL loss: 12.6189 - val_beta: 0.0062\n",
      "Epoch 2345/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 25.0973 - recon_loss: 4.7977e-04 - KL loss: 12.7382 - beta: 0.0062 - val_loss: 25.3373 - val_recon_loss: 4.9635e-04 - val_KL loss: 12.5511 - val_beta: 0.0062\n",
      "Epoch 2346/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25.3670 - recon_loss: 4.9060e-04 - KL loss: 12.7289 - beta: 0.0062 - val_loss: 25.1008 - val_recon_loss: 4.9371e-04 - val_KL loss: 12.3827 - val_beta: 0.0062\n",
      "Epoch 2347/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 25.0158 - recon_loss: 4.7854e-04 - KL loss: 12.6884 - beta: 0.0062 - val_loss: 24.0759 - val_recon_loss: 4.5089e-04 - val_KL loss: 12.4607 - val_beta: 0.0062\n",
      "Epoch 2348/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.3012 - recon_loss: 4.5577e-04 - KL loss: 12.5604 - beta: 0.0062 - val_loss: 25.4532 - val_recon_loss: 4.9677e-04 - val_KL loss: 12.6562 - val_beta: 0.0062\n",
      "Epoch 2349/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.7196 - recon_loss: 4.7016e-04 - KL loss: 12.6082 - beta: 0.0062 - val_loss: 24.0619 - val_recon_loss: 4.4966e-04 - val_KL loss: 12.4786 - val_beta: 0.0062\n",
      "Epoch 2350/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.3755 - recon_loss: 4.5705e-04 - KL loss: 12.6018 - beta: 0.0062 - val_loss: 24.7081 - val_recon_loss: 4.7159e-04 - val_KL loss: 12.5599 - val_beta: 0.0062\n",
      "Epoch 2351/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.1065 - recon_loss: 4.4993e-04 - KL loss: 12.5162 - beta: 0.0062 - val_loss: 23.5214 - val_recon_loss: 4.3490e-04 - val_KL loss: 12.3182 - val_beta: 0.0062\n",
      "Epoch 2352/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.1989 - recon_loss: 4.5645e-04 - KL loss: 12.4406 - beta: 0.0062 - val_loss: 24.9966 - val_recon_loss: 4.9569e-04 - val_KL loss: 12.2275 - val_beta: 0.0062\n",
      "Epoch 2353/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.7139 - recon_loss: 4.7884e-04 - KL loss: 12.3789 - beta: 0.0062 - val_loss: 25.9082 - val_recon_loss: 5.2272e-04 - val_KL loss: 12.4428 - val_beta: 0.0062\n",
      "Epoch 2354/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 25.2386 - recon_loss: 4.9734e-04 - KL loss: 12.4270 - beta: 0.0062 - val_loss: 26.0230 - val_recon_loss: 5.2858e-04 - val_KL loss: 12.4066 - val_beta: 0.0062\n",
      "Epoch 2355/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 25.6254 - recon_loss: 5.1303e-04 - KL loss: 12.4097 - beta: 0.0062 - val_loss: 25.1569 - val_recon_loss: 5.0035e-04 - val_KL loss: 12.2677 - val_beta: 0.0062\n",
      "Epoch 2356/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 25.3151 - recon_loss: 4.9981e-04 - KL loss: 12.4398 - beta: 0.0062\n",
      "Epoch 02356: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 25.3148 - recon_loss: 4.9980e-04 - KL loss: 12.4398 - beta: 0.0062 - val_loss: 25.2811 - val_recon_loss: 5.0620e-04 - val_KL loss: 12.2413 - val_beta: 0.0062\n",
      "Epoch 2357/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 24.3705 - recon_loss: 4.6797e-04 - KL loss: 12.3155 - beta: 0.0062 - val_loss: 24.5444 - val_recon_loss: 4.7684e-04 - val_KL loss: 12.2609 - val_beta: 0.0062\n",
      "Epoch 2358/10000\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 24.2773 - recon_loss: 4.6187e-04 - KL loss: 12.3792 - beta: 0.0062 - val_loss: 25.1908 - val_recon_loss: 4.9389e-04 - val_KL loss: 12.4679 - val_beta: 0.0062\n",
      "Epoch 2359/10000\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.3469 - recon_loss: 4.6282e-04 - KL loss: 12.4244 - beta: 0.0062 - val_loss: 24.2445 - val_recon_loss: 4.6577e-04 - val_KL loss: 12.2463 - val_beta: 0.0062\n",
      "Epoch 2360/10000\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 24.1579 - recon_loss: 4.5660e-04 - KL loss: 12.3959 - beta: 0.0062 - val_loss: 24.1700 - val_recon_loss: 4.6922e-04 - val_KL loss: 12.0826 - val_beta: 0.0062\n",
      "Epoch 2361/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 24.1747 - recon_loss: 4.5845e-04 - KL loss: 12.3650 - beta: 0.0062\n",
      "Epoch 02361: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 24.1747 - recon_loss: 4.5844e-04 - KL loss: 12.3650 - beta: 0.0062 - val_loss: 24.4354 - val_recon_loss: 4.7273e-04 - val_KL loss: 12.2576 - val_beta: 0.0062\n"
     ]
    }
   ],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0., patience=10, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "init_epoch=0\n",
    "\n",
    "for beta in betas:\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,3e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3229/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 6.9833 - recon_loss: 0.0088 - KL loss: 0.6476 - beta: 0.0373 - val_val_loss: 5.5028 - val_val_recon_loss: 0.0047 - val_val_KL loss: 2.0897 - val_beta: 0.0373\n",
      "Epoch 3230/10000\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 5.3901 - recon_loss: 0.0043 - KL loss: 2.2608 - beta: 0.0373 - val_val_loss: 5.1368 - val_val_recon_loss: 0.0037 - val_val_KL loss: 2.4528 - val_beta: 0.0373\n",
      "Epoch 3231/10000\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 5.0955 - recon_loss: 0.0036 - KL loss: 2.4881 - beta: 0.0373 - val_val_loss: 5.0536 - val_val_recon_loss: 0.0035 - val_val_KL loss: 2.5608 - val_beta: 0.0373\n",
      "Epoch 3232/10000\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 5.0007 - recon_loss: 0.0034 - KL loss: 2.5638 - beta: 0.0373 - val_val_loss: 4.9813 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.4994 - val_beta: 0.0373\n",
      "Epoch 3233/10000\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 4.9556 - recon_loss: 0.0033 - KL loss: 2.5833 - beta: 0.0373 - val_val_loss: 4.9148 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.5639 - val_beta: 0.0373\n",
      "Epoch 3234/10000\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 4.9358 - recon_loss: 0.0033 - KL loss: 2.5914 - beta: 0.0373 - val_val_loss: 4.9771 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.6285 - val_beta: 0.0373\n",
      "Epoch 3235/10000\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 4.9379 - recon_loss: 0.0033 - KL loss: 2.5938 - beta: 0.0373 - val_val_loss: 4.9083 - val_val_recon_loss: 0.0032 - val_val_KL loss: 2.6317 - val_beta: 0.0373\n",
      "Epoch 3236/10000\n",
      "1000/1000 [==============================] - 106s 106ms/step - loss: 4.9093 - recon_loss: 0.0032 - KL loss: 2.6191 - beta: 0.0373 - val_val_loss: 4.8807 - val_val_recon_loss: 0.0032 - val_val_KL loss: 2.5746 - val_beta: 0.0373\n",
      "Epoch 3237/10000\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 4.8955 - recon_loss: 0.0032 - KL loss: 2.6262 - beta: 0.0373 - val_val_loss: 4.8832 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6537 - val_beta: 0.0373\n",
      "Epoch 3238/10000\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 4.8956 - recon_loss: 0.0032 - KL loss: 2.6277 - beta: 0.0373 - val_val_loss: 4.8960 - val_val_recon_loss: 0.0032 - val_val_KL loss: 2.6125 - val_beta: 0.0373\n",
      "Epoch 3239/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 4.8840 - recon_loss: 0.0031 - KL loss: 2.6326 - beta: 0.0373 - val_val_loss: 4.9200 - val_val_recon_loss: 0.0032 - val_val_KL loss: 2.6100 - val_beta: 0.0373\n",
      "Epoch 3240/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 4.8865 - recon_loss: 0.0031 - KL loss: 2.6212 - beta: 0.0373 - val_val_loss: 4.8862 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6458 - val_beta: 0.0373\n",
      "Epoch 3241/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 4.8910 - recon_loss: 0.0031 - KL loss: 2.6277 - beta: 0.0373 - val_val_loss: 4.8766 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6273 - val_beta: 0.0373\n",
      "Epoch 3242/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 4.8633 - recon_loss: 0.0031 - KL loss: 2.6444 - beta: 0.0373 - val_val_loss: 4.8526 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6213 - val_beta: 0.0373\n",
      "Epoch 3243/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8530 - recon_loss: 0.0031 - KL loss: 2.6471 - beta: 0.0373 - val_val_loss: 4.8642 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6542 - val_beta: 0.0373\n",
      "Epoch 3244/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8643 - recon_loss: 0.0031 - KL loss: 2.6548 - beta: 0.0373 - val_val_loss: 4.8368 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6840 - val_beta: 0.0373\n",
      "Epoch 3245/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8628 - recon_loss: 0.0031 - KL loss: 2.6429 - beta: 0.0373 - val_val_loss: 4.8513 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6139 - val_beta: 0.0373\n",
      "Epoch 3246/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8796 - recon_loss: 0.0031 - KL loss: 2.6469 - beta: 0.0373 - val_val_loss: 4.8779 - val_val_recon_loss: 0.0032 - val_val_KL loss: 2.6002 - val_beta: 0.0373\n",
      "Epoch 3247/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8635 - recon_loss: 0.0031 - KL loss: 2.6540 - beta: 0.0373 - val_val_loss: 4.8544 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6798 - val_beta: 0.0373\n",
      "Epoch 3248/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8533 - recon_loss: 0.0031 - KL loss: 2.6458 - beta: 0.0373 - val_val_loss: 4.8333 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6365 - val_beta: 0.0373\n",
      "Epoch 3249/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8615 - recon_loss: 0.0031 - KL loss: 2.6631 - beta: 0.0373 - val_val_loss: 4.8365 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6110 - val_beta: 0.0373\n",
      "Epoch 3250/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8485 - recon_loss: 0.0031 - KL loss: 2.6506 - beta: 0.0373 - val_val_loss: 4.8205 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6105 - val_beta: 0.0373\n",
      "Epoch 3251/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8420 - recon_loss: 0.0031 - KL loss: 2.6392 - beta: 0.0373 - val_val_loss: 4.8491 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6974 - val_beta: 0.0373\n",
      "Epoch 3252/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8505 - recon_loss: 0.0031 - KL loss: 2.6459 - beta: 0.0373 - val_val_loss: 4.8347 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6568 - val_beta: 0.0373\n",
      "Epoch 3253/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8450 - recon_loss: 0.0030 - KL loss: 2.6589 - beta: 0.0373 - val_val_loss: 4.8229 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6426 - val_beta: 0.0373\n",
      "Epoch 3254/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8414 - recon_loss: 0.0030 - KL loss: 2.6647 - beta: 0.0373 - val_val_loss: 4.8320 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.7180 - val_beta: 0.0373\n",
      "Epoch 3255/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8327 - recon_loss: 0.0030 - KL loss: 2.6709 - beta: 0.0373 - val_val_loss: 4.8110 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6478 - val_beta: 0.0373\n",
      "Epoch 3256/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 4.8408 - recon_loss: 0.0030 - KL loss: 2.6644 - beta: 0.0373 - val_val_loss: 4.8547 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6095 - val_beta: 0.0373\n",
      "Epoch 3257/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8380 - recon_loss: 0.0030 - KL loss: 2.6662 - beta: 0.0373 - val_val_loss: 4.8298 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6265 - val_beta: 0.0373\n",
      "Epoch 3258/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8454 - recon_loss: 0.0030 - KL loss: 2.6573 - beta: 0.0373 - val_val_loss: 4.7974 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6354 - val_beta: 0.0373\n",
      "Epoch 3259/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8333 - recon_loss: 0.0030 - KL loss: 2.6761 - beta: 0.0373 - val_val_loss: 4.8694 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6291 - val_beta: 0.0373\n",
      "Epoch 3260/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8291 - recon_loss: 0.0030 - KL loss: 2.6571 - beta: 0.0373 - val_val_loss: 4.8476 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6537 - val_beta: 0.0373\n",
      "Epoch 3261/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 4.8092 - recon_loss: 0.0030 - KL loss: 2.6539 - beta: 0.0373 - val_val_loss: 4.8372 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.6359 - val_beta: 0.0373\n",
      "Epoch 3262/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8171 - recon_loss: 0.0030 - KL loss: 2.6488 - beta: 0.0373 - val_val_loss: 4.8047 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6823 - val_beta: 0.0373\n",
      "Epoch 3263/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.8231 - recon_loss: 0.0030 - KL loss: 2.6745 - beta: 0.0373\n",
      "Epoch 03263: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8231 - recon_loss: 0.0030 - KL loss: 2.6745 - beta: 0.0373 - val_val_loss: 4.8269 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.6437 - val_beta: 0.0373\n",
      "Epoch 3264/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.8028 - recon_loss: 0.0030 - KL loss: 2.6698 - beta: 0.0373 - val_val_loss: 4.7902 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6900 - val_beta: 0.0373\n",
      "Epoch 3265/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7951 - recon_loss: 0.0029 - KL loss: 2.6766 - beta: 0.0373 - val_val_loss: 4.7895 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6900 - val_beta: 0.0373\n",
      "Epoch 3266/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.8021 - recon_loss: 0.0030 - KL loss: 2.6765 - beta: 0.0373 - val_val_loss: 4.7815 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6891 - val_beta: 0.0373\n",
      "Epoch 3267/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7978 - recon_loss: 0.0029 - KL loss: 2.6779 - beta: 0.0373 - val_val_loss: 4.7883 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.7232 - val_beta: 0.0373\n",
      "Epoch 3268/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.8003 - recon_loss: 0.0029 - KL loss: 2.6778 - beta: 0.0373 - val_val_loss: 4.7824 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6628 - val_beta: 0.0373\n",
      "Epoch 3269/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7824 - recon_loss: 0.0029 - KL loss: 2.6729 - beta: 0.0373 - val_val_loss: 4.8019 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6792 - val_beta: 0.0373\n",
      "Epoch 3270/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4.7896 - recon_loss: 0.0029 - KL loss: 2.6681 - beta: 0.0373 - val_val_loss: 4.7687 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6804 - val_beta: 0.0373\n",
      "Epoch 3271/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7903 - recon_loss: 0.0029 - KL loss: 2.6765 - beta: 0.0373 - val_val_loss: 4.7810 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6807 - val_beta: 0.0373\n",
      "Epoch 3272/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7896 - recon_loss: 0.0029 - KL loss: 2.6686 - beta: 0.0373 - val_val_loss: 4.7687 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6704 - val_beta: 0.0373\n",
      "Epoch 3273/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.7830 - recon_loss: 0.0029 - KL loss: 2.6724 - beta: 0.0373 - val_val_loss: 4.7763 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6826 - val_beta: 0.0373\n",
      "Epoch 3274/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7993 - recon_loss: 0.0030 - KL loss: 2.6751 - beta: 0.0373 - val_val_loss: 4.7719 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6805 - val_beta: 0.0373\n",
      "Epoch 3275/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.7901 - recon_loss: 0.0029 - KL loss: 2.6787 - beta: 0.0373\n",
      "Epoch 03275: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7901 - recon_loss: 0.0029 - KL loss: 2.6787 - beta: 0.0373 - val_val_loss: 4.7835 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6670 - val_beta: 0.0373\n",
      "Epoch 3276/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7820 - recon_loss: 0.0029 - KL loss: 2.6773 - beta: 0.0373 - val_val_loss: 4.7747 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6743 - val_beta: 0.0373\n",
      "Epoch 3277/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7809 - recon_loss: 0.0029 - KL loss: 2.6720 - beta: 0.0373 - val_val_loss: 4.7807 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6888 - val_beta: 0.0373\n",
      "Epoch 3278/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7850 - recon_loss: 0.0029 - KL loss: 2.6785 - beta: 0.0373 - val_val_loss: 4.7792 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6804 - val_beta: 0.0373\n",
      "Epoch 3279/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7867 - recon_loss: 0.0029 - KL loss: 2.6794 - beta: 0.0373 - val_val_loss: 4.7845 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6685 - val_beta: 0.0373\n",
      "Epoch 3280/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.7844 - recon_loss: 0.0029 - KL loss: 2.6805 - beta: 0.0373\n",
      "Epoch 03280: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4.7845 - recon_loss: 0.0029 - KL loss: 2.6805 - beta: 0.0373 - val_val_loss: 4.7833 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.6615 - val_beta: 0.0373\n",
      "Epoch 3280/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.6474 - recon_loss: 0.0020 - KL loss: 3.7323 - beta: 0.0228 - val_val_loss: 7.5248 - val_val_recon_loss: 0.0020 - val_val_KL loss: 3.6746 - val_beta: 0.0228\n",
      "Epoch 3281/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5561 - recon_loss: 0.0019 - KL loss: 3.7960 - beta: 0.0228 - val_val_loss: 7.4929 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8287 - val_beta: 0.0228\n",
      "Epoch 3282/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4918 - recon_loss: 0.0019 - KL loss: 3.8090 - beta: 0.0228 - val_val_loss: 7.5087 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7904 - val_beta: 0.0228\n",
      "Epoch 3283/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5180 - recon_loss: 0.0019 - KL loss: 3.8029 - beta: 0.0228 - val_val_loss: 7.4741 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7481 - val_beta: 0.0228\n",
      "Epoch 3284/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.4853 - recon_loss: 0.0019 - KL loss: 3.8139 - beta: 0.0228 - val_val_loss: 7.5199 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7829 - val_beta: 0.0228\n",
      "Epoch 3285/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5431 - recon_loss: 0.0019 - KL loss: 3.8161 - beta: 0.0228 - val_val_loss: 7.5142 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8182 - val_beta: 0.0228\n",
      "Epoch 3286/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5198 - recon_loss: 0.0019 - KL loss: 3.8134 - beta: 0.0228 - val_val_loss: 7.4672 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8331 - val_beta: 0.0228\n",
      "Epoch 3287/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.4946 - recon_loss: 0.0019 - KL loss: 3.8164 - beta: 0.0228 - val_val_loss: 7.5025 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8227 - val_beta: 0.0228\n",
      "Epoch 3288/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5109 - recon_loss: 0.0019 - KL loss: 3.8166 - beta: 0.0228 - val_val_loss: 7.5360 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7818 - val_beta: 0.0228\n",
      "Epoch 3289/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5833 - recon_loss: 0.0019 - KL loss: 3.8238 - beta: 0.0228 - val_val_loss: 7.5180 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8272 - val_beta: 0.0228\n",
      "Epoch 3290/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5553 - recon_loss: 0.0019 - KL loss: 3.8157 - beta: 0.0228 - val_val_loss: 7.4836 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7960 - val_beta: 0.0228\n",
      "Epoch 3291/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5121 - recon_loss: 0.0019 - KL loss: 3.8117 - beta: 0.0228 - val_val_loss: 7.4642 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7812 - val_beta: 0.0228\n",
      "Epoch 3292/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5183 - recon_loss: 0.0019 - KL loss: 3.8158 - beta: 0.0228 - val_val_loss: 7.4768 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8621 - val_beta: 0.0228\n",
      "Epoch 3293/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5367 - recon_loss: 0.0019 - KL loss: 3.8202 - beta: 0.0228 - val_val_loss: 7.4715 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7930 - val_beta: 0.0228\n",
      "Epoch 3294/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4983 - recon_loss: 0.0019 - KL loss: 3.8216 - beta: 0.0228 - val_val_loss: 7.5366 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8061 - val_beta: 0.0228\n",
      "Epoch 3295/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4732 - recon_loss: 0.0019 - KL loss: 3.8207 - beta: 0.0228 - val_val_loss: 7.4388 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8227 - val_beta: 0.0228\n",
      "Epoch 3296/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4605 - recon_loss: 0.0019 - KL loss: 3.8224 - beta: 0.0228 - val_val_loss: 7.5139 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7961 - val_beta: 0.0228\n",
      "Epoch 3297/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5846 - recon_loss: 0.0020 - KL loss: 3.8132 - beta: 0.0228 - val_val_loss: 7.6175 - val_val_recon_loss: 0.0020 - val_val_KL loss: 3.7718 - val_beta: 0.0228\n",
      "Epoch 3298/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5090 - recon_loss: 0.0019 - KL loss: 3.8148 - beta: 0.0228 - val_val_loss: 7.4433 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7718 - val_beta: 0.0228\n",
      "Epoch 3299/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4857 - recon_loss: 0.0019 - KL loss: 3.8251 - beta: 0.0228 - val_val_loss: 7.5251 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8544 - val_beta: 0.0228\n",
      "Epoch 3300/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.5325 - recon_loss: 0.0019 - KL loss: 3.8342 - beta: 0.0228\n",
      "Epoch 03300: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5325 - recon_loss: 0.0019 - KL loss: 3.8342 - beta: 0.0228 - val_val_loss: 7.6474 - val_val_recon_loss: 0.0020 - val_val_KL loss: 3.8131 - val_beta: 0.0228\n",
      "Epoch 3301/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.5969 - recon_loss: 0.0020 - KL loss: 3.8283 - beta: 0.0228 - val_val_loss: 7.5475 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8645 - val_beta: 0.0228\n",
      "Epoch 3302/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 7.6060 - recon_loss: 0.0020 - KL loss: 3.8368 - beta: 0.0228 - val_val_loss: 7.4901 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8284 - val_beta: 0.0228\n",
      "Epoch 3303/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4678 - recon_loss: 0.0019 - KL loss: 3.8161 - beta: 0.0228 - val_val_loss: 7.4645 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8452 - val_beta: 0.0228\n",
      "Epoch 3304/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4673 - recon_loss: 0.0019 - KL loss: 3.8177 - beta: 0.0228 - val_val_loss: 7.4174 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7976 - val_beta: 0.0228\n",
      "Epoch 3305/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4606 - recon_loss: 0.0019 - KL loss: 3.8231 - beta: 0.0228 - val_val_loss: 7.4303 - val_val_recon_loss: 0.0018 - val_val_KL loss: 3.8596 - val_beta: 0.0228\n",
      "Epoch 3306/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.4498 - recon_loss: 0.0019 - KL loss: 3.8331 - beta: 0.0228 - val_val_loss: 7.4355 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8319 - val_beta: 0.0228\n",
      "Epoch 3307/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4522 - recon_loss: 0.0019 - KL loss: 3.8357 - beta: 0.0228 - val_val_loss: 7.4087 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8066 - val_beta: 0.0228\n",
      "Epoch 3308/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4287 - recon_loss: 0.0019 - KL loss: 3.8221 - beta: 0.0228 - val_val_loss: 7.4235 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8062 - val_beta: 0.0228\n",
      "Epoch 3309/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4591 - recon_loss: 0.0019 - KL loss: 3.8184 - beta: 0.0228 - val_val_loss: 7.4534 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8201 - val_beta: 0.0228\n",
      "Epoch 3310/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.4531 - recon_loss: 0.0019 - KL loss: 3.8281 - beta: 0.0228 - val_val_loss: 7.4320 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8060 - val_beta: 0.0228\n",
      "Epoch 3311/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4265 - recon_loss: 0.0019 - KL loss: 3.8297 - beta: 0.0228 - val_val_loss: 7.4112 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8295 - val_beta: 0.0228\n",
      "Epoch 3312/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.4488 - recon_loss: 0.0019 - KL loss: 3.8363 - beta: 0.0228\n",
      "Epoch 03312: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 7.4488 - recon_loss: 0.0019 - KL loss: 3.8363 - beta: 0.0228 - val_val_loss: 7.4167 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.7867 - val_beta: 0.0228\n",
      "Epoch 3313/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 7.4047 - recon_loss: 0.0019 - KL loss: 3.8306 - beta: 0.0228 - val_val_loss: 7.3920 - val_val_recon_loss: 0.0018 - val_val_KL loss: 3.8420 - val_beta: 0.0228\n",
      "Epoch 3314/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 7.3897 - recon_loss: 0.0018 - KL loss: 3.8331 - beta: 0.0228 - val_val_loss: 7.4023 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8008 - val_beta: 0.0228\n",
      "Epoch 3315/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 7.4020 - recon_loss: 0.0019 - KL loss: 3.8228 - beta: 0.0228 - val_val_loss: 7.3775 - val_val_recon_loss: 0.0018 - val_val_KL loss: 3.8417 - val_beta: 0.0228\n",
      "Epoch 3316/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 7.4209 - recon_loss: 0.0019 - KL loss: 3.8372 - beta: 0.0228 - val_val_loss: 7.4354 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8118 - val_beta: 0.0228\n",
      "Epoch 3317/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 7.4476 - recon_loss: 0.0019 - KL loss: 3.8273 - beta: 0.0228 - val_val_loss: 7.4466 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8257 - val_beta: 0.0228\n",
      "Epoch 3318/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 7.4427 - recon_loss: 0.0019 - KL loss: 3.8277 - beta: 0.0228 - val_val_loss: 7.4153 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8220 - val_beta: 0.0228\n",
      "Epoch 3319/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 7.4198 - recon_loss: 0.0019 - KL loss: 3.8341 - beta: 0.0228 - val_val_loss: 7.3777 - val_val_recon_loss: 0.0018 - val_val_KL loss: 3.8094 - val_beta: 0.0228\n",
      "Epoch 3320/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.3657 - recon_loss: 0.0018 - KL loss: 3.8276 - beta: 0.0228\n",
      "Epoch 03320: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 7.3658 - recon_loss: 0.0018 - KL loss: 3.8276 - beta: 0.0228 - val_val_loss: 7.4075 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8133 - val_beta: 0.0228\n",
      "Epoch 3321/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 7.3928 - recon_loss: 0.0018 - KL loss: 3.8351 - beta: 0.0228 - val_val_loss: 7.3949 - val_val_recon_loss: 0.0018 - val_val_KL loss: 3.8394 - val_beta: 0.0228\n",
      "Epoch 3322/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 7.3723 - recon_loss: 0.0018 - KL loss: 3.8395 - beta: 0.0228 - val_val_loss: 7.4098 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8221 - val_beta: 0.0228\n",
      "Epoch 3323/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 7.4104 - recon_loss: 0.0019 - KL loss: 3.8273 - beta: 0.0228 - val_val_loss: 7.4115 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8205 - val_beta: 0.0228\n",
      "Epoch 3324/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.4197 - recon_loss: 0.0019 - KL loss: 3.8308 - beta: 0.0228 - val_val_loss: 7.4003 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8080 - val_beta: 0.0228\n",
      "Epoch 3325/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 7.4259 - recon_loss: 0.0019 - KL loss: 3.8290 - beta: 0.0228\n",
      "Epoch 03325: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 7.4259 - recon_loss: 0.0019 - KL loss: 3.8290 - beta: 0.0228 - val_val_loss: 7.4075 - val_val_recon_loss: 0.0019 - val_val_KL loss: 3.8258 - val_beta: 0.0228\n",
      "Epoch 3325/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.1246 - recon_loss: 0.0016 - KL loss: 4.8315 - beta: 0.0139 - val_val_loss: 13.1643 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.9256 - val_beta: 0.0139\n",
      "Epoch 3326/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.1790 - recon_loss: 0.0016 - KL loss: 4.9015 - beta: 0.0139 - val_val_loss: 13.2404 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.9835 - val_beta: 0.0139\n",
      "Epoch 3327/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.1226 - recon_loss: 0.0016 - KL loss: 4.9116 - beta: 0.0139 - val_val_loss: 13.6545 - val_val_recon_loss: 0.0017 - val_val_KL loss: 5.0103 - val_beta: 0.0139\n",
      "Epoch 3328/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.2901 - recon_loss: 0.0016 - KL loss: 4.9036 - beta: 0.0139 - val_val_loss: 13.1691 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.9338 - val_beta: 0.0139\n",
      "Epoch 3329/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.1359 - recon_loss: 0.0016 - KL loss: 4.9007 - beta: 0.0139 - val_val_loss: 13.0532 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.9309 - val_beta: 0.0139\n",
      "Epoch 3330/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.0273 - recon_loss: 0.0016 - KL loss: 4.8956 - beta: 0.0139 - val_val_loss: 13.0750 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.9030 - val_beta: 0.0139\n",
      "Epoch 3331/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.0574 - recon_loss: 0.0016 - KL loss: 4.9103 - beta: 0.0139 - val_val_loss: 13.2631 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.8982 - val_beta: 0.0139\n",
      "Epoch 3332/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.1795 - recon_loss: 0.0016 - KL loss: 4.9141 - beta: 0.0139 - val_val_loss: 13.1751 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.9150 - val_beta: 0.0139\n",
      "Epoch 3333/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.0807 - recon_loss: 0.0016 - KL loss: 4.9003 - beta: 0.0139 - val_val_loss: 13.0407 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.8900 - val_beta: 0.0139\n",
      "Epoch 3334/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.9800 - recon_loss: 0.0016 - KL loss: 4.8959 - beta: 0.0139 - val_val_loss: 12.9454 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.8519 - val_beta: 0.0139\n",
      "Epoch 3335/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.9419 - recon_loss: 0.0016 - KL loss: 4.8902 - beta: 0.0139 - val_val_loss: 12.8743 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9525 - val_beta: 0.0139\n",
      "Epoch 3336/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.8846 - recon_loss: 0.0015 - KL loss: 4.8909 - beta: 0.0139 - val_val_loss: 12.8551 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9742 - val_beta: 0.0139\n",
      "Epoch 3337/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.8103 - recon_loss: 0.0015 - KL loss: 4.9008 - beta: 0.0139 - val_val_loss: 12.9115 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9199 - val_beta: 0.0139\n",
      "Epoch 3338/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.9707 - recon_loss: 0.0016 - KL loss: 4.9048 - beta: 0.0139 - val_val_loss: 12.8292 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9166 - val_beta: 0.0139\n",
      "Epoch 3339/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.8784 - recon_loss: 0.0015 - KL loss: 4.8966 - beta: 0.0139 - val_val_loss: 12.8718 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.8375 - val_beta: 0.0139\n",
      "Epoch 3340/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.9470 - recon_loss: 0.0016 - KL loss: 4.9022 - beta: 0.0139 - val_val_loss: 12.9071 - val_val_recon_loss: 0.0016 - val_val_KL loss: 4.8660 - val_beta: 0.0139\n",
      "Epoch 3341/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.8258 - recon_loss: 0.0015 - KL loss: 4.8980 - beta: 0.0139 - val_val_loss: 12.9190 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8911 - val_beta: 0.0139\n",
      "Epoch 3342/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13.0337 - recon_loss: 0.0016 - KL loss: 4.9198 - beta: 0.0139 - val_val_loss: 12.9095 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9085 - val_beta: 0.0139\n",
      "Epoch 3343/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.8605 - recon_loss: 0.0015 - KL loss: 4.9029 - beta: 0.0139\n",
      "Epoch 03343: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.8605 - recon_loss: 0.0015 - KL loss: 4.9029 - beta: 0.0139 - val_val_loss: 12.8572 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8902 - val_beta: 0.0139\n",
      "Epoch 3344/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.8102 - recon_loss: 0.0015 - KL loss: 4.9153 - beta: 0.0139 - val_val_loss: 12.7787 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9023 - val_beta: 0.0139\n",
      "Epoch 3345/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.7641 - recon_loss: 0.0015 - KL loss: 4.9142 - beta: 0.0139 - val_val_loss: 12.6892 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8884 - val_beta: 0.0139\n",
      "Epoch 3346/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6818 - recon_loss: 0.0015 - KL loss: 4.9008 - beta: 0.0139 - val_val_loss: 12.6479 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9095 - val_beta: 0.0139\n",
      "Epoch 3347/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6541 - recon_loss: 0.0015 - KL loss: 4.8980 - beta: 0.0139 - val_val_loss: 12.6481 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9208 - val_beta: 0.0139\n",
      "Epoch 3348/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6926 - recon_loss: 0.0015 - KL loss: 4.9194 - beta: 0.0139 - val_val_loss: 12.6365 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8731 - val_beta: 0.0139\n",
      "Epoch 3349/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.6031 - recon_loss: 0.0015 - KL loss: 4.9158 - beta: 0.0139 - val_val_loss: 12.6674 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8949 - val_beta: 0.0139\n",
      "Epoch 3350/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.7572 - recon_loss: 0.0015 - KL loss: 4.9180 - beta: 0.0139 - val_val_loss: 12.6583 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8927 - val_beta: 0.0139\n",
      "Epoch 3351/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6166 - recon_loss: 0.0015 - KL loss: 4.9062 - beta: 0.0139 - val_val_loss: 12.6374 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9160 - val_beta: 0.0139\n",
      "Epoch 3352/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6355 - recon_loss: 0.0015 - KL loss: 4.9158 - beta: 0.0139 - val_val_loss: 12.6923 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9250 - val_beta: 0.0139\n",
      "Epoch 3353/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 12.7113 - recon_loss: 0.0015 - KL loss: 4.9308 - beta: 0.0139\n",
      "Epoch 03353: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.7113 - recon_loss: 0.0015 - KL loss: 4.9308 - beta: 0.0139 - val_val_loss: 12.6825 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9008 - val_beta: 0.0139\n",
      "Epoch 3354/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.6537 - recon_loss: 0.0015 - KL loss: 4.9187 - beta: 0.0139 - val_val_loss: 12.6300 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9325 - val_beta: 0.0139\n",
      "Epoch 3355/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5900 - recon_loss: 0.0015 - KL loss: 4.9256 - beta: 0.0139 - val_val_loss: 12.6536 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9219 - val_beta: 0.0139\n",
      "Epoch 3356/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.6502 - recon_loss: 0.0015 - KL loss: 4.9277 - beta: 0.0139 - val_val_loss: 12.6222 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9129 - val_beta: 0.0139\n",
      "Epoch 3357/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6254 - recon_loss: 0.0015 - KL loss: 4.9106 - beta: 0.0139 - val_val_loss: 12.6395 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8994 - val_beta: 0.0139\n",
      "Epoch 3358/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6450 - recon_loss: 0.0015 - KL loss: 4.9230 - beta: 0.0139 - val_val_loss: 12.6193 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9106 - val_beta: 0.0139\n",
      "Epoch 3359/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6767 - recon_loss: 0.0015 - KL loss: 4.9197 - beta: 0.0139 - val_val_loss: 12.6028 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9002 - val_beta: 0.0139\n",
      "Epoch 3360/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6668 - recon_loss: 0.0015 - KL loss: 4.9102 - beta: 0.0139 - val_val_loss: 12.5874 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9170 - val_beta: 0.0139\n",
      "Epoch 3361/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5724 - recon_loss: 0.0015 - KL loss: 4.9232 - beta: 0.0139 - val_val_loss: 12.5807 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9219 - val_beta: 0.0139\n",
      "Epoch 3362/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5458 - recon_loss: 0.0015 - KL loss: 4.9229 - beta: 0.0139 - val_val_loss: 12.6100 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9024 - val_beta: 0.0139\n",
      "Epoch 3363/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5843 - recon_loss: 0.0015 - KL loss: 4.9118 - beta: 0.0139 - val_val_loss: 12.5710 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9269 - val_beta: 0.0139\n",
      "Epoch 3364/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5574 - recon_loss: 0.0015 - KL loss: 4.9134 - beta: 0.0139 - val_val_loss: 12.6013 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9186 - val_beta: 0.0139\n",
      "Epoch 3365/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5854 - recon_loss: 0.0015 - KL loss: 4.9166 - beta: 0.0139 - val_val_loss: 12.5835 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9011 - val_beta: 0.0139\n",
      "Epoch 3366/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.6061 - recon_loss: 0.0015 - KL loss: 4.9170 - beta: 0.0139 - val_val_loss: 12.5917 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9052 - val_beta: 0.0139\n",
      "Epoch 3367/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5067 - recon_loss: 0.0015 - KL loss: 4.9151 - beta: 0.0139 - val_val_loss: 12.5942 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9119 - val_beta: 0.0139\n",
      "Epoch 3368/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.5657 - recon_loss: 0.0015 - KL loss: 4.9115 - beta: 0.0139\n",
      "Epoch 03368: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5657 - recon_loss: 0.0015 - KL loss: 4.9115 - beta: 0.0139 - val_val_loss: 12.5936 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9280 - val_beta: 0.0139\n",
      "Epoch 3369/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5906 - recon_loss: 0.0015 - KL loss: 4.9231 - beta: 0.0139 - val_val_loss: 12.5949 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9198 - val_beta: 0.0139\n",
      "Epoch 3370/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6025 - recon_loss: 0.0015 - KL loss: 4.9158 - beta: 0.0139 - val_val_loss: 12.5816 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9104 - val_beta: 0.0139\n",
      "Epoch 3371/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5657 - recon_loss: 0.0015 - KL loss: 4.9173 - beta: 0.0139 - val_val_loss: 12.6459 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9066 - val_beta: 0.0139\n",
      "Epoch 3372/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5799 - recon_loss: 0.0015 - KL loss: 4.9111 - beta: 0.0139 - val_val_loss: 12.6020 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8988 - val_beta: 0.0139\n",
      "Epoch 3373/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5494 - recon_loss: 0.0015 - KL loss: 4.9037 - beta: 0.0139 - val_val_loss: 12.5601 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.8968 - val_beta: 0.0139\n",
      "Epoch 3374/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5455 - recon_loss: 0.0015 - KL loss: 4.9044 - beta: 0.0139 - val_val_loss: 12.5290 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9192 - val_beta: 0.0139\n",
      "Epoch 3375/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5963 - recon_loss: 0.0015 - KL loss: 4.9136 - beta: 0.0139 - val_val_loss: 12.5670 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9032 - val_beta: 0.0139\n",
      "Epoch 3376/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 12.5308 - recon_loss: 0.0015 - KL loss: 4.9087 - beta: 0.0139 - val_val_loss: 12.5876 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9004 - val_beta: 0.0139\n",
      "Epoch 3377/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5240 - recon_loss: 0.0015 - KL loss: 4.9112 - beta: 0.0139 - val_val_loss: 12.5854 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9162 - val_beta: 0.0139\n",
      "Epoch 3378/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6386 - recon_loss: 0.0015 - KL loss: 4.9129 - beta: 0.0139 - val_val_loss: 12.5863 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9011 - val_beta: 0.0139\n",
      "Epoch 3379/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.4717 - recon_loss: 0.0015 - KL loss: 4.9091 - beta: 0.0139\n",
      "Epoch 03379: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.4718 - recon_loss: 0.0015 - KL loss: 4.9091 - beta: 0.0139 - val_val_loss: 12.5619 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9153 - val_beta: 0.0139\n",
      "Epoch 3380/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12.5075 - recon_loss: 0.0015 - KL loss: 4.9182 - beta: 0.0139 - val_val_loss: 12.5503 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9142 - val_beta: 0.0139\n",
      "Epoch 3381/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5600 - recon_loss: 0.0015 - KL loss: 4.9156 - beta: 0.0139 - val_val_loss: 12.5593 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9133 - val_beta: 0.0139\n",
      "Epoch 3382/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5477 - recon_loss: 0.0015 - KL loss: 4.9147 - beta: 0.0139 - val_val_loss: 12.5471 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9124 - val_beta: 0.0139\n",
      "Epoch 3383/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.6113 - recon_loss: 0.0015 - KL loss: 4.9110 - beta: 0.0139 - val_val_loss: 12.5533 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9149 - val_beta: 0.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3384/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12.5575 - recon_loss: 0.0015 - KL loss: 4.9212 - beta: 0.0139\n",
      "Epoch 03384: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12.5575 - recon_loss: 0.0015 - KL loss: 4.9212 - beta: 0.0139 - val_val_loss: 12.5345 - val_val_recon_loss: 0.0015 - val_val_KL loss: 4.9148 - val_beta: 0.0139\n",
      "Epoch 3384/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.2867 - recon_loss: 0.0014 - KL loss: 5.8802 - beta: 0.0085 - val_val_loss: 25.5553 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.9241 - val_beta: 0.0085\n",
      "Epoch 3385/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.4701 - recon_loss: 0.0014 - KL loss: 5.9655 - beta: 0.0085 - val_val_loss: 25.4412 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.9231 - val_beta: 0.0085\n",
      "Epoch 3386/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 24.9942 - recon_loss: 0.0014 - KL loss: 5.9998 - beta: 0.0085 - val_val_loss: 25.0165 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0614 - val_beta: 0.0085\n",
      "Epoch 3387/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.2043 - recon_loss: 0.0014 - KL loss: 5.9996 - beta: 0.0085 - val_val_loss: 25.2364 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.9715 - val_beta: 0.0085\n",
      "Epoch 3388/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 24.8963 - recon_loss: 0.0014 - KL loss: 5.9947 - beta: 0.0085 - val_val_loss: 24.8369 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0450 - val_beta: 0.0085\n",
      "Epoch 3389/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.4457 - recon_loss: 0.0014 - KL loss: 6.0267 - beta: 0.0085 - val_val_loss: 25.2241 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0922 - val_beta: 0.0085\n",
      "Epoch 3390/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.6584 - recon_loss: 0.0014 - KL loss: 6.0177 - beta: 0.0085 - val_val_loss: 25.3647 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0893 - val_beta: 0.0085\n",
      "Epoch 3391/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 26.0279 - recon_loss: 0.0014 - KL loss: 6.0329 - beta: 0.0085 - val_val_loss: 26.7736 - val_val_recon_loss: 0.0015 - val_val_KL loss: 6.0723 - val_beta: 0.0085\n",
      "Epoch 3392/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 26.6986 - recon_loss: 0.0015 - KL loss: 6.0819 - beta: 0.0085 - val_val_loss: 26.5819 - val_val_recon_loss: 0.0015 - val_val_KL loss: 6.1555 - val_beta: 0.0085\n",
      "Epoch 3393/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 26.4520 - recon_loss: 0.0015 - KL loss: 6.0765 - beta: 0.0085\n",
      "Epoch 03393: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 26.4518 - recon_loss: 0.0015 - KL loss: 6.0765 - beta: 0.0085 - val_val_loss: 25.7757 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0985 - val_beta: 0.0085\n",
      "Epoch 3394/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.6292 - recon_loss: 0.0014 - KL loss: 6.0312 - beta: 0.0085 - val_val_loss: 25.3888 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0047 - val_beta: 0.0085\n",
      "Epoch 3395/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.4530 - recon_loss: 0.0014 - KL loss: 5.9870 - beta: 0.0085 - val_val_loss: 25.5601 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.9791 - val_beta: 0.0085\n",
      "Epoch 3396/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.6082 - recon_loss: 0.0014 - KL loss: 6.0104 - beta: 0.0085 - val_val_loss: 25.3848 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0308 - val_beta: 0.0085\n",
      "Epoch 3397/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 25.4286 - recon_loss: 0.0014 - KL loss: 6.0185 - beta: 0.0085 - val_val_loss: 25.4760 - val_val_recon_loss: 0.0014 - val_val_KL loss: 5.9961 - val_beta: 0.0085\n",
      "Epoch 3398/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 25.5173 - recon_loss: 0.0014 - KL loss: 6.0032 - beta: 0.0085\n",
      "Epoch 03398: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 25.5171 - recon_loss: 0.0014 - KL loss: 6.0032 - beta: 0.0085 - val_val_loss: 25.2545 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.0520 - val_beta: 0.0085\n",
      "Epoch 3398/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 59.4270 - recon_loss: 0.0014 - KL loss: 7.0027 - beta: 0.0052 - val_val_loss: 58.6708 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.1279 - val_beta: 0.0052\n",
      "Epoch 3399/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 58.9463 - recon_loss: 0.0014 - KL loss: 7.1264 - beta: 0.0052 - val_val_loss: 57.6729 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.2927 - val_beta: 0.0052\n",
      "Epoch 3400/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 57.6500 - recon_loss: 0.0014 - KL loss: 7.1477 - beta: 0.0052 - val_val_loss: 57.1366 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.0952 - val_beta: 0.0052\n",
      "Epoch 3401/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 56.7000 - recon_loss: 0.0013 - KL loss: 7.0652 - beta: 0.0052 - val_val_loss: 56.5030 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2526 - val_beta: 0.0052\n",
      "Epoch 3402/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 56.5153 - recon_loss: 0.0013 - KL loss: 7.1168 - beta: 0.0052 - val_val_loss: 56.5566 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.1404 - val_beta: 0.0052\n",
      "Epoch 3403/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 56.6256 - recon_loss: 0.0013 - KL loss: 7.0759 - beta: 0.0052 - val_val_loss: 56.0388 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.0306 - val_beta: 0.0052\n",
      "Epoch 3404/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 56.2409 - recon_loss: 0.0013 - KL loss: 7.0815 - beta: 0.0052 - val_val_loss: 58.5218 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.1422 - val_beta: 0.0052\n",
      "Epoch 3405/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 57.7491 - recon_loss: 0.0014 - KL loss: 7.1957 - beta: 0.0052 - val_val_loss: 59.9867 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.2332 - val_beta: 0.0052\n",
      "Epoch 3406/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 58.6558 - recon_loss: 0.0014 - KL loss: 7.2323 - beta: 0.0052 - val_val_loss: 58.1630 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.3529 - val_beta: 0.0052\n",
      "Epoch 3407/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 57.4079 - recon_loss: 0.0013 - KL loss: 7.2746 - beta: 0.0052 - val_val_loss: 57.1006 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2802 - val_beta: 0.0052\n",
      "Epoch 3408/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 57.4824 - recon_loss: 0.0013 - KL loss: 7.1834 - beta: 0.0052\n",
      "Epoch 03408: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 57.4823 - recon_loss: 0.0013 - KL loss: 7.1834 - beta: 0.0052 - val_val_loss: 56.4063 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.1672 - val_beta: 0.0052\n",
      "Epoch 3409/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 56.4650 - recon_loss: 0.0013 - KL loss: 7.1338 - beta: 0.0052 - val_val_loss: 56.1593 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.1692 - val_beta: 0.0052\n",
      "Epoch 3410/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 56.8075 - recon_loss: 0.0013 - KL loss: 7.1690 - beta: 0.0052 - val_val_loss: 56.3604 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.1926 - val_beta: 0.0052\n",
      "Epoch 3411/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 56.2188 - recon_loss: 0.0013 - KL loss: 7.1803 - beta: 0.0052 - val_val_loss: 55.7044 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.1444 - val_beta: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3412/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 56.1721 - recon_loss: 0.0013 - KL loss: 7.1531 - beta: 0.0052 - val_val_loss: 57.6387 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.1492 - val_beta: 0.0052\n",
      "Epoch 3413/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 56.6391 - recon_loss: 0.0013 - KL loss: 7.2086 - beta: 0.0052 - val_val_loss: 57.4025 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.1867 - val_beta: 0.0052\n",
      "Epoch 3414/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 57.5593 - recon_loss: 0.0014 - KL loss: 7.2190 - beta: 0.0052 - val_val_loss: 58.0413 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.2896 - val_beta: 0.0052\n",
      "Epoch 3415/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 57.9997 - recon_loss: 0.0014 - KL loss: 7.2179 - beta: 0.0052 - val_val_loss: 59.1839 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.3018 - val_beta: 0.0052\n",
      "Epoch 3416/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 58.8892 - recon_loss: 0.0014 - KL loss: 7.2997 - beta: 0.0052\n",
      "Epoch 03416: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 58.8888 - recon_loss: 0.0014 - KL loss: 7.2997 - beta: 0.0052 - val_val_loss: 57.3502 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.3105 - val_beta: 0.0052\n",
      "Epoch 3417/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 57.2820 - recon_loss: 0.0013 - KL loss: 7.3062 - beta: 0.0052 - val_val_loss: 57.8503 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.2606 - val_beta: 0.0052\n",
      "Epoch 3418/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 57.5502 - recon_loss: 0.0013 - KL loss: 7.2373 - beta: 0.0052 - val_val_loss: 57.5055 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2550 - val_beta: 0.0052\n",
      "Epoch 3419/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 57.1987 - recon_loss: 0.0013 - KL loss: 7.2670 - beta: 0.0052 - val_val_loss: 57.1450 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2979 - val_beta: 0.0052\n",
      "Epoch 3420/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 56.4881 - recon_loss: 0.0013 - KL loss: 7.2910 - beta: 0.0052 - val_val_loss: 57.0191 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2521 - val_beta: 0.0052\n",
      "Epoch 3421/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 56.8802 - recon_loss: 0.0013 - KL loss: 7.2531 - beta: 0.0052\n",
      "Epoch 03421: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 56.8803 - recon_loss: 0.0013 - KL loss: 7.2531 - beta: 0.0052 - val_val_loss: 57.3271 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2185 - val_beta: 0.0052\n",
      "Epoch 3421/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 147.2177 - recon_loss: 0.0014 - KL loss: 8.1457 - beta: 0.0032 - val_val_loss: 141.0450 - val_val_recon_loss: 0.0013 - val_val_KL loss: 8.2686 - val_beta: 0.0032\n",
      "Epoch 3422/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 140.6397 - recon_loss: 0.0013 - KL loss: 8.3472 - beta: 0.0032 - val_val_loss: 140.3017 - val_val_recon_loss: 0.0013 - val_val_KL loss: 8.2077 - val_beta: 0.0032\n",
      "Epoch 3423/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 138.0632 - recon_loss: 0.0013 - KL loss: 8.1595 - beta: 0.0032 - val_val_loss: 139.1128 - val_val_recon_loss: 0.0013 - val_val_KL loss: 8.2820 - val_beta: 0.0032\n",
      "Epoch 3424/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 138.6866 - recon_loss: 0.0013 - KL loss: 8.2641 - beta: 0.0032 - val_val_loss: 143.3583 - val_val_recon_loss: 0.0013 - val_val_KL loss: 8.5080 - val_beta: 0.0032\n",
      "Epoch 3425/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 146.9553 - recon_loss: 0.0014 - KL loss: 8.4989 - beta: 0.0032 - val_val_loss: 144.8592 - val_val_recon_loss: 0.0014 - val_val_KL loss: 8.7062 - val_beta: 0.0032\n",
      "Epoch 3426/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 146.1299 - recon_loss: 0.0014 - KL loss: 8.7831 - beta: 0.0032 - val_val_loss: 143.5051 - val_val_recon_loss: 0.0013 - val_val_KL loss: 8.6315 - val_beta: 0.0032\n",
      "Epoch 3427/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 143.8764 - recon_loss: 0.0013 - KL loss: 8.9556 - beta: 0.0032 - val_val_loss: 148.6463 - val_val_recon_loss: 0.0014 - val_val_KL loss: 9.7857 - val_beta: 0.0032\n",
      "Epoch 3428/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 143.8496 - recon_loss: 0.0013 - KL loss: 10.0790 - beta: 0.0032\n",
      "Epoch 03428: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 143.8474 - recon_loss: 0.0013 - KL loss: 10.0793 - beta: 0.0032 - val_val_loss: 139.1210 - val_val_recon_loss: 0.0013 - val_val_KL loss: 11.0682 - val_beta: 0.0032\n",
      "Epoch 3429/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 136.4204 - recon_loss: 0.0013 - KL loss: 10.9484 - beta: 0.0032 - val_val_loss: 135.6033 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.2619 - val_beta: 0.0032\n",
      "Epoch 3430/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 134.9727 - recon_loss: 0.0012 - KL loss: 11.2366 - beta: 0.0032 - val_val_loss: 133.8284 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.2129 - val_beta: 0.0032\n",
      "Epoch 3431/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 134.2440 - recon_loss: 0.0012 - KL loss: 11.3091 - beta: 0.0032 - val_val_loss: 131.0860 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.2652 - val_beta: 0.0032\n",
      "Epoch 3432/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 132.4570 - recon_loss: 0.0012 - KL loss: 11.2679 - beta: 0.0032 - val_val_loss: 131.5077 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.4892 - val_beta: 0.0032\n",
      "Epoch 3433/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 130.5378 - recon_loss: 0.0012 - KL loss: 11.3271 - beta: 0.0032 - val_val_loss: 128.1512 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.2945 - val_beta: 0.0032\n",
      "Epoch 3434/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 128.2637 - recon_loss: 0.0012 - KL loss: 11.2772 - beta: 0.0032 - val_val_loss: 128.8490 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.2782 - val_beta: 0.0032\n",
      "Epoch 3435/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 127.5568 - recon_loss: 0.0012 - KL loss: 11.3282 - beta: 0.0032 - val_val_loss: 130.3728 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.8156 - val_beta: 0.0032\n",
      "Epoch 3436/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 129.6619 - recon_loss: 0.0012 - KL loss: 11.7972 - beta: 0.0032 - val_val_loss: 129.5359 - val_val_recon_loss: 0.0012 - val_val_KL loss: 11.8919 - val_beta: 0.0032\n",
      "Epoch 3437/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 129.0074 - recon_loss: 0.0012 - KL loss: 11.9613 - beta: 0.0032 - val_val_loss: 128.8930 - val_val_recon_loss: 0.0012 - val_val_KL loss: 12.2293 - val_beta: 0.0032\n",
      "Epoch 3438/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 128.4864 - recon_loss: 0.0012 - KL loss: 11.9489 - beta: 0.0032 - val_val_loss: 126.4020 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.6485 - val_beta: 0.0032\n",
      "Epoch 3439/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 125.3830 - recon_loss: 0.0011 - KL loss: 11.5957 - beta: 0.0032 - val_val_loss: 124.9555 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.5022 - val_beta: 0.0032\n",
      "Epoch 3440/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 124.6662 - recon_loss: 0.0011 - KL loss: 11.5359 - beta: 0.0032 - val_val_loss: 124.7718 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.4932 - val_beta: 0.0032\n",
      "Epoch 3441/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 124.6035 - recon_loss: 0.0011 - KL loss: 11.3632 - beta: 0.0032 - val_val_loss: 123.3791 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.7199 - val_beta: 0.0032\n",
      "Epoch 3442/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 121.9436 - recon_loss: 0.0011 - KL loss: 11.5229 - beta: 0.0032 - val_val_loss: 121.4238 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.3993 - val_beta: 0.0032\n",
      "Epoch 3443/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 121.8248 - recon_loss: 0.0011 - KL loss: 11.4395 - beta: 0.0032 - val_val_loss: 121.4511 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.6106 - val_beta: 0.0032\n",
      "Epoch 3444/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 120.6986 - recon_loss: 0.0011 - KL loss: 11.5882 - beta: 0.0032 - val_val_loss: 121.2995 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.7032 - val_beta: 0.0032\n",
      "Epoch 3445/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 121.6328 - recon_loss: 0.0011 - KL loss: 11.6547 - beta: 0.0032 - val_val_loss: 120.6014 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.7980 - val_beta: 0.0032\n",
      "Epoch 3446/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.2297 - recon_loss: 0.0011 - KL loss: 11.7090 - beta: 0.0032 - val_val_loss: 119.8358 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.7896 - val_beta: 0.0032\n",
      "Epoch 3447/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 119.2147 - recon_loss: 0.0011 - KL loss: 11.7615 - beta: 0.0032 - val_val_loss: 120.9678 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.9081 - val_beta: 0.0032\n",
      "Epoch 3448/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.5835 - recon_loss: 0.0011 - KL loss: 11.8856 - beta: 0.0032 - val_val_loss: 121.2702 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.9674 - val_beta: 0.0032\n",
      "Epoch 3449/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.2607 - recon_loss: 0.0011 - KL loss: 11.8819 - beta: 0.0032 - val_val_loss: 121.9831 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.8390 - val_beta: 0.0032\n",
      "Epoch 3450/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.5278 - recon_loss: 0.0011 - KL loss: 11.8661 - beta: 0.0032 - val_val_loss: 119.2624 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.8467 - val_beta: 0.0032\n",
      "Epoch 3451/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.4548 - recon_loss: 0.0011 - KL loss: 11.8459 - beta: 0.0032 - val_val_loss: 119.1767 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.8169 - val_beta: 0.0032\n",
      "Epoch 3452/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.9800 - recon_loss: 0.0011 - KL loss: 12.0158 - beta: 0.0032 - val_val_loss: 122.3100 - val_val_recon_loss: 0.0011 - val_val_KL loss: 12.1172 - val_beta: 0.0032\n",
      "Epoch 3453/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 120.5893 - recon_loss: 0.0011 - KL loss: 12.1252 - beta: 0.0032 - val_val_loss: 121.0097 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.9783 - val_beta: 0.0032\n",
      "Epoch 3454/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 122.7140 - recon_loss: 0.0011 - KL loss: 12.0121 - beta: 0.0032 - val_val_loss: 120.6001 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.9752 - val_beta: 0.0032\n",
      "Epoch 3455/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 119.9809 - recon_loss: 0.0011 - KL loss: 12.0193 - beta: 0.0032 - val_val_loss: 120.4930 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.9760 - val_beta: 0.0032\n",
      "Epoch 3456/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 121.1008 - recon_loss: 0.0011 - KL loss: 12.0124 - beta: 0.0032\n",
      "Epoch 03456: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 121.0999 - recon_loss: 0.0011 - KL loss: 12.0124 - beta: 0.0032 - val_val_loss: 120.6186 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.9297 - val_beta: 0.0032\n",
      "Epoch 3457/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 121.0598 - recon_loss: 0.0011 - KL loss: 12.0571 - beta: 0.0032 - val_val_loss: 119.8642 - val_val_recon_loss: 0.0011 - val_val_KL loss: 12.1514 - val_beta: 0.0032\n",
      "Epoch 3458/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 119.1310 - recon_loss: 0.0011 - KL loss: 12.1312 - beta: 0.0032 - val_val_loss: 120.5394 - val_val_recon_loss: 0.0011 - val_val_KL loss: 12.2162 - val_beta: 0.0032\n",
      "Epoch 3459/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 120.5750 - recon_loss: 0.0011 - KL loss: 12.1924 - beta: 0.0032 - val_val_loss: 120.5201 - val_val_recon_loss: 0.0011 - val_val_KL loss: 12.2176 - val_beta: 0.0032\n",
      "Epoch 3460/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 120.7321 - recon_loss: 0.0011 - KL loss: 12.2143 - beta: 0.0032 - val_val_loss: 119.3991 - val_val_recon_loss: 0.0011 - val_val_KL loss: 12.1719 - val_beta: 0.0032\n",
      "Epoch 3461/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 120.7489 - recon_loss: 0.0011 - KL loss: 12.2163 - beta: 0.0032\n",
      "Epoch 03461: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 120.7487 - recon_loss: 0.0011 - KL loss: 12.2163 - beta: 0.0032 - val_val_loss: 119.9794 - val_val_recon_loss: 0.0011 - val_val_KL loss: 12.1708 - val_beta: 0.0032\n",
      "Epoch 3461/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 314.7493 - recon_loss: 0.0011 - KL loss: 14.8120 - beta: 0.0019 - val_val_loss: 310.0626 - val_val_recon_loss: 0.0011 - val_val_KL loss: 16.3244 - val_beta: 0.0019\n",
      "Epoch 3462/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 307.3261 - recon_loss: 0.0011 - KL loss: 16.5442 - beta: 0.0019 - val_val_loss: 307.1768 - val_val_recon_loss: 0.0011 - val_val_KL loss: 16.9640 - val_beta: 0.0019\n",
      "Epoch 3463/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 303.2117 - recon_loss: 0.0011 - KL loss: 16.1469 - beta: 0.0019 - val_val_loss: 296.0112 - val_val_recon_loss: 0.0010 - val_val_KL loss: 15.9363 - val_beta: 0.0019\n",
      "Epoch 3464/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 296.7651 - recon_loss: 0.0010 - KL loss: 16.3662 - beta: 0.0019 - val_val_loss: 307.4694 - val_val_recon_loss: 0.0011 - val_val_KL loss: 17.0531 - val_beta: 0.0019\n",
      "Epoch 3465/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 310.2494 - recon_loss: 0.0011 - KL loss: 17.1850 - beta: 0.0019 - val_val_loss: 312.6570 - val_val_recon_loss: 0.0011 - val_val_KL loss: 18.7749 - val_beta: 0.0019\n",
      "Epoch 3466/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 310.5964 - recon_loss: 0.0011 - KL loss: 17.5706 - beta: 0.0019 - val_val_loss: 305.1532 - val_val_recon_loss: 0.0011 - val_val_KL loss: 17.8765 - val_beta: 0.0019\n",
      "Epoch 3467/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 305.5029 - recon_loss: 0.0011 - KL loss: 17.9711 - beta: 0.0019 - val_val_loss: 316.0296 - val_val_recon_loss: 0.0011 - val_val_KL loss: 18.7766 - val_beta: 0.0019\n",
      "Epoch 3468/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 309.0551 - recon_loss: 0.0011 - KL loss: 18.8004 - beta: 0.0019\n",
      "Epoch 03468: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 309.0540 - recon_loss: 0.0011 - KL loss: 18.8004 - beta: 0.0019 - val_val_loss: 306.8905 - val_val_recon_loss: 0.0011 - val_val_KL loss: 18.8707 - val_beta: 0.0019\n",
      "Epoch 3469/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 302.0248 - recon_loss: 0.0011 - KL loss: 18.5872 - beta: 0.0019 - val_val_loss: 298.4450 - val_val_recon_loss: 0.0010 - val_val_KL loss: 18.4077 - val_beta: 0.0019\n",
      "Epoch 3470/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 299.7363 - recon_loss: 0.0010 - KL loss: 18.3057 - beta: 0.0019 - val_val_loss: 293.3787 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.9454 - val_beta: 0.0019\n",
      "Epoch 3471/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 294.6204 - recon_loss: 0.0010 - KL loss: 17.8711 - beta: 0.0019 - val_val_loss: 293.7485 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.8666 - val_beta: 0.0019\n",
      "Epoch 3472/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 290.9760 - recon_loss: 0.0010 - KL loss: 17.7414 - beta: 0.0019 - val_val_loss: 292.3014 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.5055 - val_beta: 0.0019\n",
      "Epoch 3473/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 289.4732 - recon_loss: 0.0010 - KL loss: 17.4951 - beta: 0.0019 - val_val_loss: 288.3490 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.4851 - val_beta: 0.0019\n",
      "Epoch 3474/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 285.7910 - recon_loss: 0.0010 - KL loss: 17.3547 - beta: 0.0019 - val_val_loss: 286.7814 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.0843 - val_beta: 0.0019\n",
      "Epoch 3475/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 285.0678 - recon_loss: 9.9886e-04 - KL loss: 17.1032 - beta: 0.0019 - val_val_loss: 285.6054 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.0111 - val_beta: 0.0019\n",
      "Epoch 3476/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 285.0781 - recon_loss: 9.9981e-04 - KL loss: 16.8591 - beta: 0.0019 - val_val_loss: 286.0237 - val_val_recon_loss: 0.0010 - val_val_KL loss: 16.7450 - val_beta: 0.0019\n",
      "Epoch 3477/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 287.2605 - recon_loss: 0.0010 - KL loss: 16.6021 - beta: 0.0019 - val_val_loss: 283.6970 - val_val_recon_loss: 9.9551e-04 - val_val_KL loss: 16.6330 - val_beta: 0.0019\n",
      "Epoch 3478/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 283.5180 - recon_loss: 9.9425e-04 - KL loss: 16.7901 - beta: 0.0019 - val_val_loss: 282.0058 - val_val_recon_loss: 9.8943e-04 - val_val_KL loss: 16.5713 - val_beta: 0.0019\n",
      "Epoch 3479/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 282.8401 - recon_loss: 9.9328e-04 - KL loss: 16.3738 - beta: 0.0019 - val_val_loss: 282.7943 - val_val_recon_loss: 9.9439e-04 - val_val_KL loss: 16.0304 - val_beta: 0.0019\n",
      "Epoch 3480/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 281.2365 - recon_loss: 9.8848e-04 - KL loss: 16.0562 - beta: 0.0019 - val_val_loss: 288.2583 - val_val_recon_loss: 0.0010 - val_val_KL loss: 16.3094 - val_beta: 0.0019\n",
      "Epoch 3481/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 282.3771 - recon_loss: 9.9226e-04 - KL loss: 16.1853 - beta: 0.0019 - val_val_loss: 282.1797 - val_val_recon_loss: 9.9201e-04 - val_val_KL loss: 16.0534 - val_beta: 0.0019\n",
      "Epoch 3482/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 281.4171 - recon_loss: 9.8943e-04 - KL loss: 15.9827 - beta: 0.0019 - val_val_loss: 281.1472 - val_val_recon_loss: 9.8801e-04 - val_val_KL loss: 16.0951 - val_beta: 0.0019\n",
      "Epoch 3483/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 278.2643 - recon_loss: 9.7824e-04 - KL loss: 15.8330 - beta: 0.0019 - val_val_loss: 278.5416 - val_val_recon_loss: 9.7886e-04 - val_val_KL loss: 15.9427 - val_beta: 0.0019\n",
      "Epoch 3484/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 279.9469 - recon_loss: 9.8457e-04 - KL loss: 15.8168 - beta: 0.0019 - val_val_loss: 278.1648 - val_val_recon_loss: 9.7875e-04 - val_val_KL loss: 15.5966 - val_beta: 0.0019\n",
      "Epoch 3485/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 278.1447 - recon_loss: 9.7887e-04 - KL loss: 15.5440 - beta: 0.0019 - val_val_loss: 277.3176 - val_val_recon_loss: 9.7620e-04 - val_val_KL loss: 15.4321 - val_beta: 0.0019\n",
      "Epoch 3486/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 276.0290 - recon_loss: 9.7143e-04 - KL loss: 15.4252 - beta: 0.0019 - val_val_loss: 278.1014 - val_val_recon_loss: 9.8006e-04 - val_val_KL loss: 15.1820 - val_beta: 0.0019\n",
      "Epoch 3487/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 276.9858 - recon_loss: 9.7571e-04 - KL loss: 15.2336 - beta: 0.0019 - val_val_loss: 275.4843 - val_val_recon_loss: 9.7034e-04 - val_val_KL loss: 15.1711 - val_beta: 0.0019\n",
      "Epoch 3488/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 277.2073 - recon_loss: 9.7647e-04 - KL loss: 15.2508 - beta: 0.0019 - val_val_loss: 275.4694 - val_val_recon_loss: 9.7034e-04 - val_val_KL loss: 15.1578 - val_beta: 0.0019\n",
      "Epoch 3489/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 276.4178 - recon_loss: 9.7425e-04 - KL loss: 15.0556 - beta: 0.0019 - val_val_loss: 275.2845 - val_val_recon_loss: 9.7047e-04 - val_val_KL loss: 14.9366 - val_beta: 0.0019\n",
      "Epoch 3490/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 277.0936 - recon_loss: 9.7734e-04 - KL loss: 14.9022 - beta: 0.0019 - val_val_loss: 274.4264 - val_val_recon_loss: 9.6708e-04 - val_val_KL loss: 14.9887 - val_beta: 0.0019\n",
      "Epoch 3491/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 273.9903 - recon_loss: 9.6529e-04 - KL loss: 15.0317 - beta: 0.0019 - val_val_loss: 273.8430 - val_val_recon_loss: 9.6539e-04 - val_val_KL loss: 14.8581 - val_beta: 0.0019\n",
      "Epoch 3492/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 273.8635 - recon_loss: 9.6543e-04 - KL loss: 14.8673 - beta: 0.0019 - val_val_loss: 273.4226 - val_val_recon_loss: 9.6486e-04 - val_val_KL loss: 14.5792 - val_beta: 0.0019\n",
      "Epoch 3493/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 272.4270 - recon_loss: 9.6128e-04 - KL loss: 14.5439 - beta: 0.0019 - val_val_loss: 273.6830 - val_val_recon_loss: 9.6532e-04 - val_val_KL loss: 14.7160 - val_beta: 0.0019\n",
      "Epoch 3494/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 273.7967 - recon_loss: 9.6600e-04 - KL loss: 14.6481 - beta: 0.0019 - val_val_loss: 274.0755 - val_val_recon_loss: 9.6704e-04 - val_val_KL loss: 14.6468 - val_beta: 0.0019\n",
      "Epoch 3495/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 271.3061 - recon_loss: 9.5743e-04 - KL loss: 14.4556 - beta: 0.0019 - val_val_loss: 273.8907 - val_val_recon_loss: 9.6692e-04 - val_val_KL loss: 14.4957 - val_beta: 0.0019\n",
      "Epoch 3496/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 270.7386 - recon_loss: 9.5469e-04 - KL loss: 14.6247 - beta: 0.0019 - val_val_loss: 271.5711 - val_val_recon_loss: 9.5767e-04 - val_val_KL loss: 14.6568 - val_beta: 0.0019\n",
      "Epoch 3497/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 270.4015 - recon_loss: 9.5336e-04 - KL loss: 14.6438 - beta: 0.0019 - val_val_loss: 270.3541 - val_val_recon_loss: 9.5299e-04 - val_val_KL loss: 14.6967 - val_beta: 0.0019\n",
      "Epoch 3498/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 270.0610 - recon_loss: 9.5178e-04 - KL loss: 14.7284 - beta: 0.0019 - val_val_loss: 270.8148 - val_val_recon_loss: 9.5504e-04 - val_val_KL loss: 14.6069 - val_beta: 0.0019\n",
      "Epoch 3499/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 272.0606 - recon_loss: 9.5963e-04 - KL loss: 14.6210 - beta: 0.0019 - val_val_loss: 270.3254 - val_val_recon_loss: 9.5294e-04 - val_val_KL loss: 14.6813 - val_beta: 0.0019\n",
      "Epoch 3500/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 268.0955 - recon_loss: 9.4467e-04 - KL loss: 14.6686 - beta: 0.0019 - val_val_loss: 269.8042 - val_val_recon_loss: 9.5071e-04 - val_val_KL loss: 14.7573 - val_beta: 0.0019\n",
      "Epoch 3501/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 269.9587 - recon_loss: 9.5105e-04 - KL loss: 14.8197 - beta: 0.0019 - val_val_loss: 270.0655 - val_val_recon_loss: 9.5134e-04 - val_val_KL loss: 14.8493 - val_beta: 0.0019\n",
      "Epoch 3502/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266.7442 - recon_loss: 9.3894e-04 - KL loss: 14.8544 - beta: 0.0019 - val_val_loss: 268.4309 - val_val_recon_loss: 9.4606e-04 - val_val_KL loss: 14.6308 - val_beta: 0.0019\n",
      "Epoch 3503/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266.4415 - recon_loss: 9.3806e-04 - KL loss: 14.7882 - beta: 0.0019 - val_val_loss: 266.9958 - val_val_recon_loss: 9.3972e-04 - val_val_KL loss: 14.8976 - val_beta: 0.0019\n",
      "Epoch 3504/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 266.6794 - recon_loss: 9.3862e-04 - KL loss: 14.8765 - beta: 0.0019 - val_val_loss: 266.9639 - val_val_recon_loss: 9.3961e-04 - val_val_KL loss: 14.8962 - val_beta: 0.0019\n",
      "Epoch 3505/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265.2013 - recon_loss: 9.3281e-04 - KL loss: 14.9555 - beta: 0.0019 - val_val_loss: 265.8748 - val_val_recon_loss: 9.3561e-04 - val_val_KL loss: 14.8787 - val_beta: 0.0019\n",
      "Epoch 3506/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 265.8786 - recon_loss: 9.3558e-04 - KL loss: 14.8911 - beta: 0.0019 - val_val_loss: 266.3352 - val_val_recon_loss: 9.3665e-04 - val_val_KL loss: 15.0599 - val_beta: 0.0019\n",
      "Epoch 3507/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265.8415 - recon_loss: 9.3472e-04 - KL loss: 15.0839 - beta: 0.0019 - val_val_loss: 267.1937 - val_val_recon_loss: 9.3827e-04 - val_val_KL loss: 15.4847 - val_beta: 0.0019\n",
      "Epoch 3508/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265.1799 - recon_loss: 9.3134e-04 - KL loss: 15.3283 - beta: 0.0019 - val_val_loss: 265.6052 - val_val_recon_loss: 9.3221e-04 - val_val_KL loss: 15.5219 - val_beta: 0.0019\n",
      "Epoch 3509/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 265.6240 - recon_loss: 9.3245e-04 - KL loss: 15.4770 - beta: 0.0019 - val_val_loss: 268.0314 - val_val_recon_loss: 9.4026e-04 - val_val_KL loss: 15.7878 - val_beta: 0.0019\n",
      "Epoch 3510/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 266.2081 - recon_loss: 9.3346e-04 - KL loss: 15.7898 - beta: 0.0019 - val_val_loss: 263.4619 - val_val_recon_loss: 9.2498e-04 - val_val_KL loss: 15.3190 - val_beta: 0.0019\n",
      "Epoch 3511/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 259.2703 - recon_loss: 9.0910e-04 - KL loss: 15.3869 - beta: 0.0019 - val_val_loss: 261.6110 - val_val_recon_loss: 9.1756e-04 - val_val_KL loss: 15.4587 - val_beta: 0.0019\n",
      "Epoch 3512/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 259.2913 - recon_loss: 9.0896e-04 - KL loss: 15.4462 - beta: 0.0019 - val_val_loss: 260.4565 - val_val_recon_loss: 9.1310e-04 - val_val_KL loss: 15.4987 - val_beta: 0.0019\n",
      "Epoch 3513/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 259.1397 - recon_loss: 9.0796e-04 - KL loss: 15.5605 - beta: 0.0019 - val_val_loss: 259.1143 - val_val_recon_loss: 9.0792e-04 - val_val_KL loss: 15.5474 - val_beta: 0.0019\n",
      "Epoch 3514/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 259.3075 - recon_loss: 9.0873e-04 - KL loss: 15.5238 - beta: 0.0019 - val_val_loss: 260.5548 - val_val_recon_loss: 9.1140e-04 - val_val_KL loss: 16.0538 - val_beta: 0.0019\n",
      "Epoch 3515/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 261.3293 - recon_loss: 9.1480e-04 - KL loss: 15.9162 - beta: 0.0019 - val_val_loss: 259.4322 - val_val_recon_loss: 9.0812e-04 - val_val_KL loss: 15.8114 - val_beta: 0.0019\n",
      "Epoch 3516/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 258.6029 - recon_loss: 9.0425e-04 - KL loss: 16.0214 - beta: 0.0019 - val_val_loss: 257.0977 - val_val_recon_loss: 8.9764e-04 - val_val_KL loss: 16.2891 - val_beta: 0.0019\n",
      "Epoch 3517/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 253.6366 - recon_loss: 8.8512e-04 - KL loss: 16.1849 - beta: 0.0019 - val_val_loss: 258.1169 - val_val_recon_loss: 9.0214e-04 - val_val_KL loss: 16.1014 - val_beta: 0.0019\n",
      "Epoch 3518/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 256.6085 - recon_loss: 8.9600e-04 - KL loss: 16.2393 - beta: 0.0019 - val_val_loss: 255.2909 - val_val_recon_loss: 8.9210e-04 - val_val_KL loss: 15.9677 - val_beta: 0.0019\n",
      "Epoch 3519/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 253.0666 - recon_loss: 8.8381e-04 - KL loss: 15.9683 - beta: 0.0019 - val_val_loss: 255.4325 - val_val_recon_loss: 8.9148e-04 - val_val_KL loss: 16.2761 - val_beta: 0.0019\n",
      "Epoch 3520/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 253.6392 - recon_loss: 8.8576e-04 - KL loss: 16.0166 - beta: 0.0019 - val_val_loss: 253.2388 - val_val_recon_loss: 8.8453e-04 - val_val_KL loss: 15.9473 - val_beta: 0.0019\n",
      "Epoch 3521/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 252.2599 - recon_loss: 8.8116e-04 - KL loss: 15.8728 - beta: 0.0019 - val_val_loss: 253.1278 - val_val_recon_loss: 8.8350e-04 - val_val_KL loss: 16.1115 - val_beta: 0.0019\n",
      "Epoch 3522/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 251.7867 - recon_loss: 8.7933e-04 - KL loss: 15.8888 - beta: 0.0019 - val_val_loss: 252.6158 - val_val_recon_loss: 8.8260e-04 - val_val_KL loss: 15.8422 - val_beta: 0.0019\n",
      "Epoch 3523/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 249.6895 - recon_loss: 8.7068e-04 - KL loss: 16.1137 - beta: 0.0019 - val_val_loss: 249.7642 - val_val_recon_loss: 8.6920e-04 - val_val_KL loss: 16.5837 - val_beta: 0.0019\n",
      "Epoch 3524/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 248.5051 - recon_loss: 8.6458e-04 - KL loss: 16.5636 - beta: 0.0019 - val_val_loss: 249.2495 - val_val_recon_loss: 8.6777e-04 - val_val_KL loss: 16.4541 - val_beta: 0.0019\n",
      "Epoch 3525/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 247.3373 - recon_loss: 8.6088e-04 - KL loss: 16.3902 - beta: 0.0019 - val_val_loss: 248.1235 - val_val_recon_loss: 8.6319e-04 - val_val_KL loss: 16.5565 - val_beta: 0.0019\n",
      "Epoch 3526/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 246.3301 - recon_loss: 8.5672e-04 - KL loss: 16.4987 - beta: 0.0019 - val_val_loss: 247.9286 - val_val_recon_loss: 8.6304e-04 - val_val_KL loss: 16.4006 - val_beta: 0.0019\n",
      "Epoch 3527/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 244.8490 - recon_loss: 8.5155e-04 - KL loss: 16.4049 - beta: 0.0019 - val_val_loss: 246.1194 - val_val_recon_loss: 8.5515e-04 - val_val_KL loss: 16.7074 - val_beta: 0.0019\n",
      "Epoch 3528/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 244.7750 - recon_loss: 8.5002e-04 - KL loss: 16.7415 - beta: 0.0019 - val_val_loss: 247.0917 - val_val_recon_loss: 8.5773e-04 - val_val_KL loss: 16.9890 - val_beta: 0.0019\n",
      "Epoch 3529/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 245.6739 - recon_loss: 8.5224e-04 - KL loss: 17.0444 - beta: 0.0019 - val_val_loss: 244.5934 - val_val_recon_loss: 8.4724e-04 - val_val_KL loss: 17.3040 - val_beta: 0.0019\n",
      "Epoch 3530/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 245.2499 - recon_loss: 8.5005e-04 - KL loss: 17.2061 - beta: 0.0019 - val_val_loss: 244.0965 - val_val_recon_loss: 8.4578e-04 - val_val_KL loss: 17.1993 - val_beta: 0.0019\n",
      "Epoch 3531/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 241.5080 - recon_loss: 8.3614e-04 - KL loss: 17.1963 - beta: 0.0019 - val_val_loss: 241.8740 - val_val_recon_loss: 8.3646e-04 - val_val_KL loss: 17.4772 - val_beta: 0.0019\n",
      "Epoch 3532/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 236.1624 - recon_loss: 8.1555e-04 - KL loss: 17.3753 - beta: 0.0019 - val_val_loss: 240.4067 - val_val_recon_loss: 8.3181e-04 - val_val_KL loss: 17.2587 - val_beta: 0.0019\n",
      "Epoch 3533/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 239.8366 - recon_loss: 8.2947e-04 - KL loss: 17.3140 - beta: 0.0019 - val_val_loss: 240.4171 - val_val_recon_loss: 8.3090e-04 - val_val_KL loss: 17.5129 - val_beta: 0.0019\n",
      "Epoch 3534/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 240.3591 - recon_loss: 8.3098e-04 - KL loss: 17.4328 - beta: 0.0019 - val_val_loss: 241.3821 - val_val_recon_loss: 8.3491e-04 - val_val_KL loss: 17.4011 - val_beta: 0.0019\n",
      "Epoch 3535/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 239.7497 - recon_loss: 8.2903e-04 - KL loss: 17.3455 - beta: 0.0019 - val_val_loss: 238.3393 - val_val_recon_loss: 8.2330e-04 - val_val_KL loss: 17.4731 - val_beta: 0.0019\n",
      "Epoch 3536/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 235.4520 - recon_loss: 8.1257e-04 - KL loss: 17.4627 - beta: 0.0019 - val_val_loss: 235.9418 - val_val_recon_loss: 8.1363e-04 - val_val_KL loss: 17.6684 - val_beta: 0.0019\n",
      "Epoch 3537/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 235.4793 - recon_loss: 8.1129e-04 - KL loss: 17.8345 - beta: 0.0019 - val_val_loss: 237.7800 - val_val_recon_loss: 8.1703e-04 - val_val_KL loss: 18.5949 - val_beta: 0.0019\n",
      "Epoch 3538/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 235.8668 - recon_loss: 8.1062e-04 - KL loss: 18.4013 - beta: 0.0019 - val_val_loss: 235.3074 - val_val_recon_loss: 8.0942e-04 - val_val_KL loss: 18.1661 - val_beta: 0.0019\n",
      "Epoch 3539/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 234.9588 - recon_loss: 8.0752e-04 - KL loss: 18.3245 - beta: 0.0019 - val_val_loss: 233.3687 - val_val_recon_loss: 8.0064e-04 - val_val_KL loss: 18.5814 - val_beta: 0.0019\n",
      "Epoch 3540/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 233.2269 - recon_loss: 8.0042e-04 - KL loss: 18.4983 - beta: 0.0019 - val_val_loss: 231.9596 - val_val_recon_loss: 7.9672e-04 - val_val_KL loss: 18.2233 - val_beta: 0.0019\n",
      "Epoch 3541/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 228.8909 - recon_loss: 7.8523e-04 - KL loss: 18.2386 - beta: 0.0019 - val_val_loss: 230.7866 - val_val_recon_loss: 7.9304e-04 - val_val_KL loss: 18.0379 - val_beta: 0.0019\n",
      "Epoch 3542/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 230.7993 - recon_loss: 7.9172e-04 - KL loss: 18.4038 - beta: 0.0019 - val_val_loss: 231.0009 - val_val_recon_loss: 7.9296e-04 - val_val_KL loss: 18.2743 - val_beta: 0.0019\n",
      "Epoch 3543/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 231.1339 - recon_loss: 7.9263e-04 - KL loss: 18.4958 - beta: 0.0019 - val_val_loss: 230.4152 - val_val_recon_loss: 7.9010e-04 - val_val_KL loss: 18.4558 - val_beta: 0.0019\n",
      "Epoch 3544/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 226.6062 - recon_loss: 7.7610e-04 - KL loss: 18.4012 - beta: 0.0019 - val_val_loss: 227.1824 - val_val_recon_loss: 7.7768e-04 - val_val_KL loss: 18.5557 - val_beta: 0.0019\n",
      "Epoch 3545/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 227.8548 - recon_loss: 7.8000e-04 - KL loss: 18.6037 - beta: 0.0019 - val_val_loss: 228.1485 - val_val_recon_loss: 7.8115e-04 - val_val_KL loss: 18.5889 - val_beta: 0.0019\n",
      "Epoch 3546/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 229.6627 - recon_loss: 7.8646e-04 - KL loss: 18.6793 - beta: 0.0019 - val_val_loss: 231.2833 - val_val_recon_loss: 7.9244e-04 - val_val_KL loss: 18.6963 - val_beta: 0.0019\n",
      "Epoch 3547/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 227.8056 - recon_loss: 7.7955e-04 - KL loss: 18.6767 - beta: 0.0019 - val_val_loss: 228.5541 - val_val_recon_loss: 7.8121e-04 - val_val_KL loss: 18.9806 - val_beta: 0.0019\n",
      "Epoch 3548/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 225.2379 - recon_loss: 7.6879e-04 - KL loss: 18.9951 - beta: 0.0019 - val_val_loss: 226.9739 - val_val_recon_loss: 7.7599e-04 - val_val_KL loss: 18.7995 - val_beta: 0.0019\n",
      "Epoch 3549/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 224.6858 - recon_loss: 7.6771e-04 - KL loss: 18.7327 - beta: 0.0019 - val_val_loss: 225.0540 - val_val_recon_loss: 7.6908e-04 - val_val_KL loss: 18.7339 - val_beta: 0.0019\n",
      "Epoch 3550/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 222.5650 - recon_loss: 7.5958e-04 - KL loss: 18.7915 - beta: 0.0019 - val_val_loss: 224.1610 - val_val_recon_loss: 7.6526e-04 - val_val_KL loss: 18.8655 - val_beta: 0.0019\n",
      "Epoch 3551/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 221.3042 - recon_loss: 7.5492e-04 - KL loss: 18.7812 - beta: 0.0019 - val_val_loss: 223.4532 - val_val_recon_loss: 7.6425e-04 - val_val_KL loss: 18.4283 - val_beta: 0.0019\n",
      "Epoch 3552/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 219.6521 - recon_loss: 7.4922e-04 - KL loss: 18.6601 - beta: 0.0019 - val_val_loss: 219.8588 - val_val_recon_loss: 7.5010e-04 - val_val_KL loss: 18.6290 - val_beta: 0.0019\n",
      "Epoch 3553/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 218.3193 - recon_loss: 7.4328e-04 - KL loss: 18.9201 - beta: 0.0019 - val_val_loss: 219.4355 - val_val_recon_loss: 7.4771e-04 - val_val_KL loss: 18.8478 - val_beta: 0.0019\n",
      "Epoch 3554/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 216.2082 - recon_loss: 7.3564e-04 - KL loss: 18.8596 - beta: 0.0019 - val_val_loss: 218.3576 - val_val_recon_loss: 7.4400e-04 - val_val_KL loss: 18.7663 - val_beta: 0.0019\n",
      "Epoch 3555/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 218.8395 - recon_loss: 7.4495e-04 - KL loss: 18.9925 - beta: 0.0019 - val_val_loss: 217.0430 - val_val_recon_loss: 7.3778e-04 - val_val_KL loss: 19.1183 - val_beta: 0.0019\n",
      "Epoch 3556/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 216.1212 - recon_loss: 7.3431e-04 - KL loss: 19.1293 - beta: 0.0019 - val_val_loss: 217.5102 - val_val_recon_loss: 7.3955e-04 - val_val_KL loss: 19.1123 - val_beta: 0.0019\n",
      "Epoch 3557/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 215.9960 - recon_loss: 7.3417e-04 - KL loss: 19.0419 - beta: 0.0019 - val_val_loss: 215.2197 - val_val_recon_loss: 7.3196e-04 - val_val_KL loss: 18.8573 - val_beta: 0.0019\n",
      "Epoch 3558/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 215.4179 - recon_loss: 7.3188e-04 - KL loss: 19.0767 - beta: 0.0019 - val_val_loss: 214.6148 - val_val_recon_loss: 7.2868e-04 - val_val_KL loss: 19.1320 - val_beta: 0.0019\n",
      "Epoch 3559/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 212.5790 - recon_loss: 7.2108e-04 - KL loss: 19.1362 - beta: 0.0019 - val_val_loss: 213.8929 - val_val_recon_loss: 7.2636e-04 - val_val_KL loss: 19.0331 - val_beta: 0.0019\n",
      "Epoch 3560/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 212.8095 - recon_loss: 7.2170e-04 - KL loss: 19.1999 - beta: 0.0019 - val_val_loss: 212.2972 - val_val_recon_loss: 7.1996e-04 - val_val_KL loss: 19.1538 - val_beta: 0.0019\n",
      "Epoch 3561/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 212.3207 - recon_loss: 7.1982e-04 - KL loss: 19.2143 - beta: 0.0019 - val_val_loss: 212.6801 - val_val_recon_loss: 7.2031e-04 - val_val_KL loss: 19.4436 - val_beta: 0.0019\n",
      "Epoch 3562/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 211.7412 - recon_loss: 7.1703e-04 - KL loss: 19.3837 - beta: 0.0019 - val_val_loss: 213.5877 - val_val_recon_loss: 7.2328e-04 - val_val_KL loss: 19.5533 - val_beta: 0.0019\n",
      "Epoch 3563/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 210.0322 - recon_loss: 7.1010e-04 - KL loss: 19.5332 - beta: 0.0019 - val_val_loss: 209.3561 - val_val_recon_loss: 7.0770e-04 - val_val_KL loss: 19.5021 - val_beta: 0.0019\n",
      "Epoch 3564/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 209.7519 - recon_loss: 7.0896e-04 - KL loss: 19.5600 - beta: 0.0019 - val_val_loss: 210.0097 - val_val_recon_loss: 7.1099e-04 - val_val_KL loss: 19.2715 - val_beta: 0.0019\n",
      "Epoch 3565/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 207.4512 - recon_loss: 7.0071e-04 - KL loss: 19.4710 - beta: 0.0019 - val_val_loss: 208.9757 - val_val_recon_loss: 7.0607e-04 - val_val_KL loss: 19.5578 - val_beta: 0.0019\n",
      "Epoch 3566/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 207.9744 - recon_loss: 7.0227e-04 - KL loss: 19.5755 - beta: 0.0019 - val_val_loss: 207.8357 - val_val_recon_loss: 7.0244e-04 - val_val_KL loss: 19.3922 - val_beta: 0.0019\n",
      "Epoch 3567/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 206.8838 - recon_loss: 6.9849e-04 - KL loss: 19.5004 - beta: 0.0019 - val_val_loss: 208.8089 - val_val_recon_loss: 7.0623e-04 - val_val_KL loss: 19.3490 - val_beta: 0.0019\n",
      "Epoch 3568/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 208.6287 - recon_loss: 7.0414e-04 - KL loss: 19.7305 - beta: 0.0019 - val_val_loss: 208.5613 - val_val_recon_loss: 7.0364e-04 - val_val_KL loss: 19.7960 - val_beta: 0.0019\n",
      "Epoch 3569/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 203.8913 - recon_loss: 6.8638e-04 - KL loss: 19.7574 - beta: 0.0019 - val_val_loss: 206.8852 - val_val_recon_loss: 6.9670e-04 - val_val_KL loss: 19.9811 - val_beta: 0.0019\n",
      "Epoch 3570/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 207.5472 - recon_loss: 6.9953e-04 - KL loss: 19.8854 - beta: 0.0019 - val_val_loss: 204.7211 - val_val_recon_loss: 6.9035e-04 - val_val_KL loss: 19.5225 - val_beta: 0.0019\n",
      "Epoch 3571/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 203.1986 - recon_loss: 6.8390e-04 - KL loss: 19.7279 - beta: 0.0019 - val_val_loss: 204.1850 - val_val_recon_loss: 6.8781e-04 - val_val_KL loss: 19.6652 - val_beta: 0.0019\n",
      "Epoch 3572/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 204.8120 - recon_loss: 6.8985e-04 - KL loss: 19.7463 - beta: 0.0019 - val_val_loss: 203.8212 - val_val_recon_loss: 6.8552e-04 - val_val_KL loss: 19.9172 - val_beta: 0.0019\n",
      "Epoch 3573/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 204.2880 - recon_loss: 6.8681e-04 - KL loss: 20.0366 - beta: 0.0019 - val_val_loss: 204.2472 - val_val_recon_loss: 6.8697e-04 - val_val_KL loss: 19.9553 - val_beta: 0.0019\n",
      "Epoch 3574/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 203.5422 - recon_loss: 6.8405e-04 - KL loss: 20.0313 - beta: 0.0019 - val_val_loss: 202.7929 - val_val_recon_loss: 6.8175e-04 - val_val_KL loss: 19.9001 - val_beta: 0.0019\n",
      "Epoch 3575/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 204.5776 - recon_loss: 6.8773e-04 - KL loss: 20.0811 - beta: 0.0019 - val_val_loss: 204.3219 - val_val_recon_loss: 6.8635e-04 - val_val_KL loss: 20.1939 - val_beta: 0.0019\n",
      "Epoch 3576/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 204.0261 - recon_loss: 6.8498e-04 - KL loss: 20.2676 - beta: 0.0019 - val_val_loss: 202.6543 - val_val_recon_loss: 6.8108e-04 - val_val_KL loss: 19.9410 - val_beta: 0.0019\n",
      "Epoch 3577/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 203.2866 - recon_loss: 6.8278e-04 - KL loss: 20.1185 - beta: 0.0019 - val_val_loss: 202.9504 - val_val_recon_loss: 6.8099e-04 - val_val_KL loss: 20.2627 - val_beta: 0.0019\n",
      "Epoch 3578/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 203.1066 - recon_loss: 6.8148e-04 - KL loss: 20.2867 - beta: 0.0019 - val_val_loss: 201.3579 - val_val_recon_loss: 6.7598e-04 - val_val_KL loss: 20.0126 - val_beta: 0.0019\n",
      "Epoch 3579/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 198.6131 - recon_loss: 6.6542e-04 - KL loss: 20.1002 - beta: 0.0019 - val_val_loss: 200.1915 - val_val_recon_loss: 6.7183e-04 - val_val_KL loss: 19.9608 - val_beta: 0.0019\n",
      "Epoch 3580/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 199.0714 - recon_loss: 6.6664e-04 - KL loss: 20.2316 - beta: 0.0019 - val_val_loss: 199.7034 - val_val_recon_loss: 6.6958e-04 - val_val_KL loss: 20.0747 - val_beta: 0.0019\n",
      "Epoch 3581/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 199.1808 - recon_loss: 6.6742e-04 - KL loss: 20.1313 - beta: 0.0019 - val_val_loss: 199.5386 - val_val_recon_loss: 6.6927e-04 - val_val_KL loss: 19.9936 - val_beta: 0.0019\n",
      "Epoch 3582/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 198.9990 - recon_loss: 6.6650e-04 - KL loss: 20.1978 - beta: 0.0019 - val_val_loss: 200.4924 - val_val_recon_loss: 6.7265e-04 - val_val_KL loss: 20.0408 - val_beta: 0.0019\n",
      "Epoch 3583/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 201.9532 - recon_loss: 6.7774e-04 - KL loss: 20.1368 - beta: 0.0019 - val_val_loss: 199.2718 - val_val_recon_loss: 6.6555e-04 - val_val_KL loss: 20.7256 - val_beta: 0.0019\n",
      "Epoch 3584/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 195.9602 - recon_loss: 6.5391e-04 - KL loss: 20.5368 - beta: 0.0019 - val_val_loss: 198.3179 - val_val_recon_loss: 6.6380e-04 - val_val_KL loss: 20.2396 - val_beta: 0.0019\n",
      "Epoch 3585/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 197.6099 - recon_loss: 6.6045e-04 - KL loss: 20.4303 - beta: 0.0019 - val_val_loss: 196.4772 - val_val_recon_loss: 6.5694e-04 - val_val_KL loss: 20.2389 - val_beta: 0.0019\n",
      "Epoch 3586/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 195.6516 - recon_loss: 6.5313e-04 - KL loss: 20.4374 - beta: 0.0019 - val_val_loss: 198.2440 - val_val_recon_loss: 6.6471e-04 - val_val_KL loss: 19.9231 - val_beta: 0.0019\n",
      "Epoch 3587/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 198.2812 - recon_loss: 6.6358e-04 - KL loss: 20.2638 - beta: 0.0019 - val_val_loss: 195.9603 - val_val_recon_loss: 6.5556e-04 - val_val_KL loss: 20.0923 - val_beta: 0.0019\n",
      "Epoch 3588/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 198.1699 - recon_loss: 6.6335e-04 - KL loss: 20.2143 - beta: 0.0019 - val_val_loss: 195.5031 - val_val_recon_loss: 6.5456e-04 - val_val_KL loss: 19.9045 - val_beta: 0.0019\n",
      "Epoch 3589/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 195.6368 - recon_loss: 6.5345e-04 - KL loss: 20.3366 - beta: 0.0019 - val_val_loss: 194.6865 - val_val_recon_loss: 6.5023e-04 - val_val_KL loss: 20.2491 - val_beta: 0.0019\n",
      "Epoch 3590/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 193.2327 - recon_loss: 6.4416e-04 - KL loss: 20.4248 - beta: 0.0019 - val_val_loss: 194.5706 - val_val_recon_loss: 6.5010e-04 - val_val_KL loss: 20.1694 - val_beta: 0.0019\n",
      "Epoch 3591/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 193.6023 - recon_loss: 6.4595e-04 - KL loss: 20.3142 - beta: 0.0019 - val_val_loss: 197.4237 - val_val_recon_loss: 6.6164e-04 - val_val_KL loss: 19.9247 - val_beta: 0.0019\n",
      "Epoch 3592/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 193.4602 - recon_loss: 6.4585e-04 - KL loss: 20.1975 - beta: 0.0019 - val_val_loss: 194.8249 - val_val_recon_loss: 6.5115e-04 - val_val_KL loss: 20.1420 - val_beta: 0.0019\n",
      "Epoch 3593/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 195.6522 - recon_loss: 6.5384e-04 - KL loss: 20.2466 - beta: 0.0019 - val_val_loss: 194.8734 - val_val_recon_loss: 6.5096e-04 - val_val_KL loss: 20.2408 - val_beta: 0.0019\n",
      "Epoch 3594/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 194.5379 - recon_loss: 6.4885e-04 - KL loss: 20.4725 - beta: 0.0019 - val_val_loss: 193.0632 - val_val_recon_loss: 6.4336e-04 - val_val_KL loss: 20.4695 - val_beta: 0.0019\n",
      "Epoch 3595/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 192.6282 - recon_loss: 6.4220e-04 - KL loss: 20.3447 - beta: 0.0019 - val_val_loss: 191.0499 - val_val_recon_loss: 6.3596e-04 - val_val_KL loss: 20.4410 - val_beta: 0.0019\n",
      "Epoch 3596/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 190.3845 - recon_loss: 6.3358e-04 - KL loss: 20.4143 - beta: 0.0019 - val_val_loss: 191.8931 - val_val_recon_loss: 6.3998e-04 - val_val_KL loss: 20.2061 - val_beta: 0.0019\n",
      "Epoch 3597/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 189.7863 - recon_loss: 6.3130e-04 - KL loss: 20.4285 - beta: 0.0019 - val_val_loss: 191.0049 - val_val_recon_loss: 6.3563e-04 - val_val_KL loss: 20.4859 - val_beta: 0.0019\n",
      "Epoch 3598/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 192.0317 - recon_loss: 6.3880e-04 - KL loss: 20.6617 - beta: 0.0019 - val_val_loss: 189.5082 - val_val_recon_loss: 6.3007e-04 - val_val_KL loss: 20.4805 - val_beta: 0.0019\n",
      "Epoch 3599/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 190.0442 - recon_loss: 6.3185e-04 - KL loss: 20.5372 - beta: 0.0019 - val_val_loss: 188.4212 - val_val_recon_loss: 6.2588e-04 - val_val_KL loss: 20.5177 - val_beta: 0.0019\n",
      "Epoch 3600/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 188.5530 - recon_loss: 6.2599e-04 - KL loss: 20.6181 - beta: 0.0019 - val_val_loss: 188.1302 - val_val_recon_loss: 6.2433e-04 - val_val_KL loss: 20.6420 - val_beta: 0.0019\n",
      "Epoch 3601/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 188.7472 - recon_loss: 6.2706e-04 - KL loss: 20.5262 - beta: 0.0019 - val_val_loss: 188.3676 - val_val_recon_loss: 6.2622e-04 - val_val_KL loss: 20.3727 - val_beta: 0.0019\n",
      "Epoch 3602/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 186.3251 - recon_loss: 6.1780e-04 - KL loss: 20.5876 - beta: 0.0019 - val_val_loss: 189.7141 - val_val_recon_loss: 6.3132e-04 - val_val_KL loss: 20.3496 - val_beta: 0.0019\n",
      "Epoch 3603/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 188.6975 - recon_loss: 6.2682e-04 - KL loss: 20.5401 - beta: 0.0019 - val_val_loss: 187.0140 - val_val_recon_loss: 6.2083e-04 - val_val_KL loss: 20.4634 - val_beta: 0.0019\n",
      "Epoch 3604/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 188.3763 - recon_loss: 6.2538e-04 - KL loss: 20.6060 - beta: 0.0019 - val_val_loss: 190.9588 - val_val_recon_loss: 6.3506e-04 - val_val_KL loss: 20.5914 - val_beta: 0.0019\n",
      "Epoch 3605/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 192.4983 - recon_loss: 6.4113e-04 - KL loss: 20.5016 - beta: 0.0019 - val_val_loss: 191.6557 - val_val_recon_loss: 6.3827e-04 - val_val_KL loss: 20.4265 - val_beta: 0.0019\n",
      "Epoch 3606/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 189.0803 - recon_loss: 6.2861e-04 - KL loss: 20.4433 - beta: 0.0019 - val_val_loss: 186.1082 - val_val_recon_loss: 6.1768e-04 - val_val_KL loss: 20.4041 - val_beta: 0.0019\n",
      "Epoch 3607/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 184.5261 - recon_loss: 6.1160e-04 - KL loss: 20.4512 - beta: 0.0019 - val_val_loss: 184.6509 - val_val_recon_loss: 6.1201e-04 - val_val_KL loss: 20.4665 - val_beta: 0.0019\n",
      "Epoch 3608/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 184.4525 - recon_loss: 6.1063e-04 - KL loss: 20.6385 - beta: 0.0019 - val_val_loss: 185.5499 - val_val_recon_loss: 6.1450e-04 - val_val_KL loss: 20.6970 - val_beta: 0.0019\n",
      "Epoch 3609/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 184.5001 - recon_loss: 6.1000e-04 - KL loss: 20.8555 - beta: 0.0019 - val_val_loss: 183.4258 - val_val_recon_loss: 6.0593e-04 - val_val_KL loss: 20.8726 - val_beta: 0.0019\n",
      "Epoch 3610/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 182.5711 - recon_loss: 6.0212e-04 - KL loss: 21.0396 - beta: 0.0019 - val_val_loss: 185.1293 - val_val_recon_loss: 6.1275e-04 - val_val_KL loss: 20.7485 - val_beta: 0.0019\n",
      "Epoch 3611/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 183.8502 - recon_loss: 6.0780e-04 - KL loss: 20.7950 - beta: 0.0019 - val_val_loss: 186.9890 - val_val_recon_loss: 6.1981e-04 - val_val_KL loss: 20.7139 - val_beta: 0.0019\n",
      "Epoch 3612/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 185.6449 - recon_loss: 6.1393e-04 - KL loss: 20.9454 - beta: 0.0019 - val_val_loss: 184.0263 - val_val_recon_loss: 6.0773e-04 - val_val_KL loss: 20.9920 - val_beta: 0.0019\n",
      "Epoch 3613/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 184.4953 - recon_loss: 6.0921e-04 - KL loss: 21.0622 - beta: 0.0019 - val_val_loss: 192.4620 - val_val_recon_loss: 6.3903e-04 - val_val_KL loss: 21.0294 - val_beta: 0.0019\n",
      "Epoch 3614/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 189.4145 - recon_loss: 6.2829e-04 - KL loss: 20.8629 - beta: 0.0019\n",
      "Epoch 03614: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 189.4150 - recon_loss: 6.2829e-04 - KL loss: 20.8629 - beta: 0.0019 - val_val_loss: 189.0879 - val_val_recon_loss: 6.2694e-04 - val_val_KL loss: 20.8977 - val_beta: 0.0019\n",
      "Epoch 3615/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 185.8945 - recon_loss: 6.1531e-04 - KL loss: 20.8256 - beta: 0.0019 - val_val_loss: 185.8803 - val_val_recon_loss: 6.1553e-04 - val_val_KL loss: 20.7518 - val_beta: 0.0019\n",
      "Epoch 3616/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 185.4926 - recon_loss: 6.1323e-04 - KL loss: 20.9822 - beta: 0.0019 - val_val_loss: 184.7111 - val_val_recon_loss: 6.1035e-04 - val_val_KL loss: 20.9714 - val_beta: 0.0019\n",
      "Epoch 3617/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 183.4000 - recon_loss: 6.0501e-04 - KL loss: 21.0937 - beta: 0.0019 - val_val_loss: 184.1964 - val_val_recon_loss: 6.0840e-04 - val_val_KL loss: 20.9797 - val_beta: 0.0019\n",
      "Epoch 3618/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 182.6134 - recon_loss: 6.0204e-04 - KL loss: 21.1051 - beta: 0.0019 - val_val_loss: 183.5799 - val_val_recon_loss: 6.0560e-04 - val_val_KL loss: 21.1161 - val_beta: 0.0019\n",
      "Epoch 3619/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 181.9379 - recon_loss: 5.9932e-04 - KL loss: 21.1593 - beta: 0.0019\n",
      "Epoch 03619: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 181.9375 - recon_loss: 5.9932e-04 - KL loss: 21.1593 - beta: 0.0019 - val_val_loss: 184.1830 - val_val_recon_loss: 6.0780e-04 - val_val_KL loss: 21.1294 - val_beta: 0.0019\n",
      "Epoch 3619/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 480.7974 - recon_loss: 6.3409e-04 - KL loss: 24.4483 - beta: 0.0012 - val_val_loss: 454.3910 - val_val_recon_loss: 5.9395e-04 - val_val_KL loss: 26.9342 - val_beta: 0.0012\n",
      "Epoch 3620/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 454.0660 - recon_loss: 5.9312e-04 - KL loss: 27.2074 - beta: 0.0012 - val_val_loss: 439.7726 - val_val_recon_loss: 5.7274e-04 - val_val_KL loss: 27.5801 - val_beta: 0.0012\n",
      "Epoch 3621/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 451.0234 - recon_loss: 5.8835e-04 - KL loss: 27.5959 - beta: 0.0012 - val_val_loss: 455.7516 - val_val_recon_loss: 5.9421e-04 - val_val_KL loss: 28.1075 - val_beta: 0.0012\n",
      "Epoch 3622/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 450.9466 - recon_loss: 5.8806e-04 - KL loss: 27.7298 - beta: 0.0012 - val_val_loss: 437.0865 - val_val_recon_loss: 5.6839e-04 - val_val_KL loss: 28.0228 - val_beta: 0.0012\n",
      "Epoch 3623/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 433.2348 - recon_loss: 5.6235e-04 - KL loss: 28.5181 - beta: 0.0012 - val_val_loss: 440.1449 - val_val_recon_loss: 5.7334e-04 - val_val_KL loss: 27.5188 - val_beta: 0.0012\n",
      "Epoch 3624/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 436.2988 - recon_loss: 5.6667e-04 - KL loss: 28.4711 - beta: 0.0012 - val_val_loss: 452.9181 - val_val_recon_loss: 5.8999e-04 - val_val_KL loss: 28.3082 - val_beta: 0.0012\n",
      "Epoch 3625/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 444.5879 - recon_loss: 5.7791e-04 - KL loss: 28.6749 - beta: 0.0012 - val_val_loss: 423.7817 - val_val_recon_loss: 5.4897e-04 - val_val_KL loss: 28.6982 - val_beta: 0.0012\n",
      "Epoch 3626/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 420.2714 - recon_loss: 5.4345e-04 - KL loss: 29.1580 - beta: 0.0012 - val_val_loss: 410.2273 - val_val_recon_loss: 5.2973e-04 - val_val_KL loss: 28.9887 - val_beta: 0.0012\n",
      "Epoch 3627/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 414.6327 - recon_loss: 5.3541e-04 - KL loss: 29.3058 - beta: 0.0012 - val_val_loss: 405.7836 - val_val_recon_loss: 5.2268e-04 - val_val_KL loss: 29.6163 - val_beta: 0.0012\n",
      "Epoch 3628/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 405.0416 - recon_loss: 5.2208e-04 - KL loss: 29.3049 - beta: 0.0012 - val_val_loss: 410.0157 - val_val_recon_loss: 5.2906e-04 - val_val_KL loss: 29.2596 - val_beta: 0.0012\n",
      "Epoch 3629/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 407.6348 - recon_loss: 5.2521e-04 - KL loss: 29.6513 - beta: 0.0012 - val_val_loss: 388.3619 - val_val_recon_loss: 4.9946e-04 - val_val_KL loss: 28.9068 - val_beta: 0.0012\n",
      "Epoch 3630/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 391.4607 - recon_loss: 5.0370e-04 - KL loss: 28.9560 - beta: 0.0012 - val_val_loss: 396.5891 - val_val_recon_loss: 5.1138e-04 - val_val_KL loss: 28.5567 - val_beta: 0.0012\n",
      "Epoch 3631/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 392.9484 - recon_loss: 5.0558e-04 - KL loss: 29.0877 - beta: 0.0012 - val_val_loss: 386.2798 - val_val_recon_loss: 4.9656e-04 - val_val_KL loss: 28.9128 - val_beta: 0.0012\n",
      "Epoch 3632/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 391.2581 - recon_loss: 5.0327e-04 - KL loss: 29.0640 - beta: 0.0012 - val_val_loss: 387.0138 - val_val_recon_loss: 4.9705e-04 - val_val_KL loss: 29.2925 - val_beta: 0.0012\n",
      "Epoch 3633/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 378.7876 - recon_loss: 4.8625e-04 - KL loss: 28.8408 - beta: 0.0012 - val_val_loss: 370.4948 - val_val_recon_loss: 4.7480e-04 - val_val_KL loss: 28.7885 - val_beta: 0.0012\n",
      "Epoch 3634/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 389.0625 - recon_loss: 4.9985e-04 - KL loss: 29.3269 - beta: 0.0012 - val_val_loss: 393.2380 - val_val_recon_loss: 5.0603e-04 - val_val_KL loss: 29.0562 - val_beta: 0.0012\n",
      "Epoch 3635/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 389.6556 - recon_loss: 5.0078e-04 - KL loss: 29.2486 - beta: 0.0012 - val_val_loss: 373.1623 - val_val_recon_loss: 4.7944e-04 - val_val_KL loss: 28.1140 - val_beta: 0.0012\n",
      "Epoch 3636/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 380.3323 - recon_loss: 4.8874e-04 - KL loss: 28.5916 - beta: 0.0012 - val_val_loss: 474.0561 - val_val_recon_loss: 6.1697e-04 - val_val_KL loss: 30.0339 - val_beta: 0.0012\n",
      "Epoch 3637/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 413.3398 - recon_loss: 5.3402e-04 - KL loss: 29.0123 - beta: 0.0012 - val_val_loss: 369.0154 - val_val_recon_loss: 4.7340e-04 - val_val_KL loss: 28.3178 - val_beta: 0.0012\n",
      "Epoch 3638/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 365.9159 - recon_loss: 4.6910e-04 - KL loss: 28.3108 - beta: 0.0012 - val_val_loss: 358.2495 - val_val_recon_loss: 4.5854e-04 - val_val_KL loss: 28.2466 - val_beta: 0.0012\n",
      "Epoch 3639/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 360.0356 - recon_loss: 4.6093e-04 - KL loss: 28.3123 - beta: 0.0012 - val_val_loss: 363.4671 - val_val_recon_loss: 4.6678e-04 - val_val_KL loss: 27.5285 - val_beta: 0.0012\n",
      "Epoch 3640/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 357.6503 - recon_loss: 4.5813e-04 - KL loss: 27.9437 - beta: 0.0012 - val_val_loss: 353.7366 - val_val_recon_loss: 4.5253e-04 - val_val_KL loss: 28.0586 - val_beta: 0.0012\n",
      "Epoch 3641/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 358.2810 - recon_loss: 4.5847e-04 - KL loss: 28.3296 - beta: 0.0012 - val_val_loss: 354.1697 - val_val_recon_loss: 4.5297e-04 - val_val_KL loss: 28.1730 - val_beta: 0.0012\n",
      "Epoch 3642/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 352.3405 - recon_loss: 4.5048e-04 - KL loss: 28.1344 - beta: 0.0012 - val_val_loss: 352.4354 - val_val_recon_loss: 4.5082e-04 - val_val_KL loss: 27.9855 - val_beta: 0.0012\n",
      "Epoch 3643/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 352.5485 - recon_loss: 4.5091e-04 - KL loss: 28.0364 - beta: 0.0012 - val_val_loss: 362.1417 - val_val_recon_loss: 4.6479e-04 - val_val_KL loss: 27.6378 - val_beta: 0.0012\n",
      "Epoch 3644/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 359.2680 - recon_loss: 4.6073e-04 - KL loss: 27.6893 - beta: 0.0012 - val_val_loss: 357.9365 - val_val_recon_loss: 4.5933e-04 - val_val_KL loss: 27.3665 - val_beta: 0.0012\n",
      "Epoch 3645/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 349.2553 - recon_loss: 4.4709e-04 - KL loss: 27.4907 - beta: 0.0012 - val_val_loss: 349.4797 - val_val_recon_loss: 4.4741e-04 - val_val_KL loss: 27.4833 - val_beta: 0.0012\n",
      "Epoch 3646/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 350.0584 - recon_loss: 4.4792e-04 - KL loss: 27.6991 - beta: 0.0012 - val_val_loss: 343.5258 - val_val_recon_loss: 4.3888e-04 - val_val_KL loss: 27.6700 - val_beta: 0.0012\n",
      "Epoch 3647/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 348.6501 - recon_loss: 4.4565e-04 - KL loss: 27.9191 - beta: 0.0012 - val_val_loss: 369.4307 - val_val_recon_loss: 4.7426e-04 - val_val_KL loss: 28.1094 - val_beta: 0.0012\n",
      "Epoch 3648/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 359.8441 - recon_loss: 4.6085e-04 - KL loss: 28.1751 - beta: 0.0012 - val_val_loss: 362.1812 - val_val_recon_loss: 4.6410e-04 - val_val_KL loss: 28.1719 - val_beta: 0.0012\n",
      "Epoch 3649/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 355.1193 - recon_loss: 4.5455e-04 - KL loss: 27.9864 - beta: 0.0012 - val_val_loss: 353.7771 - val_val_recon_loss: 4.5213e-04 - val_val_KL loss: 28.3879 - val_beta: 0.0012\n",
      "Epoch 3650/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 369.9422 - recon_loss: 4.7392e-04 - KL loss: 28.8709 - beta: 0.0012 - val_val_loss: 343.7177 - val_val_recon_loss: 4.3870e-04 - val_val_KL loss: 27.9928 - val_beta: 0.0012\n",
      "Epoch 3651/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 339.9333 - recon_loss: 4.3373e-04 - KL loss: 27.7856 - beta: 0.0012\n",
      "Epoch 03651: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 339.9384 - recon_loss: 4.3374e-04 - KL loss: 27.7856 - beta: 0.0012 - val_val_loss: 383.1608 - val_val_recon_loss: 4.9302e-04 - val_val_KL loss: 28.3431 - val_beta: 0.0012\n",
      "Epoch 3652/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 361.8331 - recon_loss: 4.6406e-04 - KL loss: 27.8588 - beta: 0.0012 - val_val_loss: 337.2065 - val_val_recon_loss: 4.3001e-04 - val_val_KL loss: 27.7376 - val_beta: 0.0012\n",
      "Epoch 3653/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 337.2111 - recon_loss: 4.3003e-04 - KL loss: 27.7260 - beta: 0.0012 - val_val_loss: 332.1464 - val_val_recon_loss: 4.2313e-04 - val_val_KL loss: 27.6227 - val_beta: 0.0012\n",
      "Epoch 3654/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 331.8858 - recon_loss: 4.2262e-04 - KL loss: 27.7293 - beta: 0.0012 - val_val_loss: 332.8234 - val_val_recon_loss: 4.2484e-04 - val_val_KL loss: 27.0724 - val_beta: 0.0012\n",
      "Epoch 3655/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 330.2342 - recon_loss: 4.2096e-04 - KL loss: 27.2726 - beta: 0.0012 - val_val_loss: 334.0750 - val_val_recon_loss: 4.2606e-04 - val_val_KL loss: 27.4460 - val_beta: 0.0012\n",
      "Epoch 3656/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 331.2367 - recon_loss: 4.2226e-04 - KL loss: 27.3417 - beta: 0.0012 - val_val_loss: 329.7284 - val_val_recon_loss: 4.2063e-04 - val_val_KL loss: 27.0071 - val_beta: 0.0012\n",
      "Epoch 3657/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 326.3361 - recon_loss: 4.1574e-04 - KL loss: 27.1332 - beta: 0.0012 - val_val_loss: 335.7654 - val_val_recon_loss: 4.2841e-04 - val_val_KL loss: 27.4427 - val_beta: 0.0012\n",
      "Epoch 3658/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 331.1308 - recon_loss: 4.2214e-04 - KL loss: 27.3260 - beta: 0.0012 - val_val_loss: 324.0004 - val_val_recon_loss: 4.1225e-04 - val_val_KL loss: 27.3112 - val_beta: 0.0012\n",
      "Epoch 3659/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 323.6914 - recon_loss: 4.1170e-04 - KL loss: 27.3967 - beta: 0.0012 - val_val_loss: 321.9484 - val_val_recon_loss: 4.0934e-04 - val_val_KL loss: 27.3503 - val_beta: 0.0012\n",
      "Epoch 3660/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 320.4594 - recon_loss: 4.0730e-04 - KL loss: 27.3300 - beta: 0.0012 - val_val_loss: 321.7909 - val_val_recon_loss: 4.0923e-04 - val_val_KL loss: 27.2770 - val_beta: 0.0012\n",
      "Epoch 3661/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 320.2053 - recon_loss: 4.0683e-04 - KL loss: 27.4159 - beta: 0.0012 - val_val_loss: 321.9643 - val_val_recon_loss: 4.0946e-04 - val_val_KL loss: 27.2848 - val_beta: 0.0012\n",
      "Epoch 3662/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 322.2395 - recon_loss: 4.0965e-04 - KL loss: 27.4189 - beta: 0.0012 - val_val_loss: 319.4113 - val_val_recon_loss: 4.0584e-04 - val_val_KL loss: 27.3348 - val_beta: 0.0012\n",
      "Epoch 3663/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 317.4287 - recon_loss: 4.0317e-04 - KL loss: 27.2733 - beta: 0.0012 - val_val_loss: 319.6057 - val_val_recon_loss: 4.0651e-04 - val_val_KL loss: 27.0443 - val_beta: 0.0012\n",
      "Epoch 3664/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 321.3925 - recon_loss: 4.0885e-04 - KL loss: 27.1456 - beta: 0.0012 - val_val_loss: 319.1735 - val_val_recon_loss: 4.0573e-04 - val_val_KL loss: 27.1724 - val_beta: 0.0012\n",
      "Epoch 3665/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 314.9231 - recon_loss: 3.9988e-04 - KL loss: 27.1316 - beta: 0.0012 - val_val_loss: 318.2271 - val_val_recon_loss: 4.0463e-04 - val_val_KL loss: 27.0217 - val_beta: 0.0012\n",
      "Epoch 3666/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 316.6202 - recon_loss: 4.0214e-04 - KL loss: 27.2089 - beta: 0.0012 - val_val_loss: 316.6226 - val_val_recon_loss: 4.0201e-04 - val_val_KL loss: 27.3042 - val_beta: 0.0012\n",
      "Epoch 3667/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 310.6397 - recon_loss: 3.9378e-04 - KL loss: 27.2418 - beta: 0.0012 - val_val_loss: 315.9978 - val_val_recon_loss: 4.0116e-04 - val_val_KL loss: 27.2917 - val_beta: 0.0012\n",
      "Epoch 3668/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 320.5425 - recon_loss: 4.0738e-04 - KL loss: 27.3552 - beta: 0.0012 - val_val_loss: 314.9402 - val_val_recon_loss: 3.9965e-04 - val_val_KL loss: 27.3162 - val_beta: 0.0012\n",
      "Epoch 3669/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 315.3764 - recon_loss: 4.0027e-04 - KL loss: 27.3050 - beta: 0.0012 - val_val_loss: 315.5038 - val_val_recon_loss: 4.0055e-04 - val_val_KL loss: 27.2315 - val_beta: 0.0012\n",
      "Epoch 3670/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 317.3110 - recon_loss: 4.0314e-04 - KL loss: 27.1762 - beta: 0.0012 - val_val_loss: 318.7054 - val_val_recon_loss: 4.0542e-04 - val_val_KL loss: 26.9315 - val_beta: 0.0012\n",
      "Epoch 3671/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 316.7515 - recon_loss: 4.0253e-04 - KL loss: 27.0573 - beta: 0.0012 - val_val_loss: 315.0099 - val_val_recon_loss: 4.0005e-04 - val_val_KL loss: 27.1017 - val_beta: 0.0012\n",
      "Epoch 3672/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 313.1299 - recon_loss: 3.9743e-04 - KL loss: 27.1052 - beta: 0.0012 - val_val_loss: 316.5587 - val_val_recon_loss: 4.0249e-04 - val_val_KL loss: 26.8959 - val_beta: 0.0012\n",
      "Epoch 3673/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 314.0495 - recon_loss: 3.9881e-04 - KL loss: 27.0291 - beta: 0.0012\n",
      "Epoch 03673: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 314.0487 - recon_loss: 3.9881e-04 - KL loss: 27.0291 - beta: 0.0012 - val_val_loss: 315.7579 - val_val_recon_loss: 4.0083e-04 - val_val_KL loss: 27.2870 - val_beta: 0.0012\n",
      "Epoch 3674/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 307.0416 - recon_loss: 3.8897e-04 - KL loss: 27.1031 - beta: 0.0012 - val_val_loss: 311.2898 - val_val_recon_loss: 3.9494e-04 - val_val_KL loss: 27.0568 - val_beta: 0.0012\n",
      "Epoch 3675/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 311.4028 - recon_loss: 3.9507e-04 - KL loss: 27.0796 - beta: 0.0012 - val_val_loss: 313.2206 - val_val_recon_loss: 3.9746e-04 - val_val_KL loss: 27.1743 - val_beta: 0.0012\n",
      "Epoch 3676/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 309.8520 - recon_loss: 3.9286e-04 - KL loss: 27.1172 - beta: 0.0012 - val_val_loss: 313.6280 - val_val_recon_loss: 3.9824e-04 - val_val_KL loss: 27.0208 - val_beta: 0.0012\n",
      "Epoch 3677/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 310.8904 - recon_loss: 3.9441e-04 - KL loss: 27.0402 - beta: 0.0012 - val_val_loss: 313.8107 - val_val_recon_loss: 3.9830e-04 - val_val_KL loss: 27.1581 - val_beta: 0.0012\n",
      "Epoch 3678/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 312.9917 - recon_loss: 3.9707e-04 - KL loss: 27.2255 - beta: 0.0012 - val_val_loss: 313.4954 - val_val_recon_loss: 3.9796e-04 - val_val_KL loss: 27.0882 - val_beta: 0.0012\n",
      "Epoch 3679/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 305.4920 - recon_loss: 3.8689e-04 - KL loss: 27.0545 - beta: 0.0012\n",
      "Epoch 03679: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.4926 - recon_loss: 3.8689e-04 - KL loss: 27.0545 - beta: 0.0012 - val_val_loss: 313.2631 - val_val_recon_loss: 3.9762e-04 - val_val_KL loss: 27.1044 - val_beta: 0.0012\n",
      "Epoch 3680/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.6712 - recon_loss: 3.9114e-04 - KL loss: 27.1740 - beta: 0.0012 - val_val_loss: 313.3683 - val_val_recon_loss: 3.9776e-04 - val_val_KL loss: 27.1033 - val_beta: 0.0012\n",
      "Epoch 3681/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 309.4685 - recon_loss: 3.9235e-04 - KL loss: 27.1024 - beta: 0.0012 - val_val_loss: 312.1892 - val_val_recon_loss: 3.9604e-04 - val_val_KL loss: 27.1664 - val_beta: 0.0012\n",
      "Epoch 3682/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 312.9110 - recon_loss: 3.9701e-04 - KL loss: 27.1916 - beta: 0.0012 - val_val_loss: 311.9126 - val_val_recon_loss: 3.9565e-04 - val_val_KL loss: 27.1708 - val_beta: 0.0012\n",
      "Epoch 3683/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.6414 - recon_loss: 3.9114e-04 - KL loss: 27.1412 - beta: 0.0012 - val_val_loss: 311.4148 - val_val_recon_loss: 3.9500e-04 - val_val_KL loss: 27.1387 - val_beta: 0.0012\n",
      "Epoch 3684/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.3931 - recon_loss: 3.9078e-04 - KL loss: 27.1564 - beta: 0.0012 - val_val_loss: 310.9689 - val_val_recon_loss: 3.9432e-04 - val_val_KL loss: 27.1820 - val_beta: 0.0012\n",
      "Epoch 3685/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 311.4179 - recon_loss: 3.9495e-04 - KL loss: 27.1765 - beta: 0.0012 - val_val_loss: 311.6553 - val_val_recon_loss: 3.9526e-04 - val_val_KL loss: 27.1953 - val_beta: 0.0012\n",
      "Epoch 3686/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 310.0728 - recon_loss: 3.9305e-04 - KL loss: 27.2022 - beta: 0.0012 - val_val_loss: 311.4607 - val_val_recon_loss: 3.9497e-04 - val_val_KL loss: 27.2067 - val_beta: 0.0012\n",
      "Epoch 3687/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.7716 - recon_loss: 3.8710e-04 - KL loss: 27.1841 - beta: 0.0012 - val_val_loss: 311.1211 - val_val_recon_loss: 3.9452e-04 - val_val_KL loss: 27.1939 - val_beta: 0.0012\n",
      "Epoch 3688/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.3714 - recon_loss: 3.9073e-04 - KL loss: 27.1651 - beta: 0.0012 - val_val_loss: 311.8962 - val_val_recon_loss: 3.9563e-04 - val_val_KL loss: 27.1668 - val_beta: 0.0012\n",
      "Epoch 3689/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 306.5574 - recon_loss: 3.8820e-04 - KL loss: 27.1759 - beta: 0.0012\n",
      "Epoch 03689: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.5575 - recon_loss: 3.8820e-04 - KL loss: 27.1759 - beta: 0.0012 - val_val_loss: 311.0369 - val_val_recon_loss: 3.9438e-04 - val_val_KL loss: 27.2057 - val_beta: 0.0012\n",
      "Epoch 3690/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 311.8361 - recon_loss: 3.9545e-04 - KL loss: 27.2358 - beta: 0.0012 - val_val_loss: 311.1736 - val_val_recon_loss: 3.9458e-04 - val_val_KL loss: 27.2004 - val_beta: 0.0012\n",
      "Epoch 3691/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.8969 - recon_loss: 3.9142e-04 - KL loss: 27.1963 - beta: 0.0012 - val_val_loss: 311.5076 - val_val_recon_loss: 3.9502e-04 - val_val_KL loss: 27.2171 - val_beta: 0.0012\n",
      "Epoch 3692/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 307.5233 - recon_loss: 3.8950e-04 - KL loss: 27.2066 - beta: 0.0012 - val_val_loss: 311.5873 - val_val_recon_loss: 3.9516e-04 - val_val_KL loss: 27.1930 - val_beta: 0.0012\n",
      "Epoch 3693/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 304.7164 - recon_loss: 3.8576e-04 - KL loss: 27.0925 - beta: 0.0012 - val_val_loss: 310.8820 - val_val_recon_loss: 3.9418e-04 - val_val_KL loss: 27.1996 - val_beta: 0.0012\n",
      "Epoch 3694/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 307.6879 - recon_loss: 3.8969e-04 - KL loss: 27.2309 - beta: 0.0012 - val_val_loss: 310.9481 - val_val_recon_loss: 3.9426e-04 - val_val_KL loss: 27.2074 - val_beta: 0.0012\n",
      "Epoch 3695/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 308.6688 - recon_loss: 3.9114e-04 - KL loss: 27.1718 - beta: 0.0012 - val_val_loss: 311.2772 - val_val_recon_loss: 3.9473e-04 - val_val_KL loss: 27.1938 - val_beta: 0.0012\n",
      "Epoch 3696/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.6881 - recon_loss: 3.8841e-04 - KL loss: 27.1534 - beta: 0.0012 - val_val_loss: 310.6691 - val_val_recon_loss: 3.9382e-04 - val_val_KL loss: 27.2399 - val_beta: 0.0012\n",
      "Epoch 3697/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.1582 - recon_loss: 3.8763e-04 - KL loss: 27.1890 - beta: 0.0012 - val_val_loss: 311.0175 - val_val_recon_loss: 3.9437e-04 - val_val_KL loss: 27.1941 - val_beta: 0.0012\n",
      "Epoch 3698/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 303.1933 - recon_loss: 3.8354e-04 - KL loss: 27.1617 - beta: 0.0012 - val_val_loss: 311.2554 - val_val_recon_loss: 3.9466e-04 - val_val_KL loss: 27.2206 - val_beta: 0.0012\n",
      "Epoch 3699/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.1233 - recon_loss: 3.8760e-04 - KL loss: 27.1764 - beta: 0.0012 - val_val_loss: 311.0306 - val_val_recon_loss: 3.9438e-04 - val_val_KL loss: 27.2019 - val_beta: 0.0012\n",
      "Epoch 3700/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.9239 - recon_loss: 3.8729e-04 - KL loss: 27.1947 - beta: 0.0012 - val_val_loss: 310.5955 - val_val_recon_loss: 3.9375e-04 - val_val_KL loss: 27.2170 - val_beta: 0.0012\n",
      "Epoch 3701/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 309.7240 - recon_loss: 3.9251e-04 - KL loss: 27.2384 - beta: 0.0012 - val_val_loss: 311.5630 - val_val_recon_loss: 3.9507e-04 - val_val_KL loss: 27.2349 - val_beta: 0.0012\n",
      "Epoch 3702/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.3752 - recon_loss: 3.9065e-04 - KL loss: 27.2322 - beta: 0.0012 - val_val_loss: 311.1992 - val_val_recon_loss: 3.9454e-04 - val_val_KL loss: 27.2511 - val_beta: 0.0012\n",
      "Epoch 3703/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 307.9187 - recon_loss: 3.9007e-04 - KL loss: 27.1935 - beta: 0.0012 - val_val_loss: 311.2375 - val_val_recon_loss: 3.9463e-04 - val_val_KL loss: 27.2244 - val_beta: 0.0012\n",
      "Epoch 3704/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.6280 - recon_loss: 3.8683e-04 - KL loss: 27.2349 - beta: 0.0012 - val_val_loss: 311.2039 - val_val_recon_loss: 3.9456e-04 - val_val_KL loss: 27.2469 - val_beta: 0.0012\n",
      "Epoch 3705/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 306.1003 - recon_loss: 3.8750e-04 - KL loss: 27.2227 - beta: 0.0012\n",
      "Epoch 03705: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.1011 - recon_loss: 3.8750e-04 - KL loss: 27.2227 - beta: 0.0012 - val_val_loss: 310.8796 - val_val_recon_loss: 3.9415e-04 - val_val_KL loss: 27.2182 - val_beta: 0.0012\n",
      "Epoch 3706/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308.2428 - recon_loss: 3.9055e-04 - KL loss: 27.1681 - beta: 0.0012 - val_val_loss: 310.9733 - val_val_recon_loss: 3.9429e-04 - val_val_KL loss: 27.2106 - val_beta: 0.0012\n",
      "Epoch 3707/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.8712 - recon_loss: 3.8863e-04 - KL loss: 27.1775 - beta: 0.0012 - val_val_loss: 311.4512 - val_val_recon_loss: 3.9495e-04 - val_val_KL loss: 27.2100 - val_beta: 0.0012\n",
      "Epoch 3708/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.9951 - recon_loss: 3.8731e-04 - KL loss: 27.2536 - beta: 0.0012 - val_val_loss: 310.5055 - val_val_recon_loss: 3.9364e-04 - val_val_KL loss: 27.2064 - val_beta: 0.0012\n",
      "Epoch 3709/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.1813 - recon_loss: 3.8630e-04 - KL loss: 27.1639 - beta: 0.0012 - val_val_loss: 310.6494 - val_val_recon_loss: 3.9383e-04 - val_val_KL loss: 27.2131 - val_beta: 0.0012\n",
      "Epoch 3710/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.9554 - recon_loss: 3.8736e-04 - KL loss: 27.1778 - beta: 0.0012 - val_val_loss: 310.6654 - val_val_recon_loss: 3.9384e-04 - val_val_KL loss: 27.2279 - val_beta: 0.0012\n",
      "Epoch 3711/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.7204 - recon_loss: 3.8696e-04 - KL loss: 27.2318 - beta: 0.0012 - val_val_loss: 310.8090 - val_val_recon_loss: 3.9404e-04 - val_val_KL loss: 27.2237 - val_beta: 0.0012\n",
      "Epoch 3712/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.6665 - recon_loss: 3.8699e-04 - KL loss: 27.1548 - beta: 0.0012 - val_val_loss: 311.0736 - val_val_recon_loss: 3.9443e-04 - val_val_KL loss: 27.2092 - val_beta: 0.0012\n",
      "Epoch 3713/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 307.9612 - recon_loss: 3.9005e-04 - KL loss: 27.2475 - beta: 0.0012\n",
      "Epoch 03713: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 307.9600 - recon_loss: 3.9005e-04 - KL loss: 27.2475 - beta: 0.0012 - val_val_loss: 310.8926 - val_val_recon_loss: 3.9417e-04 - val_val_KL loss: 27.2135 - val_beta: 0.0012\n",
      "Epoch 3714/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 307.0184 - recon_loss: 3.8881e-04 - KL loss: 27.1952 - beta: 0.0012 - val_val_loss: 310.8022 - val_val_recon_loss: 3.9405e-04 - val_val_KL loss: 27.2112 - val_beta: 0.0012\n",
      "Epoch 3715/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.5533 - recon_loss: 3.8815e-04 - KL loss: 27.2047 - beta: 0.0012 - val_val_loss: 310.7710 - val_val_recon_loss: 3.9401e-04 - val_val_KL loss: 27.2105 - val_beta: 0.0012\n",
      "Epoch 3716/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305.8748 - recon_loss: 3.8727e-04 - KL loss: 27.1634 - beta: 0.0012 - val_val_loss: 310.5399 - val_val_recon_loss: 3.9368e-04 - val_val_KL loss: 27.2117 - val_beta: 0.0012\n",
      "Epoch 3717/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306.5248 - recon_loss: 3.8808e-04 - KL loss: 27.2285 - beta: 0.0012 - val_val_loss: 310.5396 - val_val_recon_loss: 3.9368e-04 - val_val_KL loss: 27.2142 - val_beta: 0.0012\n",
      "Epoch 3718/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 307.3927 - recon_loss: 3.8933e-04 - KL loss: 27.1948 - beta: 0.0012\n",
      "Epoch 03718: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 307.3929 - recon_loss: 3.8933e-04 - KL loss: 27.1948 - beta: 0.0012 - val_val_loss: 310.9605 - val_val_recon_loss: 3.9427e-04 - val_val_KL loss: 27.2107 - val_beta: 0.0012\n",
      "Epoch 3718/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 868.1012 - recon_loss: 4.3386e-04 - KL loss: 30.4398 - beta: 7.1969e-04 - val_val_loss: 864.9519 - val_val_recon_loss: 4.3199e-04 - val_val_KL loss: 30.9080 - val_beta: 7.1969e-04\n",
      "Epoch 3719/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 887.6436 - recon_loss: 4.4311e-04 - KL loss: 32.1409 - beta: 7.1969e-04 - val_val_loss: 831.4099 - val_val_recon_loss: 4.1403e-04 - val_val_KL loss: 32.0480 - val_beta: 7.1969e-04\n",
      "Epoch 3720/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 834.5264 - recon_loss: 4.1557e-04 - KL loss: 32.1866 - beta: 7.1969e-04 - val_val_loss: 887.8501 - val_val_recon_loss: 4.4267e-04 - val_val_KL loss: 33.1790 - val_beta: 7.1969e-04\n",
      "Epoch 3721/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 874.0301 - recon_loss: 4.3580e-04 - KL loss: 32.6258 - beta: 7.1969e-04 - val_val_loss: 885.2258 - val_val_recon_loss: 4.4151e-04 - val_val_KL loss: 32.8098 - val_beta: 7.1969e-04\n",
      "Epoch 3722/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 862.8944 - recon_loss: 4.3016e-04 - KL loss: 32.3912 - beta: 7.1969e-04 - val_val_loss: 867.3298 - val_val_recon_loss: 4.3228e-04 - val_val_KL loss: 32.7311 - val_beta: 7.1969e-04\n",
      "Epoch 3723/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 913.2093 - recon_loss: 4.5557e-04 - KL loss: 33.6433 - beta: 7.1969e-04 - val_val_loss: 869.5153 - val_val_recon_loss: 4.3338e-04 - val_val_KL loss: 32.7869 - val_beta: 7.1969e-04\n",
      "Epoch 3724/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 841.6465 - recon_loss: 4.1893e-04 - KL loss: 32.8182 - beta: 7.1969e-04 - val_val_loss: 829.8849 - val_val_recon_loss: 4.1338e-04 - val_val_KL loss: 31.7718 - val_beta: 7.1969e-04\n",
      "Epoch 3725/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 821.7475 - recon_loss: 4.0878e-04 - KL loss: 32.5176 - beta: 7.1969e-04 - val_val_loss: 887.5670 - val_val_recon_loss: 4.4260e-04 - val_val_KL loss: 33.0333 - val_beta: 7.1969e-04\n",
      "Epoch 3726/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 883.0881 - recon_loss: 4.4008e-04 - KL loss: 33.4178 - beta: 7.1969e-04 - val_val_loss: 857.1797 - val_val_recon_loss: 4.2682e-04 - val_val_KL loss: 33.1176 - val_beta: 7.1969e-04\n",
      "Epoch 3727/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 854.0324 - recon_loss: 4.2512e-04 - KL loss: 33.2447 - beta: 7.1969e-04 - val_val_loss: 849.4355 - val_val_recon_loss: 4.2262e-04 - val_val_KL loss: 33.4810 - val_beta: 7.1969e-04\n",
      "Epoch 3728/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 839.4712 - recon_loss: 4.1771e-04 - KL loss: 32.9983 - beta: 7.1969e-04 - val_val_loss: 842.7960 - val_val_recon_loss: 4.1993e-04 - val_val_KL loss: 32.0468 - val_beta: 7.1969e-04\n",
      "Epoch 3729/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 826.4788 - recon_loss: 4.1093e-04 - KL loss: 33.0896 - beta: 7.1969e-04 - val_val_loss: 818.9263 - val_val_recon_loss: 4.0713e-04 - val_val_KL loss: 32.8787 - val_beta: 7.1969e-04\n",
      "Epoch 3730/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 798.3005 - recon_loss: 3.9657e-04 - KL loss: 32.6494 - beta: 7.1969e-04 - val_val_loss: 812.1474 - val_val_recon_loss: 4.0398e-04 - val_val_KL loss: 32.1870 - val_beta: 7.1969e-04\n",
      "Epoch 3731/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 814.6006 - recon_loss: 4.0509e-04 - KL loss: 32.4934 - beta: 7.1969e-04 - val_val_loss: 838.2397 - val_val_recon_loss: 4.1737e-04 - val_val_KL loss: 32.4338 - val_beta: 7.1969e-04\n",
      "Epoch 3732/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 812.9598 - recon_loss: 4.0427e-04 - KL loss: 32.4397 - beta: 7.1969e-04 - val_val_loss: 799.1629 - val_val_recon_loss: 3.9715e-04 - val_val_KL loss: 32.3860 - val_beta: 7.1969e-04\n",
      "Epoch 3733/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 806.1807 - recon_loss: 4.0066e-04 - KL loss: 32.6225 - beta: 7.1969e-04 - val_val_loss: 790.9919 - val_val_recon_loss: 3.9281e-04 - val_val_KL loss: 32.6004 - val_beta: 7.1969e-04\n",
      "Epoch 3734/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 790.7383 - recon_loss: 3.9262e-04 - KL loss: 32.7057 - beta: 7.1969e-04 - val_val_loss: 825.6520 - val_val_recon_loss: 4.1044e-04 - val_val_KL loss: 33.2262 - val_beta: 7.1969e-04\n",
      "Epoch 3735/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 813.5735 - recon_loss: 4.0418e-04 - KL loss: 33.2179 - beta: 7.1969e-04 - val_val_loss: 798.0532 - val_val_recon_loss: 3.9638e-04 - val_val_KL loss: 32.7637 - val_beta: 7.1969e-04\n",
      "Epoch 3736/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 815.4722 - recon_loss: 4.0530e-04 - KL loss: 32.9596 - beta: 7.1969e-04 - val_val_loss: 809.3430 - val_val_recon_loss: 4.0204e-04 - val_val_KL loss: 33.1228 - val_beta: 7.1969e-04\n",
      "Epoch 3737/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 788.9202 - recon_loss: 3.9162e-04 - KL loss: 32.8283 - beta: 7.1969e-04 - val_val_loss: 804.2258 - val_val_recon_loss: 3.9998e-04 - val_val_KL loss: 31.9878 - val_beta: 7.1969e-04\n",
      "Epoch 3738/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 790.3975 - recon_loss: 3.9260e-04 - KL loss: 32.4152 - beta: 7.1969e-04 - val_val_loss: 790.7656 - val_val_recon_loss: 3.9294e-04 - val_val_KL loss: 32.1157 - val_beta: 7.1969e-04\n",
      "Epoch 3739/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 785.6901 - recon_loss: 3.9017e-04 - KL loss: 32.3809 - beta: 7.1969e-04 - val_val_loss: 874.4512 - val_val_recon_loss: 4.3560e-04 - val_val_KL loss: 33.4319 - val_beta: 7.1969e-04\n",
      "Epoch 3740/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 821.4035 - recon_loss: 4.0832e-04 - KL loss: 33.0606 - beta: 7.1969e-04 - val_val_loss: 789.0617 - val_val_recon_loss: 3.9201e-04 - val_val_KL loss: 32.2162 - val_beta: 7.1969e-04\n",
      "Epoch 3741/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 794.2814 - recon_loss: 3.9444e-04 - KL loss: 32.7294 - beta: 7.1969e-04 - val_val_loss: 804.7687 - val_val_recon_loss: 4.0007e-04 - val_val_KL loss: 32.3561 - val_beta: 7.1969e-04\n",
      "Epoch 3742/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 825.0197 - recon_loss: 4.1040e-04 - KL loss: 32.6676 - beta: 7.1969e-04 - val_val_loss: 793.0643 - val_val_recon_loss: 3.9374e-04 - val_val_KL loss: 32.8714 - val_beta: 7.1969e-04\n",
      "Epoch 3743/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 805.1108 - recon_loss: 3.9995e-04 - KL loss: 32.9226 - beta: 7.1969e-04 - val_val_loss: 792.9857 - val_val_recon_loss: 3.9406e-04 - val_val_KL loss: 32.1819 - val_beta: 7.1969e-04\n",
      "Epoch 3744/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 812.7198 - recon_loss: 4.0386e-04 - KL loss: 32.9956 - beta: 7.1969e-04 - val_val_loss: 779.7332 - val_val_recon_loss: 3.8691e-04 - val_val_KL loss: 32.7311 - val_beta: 7.1969e-04\n",
      "Epoch 3745/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 772.6064 - recon_loss: 3.8324e-04 - KL loss: 32.6816 - beta: 7.1969e-04 - val_val_loss: 786.2261 - val_val_recon_loss: 3.9022e-04 - val_val_KL loss: 32.8232 - val_beta: 7.1969e-04\n",
      "Epoch 3746/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 787.8721 - recon_loss: 3.9102e-04 - KL loss: 32.9209 - beta: 7.1969e-04 - val_val_loss: 834.8402 - val_val_recon_loss: 4.1590e-04 - val_val_KL loss: 31.8602 - val_beta: 7.1969e-04\n",
      "Epoch 3747/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 799.7434 - recon_loss: 3.9733e-04 - KL loss: 32.6182 - beta: 7.1969e-04 - val_val_loss: 833.3265 - val_val_recon_loss: 4.1433e-04 - val_val_KL loss: 33.3896 - val_beta: 7.1969e-04\n",
      "Epoch 3748/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 787.5970 - recon_loss: 3.9088e-04 - KL loss: 32.9332 - beta: 7.1969e-04 - val_val_loss: 786.3754 - val_val_recon_loss: 3.9043e-04 - val_val_KL loss: 32.5689 - val_beta: 7.1969e-04\n",
      "Epoch 3749/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 790.0178 - recon_loss: 3.9221e-04 - KL loss: 32.7815 - beta: 7.1969e-04\n",
      "Epoch 03749: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 790.0247 - recon_loss: 3.9221e-04 - KL loss: 32.7817 - beta: 7.1969e-04 - val_val_loss: 796.1434 - val_val_recon_loss: 3.9551e-04 - val_val_KL loss: 32.5245 - val_beta: 7.1969e-04\n",
      "Epoch 3750/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 767.8164 - recon_loss: 3.8073e-04 - KL loss: 32.7394 - beta: 7.1969e-04 - val_val_loss: 763.1516 - val_val_recon_loss: 3.7837e-04 - val_val_KL loss: 32.6408 - val_beta: 7.1969e-04\n",
      "Epoch 3751/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 747.8816 - recon_loss: 3.7040e-04 - KL loss: 32.7528 - beta: 7.1969e-04 - val_val_loss: 765.8412 - val_val_recon_loss: 3.7961e-04 - val_val_KL loss: 32.9333 - val_beta: 7.1969e-04\n",
      "Epoch 3752/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 766.4173 - recon_loss: 3.7981e-04 - KL loss: 33.1176 - beta: 7.1969e-04 - val_val_loss: 777.3973 - val_val_recon_loss: 3.8543e-04 - val_val_KL loss: 33.2486 - val_beta: 7.1969e-04\n",
      "Epoch 3753/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 756.8336 - recon_loss: 3.7491e-04 - KL loss: 33.0040 - beta: 7.1969e-04 - val_val_loss: 772.5164 - val_val_recon_loss: 3.8287e-04 - val_val_KL loss: 33.3131 - val_beta: 7.1969e-04\n",
      "Epoch 3754/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 765.3477 - recon_loss: 3.7911e-04 - KL loss: 33.3989 - beta: 7.1969e-04 - val_val_loss: 765.2363 - val_val_recon_loss: 3.7911e-04 - val_val_KL loss: 33.2950 - val_beta: 7.1969e-04\n",
      "Epoch 3755/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 745.6399 - recon_loss: 3.6900e-04 - KL loss: 33.2148 - beta: 7.1969e-04 - val_val_loss: 760.3499 - val_val_recon_loss: 3.7676e-04 - val_val_KL loss: 32.9457 - val_beta: 7.1969e-04\n",
      "Epoch 3756/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 751.2555 - recon_loss: 3.7187e-04 - KL loss: 33.2871 - beta: 7.1969e-04 - val_val_loss: 762.8419 - val_val_recon_loss: 3.7782e-04 - val_val_KL loss: 33.3849 - val_beta: 7.1969e-04\n",
      "Epoch 3757/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 754.1528 - recon_loss: 3.7336e-04 - KL loss: 33.3004 - beta: 7.1969e-04 - val_val_loss: 761.3471 - val_val_recon_loss: 3.7709e-04 - val_val_KL loss: 33.2917 - val_beta: 7.1969e-04\n",
      "Epoch 3758/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 751.3188 - recon_loss: 3.7187e-04 - KL loss: 33.3545 - beta: 7.1969e-04 - val_val_loss: 764.4962 - val_val_recon_loss: 3.7867e-04 - val_val_KL loss: 33.3920 - val_beta: 7.1969e-04\n",
      "Epoch 3759/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 746.2085 - recon_loss: 3.6924e-04 - KL loss: 33.3134 - beta: 7.1969e-04 - val_val_loss: 765.0483 - val_val_recon_loss: 3.7916e-04 - val_val_KL loss: 32.9962 - val_beta: 7.1969e-04\n",
      "Epoch 3760/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 740.9059 - recon_loss: 3.6668e-04 - KL loss: 32.9604 - beta: 7.1969e-04 - val_val_loss: 747.9709 - val_val_recon_loss: 3.7030e-04 - val_val_KL loss: 33.0238 - val_beta: 7.1969e-04\n",
      "Epoch 3761/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 738.8968 - recon_loss: 3.6562e-04 - KL loss: 32.9950 - beta: 7.1969e-04 - val_val_loss: 747.5349 - val_val_recon_loss: 3.7023e-04 - val_val_KL loss: 32.7347 - val_beta: 7.1969e-04\n",
      "Epoch 3762/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 738.2625 - recon_loss: 3.6538e-04 - KL loss: 32.8225 - beta: 7.1969e-04 - val_val_loss: 747.7606 - val_val_recon_loss: 3.7022e-04 - val_val_KL loss: 32.9848 - val_beta: 7.1969e-04\n",
      "Epoch 3763/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 737.4582 - recon_loss: 3.6486e-04 - KL loss: 33.0271 - beta: 7.1969e-04 - val_val_loss: 747.5309 - val_val_recon_loss: 3.7020e-04 - val_val_KL loss: 32.7795 - val_beta: 7.1969e-04\n",
      "Epoch 3764/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 733.1265 - recon_loss: 3.6266e-04 - KL loss: 32.9361 - beta: 7.1969e-04 - val_val_loss: 753.7513 - val_val_recon_loss: 3.7330e-04 - val_val_KL loss: 33.0287 - val_beta: 7.1969e-04\n",
      "Epoch 3765/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 736.4048 - recon_loss: 3.6431e-04 - KL loss: 33.0395 - beta: 7.1969e-04 - val_val_loss: 744.7301 - val_val_recon_loss: 3.6859e-04 - val_val_KL loss: 33.1005 - val_beta: 7.1969e-04\n",
      "Epoch 3766/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 732.4424 - recon_loss: 3.6223e-04 - KL loss: 33.0852 - beta: 7.1969e-04 - val_val_loss: 748.3847 - val_val_recon_loss: 3.7046e-04 - val_val_KL loss: 33.1292 - val_beta: 7.1969e-04\n",
      "Epoch 3767/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 740.9127 - recon_loss: 3.6671e-04 - KL loss: 32.9070 - beta: 7.1969e-04 - val_val_loss: 740.6096 - val_val_recon_loss: 3.6675e-04 - val_val_KL loss: 32.5228 - val_beta: 7.1969e-04\n",
      "Epoch 3768/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 730.6667 - recon_loss: 3.6152e-04 - KL loss: 32.6721 - beta: 7.1969e-04 - val_val_loss: 730.0394 - val_val_recon_loss: 3.6125e-04 - val_val_KL loss: 32.5689 - val_beta: 7.1969e-04\n",
      "Epoch 3769/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 733.7966 - recon_loss: 3.6302e-04 - KL loss: 32.9121 - beta: 7.1969e-04 - val_val_loss: 740.4504 - val_val_recon_loss: 3.6631e-04 - val_val_KL loss: 33.2139 - val_beta: 7.1969e-04\n",
      "Epoch 3770/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 721.0308 - recon_loss: 3.5635e-04 - KL loss: 33.0215 - beta: 7.1969e-04 - val_val_loss: 737.2411 - val_val_recon_loss: 3.6490e-04 - val_val_KL loss: 32.7360 - val_beta: 7.1969e-04\n",
      "Epoch 3771/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 727.6975 - recon_loss: 3.5992e-04 - KL loss: 32.8101 - beta: 7.1969e-04 - val_val_loss: 735.8454 - val_val_recon_loss: 3.6412e-04 - val_val_KL loss: 32.8402 - val_beta: 7.1969e-04\n",
      "Epoch 3772/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 726.4259 - recon_loss: 3.5912e-04 - KL loss: 33.0671 - beta: 7.1969e-04 - val_val_loss: 743.8602 - val_val_recon_loss: 3.6816e-04 - val_val_KL loss: 33.0480 - val_beta: 7.1969e-04\n",
      "Epoch 3773/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 726.9489 - recon_loss: 3.5941e-04 - KL loss: 33.0315 - beta: 7.1969e-04\n",
      "Epoch 03773: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 726.9502 - recon_loss: 3.5941e-04 - KL loss: 33.0315 - beta: 7.1969e-04 - val_val_loss: 746.6393 - val_val_recon_loss: 3.6962e-04 - val_val_KL loss: 33.0219 - val_beta: 7.1969e-04\n",
      "Epoch 3774/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 721.9355 - recon_loss: 3.5676e-04 - KL loss: 33.1465 - beta: 7.1969e-04 - val_val_loss: 732.9366 - val_val_recon_loss: 3.6240e-04 - val_val_KL loss: 33.2481 - val_beta: 7.1969e-04\n",
      "Epoch 3775/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 729.1888 - recon_loss: 3.6043e-04 - KL loss: 33.2975 - beta: 7.1969e-04 - val_val_loss: 730.9398 - val_val_recon_loss: 3.6136e-04 - val_val_KL loss: 33.2588 - val_beta: 7.1969e-04\n",
      "Epoch 3776/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 718.7610 - recon_loss: 3.5505e-04 - KL loss: 33.2597 - beta: 7.1969e-04 - val_val_loss: 731.3557 - val_val_recon_loss: 3.6158e-04 - val_val_KL loss: 33.2607 - val_beta: 7.1969e-04\n",
      "Epoch 3777/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 721.7224 - recon_loss: 3.5662e-04 - KL loss: 33.1943 - beta: 7.1969e-04 - val_val_loss: 730.0623 - val_val_recon_loss: 3.6096e-04 - val_val_KL loss: 33.1489 - val_beta: 7.1969e-04\n",
      "Epoch 3778/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 715.3465 - recon_loss: 3.5335e-04 - KL loss: 33.1313 - beta: 7.1969e-04 - val_val_loss: 726.8011 - val_val_recon_loss: 3.5932e-04 - val_val_KL loss: 33.0640 - val_beta: 7.1969e-04\n",
      "Epoch 3779/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 720.6362 - recon_loss: 3.5608e-04 - KL loss: 33.1519 - beta: 7.1969e-04 - val_val_loss: 728.4952 - val_val_recon_loss: 3.6018e-04 - val_val_KL loss: 33.1029 - val_beta: 7.1969e-04\n",
      "Epoch 3780/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 715.1060 - recon_loss: 3.5320e-04 - KL loss: 33.1799 - beta: 7.1969e-04 - val_val_loss: 730.6178 - val_val_recon_loss: 3.6116e-04 - val_val_KL loss: 33.3287 - val_beta: 7.1969e-04\n",
      "Epoch 3781/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 720.3392 - recon_loss: 3.5589e-04 - KL loss: 33.2150 - beta: 7.1969e-04 - val_val_loss: 728.6431 - val_val_recon_loss: 3.6028e-04 - val_val_KL loss: 33.0490 - val_beta: 7.1969e-04\n",
      "Epoch 3782/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 719.9163 - recon_loss: 3.5574e-04 - KL loss: 33.0937 - beta: 7.1969e-04 - val_val_loss: 728.1019 - val_val_recon_loss: 3.5994e-04 - val_val_KL loss: 33.1609 - val_beta: 7.1969e-04\n",
      "Epoch 3783/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 716.7053 - recon_loss: 3.5397e-04 - KL loss: 33.2998 - beta: 7.1969e-04\n",
      "Epoch 03783: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 716.7041 - recon_loss: 3.5397e-04 - KL loss: 33.2997 - beta: 7.1969e-04 - val_val_loss: 727.3652 - val_val_recon_loss: 3.5960e-04 - val_val_KL loss: 33.0882 - val_beta: 7.1969e-04\n",
      "Epoch 3784/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 714.3475 - recon_loss: 3.5282e-04 - KL loss: 33.1665 - beta: 7.1969e-04 - val_val_loss: 725.3968 - val_val_recon_loss: 3.5856e-04 - val_val_KL loss: 33.1249 - val_beta: 7.1969e-04\n",
      "Epoch 3785/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 718.7979 - recon_loss: 3.5512e-04 - KL loss: 33.1644 - beta: 7.1969e-04 - val_val_loss: 724.3145 - val_val_recon_loss: 3.5803e-04 - val_val_KL loss: 33.0650 - val_beta: 7.1969e-04\n",
      "Epoch 3786/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 714.4288 - recon_loss: 3.5286e-04 - KL loss: 33.1687 - beta: 7.1969e-04 - val_val_loss: 724.4500 - val_val_recon_loss: 3.5808e-04 - val_val_KL loss: 33.1153 - val_beta: 7.1969e-04\n",
      "Epoch 3787/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 707.4767 - recon_loss: 3.4922e-04 - KL loss: 33.2348 - beta: 7.1969e-04 - val_val_loss: 724.0590 - val_val_recon_loss: 3.5784e-04 - val_val_KL loss: 33.1693 - val_beta: 7.1969e-04\n",
      "Epoch 3788/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 712.7117 - recon_loss: 3.5191e-04 - KL loss: 33.2780 - beta: 7.1969e-04 - val_val_loss: 725.3960 - val_val_recon_loss: 3.5850e-04 - val_val_KL loss: 33.2377 - val_beta: 7.1969e-04\n",
      "Epoch 3789/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 718.2359 - recon_loss: 3.5476e-04 - KL loss: 33.3092 - beta: 7.1969e-04 - val_val_loss: 725.0622 - val_val_recon_loss: 3.5831e-04 - val_val_KL loss: 33.2728 - val_beta: 7.1969e-04\n",
      "Epoch 3790/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 712.4593 - recon_loss: 3.5173e-04 - KL loss: 33.3819 - beta: 7.1969e-04 - val_val_loss: 726.9959 - val_val_recon_loss: 3.5931e-04 - val_val_KL loss: 33.2731 - val_beta: 7.1969e-04\n",
      "Epoch 3791/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 709.7913 - recon_loss: 3.5035e-04 - KL loss: 33.3705 - beta: 7.1969e-04 - val_val_loss: 725.7377 - val_val_recon_loss: 3.5864e-04 - val_val_KL loss: 33.3115 - val_beta: 7.1969e-04\n",
      "Epoch 3792/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 711.1307 - recon_loss: 3.5106e-04 - KL loss: 33.3319 - beta: 7.1969e-04\n",
      "Epoch 03792: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 711.1342 - recon_loss: 3.5107e-04 - KL loss: 33.3319 - beta: 7.1969e-04 - val_val_loss: 726.3954 - val_val_recon_loss: 3.5898e-04 - val_val_KL loss: 33.3042 - val_beta: 7.1969e-04\n",
      "Epoch 3793/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 713.2019 - recon_loss: 3.5213e-04 - KL loss: 33.3478 - beta: 7.1969e-04 - val_val_loss: 723.1409 - val_val_recon_loss: 3.5729e-04 - val_val_KL loss: 33.3134 - val_beta: 7.1969e-04\n",
      "Epoch 3794/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 710.8542 - recon_loss: 3.5088e-04 - KL loss: 33.4037 - beta: 7.1969e-04 - val_val_loss: 724.9453 - val_val_recon_loss: 3.5822e-04 - val_val_KL loss: 33.3222 - val_beta: 7.1969e-04\n",
      "Epoch 3795/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 714.0240 - recon_loss: 3.5258e-04 - KL loss: 33.2943 - beta: 7.1969e-04 - val_val_loss: 725.2606 - val_val_recon_loss: 3.5841e-04 - val_val_KL loss: 33.2717 - val_beta: 7.1969e-04\n",
      "Epoch 3796/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 711.6771 - recon_loss: 3.5136e-04 - KL loss: 33.3073 - beta: 7.1969e-04 - val_val_loss: 724.5005 - val_val_recon_loss: 3.5801e-04 - val_val_KL loss: 33.2986 - val_beta: 7.1969e-04\n",
      "Epoch 3797/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 709.5682 - recon_loss: 3.5025e-04 - KL loss: 33.3377 - beta: 7.1969e-04 - val_val_loss: 724.7199 - val_val_recon_loss: 3.5811e-04 - val_val_KL loss: 33.3199 - val_beta: 7.1969e-04\n",
      "Epoch 3798/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 711.1572 - recon_loss: 3.5111e-04 - KL loss: 33.2781 - beta: 7.1969e-04\n",
      "Epoch 03798: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 711.1561 - recon_loss: 3.5111e-04 - KL loss: 33.2781 - beta: 7.1969e-04 - val_val_loss: 724.1309 - val_val_recon_loss: 3.5782e-04 - val_val_KL loss: 33.2920 - val_beta: 7.1969e-04\n",
      "Epoch 3799/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 720.6605 - recon_loss: 3.5599e-04 - KL loss: 33.3427 - beta: 7.1969e-04 - val_val_loss: 723.4920 - val_val_recon_loss: 3.5749e-04 - val_val_KL loss: 33.2844 - val_beta: 7.1969e-04\n",
      "Epoch 3800/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 709.9339 - recon_loss: 3.5043e-04 - KL loss: 33.3587 - beta: 7.1969e-04 - val_val_loss: 724.5520 - val_val_recon_loss: 3.5803e-04 - val_val_KL loss: 33.2980 - val_beta: 7.1969e-04\n",
      "Epoch 3801/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 710.9394 - recon_loss: 3.5099e-04 - KL loss: 33.2780 - beta: 7.1969e-04 - val_val_loss: 724.0447 - val_val_recon_loss: 3.5777e-04 - val_val_KL loss: 33.3072 - val_beta: 7.1969e-04\n",
      "Epoch 3802/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 712.3801 - recon_loss: 3.5170e-04 - KL loss: 33.3627 - beta: 7.1969e-04 - val_val_loss: 724.7810 - val_val_recon_loss: 3.5816e-04 - val_val_KL loss: 33.2887 - val_beta: 7.1969e-04\n",
      "Epoch 3803/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 702.9329 - recon_loss: 3.4689e-04 - KL loss: 33.1889 - beta: 7.1969e-04\n",
      "Epoch 03803: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 702.9375 - recon_loss: 3.4689e-04 - KL loss: 33.1889 - beta: 7.1969e-04 - val_val_loss: 724.5074 - val_val_recon_loss: 3.5801e-04 - val_val_KL loss: 33.3044 - val_beta: 7.1969e-04\n",
      "Epoch 3803/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2075.4177 - recon_loss: 3.9357e-04 - KL loss: 36.9548 - beta: 4.3940e-04 - val_val_loss: 2046.7961 - val_val_recon_loss: 3.8778e-04 - val_val_KL loss: 38.2825 - val_beta: 4.3940e-04\n",
      "Epoch 3804/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2083.4217 - recon_loss: 3.9454e-04 - KL loss: 39.9051 - beta: 4.3940e-04 - val_val_loss: 2004.8981 - val_val_recon_loss: 3.7963e-04 - val_val_KL loss: 38.6376 - val_beta: 4.3940e-04\n",
      "Epoch 3805/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1993.8098 - recon_loss: 3.7734e-04 - KL loss: 39.3966 - beta: 4.3940e-04 - val_val_loss: 1972.5205 - val_val_recon_loss: 3.7331e-04 - val_val_KL loss: 38.9644 - val_beta: 4.3940e-04\n",
      "Epoch 3806/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1954.6950 - recon_loss: 3.6984e-04 - KL loss: 39.0962 - beta: 4.3940e-04 - val_val_loss: 1970.7699 - val_val_recon_loss: 3.7296e-04 - val_val_KL loss: 39.0566 - val_beta: 4.3940e-04\n",
      "Epoch 3807/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1960.0880 - recon_loss: 3.7096e-04 - KL loss: 38.6862 - beta: 4.3940e-04 - val_val_loss: 1990.4681 - val_val_recon_loss: 3.7663e-04 - val_val_KL loss: 39.7158 - val_beta: 4.3940e-04\n",
      "Epoch 3808/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1947.0114 - recon_loss: 3.6837e-04 - KL loss: 39.0539 - beta: 4.3940e-04 - val_val_loss: 1950.6713 - val_val_recon_loss: 3.6914e-04 - val_val_KL loss: 38.7260 - val_beta: 4.3940e-04\n",
      "Epoch 3809/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1969.8364 - recon_loss: 3.7277e-04 - KL loss: 39.0727 - beta: 4.3940e-04 - val_val_loss: 2170.9277 - val_val_recon_loss: 4.1115e-04 - val_val_KL loss: 41.3705 - val_beta: 4.3940e-04\n",
      "Epoch 3810/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2038.4736 - recon_loss: 3.8579e-04 - KL loss: 40.3038 - beta: 4.3940e-04 - val_val_loss: 1963.0989 - val_val_recon_loss: 3.7141e-04 - val_val_KL loss: 39.3751 - val_beta: 4.3940e-04\n",
      "Epoch 3811/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1935.4665 - recon_loss: 3.6603e-04 - KL loss: 39.6181 - beta: 4.3940e-04 - val_val_loss: 1937.6385 - val_val_recon_loss: 3.6647e-04 - val_val_KL loss: 39.5120 - val_beta: 4.3940e-04\n",
      "Epoch 3812/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1909.7614 - recon_loss: 3.6115e-04 - KL loss: 39.2048 - beta: 4.3940e-04 - val_val_loss: 1931.1765 - val_val_recon_loss: 3.6523e-04 - val_val_KL loss: 39.4765 - val_beta: 4.3940e-04\n",
      "Epoch 3813/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1910.8149 - recon_loss: 3.6134e-04 - KL loss: 39.2798 - beta: 4.3940e-04 - val_val_loss: 1905.3875 - val_val_recon_loss: 3.6032e-04 - val_val_KL loss: 39.1016 - val_beta: 4.3940e-04\n",
      "Epoch 3814/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1962.7465 - recon_loss: 3.7126e-04 - KL loss: 39.7902 - beta: 4.3940e-04 - val_val_loss: 2004.7332 - val_val_recon_loss: 3.7942e-04 - val_val_KL loss: 39.5330 - val_beta: 4.3940e-04\n",
      "Epoch 3815/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1990.8539 - recon_loss: 3.7656e-04 - KL loss: 40.4457 - beta: 4.3940e-04 - val_val_loss: 1954.6039 - val_val_recon_loss: 3.6949e-04 - val_val_KL loss: 40.8295 - val_beta: 4.3940e-04\n",
      "Epoch 3816/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1959.5036 - recon_loss: 3.7044e-04 - KL loss: 40.8053 - beta: 4.3940e-04 - val_val_loss: 2087.4817 - val_val_recon_loss: 3.9520e-04 - val_val_KL loss: 40.5580 - val_beta: 4.3940e-04\n",
      "Epoch 3817/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1957.8419 - recon_loss: 3.7016e-04 - KL loss: 40.5949 - beta: 4.3940e-04 - val_val_loss: 1927.6318 - val_val_recon_loss: 3.6431e-04 - val_val_KL loss: 40.6913 - val_beta: 4.3940e-04\n",
      "Epoch 3818/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1926.2494 - recon_loss: 3.6407e-04 - KL loss: 40.5733 - beta: 4.3940e-04\n",
      "Epoch 03818: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1926.2635 - recon_loss: 3.6407e-04 - KL loss: 40.5732 - beta: 4.3940e-04 - val_val_loss: 1953.9269 - val_val_recon_loss: 3.6954e-04 - val_val_KL loss: 39.8938 - val_beta: 4.3940e-04\n",
      "Epoch 3819/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1885.7773 - recon_loss: 3.5627e-04 - KL loss: 40.4796 - beta: 4.3940e-04 - val_val_loss: 1872.4237 - val_val_recon_loss: 3.5370e-04 - val_val_KL loss: 40.4527 - val_beta: 4.3940e-04\n",
      "Epoch 3820/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1830.1596 - recon_loss: 3.4555e-04 - KL loss: 40.3714 - beta: 4.3940e-04 - val_val_loss: 1857.3306 - val_val_recon_loss: 3.5083e-04 - val_val_KL loss: 40.1984 - val_beta: 4.3940e-04\n",
      "Epoch 3821/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1841.7856 - recon_loss: 3.4783e-04 - KL loss: 40.2282 - beta: 4.3940e-04 - val_val_loss: 1844.3801 - val_val_recon_loss: 3.4833e-04 - val_val_KL loss: 40.2229 - val_beta: 4.3940e-04\n",
      "Epoch 3822/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1840.7107 - recon_loss: 3.4760e-04 - KL loss: 40.3469 - beta: 4.3940e-04 - val_val_loss: 1844.7197 - val_val_recon_loss: 3.4845e-04 - val_val_KL loss: 39.9269 - val_beta: 4.3940e-04\n",
      "Epoch 3823/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1832.2130 - recon_loss: 3.4596e-04 - KL loss: 40.2971 - beta: 4.3940e-04 - val_val_loss: 1836.8398 - val_val_recon_loss: 3.4682e-04 - val_val_KL loss: 40.4927 - val_beta: 4.3940e-04\n",
      "Epoch 3824/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1833.3902 - recon_loss: 3.4616e-04 - KL loss: 40.4719 - beta: 4.3940e-04 - val_val_loss: 1837.2303 - val_val_recon_loss: 3.4694e-04 - val_val_KL loss: 40.2460 - val_beta: 4.3940e-04\n",
      "Epoch 3825/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1831.0432 - recon_loss: 3.4567e-04 - KL loss: 40.6672 - beta: 4.3940e-04 - val_val_loss: 1848.7657 - val_val_recon_loss: 3.4903e-04 - val_val_KL loss: 40.9690 - val_beta: 4.3940e-04\n",
      "Epoch 3826/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 1811.9572 - recon_loss: 3.4201e-04 - KL loss: 40.5307 - beta: 4.3940e-04 - val_val_loss: 1841.5553 - val_val_recon_loss: 3.4768e-04 - val_val_KL loss: 40.7770 - val_beta: 4.3940e-04\n",
      "Epoch 3827/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1835.6690 - recon_loss: 3.4651e-04 - KL loss: 40.9143 - beta: 4.3940e-04 - val_val_loss: 1854.3085 - val_val_recon_loss: 3.5011e-04 - val_val_KL loss: 40.9033 - val_beta: 4.3940e-04\n",
      "Epoch 3828/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 1832.0073 - recon_loss: 3.4579e-04 - KL loss: 41.0020 - beta: 4.3940e-04\n",
      "Epoch 03828: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1832.0055 - recon_loss: 3.4579e-04 - KL loss: 41.0019 - beta: 4.3940e-04 - val_val_loss: 1850.9347 - val_val_recon_loss: 3.4945e-04 - val_val_KL loss: 40.9762 - val_beta: 4.3940e-04\n",
      "Epoch 3829/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1814.5579 - recon_loss: 3.4244e-04 - KL loss: 40.8834 - beta: 4.3940e-04 - val_val_loss: 1831.7223 - val_val_recon_loss: 3.4576e-04 - val_val_KL loss: 40.8699 - val_beta: 4.3940e-04\n",
      "Epoch 3830/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1808.8221 - recon_loss: 3.4131e-04 - KL loss: 41.0029 - beta: 4.3940e-04 - val_val_loss: 1829.5024 - val_val_recon_loss: 3.4535e-04 - val_val_KL loss: 40.7509 - val_beta: 4.3940e-04\n",
      "Epoch 3831/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1826.6188 - recon_loss: 3.4477e-04 - KL loss: 40.8851 - beta: 4.3940e-04 - val_val_loss: 1825.9659 - val_val_recon_loss: 3.4467e-04 - val_val_KL loss: 40.7391 - val_beta: 4.3940e-04\n",
      "Epoch 3832/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1785.9029 - recon_loss: 3.3696e-04 - KL loss: 40.6426 - beta: 4.3940e-04 - val_val_loss: 1818.4425 - val_val_recon_loss: 3.4323e-04 - val_val_KL loss: 40.6690 - val_beta: 4.3940e-04\n",
      "Epoch 3833/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1780.3156 - recon_loss: 3.3584e-04 - KL loss: 40.8351 - beta: 4.3940e-04 - val_val_loss: 1822.7770 - val_val_recon_loss: 3.4406e-04 - val_val_KL loss: 40.7106 - val_beta: 4.3940e-04\n",
      "Epoch 3834/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1800.1235 - recon_loss: 3.3966e-04 - KL loss: 40.8794 - beta: 4.3940e-04 - val_val_loss: 1822.1444 - val_val_recon_loss: 3.4396e-04 - val_val_KL loss: 40.6139 - val_beta: 4.3940e-04\n",
      "Epoch 3835/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1788.5989 - recon_loss: 3.3745e-04 - KL loss: 40.7886 - beta: 4.3940e-04 - val_val_loss: 1823.8046 - val_val_recon_loss: 3.4425e-04 - val_val_KL loss: 40.7880 - val_beta: 4.3940e-04\n",
      "Epoch 3836/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1790.0744 - recon_loss: 3.3774e-04 - KL loss: 40.7363 - beta: 4.3940e-04 - val_val_loss: 1817.7150 - val_val_recon_loss: 3.4310e-04 - val_val_KL loss: 40.6410 - val_beta: 4.3940e-04\n",
      "Epoch 3837/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 1785.4629 - recon_loss: 3.3682e-04 - KL loss: 40.9059 - beta: 4.3940e-04 - val_val_loss: 1834.7053 - val_val_recon_loss: 3.4628e-04 - val_val_KL loss: 41.1447 - val_beta: 4.3940e-04\n",
      "Epoch 3838/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1815.2109 - recon_loss: 3.4250e-04 - KL loss: 41.2481 - beta: 4.3940e-04 - val_val_loss: 1831.3894 - val_val_recon_loss: 3.4566e-04 - val_val_KL loss: 41.0528 - val_beta: 4.3940e-04\n",
      "Epoch 3839/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1826.6573 - recon_loss: 3.4471e-04 - KL loss: 41.2175 - beta: 4.3940e-04 - val_val_loss: 1813.1216 - val_val_recon_loss: 3.4219e-04 - val_val_KL loss: 40.7645 - val_beta: 4.3940e-04\n",
      "Epoch 3840/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1798.5552 - recon_loss: 3.3935e-04 - KL loss: 40.8866 - beta: 4.3940e-04 - val_val_loss: 1813.2701 - val_val_recon_loss: 3.4218e-04 - val_val_KL loss: 40.9704 - val_beta: 4.3940e-04\n",
      "Epoch 3841/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1786.8874 - recon_loss: 3.3712e-04 - KL loss: 40.7944 - beta: 4.3940e-04 - val_val_loss: 1811.1344 - val_val_recon_loss: 3.4180e-04 - val_val_KL loss: 40.7719 - val_beta: 4.3940e-04\n",
      "Epoch 3842/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1797.0174 - recon_loss: 3.3907e-04 - KL loss: 40.8174 - beta: 4.3940e-04 - val_val_loss: 1813.1388 - val_val_recon_loss: 3.4217e-04 - val_val_KL loss: 40.8687 - val_beta: 4.3940e-04\n",
      "Epoch 3843/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1786.5991 - recon_loss: 3.3704e-04 - KL loss: 40.9050 - beta: 4.3940e-04 - val_val_loss: 1816.5624 - val_val_recon_loss: 3.4281e-04 - val_val_KL loss: 40.9724 - val_beta: 4.3940e-04\n",
      "Epoch 3844/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1791.3156 - recon_loss: 3.3792e-04 - KL loss: 41.0687 - beta: 4.3940e-04 - val_val_loss: 1812.5663 - val_val_recon_loss: 3.4207e-04 - val_val_KL loss: 40.8322 - val_beta: 4.3940e-04\n",
      "Epoch 3845/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1784.9993 - recon_loss: 3.3675e-04 - KL loss: 40.7908 - beta: 4.3940e-04 - val_val_loss: 1806.5118 - val_val_recon_loss: 3.4088e-04 - val_val_KL loss: 40.9473 - val_beta: 4.3940e-04\n",
      "Epoch 3846/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1786.3843 - recon_loss: 3.3701e-04 - KL loss: 40.8551 - beta: 4.3940e-04 - val_val_loss: 1802.8707 - val_val_recon_loss: 3.4023e-04 - val_val_KL loss: 40.6699 - val_beta: 4.3940e-04\n",
      "Epoch 3847/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1778.3881 - recon_loss: 3.3552e-04 - KL loss: 40.5524 - beta: 4.3940e-04 - val_val_loss: 1800.0933 - val_val_recon_loss: 3.3969e-04 - val_val_KL loss: 40.6553 - val_beta: 4.3940e-04\n",
      "Epoch 3848/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1777.0157 - recon_loss: 3.3522e-04 - KL loss: 40.7287 - beta: 4.3940e-04 - val_val_loss: 1804.9539 - val_val_recon_loss: 3.4065e-04 - val_val_KL loss: 40.5920 - val_beta: 4.3940e-04\n",
      "Epoch 3849/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1784.6794 - recon_loss: 3.3672e-04 - KL loss: 40.6599 - beta: 4.3940e-04 - val_val_loss: 1802.9335 - val_val_recon_loss: 3.4023e-04 - val_val_KL loss: 40.7444 - val_beta: 4.3940e-04\n",
      "Epoch 3850/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1785.4934 - recon_loss: 3.3686e-04 - KL loss: 40.7424 - beta: 4.3940e-04 - val_val_loss: 1793.5178 - val_val_recon_loss: 3.3839e-04 - val_val_KL loss: 40.8529 - val_beta: 4.3940e-04\n",
      "Epoch 3851/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1792.1793 - recon_loss: 3.3815e-04 - KL loss: 40.7648 - beta: 4.3940e-04 - val_val_loss: 1796.3539 - val_val_recon_loss: 3.3899e-04 - val_val_KL loss: 40.5478 - val_beta: 4.3940e-04\n",
      "Epoch 3852/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1764.1688 - recon_loss: 3.3276e-04 - KL loss: 40.6246 - beta: 4.3940e-04 - val_val_loss: 1795.3584 - val_val_recon_loss: 3.3876e-04 - val_val_KL loss: 40.7653 - val_beta: 4.3940e-04\n",
      "Epoch 3853/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1783.4449 - recon_loss: 3.3642e-04 - KL loss: 40.9525 - beta: 4.3940e-04 - val_val_loss: 1807.7611 - val_val_recon_loss: 3.4112e-04 - val_val_KL loss: 40.9593 - val_beta: 4.3940e-04\n",
      "Epoch 3854/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1783.2927 - recon_loss: 3.3636e-04 - KL loss: 41.1293 - beta: 4.3940e-04 - val_val_loss: 1807.7114 - val_val_recon_loss: 3.4107e-04 - val_val_KL loss: 41.1255 - val_beta: 4.3940e-04\n",
      "Epoch 3855/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1787.8877 - recon_loss: 3.3726e-04 - KL loss: 41.0352 - beta: 4.3940e-04\n",
      "Epoch 03855: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1787.8863 - recon_loss: 3.3726e-04 - KL loss: 41.0353 - beta: 4.3940e-04 - val_val_loss: 1799.1472 - val_val_recon_loss: 3.3946e-04 - val_val_KL loss: 40.9444 - val_beta: 4.3940e-04\n",
      "Epoch 3856/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1795.6443 - recon_loss: 3.3875e-04 - KL loss: 41.0724 - beta: 4.3940e-04 - val_val_loss: 1793.8961 - val_val_recon_loss: 3.3844e-04 - val_val_KL loss: 40.9575 - val_beta: 4.3940e-04\n",
      "Epoch 3857/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1753.9829 - recon_loss: 3.3073e-04 - KL loss: 40.9908 - beta: 4.3940e-04 - val_val_loss: 1795.6282 - val_val_recon_loss: 3.3874e-04 - val_val_KL loss: 41.1418 - val_beta: 4.3940e-04\n",
      "Epoch 3858/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1770.9705 - recon_loss: 3.3395e-04 - KL loss: 41.2679 - beta: 4.3940e-04 - val_val_loss: 1795.0028 - val_val_recon_loss: 3.3863e-04 - val_val_KL loss: 41.0801 - val_beta: 4.3940e-04\n",
      "Epoch 3859/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1764.8484 - recon_loss: 3.3279e-04 - KL loss: 41.1676 - beta: 4.3940e-04 - val_val_loss: 1796.6000 - val_val_recon_loss: 3.3891e-04 - val_val_KL loss: 41.2012 - val_beta: 4.3940e-04\n",
      "Epoch 3860/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1775.3569 - recon_loss: 3.3479e-04 - KL loss: 41.3077 - beta: 4.3940e-04\n",
      "Epoch 03860: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1775.3576 - recon_loss: 3.3479e-04 - KL loss: 41.3077 - beta: 4.3940e-04 - val_val_loss: 1795.5688 - val_val_recon_loss: 3.3872e-04 - val_val_KL loss: 41.1559 - val_beta: 4.3940e-04\n",
      "Epoch 3860/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 5202.5782 - recon_loss: 3.7101e-04 - KL loss: 47.3970 - beta: 2.6827e-04 - val_val_loss: 5029.7695 - val_val_recon_loss: 3.5817e-04 - val_val_KL loss: 53.0051 - val_beta: 2.6827e-04\n",
      "Epoch 3861/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5061.4289 - recon_loss: 3.6055e-04 - KL loss: 51.5333 - beta: 2.6827e-04 - val_val_loss: 5132.0645 - val_val_recon_loss: 3.6556e-04 - val_val_KL loss: 52.5974 - val_beta: 2.6827e-04\n",
      "Epoch 3862/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5034.8612 - recon_loss: 3.5861e-04 - KL loss: 51.9858 - beta: 2.6827e-04 - val_val_loss: 5041.2202 - val_val_recon_loss: 3.5910e-04 - val_val_KL loss: 51.5857 - val_beta: 2.6827e-04\n",
      "Epoch 3863/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4951.9575 - recon_loss: 3.5264e-04 - KL loss: 52.0579 - beta: 2.6827e-04 - val_val_loss: 5013.9668 - val_val_recon_loss: 3.5715e-04 - val_val_KL loss: 51.3632 - val_beta: 2.6827e-04\n",
      "Epoch 3864/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5013.9948 - recon_loss: 3.5717e-04 - KL loss: 51.1845 - beta: 2.6827e-04 - val_val_loss: 5039.9736 - val_val_recon_loss: 3.5894e-04 - val_val_KL loss: 52.5239 - val_beta: 2.6827e-04\n",
      "Epoch 3865/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4929.1180 - recon_loss: 3.5098e-04 - KL loss: 52.2247 - beta: 2.6827e-04 - val_val_loss: 4962.0269 - val_val_recon_loss: 3.5336e-04 - val_val_KL loss: 52.0702 - val_beta: 2.6827e-04\n",
      "Epoch 3866/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4965.9190 - recon_loss: 3.5361e-04 - KL loss: 52.5317 - beta: 2.6827e-04 - val_val_loss: 4951.4658 - val_val_recon_loss: 3.5264e-04 - val_val_KL loss: 51.6150 - val_beta: 2.6827e-04\n",
      "Epoch 3867/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5038.7036 - recon_loss: 3.5879e-04 - KL loss: 53.3143 - beta: 2.6827e-04 - val_val_loss: 5078.8022 - val_val_recon_loss: 3.6156e-04 - val_val_KL loss: 54.9893 - val_beta: 2.6827e-04\n",
      "Epoch 3868/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4999.1084 - recon_loss: 3.5583e-04 - KL loss: 54.9253 - beta: 2.6827e-04 - val_val_loss: 4829.5000 - val_val_recon_loss: 3.4378e-04 - val_val_KL loss: 52.6524 - val_beta: 2.6827e-04\n",
      "Epoch 3869/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4932.1644 - recon_loss: 3.5108e-04 - KL loss: 53.9456 - beta: 2.6827e-04 - val_val_loss: 5547.5806 - val_val_recon_loss: 3.9487e-04 - val_val_KL loss: 60.8148 - val_beta: 2.6827e-04\n",
      "Epoch 3870/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5356.4868 - recon_loss: 3.8128e-04 - KL loss: 58.5788 - beta: 2.6827e-04 - val_val_loss: 5159.3374 - val_val_recon_loss: 3.6729e-04 - val_val_KL loss: 55.8736 - val_beta: 2.6827e-04\n",
      "Epoch 3871/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5099.9623 - recon_loss: 3.6298e-04 - KL loss: 56.4326 - beta: 2.6827e-04 - val_val_loss: 5019.4004 - val_val_recon_loss: 3.5731e-04 - val_val_KL loss: 54.5459 - val_beta: 2.6827e-04\n",
      "Epoch 3872/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 4928.9415 - recon_loss: 3.5079e-04 - KL loss: 54.7848 - beta: 2.6827e-04 - val_val_loss: 5002.2539 - val_val_recon_loss: 3.5589e-04 - val_val_KL loss: 57.2071 - val_beta: 2.6827e-04\n",
      "Epoch 3873/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4993.5086 - recon_loss: 3.5534e-04 - KL loss: 56.0945 - beta: 2.6827e-04\n",
      "Epoch 03873: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4993.4842 - recon_loss: 3.5534e-04 - KL loss: 56.0939 - beta: 2.6827e-04 - val_val_loss: 5185.8325 - val_val_recon_loss: 3.6938e-04 - val_val_KL loss: 53.3014 - val_beta: 2.6827e-04\n",
      "Epoch 3874/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4825.9325 - recon_loss: 3.4344e-04 - KL loss: 53.9078 - beta: 2.6827e-04 - val_val_loss: 4778.1997 - val_val_recon_loss: 3.4002e-04 - val_val_KL loss: 53.5717 - val_beta: 2.6827e-04\n",
      "Epoch 3875/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 4709.5585 - recon_loss: 3.3507e-04 - KL loss: 53.7783 - beta: 2.6827e-04 - val_val_loss: 4719.6260 - val_val_recon_loss: 3.3573e-04 - val_val_KL loss: 54.7238 - val_beta: 2.6827e-04\n",
      "Epoch 3876/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4677.8048 - recon_loss: 3.3274e-04 - KL loss: 54.3977 - beta: 2.6827e-04 - val_val_loss: 4758.6538 - val_val_recon_loss: 3.3848e-04 - val_val_KL loss: 55.4974 - val_beta: 2.6827e-04\n",
      "Epoch 3877/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4689.2741 - recon_loss: 3.3353e-04 - KL loss: 54.8255 - beta: 2.6827e-04 - val_val_loss: 4769.0293 - val_val_recon_loss: 3.3929e-04 - val_val_KL loss: 54.6661 - val_beta: 2.6827e-04\n",
      "Epoch 3878/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 4825.8292 - recon_loss: 3.4332e-04 - KL loss: 55.3524 - beta: 2.6827e-04 - val_val_loss: 4898.6001 - val_val_recon_loss: 3.4853e-04 - val_val_KL loss: 55.8374 - val_beta: 2.6827e-04\n",
      "Epoch 3879/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4877.6257 - recon_loss: 3.4700e-04 - KL loss: 56.0246 - beta: 2.6827e-04 - val_val_loss: 4764.6367 - val_val_recon_loss: 3.3897e-04 - val_val_KL loss: 54.6764 - val_beta: 2.6827e-04\n",
      "Epoch 3880/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4695.3630 - recon_loss: 3.3400e-04 - KL loss: 54.4989 - beta: 2.6827e-04 - val_val_loss: 4712.1787 - val_val_recon_loss: 3.3522e-04 - val_val_KL loss: 54.3730 - val_beta: 2.6827e-04\n",
      "Epoch 3881/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4660.7700 - recon_loss: 3.3149e-04 - KL loss: 54.6967 - beta: 2.6827e-04 - val_val_loss: 4738.0620 - val_val_recon_loss: 3.3705e-04 - val_val_KL loss: 54.8115 - val_beta: 2.6827e-04\n",
      "Epoch 3882/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4676.7509 - recon_loss: 3.3262e-04 - KL loss: 54.9425 - beta: 2.6827e-04 - val_val_loss: 4730.1699 - val_val_recon_loss: 3.3645e-04 - val_val_KL loss: 55.1672 - val_beta: 2.6827e-04\n",
      "Epoch 3883/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4635.4890 - recon_loss: 3.2964e-04 - KL loss: 55.1323 - beta: 2.6827e-04 - val_val_loss: 4657.8813 - val_val_recon_loss: 3.3128e-04 - val_val_KL loss: 54.8250 - val_beta: 2.6827e-04\n",
      "Epoch 3884/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4588.9262 - recon_loss: 3.2635e-04 - KL loss: 54.3483 - beta: 2.6827e-04 - val_val_loss: 4653.7871 - val_val_recon_loss: 3.3100e-04 - val_val_KL loss: 54.6018 - val_beta: 2.6827e-04\n",
      "Epoch 3885/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4705.3954 - recon_loss: 3.3466e-04 - KL loss: 55.2629 - beta: 2.6827e-04 - val_val_loss: 4699.2827 - val_val_recon_loss: 3.3419e-04 - val_val_KL loss: 55.6797 - val_beta: 2.6827e-04\n",
      "Epoch 3886/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4687.9967 - recon_loss: 3.3337e-04 - KL loss: 55.8566 - beta: 2.6827e-04 - val_val_loss: 4717.8364 - val_val_recon_loss: 3.3560e-04 - val_val_KL loss: 54.6650 - val_beta: 2.6827e-04\n",
      "Epoch 3887/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4604.8329 - recon_loss: 3.2742e-04 - KL loss: 55.2849 - beta: 2.6827e-04 - val_val_loss: 4666.8184 - val_val_recon_loss: 3.3191e-04 - val_val_KL loss: 54.9979 - val_beta: 2.6827e-04\n",
      "Epoch 3888/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4579.1522 - recon_loss: 3.2559e-04 - KL loss: 55.1322 - beta: 2.6827e-04 - val_val_loss: 4669.4854 - val_val_recon_loss: 3.3213e-04 - val_val_KL loss: 54.4982 - val_beta: 2.6827e-04\n",
      "Epoch 3889/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 4604.7454 - recon_loss: 3.2745e-04 - KL loss: 54.7976 - beta: 2.6827e-04 - val_val_loss: 4648.3823 - val_val_recon_loss: 3.3063e-04 - val_val_KL loss: 54.2843 - val_beta: 2.6827e-04\n",
      "Epoch 3890/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4590.9061 - recon_loss: 3.2643e-04 - KL loss: 55.1749 - beta: 2.6827e-04 - val_val_loss: 4676.9004 - val_val_recon_loss: 3.3264e-04 - val_val_KL loss: 54.9274 - val_beta: 2.6827e-04\n",
      "Epoch 3891/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4605.7398 - recon_loss: 3.2752e-04 - KL loss: 54.9078 - beta: 2.6827e-04 - val_val_loss: 4653.0293 - val_val_recon_loss: 3.3085e-04 - val_val_KL loss: 55.9513 - val_beta: 2.6827e-04\n",
      "Epoch 3892/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4592.5970 - recon_loss: 3.2655e-04 - KL loss: 55.2466 - beta: 2.6827e-04 - val_val_loss: 4632.6748 - val_val_recon_loss: 3.2943e-04 - val_val_KL loss: 55.1989 - val_beta: 2.6827e-04\n",
      "Epoch 3893/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4544.0083 - recon_loss: 3.2304e-04 - KL loss: 55.3764 - beta: 2.6827e-04 - val_val_loss: 4608.8765 - val_val_recon_loss: 3.2775e-04 - val_val_KL loss: 54.8371 - val_beta: 2.6827e-04\n",
      "Epoch 3894/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4613.9264 - recon_loss: 3.2809e-04 - KL loss: 55.1583 - beta: 2.6827e-04 - val_val_loss: 4749.3760 - val_val_recon_loss: 3.3780e-04 - val_val_KL loss: 55.6739 - val_beta: 2.6827e-04\n",
      "Epoch 3895/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4622.3889 - recon_loss: 3.2867e-04 - KL loss: 55.5857 - beta: 2.6827e-04 - val_val_loss: 4669.8516 - val_val_recon_loss: 3.3214e-04 - val_val_KL loss: 54.8027 - val_beta: 2.6827e-04\n",
      "Epoch 3896/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4567.3539 - recon_loss: 3.2472e-04 - KL loss: 55.3570 - beta: 2.6827e-04 - val_val_loss: 4616.2661 - val_val_recon_loss: 3.2823e-04 - val_val_KL loss: 55.4997 - val_beta: 2.6827e-04\n",
      "Epoch 3897/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4525.5938 - recon_loss: 3.2168e-04 - KL loss: 55.8786 - beta: 2.6827e-04 - val_val_loss: 4637.9160 - val_val_recon_loss: 3.2984e-04 - val_val_KL loss: 54.7912 - val_beta: 2.6827e-04\n",
      "Epoch 3898/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4495.2091 - recon_loss: 3.1953e-04 - KL loss: 55.4046 - beta: 2.6827e-04 - val_val_loss: 4582.6045 - val_val_recon_loss: 3.2578e-04 - val_val_KL loss: 55.9430 - val_beta: 2.6827e-04\n",
      "Epoch 3899/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4579.4937 - recon_loss: 3.2558e-04 - KL loss: 55.5797 - beta: 2.6827e-04 - val_val_loss: 4565.4121 - val_val_recon_loss: 3.2458e-04 - val_val_KL loss: 55.4123 - val_beta: 2.6827e-04\n",
      "Epoch 3900/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4525.7759 - recon_loss: 3.2171e-04 - KL loss: 55.5813 - beta: 2.6827e-04 - val_val_loss: 4574.8267 - val_val_recon_loss: 3.2516e-04 - val_val_KL loss: 56.7644 - val_beta: 2.6827e-04\n",
      "Epoch 3901/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4537.8585 - recon_loss: 3.2256e-04 - KL loss: 55.9081 - beta: 2.6827e-04 - val_val_loss: 4574.2036 - val_val_recon_loss: 3.2517e-04 - val_val_KL loss: 56.0199 - val_beta: 2.6827e-04\n",
      "Epoch 3902/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4500.6902 - recon_loss: 3.1992e-04 - KL loss: 55.4533 - beta: 2.6827e-04 - val_val_loss: 4580.3750 - val_val_recon_loss: 3.2569e-04 - val_val_KL loss: 54.8597 - val_beta: 2.6827e-04\n",
      "Epoch 3903/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4522.6898 - recon_loss: 3.2152e-04 - KL loss: 55.1396 - beta: 2.6827e-04 - val_val_loss: 4547.5103 - val_val_recon_loss: 3.2331e-04 - val_val_KL loss: 55.1274 - val_beta: 2.6827e-04\n",
      "Epoch 3904/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4474.1934 - recon_loss: 3.1802e-04 - KL loss: 55.2907 - beta: 2.6827e-04 - val_val_loss: 4603.5474 - val_val_recon_loss: 3.2737e-04 - val_val_KL loss: 54.7354 - val_beta: 2.6827e-04\n",
      "Epoch 3905/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4508.3300 - recon_loss: 3.2051e-04 - KL loss: 54.8969 - beta: 2.6827e-04 - val_val_loss: 4543.2251 - val_val_recon_loss: 3.2293e-04 - val_val_KL loss: 56.1395 - val_beta: 2.6827e-04\n",
      "Epoch 3906/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4487.7872 - recon_loss: 3.1894e-04 - KL loss: 56.0917 - beta: 2.6827e-04 - val_val_loss: 4533.9731 - val_val_recon_loss: 3.2227e-04 - val_val_KL loss: 56.0035 - val_beta: 2.6827e-04\n",
      "Epoch 3907/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4497.4121 - recon_loss: 3.1962e-04 - KL loss: 56.3285 - beta: 2.6827e-04 - val_val_loss: 4608.9536 - val_val_recon_loss: 3.2754e-04 - val_val_KL loss: 57.7769 - val_beta: 2.6827e-04\n",
      "Epoch 3908/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4508.9035 - recon_loss: 3.2039e-04 - KL loss: 57.1353 - beta: 2.6827e-04 - val_val_loss: 4521.7271 - val_val_recon_loss: 3.2139e-04 - val_val_KL loss: 56.0065 - val_beta: 2.6827e-04\n",
      "Epoch 3909/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4435.7329 - recon_loss: 3.1521e-04 - KL loss: 55.9221 - beta: 2.6827e-04 - val_val_loss: 4529.4785 - val_val_recon_loss: 3.2195e-04 - val_val_KL loss: 56.0636 - val_beta: 2.6827e-04\n",
      "Epoch 3910/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4489.9590 - recon_loss: 3.1912e-04 - KL loss: 55.7877 - beta: 2.6827e-04 - val_val_loss: 4505.9609 - val_val_recon_loss: 3.2028e-04 - val_val_KL loss: 55.7354 - val_beta: 2.6827e-04\n",
      "Epoch 3911/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4435.4936 - recon_loss: 3.1518e-04 - KL loss: 56.1117 - beta: 2.6827e-04 - val_val_loss: 4505.0713 - val_val_recon_loss: 3.2015e-04 - val_val_KL loss: 56.6186 - val_beta: 2.6827e-04\n",
      "Epoch 3912/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4441.2710 - recon_loss: 3.1555e-04 - KL loss: 56.7350 - beta: 2.6827e-04 - val_val_loss: 4560.4243 - val_val_recon_loss: 3.2413e-04 - val_val_KL loss: 56.6414 - val_beta: 2.6827e-04\n",
      "Epoch 3913/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4534.1823 - recon_loss: 3.2221e-04 - KL loss: 57.1135 - beta: 2.6827e-04 - val_val_loss: 4594.3237 - val_val_recon_loss: 3.2644e-04 - val_val_KL loss: 58.4427 - val_beta: 2.6827e-04\n",
      "Epoch 3914/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4508.9311 - recon_loss: 3.2033e-04 - KL loss: 57.9644 - beta: 2.6827e-04 - val_val_loss: 4528.0439 - val_val_recon_loss: 3.2179e-04 - val_val_KL loss: 56.7963 - val_beta: 2.6827e-04\n",
      "Epoch 3915/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4451.6397 - recon_loss: 3.1626e-04 - KL loss: 57.1668 - beta: 2.6827e-04 - val_val_loss: 4569.8027 - val_val_recon_loss: 3.2482e-04 - val_val_KL loss: 56.4225 - val_beta: 2.6827e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3916/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4508.4755 - recon_loss: 3.2037e-04 - KL loss: 56.9530 - beta: 2.6827e-04\n",
      "Epoch 03916: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4508.4614 - recon_loss: 3.2037e-04 - KL loss: 56.9536 - beta: 2.6827e-04 - val_val_loss: 4636.9932 - val_val_recon_loss: 3.2955e-04 - val_val_KL loss: 57.9397 - val_beta: 2.6827e-04\n",
      "Epoch 3917/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4504.0267 - recon_loss: 3.1997e-04 - KL loss: 58.0904 - beta: 2.6827e-04 - val_val_loss: 4534.7139 - val_val_recon_loss: 3.2223e-04 - val_val_KL loss: 57.3796 - val_beta: 2.6827e-04\n",
      "Epoch 3918/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4471.4365 - recon_loss: 3.1766e-04 - KL loss: 57.6089 - beta: 2.6827e-04 - val_val_loss: 4536.2520 - val_val_recon_loss: 3.2228e-04 - val_val_KL loss: 58.1983 - val_beta: 2.6827e-04\n",
      "Epoch 3919/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 4438.2705 - recon_loss: 3.1524e-04 - KL loss: 58.0377 - beta: 2.6827e-04 - val_val_loss: 4515.8755 - val_val_recon_loss: 3.2083e-04 - val_val_KL loss: 57.8937 - val_beta: 2.6827e-04\n",
      "Epoch 3920/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4454.8824 - recon_loss: 3.1646e-04 - KL loss: 57.6386 - beta: 2.6827e-04 - val_val_loss: 4513.3013 - val_val_recon_loss: 3.2067e-04 - val_val_KL loss: 57.6659 - val_beta: 2.6827e-04\n",
      "Epoch 3921/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4497.8269 - recon_loss: 3.1954e-04 - KL loss: 57.8161 - beta: 2.6827e-04\n",
      "Epoch 03921: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4497.8062 - recon_loss: 3.1954e-04 - KL loss: 57.8163 - beta: 2.6827e-04 - val_val_loss: 4512.6992 - val_val_recon_loss: 3.2058e-04 - val_val_KL loss: 58.2720 - val_beta: 2.6827e-04\n",
      "Epoch 3921/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 13410.8213 - recon_loss: 3.5789e-04 - KL loss: 69.9844 - beta: 1.6379e-04 - val_val_loss: 13263.7305 - val_val_recon_loss: 3.5365e-04 - val_val_KL loss: 81.1264 - val_beta: 1.6379e-04\n",
      "Epoch 3922/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 13095.3044 - recon_loss: 3.4911e-04 - KL loss: 82.0800 - beta: 1.6379e-04 - val_val_loss: 13052.6963 - val_val_recon_loss: 3.4792e-04 - val_val_KL loss: 83.7978 - val_beta: 1.6379e-04\n",
      "Epoch 3923/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 13127.9789 - recon_loss: 3.4995e-04 - KL loss: 83.0894 - beta: 1.6379e-04 - val_val_loss: 12720.7266 - val_val_recon_loss: 3.3904e-04 - val_val_KL loss: 82.5489 - val_beta: 1.6379e-04\n",
      "Epoch 3924/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 12600.2673 - recon_loss: 3.3580e-04 - KL loss: 82.8993 - beta: 1.6379e-04 - val_val_loss: 12558.9092 - val_val_recon_loss: 3.3470e-04 - val_val_KL loss: 82.7743 - val_beta: 1.6379e-04\n",
      "Epoch 3925/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12463.1790 - recon_loss: 3.3209e-04 - KL loss: 84.0706 - beta: 1.6379e-04 - val_val_loss: 12375.6523 - val_val_recon_loss: 3.2973e-04 - val_val_KL loss: 84.8325 - val_beta: 1.6379e-04\n",
      "Epoch 3926/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12377.9501 - recon_loss: 3.2980e-04 - KL loss: 84.4308 - beta: 1.6379e-04 - val_val_loss: 12234.4658 - val_val_recon_loss: 3.2597e-04 - val_val_KL loss: 83.5975 - val_beta: 1.6379e-04\n",
      "Epoch 3927/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12342.8318 - recon_loss: 3.2886e-04 - KL loss: 84.4128 - beta: 1.6379e-04 - val_val_loss: 12918.3779 - val_val_recon_loss: 3.4429e-04 - val_val_KL loss: 84.7943 - val_beta: 1.6379e-04\n",
      "Epoch 3928/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12804.8590 - recon_loss: 3.4119e-04 - KL loss: 86.7785 - beta: 1.6379e-04 - val_val_loss: 12839.5771 - val_val_recon_loss: 3.4209e-04 - val_val_KL loss: 87.9714 - val_beta: 1.6379e-04\n",
      "Epoch 3929/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 13018.9863 - recon_loss: 3.4687e-04 - KL loss: 89.0751 - beta: 1.6379e-04 - val_val_loss: 12377.8320 - val_val_recon_loss: 3.2977e-04 - val_val_KL loss: 85.4192 - val_beta: 1.6379e-04\n",
      "Epoch 3930/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12289.0315 - recon_loss: 3.2738e-04 - KL loss: 85.7856 - beta: 1.6379e-04 - val_val_loss: 12509.8340 - val_val_recon_loss: 3.3330e-04 - val_val_KL loss: 85.7239 - val_beta: 1.6379e-04\n",
      "Epoch 3931/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 12162.1160 - recon_loss: 3.2396e-04 - KL loss: 86.2323 - beta: 1.6379e-04\n",
      "Epoch 03931: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 12162.1815 - recon_loss: 3.2396e-04 - KL loss: 86.2327 - beta: 1.6379e-04 - val_val_loss: 12676.2178 - val_val_recon_loss: 3.3764e-04 - val_val_KL loss: 90.3207 - val_beta: 1.6379e-04\n",
      "Epoch 3932/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11940.7275 - recon_loss: 3.1798e-04 - KL loss: 87.9020 - beta: 1.6379e-04 - val_val_loss: 12064.7314 - val_val_recon_loss: 3.2128e-04 - val_val_KL loss: 88.7514 - val_beta: 1.6379e-04\n",
      "Epoch 3933/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 11776.1131 - recon_loss: 3.1357e-04 - KL loss: 87.3679 - beta: 1.6379e-04 - val_val_loss: 12049.1191 - val_val_recon_loss: 3.2099e-04 - val_val_KL loss: 83.8265 - val_beta: 1.6379e-04\n",
      "Epoch 3934/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11743.7278 - recon_loss: 3.1277e-04 - KL loss: 84.7744 - beta: 1.6379e-04 - val_val_loss: 11792.1641 - val_val_recon_loss: 3.1408e-04 - val_val_KL loss: 84.5593 - val_beta: 1.6379e-04\n",
      "Epoch 3935/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11616.3955 - recon_loss: 3.0940e-04 - KL loss: 83.1857 - beta: 1.6379e-04 - val_val_loss: 11776.5225 - val_val_recon_loss: 3.1367e-04 - val_val_KL loss: 84.1789 - val_beta: 1.6379e-04\n",
      "Epoch 3936/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11706.8348 - recon_loss: 3.1183e-04 - KL loss: 83.2479 - beta: 1.6379e-04 - val_val_loss: 11724.0576 - val_val_recon_loss: 3.1228e-04 - val_val_KL loss: 83.3766 - val_beta: 1.6379e-04\n",
      "Epoch 3937/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11666.9618 - recon_loss: 3.1071e-04 - KL loss: 84.7876 - beta: 1.6379e-04 - val_val_loss: 11724.9688 - val_val_recon_loss: 3.1227e-04 - val_val_KL loss: 84.6643 - val_beta: 1.6379e-04\n",
      "Epoch 3938/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11514.6711 - recon_loss: 3.0662e-04 - KL loss: 84.9458 - beta: 1.6379e-04 - val_val_loss: 11832.2305 - val_val_recon_loss: 3.1516e-04 - val_val_KL loss: 84.4362 - val_beta: 1.6379e-04\n",
      "Epoch 3939/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11605.7198 - recon_loss: 3.0905e-04 - KL loss: 85.4179 - beta: 1.6379e-04 - val_val_loss: 11826.9424 - val_val_recon_loss: 3.1495e-04 - val_val_KL loss: 86.7402 - val_beta: 1.6379e-04\n",
      "Epoch 3940/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11549.5137 - recon_loss: 3.0753e-04 - KL loss: 86.0086 - beta: 1.6379e-04 - val_val_loss: 11705.3887 - val_val_recon_loss: 3.1172e-04 - val_val_KL loss: 85.8196 - val_beta: 1.6379e-04\n",
      "Epoch 3941/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 11708.6960 - recon_loss: 3.1179e-04 - KL loss: 86.4845 - beta: 1.6379e-04 - val_val_loss: 11774.3564 - val_val_recon_loss: 3.1355e-04 - val_val_KL loss: 86.3291 - val_beta: 1.6379e-04\n",
      "Epoch 3942/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11507.9838 - recon_loss: 3.0642e-04 - KL loss: 85.9849 - beta: 1.6379e-04 - val_val_loss: 11698.5771 - val_val_recon_loss: 3.1156e-04 - val_val_KL loss: 84.8580 - val_beta: 1.6379e-04\n",
      "Epoch 3943/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11530.8748 - recon_loss: 3.0706e-04 - KL loss: 84.8613 - beta: 1.6379e-04 - val_val_loss: 11546.8740 - val_val_recon_loss: 3.0748e-04 - val_val_KL loss: 85.3773 - val_beta: 1.6379e-04\n",
      "Epoch 3944/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11568.6758 - recon_loss: 3.0808e-04 - KL loss: 84.6969 - beta: 1.6379e-04 - val_val_loss: 11655.3301 - val_val_recon_loss: 3.1038e-04 - val_val_KL loss: 85.4456 - val_beta: 1.6379e-04\n",
      "Epoch 3945/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11510.8236 - recon_loss: 3.0651e-04 - KL loss: 85.3547 - beta: 1.6379e-04 - val_val_loss: 11606.6748 - val_val_recon_loss: 3.0910e-04 - val_val_KL loss: 84.7797 - val_beta: 1.6379e-04\n",
      "Epoch 3946/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11353.9372 - recon_loss: 3.0232e-04 - KL loss: 84.5914 - beta: 1.6379e-04 - val_val_loss: 11530.3799 - val_val_recon_loss: 3.0701e-04 - val_val_KL loss: 86.2264 - val_beta: 1.6379e-04\n",
      "Epoch 3947/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11493.6336 - recon_loss: 3.0604e-04 - KL loss: 85.8095 - beta: 1.6379e-04 - val_val_loss: 11610.6992 - val_val_recon_loss: 3.0915e-04 - val_val_KL loss: 86.9282 - val_beta: 1.6379e-04\n",
      "Epoch 3948/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11441.7024 - recon_loss: 3.0464e-04 - KL loss: 85.8315 - beta: 1.6379e-04 - val_val_loss: 11521.7139 - val_val_recon_loss: 3.0681e-04 - val_val_KL loss: 85.0235 - val_beta: 1.6379e-04\n",
      "Epoch 3949/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11448.3261 - recon_loss: 3.0483e-04 - KL loss: 85.3953 - beta: 1.6379e-04 - val_val_loss: 11632.9961 - val_val_recon_loss: 3.0977e-04 - val_val_KL loss: 85.9496 - val_beta: 1.6379e-04\n",
      "Epoch 3950/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11327.5877 - recon_loss: 3.0157e-04 - KL loss: 86.3764 - beta: 1.6379e-04 - val_val_loss: 11796.6729 - val_val_recon_loss: 3.1411e-04 - val_val_KL loss: 88.0644 - val_beta: 1.6379e-04\n",
      "Epoch 3951/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11643.5909 - recon_loss: 3.1002e-04 - KL loss: 87.4605 - beta: 1.6379e-04 - val_val_loss: 12173.9424 - val_val_recon_loss: 3.2412e-04 - val_val_KL loss: 92.2049 - val_beta: 1.6379e-04\n",
      "Epoch 3952/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11712.8087 - recon_loss: 3.1182e-04 - KL loss: 89.2556 - beta: 1.6379e-04 - val_val_loss: 11863.1729 - val_val_recon_loss: 3.1585e-04 - val_val_KL loss: 89.7395 - val_beta: 1.6379e-04\n",
      "Epoch 3953/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11676.0885 - recon_loss: 3.1084e-04 - KL loss: 89.1806 - beta: 1.6379e-04\n",
      "Epoch 03953: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11676.1194 - recon_loss: 3.1084e-04 - KL loss: 89.1809 - beta: 1.6379e-04 - val_val_loss: 11999.5186 - val_val_recon_loss: 3.1947e-04 - val_val_KL loss: 90.9781 - val_beta: 1.6379e-04\n",
      "Epoch 3954/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11841.3280 - recon_loss: 3.1525e-04 - KL loss: 90.2244 - beta: 1.6379e-04 - val_val_loss: 11785.5967 - val_val_recon_loss: 3.1376e-04 - val_val_KL loss: 89.9073 - val_beta: 1.6379e-04\n",
      "Epoch 3955/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11677.7060 - recon_loss: 3.1085e-04 - KL loss: 90.3263 - beta: 1.6379e-04 - val_val_loss: 11699.4746 - val_val_recon_loss: 3.1147e-04 - val_val_KL loss: 89.2484 - val_beta: 1.6379e-04\n",
      "Epoch 3956/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11456.7279 - recon_loss: 3.0497e-04 - KL loss: 88.5282 - beta: 1.6379e-04 - val_val_loss: 11623.5166 - val_val_recon_loss: 3.0945e-04 - val_val_KL loss: 88.5588 - val_beta: 1.6379e-04\n",
      "Epoch 3957/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11404.6971 - recon_loss: 3.0358e-04 - KL loss: 88.2992 - beta: 1.6379e-04 - val_val_loss: 11631.8799 - val_val_recon_loss: 3.0964e-04 - val_val_KL loss: 89.7402 - val_beta: 1.6379e-04\n",
      "Epoch 3958/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11384.4686 - recon_loss: 3.0302e-04 - KL loss: 89.0349 - beta: 1.6379e-04\n",
      "Epoch 03958: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11384.5087 - recon_loss: 3.0302e-04 - KL loss: 89.0349 - beta: 1.6379e-04 - val_val_loss: 11617.3301 - val_val_recon_loss: 3.0926e-04 - val_val_KL loss: 89.2033 - val_beta: 1.6379e-04\n",
      "Epoch 3958/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 33591.1860 - recon_loss: 3.3490e-04 - KL loss: 101.1153 - beta: 1.0000e-04 - val_val_loss: 31878.3477 - val_val_recon_loss: 3.1756e-04 - val_val_KL loss: 121.9791 - val_beta: 1.0000e-04\n",
      "Epoch 3959/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31504.7809 - recon_loss: 3.1380e-04 - KL loss: 124.4661 - beta: 1.0000e-04 - val_val_loss: 34380.3516 - val_val_recon_loss: 3.4247e-04 - val_val_KL loss: 133.6364 - val_beta: 1.0000e-04\n",
      "Epoch 3960/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32631.6794 - recon_loss: 3.2497e-04 - KL loss: 135.1191 - beta: 1.0000e-04 - val_val_loss: 35284.6836 - val_val_recon_loss: 3.5153e-04 - val_val_KL loss: 131.8408 - val_beta: 1.0000e-04\n",
      "Epoch 3961/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32839.6479 - recon_loss: 3.2702e-04 - KL loss: 137.6690 - beta: 1.0000e-04 - val_val_loss: 32849.1875 - val_val_recon_loss: 3.2706e-04 - val_val_KL loss: 143.5226 - val_beta: 1.0000e-04\n",
      "Epoch 3962/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32844.1530 - recon_loss: 3.2701e-04 - KL loss: 143.0631 - beta: 1.0000e-04 - val_val_loss: 32377.6992 - val_val_recon_loss: 3.2237e-04 - val_val_KL loss: 141.0420 - val_beta: 1.0000e-04\n",
      "Epoch 3963/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31949.6686 - recon_loss: 3.1808e-04 - KL loss: 142.1374 - beta: 1.0000e-04\n",
      "Epoch 03963: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31949.7732 - recon_loss: 3.1808e-04 - KL loss: 142.1366 - beta: 1.0000e-04 - val_val_loss: 32385.7773 - val_val_recon_loss: 3.2249e-04 - val_val_KL loss: 136.7717 - val_beta: 1.0000e-04\n",
      "Epoch 3964/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30904.4594 - recon_loss: 3.0766e-04 - KL loss: 138.0263 - beta: 1.0000e-04 - val_val_loss: 30814.3750 - val_val_recon_loss: 3.0674e-04 - val_val_KL loss: 140.7479 - val_beta: 1.0000e-04\n",
      "Epoch 3965/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30178.0746 - recon_loss: 3.0038e-04 - KL loss: 140.4137 - beta: 1.0000e-04 - val_val_loss: 30790.3672 - val_val_recon_loss: 3.0650e-04 - val_val_KL loss: 140.2811 - val_beta: 1.0000e-04\n",
      "Epoch 3966/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30725.3792 - recon_loss: 3.0586e-04 - KL loss: 139.7794 - beta: 1.0000e-04 - val_val_loss: 30460.1152 - val_val_recon_loss: 3.0322e-04 - val_val_KL loss: 138.3659 - val_beta: 1.0000e-04\n",
      "Epoch 3967/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30192.4470 - recon_loss: 3.0053e-04 - KL loss: 139.1493 - beta: 1.0000e-04 - val_val_loss: 30653.1934 - val_val_recon_loss: 3.0512e-04 - val_val_KL loss: 141.1413 - val_beta: 1.0000e-04\n",
      "Epoch 3968/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30437.4002 - recon_loss: 3.0296e-04 - KL loss: 141.3003 - beta: 1.0000e-04 - val_val_loss: 31480.7930 - val_val_recon_loss: 3.1337e-04 - val_val_KL loss: 143.4957 - val_beta: 1.0000e-04\n",
      "Epoch 3969/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30972.1692 - recon_loss: 3.0828e-04 - KL loss: 144.3750 - beta: 1.0000e-04 - val_val_loss: 30693.4980 - val_val_recon_loss: 3.0550e-04 - val_val_KL loss: 143.6693 - val_beta: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3970/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30390.7032 - recon_loss: 3.0246e-04 - KL loss: 144.4160 - beta: 1.0000e-04 - val_val_loss: 31465.9316 - val_val_recon_loss: 3.1319e-04 - val_val_KL loss: 147.2839 - val_beta: 1.0000e-04\n",
      "Epoch 3971/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 30605.4073 - recon_loss: 3.0460e-04 - KL loss: 145.3790 - beta: 1.0000e-04\n",
      "Epoch 03971: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30605.1529 - recon_loss: 3.0460e-04 - KL loss: 145.3785 - beta: 1.0000e-04 - val_val_loss: 30703.7969 - val_val_recon_loss: 3.0558e-04 - val_val_KL loss: 145.9330 - val_beta: 1.0000e-04\n",
      "Epoch 3972/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30368.4104 - recon_loss: 3.0222e-04 - KL loss: 145.9436 - beta: 1.0000e-04 - val_val_loss: 30479.6797 - val_val_recon_loss: 3.0333e-04 - val_val_KL loss: 146.2202 - val_beta: 1.0000e-04\n",
      "Epoch 3973/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30086.1813 - recon_loss: 2.9940e-04 - KL loss: 145.8219 - beta: 1.0000e-04 - val_val_loss: 30348.9707 - val_val_recon_loss: 3.0203e-04 - val_val_KL loss: 145.6610 - val_beta: 1.0000e-04\n",
      "Epoch 3974/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 29719.3657 - recon_loss: 2.9574e-04 - KL loss: 145.0256 - beta: 1.0000e-04 - val_val_loss: 30371.5469 - val_val_recon_loss: 3.0227e-04 - val_val_KL loss: 144.4561 - val_beta: 1.0000e-04\n",
      "Epoch 3975/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30021.3970 - recon_loss: 2.9877e-04 - KL loss: 144.6451 - beta: 1.0000e-04 - val_val_loss: 30501.0645 - val_val_recon_loss: 3.0356e-04 - val_val_KL loss: 145.3878 - val_beta: 1.0000e-04\n",
      "Epoch 3976/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29938.3206 - recon_loss: 2.9793e-04 - KL loss: 144.8317 - beta: 1.0000e-04 - val_val_loss: 30387.0918 - val_val_recon_loss: 3.0242e-04 - val_val_KL loss: 144.8084 - val_beta: 1.0000e-04\n",
      "Epoch 3977/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 29888.4303 - recon_loss: 2.9744e-04 - KL loss: 144.7985 - beta: 1.0000e-04 - val_val_loss: 30277.0625 - val_val_recon_loss: 3.0133e-04 - val_val_KL loss: 144.5319 - val_beta: 1.0000e-04\n",
      "Epoch 3978/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29757.3348 - recon_loss: 2.9613e-04 - KL loss: 144.1090 - beta: 1.0000e-04 - val_val_loss: 30406.0566 - val_val_recon_loss: 3.0260e-04 - val_val_KL loss: 146.0853 - val_beta: 1.0000e-04\n",
      "Epoch 3979/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29590.2329 - recon_loss: 2.9445e-04 - KL loss: 145.3345 - beta: 1.0000e-04 - val_val_loss: 30290.5801 - val_val_recon_loss: 3.0146e-04 - val_val_KL loss: 144.4080 - val_beta: 1.0000e-04\n",
      "Epoch 3980/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29952.2645 - recon_loss: 2.9807e-04 - KL loss: 144.8683 - beta: 1.0000e-04 - val_val_loss: 30123.9492 - val_val_recon_loss: 2.9980e-04 - val_val_KL loss: 144.2715 - val_beta: 1.0000e-04\n",
      "Epoch 3981/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29571.3622 - recon_loss: 2.9428e-04 - KL loss: 143.6043 - beta: 1.0000e-04 - val_val_loss: 30140.1250 - val_val_recon_loss: 2.9996e-04 - val_val_KL loss: 144.2843 - val_beta: 1.0000e-04\n",
      "Epoch 3982/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29877.5939 - recon_loss: 2.9734e-04 - KL loss: 143.9974 - beta: 1.0000e-04 - val_val_loss: 30109.0117 - val_val_recon_loss: 2.9963e-04 - val_val_KL loss: 145.6407 - val_beta: 1.0000e-04\n",
      "Epoch 3983/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 29746.5156 - recon_loss: 2.9601e-04 - KL loss: 145.4140 - beta: 1.0000e-04 - val_val_loss: 30105.7344 - val_val_recon_loss: 2.9961e-04 - val_val_KL loss: 145.1327 - val_beta: 1.0000e-04\n",
      "Epoch 3984/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29694.5624 - recon_loss: 2.9549e-04 - KL loss: 145.4023 - beta: 1.0000e-04 - val_val_loss: 30023.1426 - val_val_recon_loss: 2.9878e-04 - val_val_KL loss: 144.9992 - val_beta: 1.0000e-04\n",
      "Epoch 3985/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29529.2633 - recon_loss: 2.9385e-04 - KL loss: 144.5594 - beta: 1.0000e-04 - val_val_loss: 29900.1074 - val_val_recon_loss: 2.9756e-04 - val_val_KL loss: 144.4674 - val_beta: 1.0000e-04\n",
      "Epoch 3986/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29474.6358 - recon_loss: 2.9330e-04 - KL loss: 144.3885 - beta: 1.0000e-04 - val_val_loss: 29907.5547 - val_val_recon_loss: 2.9762e-04 - val_val_KL loss: 145.2069 - val_beta: 1.0000e-04\n",
      "Epoch 3987/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29494.2591 - recon_loss: 2.9349e-04 - KL loss: 145.1190 - beta: 1.0000e-04 - val_val_loss: 29954.4648 - val_val_recon_loss: 2.9810e-04 - val_val_KL loss: 144.3628 - val_beta: 1.0000e-04\n",
      "Epoch 3988/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29469.7998 - recon_loss: 2.9326e-04 - KL loss: 144.2208 - beta: 1.0000e-04 - val_val_loss: 29822.7402 - val_val_recon_loss: 2.9679e-04 - val_val_KL loss: 144.1563 - val_beta: 1.0000e-04\n",
      "Epoch 3989/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29200.5170 - recon_loss: 2.9057e-04 - KL loss: 143.5524 - beta: 1.0000e-04 - val_val_loss: 29840.7949 - val_val_recon_loss: 2.9697e-04 - val_val_KL loss: 144.0605 - val_beta: 1.0000e-04\n",
      "Epoch 3990/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29438.9004 - recon_loss: 2.9294e-04 - KL loss: 144.6139 - beta: 1.0000e-04 - val_val_loss: 29923.0645 - val_val_recon_loss: 2.9778e-04 - val_val_KL loss: 145.2921 - val_beta: 1.0000e-04\n",
      "Epoch 3991/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29457.5554 - recon_loss: 2.9312e-04 - KL loss: 145.7500 - beta: 1.0000e-04 - val_val_loss: 29939.0977 - val_val_recon_loss: 2.9793e-04 - val_val_KL loss: 146.2998 - val_beta: 1.0000e-04\n",
      "Epoch 3992/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29559.9953 - recon_loss: 2.9415e-04 - KL loss: 145.0640 - beta: 1.0000e-04 - val_val_loss: 29844.3926 - val_val_recon_loss: 2.9699e-04 - val_val_KL loss: 145.7102 - val_beta: 1.0000e-04\n",
      "Epoch 3993/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29060.0321 - recon_loss: 2.8915e-04 - KL loss: 145.2239 - beta: 1.0000e-04 - val_val_loss: 29774.1426 - val_val_recon_loss: 2.9629e-04 - val_val_KL loss: 145.4624 - val_beta: 1.0000e-04\n",
      "Epoch 3994/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29270.8104 - recon_loss: 2.9125e-04 - KL loss: 145.3674 - beta: 1.0000e-04 - val_val_loss: 29777.3301 - val_val_recon_loss: 2.9631e-04 - val_val_KL loss: 145.9894 - val_beta: 1.0000e-04\n",
      "Epoch 3995/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29463.3730 - recon_loss: 2.9318e-04 - KL loss: 145.7462 - beta: 1.0000e-04 - val_val_loss: 29743.4199 - val_val_recon_loss: 2.9598e-04 - val_val_KL loss: 145.4037 - val_beta: 1.0000e-04\n",
      "Epoch 3996/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29181.9782 - recon_loss: 2.9036e-04 - KL loss: 145.6605 - beta: 1.0000e-04 - val_val_loss: 29720.5020 - val_val_recon_loss: 2.9575e-04 - val_val_KL loss: 145.6998 - val_beta: 1.0000e-04\n",
      "Epoch 3997/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29354.4619 - recon_loss: 2.9209e-04 - KL loss: 145.0604 - beta: 1.0000e-04 - val_val_loss: 29749.3203 - val_val_recon_loss: 2.9603e-04 - val_val_KL loss: 146.0604 - val_beta: 1.0000e-04\n",
      "Epoch 3998/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29441.1094 - recon_loss: 2.9295e-04 - KL loss: 146.2769 - beta: 1.0000e-04 - val_val_loss: 29886.9824 - val_val_recon_loss: 2.9740e-04 - val_val_KL loss: 147.2907 - val_beta: 1.0000e-04\n",
      "Epoch 3999/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29507.2187 - recon_loss: 2.9360e-04 - KL loss: 147.2308 - beta: 1.0000e-04 - val_val_loss: 29870.1191 - val_val_recon_loss: 2.9723e-04 - val_val_KL loss: 147.3313 - val_beta: 1.0000e-04\n",
      "Epoch 4000/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29181.1937 - recon_loss: 2.9034e-04 - KL loss: 146.8915 - beta: 1.0000e-04 - val_val_loss: 29768.0801 - val_val_recon_loss: 2.9621e-04 - val_val_KL loss: 147.2242 - val_beta: 1.0000e-04\n",
      "Epoch 4001/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29209.7714 - recon_loss: 2.9064e-04 - KL loss: 145.6180 - beta: 1.0000e-04 - val_val_loss: 29666.2266 - val_val_recon_loss: 2.9520e-04 - val_val_KL loss: 146.5338 - val_beta: 1.0000e-04\n",
      "Epoch 4002/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29174.4734 - recon_loss: 2.9028e-04 - KL loss: 146.6573 - beta: 1.0000e-04 - val_val_loss: 29675.6953 - val_val_recon_loss: 2.9529e-04 - val_val_KL loss: 146.6197 - val_beta: 1.0000e-04\n",
      "Epoch 4003/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 29082.1036 - recon_loss: 2.8935e-04 - KL loss: 147.0450 - beta: 1.0000e-04 - val_val_loss: 29775.8867 - val_val_recon_loss: 2.9629e-04 - val_val_KL loss: 147.3519 - val_beta: 1.0000e-04\n",
      "Epoch 4004/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29234.6926 - recon_loss: 2.9086e-04 - KL loss: 148.2389 - beta: 1.0000e-04 - val_val_loss: 29846.4141 - val_val_recon_loss: 2.9697e-04 - val_val_KL loss: 149.2150 - val_beta: 1.0000e-04\n",
      "Epoch 4005/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29202.0907 - recon_loss: 2.9053e-04 - KL loss: 149.1003 - beta: 1.0000e-04 - val_val_loss: 29875.1641 - val_val_recon_loss: 2.9726e-04 - val_val_KL loss: 148.7558 - val_beta: 1.0000e-04\n",
      "Epoch 4006/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 29112.5966 - recon_loss: 2.8964e-04 - KL loss: 148.2225 - beta: 1.0000e-04\n",
      "Epoch 04006: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29112.6181 - recon_loss: 2.8964e-04 - KL loss: 148.2222 - beta: 1.0000e-04 - val_val_loss: 29736.4199 - val_val_recon_loss: 2.9589e-04 - val_val_KL loss: 147.4700 - val_beta: 1.0000e-04\n",
      "Epoch 4007/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29072.2788 - recon_loss: 2.8925e-04 - KL loss: 147.5855 - beta: 1.0000e-04 - val_val_loss: 29576.7598 - val_val_recon_loss: 2.9429e-04 - val_val_KL loss: 148.1689 - val_beta: 1.0000e-04\n",
      "Epoch 4008/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29078.9905 - recon_loss: 2.8931e-04 - KL loss: 147.4804 - beta: 1.0000e-04 - val_val_loss: 29667.0195 - val_val_recon_loss: 2.9519e-04 - val_val_KL loss: 148.4227 - val_beta: 1.0000e-04\n",
      "Epoch 4009/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29050.4541 - recon_loss: 2.8902e-04 - KL loss: 148.1752 - beta: 1.0000e-04 - val_val_loss: 29609.6094 - val_val_recon_loss: 2.9461e-04 - val_val_KL loss: 148.6277 - val_beta: 1.0000e-04\n",
      "Epoch 4010/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29160.0024 - recon_loss: 2.9011e-04 - KL loss: 149.0536 - beta: 1.0000e-04 - val_val_loss: 29564.3809 - val_val_recon_loss: 2.9416e-04 - val_val_KL loss: 148.8518 - val_beta: 1.0000e-04\n",
      "Epoch 4011/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 28796.7285 - recon_loss: 2.8648e-04 - KL loss: 148.9595 - beta: 1.0000e-04 - val_val_loss: 29579.1250 - val_val_recon_loss: 2.9430e-04 - val_val_KL loss: 148.8053 - val_beta: 1.0000e-04\n",
      "Epoch 4012/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29200.7881 - recon_loss: 2.9052e-04 - KL loss: 148.6037 - beta: 1.0000e-04 - val_val_loss: 29580.8574 - val_val_recon_loss: 2.9432e-04 - val_val_KL loss: 149.2177 - val_beta: 1.0000e-04\n",
      "Epoch 4013/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 28992.6611 - recon_loss: 2.8844e-04 - KL loss: 149.0465 - beta: 1.0000e-04 - val_val_loss: 29523.0195 - val_val_recon_loss: 2.9374e-04 - val_val_KL loss: 148.8427 - val_beta: 1.0000e-04\n",
      "Epoch 4014/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29284.0891 - recon_loss: 2.9135e-04 - KL loss: 148.8763 - beta: 1.0000e-04 - val_val_loss: 29553.3672 - val_val_recon_loss: 2.9404e-04 - val_val_KL loss: 149.4171 - val_beta: 1.0000e-04\n",
      "Epoch 4015/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 28880.2255 - recon_loss: 2.8731e-04 - KL loss: 149.4343 - beta: 1.0000e-04 - val_val_loss: 29561.3984 - val_val_recon_loss: 2.9412e-04 - val_val_KL loss: 149.0214 - val_beta: 1.0000e-04\n",
      "Epoch 4016/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29131.6187 - recon_loss: 2.8982e-04 - KL loss: 149.1417 - beta: 1.0000e-04 - val_val_loss: 29559.4902 - val_val_recon_loss: 2.9410e-04 - val_val_KL loss: 149.4195 - val_beta: 1.0000e-04\n",
      "Epoch 4017/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 28849.6088 - recon_loss: 2.8700e-04 - KL loss: 149.3499 - beta: 1.0000e-04 - val_val_loss: 29540.0430 - val_val_recon_loss: 2.9392e-04 - val_val_KL loss: 148.5454 - val_beta: 1.0000e-04\n",
      "Epoch 4018/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 29002.0594 - recon_loss: 2.8853e-04 - KL loss: 148.5937 - beta: 1.0000e-04\n",
      "Epoch 04018: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29001.9939 - recon_loss: 2.8853e-04 - KL loss: 148.5937 - beta: 1.0000e-04 - val_val_loss: 29552.5605 - val_val_recon_loss: 2.9404e-04 - val_val_KL loss: 148.8103 - val_beta: 1.0000e-04\n",
      "Epoch 4019/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 28781.6352 - recon_loss: 2.8633e-04 - KL loss: 148.7379 - beta: 1.0000e-04 - val_val_loss: 29503.9199 - val_val_recon_loss: 2.9355e-04 - val_val_KL loss: 148.8492 - val_beta: 1.0000e-04\n",
      "Epoch 4020/10000\n",
      "1000/1000 [==============================] - 124s 124ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4021/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4022/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4023/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4024/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04\n",
      "Epoch 04024: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4025/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4026/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4027/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4028/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n",
      "Epoch 4029/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04\n",
      "Epoch 04029: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0000e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_val_loss', min_delta=0., patience=10, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "\n",
    "for beta in np.logspace(-1,-4,15)[2:]:\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,3e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 756/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 31734.9253 - recon_loss: 3.1504e-04 - KL loss: 231.1730 - beta: 1.0000e-04 - val_val_loss: 32552.8555 - val_val_recon_loss: 3.2328e-04 - val_val_KL loss: 224.8359 - val_beta: 1.0000e-04\n",
      "Epoch 757/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 31422.9057 - recon_loss: 3.1198e-04 - KL loss: 225.1942 - beta: 1.0000e-04 - val_val_loss: 32635.0020 - val_val_recon_loss: 3.2409e-04 - val_val_KL loss: 225.6331 - val_beta: 1.0000e-04\n",
      "Epoch 758/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 32146.5800 - recon_loss: 3.1916e-04 - KL loss: 230.2496 - beta: 1.0000e-04 - val_val_loss: 34566.9961 - val_val_recon_loss: 3.4329e-04 - val_val_KL loss: 237.7053 - val_beta: 1.0000e-04\n",
      "Epoch 759/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 34457.7641 - recon_loss: 3.4222e-04 - KL loss: 235.7530 - beta: 1.0000e-04 - val_val_loss: 33953.9844 - val_val_recon_loss: 3.3723e-04 - val_val_KL loss: 230.8280 - val_beta: 1.0000e-04\n",
      "Epoch 760/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 33973.7853 - recon_loss: 3.3739e-04 - KL loss: 234.4306 - beta: 1.0000e-04 - val_val_loss: 33504.1016 - val_val_recon_loss: 3.3269e-04 - val_val_KL loss: 235.2220 - val_beta: 1.0000e-04\n",
      "Epoch 761/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 33148.8028 - recon_loss: 3.2916e-04 - KL loss: 232.4198 - beta: 1.0000e-04\n",
      "Epoch 00761: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 33148.5909 - recon_loss: 3.2916e-04 - KL loss: 232.4179 - beta: 1.0000e-04 - val_val_loss: 33597.3906 - val_val_recon_loss: 3.3367e-04 - val_val_KL loss: 230.8152 - val_beta: 1.0000e-04\n",
      "Epoch 762/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 32748.2018 - recon_loss: 3.2515e-04 - KL loss: 232.7624 - beta: 1.0000e-04 - val_val_loss: 32675.5820 - val_val_recon_loss: 3.2444e-04 - val_val_KL loss: 231.4207 - val_beta: 1.0000e-04\n",
      "Epoch 763/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32084.4247 - recon_loss: 3.1850e-04 - KL loss: 233.9477 - beta: 1.0000e-04 - val_val_loss: 33216.9258 - val_val_recon_loss: 3.2975e-04 - val_val_KL loss: 241.4691 - val_beta: 1.0000e-04\n",
      "Epoch 764/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32980.4050 - recon_loss: 3.2738e-04 - KL loss: 242.5221 - beta: 1.0000e-04 - val_val_loss: 32560.9824 - val_val_recon_loss: 3.2322e-04 - val_val_KL loss: 239.3627 - val_beta: 1.0000e-04\n",
      "Epoch 765/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32125.8578 - recon_loss: 3.1886e-04 - KL loss: 239.4620 - beta: 1.0000e-04 - val_val_loss: 32372.7109 - val_val_recon_loss: 3.2139e-04 - val_val_KL loss: 233.8444 - val_beta: 1.0000e-04\n",
      "Epoch 766/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 31508.4112 - recon_loss: 3.1272e-04 - KL loss: 236.7888 - beta: 1.0000e-04 - val_val_loss: 32161.9297 - val_val_recon_loss: 3.1923e-04 - val_val_KL loss: 239.4142 - val_beta: 1.0000e-04\n",
      "Epoch 767/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 31453.0612 - recon_loss: 3.1214e-04 - KL loss: 239.3167 - beta: 1.0000e-04 - val_val_loss: 32460.1953 - val_val_recon_loss: 3.2222e-04 - val_val_KL loss: 237.9905 - val_beta: 1.0000e-04\n",
      "Epoch 768/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 32416.1813 - recon_loss: 3.2175e-04 - KL loss: 241.3270 - beta: 1.0000e-04 - val_val_loss: 32403.3848 - val_val_recon_loss: 3.2163e-04 - val_val_KL loss: 239.9623 - val_beta: 1.0000e-04\n",
      "Epoch 769/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 32062.8120 - recon_loss: 3.1820e-04 - KL loss: 242.7523 - beta: 1.0000e-04 - val_val_loss: 31870.1621 - val_val_recon_loss: 3.1633e-04 - val_val_KL loss: 237.1737 - val_beta: 1.0000e-04\n",
      "Epoch 770/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31758.2375 - recon_loss: 3.1520e-04 - KL loss: 238.6980 - beta: 1.0000e-04 - val_val_loss: 31717.4180 - val_val_recon_loss: 3.1479e-04 - val_val_KL loss: 238.1461 - val_beta: 1.0000e-04\n",
      "Epoch 771/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 30949.9720 - recon_loss: 3.0712e-04 - KL loss: 237.5664 - beta: 1.0000e-04 - val_val_loss: 31445.7305 - val_val_recon_loss: 3.1207e-04 - val_val_KL loss: 238.8710 - val_beta: 1.0000e-04\n",
      "Epoch 772/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31135.9858 - recon_loss: 3.0898e-04 - KL loss: 238.0942 - beta: 1.0000e-04 - val_val_loss: 31617.3379 - val_val_recon_loss: 3.1378e-04 - val_val_KL loss: 239.1307 - val_beta: 1.0000e-04\n",
      "Epoch 773/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31102.3219 - recon_loss: 3.0863e-04 - KL loss: 239.6461 - beta: 1.0000e-04 - val_val_loss: 31689.9805 - val_val_recon_loss: 3.1451e-04 - val_val_KL loss: 238.9722 - val_beta: 1.0000e-04\n",
      "Epoch 774/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31162.3538 - recon_loss: 3.0922e-04 - KL loss: 240.4582 - beta: 1.0000e-04 - val_val_loss: 31920.4609 - val_val_recon_loss: 3.1677e-04 - val_val_KL loss: 243.7856 - val_beta: 1.0000e-04\n",
      "Epoch 775/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31809.6359 - recon_loss: 3.1566e-04 - KL loss: 243.5698 - beta: 1.0000e-04 - val_val_loss: 32361.6523 - val_val_recon_loss: 3.2113e-04 - val_val_KL loss: 249.0607 - val_beta: 1.0000e-04\n",
      "Epoch 776/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 32028.7363 - recon_loss: 3.1779e-04 - KL loss: 249.9569 - beta: 1.0000e-04- ETA: 5s - loss: 32029.3446 - recon_loss\n",
      "Epoch 00776: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 32028.7376 - recon_loss: 3.1779e-04 - KL loss: 249.9555 - beta: 1.0000e-04 - val_val_loss: 32466.6250 - val_val_recon_loss: 3.2221e-04 - val_val_KL loss: 246.0588 - val_beta: 1.0000e-04\n",
      "Epoch 777/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31993.3283 - recon_loss: 3.1745e-04 - KL loss: 248.0733 - beta: 1.0000e-04 - val_val_loss: 32325.2559 - val_val_recon_loss: 3.2075e-04 - val_val_KL loss: 250.3663 - val_beta: 1.0000e-04\n",
      "Epoch 778/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31863.4494 - recon_loss: 3.1613e-04 - KL loss: 250.3737 - beta: 1.0000e-04 - val_val_loss: 32090.9746 - val_val_recon_loss: 3.1841e-04 - val_val_KL loss: 250.0829 - val_beta: 1.0000e-04\n",
      "Epoch 779/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 31787.1841 - recon_loss: 3.1537e-04 - KL loss: 250.0444 - beta: 1.0000e-04 - val_val_loss: 31917.4824 - val_val_recon_loss: 3.1669e-04 - val_val_KL loss: 248.8754 - val_beta: 1.0000e-04\n",
      "Epoch 780/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 31573.9766 - recon_loss: 3.1324e-04 - KL loss: 250.2026 - beta: 1.0000e-04 - val_val_loss: 31871.2559 - val_val_recon_loss: 3.1623e-04 - val_val_KL loss: 248.6668 - val_beta: 1.0000e-04\n",
      "Epoch 781/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31369.9170 - recon_loss: 3.1121e-04 - KL loss: 249.3442 - beta: 1.0000e-04\n",
      "Epoch 00781: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 31370.0124 - recon_loss: 3.1121e-04 - KL loss: 249.3450 - beta: 1.0000e-04 - val_val_loss: 31931.5078 - val_val_recon_loss: 3.1681e-04 - val_val_KL loss: 250.7457 - val_beta: 1.0000e-04\n",
      "Epoch 781/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 9120.9496 - recon_loss: 3.1488e-04 - KL loss: 232.1327 - beta: 1.8821e-04 - val_val_loss: 9433.7383 - val_val_recon_loss: 3.2735e-04 - val_val_KL loss: 192.9590 - val_beta: 1.8821e-04\n",
      "Epoch 782/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 9294.5237 - recon_loss: 3.2265e-04 - KL loss: 186.2035 - beta: 1.8821e-04 - val_val_loss: 10041.1953 - val_val_recon_loss: 3.4922e-04 - val_val_KL loss: 183.0658 - val_beta: 1.8821e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 783/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 9695.9676 - recon_loss: 3.3708e-04 - KL loss: 180.3865 - beta: 1.8821e-04 - val_val_loss: 9603.8359 - val_val_recon_loss: 3.3405e-04 - val_val_KL loss: 173.7154 - val_beta: 1.8821e-04\n",
      "Epoch 784/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 9490.7684 - recon_loss: 3.3011e-04 - KL loss: 172.1215 - beta: 1.8821e-04 - val_val_loss: 9527.5752 - val_val_recon_loss: 3.3166e-04 - val_val_KL loss: 165.1717 - val_beta: 1.8821e-04\n",
      "Epoch 785/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 9402.9572 - recon_loss: 3.2723e-04 - KL loss: 165.3779 - beta: 1.8821e-04 - val_val_loss: 9534.2842 - val_val_recon_loss: 3.3178e-04 - val_val_KL loss: 168.4199 - val_beta: 1.8821e-04\n",
      "Epoch 786/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 9340.7008 - recon_loss: 3.2503e-04 - KL loss: 165.3658 - beta: 1.8821e-04 - val_val_loss: 9195.4521 - val_val_recon_loss: 3.2021e-04 - val_val_KL loss: 156.0148 - val_beta: 1.8821e-04\n",
      "Epoch 787/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 9055.9824 - recon_loss: 3.1520e-04 - KL loss: 158.2086 - beta: 1.8821e-04 - val_val_loss: 9287.2285 - val_val_recon_loss: 3.2335e-04 - val_val_KL loss: 159.3331 - val_beta: 1.8821e-04\n",
      "Epoch 788/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 9268.3444 - recon_loss: 3.2263e-04 - KL loss: 160.7528 - beta: 1.8821e-04 - val_val_loss: 10014.8652 - val_val_recon_loss: 3.4858e-04 - val_val_KL loss: 174.5871 - val_beta: 1.8821e-04\n",
      "Epoch 789/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 9562.0885 - recon_loss: 3.3287e-04 - KL loss: 165.3954 - beta: 1.8821e-04 - val_val_loss: 9440.2617 - val_val_recon_loss: 3.2891e-04 - val_val_KL loss: 155.4210 - val_beta: 1.8821e-04\n",
      "Epoch 790/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 9229.0630 - recon_loss: 3.2151e-04 - KL loss: 153.1188 - beta: 1.8821e-04 - val_val_loss: 9168.3447 - val_val_recon_loss: 3.1945e-04 - val_val_KL loss: 150.6188 - val_beta: 1.8821e-04\n",
      "Epoch 791/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 8964.7566 - recon_loss: 3.1230e-04 - KL loss: 148.7679 - beta: 1.8821e-04 - val_val_loss: 9144.7852 - val_val_recon_loss: 3.1864e-04 - val_val_KL loss: 149.6818 - val_beta: 1.8821e-04\n",
      "Epoch 792/10000\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 8993.3632 - recon_loss: 3.1328e-04 - KL loss: 149.8152 - beta: 1.8821e-04 - val_val_loss: 9121.7041 - val_val_recon_loss: 3.1798e-04 - val_val_KL loss: 145.2145 - val_beta: 1.8821e-04\n",
      "Epoch 793/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 8935.8022 - recon_loss: 3.1131e-04 - KL loss: 147.7187 - beta: 1.8821e-04 - val_val_loss: 8981.2383 - val_val_recon_loss: 3.1280e-04 - val_val_KL loss: 151.1387 - val_beta: 1.8821e-04\n",
      "Epoch 794/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 8958.7546 - recon_loss: 3.1200e-04 - KL loss: 151.2540 - beta: 1.8821e-04 - val_val_loss: 9037.2734 - val_val_recon_loss: 3.1476e-04 - val_val_KL loss: 151.8327 - val_beta: 1.8821e-04\n",
      "Epoch 795/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 8916.5986 - recon_loss: 3.1057e-04 - KL loss: 149.3989 - beta: 1.8821e-04 - val_val_loss: 8831.5811 - val_val_recon_loss: 3.0769e-04 - val_val_KL loss: 145.8178 - val_beta: 1.8821e-04\n",
      "Epoch 796/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 8857.5242 - recon_loss: 3.0849e-04 - KL loss: 148.9430 - beta: 1.8821e-04 - val_val_loss: 8859.4102 - val_val_recon_loss: 3.0865e-04 - val_val_KL loss: 146.5707 - val_beta: 1.8821e-04\n",
      "Epoch 797/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 8851.8109 - recon_loss: 3.0843e-04 - KL loss: 145.0381 - beta: 1.8821e-04 - val_val_loss: 8873.1660 - val_val_recon_loss: 3.0907e-04 - val_val_KL loss: 148.3136 - val_beta: 1.8821e-04\n",
      "Epoch 798/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 8888.7785 - recon_loss: 3.0963e-04 - KL loss: 148.1650 - beta: 1.8821e-04 - val_val_loss: 8932.6055 - val_val_recon_loss: 3.1114e-04 - val_val_KL loss: 149.4586 - val_beta: 1.8821e-04\n",
      "Epoch 799/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 8780.1541 - recon_loss: 3.0585e-04 - KL loss: 146.2955 - beta: 1.8821e-04 - val_val_loss: 8839.6191 - val_val_recon_loss: 3.0802e-04 - val_val_KL loss: 144.4619 - val_beta: 1.8821e-04\n",
      "Epoch 800/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8715.2011 - recon_loss: 3.0361e-04 - KL loss: 144.6166 - beta: 1.8821e-04 - val_val_loss: 8829.5801 - val_val_recon_loss: 3.0781e-04 - val_val_KL loss: 140.4396 - val_beta: 1.8821e-04\n",
      "Epoch 801/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8932.1605 - recon_loss: 3.1129e-04 - KL loss: 144.7607 - beta: 1.8821e-04 - val_val_loss: 8950.7109 - val_val_recon_loss: 3.1187e-04 - val_val_KL loss: 146.8484 - val_beta: 1.8821e-04\n",
      "Epoch 802/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8819.8925 - recon_loss: 3.0728e-04 - KL loss: 145.7075 - beta: 1.8821e-04 - val_val_loss: 8780.6768 - val_val_recon_loss: 3.0599e-04 - val_val_KL loss: 142.8170 - val_beta: 1.8821e-04\n",
      "Epoch 803/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8734.5982 - recon_loss: 3.0430e-04 - KL loss: 144.4035 - beta: 1.8821e-04 - val_val_loss: 9080.6855 - val_val_recon_loss: 3.1632e-04 - val_val_KL loss: 151.3258 - val_beta: 1.8821e-04\n",
      "Epoch 804/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8786.1809 - recon_loss: 3.0609e-04 - KL loss: 145.5030 - beta: 1.8821e-04 - val_val_loss: 8714.9746 - val_val_recon_loss: 3.0369e-04 - val_val_KL loss: 141.9438 - val_beta: 1.8821e-04\n",
      "Epoch 805/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8660.7822 - recon_loss: 3.0176e-04 - KL loss: 142.3120 - beta: 1.8821e-04 - val_val_loss: 8881.0205 - val_val_recon_loss: 3.0938e-04 - val_val_KL loss: 147.3856 - val_beta: 1.8821e-04\n",
      "Epoch 806/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8644.6820 - recon_loss: 3.0111e-04 - KL loss: 144.4958 - beta: 1.8821e-04 - val_val_loss: 8970.0752 - val_val_recon_loss: 3.1250e-04 - val_val_KL loss: 148.2917 - val_beta: 1.8821e-04\n",
      "Epoch 807/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 8783.1169 - recon_loss: 3.0589e-04 - KL loss: 147.9910 - beta: 1.8821e-04 - val_val_loss: 9020.8740 - val_val_recon_loss: 3.1440e-04 - val_val_KL loss: 145.7129 - val_beta: 1.8821e-04\n",
      "Epoch 808/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 9153.7325 - recon_loss: 3.1894e-04 - KL loss: 150.2759 - beta: 1.8821e-04 - val_val_loss: 9606.5527 - val_val_recon_loss: 3.3464e-04 - val_val_KL loss: 159.9084 - val_beta: 1.8821e-04\n",
      "Epoch 809/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9474.2537 - recon_loss: 3.3006e-04 - KL loss: 156.9918 - beta: 1.8821e-04\n",
      "Epoch 00809: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 9474.2864 - recon_loss: 3.3006e-04 - KL loss: 156.9934 - beta: 1.8821e-04 - val_val_loss: 9490.1865 - val_val_recon_loss: 3.3052e-04 - val_val_KL loss: 159.7274 - val_beta: 1.8821e-04\n",
      "Epoch 810/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 9313.6948 - recon_loss: 3.2429e-04 - KL loss: 159.1545 - beta: 1.8821e-04 - val_val_loss: 9012.1953 - val_val_recon_loss: 3.1384e-04 - val_val_KL loss: 152.6553 - val_beta: 1.8821e-04\n",
      "Epoch 811/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 8900.5738 - recon_loss: 3.0983e-04 - KL loss: 154.3698 - beta: 1.8821e-04 - val_val_loss: 8958.0479 - val_val_recon_loss: 3.1171e-04 - val_val_KL loss: 158.7372 - val_beta: 1.8821e-04\n",
      "Epoch 812/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 8960.3873 - recon_loss: 3.1175e-04 - KL loss: 159.8263 - beta: 1.8821e-04 - val_val_loss: 9002.4404 - val_val_recon_loss: 3.1317e-04 - val_val_KL loss: 161.8598 - val_beta: 1.8821e-04\n",
      "Epoch 813/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 8987.7007 - recon_loss: 3.1270e-04 - KL loss: 160.2957 - beta: 1.8821e-04 - val_val_loss: 9065.2637 - val_val_recon_loss: 3.1541e-04 - val_val_KL loss: 161.4455 - val_beta: 1.8821e-04\n",
      "Epoch 814/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 9032.8043 - recon_loss: 3.1419e-04 - KL loss: 163.3644 - beta: 1.8821e-04\n",
      "Epoch 00814: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 9032.8269 - recon_loss: 3.1419e-04 - KL loss: 163.3644 - beta: 1.8821e-04 - val_val_loss: 9055.6562 - val_val_recon_loss: 3.1505e-04 - val_val_KL loss: 161.8716 - val_beta: 1.8821e-04\n",
      "Epoch 814/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2671.1607 - recon_loss: 3.1767e-04 - KL loss: 139.6631 - beta: 3.5424e-04 - val_val_loss: 2647.0181 - val_val_recon_loss: 3.1810e-04 - val_val_KL loss: 112.0914 - val_beta: 3.5424e-04\n",
      "Epoch 815/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2674.1779 - recon_loss: 3.2168e-04 - KL loss: 110.6967 - beta: 3.5424e-04 - val_val_loss: 2592.7842 - val_val_recon_loss: 3.1261e-04 - val_val_KL loss: 101.5751 - val_beta: 3.5424e-04\n",
      "Epoch 816/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2563.1162 - recon_loss: 3.0898e-04 - KL loss: 100.8492 - beta: 3.5424e-04 - val_val_loss: 2552.3596 - val_val_recon_loss: 3.0812e-04 - val_val_KL loss: 96.9504 - val_beta: 3.5424e-04\n",
      "Epoch 817/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2542.2832 - recon_loss: 3.0673e-04 - KL loss: 98.0097 - beta: 3.5424e-04 - val_val_loss: 2560.9094 - val_val_recon_loss: 3.0929e-04 - val_val_KL loss: 96.2304 - val_beta: 3.5424e-04\n",
      "Epoch 818/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2544.3519 - recon_loss: 3.0725e-04 - KL loss: 95.9130 - beta: 3.5424e-04 - val_val_loss: 2538.5266 - val_val_recon_loss: 3.0691e-04 - val_val_KL loss: 92.8125 - val_beta: 3.5424e-04\n",
      "Epoch 819/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2534.1573 - recon_loss: 3.0643e-04 - KL loss: 92.2312 - beta: 3.5424e-04 - val_val_loss: 2551.2197 - val_val_recon_loss: 3.0857e-04 - val_val_KL loss: 92.2178 - val_beta: 3.5424e-04\n",
      "Epoch 820/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2563.2699 - recon_loss: 3.1009e-04 - KL loss: 92.1890 - beta: 3.5424e-04 - val_val_loss: 2594.2832 - val_val_recon_loss: 3.1389e-04 - val_val_KL loss: 92.9342 - val_beta: 3.5424e-04\n",
      "Epoch 821/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2567.9216 - recon_loss: 3.1065e-04 - KL loss: 92.3614 - beta: 3.5424e-04 - val_val_loss: 2597.7798 - val_val_recon_loss: 3.1462e-04 - val_val_KL loss: 90.6049 - val_beta: 3.5424e-04\n",
      "Epoch 822/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2570.6575 - recon_loss: 3.1121e-04 - KL loss: 90.6154 - beta: 3.5424e-04 - val_val_loss: 2571.7642 - val_val_recon_loss: 3.1133e-04 - val_val_KL loss: 90.7621 - val_beta: 3.5424e-04\n",
      "Epoch 823/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2534.3025 - recon_loss: 3.0664e-04 - KL loss: 90.7306 - beta: 3.5424e-04\n",
      "Epoch 00823: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2534.3093 - recon_loss: 3.0664e-04 - KL loss: 90.7293 - beta: 3.5424e-04 - val_val_loss: 2547.3083 - val_val_recon_loss: 3.0871e-04 - val_val_KL loss: 87.2509 - val_beta: 3.5424e-04\n",
      "Epoch 824/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2483.0640 - recon_loss: 3.0049e-04 - KL loss: 88.4429 - beta: 3.5424e-04 - val_val_loss: 2529.3894 - val_val_recon_loss: 3.0633e-04 - val_val_KL loss: 88.2790 - val_beta: 3.5424e-04\n",
      "Epoch 825/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2465.7338 - recon_loss: 2.9822e-04 - KL loss: 89.2184 - beta: 3.5424e-04 - val_val_loss: 2474.5244 - val_val_recon_loss: 2.9957e-04 - val_val_KL loss: 87.2819 - val_beta: 3.5424e-04\n",
      "Epoch 826/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2445.0972 - recon_loss: 2.9572e-04 - KL loss: 88.4850 - beta: 3.5424e-04 - val_val_loss: 2450.6003 - val_val_recon_loss: 2.9653e-04 - val_val_KL loss: 87.6040 - val_beta: 3.5424e-04\n",
      "Epoch 827/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2421.8533 - recon_loss: 2.9290e-04 - KL loss: 87.7475 - beta: 3.5424e-04 - val_val_loss: 2451.1577 - val_val_recon_loss: 2.9672e-04 - val_val_KL loss: 86.6308 - val_beta: 3.5424e-04\n",
      "Epoch 828/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2421.6208 - recon_loss: 2.9291e-04 - KL loss: 87.4040 - beta: 3.5424e-04 - val_val_loss: 2481.9998 - val_val_recon_loss: 3.0053e-04 - val_val_KL loss: 87.0848 - val_beta: 3.5424e-04\n",
      "Epoch 829/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2459.1649 - recon_loss: 2.9756e-04 - KL loss: 87.8888 - beta: 3.5424e-04 - val_val_loss: 2465.0979 - val_val_recon_loss: 2.9834e-04 - val_val_KL loss: 87.6434 - val_beta: 3.5424e-04\n",
      "Epoch 830/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2429.4955 - recon_loss: 2.9389e-04 - KL loss: 87.5017 - beta: 3.5424e-04 - val_val_loss: 2482.7322 - val_val_recon_loss: 3.0041e-04 - val_val_KL loss: 88.7801 - val_beta: 3.5424e-04\n",
      "Epoch 831/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2448.4575 - recon_loss: 2.9611e-04 - KL loss: 88.7575 - beta: 3.5424e-04\n",
      "Epoch 00831: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2448.4378 - recon_loss: 2.9611e-04 - KL loss: 88.7571 - beta: 3.5424e-04 - val_val_loss: 2492.1348 - val_val_recon_loss: 3.0171e-04 - val_val_KL loss: 87.8416 - val_beta: 3.5424e-04\n",
      "Epoch 832/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2458.6369 - recon_loss: 2.9745e-04 - KL loss: 88.2765 - beta: 3.5424e-04 - val_val_loss: 2459.0728 - val_val_recon_loss: 2.9757e-04 - val_val_KL loss: 87.7156 - val_beta: 3.5424e-04\n",
      "Epoch 833/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2425.3032 - recon_loss: 2.9332e-04 - KL loss: 87.8401 - beta: 3.5424e-04 - val_val_loss: 2459.3491 - val_val_recon_loss: 2.9750e-04 - val_val_KL loss: 88.5678 - val_beta: 3.5424e-04\n",
      "Epoch 834/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2421.7421 - recon_loss: 2.9283e-04 - KL loss: 88.1630 - beta: 3.5424e-04 - val_val_loss: 2440.0146 - val_val_recon_loss: 2.9516e-04 - val_val_KL loss: 87.9085 - val_beta: 3.5424e-04\n",
      "Epoch 835/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2397.9272 - recon_loss: 2.8991e-04 - KL loss: 87.6698 - beta: 3.5424e-04 - val_val_loss: 2439.5969 - val_val_recon_loss: 2.9513e-04 - val_val_KL loss: 87.7506 - val_beta: 3.5424e-04\n",
      "Epoch 836/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2409.6742 - recon_loss: 2.9131e-04 - KL loss: 88.2096 - beta: 3.5424e-04 - val_val_loss: 2430.7358 - val_val_recon_loss: 2.9397e-04 - val_val_KL loss: 88.1280 - val_beta: 3.5424e-04\n",
      "Epoch 837/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2392.5366 - recon_loss: 2.8918e-04 - KL loss: 88.0868 - beta: 3.5424e-04 - val_val_loss: 2428.9443 - val_val_recon_loss: 2.9373e-04 - val_val_KL loss: 88.2589 - val_beta: 3.5424e-04\n",
      "Epoch 838/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2372.6026 - recon_loss: 2.8672e-04 - KL loss: 87.7748 - beta: 3.5424e-04 - val_val_loss: 2421.1257 - val_val_recon_loss: 2.9281e-04 - val_val_KL loss: 87.7471 - val_beta: 3.5424e-04\n",
      "Epoch 839/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2377.9861 - recon_loss: 2.8740e-04 - KL loss: 87.7404 - beta: 3.5424e-04 - val_val_loss: 2414.1265 - val_val_recon_loss: 2.9189e-04 - val_val_KL loss: 88.0672 - val_beta: 3.5424e-04\n",
      "Epoch 840/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2384.8154 - recon_loss: 2.8822e-04 - KL loss: 87.9728 - beta: 3.5424e-04 - val_val_loss: 2418.5300 - val_val_recon_loss: 2.9241e-04 - val_val_KL loss: 88.3051 - val_beta: 3.5424e-04\n",
      "Epoch 841/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2394.0915 - recon_loss: 2.8941e-04 - KL loss: 87.8014 - beta: 3.5424e-04 - val_val_loss: 2402.1157 - val_val_recon_loss: 2.9049e-04 - val_val_KL loss: 87.2023 - val_beta: 3.5424e-04\n",
      "Epoch 842/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2357.0481 - recon_loss: 2.8485e-04 - KL loss: 87.1211 - beta: 3.5424e-04 - val_val_loss: 2399.1523 - val_val_recon_loss: 2.9011e-04 - val_val_KL loss: 87.2614 - val_beta: 3.5424e-04\n",
      "Epoch 843/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2386.6119 - recon_loss: 2.8855e-04 - KL loss: 87.1759 - beta: 3.5424e-04 - val_val_loss: 2409.4646 - val_val_recon_loss: 2.9149e-04 - val_val_KL loss: 86.5634 - val_beta: 3.5424e-04\n",
      "Epoch 844/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2363.4540 - recon_loss: 2.8567e-04 - KL loss: 86.9620 - beta: 3.5424e-04 - val_val_loss: 2398.7700 - val_val_recon_loss: 2.9012e-04 - val_val_KL loss: 86.8167 - val_beta: 3.5424e-04\n",
      "Epoch 845/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2339.6671 - recon_loss: 2.8280e-04 - KL loss: 86.0905 - beta: 3.5424e-04 - val_val_loss: 2397.2698 - val_val_recon_loss: 2.8985e-04 - val_val_KL loss: 87.5062 - val_beta: 3.5424e-04\n",
      "Epoch 846/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2366.0219 - recon_loss: 2.8598e-04 - KL loss: 87.0712 - beta: 3.5424e-04 - val_val_loss: 2391.2214 - val_val_recon_loss: 2.8921e-04 - val_val_KL loss: 86.5069 - val_beta: 3.5424e-04\n",
      "Epoch 847/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2353.5599 - recon_loss: 2.8443e-04 - KL loss: 86.9204 - beta: 3.5424e-04 - val_val_loss: 2388.1860 - val_val_recon_loss: 2.8870e-04 - val_val_KL loss: 87.5783 - val_beta: 3.5424e-04\n",
      "Epoch 848/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2366.4228 - recon_loss: 2.8598e-04 - KL loss: 87.4272 - beta: 3.5424e-04 - val_val_loss: 2395.9680 - val_val_recon_loss: 2.8973e-04 - val_val_KL loss: 87.1620 - val_beta: 3.5424e-04\n",
      "Epoch 849/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2376.7562 - recon_loss: 2.8728e-04 - KL loss: 87.4244 - beta: 3.5424e-04 - val_val_loss: 2390.8701 - val_val_recon_loss: 2.8918e-04 - val_val_KL loss: 86.4151 - val_beta: 3.5424e-04\n",
      "Epoch 850/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2357.0765 - recon_loss: 2.8489e-04 - KL loss: 86.8127 - beta: 3.5424e-04 - val_val_loss: 2394.6973 - val_val_recon_loss: 2.8961e-04 - val_val_KL loss: 86.8397 - val_beta: 3.5424e-04\n",
      "Epoch 851/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2335.3009 - recon_loss: 2.8219e-04 - KL loss: 86.5331 - beta: 3.5424e-04 - val_val_loss: 2382.6167 - val_val_recon_loss: 2.8805e-04 - val_val_KL loss: 87.1356 - val_beta: 3.5424e-04\n",
      "Epoch 852/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2348.7810 - recon_loss: 2.8381e-04 - KL loss: 87.1033 - beta: 3.5424e-04 - val_val_loss: 2386.8049 - val_val_recon_loss: 2.8861e-04 - val_val_KL loss: 86.8660 - val_beta: 3.5424e-04\n",
      "Epoch 853/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2351.0511 - recon_loss: 2.8411e-04 - KL loss: 86.9927 - beta: 3.5424e-04 - val_val_loss: 2383.0454 - val_val_recon_loss: 2.8810e-04 - val_val_KL loss: 87.1881 - val_beta: 3.5424e-04\n",
      "Epoch 854/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2330.9636 - recon_loss: 2.8155e-04 - KL loss: 87.2758 - beta: 3.5424e-04 - val_val_loss: 2379.8889 - val_val_recon_loss: 2.8777e-04 - val_val_KL loss: 86.6921 - val_beta: 3.5424e-04\n",
      "Epoch 855/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2355.8078 - recon_loss: 2.8477e-04 - KL loss: 86.4900 - beta: 3.5424e-04 - val_val_loss: 2376.5945 - val_val_recon_loss: 2.8727e-04 - val_val_KL loss: 87.3621 - val_beta: 3.5424e-04\n",
      "Epoch 856/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2357.4793 - recon_loss: 2.8484e-04 - KL loss: 87.5795 - beta: 3.5424e-04 - val_val_loss: 2368.6392 - val_val_recon_loss: 2.8638e-04 - val_val_KL loss: 86.4713 - val_beta: 3.5424e-04\n",
      "Epoch 857/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2344.7898 - recon_loss: 2.8342e-04 - KL loss: 86.2208 - beta: 3.5424e-04 - val_val_loss: 2364.8730 - val_val_recon_loss: 2.8591e-04 - val_val_KL loss: 86.4903 - val_beta: 3.5424e-04\n",
      "Epoch 858/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2362.9388 - recon_loss: 2.8563e-04 - KL loss: 86.7693 - beta: 3.5424e-04 - val_val_loss: 2367.0544 - val_val_recon_loss: 2.8620e-04 - val_val_KL loss: 86.3501 - val_beta: 3.5424e-04\n",
      "Epoch 859/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2341.1269 - recon_loss: 2.8293e-04 - KL loss: 86.4730 - beta: 3.5424e-04 - val_val_loss: 2360.0168 - val_val_recon_loss: 2.8532e-04 - val_val_KL loss: 86.3359 - val_beta: 3.5424e-04\n",
      "Epoch 860/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2331.3244 - recon_loss: 2.8172e-04 - KL loss: 86.3533 - beta: 3.5424e-04 - val_val_loss: 2364.5601 - val_val_recon_loss: 2.8582e-04 - val_val_KL loss: 86.8813 - val_beta: 3.5424e-04\n",
      "Epoch 861/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2335.8178 - recon_loss: 2.8220e-04 - KL loss: 86.9942 - beta: 3.5424e-04 - val_val_loss: 2361.4863 - val_val_recon_loss: 2.8545e-04 - val_val_KL loss: 86.7186 - val_beta: 3.5424e-04\n",
      "Epoch 862/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2327.7069 - recon_loss: 2.8124e-04 - KL loss: 86.4858 - beta: 3.5424e-04 - val_val_loss: 2368.6323 - val_val_recon_loss: 2.8632e-04 - val_val_KL loss: 87.0042 - val_beta: 3.5424e-04\n",
      "Epoch 863/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2335.1988 - recon_loss: 2.8211e-04 - KL loss: 87.0850 - beta: 3.5424e-04 - val_val_loss: 2360.8235 - val_val_recon_loss: 2.8546e-04 - val_val_KL loss: 86.0206 - val_beta: 3.5424e-04\n",
      "Epoch 864/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2329.1875 - recon_loss: 2.8142e-04 - KL loss: 86.5281 - beta: 3.5424e-04 - val_val_loss: 2358.8474 - val_val_recon_loss: 2.8516e-04 - val_val_KL loss: 86.3860 - val_beta: 3.5424e-04\n",
      "Epoch 865/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2331.6838 - recon_loss: 2.8170e-04 - KL loss: 86.8206 - beta: 3.5424e-04 - val_val_loss: 2363.8406 - val_val_recon_loss: 2.8579e-04 - val_val_KL loss: 86.3713 - val_beta: 3.5424e-04\n",
      "Epoch 866/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2335.6829 - recon_loss: 2.8223e-04 - KL loss: 86.6303 - beta: 3.5424e-04 - val_val_loss: 2367.7600 - val_val_recon_loss: 2.8632e-04 - val_val_KL loss: 86.1247 - val_beta: 3.5424e-04\n",
      "Epoch 867/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2329.9298 - recon_loss: 2.8153e-04 - KL loss: 86.4244 - beta: 3.5424e-04 - val_val_loss: 2359.7085 - val_val_recon_loss: 2.8529e-04 - val_val_KL loss: 86.2355 - val_beta: 3.5424e-04\n",
      "Epoch 868/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2307.1230 - recon_loss: 2.7875e-04 - KL loss: 85.8089 - beta: 3.5424e-04 - val_val_loss: 2354.4312 - val_val_recon_loss: 2.8467e-04 - val_val_KL loss: 85.9310 - val_beta: 3.5424e-04\n",
      "Epoch 869/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2331.7553 - recon_loss: 2.8178e-04 - KL loss: 86.2391 - beta: 3.5424e-04 - val_val_loss: 2359.2542 - val_val_recon_loss: 2.8522e-04 - val_val_KL loss: 86.3842 - val_beta: 3.5424e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 870/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2332.3216 - recon_loss: 2.8177e-04 - KL loss: 86.9308 - beta: 3.5424e-04 - val_val_loss: 2361.6855 - val_val_recon_loss: 2.8556e-04 - val_val_KL loss: 86.0360 - val_beta: 3.5424e-04\n",
      "Epoch 871/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2319.6263 - recon_loss: 2.8028e-04 - KL loss: 86.0771 - beta: 3.5424e-04 - val_val_loss: 2358.6091 - val_val_recon_loss: 2.8514e-04 - val_val_KL loss: 86.3215 - val_beta: 3.5424e-04\n",
      "Epoch 872/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2324.0502 - recon_loss: 2.8078e-04 - KL loss: 86.5661 - beta: 3.5424e-04 - val_val_loss: 2358.6531 - val_val_recon_loss: 2.8506e-04 - val_val_KL loss: 86.9938 - val_beta: 3.5424e-04\n",
      "Epoch 873/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2331.8936 - recon_loss: 2.8173e-04 - KL loss: 86.7872 - beta: 3.5424e-04\n",
      "Epoch 00873: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2331.8907 - recon_loss: 2.8173e-04 - KL loss: 86.7873 - beta: 3.5424e-04 - val_val_loss: 2360.2681 - val_val_recon_loss: 2.8538e-04 - val_val_KL loss: 86.0843 - val_beta: 3.5424e-04\n",
      "Epoch 874/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2299.9712 - recon_loss: 2.7780e-04 - KL loss: 86.2036 - beta: 3.5424e-04 - val_val_loss: 2353.1663 - val_val_recon_loss: 2.8444e-04 - val_val_KL loss: 86.4907 - val_beta: 3.5424e-04\n",
      "Epoch 875/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2335.6769 - recon_loss: 2.8219e-04 - KL loss: 86.9556 - beta: 3.5424e-04 - val_val_loss: 2349.8425 - val_val_recon_loss: 2.8402e-04 - val_val_KL loss: 86.5271 - val_beta: 3.5424e-04\n",
      "Epoch 876/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2332.4705 - recon_loss: 2.8177e-04 - KL loss: 87.0940 - beta: 3.5424e-04 - val_val_loss: 2348.8218 - val_val_recon_loss: 2.8387e-04 - val_val_KL loss: 86.6440 - val_beta: 3.5424e-04\n",
      "Epoch 877/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2310.6819 - recon_loss: 2.7907e-04 - KL loss: 86.8005 - beta: 3.5424e-04 - val_val_loss: 2358.0439 - val_val_recon_loss: 2.8502e-04 - val_val_KL loss: 86.7041 - val_beta: 3.5424e-04\n",
      "Epoch 878/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2320.1942 - recon_loss: 2.8024e-04 - KL loss: 86.9743 - beta: 3.5424e-04 - val_val_loss: 2357.9236 - val_val_recon_loss: 2.8500e-04 - val_val_KL loss: 86.8090 - val_beta: 3.5424e-04\n",
      "Epoch 879/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2328.3351 - recon_loss: 2.8124e-04 - KL loss: 87.1297 - beta: 3.5424e-04 - val_val_loss: 2355.1152 - val_val_recon_loss: 2.8465e-04 - val_val_KL loss: 86.7935 - val_beta: 3.5424e-04\n",
      "Epoch 880/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2298.3385 - recon_loss: 2.7754e-04 - KL loss: 86.6119 - beta: 3.5424e-04 - val_val_loss: 2354.8269 - val_val_recon_loss: 2.8461e-04 - val_val_KL loss: 86.7986 - val_beta: 3.5424e-04\n",
      "Epoch 881/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2324.8699 - recon_loss: 2.8085e-04 - KL loss: 86.7852 - beta: 3.5424e-04\n",
      "Epoch 00881: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2324.8711 - recon_loss: 2.8085e-04 - KL loss: 86.7854 - beta: 3.5424e-04 - val_val_loss: 2357.9707 - val_val_recon_loss: 2.8504e-04 - val_val_KL loss: 86.5352 - val_beta: 3.5424e-04\n",
      "Epoch 882/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2300.1724 - recon_loss: 2.7777e-04 - KL loss: 86.6208 - beta: 3.5424e-04 - val_val_loss: 2356.1804 - val_val_recon_loss: 2.8478e-04 - val_val_KL loss: 86.7643 - val_beta: 3.5424e-04\n",
      "Epoch 883/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2317.3035 - recon_loss: 2.7990e-04 - KL loss: 86.8207 - beta: 3.5424e-04 - val_val_loss: 2356.3674 - val_val_recon_loss: 2.8480e-04 - val_val_KL loss: 86.8400 - val_beta: 3.5424e-04\n",
      "Epoch 884/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2308.8723 - recon_loss: 2.7884e-04 - KL loss: 86.8022 - beta: 3.5424e-04 - val_val_loss: 2355.0422 - val_val_recon_loss: 2.8463e-04 - val_val_KL loss: 86.8474 - val_beta: 3.5424e-04\n",
      "Epoch 885/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2296.2479 - recon_loss: 2.7725e-04 - KL loss: 86.8329 - beta: 3.5424e-04 - val_val_loss: 2354.1375 - val_val_recon_loss: 2.8453e-04 - val_val_KL loss: 86.7716 - val_beta: 3.5424e-04\n",
      "Epoch 886/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2310.5669 - recon_loss: 2.7908e-04 - KL loss: 86.5801 - beta: 3.5424e-04\n",
      "Epoch 00886: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2310.5663 - recon_loss: 2.7908e-04 - KL loss: 86.5802 - beta: 3.5424e-04 - val_val_loss: 2352.9355 - val_val_recon_loss: 2.8438e-04 - val_val_KL loss: 86.7297 - val_beta: 3.5424e-04\n",
      "Epoch 886/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 715.9178 - recon_loss: 2.8617e-04 - KL loss: 72.1642 - beta: 6.6673e-04 - val_val_loss: 742.3240 - val_val_recon_loss: 3.0180e-04 - val_val_KL loss: 63.4119 - val_beta: 6.6673e-04\n",
      "Epoch 887/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 722.2794 - recon_loss: 2.9308e-04 - KL loss: 62.9667 - beta: 6.6673e-04 - val_val_loss: 734.4524 - val_val_recon_loss: 2.9953e-04 - val_val_KL loss: 60.6342 - val_beta: 6.6673e-04\n",
      "Epoch 888/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 721.3537 - recon_loss: 2.9414e-04 - KL loss: 59.6723 - beta: 6.6673e-04 - val_val_loss: 727.4402 - val_val_recon_loss: 2.9742e-04 - val_val_KL loss: 58.3781 - val_beta: 6.6673e-04\n",
      "Epoch 889/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 725.0393 - recon_loss: 2.9652e-04 - KL loss: 57.9840 - beta: 6.6673e-04 - val_val_loss: 752.6011 - val_val_recon_loss: 3.0949e-04 - val_val_KL loss: 56.3808 - val_beta: 6.6673e-04\n",
      "Epoch 890/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 736.7233 - recon_loss: 3.0223e-04 - KL loss: 56.8302 - beta: 6.6673e-04 - val_val_loss: 759.3339 - val_val_recon_loss: 3.1303e-04 - val_val_KL loss: 55.1577 - val_beta: 6.6673e-04\n",
      "Epoch 891/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 737.7542 - recon_loss: 3.0304e-04 - KL loss: 56.0397 - beta: 6.6673e-04 - val_val_loss: 737.5136 - val_val_recon_loss: 3.0317e-04 - val_val_KL loss: 55.5188 - val_beta: 6.6673e-04\n",
      "Epoch 892/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 726.2503 - recon_loss: 2.9835e-04 - KL loss: 55.0909 - beta: 6.6673e-04 - val_val_loss: 733.8825 - val_val_recon_loss: 3.0160e-04 - val_val_KL loss: 55.4003 - val_beta: 6.6673e-04\n",
      "Epoch 893/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 719.0835 - recon_loss: 2.9539e-04 - KL loss: 54.5843 - beta: 6.6673e-04\n",
      "Epoch 00893: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 719.0808 - recon_loss: 2.9539e-04 - KL loss: 54.5837 - beta: 6.6673e-04 - val_val_loss: 727.4455 - val_val_recon_loss: 2.9946e-04 - val_val_KL loss: 53.7769 - val_beta: 6.6673e-04\n",
      "Epoch 894/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 708.2153 - recon_loss: 2.9101e-04 - KL loss: 53.5606 - beta: 6.6673e-04 - val_val_loss: 706.9704 - val_val_recon_loss: 2.9036e-04 - val_val_KL loss: 53.7862 - val_beta: 6.6673e-04\n",
      "Epoch 895/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 707.1851 - recon_loss: 2.9042e-04 - KL loss: 53.8534 - beta: 6.6673e-04 - val_val_loss: 707.4611 - val_val_recon_loss: 2.9090e-04 - val_val_KL loss: 53.0627 - val_beta: 6.6673e-04\n",
      "Epoch 896/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 704.9109 - recon_loss: 2.8940e-04 - KL loss: 53.8760 - beta: 6.6673e-04 - val_val_loss: 709.2504 - val_val_recon_loss: 2.9171e-04 - val_val_KL loss: 53.0215 - val_beta: 6.6673e-04\n",
      "Epoch 897/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 695.8292 - recon_loss: 2.8572e-04 - KL loss: 53.0836 - beta: 6.6673e-04 - val_val_loss: 705.1111 - val_val_recon_loss: 2.8997e-04 - val_val_KL loss: 52.8032 - val_beta: 6.6673e-04\n",
      "Epoch 898/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 696.9754 - recon_loss: 2.8632e-04 - KL loss: 52.8795 - beta: 6.6673e-04 - val_val_loss: 702.9266 - val_val_recon_loss: 2.8907e-04 - val_val_KL loss: 52.6333 - val_beta: 6.6673e-04\n",
      "Epoch 899/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 695.8745 - recon_loss: 2.8590e-04 - KL loss: 52.7123 - beta: 6.6673e-04 - val_val_loss: 713.1071 - val_val_recon_loss: 2.9374e-04 - val_val_KL loss: 52.3062 - val_beta: 6.6673e-04\n",
      "Epoch 900/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 697.7516 - recon_loss: 2.8680e-04 - KL loss: 52.5733 - beta: 6.6673e-04 - val_val_loss: 705.8062 - val_val_recon_loss: 2.9022e-04 - val_val_KL loss: 52.9311 - val_beta: 6.6673e-04\n",
      "Epoch 901/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 697.7219 - recon_loss: 2.8660e-04 - KL loss: 52.9953 - beta: 6.6673e-04 - val_val_loss: 705.6599 - val_val_recon_loss: 2.9020e-04 - val_val_KL loss: 52.8309 - val_beta: 6.6673e-04\n",
      "Epoch 902/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 701.4650 - recon_loss: 2.8822e-04 - KL loss: 53.0961 - beta: 6.6673e-04 - val_val_loss: 703.7980 - val_val_recon_loss: 2.8929e-04 - val_val_KL loss: 53.0138 - val_beta: 6.6673e-04\n",
      "Epoch 903/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 698.7612 - recon_loss: 2.8692e-04 - KL loss: 53.3086 - beta: 6.6673e-04\n",
      "Epoch 00903: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 698.7587 - recon_loss: 2.8692e-04 - KL loss: 53.3083 - beta: 6.6673e-04 - val_val_loss: 705.3010 - val_val_recon_loss: 2.9004e-04 - val_val_KL loss: 52.8436 - val_beta: 6.6673e-04\n",
      "Epoch 904/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 694.8902 - recon_loss: 2.8542e-04 - KL loss: 52.8265 - beta: 6.6673e-04 - val_val_loss: 698.1407 - val_val_recon_loss: 2.8683e-04 - val_val_KL loss: 52.8894 - val_beta: 6.6673e-04\n",
      "Epoch 905/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 685.9371 - recon_loss: 2.8147e-04 - KL loss: 52.7435 - beta: 6.6673e-04 - val_val_loss: 696.4523 - val_val_recon_loss: 2.8632e-04 - val_val_KL loss: 52.3634 - val_beta: 6.6673e-04\n",
      "Epoch 906/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 686.7743 - recon_loss: 2.8191e-04 - KL loss: 52.5956 - beta: 6.6673e-04 - val_val_loss: 695.7240 - val_val_recon_loss: 2.8609e-04 - val_val_KL loss: 52.1324 - val_beta: 6.6673e-04\n",
      "Epoch 907/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 689.1829 - recon_loss: 2.8304e-04 - KL loss: 52.4575 - beta: 6.6673e-04 - val_val_loss: 696.3543 - val_val_recon_loss: 2.8634e-04 - val_val_KL loss: 52.2012 - val_beta: 6.6673e-04\n",
      "Epoch 908/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 693.1333 - recon_loss: 2.8466e-04 - KL loss: 52.7590 - beta: 6.6673e-04 - val_val_loss: 695.9769 - val_val_recon_loss: 2.8614e-04 - val_val_KL loss: 52.2896 - val_beta: 6.6673e-04\n",
      "Epoch 909/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 685.4716 - recon_loss: 2.8142e-04 - KL loss: 52.3953 - beta: 6.6673e-04 - val_val_loss: 694.3415 - val_val_recon_loss: 2.8538e-04 - val_val_KL loss: 52.3667 - val_beta: 6.6673e-04\n",
      "Epoch 910/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 687.3507 - recon_loss: 2.8225e-04 - KL loss: 52.4160 - beta: 6.6673e-04 - val_val_loss: 693.6912 - val_val_recon_loss: 2.8506e-04 - val_val_KL loss: 52.4362 - val_beta: 6.6673e-04\n",
      "Epoch 911/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 685.5660 - recon_loss: 2.8144e-04 - KL loss: 52.4491 - beta: 6.6673e-04 - val_val_loss: 693.7411 - val_val_recon_loss: 2.8524e-04 - val_val_KL loss: 52.0671 - val_beta: 6.6673e-04\n",
      "Epoch 912/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 680.9584 - recon_loss: 2.7942e-04 - KL loss: 52.3867 - beta: 6.6673e-04 - val_val_loss: 694.6353 - val_val_recon_loss: 2.8547e-04 - val_val_KL loss: 52.4501 - val_beta: 6.6673e-04\n",
      "Epoch 913/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 679.3100 - recon_loss: 2.7873e-04 - KL loss: 52.2744 - beta: 6.6673e-04 - val_val_loss: 694.3795 - val_val_recon_loss: 2.8544e-04 - val_val_KL loss: 52.2698 - val_beta: 6.6673e-04\n",
      "Epoch 914/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 690.1779 - recon_loss: 2.8341e-04 - KL loss: 52.6195 - beta: 6.6673e-04 - val_val_loss: 696.8678 - val_val_recon_loss: 2.8653e-04 - val_val_KL loss: 52.2940 - val_beta: 6.6673e-04\n",
      "Epoch 915/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 686.6936 - recon_loss: 2.8199e-04 - KL loss: 52.3314 - beta: 6.6673e-04\n",
      "Epoch 00915: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 686.6927 - recon_loss: 2.8199e-04 - KL loss: 52.3314 - beta: 6.6673e-04 - val_val_loss: 696.7360 - val_val_recon_loss: 2.8647e-04 - val_val_KL loss: 52.2943 - val_beta: 6.6673e-04\n",
      "Epoch 916/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 684.8313 - recon_loss: 2.8117e-04 - KL loss: 52.3077 - beta: 6.6673e-04 - val_val_loss: 694.6080 - val_val_recon_loss: 2.8552e-04 - val_val_KL loss: 52.3117 - val_beta: 6.6673e-04\n",
      "Epoch 917/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 686.9765 - recon_loss: 2.8203e-04 - KL loss: 52.5301 - beta: 6.6673e-04 - val_val_loss: 694.9662 - val_val_recon_loss: 2.8561e-04 - val_val_KL loss: 52.4583 - val_beta: 6.6673e-04\n",
      "Epoch 918/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 684.6950 - recon_loss: 2.8099e-04 - KL loss: 52.5790 - beta: 6.6673e-04 - val_val_loss: 696.0246 - val_val_recon_loss: 2.8613e-04 - val_val_KL loss: 52.3497 - val_beta: 6.6673e-04\n",
      "Epoch 919/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 686.7847 - recon_loss: 2.8206e-04 - KL loss: 52.2716 - beta: 6.6673e-04 - val_val_loss: 694.5257 - val_val_recon_loss: 2.8557e-04 - val_val_KL loss: 52.1199 - val_beta: 6.6673e-04\n",
      "Epoch 920/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 684.7459 - recon_loss: 2.8112e-04 - KL loss: 52.3447 - beta: 6.6673e-04\n",
      "Epoch 00920: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 684.7464 - recon_loss: 2.8112e-04 - KL loss: 52.3447 - beta: 6.6673e-04 - val_val_loss: 694.5232 - val_val_recon_loss: 2.8543e-04 - val_val_KL loss: 52.4222 - val_beta: 6.6673e-04\n",
      "Epoch 920/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 228.1611 - recon_loss: 2.8923e-04 - KL loss: 44.4889 - beta: 0.0013 - val_val_loss: 229.7703 - val_val_recon_loss: 2.9896e-04 - val_val_KL loss: 39.9220 - val_beta: 0.0013\n",
      "Epoch 921/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 227.9769 - recon_loss: 2.9625e-04 - KL loss: 39.8438 - beta: 0.0013 - val_val_loss: 230.0675 - val_val_recon_loss: 3.0367e-04 - val_val_KL loss: 37.2242 - val_beta: 0.0013\n",
      "Epoch 922/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 228.7908 - recon_loss: 3.0161e-04 - KL loss: 37.2546 - beta: 0.0013 - val_val_loss: 230.7031 - val_val_recon_loss: 3.0599e-04 - val_val_KL loss: 36.3870 - val_beta: 0.0013\n",
      "Epoch 923/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 225.6735 - recon_loss: 2.9861e-04 - KL loss: 36.0428 - beta: 0.0013 - val_val_loss: 227.1661 - val_val_recon_loss: 3.0204e-04 - val_val_KL loss: 35.3595 - val_beta: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 924/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 227.9508 - recon_loss: 3.0360e-04 - KL loss: 35.1542 - beta: 0.0013 - val_val_loss: 226.2829 - val_val_recon_loss: 3.0218e-04 - val_val_KL loss: 34.3893 - val_beta: 0.0013\n",
      "Epoch 925/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 231.6893 - recon_loss: 3.0988e-04 - KL loss: 34.9044 - beta: 0.0013 - val_val_loss: 230.6033 - val_val_recon_loss: 3.0943e-04 - val_val_KL loss: 34.1046 - val_beta: 0.0013\n",
      "Epoch 926/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 230.2135 - recon_loss: 3.0852e-04 - KL loss: 34.2909 - beta: 0.0013 - val_val_loss: 235.5328 - val_val_recon_loss: 3.1849e-04 - val_val_KL loss: 33.2770 - val_beta: 0.0013\n",
      "Epoch 927/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 225.6491 - recon_loss: 3.0229e-04 - KL loss: 33.6803 - beta: 0.0013 - val_val_loss: 227.6791 - val_val_recon_loss: 3.0565e-04 - val_val_KL loss: 33.5798 - val_beta: 0.0013\n",
      "Epoch 928/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 223.7753 - recon_loss: 2.9977e-04 - KL loss: 33.4102 - beta: 0.0013 - val_val_loss: 224.9149 - val_val_recon_loss: 3.0224e-04 - val_val_KL loss: 32.9812 - val_beta: 0.0013\n",
      "Epoch 929/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 229.6028 - recon_loss: 3.0970e-04 - KL loss: 32.9314 - beta: 0.0013 - val_val_loss: 227.1497 - val_val_recon_loss: 3.0596e-04 - val_val_KL loss: 32.8509 - val_beta: 0.0013\n",
      "Epoch 930/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 222.8938 - recon_loss: 2.9962e-04 - KL loss: 32.6256 - beta: 0.0013 - val_val_loss: 226.0332 - val_val_recon_loss: 3.0512e-04 - val_val_KL loss: 32.2684 - val_beta: 0.0013\n",
      "Epoch 931/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 223.7367 - recon_loss: 3.0121e-04 - KL loss: 32.4548 - beta: 0.0013 - val_val_loss: 232.0871 - val_val_recon_loss: 3.1398e-04 - val_val_KL loss: 32.6987 - val_beta: 0.0013\n",
      "Epoch 932/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 233.7385 - recon_loss: 3.1618e-04 - KL loss: 32.9502 - beta: 0.0013 - val_val_loss: 245.5828 - val_val_recon_loss: 3.3446e-04 - val_val_KL loss: 33.1847 - val_beta: 0.0013\n",
      "Epoch 933/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 239.8349 - recon_loss: 3.2551e-04 - KL loss: 33.1258 - beta: 0.0013\n",
      "Epoch 00933: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 239.8335 - recon_loss: 3.2550e-04 - KL loss: 33.1256 - beta: 0.0013 - val_val_loss: 237.3039 - val_val_recon_loss: 3.2262e-04 - val_val_KL loss: 32.4290 - val_beta: 0.0013\n",
      "Epoch 934/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 230.2299 - recon_loss: 3.1093e-04 - KL loss: 32.7752 - beta: 0.0013 - val_val_loss: 232.1465 - val_val_recon_loss: 3.1370e-04 - val_val_KL loss: 32.9372 - val_beta: 0.0013\n",
      "Epoch 935/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 229.0024 - recon_loss: 3.0894e-04 - KL loss: 32.8117 - beta: 0.0013 - val_val_loss: 233.7412 - val_val_recon_loss: 3.1619e-04 - val_val_KL loss: 32.9460 - val_beta: 0.0013\n",
      "Epoch 936/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 231.1023 - recon_loss: 3.1206e-04 - KL loss: 32.9291 - beta: 0.0013 - val_val_loss: 229.8429 - val_val_recon_loss: 3.1010e-04 - val_val_KL loss: 32.9150 - val_beta: 0.0013\n",
      "Epoch 937/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 229.1739 - recon_loss: 3.0921e-04 - KL loss: 32.8115 - beta: 0.0013 - val_val_loss: 228.8979 - val_val_recon_loss: 3.0936e-04 - val_val_KL loss: 32.4413 - val_beta: 0.0013\n",
      "Epoch 938/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 225.6819 - recon_loss: 3.0459e-04 - KL loss: 32.2537 - beta: 0.0013\n",
      "Epoch 00938: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 225.6808 - recon_loss: 3.0459e-04 - KL loss: 32.2537 - beta: 0.0013 - val_val_loss: 226.6530 - val_val_recon_loss: 3.0617e-04 - val_val_KL loss: 32.2257 - val_beta: 0.0013\n",
      "Epoch 938/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 84.1915 - recon_loss: 3.1828e-04 - KL loss: 27.1337 - beta: 0.0024 - val_val_loss: 83.5073 - val_val_recon_loss: 3.2637e-04 - val_val_KL loss: 24.9992 - val_beta: 0.0024\n",
      "Epoch 939/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 82.5744 - recon_loss: 3.2154e-04 - KL loss: 24.9320 - beta: 0.0024 - val_val_loss: 83.4404 - val_val_recon_loss: 3.3015e-04 - val_val_KL loss: 24.2554 - val_beta: 0.0024\n",
      "Epoch 940/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83.1828 - recon_loss: 3.2883e-04 - KL loss: 24.2349 - beta: 0.0024 - val_val_loss: 84.1479 - val_val_recon_loss: 3.3651e-04 - val_val_KL loss: 23.8225 - val_beta: 0.0024\n",
      "Epoch 941/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 82.5168 - recon_loss: 3.2833e-04 - KL loss: 23.6571 - beta: 0.0024 - val_val_loss: 84.2472 - val_val_recon_loss: 3.3810e-04 - val_val_KL loss: 23.6374 - val_beta: 0.0024\n",
      "Epoch 942/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83.7830 - recon_loss: 3.3648e-04 - KL loss: 23.4629 - beta: 0.0024 - val_val_loss: 83.3915 - val_val_recon_loss: 3.3592e-04 - val_val_KL loss: 23.1714 - val_beta: 0.0024\n",
      "Epoch 943/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83.0746 - recon_loss: 3.3449e-04 - KL loss: 23.1109 - beta: 0.0024 - val_val_loss: 83.0524 - val_val_recon_loss: 3.3600e-04 - val_val_KL loss: 22.8179 - val_beta: 0.0024\n",
      "Epoch 944/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83.3967 - recon_loss: 3.3730e-04 - KL loss: 22.9292 - beta: 0.0024 - val_val_loss: 83.9561 - val_val_recon_loss: 3.4279e-04 - val_val_KL loss: 22.5047 - val_beta: 0.0024\n",
      "Epoch 945/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 82.8413 - recon_loss: 3.3607e-04 - KL loss: 22.5952 - beta: 0.0024 - val_val_loss: 83.9339 - val_val_recon_loss: 3.4256e-04 - val_val_KL loss: 22.5241 - val_beta: 0.0024\n",
      "Epoch 946/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83.7385 - recon_loss: 3.4133e-04 - KL loss: 22.5487 - beta: 0.0024 - val_val_loss: 83.7744 - val_val_recon_loss: 3.4289e-04 - val_val_KL loss: 22.3045 - val_beta: 0.0024\n",
      "Epoch 947/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83.2806 - recon_loss: 3.3953e-04 - KL loss: 22.4143 - beta: 0.0024 - val_val_loss: 82.7921 - val_val_recon_loss: 3.3815e-04 - val_val_KL loss: 22.1724 - val_beta: 0.0024\n",
      "Epoch 948/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 82.5678 - recon_loss: 3.3625e-04 - KL loss: 22.2899 - beta: 0.0024 - val_val_loss: 84.5265 - val_val_recon_loss: 3.4810e-04 - val_val_KL loss: 22.1234 - val_beta: 0.0024\n",
      "Epoch 949/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81.8050 - recon_loss: 3.3331e-04 - KL loss: 22.0540 - beta: 0.0024 - val_val_loss: 82.9227 - val_val_recon_loss: 3.3940e-04 - val_val_KL loss: 22.0795 - val_beta: 0.0024\n",
      "Epoch 950/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81.9319 - recon_loss: 3.3409e-04 - KL loss: 22.0397 - beta: 0.0024 - val_val_loss: 82.6405 - val_val_recon_loss: 3.3847e-04 - val_val_KL loss: 21.9631 - val_beta: 0.0024\n",
      "Epoch 951/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 82.2357 - recon_loss: 3.3421e-04 - KL loss: 22.3225 - beta: 0.0024 - val_val_loss: 82.7133 - val_val_recon_loss: 3.3780e-04 - val_val_KL loss: 22.1570 - val_beta: 0.0024\n",
      "Epoch 952/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 81.9324 - recon_loss: 3.3320e-04 - KL loss: 22.2012 - beta: 0.0024 - val_val_loss: 82.2035 - val_val_recon_loss: 3.3548e-04 - val_val_KL loss: 22.0622 - val_beta: 0.0024\n",
      "Epoch 953/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81.5174 - recon_loss: 3.3246e-04 - KL loss: 21.9189 - beta: 0.0024 - val_val_loss: 81.6732 - val_val_recon_loss: 3.3371e-04 - val_val_KL loss: 21.8493 - val_beta: 0.0024\n",
      "Epoch 954/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.6288 - recon_loss: 3.2765e-04 - KL loss: 21.8918 - beta: 0.0024 - val_val_loss: 80.4265 - val_val_recon_loss: 3.2621e-04 - val_val_KL loss: 21.9486 - val_beta: 0.0024\n",
      "Epoch 955/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.6313 - recon_loss: 3.2784e-04 - KL loss: 21.8606 - beta: 0.0024 - val_val_loss: 80.8029 - val_val_recon_loss: 3.2776e-04 - val_val_KL loss: 22.0465 - val_beta: 0.0024\n",
      "Epoch 956/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.2387 - recon_loss: 3.2641e-04 - KL loss: 21.7250 - beta: 0.0024 - val_val_loss: 80.4581 - val_val_recon_loss: 3.2749e-04 - val_val_KL loss: 21.7493 - val_beta: 0.0024\n",
      "Epoch 957/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81.0763 - recon_loss: 3.3117e-04 - KL loss: 21.7088 - beta: 0.0024 - val_val_loss: 81.0441 - val_val_recon_loss: 3.2961e-04 - val_val_KL loss: 21.9559 - val_beta: 0.0024\n",
      "Epoch 958/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.4641 - recon_loss: 3.2710e-04 - KL loss: 21.8258 - beta: 0.0024 - val_val_loss: 79.6327 - val_val_recon_loss: 3.2231e-04 - val_val_KL loss: 21.8537 - val_beta: 0.0024\n",
      "Epoch 959/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79.2368 - recon_loss: 3.2081e-04 - KL loss: 21.7266 - beta: 0.0024 - val_val_loss: 80.8490 - val_val_recon_loss: 3.2774e-04 - val_val_KL loss: 22.0951 - val_beta: 0.0024\n",
      "Epoch 960/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.6992 - recon_loss: 3.2868e-04 - KL loss: 21.7783 - beta: 0.0024 - val_val_loss: 80.1884 - val_val_recon_loss: 3.2632e-04 - val_val_KL loss: 21.6898 - val_beta: 0.0024\n",
      "Epoch 961/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79.6188 - recon_loss: 3.2336e-04 - KL loss: 21.6514 - beta: 0.0024 - val_val_loss: 79.5009 - val_val_recon_loss: 3.2290e-04 - val_val_KL loss: 21.6150 - val_beta: 0.0024\n",
      "Epoch 962/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78.7738 - recon_loss: 3.1849e-04 - KL loss: 21.6796 - beta: 0.0024 - val_val_loss: 80.5079 - val_val_recon_loss: 3.2855e-04 - val_val_KL loss: 21.6102 - val_beta: 0.0024\n",
      "Epoch 963/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 79.0878 - recon_loss: 3.2065e-04 - KL loss: 21.6058 - beta: 0.0024 - val_val_loss: 80.0961 - val_val_recon_loss: 3.2595e-04 - val_val_KL loss: 21.6636 - val_beta: 0.0024\n",
      "Epoch 964/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.0841 - recon_loss: 3.2602e-04 - KL loss: 21.6394 - beta: 0.0024 - val_val_loss: 79.6458 - val_val_recon_loss: 3.2327e-04 - val_val_KL loss: 21.6943 - val_beta: 0.0024\n",
      "Epoch 965/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79.3461 - recon_loss: 3.2212e-04 - KL loss: 21.6013 - beta: 0.0024 - val_val_loss: 80.7482 - val_val_recon_loss: 3.3105e-04 - val_val_KL loss: 21.4024 - val_beta: 0.0024\n",
      "Epoch 966/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78.9388 - recon_loss: 3.2033e-04 - KL loss: 21.5146 - beta: 0.0024 - val_val_loss: 78.7953 - val_val_recon_loss: 3.1970e-04 - val_val_KL loss: 21.4835 - val_beta: 0.0024\n",
      "Epoch 967/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79.9699 - recon_loss: 3.2559e-04 - KL loss: 21.6027 - beta: 0.0024 - val_val_loss: 81.8386 - val_val_recon_loss: 3.3649e-04 - val_val_KL loss: 21.5176 - val_beta: 0.0024\n",
      "Epoch 968/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.4011 - recon_loss: 3.2787e-04 - KL loss: 21.6250 - beta: 0.0024 - val_val_loss: 83.3156 - val_val_recon_loss: 3.4805e-04 - val_val_KL loss: 20.9213 - val_beta: 0.0024\n",
      "Epoch 969/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79.4864 - recon_loss: 3.2353e-04 - KL loss: 21.4888 - beta: 0.0024 - val_val_loss: 79.4290 - val_val_recon_loss: 3.2314e-04 - val_val_KL loss: 21.5006 - val_beta: 0.0024\n",
      "Epoch 970/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80.5435 - recon_loss: 3.2879e-04 - KL loss: 21.6027 - beta: 0.0024 - val_val_loss: 79.6409 - val_val_recon_loss: 3.2334e-04 - val_val_KL loss: 21.6766 - val_beta: 0.0024\n",
      "Epoch 971/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 79.3035 - recon_loss: 3.2200e-04 - KL loss: 21.5797 - beta: 0.0024\n",
      "Epoch 00971: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79.3036 - recon_loss: 3.2200e-04 - KL loss: 21.5797 - beta: 0.0024 - val_val_loss: 80.1811 - val_val_recon_loss: 3.2820e-04 - val_val_KL loss: 21.3448 - val_beta: 0.0024\n",
      "Epoch 972/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78.1254 - recon_loss: 3.1546e-04 - KL loss: 21.5732 - beta: 0.0024 - val_val_loss: 78.3573 - val_val_recon_loss: 3.1696e-04 - val_val_KL loss: 21.5360 - val_beta: 0.0024\n",
      "Epoch 973/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77.5546 - recon_loss: 3.1164e-04 - KL loss: 21.6870 - beta: 0.0024 - val_val_loss: 78.3505 - val_val_recon_loss: 3.1600e-04 - val_val_KL loss: 21.7028 - val_beta: 0.0024\n",
      "Epoch 974/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 77.8825 - recon_loss: 3.1350e-04 - KL loss: 21.6817 - beta: 0.0024 - val_val_loss: 77.9149 - val_val_recon_loss: 3.1395e-04 - val_val_KL loss: 21.6337 - val_beta: 0.0024\n",
      "Epoch 975/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77.7414 - recon_loss: 3.1262e-04 - KL loss: 21.6984 - beta: 0.0024 - val_val_loss: 78.2411 - val_val_recon_loss: 3.1478e-04 - val_val_KL loss: 21.8117 - val_beta: 0.0024\n",
      "Epoch 976/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77.6114 - recon_loss: 3.1188e-04 - KL loss: 21.7011 - beta: 0.0024 - val_val_loss: 78.6104 - val_val_recon_loss: 3.1692e-04 - val_val_KL loss: 21.7961 - val_beta: 0.0024\n",
      "Epoch 977/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77.8030 - recon_loss: 3.1279e-04 - KL loss: 21.7305 - beta: 0.0024 - val_val_loss: 79.2475 - val_val_recon_loss: 3.1939e-04 - val_val_KL loss: 21.9909 - val_beta: 0.0024\n",
      "Epoch 978/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78.0888 - recon_loss: 3.1437e-04 - KL loss: 21.7332 - beta: 0.0024 - val_val_loss: 78.1699 - val_val_recon_loss: 3.1519e-04 - val_val_KL loss: 21.6660 - val_beta: 0.0024\n",
      "Epoch 979/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 77.6397 - recon_loss: 3.1220e-04 - KL loss: 21.6731 - beta: 0.0024\n",
      "Epoch 00979: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77.6400 - recon_loss: 3.1220e-04 - KL loss: 21.6731 - beta: 0.0024 - val_val_loss: 78.8084 - val_val_recon_loss: 3.1848e-04 - val_val_KL loss: 21.7158 - val_beta: 0.0024\n",
      "Epoch 980/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78.6071 - recon_loss: 3.1711e-04 - KL loss: 21.7593 - beta: 0.0024 - val_val_loss: 78.5219 - val_val_recon_loss: 3.1684e-04 - val_val_KL loss: 21.7226 - val_beta: 0.0024\n",
      "Epoch 981/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77.5220 - recon_loss: 3.1153e-04 - KL loss: 21.6743 - beta: 0.0024 - val_val_loss: 79.1969 - val_val_recon_loss: 3.2011e-04 - val_val_KL loss: 21.8118 - val_beta: 0.0024\n",
      "Epoch 982/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 78.3166 - recon_loss: 3.1555e-04 - KL loss: 21.7484 - beta: 0.0024 - val_val_loss: 78.3560 - val_val_recon_loss: 3.1567e-04 - val_val_KL loss: 21.7674 - val_beta: 0.0024\n",
      "Epoch 983/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 78.2462 - recon_loss: 3.1493e-04 - KL loss: 21.7902 - beta: 0.0024 - val_val_loss: 78.6724 - val_val_recon_loss: 3.1762e-04 - val_val_KL loss: 21.7330 - val_beta: 0.0024\n",
      "Epoch 984/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 78.0206 - recon_loss: 3.1383e-04 - KL loss: 21.7613 - beta: 0.0024- ETA: 2s - loss: 78.0232 - recon_loss: 3.1384e-04 - KL loss: \n",
      "Epoch 00984: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78.0205 - recon_loss: 3.1383e-04 - KL loss: 21.7613 - beta: 0.0024 - val_val_loss: 78.4990 - val_val_recon_loss: 3.1672e-04 - val_val_KL loss: 21.7220 - val_beta: 0.0024\n",
      "Epoch 984/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.8631 - recon_loss: 3.7114e-04 - KL loss: 17.0813 - beta: 0.0044 - val_val_loss: 35.6457 - val_val_recon_loss: 3.8449e-04 - val_val_KL loss: 16.1883 - val_beta: 0.0044\n",
      "Epoch 985/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.7908 - recon_loss: 3.8736e-04 - KL loss: 16.1880 - beta: 0.0044 - val_val_loss: 36.2678 - val_val_recon_loss: 3.9783e-04 - val_val_KL loss: 16.1354 - val_beta: 0.0044\n",
      "Epoch 986/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35.9739 - recon_loss: 3.9629e-04 - KL loss: 15.9192 - beta: 0.0044 - val_val_loss: 36.1041 - val_val_recon_loss: 4.0423e-04 - val_val_KL loss: 15.6475 - val_beta: 0.0044\n",
      "Epoch 987/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35.9122 - recon_loss: 4.0033e-04 - KL loss: 15.6529 - beta: 0.0044 - val_val_loss: 35.7915 - val_val_recon_loss: 3.9815e-04 - val_val_KL loss: 15.6427 - val_beta: 0.0044\n",
      "Epoch 988/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.4248 - recon_loss: 3.9259e-04 - KL loss: 15.5576 - beta: 0.0044 - val_val_loss: 35.4701 - val_val_recon_loss: 3.9971e-04 - val_val_KL loss: 15.2423 - val_beta: 0.0044\n",
      "Epoch 989/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35.3714 - recon_loss: 3.9275e-04 - KL loss: 15.4961 - beta: 0.0044 - val_val_loss: 35.3759 - val_val_recon_loss: 3.9536e-04 - val_val_KL loss: 15.3682 - val_beta: 0.0044\n",
      "Epoch 990/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.2319 - recon_loss: 3.9155e-04 - KL loss: 15.4172 - beta: 0.0044 - val_val_loss: 35.5402 - val_val_recon_loss: 3.9843e-04 - val_val_KL loss: 15.3770 - val_beta: 0.0044\n",
      "Epoch 991/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.2926 - recon_loss: 3.9349e-04 - KL loss: 15.3794 - beta: 0.0044 - val_val_loss: 36.2813 - val_val_recon_loss: 4.1613e-04 - val_val_KL loss: 15.2228 - val_beta: 0.0044\n",
      "Epoch 992/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.7832 - recon_loss: 4.0408e-04 - KL loss: 15.3343 - beta: 0.0044 - val_val_loss: 35.6158 - val_val_recon_loss: 4.0175e-04 - val_val_KL loss: 15.2851 - val_beta: 0.0044\n",
      "Epoch 993/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35.4086 - recon_loss: 3.9768e-04 - KL loss: 15.2835 - beta: 0.0044 - val_val_loss: 35.5857 - val_val_recon_loss: 4.0019e-04 - val_val_KL loss: 15.3337 - val_beta: 0.0044\n",
      "Epoch 994/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 35.6631 - recon_loss: 4.0303e-04 - KL loss: 15.2674 - beta: 0.0044\n",
      "Epoch 00994: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35.6632 - recon_loss: 4.0303e-04 - KL loss: 15.2674 - beta: 0.0044 - val_val_loss: 36.3956 - val_val_recon_loss: 4.1364e-04 - val_val_KL loss: 15.4632 - val_beta: 0.0044\n",
      "Epoch 995/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.6664 - recon_loss: 4.0229e-04 - KL loss: 15.3080 - beta: 0.0044 - val_val_loss: 36.2427 - val_val_recon_loss: 4.1497e-04 - val_val_KL loss: 15.2426 - val_beta: 0.0044\n",
      "Epoch 996/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.0632 - recon_loss: 4.1040e-04 - KL loss: 15.2947 - beta: 0.0044 - val_val_loss: 35.4906 - val_val_recon_loss: 3.9928e-04 - val_val_KL loss: 15.2847 - val_beta: 0.0044\n",
      "Epoch 997/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.2798 - recon_loss: 3.9519e-04 - KL loss: 15.2808 - beta: 0.0044 - val_val_loss: 35.4051 - val_val_recon_loss: 3.9762e-04 - val_val_KL loss: 15.2834 - val_beta: 0.0044\n",
      "Epoch 998/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35.3081 - recon_loss: 3.9563e-04 - KL loss: 15.2867 - beta: 0.0044 - val_val_loss: 35.4152 - val_val_recon_loss: 3.9723e-04 - val_val_KL loss: 15.3128 - val_beta: 0.0044\n",
      "Epoch 999/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 35.0767 - recon_loss: 3.9166e-04 - KL loss: 15.2563 - beta: 0.0044\n",
      "Epoch 00999: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 35.0770 - recon_loss: 3.9167e-04 - KL loss: 15.2563 - beta: 0.0044 - val_val_loss: 35.4798 - val_val_recon_loss: 3.9883e-04 - val_val_KL loss: 15.2966 - val_beta: 0.0044\n",
      "Epoch 999/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 19.2205 - recon_loss: 5.5309e-04 - KL loss: 11.3193 - beta: 0.0084 - val_val_loss: 18.8930 - val_val_recon_loss: 5.7338e-04 - val_val_KL loss: 10.7019 - val_beta: 0.0084\n",
      "Epoch 1000/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.8251 - recon_loss: 5.7465e-04 - KL loss: 10.6158 - beta: 0.0084 - val_val_loss: 18.7202 - val_val_recon_loss: 5.8626e-04 - val_val_KL loss: 10.3451 - val_beta: 0.0084\n",
      "Epoch 1001/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.7627 - recon_loss: 5.8258e-04 - KL loss: 10.4401 - beta: 0.0084 - val_val_loss: 18.8025 - val_val_recon_loss: 5.8561e-04 - val_val_KL loss: 10.4366 - val_beta: 0.0084\n",
      "Epoch 1002/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.7726 - recon_loss: 5.9094e-04 - KL loss: 10.3306 - beta: 0.0084 - val_val_loss: 18.7345 - val_val_recon_loss: 5.9019e-04 - val_val_KL loss: 10.3032 - val_beta: 0.0084\n",
      "Epoch 1003/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.6461 - recon_loss: 5.8867e-04 - KL loss: 10.2365 - beta: 0.0084 - val_val_loss: 18.6062 - val_val_recon_loss: 5.8939e-04 - val_val_KL loss: 10.1864 - val_beta: 0.0084\n",
      "Epoch 1004/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.5592 - recon_loss: 5.8767e-04 - KL loss: 10.1640 - beta: 0.0084 - val_val_loss: 18.5815 - val_val_recon_loss: 6.0183e-04 - val_val_KL loss: 9.9839 - val_beta: 0.0084\n",
      "Epoch 1005/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.5225 - recon_loss: 5.9072e-04 - KL loss: 10.0837 - beta: 0.0084 - val_val_loss: 18.5216 - val_val_recon_loss: 5.9508e-04 - val_val_KL loss: 10.0204 - val_beta: 0.0084\n",
      "Epoch 1006/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.4100 - recon_loss: 5.8501e-04 - KL loss: 10.0528 - beta: 0.0084 - val_val_loss: 18.5587 - val_val_recon_loss: 6.0544e-04 - val_val_KL loss: 9.9096 - val_beta: 0.0084\n",
      "Epoch 1007/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.5061 - recon_loss: 5.9698e-04 - KL loss: 9.9779 - beta: 0.0084 - val_val_loss: 18.5933 - val_val_recon_loss: 6.0172e-04 - val_val_KL loss: 9.9973 - val_beta: 0.0084\n",
      "Epoch 1008/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.6100 - recon_loss: 6.0339e-04 - KL loss: 9.9901 - beta: 0.0084 - val_val_loss: 18.5070 - val_val_recon_loss: 6.0547e-04 - val_val_KL loss: 9.8573 - val_beta: 0.0084\n",
      "Epoch 1009/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.5343 - recon_loss: 6.0004e-04 - KL loss: 9.9623 - beta: 0.0084 - val_val_loss: 18.4855 - val_val_recon_loss: 6.0005e-04 - val_val_KL loss: 9.9134 - val_beta: 0.0084\n",
      "Epoch 1010/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.5339 - recon_loss: 6.0098e-04 - KL loss: 9.9485 - beta: 0.0084 - val_val_loss: 18.3901 - val_val_recon_loss: 5.9444e-04 - val_val_KL loss: 9.8981 - val_beta: 0.0084\n",
      "Epoch 1011/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.6841 - recon_loss: 6.1133e-04 - KL loss: 9.9509 - beta: 0.0084 - val_val_loss: 18.4289 - val_val_recon_loss: 5.9941e-04 - val_val_KL loss: 9.8660 - val_beta: 0.0084\n",
      "Epoch 1012/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.4152 - recon_loss: 5.9801e-04 - KL loss: 9.8722 - beta: 0.0084 - val_val_loss: 18.3426 - val_val_recon_loss: 5.9472e-04 - val_val_KL loss: 9.8466 - val_beta: 0.0084\n",
      "Epoch 1013/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.3029 - recon_loss: 5.9467e-04 - KL loss: 9.8077 - beta: 0.0084 - val_val_loss: 18.3486 - val_val_recon_loss: 5.9262e-04 - val_val_KL loss: 9.8826 - val_beta: 0.0084\n",
      "Epoch 1014/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.3977 - recon_loss: 5.9902e-04 - KL loss: 9.8403 - beta: 0.0084 - val_val_loss: 18.2848 - val_val_recon_loss: 5.9376e-04 - val_val_KL loss: 9.8025 - val_beta: 0.0084\n",
      "Epoch 1015/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.2710 - recon_loss: 5.9428e-04 - KL loss: 9.7813 - beta: 0.0084 - val_val_loss: 18.3565 - val_val_recon_loss: 6.0142e-04 - val_val_KL loss: 9.7649 - val_beta: 0.0084\n",
      "Epoch 1016/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.4373 - recon_loss: 6.0381e-04 - KL loss: 9.8115 - beta: 0.0084 - val_val_loss: 18.3930 - val_val_recon_loss: 6.0853e-04 - val_val_KL loss: 9.6996 - val_beta: 0.0084\n",
      "Epoch 1017/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.3028 - recon_loss: 5.9698e-04 - KL loss: 9.7745 - beta: 0.0084 - val_val_loss: 18.2242 - val_val_recon_loss: 5.8418e-04 - val_val_KL loss: 9.8788 - val_beta: 0.0084\n",
      "Epoch 1018/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.3817 - recon_loss: 6.0550e-04 - KL loss: 9.7317 - beta: 0.0084 - val_val_loss: 18.4485 - val_val_recon_loss: 6.0591e-04 - val_val_KL loss: 9.7927 - val_beta: 0.0084\n",
      "Epoch 1019/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.3001 - recon_loss: 5.9958e-04 - KL loss: 9.7347 - beta: 0.0084 - val_val_loss: 18.4300 - val_val_recon_loss: 6.0579e-04 - val_val_KL loss: 9.7759 - val_beta: 0.0084\n",
      "Epoch 1020/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.4066 - recon_loss: 6.0697e-04 - KL loss: 9.7356 - beta: 0.0084 - val_val_loss: 18.7082 - val_val_recon_loss: 6.1843e-04 - val_val_KL loss: 9.8735 - val_beta: 0.0084\n",
      "Epoch 1021/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.6784 - recon_loss: 6.2609e-04 - KL loss: 9.7343 - beta: 0.0084 - val_val_loss: 18.4864 - val_val_recon_loss: 6.1329e-04 - val_val_KL loss: 9.7250 - val_beta: 0.0084\n",
      "Epoch 1022/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18.4064 - recon_loss: 6.0983e-04 - KL loss: 9.6946 - beta: 0.0084\n",
      "Epoch 01022: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.4064 - recon_loss: 6.0983e-04 - KL loss: 9.6946 - beta: 0.0084 - val_val_loss: 18.4343 - val_val_recon_loss: 6.1377e-04 - val_val_KL loss: 9.6661 - val_beta: 0.0084\n",
      "Epoch 1023/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.3285 - recon_loss: 6.0180e-04 - KL loss: 9.7314 - beta: 0.0084 - val_val_loss: 18.4398 - val_val_recon_loss: 6.1100e-04 - val_val_KL loss: 9.7113 - val_beta: 0.0084\n",
      "Epoch 1024/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.3442 - recon_loss: 6.0496e-04 - KL loss: 9.7019 - beta: 0.0084 - val_val_loss: 18.1760 - val_val_recon_loss: 5.9399e-04 - val_val_KL loss: 9.6904 - val_beta: 0.0084\n",
      "Epoch 1025/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.1379 - recon_loss: 5.9062e-04 - KL loss: 9.7005 - beta: 0.0084 - val_val_loss: 18.1378 - val_val_recon_loss: 5.9283e-04 - val_val_KL loss: 9.6687 - val_beta: 0.0084\n",
      "Epoch 1026/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0812 - recon_loss: 5.8676e-04 - KL loss: 9.6990 - beta: 0.0084 - val_val_loss: 18.1450 - val_val_recon_loss: 5.9055e-04 - val_val_KL loss: 9.7086 - val_beta: 0.0084\n",
      "Epoch 1027/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0875 - recon_loss: 5.8799e-04 - KL loss: 9.6876 - beta: 0.0084 - val_val_loss: 18.1862 - val_val_recon_loss: 5.9771e-04 - val_val_KL loss: 9.6475 - val_beta: 0.0084\n",
      "Epoch 1028/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0496 - recon_loss: 5.8446e-04 - KL loss: 9.7001 - beta: 0.0084 - val_val_loss: 18.0578 - val_val_recon_loss: 5.8565e-04 - val_val_KL loss: 9.6913 - val_beta: 0.0084\n",
      "Epoch 1029/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0269 - recon_loss: 5.8449e-04 - KL loss: 9.6771 - beta: 0.0084 - val_val_loss: 18.1201 - val_val_recon_loss: 5.9283e-04 - val_val_KL loss: 9.6511 - val_beta: 0.0084\n",
      "Epoch 1030/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0715 - recon_loss: 5.8534e-04 - KL loss: 9.7095 - beta: 0.0084 - val_val_loss: 18.0231 - val_val_recon_loss: 5.8261e-04 - val_val_KL loss: 9.7000 - val_beta: 0.0084\n",
      "Epoch 1031/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9423 - recon_loss: 5.8025e-04 - KL loss: 9.6530 - beta: 0.0084 - val_val_loss: 18.0529 - val_val_recon_loss: 5.8421e-04 - val_val_KL loss: 9.7071 - val_beta: 0.0084\n",
      "Epoch 1032/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.0085 - recon_loss: 5.8508e-04 - KL loss: 9.6502 - beta: 0.0084 - val_val_loss: 18.0286 - val_val_recon_loss: 5.9033e-04 - val_val_KL loss: 9.5952 - val_beta: 0.0084\n",
      "Epoch 1033/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.1323 - recon_loss: 5.9114e-04 - KL loss: 9.6875 - beta: 0.0084 - val_val_loss: 18.0445 - val_val_recon_loss: 5.8587e-04 - val_val_KL loss: 9.6749 - val_beta: 0.0084\n",
      "Epoch 1034/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0527 - recon_loss: 5.8388e-04 - KL loss: 9.7116 - beta: 0.0084 - val_val_loss: 18.0364 - val_val_recon_loss: 5.8352e-04 - val_val_KL loss: 9.7004 - val_beta: 0.0084\n",
      "Epoch 1035/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 18.0267 - recon_loss: 5.8589e-04 - KL loss: 9.6569 - beta: 0.0084\n",
      "Epoch 01035: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0266 - recon_loss: 5.8589e-04 - KL loss: 9.6569 - beta: 0.0084 - val_val_loss: 18.0826 - val_val_recon_loss: 5.9186e-04 - val_val_KL loss: 9.6274 - val_beta: 0.0084\n",
      "Epoch 1036/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 18.0373 - recon_loss: 5.8634e-04 - KL loss: 9.6610 - beta: 0.0084 - val_val_loss: 17.9900 - val_val_recon_loss: 5.8300e-04 - val_val_KL loss: 9.6615 - val_beta: 0.0084\n",
      "Epoch 1037/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.9621 - recon_loss: 5.8071e-04 - KL loss: 9.6664 - beta: 0.0084 - val_val_loss: 17.9776 - val_val_recon_loss: 5.8145e-04 - val_val_KL loss: 9.6712 - val_beta: 0.0084\n",
      "Epoch 1038/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.9400 - recon_loss: 5.7978e-04 - KL loss: 9.6574 - beta: 0.0084 - val_val_loss: 17.9715 - val_val_recon_loss: 5.8039e-04 - val_val_KL loss: 9.6802 - val_beta: 0.0084\n",
      "Epoch 1039/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.8813 - recon_loss: 5.7684e-04 - KL loss: 9.6407 - beta: 0.0084 - val_val_loss: 17.9857 - val_val_recon_loss: 5.8513e-04 - val_val_KL loss: 9.6267 - val_beta: 0.0084\n",
      "Epoch 1040/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.8829 - recon_loss: 5.7597e-04 - KL loss: 9.6548 - beta: 0.0084 - val_val_loss: 17.9269 - val_val_recon_loss: 5.7811e-04 - val_val_KL loss: 9.6682 - val_beta: 0.0084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1041/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.9606 - recon_loss: 5.8067e-04 - KL loss: 9.6653 - beta: 0.0084 - val_val_loss: 17.9650 - val_val_recon_loss: 5.8208e-04 - val_val_KL loss: 9.6496 - val_beta: 0.0084\n",
      "Epoch 1042/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 18.0140 - recon_loss: 5.8185e-04 - KL loss: 9.7018 - beta: 0.0084 - val_val_loss: 17.9448 - val_val_recon_loss: 5.8365e-04 - val_val_KL loss: 9.6069 - val_beta: 0.0084\n",
      "Epoch 1043/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9691 - recon_loss: 5.8126e-04 - KL loss: 9.6655 - beta: 0.0084 - val_val_loss: 17.9723 - val_val_recon_loss: 5.8214e-04 - val_val_KL loss: 9.6560 - val_beta: 0.0084\n",
      "Epoch 1044/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9808 - recon_loss: 5.8037e-04 - KL loss: 9.6897 - beta: 0.0084 - val_val_loss: 17.9806 - val_val_recon_loss: 5.8503e-04 - val_val_KL loss: 9.6231 - val_beta: 0.0084\n",
      "Epoch 1045/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17.8799 - recon_loss: 5.7570e-04 - KL loss: 9.6556 - beta: 0.0084\n",
      "Epoch 01045: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.8799 - recon_loss: 5.7571e-04 - KL loss: 9.6556 - beta: 0.0084 - val_val_loss: 17.9767 - val_val_recon_loss: 5.8287e-04 - val_val_KL loss: 9.6499 - val_beta: 0.0084\n",
      "Epoch 1046/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9198 - recon_loss: 5.7790e-04 - KL loss: 9.6641 - beta: 0.0084 - val_val_loss: 17.9294 - val_val_recon_loss: 5.7836e-04 - val_val_KL loss: 9.6670 - val_beta: 0.0084\n",
      "Epoch 1047/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9309 - recon_loss: 5.7859e-04 - KL loss: 9.6653 - beta: 0.0084 - val_val_loss: 17.9538 - val_val_recon_loss: 5.8119e-04 - val_val_KL loss: 9.6511 - val_beta: 0.0084\n",
      "Epoch 1048/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9192 - recon_loss: 5.7756e-04 - KL loss: 9.6684 - beta: 0.0084 - val_val_loss: 17.9279 - val_val_recon_loss: 5.7956e-04 - val_val_KL loss: 9.6484 - val_beta: 0.0084\n",
      "Epoch 1049/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.9215 - recon_loss: 5.7786e-04 - KL loss: 9.6664 - beta: 0.0084 - val_val_loss: 17.9001 - val_val_recon_loss: 5.7592e-04 - val_val_KL loss: 9.6726 - val_beta: 0.0084\n",
      "Epoch 1050/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9490 - recon_loss: 5.7971e-04 - KL loss: 9.6674 - beta: 0.0084 - val_val_loss: 17.9526 - val_val_recon_loss: 5.8088e-04 - val_val_KL loss: 9.6543 - val_beta: 0.0084\n",
      "Epoch 1051/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9074 - recon_loss: 5.7694e-04 - KL loss: 9.6654 - beta: 0.0084 - val_val_loss: 17.9333 - val_val_recon_loss: 5.7911e-04 - val_val_KL loss: 9.6603 - val_beta: 0.0084\n",
      "Epoch 1052/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.8920 - recon_loss: 5.7681e-04 - KL loss: 9.6519 - beta: 0.0084 - val_val_loss: 17.8983 - val_val_recon_loss: 5.7703e-04 - val_val_KL loss: 9.6550 - val_beta: 0.0084\n",
      "Epoch 1053/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9212 - recon_loss: 5.7853e-04 - KL loss: 9.6565 - beta: 0.0084 - val_val_loss: 17.9151 - val_val_recon_loss: 5.7855e-04 - val_val_KL loss: 9.6501 - val_beta: 0.0084\n",
      "Epoch 1054/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9172 - recon_loss: 5.7797e-04 - KL loss: 9.6605 - beta: 0.0084 - val_val_loss: 17.9328 - val_val_recon_loss: 5.8132e-04 - val_val_KL loss: 9.6282 - val_beta: 0.0084\n",
      "Epoch 1055/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9159 - recon_loss: 5.7837e-04 - KL loss: 9.6536 - beta: 0.0084 - val_val_loss: 17.9611 - val_val_recon_loss: 5.8203e-04 - val_val_KL loss: 9.6464 - val_beta: 0.0084\n",
      "Epoch 1056/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.9021 - recon_loss: 5.7701e-04 - KL loss: 9.6591 - beta: 0.0084 - val_val_loss: 17.9365 - val_val_recon_loss: 5.8140e-04 - val_val_KL loss: 9.6308 - val_beta: 0.0084\n",
      "Epoch 1057/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17.9240 - recon_loss: 5.8050e-04 - KL loss: 9.6312 - beta: 0.0084\n",
      "Epoch 01057: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9240 - recon_loss: 5.8049e-04 - KL loss: 9.6312 - beta: 0.0084 - val_val_loss: 17.9413 - val_val_recon_loss: 5.8109e-04 - val_val_KL loss: 9.6400 - val_beta: 0.0084\n",
      "Epoch 1058/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.9415 - recon_loss: 5.8018e-04 - KL loss: 9.6532 - beta: 0.0084 - val_val_loss: 17.9196 - val_val_recon_loss: 5.8018e-04 - val_val_KL loss: 9.6314 - val_beta: 0.0084\n",
      "Epoch 1059/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.8618 - recon_loss: 5.7698e-04 - KL loss: 9.6192 - beta: 0.0084 - val_val_loss: 17.9640 - val_val_recon_loss: 5.8208e-04 - val_val_KL loss: 9.6486 - val_beta: 0.0084\n",
      "Epoch 1060/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.9500 - recon_loss: 5.8024e-04 - KL loss: 9.6610 - beta: 0.0084 - val_val_loss: 17.9060 - val_val_recon_loss: 5.7838e-04 - val_val_KL loss: 9.6435 - val_beta: 0.0084\n",
      "Epoch 1061/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 17.8608 - recon_loss: 5.7575e-04 - KL loss: 9.6358 - beta: 0.0084 - val_val_loss: 17.9134 - val_val_recon_loss: 5.7898e-04 - val_val_KL loss: 9.6422 - val_beta: 0.0084\n",
      "Epoch 1062/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17.8842 - recon_loss: 5.7639e-04 - KL loss: 9.6501 - beta: 0.0084\n",
      "Epoch 01062: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 17.8842 - recon_loss: 5.7639e-04 - KL loss: 9.6501 - beta: 0.0084 - val_val_loss: 17.9004 - val_val_recon_loss: 5.7787e-04 - val_val_KL loss: 9.6451 - val_beta: 0.0084\n",
      "Epoch 1062/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.6750 - recon_loss: 9.6505e-04 - KL loss: 6.7832 - beta: 0.0157 - val_val_loss: 10.5136 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.2552 - val_beta: 0.0157\n",
      "Epoch 1063/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.5136 - recon_loss: 0.0010 - KL loss: 6.2907 - beta: 0.0157 - val_val_loss: 10.4784 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.1347 - val_beta: 0.0157\n",
      "Epoch 1064/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.5235 - recon_loss: 0.0011 - KL loss: 6.1829 - beta: 0.0157 - val_val_loss: 10.4784 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.0259 - val_beta: 0.0157\n",
      "Epoch 1065/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.5117 - recon_loss: 0.0011 - KL loss: 6.0966 - beta: 0.0157 - val_val_loss: 10.4234 - val_val_recon_loss: 0.0011 - val_val_KL loss: 6.0287 - val_beta: 0.0157\n",
      "Epoch 1066/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.4231 - recon_loss: 0.0011 - KL loss: 6.0093 - beta: 0.0157 - val_val_loss: 10.4117 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.9283 - val_beta: 0.0157\n",
      "Epoch 1067/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.4043 - recon_loss: 0.0011 - KL loss: 5.9577 - beta: 0.0157 - val_val_loss: 10.3830 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.9745 - val_beta: 0.0157\n",
      "Epoch 1068/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.4236 - recon_loss: 0.0011 - KL loss: 5.9393 - beta: 0.0157 - val_val_loss: 10.3703 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8350 - val_beta: 0.0157\n",
      "Epoch 1069/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.4152 - recon_loss: 0.0011 - KL loss: 5.9044 - beta: 0.0157 - val_val_loss: 10.3382 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.9118 - val_beta: 0.0157\n",
      "Epoch 1070/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3777 - recon_loss: 0.0011 - KL loss: 5.8551 - beta: 0.0157 - val_val_loss: 10.3631 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8589 - val_beta: 0.0157\n",
      "Epoch 1071/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.3570 - recon_loss: 0.0011 - KL loss: 5.8656 - beta: 0.0157 - val_val_loss: 10.3292 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.9158 - val_beta: 0.0157\n",
      "Epoch 1072/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3651 - recon_loss: 0.0011 - KL loss: 5.8624 - beta: 0.0157 - val_val_loss: 10.3296 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8922 - val_beta: 0.0157\n",
      "Epoch 1073/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.3082 - recon_loss: 0.0011 - KL loss: 5.8305 - beta: 0.0157 - val_val_loss: 10.3686 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8233 - val_beta: 0.0157\n",
      "Epoch 1074/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.3631 - recon_loss: 0.0011 - KL loss: 5.8184 - beta: 0.0157 - val_val_loss: 10.3216 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8198 - val_beta: 0.0157\n",
      "Epoch 1075/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3537 - recon_loss: 0.0011 - KL loss: 5.8098 - beta: 0.0157 - val_val_loss: 10.2657 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7662 - val_beta: 0.0157\n",
      "Epoch 1076/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.2569 - recon_loss: 0.0011 - KL loss: 5.7808 - beta: 0.0157 - val_val_loss: 10.2721 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8395 - val_beta: 0.0157\n",
      "Epoch 1077/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3268 - recon_loss: 0.0011 - KL loss: 5.7940 - beta: 0.0157 - val_val_loss: 10.3405 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8007 - val_beta: 0.0157\n",
      "Epoch 1078/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3039 - recon_loss: 0.0011 - KL loss: 5.8067 - beta: 0.0157 - val_val_loss: 10.4008 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7993 - val_beta: 0.0157\n",
      "Epoch 1079/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3955 - recon_loss: 0.0011 - KL loss: 5.7700 - beta: 0.0157 - val_val_loss: 10.3348 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7618 - val_beta: 0.0157\n",
      "Epoch 1080/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.3082 - recon_loss: 0.0011 - KL loss: 5.7609 - beta: 0.0157\n",
      "Epoch 01080: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.3082 - recon_loss: 0.0011 - KL loss: 5.7609 - beta: 0.0157 - val_val_loss: 10.3746 - val_val_recon_loss: 0.0012 - val_val_KL loss: 5.7253 - val_beta: 0.0157\n",
      "Epoch 1081/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2854 - recon_loss: 0.0011 - KL loss: 5.7439 - beta: 0.0157 - val_val_loss: 10.2681 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.6965 - val_beta: 0.0157\n",
      "Epoch 1082/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2607 - recon_loss: 0.0011 - KL loss: 5.7536 - beta: 0.0157 - val_val_loss: 10.2566 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7715 - val_beta: 0.0157\n",
      "Epoch 1083/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2656 - recon_loss: 0.0011 - KL loss: 5.7863 - beta: 0.0157 - val_val_loss: 10.2433 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7403 - val_beta: 0.0157\n",
      "Epoch 1084/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2455 - recon_loss: 0.0011 - KL loss: 5.7487 - beta: 0.0157 - val_val_loss: 10.2338 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7879 - val_beta: 0.0157\n",
      "Epoch 1085/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2700 - recon_loss: 0.0011 - KL loss: 5.7554 - beta: 0.0157 - val_val_loss: 10.2473 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7287 - val_beta: 0.0157\n",
      "Epoch 1086/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2406 - recon_loss: 0.0011 - KL loss: 5.7578 - beta: 0.0157 - val_val_loss: 10.2281 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7521 - val_beta: 0.0157\n",
      "Epoch 1087/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2516 - recon_loss: 0.0011 - KL loss: 5.7622 - beta: 0.0157 - val_val_loss: 10.2330 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7069 - val_beta: 0.0157\n",
      "Epoch 1088/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.2378 - recon_loss: 0.0011 - KL loss: 5.7492 - beta: 0.0157 - val_val_loss: 10.2036 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7730 - val_beta: 0.0157\n",
      "Epoch 1089/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1963 - recon_loss: 0.0011 - KL loss: 5.7428 - beta: 0.0157 - val_val_loss: 10.2094 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7304 - val_beta: 0.0157\n",
      "Epoch 1090/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1844 - recon_loss: 0.0011 - KL loss: 5.7361 - beta: 0.0157 - val_val_loss: 10.2254 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7073 - val_beta: 0.0157\n",
      "Epoch 1091/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.2147 - recon_loss: 0.0011 - KL loss: 5.7434 - beta: 0.0157 - val_val_loss: 10.2136 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7720 - val_beta: 0.0157\n",
      "Epoch 1092/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.2285 - recon_loss: 0.0011 - KL loss: 5.7496 - beta: 0.0157 - val_val_loss: 10.2122 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7675 - val_beta: 0.0157\n",
      "Epoch 1093/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.2075 - recon_loss: 0.0011 - KL loss: 5.7292 - beta: 0.0157\n",
      "Epoch 01093: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.2075 - recon_loss: 0.0011 - KL loss: 5.7292 - beta: 0.0157 - val_val_loss: 10.2334 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.8103 - val_beta: 0.0157\n",
      "Epoch 1094/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2417 - recon_loss: 0.0011 - KL loss: 5.7753 - beta: 0.0157 - val_val_loss: 10.1907 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7707 - val_beta: 0.0157\n",
      "Epoch 1095/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.1951 - recon_loss: 0.0011 - KL loss: 5.7517 - beta: 0.0157 - val_val_loss: 10.1902 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7590 - val_beta: 0.0157\n",
      "Epoch 1096/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2059 - recon_loss: 0.0011 - KL loss: 5.7497 - beta: 0.0157 - val_val_loss: 10.1765 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7450 - val_beta: 0.0157\n",
      "Epoch 1097/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1855 - recon_loss: 0.0011 - KL loss: 5.7412 - beta: 0.0157 - val_val_loss: 10.1726 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7246 - val_beta: 0.0157\n",
      "Epoch 1098/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1560 - recon_loss: 0.0011 - KL loss: 5.7248 - beta: 0.0157 - val_val_loss: 10.1753 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7448 - val_beta: 0.0157\n",
      "Epoch 1099/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2197 - recon_loss: 0.0011 - KL loss: 5.7601 - beta: 0.0157 - val_val_loss: 10.1811 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7340 - val_beta: 0.0157\n",
      "Epoch 1100/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.1793 - recon_loss: 0.0011 - KL loss: 5.7440 - beta: 0.0157 - val_val_loss: 10.1584 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7411 - val_beta: 0.0157\n",
      "Epoch 1101/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2172 - recon_loss: 0.0011 - KL loss: 5.7634 - beta: 0.0157 - val_val_loss: 10.1792 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7533 - val_beta: 0.0157\n",
      "Epoch 1102/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1940 - recon_loss: 0.0011 - KL loss: 5.7560 - beta: 0.0157 - val_val_loss: 10.1755 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7252 - val_beta: 0.0157\n",
      "Epoch 1103/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.2009 - recon_loss: 0.0011 - KL loss: 5.7645 - beta: 0.0157 - val_val_loss: 10.1877 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7644 - val_beta: 0.0157\n",
      "Epoch 1104/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.1461 - recon_loss: 0.0011 - KL loss: 5.7474 - beta: 0.0157 - val_val_loss: 10.1879 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7408 - val_beta: 0.0157\n",
      "Epoch 1105/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.1661 - recon_loss: 0.0011 - KL loss: 5.7451 - beta: 0.0157\n",
      "Epoch 01105: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.1661 - recon_loss: 0.0011 - KL loss: 5.7451 - beta: 0.0157 - val_val_loss: 10.1944 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7573 - val_beta: 0.0157\n",
      "Epoch 1106/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1794 - recon_loss: 0.0011 - KL loss: 5.7459 - beta: 0.0157 - val_val_loss: 10.1838 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7212 - val_beta: 0.0157\n",
      "Epoch 1107/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1934 - recon_loss: 0.0011 - KL loss: 5.7428 - beta: 0.0157 - val_val_loss: 10.1728 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7254 - val_beta: 0.0157\n",
      "Epoch 1108/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10.1570 - recon_loss: 0.0011 - KL loss: 5.7351 - beta: 0.0157 - val_val_loss: 10.1654 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7542 - val_beta: 0.0157\n",
      "Epoch 1109/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1858 - recon_loss: 0.0011 - KL loss: 5.7579 - beta: 0.0157 - val_val_loss: 10.1679 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7538 - val_beta: 0.0157\n",
      "Epoch 1110/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10.1801 - recon_loss: 0.0011 - KL loss: 5.7605 - beta: 0.0157\n",
      "Epoch 01110: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 10.1801 - recon_loss: 0.0011 - KL loss: 5.7605 - beta: 0.0157 - val_val_loss: 10.1817 - val_val_recon_loss: 0.0011 - val_val_KL loss: 5.7651 - val_beta: 0.0157\n",
      "Epoch 1110/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 6.1320 - recon_loss: 0.0020 - KL loss: 3.8088 - beta: 0.0296 - val_val_loss: 5.9858 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.5274 - val_beta: 0.0296\n",
      "Epoch 1111/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.9788 - recon_loss: 0.0022 - KL loss: 3.4214 - beta: 0.0296 - val_val_loss: 5.9426 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.3886 - val_beta: 0.0296\n",
      "Epoch 1112/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.9359 - recon_loss: 0.0023 - KL loss: 3.3500 - beta: 0.0296 - val_val_loss: 5.9142 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.3092 - val_beta: 0.0296\n",
      "Epoch 1113/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.9282 - recon_loss: 0.0023 - KL loss: 3.3156 - beta: 0.0296 - val_val_loss: 5.8860 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2845 - val_beta: 0.0296\n",
      "Epoch 1114/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8867 - recon_loss: 0.0023 - KL loss: 3.2782 - beta: 0.0296 - val_val_loss: 5.8935 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2820 - val_beta: 0.0296\n",
      "Epoch 1115/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5.8864 - recon_loss: 0.0023 - KL loss: 3.2761 - beta: 0.0296 - val_val_loss: 5.8968 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2324 - val_beta: 0.0296\n",
      "Epoch 1116/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.8876 - recon_loss: 0.0023 - KL loss: 3.2569 - beta: 0.0296 - val_val_loss: 5.8578 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2590 - val_beta: 0.0296\n",
      "Epoch 1117/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8545 - recon_loss: 0.0023 - KL loss: 3.2472 - beta: 0.0296 - val_val_loss: 5.8519 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2000 - val_beta: 0.0296\n",
      "Epoch 1118/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8461 - recon_loss: 0.0023 - KL loss: 3.2478 - beta: 0.0296 - val_val_loss: 5.8446 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2186 - val_beta: 0.0296\n",
      "Epoch 1119/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8567 - recon_loss: 0.0023 - KL loss: 3.2542 - beta: 0.0296 - val_val_loss: 5.8637 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2201 - val_beta: 0.0296\n",
      "Epoch 1120/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8911 - recon_loss: 0.0023 - KL loss: 3.2710 - beta: 0.0296 - val_val_loss: 5.8964 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2881 - val_beta: 0.0296\n",
      "Epoch 1121/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.8685 - recon_loss: 0.0023 - KL loss: 3.2708 - beta: 0.0296 - val_val_loss: 5.8684 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2160 - val_beta: 0.0296\n",
      "Epoch 1122/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8779 - recon_loss: 0.0023 - KL loss: 3.2671 - beta: 0.0296 - val_val_loss: 5.9439 - val_val_recon_loss: 0.0024 - val_val_KL loss: 3.2234 - val_beta: 0.0296\n",
      "Epoch 1123/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.9210 - recon_loss: 0.0023 - KL loss: 3.2593 - beta: 0.0296\n",
      "Epoch 01123: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.9210 - recon_loss: 0.0023 - KL loss: 3.2593 - beta: 0.0296 - val_val_loss: 5.8969 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2354 - val_beta: 0.0296\n",
      "Epoch 1124/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8572 - recon_loss: 0.0023 - KL loss: 3.2724 - beta: 0.0296 - val_val_loss: 5.8397 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2697 - val_beta: 0.0296\n",
      "Epoch 1125/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8433 - recon_loss: 0.0022 - KL loss: 3.2826 - beta: 0.0296 - val_val_loss: 5.8264 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.2844 - val_beta: 0.0296\n",
      "Epoch 1126/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8401 - recon_loss: 0.0023 - KL loss: 3.2706 - beta: 0.0296 - val_val_loss: 5.8501 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2776 - val_beta: 0.0296\n",
      "Epoch 1127/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8414 - recon_loss: 0.0023 - KL loss: 3.2748 - beta: 0.0296 - val_val_loss: 5.8437 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2593 - val_beta: 0.0296\n",
      "Epoch 1128/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8399 - recon_loss: 0.0023 - KL loss: 3.2658 - beta: 0.0296 - val_val_loss: 5.8432 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2563 - val_beta: 0.0296\n",
      "Epoch 1129/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8254 - recon_loss: 0.0022 - KL loss: 3.2702 - beta: 0.0296 - val_val_loss: 5.8330 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.2845 - val_beta: 0.0296\n",
      "Epoch 1130/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8209 - recon_loss: 0.0022 - KL loss: 3.2641 - beta: 0.0296 - val_val_loss: 5.8206 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2472 - val_beta: 0.0296\n",
      "Epoch 1131/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8372 - recon_loss: 0.0023 - KL loss: 3.2654 - beta: 0.0296 - val_val_loss: 5.8258 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2438 - val_beta: 0.0296\n",
      "Epoch 1132/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5.8400 - recon_loss: 0.0023 - KL loss: 3.2708 - beta: 0.0296 - val_val_loss: 5.8273 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.2875 - val_beta: 0.0296\n",
      "Epoch 1133/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8428 - recon_loss: 0.0023 - KL loss: 3.2722 - beta: 0.0296 - val_val_loss: 5.8261 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.2656 - val_beta: 0.0296\n",
      "Epoch 1134/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8413 - recon_loss: 0.0023 - KL loss: 3.2790 - beta: 0.0296 - val_val_loss: 5.8252 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.3059 - val_beta: 0.0296\n",
      "Epoch 1135/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.8188 - recon_loss: 0.0022 - KL loss: 3.2723 - beta: 0.0296- ETA: 7s -\n",
      "Epoch 01135: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8188 - recon_loss: 0.0022 - KL loss: 3.2723 - beta: 0.0296 - val_val_loss: 5.8607 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2833 - val_beta: 0.0296\n",
      "Epoch 1136/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8553 - recon_loss: 0.0023 - KL loss: 3.2751 - beta: 0.0296 - val_val_loss: 5.8330 - val_val_recon_loss: 0.0022 - val_val_KL loss: 3.2851 - val_beta: 0.0296\n",
      "Epoch 1137/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8349 - recon_loss: 0.0023 - KL loss: 3.2654 - beta: 0.0296 - val_val_loss: 5.8435 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2708 - val_beta: 0.0296\n",
      "Epoch 1138/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8473 - recon_loss: 0.0023 - KL loss: 3.2686 - beta: 0.0296 - val_val_loss: 5.8391 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2577 - val_beta: 0.0296\n",
      "Epoch 1139/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5.8286 - recon_loss: 0.0023 - KL loss: 3.2625 - beta: 0.0296 - val_val_loss: 5.8508 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2701 - val_beta: 0.0296\n",
      "Epoch 1140/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.8405 - recon_loss: 0.0023 - KL loss: 3.2716 - beta: 0.0296\n",
      "Epoch 01140: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5.8405 - recon_loss: 0.0023 - KL loss: 3.2716 - beta: 0.0296 - val_val_loss: 5.8417 - val_val_recon_loss: 0.0023 - val_val_KL loss: 3.2773 - val_beta: 0.0296\n",
      "Epoch 1140/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 3.3939 - recon_loss: 0.0050 - KL loss: 1.7893 - beta: 0.0558 - val_val_loss: 3.3057 - val_val_recon_loss: 0.0059 - val_val_KL loss: 1.4041 - val_beta: 0.0558\n",
      "Epoch 1141/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 3.3140 - recon_loss: 0.0059 - KL loss: 1.4062 - beta: 0.0558 - val_val_loss: 3.2986 - val_val_recon_loss: 0.0060 - val_val_KL loss: 1.3574 - val_beta: 0.0558\n",
      "Epoch 1142/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2971 - recon_loss: 0.0062 - KL loss: 1.2898 - beta: 0.0558 - val_val_loss: 3.2919 - val_val_recon_loss: 0.0065 - val_val_KL loss: 1.2163 - val_beta: 0.0558\n",
      "Epoch 1143/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2872 - recon_loss: 0.0065 - KL loss: 1.2024 - beta: 0.0558 - val_val_loss: 3.2975 - val_val_recon_loss: 0.0067 - val_val_KL loss: 1.1597 - val_beta: 0.0558\n",
      "Epoch 1144/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2824 - recon_loss: 0.0067 - KL loss: 1.1303 - beta: 0.0558 - val_val_loss: 3.2864 - val_val_recon_loss: 0.0068 - val_val_KL loss: 1.1024 - val_beta: 0.0558\n",
      "Epoch 1145/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2817 - recon_loss: 0.0069 - KL loss: 1.0621 - beta: 0.0558 - val_val_loss: 3.2921 - val_val_recon_loss: 0.0070 - val_val_KL loss: 1.0371 - val_beta: 0.0558\n",
      "Epoch 1146/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2927 - recon_loss: 0.0071 - KL loss: 1.0209 - beta: 0.0558 - val_val_loss: 3.2713 - val_val_recon_loss: 0.0068 - val_val_KL loss: 1.0840 - val_beta: 0.0558\n",
      "Epoch 1147/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2783 - recon_loss: 0.0070 - KL loss: 1.0336 - beta: 0.0558 - val_val_loss: 3.2769 - val_val_recon_loss: 0.0070 - val_val_KL loss: 1.0408 - val_beta: 0.0558\n",
      "Epoch 1148/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2764 - recon_loss: 0.0071 - KL loss: 0.9977 - beta: 0.0558 - val_val_loss: 3.2837 - val_val_recon_loss: 0.0072 - val_val_KL loss: 0.9594 - val_beta: 0.0558\n",
      "Epoch 1149/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2811 - recon_loss: 0.0072 - KL loss: 0.9668 - beta: 0.0558 - val_val_loss: 3.2675 - val_val_recon_loss: 0.0073 - val_val_KL loss: 0.9373 - val_beta: 0.0558\n",
      "Epoch 1150/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2729 - recon_loss: 0.0072 - KL loss: 0.9435 - beta: 0.0558 - val_val_loss: 3.2491 - val_val_recon_loss: 0.0072 - val_val_KL loss: 0.9401 - val_beta: 0.0558\n",
      "Epoch 1151/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 3.2726 - recon_loss: 0.0073 - KL loss: 0.9246 - beta: 0.0558 - val_val_loss: 3.2789 - val_val_recon_loss: 0.0073 - val_val_KL loss: 0.9387 - val_beta: 0.0558\n",
      "Epoch 1152/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2708 - recon_loss: 0.0073 - KL loss: 0.9309 - beta: 0.0558 - val_val_loss: 3.2620 - val_val_recon_loss: 0.0073 - val_val_KL loss: 0.9052 - val_beta: 0.0558\n",
      "Epoch 1153/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2652 - recon_loss: 0.0074 - KL loss: 0.8921 - beta: 0.0558 - val_val_loss: 3.2707 - val_val_recon_loss: 0.0075 - val_val_KL loss: 0.8484 - val_beta: 0.0558\n",
      "Epoch 1154/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2724 - recon_loss: 0.0075 - KL loss: 0.8650 - beta: 0.0558 - val_val_loss: 3.2729 - val_val_recon_loss: 0.0075 - val_val_KL loss: 0.8783 - val_beta: 0.0558\n",
      "Epoch 1155/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3.2673 - recon_loss: 0.0075 - KL loss: 0.8624 - beta: 0.0558\n",
      "Epoch 01155: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2673 - recon_loss: 0.0075 - KL loss: 0.8624 - beta: 0.0558 - val_val_loss: 3.2740 - val_val_recon_loss: 0.0076 - val_val_KL loss: 0.8459 - val_beta: 0.0558\n",
      "Epoch 1156/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2594 - recon_loss: 0.0076 - KL loss: 0.8259 - beta: 0.0558 - val_val_loss: 3.2503 - val_val_recon_loss: 0.0075 - val_val_KL loss: 0.8274 - val_beta: 0.0558\n",
      "Epoch 1157/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2698 - recon_loss: 0.0076 - KL loss: 0.8305 - beta: 0.0558 - val_val_loss: 3.2673 - val_val_recon_loss: 0.0076 - val_val_KL loss: 0.8184 - val_beta: 0.0558\n",
      "Epoch 1158/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2638 - recon_loss: 0.0076 - KL loss: 0.8157 - beta: 0.0558 - val_val_loss: 3.2659 - val_val_recon_loss: 0.0077 - val_val_KL loss: 0.7892 - val_beta: 0.0558\n",
      "Epoch 1159/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 3.2752 - recon_loss: 0.0077 - KL loss: 0.7914 - beta: 0.0558 - val_val_loss: 3.2587 - val_val_recon_loss: 0.0077 - val_val_KL loss: 0.7859 - val_beta: 0.0558\n",
      "Epoch 1160/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3.2595 - recon_loss: 0.0077 - KL loss: 0.7907 - beta: 0.0558\n",
      "Epoch 01160: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 3.2595 - recon_loss: 0.0077 - KL loss: 0.7907 - beta: 0.0558 - val_val_loss: 3.2576 - val_val_recon_loss: 0.0078 - val_val_KL loss: 0.7635 - val_beta: 0.0558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1160/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 1.0724 - recon_loss: 0.0105 - KL loss: 0.1192 - beta: 0.1050 - val_val_loss: 0.9804 - val_val_recon_loss: 0.0107 - val_val_KL loss: 0.0054 - val_beta: 0.1050\n",
      "Epoch 1161/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9781 - recon_loss: 0.0107 - KL loss: 0.0041 - beta: 0.1050 - val_val_loss: 0.9728 - val_val_recon_loss: 0.0107 - val_val_KL loss: 0.0018 - val_beta: 0.1050\n",
      "Epoch 1162/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9739 - recon_loss: 0.0107 - KL loss: 0.0015 - beta: 0.1050 - val_val_loss: 0.9705 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.0647e-04 - val_beta: 0.1050\n",
      "Epoch 1163/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9680 - recon_loss: 0.0107 - KL loss: 8.4354e-04 - beta: 0.1050 - val_val_loss: 0.9689 - val_val_recon_loss: 0.0107 - val_val_KL loss: 6.7246e-04 - val_beta: 0.1050\n",
      "Epoch 1164/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9696 - recon_loss: 0.0107 - KL loss: 5.8475e-04 - beta: 0.1050 - val_val_loss: 0.9672 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.4991e-04 - val_beta: 0.1050\n",
      "Epoch 1165/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9690 - recon_loss: 0.0107 - KL loss: 3.9937e-04 - beta: 0.1050 - val_val_loss: 0.9684 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.0935e-04 - val_beta: 0.1050\n",
      "Epoch 1166/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9676 - recon_loss: 0.0107 - KL loss: 3.3296e-04 - beta: 0.1050 - val_val_loss: 0.9678 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.5092e-04 - val_beta: 0.1050\n",
      "Epoch 1167/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9676 - recon_loss: 0.0107 - KL loss: 2.5869e-04 - beta: 0.1050 - val_val_loss: 0.9682 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.4904e-04 - val_beta: 0.1050\n",
      "Epoch 1168/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9690 - recon_loss: 0.0107 - KL loss: 2.3597e-04 - beta: 0.1050 - val_val_loss: 0.9683 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.9338e-04 - val_beta: 0.1050\n",
      "Epoch 1169/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.9697 - recon_loss: 0.0107 - KL loss: 2.0757e-04 - beta: 0.1050\n",
      "Epoch 01169: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9697 - recon_loss: 0.0107 - KL loss: 2.0755e-04 - beta: 0.1050 - val_val_loss: 0.9683 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5272e-04 - val_beta: 0.1050\n",
      "Epoch 1170/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9682 - recon_loss: 0.0107 - KL loss: 1.3385e-04 - beta: 0.1050 - val_val_loss: 0.9686 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2216e-04 - val_beta: 0.1050\n",
      "Epoch 1171/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9681 - recon_loss: 0.0107 - KL loss: 1.2354e-04 - beta: 0.1050 - val_val_loss: 0.9690 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1060e-04 - val_beta: 0.1050\n",
      "Epoch 1172/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9700 - recon_loss: 0.0107 - KL loss: 1.1279e-04 - beta: 0.1050 - val_val_loss: 0.9685 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.8526e-05 - val_beta: 0.1050\n",
      "Epoch 1173/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9689 - recon_loss: 0.0107 - KL loss: 1.0120e-04 - beta: 0.1050 - val_val_loss: 0.9687 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.0294e-04 - val_beta: 0.1050\n",
      "Epoch 1174/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.9688 - recon_loss: 0.0107 - KL loss: 1.0269e-04 - beta: 0.1050\n",
      "Epoch 01174: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.9688 - recon_loss: 0.0107 - KL loss: 1.0269e-04 - beta: 0.1050 - val_val_loss: 0.9687 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.5336e-05 - val_beta: 0.1050\n",
      "Epoch 1174/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2738 - recon_loss: 0.0107 - KL loss: 1.0398e-04 - beta: 0.1976 - val_val_loss: 0.2738 - val_val_recon_loss: 0.0107 - val_val_KL loss: 7.3149e-05 - val_beta: 0.1976\n",
      "Epoch 1175/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2737 - recon_loss: 0.0107 - KL loss: 8.4015e-05 - beta: 0.1976 - val_val_loss: 0.2738 - val_val_recon_loss: 0.0107 - val_val_KL loss: 6.4769e-05 - val_beta: 0.1976\n",
      "Epoch 1176/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2730 - recon_loss: 0.0107 - KL loss: 7.0936e-05 - beta: 0.1976 - val_val_loss: 0.2737 - val_val_recon_loss: 0.0107 - val_val_KL loss: 5.5335e-05 - val_beta: 0.1976\n",
      "Epoch 1177/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2737 - recon_loss: 0.0107 - KL loss: 6.9050e-05 - beta: 0.1976 - val_val_loss: 0.2739 - val_val_recon_loss: 0.0107 - val_val_KL loss: 5.2594e-05 - val_beta: 0.1976\n",
      "Epoch 1178/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2738 - recon_loss: 0.0107 - KL loss: 6.1996e-05 - beta: 0.1976 - val_val_loss: 0.2742 - val_val_recon_loss: 0.0107 - val_val_KL loss: 6.1241e-05 - val_beta: 0.1976\n",
      "Epoch 1179/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2740 - recon_loss: 0.0107 - KL loss: 5.9786e-05 - beta: 0.1976 - val_val_loss: 0.2742 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.7351e-05 - val_beta: 0.1976\n",
      "Epoch 1180/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2738 - recon_loss: 0.0107 - KL loss: 5.1337e-05 - beta: 0.1976 - val_val_loss: 0.2739 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.6334e-05 - val_beta: 0.1976\n",
      "Epoch 1181/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2741 - recon_loss: 0.0107 - KL loss: 4.9327e-05 - beta: 0.1976\n",
      "Epoch 01181: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2741 - recon_loss: 0.0107 - KL loss: 4.9326e-05 - beta: 0.1976 - val_val_loss: 0.2741 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.6366e-05 - val_beta: 0.1976\n",
      "Epoch 1182/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2739 - recon_loss: 0.0107 - KL loss: 3.4492e-05 - beta: 0.1976 - val_val_loss: 0.2739 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.1854e-05 - val_beta: 0.1976\n",
      "Epoch 1183/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2739 - recon_loss: 0.0107 - KL loss: 3.3053e-05 - beta: 0.1976 - val_val_loss: 0.2739 - val_val_recon_loss: 0.0107 - val_val_KL loss: 5.0288e-05 - val_beta: 0.1976\n",
      "Epoch 1184/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2736 - recon_loss: 0.0107 - KL loss: 3.3154e-05 - beta: 0.1976 - val_val_loss: 0.2738 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.0855e-05 - val_beta: 0.1976\n",
      "Epoch 1185/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2742 - recon_loss: 0.0107 - KL loss: 3.1979e-05 - beta: 0.1976 - val_val_loss: 0.2739 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.9075e-05 - val_beta: 0.1976\n",
      "Epoch 1186/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2737 - recon_loss: 0.0107 - KL loss: 3.0977e-05 - beta: 0.1976\n",
      "Epoch 01186: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2737 - recon_loss: 0.0107 - KL loss: 3.0977e-05 - beta: 0.1976 - val_val_loss: 0.2739 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.0412e-05 - val_beta: 0.1976\n",
      "Epoch 1186/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0774 - recon_loss: 0.0107 - KL loss: 8.6226e-05 - beta: 0.3719 - val_val_loss: 0.0773 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.1069e-05 - val_beta: 0.3719\n",
      "Epoch 1187/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0774 - recon_loss: 0.0107 - KL loss: 3.7595e-05 - beta: 0.3719 - val_val_loss: 0.0774 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.1261e-05 - val_beta: 0.3719\n",
      "Epoch 1188/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0773 - recon_loss: 0.0107 - KL loss: 3.3656e-05 - beta: 0.3719 - val_val_loss: 0.0773 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.7614e-05 - val_beta: 0.3719\n",
      "Epoch 1189/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0774 - recon_loss: 0.0107 - KL loss: 3.5244e-05 - beta: 0.3719 - val_val_loss: 0.0775 - val_val_recon_loss: 0.0107 - val_val_KL loss: 6.1094e-05 - val_beta: 0.3719\n",
      "Epoch 1190/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0773 - recon_loss: 0.0107 - KL loss: 3.4352e-05 - beta: 0.3719 - val_val_loss: 0.0774 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.2841e-05 - val_beta: 0.3719\n",
      "Epoch 1191/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0775 - recon_loss: 0.0107 - KL loss: 2.8957e-05 - beta: 0.3719\n",
      "Epoch 01191: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0775 - recon_loss: 0.0107 - KL loss: 2.8957e-05 - beta: 0.3719 - val_val_loss: 0.0774 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.8948e-05 - val_beta: 0.3719\n",
      "Epoch 1192/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0772 - recon_loss: 0.0107 - KL loss: 2.1164e-05 - beta: 0.3719 - val_val_loss: 0.0773 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0285e-05 - val_beta: 0.3719\n",
      "Epoch 1193/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0773 - recon_loss: 0.0107 - KL loss: 2.1301e-05 - beta: 0.3719 - val_val_loss: 0.0773 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1767e-05 - val_beta: 0.3719\n",
      "Epoch 1194/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0774 - recon_loss: 0.0107 - KL loss: 2.1768e-05 - beta: 0.3719 - val_val_loss: 0.0774 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.9993e-05 - val_beta: 0.3719\n",
      "Epoch 1195/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0773 - recon_loss: 0.0107 - KL loss: 2.1022e-05 - beta: 0.3719 - val_val_loss: 0.0775 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.8939e-05 - val_beta: 0.3719\n",
      "Epoch 1196/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0774 - recon_loss: 0.0107 - KL loss: 2.0428e-05 - beta: 0.3719\n",
      "Epoch 01196: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.0774 - recon_loss: 0.0107 - KL loss: 2.0428e-05 - beta: 0.3719 - val_val_loss: 0.0773 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1251e-05 - val_beta: 0.3719\n",
      "Epoch 1196/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 8.4871e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.5977e-05 - val_beta: 0.7000\n",
      "Epoch 1197/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 2.7097e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.4572e-05 - val_beta: 0.7000\n",
      "Epoch 1198/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 2.6423e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.3737e-05 - val_beta: 0.7000\n",
      "Epoch 1199/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 2.4308e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.3668e-05 - val_beta: 0.7000\n",
      "Epoch 1200/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 2.6565e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0410e-05 - val_beta: 0.7000\n",
      "Epoch 1201/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 2.8620e-05 - beta: 0.7000\n",
      "Epoch 01201: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 2.8617e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.9878e-05 - val_beta: 0.7000\n",
      "Epoch 1202/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.5692e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.4945e-05 - val_beta: 0.7000\n",
      "Epoch 1203/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.5547e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5634e-05 - val_beta: 0.7000\n",
      "Epoch 1204/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.6113e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5711e-05 - val_beta: 0.7000\n",
      "Epoch 1205/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.6735e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.4885e-05 - val_beta: 0.7000\n",
      "Epoch 1206/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.5445e-05 - beta: 0.7000\n",
      "Epoch 01206: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.5445e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.7365e-05 - val_beta: 0.7000\n",
      "Epoch 1207/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.3410e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.4495e-05 - val_beta: 0.7000\n",
      "Epoch 1208/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.3521e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3531e-05 - val_beta: 0.7000\n",
      "Epoch 1209/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.3497e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.4649e-05 - val_beta: 0.7000\n",
      "Epoch 1210/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.3446e-05 - beta: 0.7000 - val_val_loss: 0.0218 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3544e-05 - val_beta: 0.7000\n",
      "Epoch 1211/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.3360e-05 - beta: 0.7000\n",
      "Epoch 01211: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.3360e-05 - beta: 0.7000 - val_val_loss: 0.0218 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5016e-05 - val_beta: 0.7000\n",
      "Epoch 1212/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.2704e-05 - beta: 0.7000 - val_val_loss: 0.0218 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3137e-05 - val_beta: 0.7000\n",
      "Epoch 1213/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.2557e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2970e-05 - val_beta: 0.7000\n",
      "Epoch 1214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.2622e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3086e-05 - val_beta: 0.7000\n",
      "Epoch 1215/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.2377e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2989e-05 - val_beta: 0.7000\n",
      "Epoch 1216/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.2421e-05 - beta: 0.7000\n",
      "Epoch 01216: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.2421e-05 - beta: 0.7000 - val_val_loss: 0.0218 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3196e-05 - val_beta: 0.7000\n",
      "Epoch 1217/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.2326e-05 - beta: 0.7000 - val_val_loss: 0.0218 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2818e-05 - val_beta: 0.7000\n",
      "Epoch 1218/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.2223e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2869e-05 - val_beta: 0.7000\n",
      "Epoch 1219/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0218 - recon_loss: 0.0107 - KL loss: 1.2146e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2741e-05 - val_beta: 0.7000\n",
      "Epoch 1220/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0219 - recon_loss: 0.0107 - KL loss: 1.2133e-05 - beta: 0.7000 - val_val_loss: 0.0219 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2882e-05 - val_beta: 0.7000\n",
      "Epoch 1220/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.0714 - recon_loss: 0.0107 - KL loss: 5.7062e-04 - beta: 0.3891 - val_val_loss: 0.0708 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.9985e-05 - val_beta: 0.3891\n",
      "Epoch 1221/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 2.4089e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1467e-05 - val_beta: 0.3891\n",
      "Epoch 1222/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 2.3124e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.3620e-05 - val_beta: 0.3891\n",
      "Epoch 1223/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 2.7530e-05 - beta: 0.3891 - val_val_loss: 0.0708 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0977e-05 - val_beta: 0.3891\n",
      "Epoch 1224/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 2.4069e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.8568e-05 - val_beta: 0.3891\n",
      "Epoch 1225/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0705 - recon_loss: 0.0107 - KL loss: 2.2495e-05 - beta: 0.3891- ETA: 2s - loss: 0.0705 - recon_loss: 0.0107 - KL los\n",
      "Epoch 01225: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0705 - recon_loss: 0.0107 - KL loss: 2.2496e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5914e-05 - val_beta: 0.3891\n",
      "Epoch 1226/10000\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.4477e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3991e-05 - val_beta: 0.3891\n",
      "Epoch 1227/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.0706 - recon_loss: 0.0107 - KL loss: 1.4853e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3613e-05 - val_beta: 0.3891\n",
      "Epoch 1228/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0709 - recon_loss: 0.0107 - KL loss: 1.4667e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.6663e-05 - val_beta: 0.3891\n",
      "Epoch 1229/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.4519e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.4093e-05 - val_beta: 0.3891\n",
      "Epoch 1230/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.5263e-05 - beta: 0.3891\n",
      "Epoch 01230: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.5262e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.3918e-05 - val_beta: 0.3891\n",
      "Epoch 1231/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.2617e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2343e-05 - val_beta: 0.3891\n",
      "Epoch 1232/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0706 - recon_loss: 0.0107 - KL loss: 1.2256e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2477e-05 - val_beta: 0.3891\n",
      "Epoch 1233/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.2288e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2286e-05 - val_beta: 0.3891\n",
      "Epoch 1234/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.2397e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3648e-05 - val_beta: 0.3891\n",
      "Epoch 1235/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.2078e-05 - beta: 0.3891\n",
      "Epoch 01235: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.2078e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2116e-05 - val_beta: 0.3891\n",
      "Epoch 1236/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.1467e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1921e-05 - val_beta: 0.3891\n",
      "Epoch 1237/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0709 - recon_loss: 0.0107 - KL loss: 1.1415e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1855e-05 - val_beta: 0.3891\n",
      "Epoch 1238/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0706 - recon_loss: 0.0107 - KL loss: 1.1277e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1670e-05 - val_beta: 0.3891\n",
      "Epoch 1239/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.1178e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1725e-05 - val_beta: 0.3891\n",
      "Epoch 1240/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.1233e-05 - beta: 0.3891\n",
      "Epoch 01240: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.1233e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1704e-05 - val_beta: 0.3891\n",
      "Epoch 1241/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.1078e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1514e-05 - val_beta: 0.3891\n",
      "Epoch 1242/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0708 - recon_loss: 0.0107 - KL loss: 1.1141e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1543e-05 - val_beta: 0.3891\n",
      "Epoch 1243/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0706 - recon_loss: 0.0107 - KL loss: 1.0982e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1468e-05 - val_beta: 0.3891\n",
      "Epoch 1244/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.0979e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1542e-05 - val_beta: 0.3891\n",
      "Epoch 1245/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.0964e-05 - beta: 0.3891\n",
      "Epoch 01245: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0707 - recon_loss: 0.0107 - KL loss: 1.0964e-05 - beta: 0.3891 - val_val_loss: 0.0707 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1605e-05 - val_beta: 0.3891\n",
      "Epoch 1245/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2298 - recon_loss: 0.0107 - KL loss: 6.5802e-04 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.4916e-05 - val_beta: 0.2163\n",
      "Epoch 1246/10000\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 0.2289 - recon_loss: 0.0107 - KL loss: 1.5416e-05 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1048e-05 - val_beta: 0.2163\n",
      "Epoch 1247/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2293 - recon_loss: 0.0107 - KL loss: 1.7010e-05 - beta: 0.2163 - val_val_loss: 0.2290 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3957e-05 - val_beta: 0.2163\n",
      "Epoch 1248/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2286 - recon_loss: 0.0107 - KL loss: 1.9039e-05 - beta: 0.2163 - val_val_loss: 0.2289 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.6883e-05 - val_beta: 0.2163\n",
      "Epoch 1249/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2289 - recon_loss: 0.0107 - KL loss: 1.9555e-05 - beta: 0.2163 - val_val_loss: 0.2290 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.8509e-05 - val_beta: 0.2163\n",
      "Epoch 1250/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 2.0597e-05 - beta: 0.2163\n",
      "Epoch 01250: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 2.0597e-05 - beta: 0.2163 - val_val_loss: 0.2292 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3787e-05 - val_beta: 0.2163\n",
      "Epoch 1251/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2291 - recon_loss: 0.0107 - KL loss: 1.1869e-05 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2223e-05 - val_beta: 0.2163\n",
      "Epoch 1252/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 1.1568e-05 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5733e-05 - val_beta: 0.2163\n",
      "Epoch 1253/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2291 - recon_loss: 0.0107 - KL loss: 1.2020e-05 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.0678e-05 - val_beta: 0.2163\n",
      "Epoch 1254/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2289 - recon_loss: 0.0107 - KL loss: 1.1506e-05 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.0942e-05 - val_beta: 0.2163\n",
      "Epoch 1255/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2291 - recon_loss: 0.0107 - KL loss: 1.1429e-05 - beta: 0.2163\n",
      "Epoch 01255: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2291 - recon_loss: 0.0107 - KL loss: 1.1429e-05 - beta: 0.2163 - val_val_loss: 0.2289 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.5800e-05 - val_beta: 0.2163\n",
      "Epoch 1256/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2288 - recon_loss: 0.0107 - KL loss: 9.8782e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.0458e-05 - val_beta: 0.2163\n",
      "Epoch 1257/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2289 - recon_loss: 0.0107 - KL loss: 9.8803e-06 - beta: 0.2163 - val_val_loss: 0.2289 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1336e-05 - val_beta: 0.2163\n",
      "Epoch 1258/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2286 - recon_loss: 0.0107 - KL loss: 9.9605e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.0549e-05 - val_beta: 0.2163\n",
      "Epoch 1259/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.2292 - recon_loss: 0.0107 - KL loss: 1.0003e-05 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.0278e-05 - val_beta: 0.2163\n",
      "Epoch 1260/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 9.7770e-06 - beta: 0.2163\n",
      "Epoch 01260: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 9.7770e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.6292e-06 - val_beta: 0.2163\n",
      "Epoch 1261/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2290 - recon_loss: 0.0107 - KL loss: 9.0995e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.4013e-06 - val_beta: 0.2163\n",
      "Epoch 1262/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2286 - recon_loss: 0.0107 - KL loss: 8.9239e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.4938e-06 - val_beta: 0.2163\n",
      "Epoch 1263/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2292 - recon_loss: 0.0107 - KL loss: 9.1761e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.6133e-06 - val_beta: 0.2163\n",
      "Epoch 1264/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 9.1579e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.6179e-06 - val_beta: 0.2163\n",
      "Epoch 1265/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2286 - recon_loss: 0.0107 - KL loss: 9.0127e-06 - beta: 0.2163\n",
      "Epoch 01265: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2286 - recon_loss: 0.0107 - KL loss: 9.0127e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.5240e-06 - val_beta: 0.2163\n",
      "Epoch 1266/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.2291 - recon_loss: 0.0107 - KL loss: 8.9679e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.4269e-06 - val_beta: 0.2163\n",
      "Epoch 1267/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 8.7311e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.1976e-06 - val_beta: 0.2163\n",
      "Epoch 1268/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2287 - recon_loss: 0.0107 - KL loss: 8.7403e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.4195e-06 - val_beta: 0.2163\n",
      "Epoch 1269/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2288 - recon_loss: 0.0107 - KL loss: 8.7867e-06 - beta: 0.2163 - val_val_loss: 0.2288 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.2464e-06 - val_beta: 0.2163\n",
      "Epoch 1269/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.7418 - recon_loss: 0.0107 - KL loss: 4.2233e-04 - beta: 0.1202 - val_val_loss: 0.7410 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.7473e-05 - val_beta: 0.1202\n",
      "Epoch 1270/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7415 - recon_loss: 0.0107 - KL loss: 1.8820e-05 - beta: 0.1202 - val_val_loss: 0.7410 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.8231e-05 - val_beta: 0.1202\n",
      "Epoch 1271/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7405 - recon_loss: 0.0107 - KL loss: 2.6889e-05 - beta: 0.1202 - val_val_loss: 0.7413 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.5231e-05 - val_beta: 0.1202\n",
      "Epoch 1272/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7406 - recon_loss: 0.0107 - KL loss: 2.4183e-05 - beta: 0.1202 - val_val_loss: 0.7407 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0926e-05 - val_beta: 0.1202\n",
      "Epoch 1273/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7394 - recon_loss: 0.0107 - KL loss: 2.1270e-05 - beta: 0.1202 - val_val_loss: 0.7416 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.8719e-05 - val_beta: 0.1202\n",
      "Epoch 1274/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7417 - recon_loss: 0.0107 - KL loss: 2.0348e-05 - beta: 0.1202 - val_val_loss: 0.7408 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.9484e-05 - val_beta: 0.1202\n",
      "Epoch 1275/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7419 - recon_loss: 0.0107 - KL loss: 2.3545e-05 - beta: 0.1202 - val_val_loss: 0.7410 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.3313e-05 - val_beta: 0.1202\n",
      "Epoch 1276/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7404 - recon_loss: 0.0107 - KL loss: 1.7642e-05 - beta: 0.1202 - val_val_loss: 0.7406 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1395e-05 - val_beta: 0.1202\n",
      "Epoch 1277/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7414 - recon_loss: 0.0107 - KL loss: 1.8292e-05 - beta: 0.1202 - val_val_loss: 0.7407 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2830e-05 - val_beta: 0.1202\n",
      "Epoch 1278/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7418 - recon_loss: 0.0107 - KL loss: 1.8740e-05 - beta: 0.1202 - val_val_loss: 0.7410 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.6114e-05 - val_beta: 0.1202\n",
      "Epoch 1279/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7410 - recon_loss: 0.0107 - KL loss: 1.9377e-05 - beta: 0.1202 - val_val_loss: 0.7406 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.2102e-05 - val_beta: 0.1202\n",
      "Epoch 1280/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7412 - recon_loss: 0.0107 - KL loss: 1.9101e-05 - beta: 0.1202 - val_val_loss: 0.7408 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.5704e-05 - val_beta: 0.1202\n",
      "Epoch 1281/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.7408 - recon_loss: 0.0107 - KL loss: 2.1044e-05 - beta: 0.1202\n",
      "Epoch 01281: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7408 - recon_loss: 0.0107 - KL loss: 2.1041e-05 - beta: 0.1202 - val_val_loss: 0.7407 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.2890e-05 - val_beta: 0.1202\n",
      "Epoch 1282/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7399 - recon_loss: 0.0107 - KL loss: 9.7539e-06 - beta: 0.1202 - val_val_loss: 0.7403 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.6372e-06 - val_beta: 0.1202\n",
      "Epoch 1283/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7400 - recon_loss: 0.0107 - KL loss: 9.9953e-06 - beta: 0.1202 - val_val_loss: 0.7406 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.6812e-05 - val_beta: 0.1202\n",
      "Epoch 1284/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.7401 - recon_loss: 0.0107 - KL loss: 1.0698e-05 - beta: 0.1202 - val_val_loss: 0.7406 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.7874e-06 - val_beta: 0.1202\n",
      "Epoch 1285/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.7411 - recon_loss: 0.0107 - KL loss: 1.0271e-05 - beta: 0.1202 - val_val_loss: 0.7410 - val_val_recon_loss: 0.0107 - val_val_KL loss: 9.7019e-06 - val_beta: 0.1202\n",
      "Epoch 1286/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7409 - recon_loss: 0.0107 - KL loss: 1.0201e-05 - beta: 0.1202 - val_val_loss: 0.7407 - val_val_recon_loss: 0.0107 - val_val_KL loss: 8.5999e-06 - val_beta: 0.1202\n",
      "Epoch 1287/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.7400 - recon_loss: 0.0107 - KL loss: 1.0379e-05 - beta: 0.1202\n",
      "Epoch 01287: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7400 - recon_loss: 0.0107 - KL loss: 1.0379e-05 - beta: 0.1202 - val_val_loss: 0.7404 - val_val_recon_loss: 0.0107 - val_val_KL loss: 1.1818e-05 - val_beta: 0.1202\n",
      "Epoch 1288/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7418 - recon_loss: 0.0107 - KL loss: 8.4252e-06 - beta: 0.1202 - val_val_loss: 0.7408 - val_val_recon_loss: 0.0107 - val_val_KL loss: 8.7936e-06 - val_beta: 0.1202\n",
      "Epoch 1289/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7419 - recon_loss: 0.0107 - KL loss: 8.2905e-06 - beta: 0.1202 - val_val_loss: 0.7406 - val_val_recon_loss: 0.0107 - val_val_KL loss: 8.7806e-06 - val_beta: 0.1202\n",
      "Epoch 1290/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7407 - recon_loss: 0.0107 - KL loss: 8.3667e-06 - beta: 0.1202 - val_val_loss: 0.7407 - val_val_recon_loss: 0.0107 - val_val_KL loss: 8.9313e-06 - val_beta: 0.1202\n",
      "Epoch 1291/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7394 - recon_loss: 0.0107 - KL loss: 8.0475e-06 - beta: 0.1202 - val_val_loss: 0.7407 - val_val_recon_loss: 0.0107 - val_val_KL loss: 8.0432e-06 - val_beta: 0.1202\n",
      "Epoch 1292/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.7408 - recon_loss: 0.0107 - KL loss: 8.0126e-06 - beta: 0.1202\n",
      "Epoch 01292: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.7408 - recon_loss: 0.0107 - KL loss: 8.0126e-06 - beta: 0.1202 - val_val_loss: 0.7405 - val_val_recon_loss: 0.0107 - val_val_KL loss: 8.1798e-06 - val_beta: 0.1202\n",
      "Epoch 1292/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.4024 - recon_loss: 0.0107 - KL loss: 3.0339e-04 - beta: 0.0668 - val_val_loss: 2.3975 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.7230e-05 - val_beta: 0.0668\n",
      "Epoch 1293/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3998 - recon_loss: 0.0107 - KL loss: 3.4130e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.0635e-05 - val_beta: 0.0668\n",
      "Epoch 1294/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3961 - recon_loss: 0.0107 - KL loss: 3.9056e-05 - beta: 0.0668 - val_val_loss: 2.3975 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.2400e-05 - val_beta: 0.0668\n",
      "Epoch 1295/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3954 - recon_loss: 0.0107 - KL loss: 4.4523e-05 - beta: 0.0668 - val_val_loss: 2.3977 - val_val_recon_loss: 0.0107 - val_val_KL loss: 4.0206e-05 - val_beta: 0.0668\n",
      "Epoch 1296/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3925 - recon_loss: 0.0107 - KL loss: 4.3809e-05 - beta: 0.0668 - val_val_loss: 2.3976 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.2491e-05 - val_beta: 0.0668\n",
      "Epoch 1297/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3988 - recon_loss: 0.0107 - KL loss: 3.6366e-05 - beta: 0.0668 - val_val_loss: 2.3978 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.1875e-05 - val_beta: 0.0668\n",
      "Epoch 1298/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3966 - recon_loss: 0.0107 - KL loss: 3.7380e-05 - beta: 0.0668\n",
      "Epoch 01298: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3966 - recon_loss: 0.0107 - KL loss: 3.7379e-05 - beta: 0.0668 - val_val_loss: 2.3987 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.6891e-05 - val_beta: 0.0668\n",
      "Epoch 1299/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3958 - recon_loss: 0.0107 - KL loss: 2.4628e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.2876e-05 - val_beta: 0.0668\n",
      "Epoch 1300/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3997 - recon_loss: 0.0107 - KL loss: 2.4388e-05 - beta: 0.0668 - val_val_loss: 2.3972 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.4449e-05 - val_beta: 0.0668\n",
      "Epoch 1301/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 2.3952 - recon_loss: 0.0107 - KL loss: 2.5899e-05 - beta: 0.0668 - val_val_loss: 2.3969 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.7180e-05 - val_beta: 0.0668\n",
      "Epoch 1302/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3978 - recon_loss: 0.0107 - KL loss: 3.1433e-05 - beta: 0.0668 - val_val_loss: 2.3981 - val_val_recon_loss: 0.0107 - val_val_KL loss: 3.2397e-05 - val_beta: 0.0668\n",
      "Epoch 1303/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3971 - recon_loss: 0.0107 - KL loss: 2.8572e-05 - beta: 0.0668\n",
      "Epoch 01303: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3971 - recon_loss: 0.0107 - KL loss: 2.8572e-05 - beta: 0.0668 - val_val_loss: 2.3975 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.9705e-05 - val_beta: 0.0668\n",
      "Epoch 1304/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3963 - recon_loss: 0.0107 - KL loss: 2.6669e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.7164e-05 - val_beta: 0.0668\n",
      "Epoch 1305/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3988 - recon_loss: 0.0107 - KL loss: 2.5648e-05 - beta: 0.0668 - val_val_loss: 2.3969 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.7510e-05 - val_beta: 0.0668\n",
      "Epoch 1306/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3978 - recon_loss: 0.0107 - KL loss: 2.4891e-05 - beta: 0.0668 - val_val_loss: 2.3965 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.4334e-05 - val_beta: 0.0668\n",
      "Epoch 1307/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3957 - recon_loss: 0.0107 - KL loss: 2.4283e-05 - beta: 0.0668 - val_val_loss: 2.3969 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.4837e-05 - val_beta: 0.0668\n",
      "Epoch 1308/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3995 - recon_loss: 0.0107 - KL loss: 2.4707e-05 - beta: 0.0668 - val_val_loss: 2.3969 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.4334e-05 - val_beta: 0.0668\n",
      "Epoch 1309/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3956 - recon_loss: 0.0107 - KL loss: 2.4802e-05 - beta: 0.0668 - val_val_loss: 2.3968 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.4485e-05 - val_beta: 0.0668\n",
      "Epoch 1310/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3957 - recon_loss: 0.0107 - KL loss: 2.4209e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.3198e-05 - val_beta: 0.0668\n",
      "Epoch 1311/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3952 - recon_loss: 0.0107 - KL loss: 2.3082e-05 - beta: 0.0668\n",
      "Epoch 01311: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 2.3952 - recon_loss: 0.0107 - KL loss: 2.3082e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.2030e-05 - val_beta: 0.0668\n",
      "Epoch 1312/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3992 - recon_loss: 0.0107 - KL loss: 2.1543e-05 - beta: 0.0668 - val_val_loss: 2.3969 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.2127e-05 - val_beta: 0.0668\n",
      "Epoch 1313/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3949 - recon_loss: 0.0107 - KL loss: 2.1146e-05 - beta: 0.0668 - val_val_loss: 2.3968 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.2296e-05 - val_beta: 0.0668\n",
      "Epoch 1314/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3963 - recon_loss: 0.0107 - KL loss: 2.1317e-05 - beta: 0.0668 - val_val_loss: 2.3971 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1555e-05 - val_beta: 0.0668\n",
      "Epoch 1315/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3993 - recon_loss: 0.0107 - KL loss: 2.1307e-05 - beta: 0.0668 - val_val_loss: 2.3966 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.2474e-05 - val_beta: 0.0668\n",
      "Epoch 1316/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3969 - recon_loss: 0.0107 - KL loss: 2.1274e-05 - beta: 0.0668\n",
      "Epoch 01316: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3969 - recon_loss: 0.0107 - KL loss: 2.1274e-05 - beta: 0.0668 - val_val_loss: 2.3965 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1263e-05 - val_beta: 0.0668\n",
      "Epoch 1317/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3946 - recon_loss: 0.0107 - KL loss: 2.0922e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0708e-05 - val_beta: 0.0668\n",
      "Epoch 1318/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3993 - recon_loss: 0.0107 - KL loss: 2.0648e-05 - beta: 0.0668 - val_val_loss: 2.3965 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1054e-05 - val_beta: 0.0668\n",
      "Epoch 1319/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3959 - recon_loss: 0.0107 - KL loss: 2.0539e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0931e-05 - val_beta: 0.0668\n",
      "Epoch 1320/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3980 - recon_loss: 0.0107 - KL loss: 2.0698e-05 - beta: 0.0668 - val_val_loss: 2.3968 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1310e-05 - val_beta: 0.0668\n",
      "Epoch 1321/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3961 - recon_loss: 0.0107 - KL loss: 2.0739e-05 - beta: 0.0668\n",
      "Epoch 01321: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3961 - recon_loss: 0.0107 - KL loss: 2.0739e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1056e-05 - val_beta: 0.0668\n",
      "Epoch 1322/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3979 - recon_loss: 0.0107 - KL loss: 2.0488e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.0976e-05 - val_beta: 0.0668\n",
      "Epoch 1323/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3939 - recon_loss: 0.0107 - KL loss: 2.0528e-05 - beta: 0.0668 - val_val_loss: 2.3968 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1172e-05 - val_beta: 0.0668\n",
      "Epoch 1324/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3969 - recon_loss: 0.0107 - KL loss: 2.0752e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1028e-05 - val_beta: 0.0668\n",
      "Epoch 1325/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3940 - recon_loss: 0.0107 - KL loss: 2.0642e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1333e-05 - val_beta: 0.0668\n",
      "Epoch 1326/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3990 - recon_loss: 0.0107 - KL loss: 2.0727e-05 - beta: 0.0668\n",
      "Epoch 01326: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3990 - recon_loss: 0.0107 - KL loss: 2.0727e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1031e-05 - val_beta: 0.0668\n",
      "Epoch 1327/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3943 - recon_loss: 0.0107 - KL loss: 2.0567e-05 - beta: 0.0668 - val_val_loss: 2.3968 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1091e-05 - val_beta: 0.0668\n",
      "Epoch 1328/10000\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 2.3926 - recon_loss: 0.0107 - KL loss: 2.0467e-05 - beta: 0.0668 - val_val_loss: 2.3967 - val_val_recon_loss: 0.0107 - val_val_KL loss: 2.1035e-05 - val_beta: 0.0668\n",
      "Epoch 1328/10000\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 7.7431 - recon_loss: 0.0107 - KL loss: 0.0186 - beta: 0.0372 - val_val_loss: 6.8101 - val_val_recon_loss: 0.0082 - val_val_KL loss: 0.8371 - val_beta: 0.0372\n",
      "Epoch 1329/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 6.6419 - recon_loss: 0.0078 - KL loss: 0.9870 - beta: 0.0372 - val_val_loss: 6.3076 - val_val_recon_loss: 0.0068 - val_val_KL loss: 1.3570 - val_beta: 0.0372\n",
      "Epoch 1330/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 6.1945 - recon_loss: 0.0065 - KL loss: 1.4735 - beta: 0.0372 - val_val_loss: 6.0255 - val_val_recon_loss: 0.0059 - val_val_KL loss: 1.7354 - val_beta: 0.0372\n",
      "Epoch 1331/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 5.8901 - recon_loss: 0.0056 - KL loss: 1.8077 - beta: 0.0372 - val_val_loss: 5.7455 - val_val_recon_loss: 0.0052 - val_val_KL loss: 1.9610 - val_beta: 0.0372\n",
      "Epoch 1332/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.7031 - recon_loss: 0.0051 - KL loss: 1.9936 - beta: 0.0372 - val_val_loss: 5.5774 - val_val_recon_loss: 0.0047 - val_val_KL loss: 2.1434 - val_beta: 0.0372\n",
      "Epoch 1333/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.5829 - recon_loss: 0.0047 - KL loss: 2.1482 - beta: 0.0372 - val_val_loss: 5.5326 - val_val_recon_loss: 0.0046 - val_val_KL loss: 2.1796 - val_beta: 0.0372\n",
      "Epoch 1334/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.5247 - recon_loss: 0.0046 - KL loss: 2.2074 - beta: 0.0372 - val_val_loss: 5.4990 - val_val_recon_loss: 0.0045 - val_val_KL loss: 2.2217 - val_beta: 0.0372\n",
      "Epoch 1335/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.4724 - recon_loss: 0.0045 - KL loss: 2.2100 - beta: 0.0372 - val_val_loss: 5.4506 - val_val_recon_loss: 0.0044 - val_val_KL loss: 2.2616 - val_beta: 0.0372\n",
      "Epoch 1336/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.4560 - recon_loss: 0.0044 - KL loss: 2.2684 - beta: 0.0372 - val_val_loss: 5.4563 - val_val_recon_loss: 0.0043 - val_val_KL loss: 2.3073 - val_beta: 0.0372\n",
      "Epoch 1337/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.4197 - recon_loss: 0.0043 - KL loss: 2.3073 - beta: 0.0372 - val_val_loss: 5.3829 - val_val_recon_loss: 0.0042 - val_val_KL loss: 2.3324 - val_beta: 0.0372\n",
      "Epoch 1338/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.3882 - recon_loss: 0.0042 - KL loss: 2.3503 - beta: 0.0372 - val_val_loss: 5.3872 - val_val_recon_loss: 0.0042 - val_val_KL loss: 2.3640 - val_beta: 0.0372\n",
      "Epoch 1339/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.3453 - recon_loss: 0.0041 - KL loss: 2.3817 - beta: 0.0372 - val_val_loss: 5.3080 - val_val_recon_loss: 0.0040 - val_val_KL loss: 2.4197 - val_beta: 0.0372\n",
      "Epoch 1340/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.3267 - recon_loss: 0.0040 - KL loss: 2.4094 - beta: 0.0372 - val_val_loss: 5.3390 - val_val_recon_loss: 0.0040 - val_val_KL loss: 2.4222 - val_beta: 0.0372\n",
      "Epoch 1341/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.3320 - recon_loss: 0.0040 - KL loss: 2.4244 - beta: 0.0372 - val_val_loss: 5.2935 - val_val_recon_loss: 0.0040 - val_val_KL loss: 2.4183 - val_beta: 0.0372\n",
      "Epoch 1342/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.3109 - recon_loss: 0.0040 - KL loss: 2.4338 - beta: 0.0372 - val_val_loss: 5.2702 - val_val_recon_loss: 0.0039 - val_val_KL loss: 2.4319 - val_beta: 0.0372\n",
      "Epoch 1343/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2940 - recon_loss: 0.0039 - KL loss: 2.4429 - beta: 0.0372 - val_val_loss: 5.2925 - val_val_recon_loss: 0.0040 - val_val_KL loss: 2.4011 - val_beta: 0.0372\n",
      "Epoch 1344/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.2877 - recon_loss: 0.0039 - KL loss: 2.4420 - beta: 0.0372 - val_val_loss: 5.2661 - val_val_recon_loss: 0.0038 - val_val_KL loss: 2.4891 - val_beta: 0.0372\n",
      "Epoch 1345/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.2865 - recon_loss: 0.0039 - KL loss: 2.4614 - beta: 0.0372 - val_val_loss: 5.2682 - val_val_recon_loss: 0.0039 - val_val_KL loss: 2.4561 - val_beta: 0.0372\n",
      "Epoch 1346/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2407 - recon_loss: 0.0038 - KL loss: 2.4542 - beta: 0.0372 - val_val_loss: 5.2670 - val_val_recon_loss: 0.0039 - val_val_KL loss: 2.4188 - val_beta: 0.0372\n",
      "Epoch 1347/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2646 - recon_loss: 0.0039 - KL loss: 2.4466 - beta: 0.0372 - val_val_loss: 5.2447 - val_val_recon_loss: 0.0038 - val_val_KL loss: 2.4868 - val_beta: 0.0372\n",
      "Epoch 1348/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2571 - recon_loss: 0.0039 - KL loss: 2.4642 - beta: 0.0372 - val_val_loss: 5.2413 - val_val_recon_loss: 0.0039 - val_val_KL loss: 2.4453 - val_beta: 0.0372\n",
      "Epoch 1349/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2445 - recon_loss: 0.0039 - KL loss: 2.4537 - beta: 0.0372 - val_val_loss: 5.2256 - val_val_recon_loss: 0.0038 - val_val_KL loss: 2.5054 - val_beta: 0.0372\n",
      "Epoch 1350/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2233 - recon_loss: 0.0038 - KL loss: 2.4820 - beta: 0.0372 - val_val_loss: 5.1883 - val_val_recon_loss: 0.0037 - val_val_KL loss: 2.5371 - val_beta: 0.0372\n",
      "Epoch 1351/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.2306 - recon_loss: 0.0038 - KL loss: 2.5066 - beta: 0.0372 - val_val_loss: 5.1637 - val_val_recon_loss: 0.0037 - val_val_KL loss: 2.4898 - val_beta: 0.0372\n",
      "Epoch 1352/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.1549 - recon_loss: 0.0036 - KL loss: 2.5475 - beta: 0.0372 - val_val_loss: 5.0403 - val_val_recon_loss: 0.0034 - val_val_KL loss: 2.6091 - val_beta: 0.0372\n",
      "Epoch 1353/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.0200 - recon_loss: 0.0033 - KL loss: 2.6363 - beta: 0.0372 - val_val_loss: 5.0117 - val_val_recon_loss: 0.0032 - val_val_KL loss: 2.6706 - val_beta: 0.0372\n",
      "Epoch 1354/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9951 - recon_loss: 0.0032 - KL loss: 2.6783 - beta: 0.0372 - val_val_loss: 5.0085 - val_val_recon_loss: 0.0033 - val_val_KL loss: 2.6452 - val_beta: 0.0372\n",
      "Epoch 1355/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.9747 - recon_loss: 0.0032 - KL loss: 2.6832 - beta: 0.0372 - val_val_loss: 4.9916 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7168 - val_beta: 0.0372\n",
      "Epoch 1356/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.0294 - recon_loss: 0.0032 - KL loss: 2.6928 - beta: 0.0372 - val_val_loss: 4.9808 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7134 - val_beta: 0.0372\n",
      "Epoch 1357/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9692 - recon_loss: 0.0031 - KL loss: 2.7141 - beta: 0.0372 - val_val_loss: 4.9531 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7413 - val_beta: 0.0372\n",
      "Epoch 1358/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9815 - recon_loss: 0.0031 - KL loss: 2.7056 - beta: 0.0372 - val_val_loss: 4.9483 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7227 - val_beta: 0.0372\n",
      "Epoch 1359/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9686 - recon_loss: 0.0031 - KL loss: 2.6986 - beta: 0.0372 - val_val_loss: 5.0261 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7951 - val_beta: 0.0372\n",
      "Epoch 1360/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 5.0117 - recon_loss: 0.0032 - KL loss: 2.7242 - beta: 0.0372 - val_val_loss: 4.9445 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7257 - val_beta: 0.0372\n",
      "Epoch 1361/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9586 - recon_loss: 0.0031 - KL loss: 2.7220 - beta: 0.0372 - val_val_loss: 4.9663 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7370 - val_beta: 0.0372\n",
      "Epoch 1362/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9697 - recon_loss: 0.0031 - KL loss: 2.7204 - beta: 0.0372 - val_val_loss: 4.9849 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7346 - val_beta: 0.0372\n",
      "Epoch 1363/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.9797 - recon_loss: 0.0031 - KL loss: 2.7213 - beta: 0.0372 - val_val_loss: 4.9596 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7183 - val_beta: 0.0372\n",
      "Epoch 1364/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9678 - recon_loss: 0.0031 - KL loss: 2.7202 - beta: 0.0372 - val_val_loss: 4.9600 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7132 - val_beta: 0.0372\n",
      "Epoch 1365/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 5.0064 - recon_loss: 0.0032 - KL loss: 2.7219 - beta: 0.0372\n",
      "Epoch 01365: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 5.0064 - recon_loss: 0.0032 - KL loss: 2.7219 - beta: 0.0372 - val_val_loss: 5.0040 - val_val_recon_loss: 0.0031 - val_val_KL loss: 2.7346 - val_beta: 0.0372\n",
      "Epoch 1366/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9751 - recon_loss: 0.0031 - KL loss: 2.7445 - beta: 0.0372 - val_val_loss: 4.9265 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7394 - val_beta: 0.0372\n",
      "Epoch 1367/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9503 - recon_loss: 0.0030 - KL loss: 2.7442 - beta: 0.0372 - val_val_loss: 4.9199 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7751 - val_beta: 0.0372\n",
      "Epoch 1368/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.9283 - recon_loss: 0.0030 - KL loss: 2.7496 - beta: 0.0372 - val_val_loss: 4.9286 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7260 - val_beta: 0.0372\n",
      "Epoch 1369/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9187 - recon_loss: 0.0030 - KL loss: 2.7351 - beta: 0.0372 - val_val_loss: 4.9205 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7345 - val_beta: 0.0372\n",
      "Epoch 1370/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.9187 - recon_loss: 0.0030 - KL loss: 2.7382 - beta: 0.0372 - val_val_loss: 4.9063 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7502 - val_beta: 0.0372\n",
      "Epoch 1371/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9162 - recon_loss: 0.0030 - KL loss: 2.7432 - beta: 0.0372 - val_val_loss: 4.9139 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7388 - val_beta: 0.0372\n",
      "Epoch 1372/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9243 - recon_loss: 0.0030 - KL loss: 2.7414 - beta: 0.0372 - val_val_loss: 4.9181 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7377 - val_beta: 0.0372\n",
      "Epoch 1373/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9159 - recon_loss: 0.0030 - KL loss: 2.7402 - beta: 0.0372 - val_val_loss: 4.9125 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7181 - val_beta: 0.0372\n",
      "Epoch 1374/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9239 - recon_loss: 0.0030 - KL loss: 2.7347 - beta: 0.0372 - val_val_loss: 4.9171 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7378 - val_beta: 0.0372\n",
      "Epoch 1375/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.9270 - recon_loss: 0.0030 - KL loss: 2.7453 - beta: 0.0372\n",
      "Epoch 01375: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9270 - recon_loss: 0.0030 - KL loss: 2.7453 - beta: 0.0372 - val_val_loss: 4.9149 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7640 - val_beta: 0.0372\n",
      "Epoch 1376/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9108 - recon_loss: 0.0030 - KL loss: 2.7409 - beta: 0.0372 - val_val_loss: 4.9072 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7576 - val_beta: 0.0372\n",
      "Epoch 1377/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9191 - recon_loss: 0.0030 - KL loss: 2.7476 - beta: 0.0372 - val_val_loss: 4.9151 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7316 - val_beta: 0.0372\n",
      "Epoch 1378/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.9183 - recon_loss: 0.0030 - KL loss: 2.7492 - beta: 0.0372 - val_val_loss: 4.9079 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7415 - val_beta: 0.0372\n",
      "Epoch 1379/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9058 - recon_loss: 0.0030 - KL loss: 2.7488 - beta: 0.0372 - val_val_loss: 4.8931 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7539 - val_beta: 0.0372\n",
      "Epoch 1380/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9147 - recon_loss: 0.0030 - KL loss: 2.7511 - beta: 0.0372 - val_val_loss: 4.9100 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7622 - val_beta: 0.0372\n",
      "Epoch 1381/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8991 - recon_loss: 0.0030 - KL loss: 2.7494 - beta: 0.0372 - val_val_loss: 4.8948 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7226 - val_beta: 0.0372\n",
      "Epoch 1382/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8976 - recon_loss: 0.0030 - KL loss: 2.7401 - beta: 0.0372 - val_val_loss: 4.8926 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7356 - val_beta: 0.0372\n",
      "Epoch 1383/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8884 - recon_loss: 0.0030 - KL loss: 2.7395 - beta: 0.0372 - val_val_loss: 4.9025 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7368 - val_beta: 0.0372\n",
      "Epoch 1384/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9018 - recon_loss: 0.0030 - KL loss: 2.7432 - beta: 0.0372 - val_val_loss: 4.9049 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7581 - val_beta: 0.0372\n",
      "Epoch 1385/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8935 - recon_loss: 0.0030 - KL loss: 2.7420 - beta: 0.0372 - val_val_loss: 4.8895 - val_val_recon_loss: 0.0029 - val_val_KL loss: 2.7547 - val_beta: 0.0372\n",
      "Epoch 1386/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8892 - recon_loss: 0.0030 - KL loss: 2.7457 - beta: 0.0372 - val_val_loss: 4.8942 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7433 - val_beta: 0.0372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1387/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9167 - recon_loss: 0.0030 - KL loss: 2.7492 - beta: 0.0372 - val_val_loss: 4.9016 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7471 - val_beta: 0.0372\n",
      "Epoch 1388/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9128 - recon_loss: 0.0030 - KL loss: 2.7544 - beta: 0.0372 - val_val_loss: 4.9178 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7637 - val_beta: 0.0372\n",
      "Epoch 1389/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9191 - recon_loss: 0.0030 - KL loss: 2.7537 - beta: 0.0372 - val_val_loss: 4.9192 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7591 - val_beta: 0.0372\n",
      "Epoch 1390/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.9132 - recon_loss: 0.0030 - KL loss: 2.7534 - beta: 0.0372\n",
      "Epoch 01390: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.9132 - recon_loss: 0.0030 - KL loss: 2.7534 - beta: 0.0372 - val_val_loss: 4.9095 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7626 - val_beta: 0.0372\n",
      "Epoch 1391/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8993 - recon_loss: 0.0030 - KL loss: 2.7526 - beta: 0.0372 - val_val_loss: 4.9032 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7478 - val_beta: 0.0372\n",
      "Epoch 1392/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 4.8894 - recon_loss: 0.0029 - KL loss: 2.7556 - beta: 0.0372 - val_val_loss: 4.9005 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7602 - val_beta: 0.0372\n",
      "Epoch 1393/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9054 - recon_loss: 0.0030 - KL loss: 2.7575 - beta: 0.0372 - val_val_loss: 4.9021 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7636 - val_beta: 0.0372\n",
      "Epoch 1394/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.9056 - recon_loss: 0.0030 - KL loss: 2.7583 - beta: 0.0372 - val_val_loss: 4.9049 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7509 - val_beta: 0.0372\n",
      "Epoch 1395/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 4.8947 - recon_loss: 0.0030 - KL loss: 2.7517 - beta: 0.0372\n",
      "Epoch 01395: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 4.8947 - recon_loss: 0.0030 - KL loss: 2.7517 - beta: 0.0372 - val_val_loss: 4.9057 - val_val_recon_loss: 0.0030 - val_val_KL loss: 2.7518 - val_beta: 0.0372\n",
      "Epoch 1395/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 8.8156 - recon_loss: 0.0021 - KL loss: 3.9430 - beta: 0.0207 - val_val_loss: 8.4819 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0767 - val_beta: 0.0207\n",
      "Epoch 1396/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.5526 - recon_loss: 0.0019 - KL loss: 4.0502 - beta: 0.0207 - val_val_loss: 8.4795 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0295 - val_beta: 0.0207\n",
      "Epoch 1397/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4695 - recon_loss: 0.0019 - KL loss: 4.0426 - beta: 0.0207 - val_val_loss: 8.4788 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0636 - val_beta: 0.0207\n",
      "Epoch 1398/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4762 - recon_loss: 0.0019 - KL loss: 4.0576 - beta: 0.0207 - val_val_loss: 8.5377 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0603 - val_beta: 0.0207\n",
      "Epoch 1399/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.5091 - recon_loss: 0.0019 - KL loss: 4.0646 - beta: 0.0207 - val_val_loss: 8.4728 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0569 - val_beta: 0.0207\n",
      "Epoch 1400/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4376 - recon_loss: 0.0019 - KL loss: 4.0707 - beta: 0.0207 - val_val_loss: 8.5245 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0771 - val_beta: 0.0207\n",
      "Epoch 1401/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4476 - recon_loss: 0.0019 - KL loss: 4.0872 - beta: 0.0207 - val_val_loss: 8.3656 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0588 - val_beta: 0.0207\n",
      "Epoch 1402/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3875 - recon_loss: 0.0018 - KL loss: 4.0822 - beta: 0.0207 - val_val_loss: 8.3794 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0566 - val_beta: 0.0207\n",
      "Epoch 1403/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4143 - recon_loss: 0.0018 - KL loss: 4.0805 - beta: 0.0207 - val_val_loss: 8.3725 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1002 - val_beta: 0.0207\n",
      "Epoch 1404/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4173 - recon_loss: 0.0018 - KL loss: 4.0894 - beta: 0.0207 - val_val_loss: 8.3750 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0819 - val_beta: 0.0207\n",
      "Epoch 1405/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4152 - recon_loss: 0.0018 - KL loss: 4.0816 - beta: 0.0207 - val_val_loss: 8.3713 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0323 - val_beta: 0.0207\n",
      "Epoch 1406/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3741 - recon_loss: 0.0018 - KL loss: 4.0744 - beta: 0.0207 - val_val_loss: 8.3576 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0458 - val_beta: 0.0207\n",
      "Epoch 1407/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 8.3913 - recon_loss: 0.0018 - KL loss: 4.0875 - beta: 0.0207 - val_val_loss: 8.4156 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1541 - val_beta: 0.0207\n",
      "Epoch 1408/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3866 - recon_loss: 0.0018 - KL loss: 4.1112 - beta: 0.0207 - val_val_loss: 8.4218 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0096 - val_beta: 0.0207\n",
      "Epoch 1409/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3783 - recon_loss: 0.0018 - KL loss: 4.0888 - beta: 0.0207 - val_val_loss: 8.4153 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1164 - val_beta: 0.0207\n",
      "Epoch 1410/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4010 - recon_loss: 0.0018 - KL loss: 4.0781 - beta: 0.0207 - val_val_loss: 8.4644 - val_val_recon_loss: 0.0019 - val_val_KL loss: 4.0435 - val_beta: 0.0207\n",
      "Epoch 1411/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.4356 - recon_loss: 0.0019 - KL loss: 4.0555 - beta: 0.0207 - val_val_loss: 8.3228 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0513 - val_beta: 0.0207\n",
      "Epoch 1412/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3764 - recon_loss: 0.0018 - KL loss: 4.0725 - beta: 0.0207 - val_val_loss: 8.3544 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0787 - val_beta: 0.0207\n",
      "Epoch 1413/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3975 - recon_loss: 0.0018 - KL loss: 4.0714 - beta: 0.0207 - val_val_loss: 8.2985 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1169 - val_beta: 0.0207\n",
      "Epoch 1414/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 8.3480 - recon_loss: 0.0018 - KL loss: 4.0855 - beta: 0.0207 - val_val_loss: 8.3583 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0558 - val_beta: 0.0207\n",
      "Epoch 1415/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3226 - recon_loss: 0.0018 - KL loss: 4.0734 - beta: 0.0207 - val_val_loss: 8.3260 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1981 - val_beta: 0.0207\n",
      "Epoch 1416/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3698 - recon_loss: 0.0018 - KL loss: 4.0919 - beta: 0.0207 - val_val_loss: 8.3664 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1278 - val_beta: 0.0207\n",
      "Epoch 1417/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 8.3141 - recon_loss: 0.0018 - KL loss: 4.1021 - beta: 0.0207 - val_val_loss: 8.3547 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1076 - val_beta: 0.0207\n",
      "Epoch 1418/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.3671 - recon_loss: 0.0018 - KL loss: 4.1125 - beta: 0.0207\n",
      "Epoch 01418: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3672 - recon_loss: 0.0018 - KL loss: 4.1125 - beta: 0.0207 - val_val_loss: 8.4245 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0932 - val_beta: 0.0207\n",
      "Epoch 1419/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3485 - recon_loss: 0.0018 - KL loss: 4.1119 - beta: 0.0207 - val_val_loss: 8.3115 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0951 - val_beta: 0.0207\n",
      "Epoch 1420/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2961 - recon_loss: 0.0018 - KL loss: 4.0972 - beta: 0.0207 - val_val_loss: 8.3241 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0718 - val_beta: 0.0207\n",
      "Epoch 1421/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.3031 - recon_loss: 0.0018 - KL loss: 4.0746 - beta: 0.0207 - val_val_loss: 8.3338 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0666 - val_beta: 0.0207\n",
      "Epoch 1422/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2976 - recon_loss: 0.0018 - KL loss: 4.0725 - beta: 0.0207 - val_val_loss: 8.3049 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1011 - val_beta: 0.0207\n",
      "Epoch 1423/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2910 - recon_loss: 0.0018 - KL loss: 4.0898 - beta: 0.0207 - val_val_loss: 8.2729 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0764 - val_beta: 0.0207\n",
      "Epoch 1424/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2712 - recon_loss: 0.0018 - KL loss: 4.0886 - beta: 0.0207 - val_val_loss: 8.2586 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1449 - val_beta: 0.0207\n",
      "Epoch 1425/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2396 - recon_loss: 0.0018 - KL loss: 4.0922 - beta: 0.0207 - val_val_loss: 8.2659 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0998 - val_beta: 0.0207\n",
      "Epoch 1426/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2015 - recon_loss: 0.0018 - KL loss: 4.0968 - beta: 0.0207 - val_val_loss: 8.2596 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0997 - val_beta: 0.0207\n",
      "Epoch 1427/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2802 - recon_loss: 0.0018 - KL loss: 4.0925 - beta: 0.0207 - val_val_loss: 8.2482 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1226 - val_beta: 0.0207\n",
      "Epoch 1428/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2320 - recon_loss: 0.0018 - KL loss: 4.0875 - beta: 0.0207 - val_val_loss: 8.2300 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0955 - val_beta: 0.0207\n",
      "Epoch 1429/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2341 - recon_loss: 0.0018 - KL loss: 4.0840 - beta: 0.0207 - val_val_loss: 8.2230 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0660 - val_beta: 0.0207\n",
      "Epoch 1430/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2360 - recon_loss: 0.0018 - KL loss: 4.0967 - beta: 0.0207 - val_val_loss: 8.2410 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1252 - val_beta: 0.0207\n",
      "Epoch 1431/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2093 - recon_loss: 0.0018 - KL loss: 4.0989 - beta: 0.0207 - val_val_loss: 8.2496 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0957 - val_beta: 0.0207\n",
      "Epoch 1432/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2214 - recon_loss: 0.0018 - KL loss: 4.0988 - beta: 0.0207 - val_val_loss: 8.2224 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1050 - val_beta: 0.0207\n",
      "Epoch 1433/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2609 - recon_loss: 0.0018 - KL loss: 4.1055 - beta: 0.0207 - val_val_loss: 8.2785 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1010 - val_beta: 0.0207\n",
      "Epoch 1434/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2339 - recon_loss: 0.0018 - KL loss: 4.0998 - beta: 0.0207 - val_val_loss: 8.2224 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0925 - val_beta: 0.0207\n",
      "Epoch 1435/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2330 - recon_loss: 0.0018 - KL loss: 4.0925 - beta: 0.0207 - val_val_loss: 8.2269 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0577 - val_beta: 0.0207\n",
      "Epoch 1436/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2303 - recon_loss: 0.0018 - KL loss: 4.0838 - beta: 0.0207 - val_val_loss: 8.2514 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0772 - val_beta: 0.0207\n",
      "Epoch 1437/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.2155 - recon_loss: 0.0018 - KL loss: 4.0713 - beta: 0.0207\n",
      "Epoch 01437: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2155 - recon_loss: 0.0018 - KL loss: 4.0713 - beta: 0.0207 - val_val_loss: 8.2427 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.1301 - val_beta: 0.0207\n",
      "Epoch 1438/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2236 - recon_loss: 0.0018 - KL loss: 4.0976 - beta: 0.0207 - val_val_loss: 8.1978 - val_val_recon_loss: 0.0017 - val_val_KL loss: 4.0998 - val_beta: 0.0207\n",
      "Epoch 1439/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.1718 - recon_loss: 0.0017 - KL loss: 4.0833 - beta: 0.0207 - val_val_loss: 8.1858 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0832 - val_beta: 0.0207\n",
      "Epoch 1440/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.1927 - recon_loss: 0.0018 - KL loss: 4.0848 - beta: 0.0207 - val_val_loss: 8.1893 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0761 - val_beta: 0.0207\n",
      "Epoch 1441/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2246 - recon_loss: 0.0018 - KL loss: 4.0842 - beta: 0.0207 - val_val_loss: 8.2174 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0869 - val_beta: 0.0207\n",
      "Epoch 1442/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.1947 - recon_loss: 0.0018 - KL loss: 4.0927 - beta: 0.0207 - val_val_loss: 8.1889 - val_val_recon_loss: 0.0017 - val_val_KL loss: 4.1185 - val_beta: 0.0207\n",
      "Epoch 1443/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2035 - recon_loss: 0.0018 - KL loss: 4.0868 - beta: 0.0207 - val_val_loss: 8.2072 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0870 - val_beta: 0.0207\n",
      "Epoch 1444/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.2088 - recon_loss: 0.0018 - KL loss: 4.0821 - beta: 0.0207\n",
      "Epoch 01444: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2087 - recon_loss: 0.0018 - KL loss: 4.0821 - beta: 0.0207 - val_val_loss: 8.2039 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0714 - val_beta: 0.0207\n",
      "Epoch 1445/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.1884 - recon_loss: 0.0018 - KL loss: 4.0782 - beta: 0.0207 - val_val_loss: 8.2001 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0794 - val_beta: 0.0207\n",
      "Epoch 1446/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2212 - recon_loss: 0.0018 - KL loss: 4.0836 - beta: 0.0207 - val_val_loss: 8.1988 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0893 - val_beta: 0.0207\n",
      "Epoch 1447/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2254 - recon_loss: 0.0018 - KL loss: 4.0878 - beta: 0.0207 - val_val_loss: 8.2043 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0884 - val_beta: 0.0207\n",
      "Epoch 1448/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.2018 - recon_loss: 0.0018 - KL loss: 4.0912 - beta: 0.0207 - val_val_loss: 8.2059 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0853 - val_beta: 0.0207\n",
      "Epoch 1449/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 8.1722 - recon_loss: 0.0017 - KL loss: 4.0841 - beta: 0.0207\n",
      "Epoch 01449: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 8.1722 - recon_loss: 0.0017 - KL loss: 4.0841 - beta: 0.0207 - val_val_loss: 8.2017 - val_val_recon_loss: 0.0018 - val_val_KL loss: 4.0861 - val_beta: 0.0207\n",
      "Epoch 1449/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.7959 - recon_loss: 0.0015 - KL loss: 5.2486 - beta: 0.0115 - val_val_loss: 16.5466 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.2983 - val_beta: 0.0115\n",
      "Epoch 1450/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.6173 - recon_loss: 0.0015 - KL loss: 5.3202 - beta: 0.0115 - val_val_loss: 16.5288 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3581 - val_beta: 0.0115\n",
      "Epoch 1451/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.4849 - recon_loss: 0.0015 - KL loss: 5.3521 - beta: 0.0115 - val_val_loss: 16.8190 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4194 - val_beta: 0.0115\n",
      "Epoch 1452/10000\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 16.8882 - recon_loss: 0.0015 - KL loss: 5.3984 - beta: 0.0115 - val_val_loss: 16.5676 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3369 - val_beta: 0.0115\n",
      "Epoch 1453/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 16.7157 - recon_loss: 0.0015 - KL loss: 5.3790 - beta: 0.0115 - val_val_loss: 16.5150 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3658 - val_beta: 0.0115\n",
      "Epoch 1454/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.4322 - recon_loss: 0.0015 - KL loss: 5.3910 - beta: 0.0115 - val_val_loss: 16.4319 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4115 - val_beta: 0.0115\n",
      "Epoch 1455/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.3948 - recon_loss: 0.0015 - KL loss: 5.3696 - beta: 0.0115 - val_val_loss: 16.5048 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3043 - val_beta: 0.0115\n",
      "Epoch 1456/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.3973 - recon_loss: 0.0015 - KL loss: 5.3487 - beta: 0.0115 - val_val_loss: 16.6187 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4017 - val_beta: 0.0115\n",
      "Epoch 1457/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.7326 - recon_loss: 0.0015 - KL loss: 5.3766 - beta: 0.0115 - val_val_loss: 16.5360 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3011 - val_beta: 0.0115\n",
      "Epoch 1458/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 16.6434 - recon_loss: 0.0015 - KL loss: 5.3951 - beta: 0.0115 - val_val_loss: 16.7561 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3852 - val_beta: 0.0115\n",
      "Epoch 1459/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 16.6135 - recon_loss: 0.0015 - KL loss: 5.3990 - beta: 0.0115\n",
      "Epoch 01459: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.6136 - recon_loss: 0.0015 - KL loss: 5.3990 - beta: 0.0115 - val_val_loss: 16.6986 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.1347 - val_beta: 0.0115\n",
      "Epoch 1460/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.5206 - recon_loss: 0.0015 - KL loss: 5.3660 - beta: 0.0115 - val_val_loss: 16.5294 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4174 - val_beta: 0.0115\n",
      "Epoch 1461/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 16.5814 - recon_loss: 0.0015 - KL loss: 5.4088 - beta: 0.0115 - val_val_loss: 16.6161 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4008 - val_beta: 0.0115\n",
      "Epoch 1462/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.6155 - recon_loss: 0.0015 - KL loss: 5.4323 - beta: 0.0115 - val_val_loss: 16.7461 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4347 - val_beta: 0.0115\n",
      "Epoch 1463/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 16.7827 - recon_loss: 0.0015 - KL loss: 5.4522 - beta: 0.0115 - val_val_loss: 16.7082 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.4487 - val_beta: 0.0115\n",
      "Epoch 1464/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 16.6373 - recon_loss: 0.0015 - KL loss: 5.4391 - beta: 0.0115\n",
      "Epoch 01464: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 16.6372 - recon_loss: 0.0015 - KL loss: 5.4391 - beta: 0.0115 - val_val_loss: 16.6299 - val_val_recon_loss: 0.0015 - val_val_KL loss: 5.3994 - val_beta: 0.0115\n",
      "Epoch 1464/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 43.4451 - recon_loss: 0.0015 - KL loss: 6.6631 - beta: 0.0064 - val_val_loss: 43.4661 - val_val_recon_loss: 0.0015 - val_val_KL loss: 6.8600 - val_beta: 0.0064\n",
      "Epoch 1465/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 43.5024 - recon_loss: 0.0015 - KL loss: 7.0650 - beta: 0.0064 - val_val_loss: 41.4834 - val_val_recon_loss: 0.0014 - val_val_KL loss: 7.0630 - val_beta: 0.0064\n",
      "Epoch 1466/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 41.1016 - recon_loss: 0.0014 - KL loss: 6.9958 - beta: 0.0064 - val_val_loss: 40.2988 - val_val_recon_loss: 0.0014 - val_val_KL loss: 6.9980 - val_beta: 0.0064\n",
      "Epoch 1467/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 39.9393 - recon_loss: 0.0013 - KL loss: 7.0424 - beta: 0.0064 - val_val_loss: 39.6466 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.0555 - val_beta: 0.0064\n",
      "Epoch 1468/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 39.5393 - recon_loss: 0.0013 - KL loss: 7.0886 - beta: 0.0064 - val_val_loss: 39.1513 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.0914 - val_beta: 0.0064\n",
      "Epoch 1469/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 38.8692 - recon_loss: 0.0013 - KL loss: 7.1359 - beta: 0.0064 - val_val_loss: 38.9814 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.2462 - val_beta: 0.0064\n",
      "Epoch 1470/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 38.7484 - recon_loss: 0.0013 - KL loss: 7.2765 - beta: 0.0064 - val_val_loss: 38.4193 - val_val_recon_loss: 0.0013 - val_val_KL loss: 7.3144 - val_beta: 0.0064\n",
      "Epoch 1471/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 38.0956 - recon_loss: 0.0013 - KL loss: 7.4078 - beta: 0.0064 - val_val_loss: 37.7369 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.5097 - val_beta: 0.0064\n",
      "Epoch 1472/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.6566 - recon_loss: 0.0012 - KL loss: 7.5325 - beta: 0.0064 - val_val_loss: 37.5145 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.6461 - val_beta: 0.0064\n",
      "Epoch 1473/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 37.3646 - recon_loss: 0.0012 - KL loss: 7.6162 - beta: 0.0064 - val_val_loss: 37.2573 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.6781 - val_beta: 0.0064\n",
      "Epoch 1474/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.1692 - recon_loss: 0.0012 - KL loss: 7.6846 - beta: 0.0064 - val_val_loss: 37.3692 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.7382 - val_beta: 0.0064\n",
      "Epoch 1475/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.0459 - recon_loss: 0.0012 - KL loss: 7.7395 - beta: 0.0064 - val_val_loss: 37.0905 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.7912 - val_beta: 0.0064\n",
      "Epoch 1476/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.0687 - recon_loss: 0.0012 - KL loss: 7.7843 - beta: 0.0064 - val_val_loss: 37.1483 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.8462 - val_beta: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1477/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.7504 - recon_loss: 0.0012 - KL loss: 7.8116 - beta: 0.0064 - val_val_loss: 36.7887 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.8921 - val_beta: 0.0064\n",
      "Epoch 1478/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 37.1083 - recon_loss: 0.0012 - KL loss: 7.8956 - beta: 0.0064 - val_val_loss: 37.3102 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.8383 - val_beta: 0.0064\n",
      "Epoch 1479/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 37.3692 - recon_loss: 0.0012 - KL loss: 7.8789 - beta: 0.0064 - val_val_loss: 37.3554 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.8499 - val_beta: 0.0064\n",
      "Epoch 1480/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.7914 - recon_loss: 0.0012 - KL loss: 7.9704 - beta: 0.0064 - val_val_loss: 38.6289 - val_val_recon_loss: 0.0012 - val_val_KL loss: 8.0926 - val_beta: 0.0064\n",
      "Epoch 1481/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 38.5164 - recon_loss: 0.0012 - KL loss: 8.1194 - beta: 0.0064 - val_val_loss: 37.7122 - val_val_recon_loss: 0.0012 - val_val_KL loss: 8.0000 - val_beta: 0.0064\n",
      "Epoch 1482/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 38.1963 - recon_loss: 0.0012 - KL loss: 8.1140 - beta: 0.0064\n",
      "Epoch 01482: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 38.1964 - recon_loss: 0.0012 - KL loss: 8.1140 - beta: 0.0064 - val_val_loss: 37.3442 - val_val_recon_loss: 0.0012 - val_val_KL loss: 8.0923 - val_beta: 0.0064\n",
      "Epoch 1483/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.0914 - recon_loss: 0.0012 - KL loss: 8.0378 - beta: 0.0064 - val_val_loss: 37.1502 - val_val_recon_loss: 0.0012 - val_val_KL loss: 8.0133 - val_beta: 0.0064\n",
      "Epoch 1484/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 37.1835 - recon_loss: 0.0012 - KL loss: 8.0005 - beta: 0.0064 - val_val_loss: 36.7332 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.9238 - val_beta: 0.0064\n",
      "Epoch 1485/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.4513 - recon_loss: 0.0012 - KL loss: 7.9339 - beta: 0.0064 - val_val_loss: 36.6175 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.9753 - val_beta: 0.0064\n",
      "Epoch 1486/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.4827 - recon_loss: 0.0012 - KL loss: 7.9592 - beta: 0.0064 - val_val_loss: 36.3193 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.9361 - val_beta: 0.0064\n",
      "Epoch 1487/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.4873 - recon_loss: 0.0012 - KL loss: 7.9616 - beta: 0.0064 - val_val_loss: 36.2884 - val_val_recon_loss: 0.0012 - val_val_KL loss: 7.9710 - val_beta: 0.0064\n",
      "Epoch 1488/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.5366 - recon_loss: 0.0012 - KL loss: 8.0035 - beta: 0.0064 - val_val_loss: 36.1557 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0000 - val_beta: 0.0064\n",
      "Epoch 1489/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.3069 - recon_loss: 0.0012 - KL loss: 8.0142 - beta: 0.0064 - val_val_loss: 35.9920 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0338 - val_beta: 0.0064\n",
      "Epoch 1490/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.0002 - recon_loss: 0.0011 - KL loss: 7.9860 - beta: 0.0064 - val_val_loss: 36.0027 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0458 - val_beta: 0.0064\n",
      "Epoch 1491/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.0153 - recon_loss: 0.0011 - KL loss: 7.9882 - beta: 0.0064 - val_val_loss: 35.9980 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0047 - val_beta: 0.0064\n",
      "Epoch 1492/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 36.0476 - recon_loss: 0.0011 - KL loss: 7.9944 - beta: 0.0064 - val_val_loss: 36.1147 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0058 - val_beta: 0.0064\n",
      "Epoch 1493/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.1262 - recon_loss: 0.0011 - KL loss: 8.0250 - beta: 0.0064 - val_val_loss: 36.2331 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0545 - val_beta: 0.0064\n",
      "Epoch 1494/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 36.2605 - recon_loss: 0.0012 - KL loss: 8.0352 - beta: 0.0064\n",
      "Epoch 01494: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.2606 - recon_loss: 0.0012 - KL loss: 8.0352 - beta: 0.0064 - val_val_loss: 36.1824 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0373 - val_beta: 0.0064\n",
      "Epoch 1495/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.0706 - recon_loss: 0.0011 - KL loss: 8.0279 - beta: 0.0064 - val_val_loss: 36.1839 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0550 - val_beta: 0.0064\n",
      "Epoch 1496/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.9865 - recon_loss: 0.0011 - KL loss: 8.0494 - beta: 0.0064 - val_val_loss: 36.0517 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0462 - val_beta: 0.0064\n",
      "Epoch 1497/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.2049 - recon_loss: 0.0011 - KL loss: 8.0349 - beta: 0.0064 - val_val_loss: 36.0466 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0265 - val_beta: 0.0064\n",
      "Epoch 1498/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 35.9828 - recon_loss: 0.0011 - KL loss: 8.0214 - beta: 0.0064 - val_val_loss: 36.2212 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0941 - val_beta: 0.0064\n",
      "Epoch 1499/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 36.1930 - recon_loss: 0.0011 - KL loss: 8.0532 - beta: 0.0064\n",
      "Epoch 01499: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 36.1929 - recon_loss: 0.0011 - KL loss: 8.0532 - beta: 0.0064 - val_val_loss: 36.0086 - val_val_recon_loss: 0.0011 - val_val_KL loss: 8.0204 - val_beta: 0.0064\n",
      "Epoch 1499/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 101.4232 - recon_loss: 0.0012 - KL loss: 10.0793 - beta: 0.0035 - val_val_loss: 99.3053 - val_val_recon_loss: 0.0011 - val_val_KL loss: 10.8861 - val_beta: 0.0035\n",
      "Epoch 1500/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 98.2342 - recon_loss: 0.0011 - KL loss: 10.7456 - beta: 0.0035 - val_val_loss: 99.2486 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1345 - val_beta: 0.0035\n",
      "Epoch 1501/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 97.0721 - recon_loss: 0.0011 - KL loss: 10.8606 - beta: 0.0035 - val_val_loss: 97.1952 - val_val_recon_loss: 0.0011 - val_val_KL loss: 10.9631 - val_beta: 0.0035\n",
      "Epoch 1502/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 98.2356 - recon_loss: 0.0011 - KL loss: 11.0364 - beta: 0.0035 - val_val_loss: 99.3442 - val_val_recon_loss: 0.0011 - val_val_KL loss: 10.8573 - val_beta: 0.0035\n",
      "Epoch 1503/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 99.2517 - recon_loss: 0.0011 - KL loss: 10.8979 - beta: 0.0035 - val_val_loss: 99.9083 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.0939 - val_beta: 0.0035\n",
      "Epoch 1504/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 99.4769 - recon_loss: 0.0011 - KL loss: 11.0955 - beta: 0.0035 - val_val_loss: 98.3639 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.0114 - val_beta: 0.0035\n",
      "Epoch 1505/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 97.5536 - recon_loss: 0.0011 - KL loss: 11.0337 - beta: 0.0035 - val_val_loss: 97.6781 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.0513 - val_beta: 0.0035\n",
      "Epoch 1506/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 98.4462 - recon_loss: 0.0011 - KL loss: 11.1638 - beta: 0.0035\n",
      "Epoch 01506: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 98.4458 - recon_loss: 0.0011 - KL loss: 11.1638 - beta: 0.0035 - val_val_loss: 98.2264 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.2340 - val_beta: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1507/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96.7840 - recon_loss: 0.0011 - KL loss: 11.2413 - beta: 0.0035 - val_val_loss: 96.0201 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.0768 - val_beta: 0.0035\n",
      "Epoch 1508/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 96.4098 - recon_loss: 0.0011 - KL loss: 11.1753 - beta: 0.0035 - val_val_loss: 95.8321 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1602 - val_beta: 0.0035\n",
      "Epoch 1509/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96.1042 - recon_loss: 0.0011 - KL loss: 11.2770 - beta: 0.0035 - val_val_loss: 95.9999 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.2522 - val_beta: 0.0035\n",
      "Epoch 1510/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96.3479 - recon_loss: 0.0011 - KL loss: 11.2213 - beta: 0.0035 - val_val_loss: 96.0295 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1817 - val_beta: 0.0035\n",
      "Epoch 1511/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96.0333 - recon_loss: 0.0011 - KL loss: 11.2547 - beta: 0.0035 - val_val_loss: 96.7696 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.2617 - val_beta: 0.0035\n",
      "Epoch 1512/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 96.6433 - recon_loss: 0.0011 - KL loss: 11.2311 - beta: 0.0035 - val_val_loss: 96.4477 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.0958 - val_beta: 0.0035\n",
      "Epoch 1513/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 95.1655 - recon_loss: 0.0011 - KL loss: 11.1503 - beta: 0.0035- ETA: 6s - loss: 95.\n",
      "Epoch 01513: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95.1662 - recon_loss: 0.0011 - KL loss: 11.1503 - beta: 0.0035 - val_val_loss: 96.0767 - val_val_recon_loss: 0.0011 - val_val_KL loss: 10.9789 - val_beta: 0.0035\n",
      "Epoch 1514/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95.6147 - recon_loss: 0.0011 - KL loss: 11.0407 - beta: 0.0035 - val_val_loss: 95.3901 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.2146 - val_beta: 0.0035\n",
      "Epoch 1515/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 95.0459 - recon_loss: 0.0011 - KL loss: 11.1707 - beta: 0.0035 - val_val_loss: 95.2015 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1143 - val_beta: 0.0035\n",
      "Epoch 1516/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 95.2665 - recon_loss: 0.0011 - KL loss: 11.1438 - beta: 0.0035 - val_val_loss: 94.9986 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1086 - val_beta: 0.0035\n",
      "Epoch 1517/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 95.0635 - recon_loss: 0.0011 - KL loss: 11.1371 - beta: 0.0035 - val_val_loss: 95.1969 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1160 - val_beta: 0.0035\n",
      "Epoch 1518/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 93.8258 - recon_loss: 0.0010 - KL loss: 11.1803 - beta: 0.0035 - val_val_loss: 95.0389 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1554 - val_beta: 0.0035\n",
      "Epoch 1519/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.8899 - recon_loss: 0.0011 - KL loss: 11.2094 - beta: 0.0035 - val_val_loss: 95.1811 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1820 - val_beta: 0.0035\n",
      "Epoch 1520/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95.7542 - recon_loss: 0.0011 - KL loss: 11.1798 - beta: 0.0035 - val_val_loss: 95.1580 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.2714 - val_beta: 0.0035\n",
      "Epoch 1521/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 94.7550 - recon_loss: 0.0011 - KL loss: 11.2267 - beta: 0.0035\n",
      "Epoch 01521: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.7554 - recon_loss: 0.0011 - KL loss: 11.2267 - beta: 0.0035 - val_val_loss: 95.0153 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1494 - val_beta: 0.0035\n",
      "Epoch 1522/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.9222 - recon_loss: 0.0011 - KL loss: 11.1800 - beta: 0.0035 - val_val_loss: 94.9318 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1278 - val_beta: 0.0035\n",
      "Epoch 1523/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95.0487 - recon_loss: 0.0011 - KL loss: 11.1787 - beta: 0.0035 - val_val_loss: 95.2249 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1032 - val_beta: 0.0035\n",
      "Epoch 1524/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.7152 - recon_loss: 0.0011 - KL loss: 11.1529 - beta: 0.0035 - val_val_loss: 94.8842 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1219 - val_beta: 0.0035\n",
      "Epoch 1525/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.6145 - recon_loss: 0.0011 - KL loss: 11.1421 - beta: 0.0035 - val_val_loss: 94.8069 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1471 - val_beta: 0.0035\n",
      "Epoch 1526/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.6337 - recon_loss: 0.0011 - KL loss: 11.1457 - beta: 0.0035 - val_val_loss: 94.6058 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1363 - val_beta: 0.0035\n",
      "Epoch 1527/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.3245 - recon_loss: 0.0010 - KL loss: 11.1798 - beta: 0.0035 - val_val_loss: 94.6676 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1395 - val_beta: 0.0035\n",
      "Epoch 1528/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 95.4231 - recon_loss: 0.0011 - KL loss: 11.1820 - beta: 0.0035 - val_val_loss: 94.6624 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.0987 - val_beta: 0.0035\n",
      "Epoch 1529/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.5686 - recon_loss: 0.0011 - KL loss: 11.0645 - beta: 0.0035 - val_val_loss: 94.4290 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.0927 - val_beta: 0.0035\n",
      "Epoch 1530/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.6492 - recon_loss: 0.0011 - KL loss: 11.1599 - beta: 0.0035 - val_val_loss: 95.0016 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1131 - val_beta: 0.0035\n",
      "Epoch 1531/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.0452 - recon_loss: 0.0010 - KL loss: 11.1656 - beta: 0.0035 - val_val_loss: 94.5463 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1358 - val_beta: 0.0035\n",
      "Epoch 1532/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.4251 - recon_loss: 0.0010 - KL loss: 11.1634 - beta: 0.0035 - val_val_loss: 94.5570 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1451 - val_beta: 0.0035\n",
      "Epoch 1533/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.5301 - recon_loss: 0.0010 - KL loss: 11.1690 - beta: 0.0035 - val_val_loss: 94.5919 - val_val_recon_loss: 0.0011 - val_val_KL loss: 11.1215 - val_beta: 0.0035\n",
      "Epoch 1534/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 94.9622 - recon_loss: 0.0011 - KL loss: 11.1699 - beta: 0.0035\n",
      "Epoch 01534: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.9621 - recon_loss: 0.0011 - KL loss: 11.1699 - beta: 0.0035 - val_val_loss: 94.4426 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1535 - val_beta: 0.0035\n",
      "Epoch 1535/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 95.5393 - recon_loss: 0.0011 - KL loss: 11.2184 - beta: 0.0035 - val_val_loss: 94.4062 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1611 - val_beta: 0.0035\n",
      "Epoch 1536/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.5648 - recon_loss: 0.0010 - KL loss: 11.2057 - beta: 0.0035 - val_val_loss: 94.1751 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1516 - val_beta: 0.0035\n",
      "Epoch 1537/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93.5676 - recon_loss: 0.0010 - KL loss: 11.1611 - beta: 0.0035 - val_val_loss: 94.3405 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1468 - val_beta: 0.0035\n",
      "Epoch 1538/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.5359 - recon_loss: 0.0010 - KL loss: 11.1990 - beta: 0.0035 - val_val_loss: 94.0098 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1401 - val_beta: 0.0035\n",
      "Epoch 1539/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 93.6817 - recon_loss: 0.0010 - KL loss: 11.1720 - beta: 0.0035 - val_val_loss: 94.1401 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1459 - val_beta: 0.0035\n",
      "Epoch 1540/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 93.6590 - recon_loss: 0.0010 - KL loss: 11.1485 - beta: 0.0035 - val_val_loss: 94.0221 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1476 - val_beta: 0.0035\n",
      "Epoch 1541/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.3355 - recon_loss: 0.0010 - KL loss: 11.1815 - beta: 0.0035 - val_val_loss: 93.9829 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1558 - val_beta: 0.0035\n",
      "Epoch 1542/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.8288 - recon_loss: 0.0011 - KL loss: 11.1830 - beta: 0.0035 - val_val_loss: 94.1466 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1458 - val_beta: 0.0035\n",
      "Epoch 1543/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.7254 - recon_loss: 0.0011 - KL loss: 11.2042 - beta: 0.0035 - val_val_loss: 94.1122 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1434 - val_beta: 0.0035\n",
      "Epoch 1544/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.0183 - recon_loss: 0.0010 - KL loss: 11.1736 - beta: 0.0035 - val_val_loss: 94.2011 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1608 - val_beta: 0.0035\n",
      "Epoch 1545/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.8680 - recon_loss: 0.0011 - KL loss: 11.1795 - beta: 0.0035 - val_val_loss: 94.1536 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1399 - val_beta: 0.0035\n",
      "Epoch 1546/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.2093 - recon_loss: 0.0010 - KL loss: 11.1959 - beta: 0.0035 - val_val_loss: 93.9588 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1384 - val_beta: 0.0035\n",
      "Epoch 1547/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.7413 - recon_loss: 0.0011 - KL loss: 11.2110 - beta: 0.0035 - val_val_loss: 94.2316 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1461 - val_beta: 0.0035\n",
      "Epoch 1548/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.7124 - recon_loss: 0.0011 - KL loss: 11.1764 - beta: 0.0035 - val_val_loss: 94.3055 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1398 - val_beta: 0.0035\n",
      "Epoch 1549/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 93.4873 - recon_loss: 0.0010 - KL loss: 11.1242 - beta: 0.0035 - val_val_loss: 94.0277 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1485 - val_beta: 0.0035\n",
      "Epoch 1550/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.4608 - recon_loss: 0.0010 - KL loss: 11.1562 - beta: 0.0035 - val_val_loss: 94.1589 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1423 - val_beta: 0.0035\n",
      "Epoch 1551/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 93.8594 - recon_loss: 0.0010 - KL loss: 11.1738 - beta: 0.0035\n",
      "Epoch 01551: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93.8601 - recon_loss: 0.0010 - KL loss: 11.1738 - beta: 0.0035 - val_val_loss: 94.1127 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1359 - val_beta: 0.0035\n",
      "Epoch 1552/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.3349 - recon_loss: 0.0010 - KL loss: 11.1892 - beta: 0.0035 - val_val_loss: 94.2445 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1377 - val_beta: 0.0035\n",
      "Epoch 1553/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95.0994 - recon_loss: 0.0011 - KL loss: 11.1764 - beta: 0.0035 - val_val_loss: 94.2144 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1418 - val_beta: 0.0035\n",
      "Epoch 1554/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94.3670 - recon_loss: 0.0010 - KL loss: 11.1456 - beta: 0.0035 - val_val_loss: 94.1848 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1429 - val_beta: 0.0035\n",
      "Epoch 1555/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.2639 - recon_loss: 0.0010 - KL loss: 11.1804 - beta: 0.0035 - val_val_loss: 94.1461 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1496 - val_beta: 0.0035\n",
      "Epoch 1556/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 94.8266 - recon_loss: 0.0011 - KL loss: 11.2005 - beta: 0.0035\n",
      "Epoch 01556: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 94.8266 - recon_loss: 0.0011 - KL loss: 11.2005 - beta: 0.0035 - val_val_loss: 94.0143 - val_val_recon_loss: 0.0010 - val_val_KL loss: 11.1514 - val_beta: 0.0035\n",
      "Epoch 1556/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 294.6963 - recon_loss: 0.0011 - KL loss: 14.1943 - beta: 0.0020 - val_val_loss: 284.2715 - val_val_recon_loss: 0.0010 - val_val_KL loss: 15.0328 - val_beta: 0.0020\n",
      "Epoch 1557/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 287.2007 - recon_loss: 0.0011 - KL loss: 15.3142 - beta: 0.0020 - val_val_loss: 289.1927 - val_val_recon_loss: 0.0011 - val_val_KL loss: 16.0566 - val_beta: 0.0020\n",
      "Epoch 1558/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 287.3280 - recon_loss: 0.0011 - KL loss: 16.0424 - beta: 0.0020 - val_val_loss: 279.5905 - val_val_recon_loss: 0.0010 - val_val_KL loss: 15.8194 - val_beta: 0.0020\n",
      "Epoch 1559/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 278.2480 - recon_loss: 0.0010 - KL loss: 15.8241 - beta: 0.0020 - val_val_loss: 282.2134 - val_val_recon_loss: 0.0010 - val_val_KL loss: 16.1074 - val_beta: 0.0020\n",
      "Epoch 1560/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 282.7798 - recon_loss: 0.0010 - KL loss: 16.1638 - beta: 0.0020 - val_val_loss: 288.4546 - val_val_recon_loss: 0.0011 - val_val_KL loss: 16.6217 - val_beta: 0.0020\n",
      "Epoch 1561/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 288.3847 - recon_loss: 0.0011 - KL loss: 16.6875 - beta: 0.0020 - val_val_loss: 290.4715 - val_val_recon_loss: 0.0011 - val_val_KL loss: 17.1163 - val_beta: 0.0020\n",
      "Epoch 1562/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 291.3066 - recon_loss: 0.0011 - KL loss: 17.1934 - beta: 0.0020 - val_val_loss: 284.6950 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.0293 - val_beta: 0.0020\n",
      "Epoch 1563/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 290.0777 - recon_loss: 0.0011 - KL loss: 17.2118 - beta: 0.0020\n",
      "Epoch 01563: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 290.0767 - recon_loss: 0.0011 - KL loss: 17.2117 - beta: 0.0020 - val_val_loss: 286.5746 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.0086 - val_beta: 0.0020\n",
      "Epoch 1564/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 283.3914 - recon_loss: 0.0010 - KL loss: 17.0412 - beta: 0.0020 - val_val_loss: 277.3213 - val_val_recon_loss: 0.0010 - val_val_KL loss: 16.8457 - val_beta: 0.0020\n",
      "Epoch 1565/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 276.3371 - recon_loss: 0.0010 - KL loss: 16.9066 - beta: 0.0020 - val_val_loss: 276.0626 - val_val_recon_loss: 0.0010 - val_val_KL loss: 17.1856 - val_beta: 0.0020\n",
      "Epoch 1566/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 276.3639 - recon_loss: 0.0010 - KL loss: 16.9384 - beta: 0.0020 - val_val_loss: 272.1277 - val_val_recon_loss: 9.9458e-04 - val_val_KL loss: 16.5352 - val_beta: 0.0020\n",
      "Epoch 1567/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 274.1410 - recon_loss: 0.0010 - KL loss: 16.5997 - beta: 0.0020 - val_val_loss: 271.4066 - val_val_recon_loss: 9.9242e-04 - val_val_KL loss: 16.3703 - val_beta: 0.0020\n",
      "Epoch 1568/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 272.2842 - recon_loss: 9.9583e-04 - KL loss: 16.3716 - beta: 0.0020 - val_val_loss: 270.2649 - val_val_recon_loss: 9.8803e-04 - val_val_KL loss: 16.3565 - val_beta: 0.0020\n",
      "Epoch 1569/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 271.5099 - recon_loss: 9.9317e-04 - KL loss: 16.2807 - beta: 0.0020 - val_val_loss: 271.0623 - val_val_recon_loss: 9.9200e-04 - val_val_KL loss: 16.1341 - val_beta: 0.0020\n",
      "Epoch 1570/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 273.3565 - recon_loss: 0.0010 - KL loss: 16.1831 - beta: 0.0020 - val_val_loss: 271.9944 - val_val_recon_loss: 9.9582e-04 - val_val_KL loss: 16.0828 - val_beta: 0.0020\n",
      "Epoch 1571/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 271.5908 - recon_loss: 9.9488e-04 - KL loss: 15.9211 - beta: 0.0020 - val_val_loss: 270.0796 - val_val_recon_loss: 9.9083e-04 - val_val_KL loss: 15.4506 - val_beta: 0.0020\n",
      "Epoch 1572/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 268.7325 - recon_loss: 9.8569e-04 - KL loss: 15.4264 - beta: 0.0020 - val_val_loss: 265.6221 - val_val_recon_loss: 9.7394e-04 - val_val_KL loss: 15.3336 - val_beta: 0.0020\n",
      "Epoch 1573/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 265.6074 - recon_loss: 9.7415e-04 - KL loss: 15.2647 - beta: 0.0020 - val_val_loss: 263.4286 - val_val_recon_loss: 9.6596e-04 - val_val_KL loss: 15.1916 - val_beta: 0.0020\n",
      "Epoch 1574/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 263.2589 - recon_loss: 9.6552e-04 - KL loss: 15.1340 - beta: 0.0020 - val_val_loss: 266.4163 - val_val_recon_loss: 9.7833e-04 - val_val_KL loss: 15.0006 - val_beta: 0.0020\n",
      "Epoch 1575/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265.1146 - recon_loss: 9.7372e-04 - KL loss: 14.8828 - beta: 0.0020 - val_val_loss: 264.1250 - val_val_recon_loss: 9.7014e-04 - val_val_KL loss: 14.8142 - val_beta: 0.0020\n",
      "Epoch 1576/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 262.3132 - recon_loss: 9.6358e-04 - KL loss: 14.6889 - beta: 0.0020 - val_val_loss: 262.6974 - val_val_recon_loss: 9.6508e-04 - val_val_KL loss: 14.6856 - val_beta: 0.0020\n",
      "Epoch 1577/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 262.2276 - recon_loss: 9.6359e-04 - KL loss: 14.6006 - beta: 0.0020 - val_val_loss: 263.8901 - val_val_recon_loss: 9.7014e-04 - val_val_KL loss: 14.5799 - val_beta: 0.0020\n",
      "Epoch 1578/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264.4946 - recon_loss: 9.7241e-04 - KL loss: 14.6013 - beta: 0.0020 - val_val_loss: 263.9162 - val_val_recon_loss: 9.7010e-04 - val_val_KL loss: 14.6164 - val_beta: 0.0020\n",
      "Epoch 1579/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 263.7164 - recon_loss: 9.7004e-04 - KL loss: 14.4305 - beta: 0.0020 - val_val_loss: 263.0760 - val_val_recon_loss: 9.6835e-04 - val_val_KL loss: 14.2245 - val_beta: 0.0020\n",
      "Epoch 1580/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 262.9643 - recon_loss: 9.6771e-04 - KL loss: 14.2790 - beta: 0.0020 - val_val_loss: 263.3329 - val_val_recon_loss: 9.6955e-04 - val_val_KL loss: 14.1743 - val_beta: 0.0020\n",
      "Epoch 1581/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265.1524 - recon_loss: 9.7671e-04 - KL loss: 14.1527 - beta: 0.0020 - val_val_loss: 261.6140 - val_val_recon_loss: 9.6344e-04 - val_val_KL loss: 14.0247 - val_beta: 0.0020\n",
      "Epoch 1582/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264.8464 - recon_loss: 9.7595e-04 - KL loss: 14.0420 - beta: 0.0020 - val_val_loss: 259.2641 - val_val_recon_loss: 9.5422e-04 - val_val_KL loss: 14.0444 - val_beta: 0.0020\n",
      "Epoch 1583/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 260.0304 - recon_loss: 9.5722e-04 - KL loss: 14.0384 - beta: 0.0020 - val_val_loss: 259.7224 - val_val_recon_loss: 9.5600e-04 - val_val_KL loss: 14.0441 - val_beta: 0.0020\n",
      "Epoch 1584/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 259.1359 - recon_loss: 9.5370e-04 - KL loss: 14.0493 - beta: 0.0020 - val_val_loss: 260.2354 - val_val_recon_loss: 9.5839e-04 - val_val_KL loss: 13.9434 - val_beta: 0.0020\n",
      "Epoch 1585/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 258.9052 - recon_loss: 9.5325e-04 - KL loss: 13.9334 - beta: 0.0020 - val_val_loss: 259.9172 - val_val_recon_loss: 9.5686e-04 - val_val_KL loss: 14.0186 - val_beta: 0.0020\n",
      "Epoch 1586/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 261.3130 - recon_loss: 9.6269e-04 - KL loss: 13.9160 - beta: 0.0020 - val_val_loss: 259.4178 - val_val_recon_loss: 9.5583e-04 - val_val_KL loss: 13.7854 - val_beta: 0.0020\n",
      "Epoch 1587/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 259.3152 - recon_loss: 9.5516e-04 - KL loss: 13.8527 - beta: 0.0020 - val_val_loss: 257.2420 - val_val_recon_loss: 9.4763e-04 - val_val_KL loss: 13.7151 - val_beta: 0.0020\n",
      "Epoch 1588/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 257.7460 - recon_loss: 9.4931e-04 - KL loss: 13.7883 - beta: 0.0020 - val_val_loss: 257.5017 - val_val_recon_loss: 9.4860e-04 - val_val_KL loss: 13.7272 - val_beta: 0.0020\n",
      "Epoch 1589/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 257.2435 - recon_loss: 9.4740e-04 - KL loss: 13.7751 - beta: 0.0020 - val_val_loss: 257.6917 - val_val_recon_loss: 9.4935e-04 - val_val_KL loss: 13.7234 - val_beta: 0.0020\n",
      "Epoch 1590/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 257.0986 - recon_loss: 9.4686e-04 - KL loss: 13.7710 - beta: 0.0020 - val_val_loss: 256.7947 - val_val_recon_loss: 9.4537e-04 - val_val_KL loss: 13.8500 - val_beta: 0.0020\n",
      "Epoch 1591/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 256.7740 - recon_loss: 9.4543e-04 - KL loss: 13.8132 - beta: 0.0020 - val_val_loss: 257.7301 - val_val_recon_loss: 9.4895e-04 - val_val_KL loss: 13.8634 - val_beta: 0.0020\n",
      "Epoch 1592/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 256.4252 - recon_loss: 9.4390e-04 - KL loss: 13.8565 - beta: 0.0020 - val_val_loss: 259.3503 - val_val_recon_loss: 9.5549e-04 - val_val_KL loss: 13.8038 - val_beta: 0.0020\n",
      "Epoch 1593/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 258.0012 - recon_loss: 9.4995e-04 - KL loss: 13.8798 - beta: 0.0020 - val_val_loss: 258.1379 - val_val_recon_loss: 9.5079e-04 - val_val_KL loss: 13.7991 - val_beta: 0.0020\n",
      "Epoch 1594/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 256.0505 - recon_loss: 9.4252e-04 - KL loss: 13.8380 - beta: 0.0020 - val_val_loss: 257.5441 - val_val_recon_loss: 9.4818e-04 - val_val_KL loss: 13.8768 - val_beta: 0.0020\n",
      "Epoch 1595/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 259.0228 - recon_loss: 9.5363e-04 - KL loss: 13.9541 - beta: 0.0020\n",
      "Epoch 01595: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 259.0221 - recon_loss: 9.5363e-04 - KL loss: 13.9541 - beta: 0.0020 - val_val_loss: 257.6218 - val_val_recon_loss: 9.4811e-04 - val_val_KL loss: 13.9729 - val_beta: 0.0020\n",
      "Epoch 1596/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 256.6522 - recon_loss: 9.4447e-04 - KL loss: 13.9373 - beta: 0.0020 - val_val_loss: 255.5041 - val_val_recon_loss: 9.3995e-04 - val_val_KL loss: 13.9514 - val_beta: 0.0020\n",
      "Epoch 1597/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 256.9466 - recon_loss: 9.4537e-04 - KL loss: 13.9999 - beta: 0.0020 - val_val_loss: 254.5704 - val_val_recon_loss: 9.3620e-04 - val_val_KL loss: 13.9804 - val_beta: 0.0020\n",
      "Epoch 1598/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 254.4854 - recon_loss: 9.3565e-04 - KL loss: 14.0384 - beta: 0.0020 - val_val_loss: 254.3285 - val_val_recon_loss: 9.3504e-04 - val_val_KL loss: 14.0383 - val_beta: 0.0020\n",
      "Epoch 1599/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 254.5176 - recon_loss: 9.3583e-04 - KL loss: 14.0241 - beta: 0.0020 - val_val_loss: 254.6265 - val_val_recon_loss: 9.3617e-04 - val_val_KL loss: 14.0441 - val_beta: 0.0020\n",
      "Epoch 1600/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 251.3876 - recon_loss: 9.2358e-04 - KL loss: 14.0412 - beta: 0.0020 - val_val_loss: 253.6315 - val_val_recon_loss: 9.3253e-04 - val_val_KL loss: 13.9851 - val_beta: 0.0020\n",
      "Epoch 1601/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 254.9989 - recon_loss: 9.3769e-04 - KL loss: 14.0275 - beta: 0.0020 - val_val_loss: 253.8636 - val_val_recon_loss: 9.3328e-04 - val_val_KL loss: 14.0259 - val_beta: 0.0020\n",
      "Epoch 1602/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 252.1221 - recon_loss: 9.2653e-04 - KL loss: 14.0177 - beta: 0.0020 - val_val_loss: 253.7916 - val_val_recon_loss: 9.3323e-04 - val_val_KL loss: 13.9669 - val_beta: 0.0020\n",
      "Epoch 1603/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 252.7088 - recon_loss: 9.2871e-04 - KL loss: 14.0448 - beta: 0.0020 - val_val_loss: 254.4710 - val_val_recon_loss: 9.3548e-04 - val_val_KL loss: 14.0670 - val_beta: 0.0020\n",
      "Epoch 1604/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 254.1042 - recon_loss: 9.3415e-04 - KL loss: 14.0414 - beta: 0.0020 - val_val_loss: 253.5023 - val_val_recon_loss: 9.3201e-04 - val_val_KL loss: 13.9892 - val_beta: 0.0020\n",
      "Epoch 1605/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 254.1722 - recon_loss: 9.3456e-04 - KL loss: 14.0043 - beta: 0.0020 - val_val_loss: 253.7865 - val_val_recon_loss: 9.3287e-04 - val_val_KL loss: 14.0523 - val_beta: 0.0020\n",
      "Epoch 1606/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 252.9883 - recon_loss: 9.2984e-04 - KL loss: 14.0332 - beta: 0.0020 - val_val_loss: 254.0349 - val_val_recon_loss: 9.3406e-04 - val_val_KL loss: 13.9964 - val_beta: 0.0020\n",
      "Epoch 1607/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 254.7881 - recon_loss: 9.3680e-04 - KL loss: 14.0438 - beta: 0.0020 - val_val_loss: 254.1943 - val_val_recon_loss: 9.3463e-04 - val_val_KL loss: 14.0086 - val_beta: 0.0020\n",
      "Epoch 1608/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 253.9416 - recon_loss: 9.3342e-04 - KL loss: 14.0659 - beta: 0.0020 - val_val_loss: 254.9288 - val_val_recon_loss: 9.3741e-04 - val_val_KL loss: 14.0297 - val_beta: 0.0020\n",
      "Epoch 1609/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 252.7359 - recon_loss: 9.2865e-04 - KL loss: 14.0876 - beta: 0.0020\n",
      "Epoch 01609: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 252.7363 - recon_loss: 9.2865e-04 - KL loss: 14.0876 - beta: 0.0020 - val_val_loss: 254.8295 - val_val_recon_loss: 9.3691e-04 - val_val_KL loss: 14.0584 - val_beta: 0.0020\n",
      "Epoch 1610/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 257.3530 - recon_loss: 9.4665e-04 - KL loss: 14.0782 - beta: 0.0020 - val_val_loss: 254.4655 - val_val_recon_loss: 9.3535e-04 - val_val_KL loss: 14.0940 - val_beta: 0.0020\n",
      "Epoch 1611/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 251.8343 - recon_loss: 9.2506e-04 - KL loss: 14.1077 - beta: 0.0020 - val_val_loss: 254.9639 - val_val_recon_loss: 9.3730e-04 - val_val_KL loss: 14.0927 - val_beta: 0.0020\n",
      "Epoch 1612/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 253.4770 - recon_loss: 9.3131e-04 - KL loss: 14.1435 - beta: 0.0020 - val_val_loss: 254.1640 - val_val_recon_loss: 9.3428e-04 - val_val_KL loss: 14.0685 - val_beta: 0.0020\n",
      "Epoch 1613/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 254.2472 - recon_loss: 9.3452e-04 - KL loss: 14.0896 - beta: 0.0020 - val_val_loss: 254.2812 - val_val_recon_loss: 9.3478e-04 - val_val_KL loss: 14.0570 - val_beta: 0.0020\n",
      "Epoch 1614/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 252.5868 - recon_loss: 9.2799e-04 - KL loss: 14.1072 - beta: 0.0020\n",
      "Epoch 01614: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 252.5867 - recon_loss: 9.2799e-04 - KL loss: 14.1072 - beta: 0.0020 - val_val_loss: 254.6856 - val_val_recon_loss: 9.3633e-04 - val_val_KL loss: 14.0636 - val_beta: 0.0020\n",
      "Epoch 1614/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 835.9469 - recon_loss: 9.8543e-04 - KL loss: 16.4586 - beta: 0.0011 - val_val_loss: 815.3420 - val_val_recon_loss: 9.6045e-04 - val_val_KL loss: 16.6264 - val_beta: 0.0011\n",
      "Epoch 1615/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 814.8295 - recon_loss: 9.5908e-04 - KL loss: 17.2564 - beta: 0.0011 - val_val_loss: 821.2053 - val_val_recon_loss: 9.6546e-04 - val_val_KL loss: 18.3265 - val_beta: 0.0011\n",
      "Epoch 1616/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 819.2088 - recon_loss: 9.6318e-04 - KL loss: 18.2235 - beta: 0.0011 - val_val_loss: 803.8745 - val_val_recon_loss: 9.4554e-04 - val_val_KL loss: 17.5567 - val_beta: 0.0011\n",
      "Epoch 1617/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 783.6957 - recon_loss: 9.2127e-04 - KL loss: 17.5627 - beta: 0.0011 - val_val_loss: 779.6004 - val_val_recon_loss: 9.1642e-04 - val_val_KL loss: 17.5018 - val_beta: 0.0011\n",
      "Epoch 1618/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 794.7201 - recon_loss: 9.3457e-04 - KL loss: 17.5300 - beta: 0.0011 - val_val_loss: 788.5203 - val_val_recon_loss: 9.2732e-04 - val_val_KL loss: 17.3595 - val_beta: 0.0011\n",
      "Epoch 1619/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 783.5730 - recon_loss: 9.2121e-04 - KL loss: 17.4857 - beta: 0.0011 - val_val_loss: 787.6068 - val_val_recon_loss: 9.2637e-04 - val_val_KL loss: 17.2347 - val_beta: 0.0011\n",
      "Epoch 1620/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 780.0765 - recon_loss: 9.1707e-04 - KL loss: 17.4333 - beta: 0.0011 - val_val_loss: 768.6177 - val_val_recon_loss: 9.0296e-04 - val_val_KL loss: 17.7072 - val_beta: 0.0011\n",
      "Epoch 1621/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 776.7040 - recon_loss: 9.1251e-04 - KL loss: 17.8533 - beta: 0.0011 - val_val_loss: 765.7119 - val_val_recon_loss: 8.9907e-04 - val_val_KL loss: 18.0440 - val_beta: 0.0011\n",
      "Epoch 1622/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 766.7344 - recon_loss: 9.0024e-04 - KL loss: 18.0938 - beta: 0.0011 - val_val_loss: 776.0240 - val_val_recon_loss: 9.1196e-04 - val_val_KL loss: 17.6342 - val_beta: 0.0011\n",
      "Epoch 1623/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 761.3336 - recon_loss: 8.9386e-04 - KL loss: 17.9974 - beta: 0.0011 - val_val_loss: 770.9543 - val_val_recon_loss: 9.0494e-04 - val_val_KL loss: 18.4025 - val_beta: 0.0011\n",
      "Epoch 1624/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 769.0716 - recon_loss: 9.0213e-04 - KL loss: 18.8565 - beta: 0.0011 - val_val_loss: 766.0119 - val_val_recon_loss: 8.9807e-04 - val_val_KL loss: 19.1727 - val_beta: 0.0011\n",
      "Epoch 1625/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 756.9323 - recon_loss: 8.8696e-04 - KL loss: 19.3322 - beta: 0.0011 - val_val_loss: 751.4730 - val_val_recon_loss: 8.8130e-04 - val_val_KL loss: 18.5790 - val_beta: 0.0011\n",
      "Epoch 1626/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 758.6018 - recon_loss: 8.8922e-04 - KL loss: 19.1209 - beta: 0.0011 - val_val_loss: 763.1834 - val_val_recon_loss: 8.9484e-04 - val_val_KL loss: 19.0311 - val_beta: 0.0011\n",
      "Epoch 1627/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 763.6077 - recon_loss: 8.9512e-04 - KL loss: 19.2212 - beta: 0.0011 - val_val_loss: 759.2870 - val_val_recon_loss: 8.8993e-04 - val_val_KL loss: 19.2166 - val_beta: 0.0011\n",
      "Epoch 1628/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 751.4255 - recon_loss: 8.8037e-04 - KL loss: 19.3080 - beta: 0.0011 - val_val_loss: 748.0732 - val_val_recon_loss: 8.7650e-04 - val_val_KL loss: 19.1712 - val_beta: 0.0011\n",
      "Epoch 1629/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 751.0672 - recon_loss: 8.7986e-04 - KL loss: 19.3708 - beta: 0.0011 - val_val_loss: 760.5078 - val_val_recon_loss: 8.9028e-04 - val_val_KL loss: 20.1422 - val_beta: 0.0011\n",
      "Epoch 1630/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 762.0158 - recon_loss: 8.9166e-04 - KL loss: 20.5052 - beta: 0.0011 - val_val_loss: 802.2679 - val_val_recon_loss: 9.3756e-04 - val_val_KL loss: 22.5905 - val_beta: 0.0011\n",
      "Epoch 1631/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 804.1535 - recon_loss: 9.3970e-04 - KL loss: 22.6920 - beta: 0.0011 - val_val_loss: 754.0341 - val_val_recon_loss: 8.8060e-04 - val_val_KL loss: 21.7219 - val_beta: 0.0011\n",
      "Epoch 1632/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 750.1702 - recon_loss: 8.7593e-04 - KL loss: 21.7384 - beta: 0.0011 - val_val_loss: 750.6075 - val_val_recon_loss: 8.7618e-04 - val_val_KL loss: 21.9701 - val_beta: 0.0011\n",
      "Epoch 1633/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 752.2823 - recon_loss: 8.7832e-04 - KL loss: 21.8639 - beta: 0.0011\n",
      "Epoch 01633: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 752.2844 - recon_loss: 8.7833e-04 - KL loss: 21.8644 - beta: 0.0011 - val_val_loss: 752.8289 - val_val_recon_loss: 8.7813e-04 - val_val_KL loss: 22.5737 - val_beta: 0.0011\n",
      "Epoch 1634/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 738.3443 - recon_loss: 8.6090e-04 - KL loss: 22.4131 - beta: 0.0011 - val_val_loss: 729.5279 - val_val_recon_loss: 8.5088e-04 - val_val_KL loss: 21.9347 - val_beta: 0.0011\n",
      "Epoch 1635/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 729.0186 - recon_loss: 8.5008e-04 - KL loss: 22.0881 - beta: 0.0011 - val_val_loss: 723.5016 - val_val_recon_loss: 8.4402e-04 - val_val_KL loss: 21.6085 - val_beta: 0.0011\n",
      "Epoch 1636/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 718.7290 - recon_loss: 8.3802e-04 - KL loss: 21.8292 - beta: 0.0011 - val_val_loss: 716.4914 - val_val_recon_loss: 8.3532e-04 - val_val_KL loss: 21.8385 - val_beta: 0.0011\n",
      "Epoch 1637/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 712.0658 - recon_loss: 8.2986e-04 - KL loss: 21.9498 - beta: 0.0011 - val_val_loss: 715.8054 - val_val_recon_loss: 8.3431e-04 - val_val_KL loss: 21.9906 - val_beta: 0.0011\n",
      "Epoch 1638/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 716.1115 - recon_loss: 8.3483e-04 - KL loss: 21.8582 - beta: 0.0011 - val_val_loss: 716.8420 - val_val_recon_loss: 8.3589e-04 - val_val_KL loss: 21.7147 - val_beta: 0.0011\n",
      "Epoch 1639/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 709.0688 - recon_loss: 8.2668e-04 - KL loss: 21.6004 - beta: 0.0011 - val_val_loss: 714.3251 - val_val_recon_loss: 8.3292e-04 - val_val_KL loss: 21.6614 - val_beta: 0.0011\n",
      "Epoch 1640/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 708.7456 - recon_loss: 8.2602e-04 - KL loss: 21.8208 - beta: 0.0011 - val_val_loss: 713.1715 - val_val_recon_loss: 8.3126e-04 - val_val_KL loss: 21.8884 - val_beta: 0.0011\n",
      "Epoch 1641/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 711.2100 - recon_loss: 8.2883e-04 - KL loss: 21.9460 - beta: 0.0011 - val_val_loss: 710.5932 - val_val_recon_loss: 8.2826e-04 - val_val_KL loss: 21.8077 - val_beta: 0.0011\n",
      "Epoch 1642/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 705.5420 - recon_loss: 8.2202e-04 - KL loss: 21.9491 - beta: 0.0011 - val_val_loss: 706.4683 - val_val_recon_loss: 8.2330e-04 - val_val_KL loss: 21.8035 - val_beta: 0.0011\n",
      "Epoch 1643/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 714.2500 - recon_loss: 8.3233e-04 - KL loss: 22.0829 - beta: 0.0011 - val_val_loss: 707.1428 - val_val_recon_loss: 8.2409e-04 - val_val_KL loss: 21.8277 - val_beta: 0.0011\n",
      "Epoch 1644/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 706.2355 - recon_loss: 8.2271e-04 - KL loss: 22.0683 - beta: 0.0011 - val_val_loss: 706.0074 - val_val_recon_loss: 8.2284e-04 - val_val_KL loss: 21.7294 - val_beta: 0.0011\n",
      "Epoch 1645/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 700.1099 - recon_loss: 8.1552e-04 - KL loss: 21.9215 - beta: 0.0011 - val_val_loss: 705.8359 - val_val_recon_loss: 8.2225e-04 - val_val_KL loss: 22.0455 - val_beta: 0.0011\n",
      "Epoch 1646/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 706.1820 - recon_loss: 8.2243e-04 - KL loss: 22.2486 - beta: 0.0011 - val_val_loss: 703.5526 - val_val_recon_loss: 8.1939e-04 - val_val_KL loss: 22.1459 - val_beta: 0.0011\n",
      "Epoch 1647/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 700.5872 - recon_loss: 8.1555e-04 - KL loss: 22.3697 - beta: 0.0011 - val_val_loss: 701.4130 - val_val_recon_loss: 8.1661e-04 - val_val_KL loss: 22.3146 - val_beta: 0.0011\n",
      "Epoch 1648/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 698.6120 - recon_loss: 8.1318e-04 - KL loss: 22.3659 - beta: 0.0011 - val_val_loss: 706.8513 - val_val_recon_loss: 8.2287e-04 - val_val_KL loss: 22.5455 - val_beta: 0.0011\n",
      "Epoch 1649/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 697.1945 - recon_loss: 8.1129e-04 - KL loss: 22.5203 - beta: 0.0011 - val_val_loss: 705.9481 - val_val_recon_loss: 8.2179e-04 - val_val_KL loss: 22.5437 - val_beta: 0.0011\n",
      "Epoch 1650/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 707.9942 - recon_loss: 8.2389e-04 - KL loss: 22.8381 - beta: 0.0011 - val_val_loss: 704.4314 - val_val_recon_loss: 8.1959e-04 - val_val_KL loss: 22.8585 - val_beta: 0.0011\n",
      "Epoch 1651/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 708.6058 - recon_loss: 8.2417e-04 - KL loss: 23.2230 - beta: 0.0011 - val_val_loss: 708.4532 - val_val_recon_loss: 8.2406e-04 - val_val_KL loss: 23.1634 - val_beta: 0.0011\n",
      "Epoch 1652/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 703.9025 - recon_loss: 8.1872e-04 - KL loss: 23.0511 - beta: 0.0011\n",
      "Epoch 01652: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 703.8979 - recon_loss: 8.1871e-04 - KL loss: 23.0511 - beta: 0.0011 - val_val_loss: 706.4995 - val_val_recon_loss: 8.2157e-04 - val_val_KL loss: 23.2766 - val_beta: 0.0011\n",
      "Epoch 1653/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 704.5577 - recon_loss: 8.1915e-04 - KL loss: 23.3444 - beta: 0.0011 - val_val_loss: 706.0739 - val_val_recon_loss: 8.2090e-04 - val_val_KL loss: 23.4059 - val_beta: 0.0011\n",
      "Epoch 1654/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 697.8438 - recon_loss: 8.1098e-04 - KL loss: 23.4306 - beta: 0.0011 - val_val_loss: 701.5933 - val_val_recon_loss: 8.1571e-04 - val_val_KL loss: 23.2437 - val_beta: 0.0011\n",
      "Epoch 1655/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 706.7415 - recon_loss: 8.2158e-04 - KL loss: 23.5131 - beta: 0.0011 - val_val_loss: 698.7149 - val_val_recon_loss: 8.1225e-04 - val_val_KL loss: 23.2446 - val_beta: 0.0011\n",
      "Epoch 1656/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 116s 116ms/step - loss: 694.0353 - recon_loss: 8.0640e-04 - KL loss: 23.4280 - beta: 0.0011 - val_val_loss: 695.9814 - val_val_recon_loss: 8.0896e-04 - val_val_KL loss: 23.2464 - val_beta: 0.0011\n",
      "Epoch 1657/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 693.8276 - recon_loss: 8.0603e-04 - KL loss: 23.5294 - beta: 0.0011 - val_val_loss: 697.6355 - val_val_recon_loss: 8.1077e-04 - val_val_KL loss: 23.3904 - val_beta: 0.0011\n",
      "Epoch 1658/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 696.1085 - recon_loss: 8.0880e-04 - KL loss: 23.5027 - beta: 0.0011 - val_val_loss: 697.1534 - val_val_recon_loss: 8.1015e-04 - val_val_KL loss: 23.4251 - val_beta: 0.0011\n",
      "Epoch 1659/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 691.9333 - recon_loss: 8.0374e-04 - KL loss: 23.5410 - beta: 0.0011 - val_val_loss: 695.0499 - val_val_recon_loss: 8.0780e-04 - val_val_KL loss: 23.2785 - val_beta: 0.0011\n",
      "Epoch 1660/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 690.9695 - recon_loss: 8.0276e-04 - KL loss: 23.3923 - beta: 0.0011 - val_val_loss: 693.1733 - val_val_recon_loss: 8.0547e-04 - val_val_KL loss: 23.3440 - val_beta: 0.0011\n",
      "Epoch 1661/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 692.3152 - recon_loss: 8.0432e-04 - KL loss: 23.4408 - beta: 0.0011 - val_val_loss: 693.4396 - val_val_recon_loss: 8.0597e-04 - val_val_KL loss: 23.1879 - val_beta: 0.0011\n",
      "Epoch 1662/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 686.6062 - recon_loss: 7.9764e-04 - KL loss: 23.2879 - beta: 0.0011 - val_val_loss: 693.9955 - val_val_recon_loss: 8.0677e-04 - val_val_KL loss: 23.0794 - val_beta: 0.0011\n",
      "Epoch 1663/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 687.0097 - recon_loss: 7.9821e-04 - KL loss: 23.2170 - beta: 0.0011 - val_val_loss: 691.6865 - val_val_recon_loss: 8.0396e-04 - val_val_KL loss: 23.1125 - val_beta: 0.0011\n",
      "Epoch 1664/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 688.4851 - recon_loss: 7.9989e-04 - KL loss: 23.2879 - beta: 0.0011 - val_val_loss: 690.5345 - val_val_recon_loss: 8.0264e-04 - val_val_KL loss: 23.0521 - val_beta: 0.0011\n",
      "Epoch 1665/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 684.1678 - recon_loss: 7.9483e-04 - KL loss: 23.1826 - beta: 0.0011 - val_val_loss: 690.4040 - val_val_recon_loss: 8.0255e-04 - val_val_KL loss: 23.0033 - val_beta: 0.0011\n",
      "Epoch 1666/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 691.7114 - recon_loss: 8.0396e-04 - KL loss: 23.1369 - beta: 0.0011 - val_val_loss: 689.1689 - val_val_recon_loss: 8.0118e-04 - val_val_KL loss: 22.9061 - val_beta: 0.0011\n",
      "Epoch 1667/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 692.5383 - recon_loss: 8.0504e-04 - KL loss: 23.0631 - beta: 0.0011 - val_val_loss: 688.4843 - val_val_recon_loss: 8.0010e-04 - val_val_KL loss: 23.1150 - val_beta: 0.0011\n",
      "Epoch 1668/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 684.8506 - recon_loss: 7.9551e-04 - KL loss: 23.2981 - beta: 0.0011 - val_val_loss: 687.5109 - val_val_recon_loss: 7.9896e-04 - val_val_KL loss: 23.0888 - val_beta: 0.0011\n",
      "Epoch 1669/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 679.5609 - recon_loss: 7.8928e-04 - KL loss: 23.1928 - beta: 0.0011 - val_val_loss: 687.1417 - val_val_recon_loss: 7.9856e-04 - val_val_KL loss: 23.0555 - val_beta: 0.0011\n",
      "Epoch 1670/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 688.8916 - recon_loss: 8.0050e-04 - KL loss: 23.1900 - beta: 0.0011 - val_val_loss: 685.4658 - val_val_recon_loss: 7.9635e-04 - val_val_KL loss: 23.2162 - val_beta: 0.0011\n",
      "Epoch 1671/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 683.0277 - recon_loss: 7.9336e-04 - KL loss: 23.2660 - beta: 0.0011 - val_val_loss: 685.8694 - val_val_recon_loss: 7.9716e-04 - val_val_KL loss: 22.9476 - val_beta: 0.0011\n",
      "Epoch 1672/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 687.2119 - recon_loss: 7.9851e-04 - KL loss: 23.1636 - beta: 0.0011 - val_val_loss: 686.1038 - val_val_recon_loss: 7.9744e-04 - val_val_KL loss: 22.9447 - val_beta: 0.0011\n",
      "Epoch 1673/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 677.3520 - recon_loss: 7.8674e-04 - KL loss: 23.0966 - beta: 0.0011 - val_val_loss: 685.7820 - val_val_recon_loss: 7.9678e-04 - val_val_KL loss: 23.1792 - val_beta: 0.0011\n",
      "Epoch 1674/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 681.4421 - recon_loss: 7.9145e-04 - KL loss: 23.2655 - beta: 0.0011 - val_val_loss: 685.6281 - val_val_recon_loss: 7.9661e-04 - val_val_KL loss: 23.1641 - val_beta: 0.0011\n",
      "Epoch 1675/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 687.8803 - recon_loss: 7.9921e-04 - KL loss: 23.2548 - beta: 0.0011 - val_val_loss: 684.3836 - val_val_recon_loss: 7.9507e-04 - val_val_KL loss: 23.1972 - val_beta: 0.0011\n",
      "Epoch 1676/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 675.6329 - recon_loss: 7.8455e-04 - KL loss: 23.1936 - beta: 0.0011 - val_val_loss: 685.1590 - val_val_recon_loss: 7.9639e-04 - val_val_KL loss: 22.8753 - val_beta: 0.0011\n",
      "Epoch 1677/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 687.6157 - recon_loss: 7.9906e-04 - KL loss: 23.1126 - beta: 0.0011 - val_val_loss: 685.1852 - val_val_recon_loss: 7.9636e-04 - val_val_KL loss: 22.9247 - val_beta: 0.0011\n",
      "Epoch 1678/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 681.3077 - recon_loss: 7.9165e-04 - KL loss: 22.9641 - beta: 0.0011 - val_val_loss: 684.7581 - val_val_recon_loss: 7.9584e-04 - val_val_KL loss: 22.9359 - val_beta: 0.0011\n",
      "Epoch 1679/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 676.8401 - recon_loss: 7.8616e-04 - KL loss: 23.0644 - beta: 0.0011 - val_val_loss: 683.7397 - val_val_recon_loss: 7.9456e-04 - val_val_KL loss: 22.9775 - val_beta: 0.0011\n",
      "Epoch 1680/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 688.6983 - recon_loss: 8.0047e-04 - KL loss: 23.0269 - beta: 0.0011 - val_val_loss: 683.4498 - val_val_recon_loss: 7.9413e-04 - val_val_KL loss: 23.0475 - val_beta: 0.0011\n",
      "Epoch 1681/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 676.2397 - recon_loss: 7.8547e-04 - KL loss: 23.0389 - beta: 0.0011 - val_val_loss: 681.9539 - val_val_recon_loss: 7.9215e-04 - val_val_KL loss: 23.2004 - val_beta: 0.0011\n",
      "Epoch 1682/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 677.5733 - recon_loss: 7.8679e-04 - KL loss: 23.2704 - beta: 0.0011 - val_val_loss: 683.5206 - val_val_recon_loss: 7.9420e-04 - val_val_KL loss: 23.0590 - val_beta: 0.0011\n",
      "Epoch 1683/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 683.3933 - recon_loss: 7.9374e-04 - KL loss: 23.3182 - beta: 0.0011 - val_val_loss: 683.5894 - val_val_recon_loss: 7.9412e-04 - val_val_KL loss: 23.1986 - val_beta: 0.0011\n",
      "Epoch 1684/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 678.9436 - recon_loss: 7.8848e-04 - KL loss: 23.2365 - beta: 0.0011 - val_val_loss: 680.0818 - val_val_recon_loss: 7.8999e-04 - val_val_KL loss: 23.1253 - val_beta: 0.0011\n",
      "Epoch 1685/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 674.7662 - recon_loss: 7.8357e-04 - KL loss: 23.1474 - beta: 0.0011 - val_val_loss: 682.7277 - val_val_recon_loss: 7.9332e-04 - val_val_KL loss: 22.9998 - val_beta: 0.0011\n",
      "Epoch 1686/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 679.6140 - recon_loss: 7.8929e-04 - KL loss: 23.2319 - beta: 0.0011 - val_val_loss: 681.1002 - val_val_recon_loss: 7.9125e-04 - val_val_KL loss: 23.0901 - val_beta: 0.0011\n",
      "Epoch 1687/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 680.1645 - recon_loss: 7.8983e-04 - KL loss: 23.3369 - beta: 0.0011 - val_val_loss: 679.5798 - val_val_recon_loss: 7.8935e-04 - val_val_KL loss: 23.1484 - val_beta: 0.0011\n",
      "Epoch 1688/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 676.3957 - recon_loss: 7.8547e-04 - KL loss: 23.1937 - beta: 0.0011 - val_val_loss: 679.4469 - val_val_recon_loss: 7.8907e-04 - val_val_KL loss: 23.2523 - val_beta: 0.0011\n",
      "Epoch 1689/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 681.0183 - recon_loss: 7.9092e-04 - KL loss: 23.2815 - beta: 0.0011 - val_val_loss: 679.6406 - val_val_recon_loss: 7.8944e-04 - val_val_KL loss: 23.1337 - val_beta: 0.0011\n",
      "Epoch 1690/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 670.6944 - recon_loss: 7.7867e-04 - KL loss: 23.1459 - beta: 0.0011 - val_val_loss: 678.6266 - val_val_recon_loss: 7.8807e-04 - val_val_KL loss: 23.2631 - val_beta: 0.0011\n",
      "Epoch 1691/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 676.8434 - recon_loss: 7.8568e-04 - KL loss: 23.4641 - beta: 0.0011 - val_val_loss: 680.3977 - val_val_recon_loss: 7.9038e-04 - val_val_KL loss: 23.1136 - val_beta: 0.0011\n",
      "Epoch 1692/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 679.0368 - recon_loss: 7.8860e-04 - KL loss: 23.2355 - beta: 0.0011 - val_val_loss: 680.5416 - val_val_recon_loss: 7.9062e-04 - val_val_KL loss: 23.0557 - val_beta: 0.0011\n",
      "Epoch 1693/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 677.6650 - recon_loss: 7.8694e-04 - KL loss: 23.2410 - beta: 0.0011 - val_val_loss: 681.1808 - val_val_recon_loss: 7.9144e-04 - val_val_KL loss: 23.0164 - val_beta: 0.0011\n",
      "Epoch 1694/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 673.2929 - recon_loss: 7.8179e-04 - KL loss: 23.1497 - beta: 0.0011 - val_val_loss: 679.1357 - val_val_recon_loss: 7.8888e-04 - val_val_KL loss: 23.0999 - val_beta: 0.0011\n",
      "Epoch 1695/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 674.1304 - recon_loss: 7.8276e-04 - KL loss: 23.1840 - beta: 0.0011 - val_val_loss: 677.4131 - val_val_recon_loss: 7.8667e-04 - val_val_KL loss: 23.2174 - val_beta: 0.0011\n",
      "Epoch 1696/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 675.3543 - recon_loss: 7.8407e-04 - KL loss: 23.3140 - beta: 0.0011 - val_val_loss: 677.5703 - val_val_recon_loss: 7.8677e-04 - val_val_KL loss: 23.2844 - val_beta: 0.0011\n",
      "Epoch 1697/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 675.1985 - recon_loss: 7.8397e-04 - KL loss: 23.2412 - beta: 0.0011 - val_val_loss: 678.4183 - val_val_recon_loss: 7.8796e-04 - val_val_KL loss: 23.1493 - val_beta: 0.0011\n",
      "Epoch 1698/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 679.7901 - recon_loss: 7.8942e-04 - KL loss: 23.3064 - beta: 0.0011 - val_val_loss: 678.2449 - val_val_recon_loss: 7.8785e-04 - val_val_KL loss: 23.0639 - val_beta: 0.0011\n",
      "Epoch 1699/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 676.8182 - recon_loss: 7.8595e-04 - KL loss: 23.2219 - beta: 0.0011 - val_val_loss: 677.6689 - val_val_recon_loss: 7.8728e-04 - val_val_KL loss: 22.9594 - val_beta: 0.0011\n",
      "Epoch 1700/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 670.2691 - recon_loss: 7.7805e-04 - KL loss: 23.2423 - beta: 0.0011 - val_val_loss: 677.4104 - val_val_recon_loss: 7.8664e-04 - val_val_KL loss: 23.2376 - val_beta: 0.0011\n",
      "Epoch 1701/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 680.0389 - recon_loss: 7.8978e-04 - KL loss: 23.2563 - beta: 0.0011 - val_val_loss: 677.5576 - val_val_recon_loss: 7.8682e-04 - val_val_KL loss: 23.2360 - val_beta: 0.0011\n",
      "Epoch 1702/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 681.5668 - recon_loss: 7.9143e-04 - KL loss: 23.4092 - beta: 0.0011 - val_val_loss: 677.3703 - val_val_recon_loss: 7.8660e-04 - val_val_KL loss: 23.2286 - val_beta: 0.0011\n",
      "Epoch 1703/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 674.0559 - recon_loss: 7.8238e-04 - KL loss: 23.4224 - beta: 0.0011 - val_val_loss: 676.5923 - val_val_recon_loss: 7.8550e-04 - val_val_KL loss: 23.3636 - val_beta: 0.0011\n",
      "Epoch 1704/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 667.2695 - recon_loss: 7.7428e-04 - KL loss: 23.3712 - beta: 0.0011 - val_val_loss: 676.2756 - val_val_recon_loss: 7.8488e-04 - val_val_KL loss: 23.5613 - val_beta: 0.0011\n",
      "Epoch 1705/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 673.5994 - recon_loss: 7.8165e-04 - KL loss: 23.5739 - beta: 0.0011 - val_val_loss: 678.0891 - val_val_recon_loss: 7.8722e-04 - val_val_KL loss: 23.4340 - val_beta: 0.0011\n",
      "Epoch 1706/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 674.6640 - recon_loss: 7.8313e-04 - KL loss: 23.4046 - beta: 0.0011 - val_val_loss: 676.1256 - val_val_recon_loss: 7.8503e-04 - val_val_KL loss: 23.2870 - val_beta: 0.0011\n",
      "Epoch 1707/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 672.5620 - recon_loss: 7.8030e-04 - KL loss: 23.6575 - beta: 0.0011 - val_val_loss: 675.1490 - val_val_recon_loss: 7.8364e-04 - val_val_KL loss: 23.4692 - val_beta: 0.0011\n",
      "Epoch 1708/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 675.3865 - recon_loss: 7.8368e-04 - KL loss: 23.6765 - beta: 0.0011 - val_val_loss: 674.3608 - val_val_recon_loss: 7.8287e-04 - val_val_KL loss: 23.3243 - val_beta: 0.0011\n",
      "Epoch 1709/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 672.2102 - recon_loss: 7.8001e-04 - KL loss: 23.5462 - beta: 0.0011 - val_val_loss: 675.1978 - val_val_recon_loss: 7.8364e-04 - val_val_KL loss: 23.5203 - val_beta: 0.0011\n",
      "Epoch 1710/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 671.8935 - recon_loss: 7.7935e-04 - KL loss: 23.7794 - beta: 0.0011 - val_val_loss: 675.0291 - val_val_recon_loss: 7.8297e-04 - val_val_KL loss: 23.9095 - val_beta: 0.0011\n",
      "Epoch 1711/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 671.2860 - recon_loss: 7.7837e-04 - KL loss: 23.9929 - beta: 0.0011 - val_val_loss: 672.0334 - val_val_recon_loss: 7.7963e-04 - val_val_KL loss: 23.6868 - val_beta: 0.0011\n",
      "Epoch 1712/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 665.8866 - recon_loss: 7.7213e-04 - KL loss: 23.7825 - beta: 0.0011 - val_val_loss: 673.3184 - val_val_recon_loss: 7.8121e-04 - val_val_KL loss: 23.6635 - val_beta: 0.0011\n",
      "Epoch 1713/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 665.7879 - recon_loss: 7.7186e-04 - KL loss: 23.9075 - beta: 0.0011 - val_val_loss: 673.8437 - val_val_recon_loss: 7.8157e-04 - val_val_KL loss: 23.8894 - val_beta: 0.0011\n",
      "Epoch 1714/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 675.4367 - recon_loss: 7.8325e-04 - KL loss: 24.0848 - beta: 0.0011 - val_val_loss: 674.5388 - val_val_recon_loss: 7.8247e-04 - val_val_KL loss: 23.8288 - val_beta: 0.0011\n",
      "Epoch 1715/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 667.5762 - recon_loss: 7.7406e-04 - KL loss: 23.8656 - beta: 0.0011 - val_val_loss: 672.1584 - val_val_recon_loss: 7.7959e-04 - val_val_KL loss: 23.8465 - val_beta: 0.0011\n",
      "Epoch 1716/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 669.2952 - recon_loss: 7.7599e-04 - KL loss: 23.9793 - beta: 0.0011\n",
      "Epoch 01716: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 669.2953 - recon_loss: 7.7599e-04 - KL loss: 23.9794 - beta: 0.0011 - val_val_loss: 672.7455 - val_val_recon_loss: 7.8005e-04 - val_val_KL loss: 24.0488 - val_beta: 0.0011\n",
      "Epoch 1717/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 669.9084 - recon_loss: 7.7648e-04 - KL loss: 24.1793 - beta: 0.0011 - val_val_loss: 671.3940 - val_val_recon_loss: 7.7850e-04 - val_val_KL loss: 23.9912 - val_beta: 0.0011\n",
      "Epoch 1718/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 664.0636 - recon_loss: 7.6949e-04 - KL loss: 24.1530 - beta: 0.0011 - val_val_loss: 671.4457 - val_val_recon_loss: 7.7863e-04 - val_val_KL loss: 23.9328 - val_beta: 0.0011\n",
      "Epoch 1719/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 663.3224 - recon_loss: 7.6878e-04 - KL loss: 24.0017 - beta: 0.0011 - val_val_loss: 670.0535 - val_val_recon_loss: 7.7687e-04 - val_val_KL loss: 24.0004 - val_beta: 0.0011\n",
      "Epoch 1720/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 661.5059 - recon_loss: 7.6659e-04 - KL loss: 24.0038 - beta: 0.0011 - val_val_loss: 670.2449 - val_val_recon_loss: 7.7719e-04 - val_val_KL loss: 23.9308 - val_beta: 0.0011\n",
      "Epoch 1721/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 674.1592 - recon_loss: 7.8161e-04 - KL loss: 24.1655 - beta: 0.0011 - val_val_loss: 670.0578 - val_val_recon_loss: 7.7698e-04 - val_val_KL loss: 23.9195 - val_beta: 0.0011\n",
      "Epoch 1722/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 665.8742 - recon_loss: 7.7167e-04 - KL loss: 24.1455 - beta: 0.0011 - val_val_loss: 669.5120 - val_val_recon_loss: 7.7620e-04 - val_val_KL loss: 24.0189 - val_beta: 0.0011\n",
      "Epoch 1723/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 663.7704 - recon_loss: 7.6907e-04 - KL loss: 24.2051 - beta: 0.0011 - val_val_loss: 669.5929 - val_val_recon_loss: 7.7639e-04 - val_val_KL loss: 23.9458 - val_beta: 0.0011\n",
      "Epoch 1724/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 666.9292 - recon_loss: 7.7311e-04 - KL loss: 24.0041 - beta: 0.0011 - val_val_loss: 669.7618 - val_val_recon_loss: 7.7660e-04 - val_val_KL loss: 23.9375 - val_beta: 0.0011\n",
      "Epoch 1725/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 667.8289 - recon_loss: 7.7421e-04 - KL loss: 23.9873 - beta: 0.0011 - val_val_loss: 669.8651 - val_val_recon_loss: 7.7674e-04 - val_val_KL loss: 23.9247 - val_beta: 0.0011\n",
      "Epoch 1726/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 669.4388 - recon_loss: 7.7598e-04 - KL loss: 24.1323 - beta: 0.0011 - val_val_loss: 668.4611 - val_val_recon_loss: 7.7499e-04 - val_val_KL loss: 23.9736 - val_beta: 0.0011\n",
      "Epoch 1727/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 662.2119 - recon_loss: 7.6730e-04 - KL loss: 24.1199 - beta: 0.0011 - val_val_loss: 669.9645 - val_val_recon_loss: 7.7663e-04 - val_val_KL loss: 24.1163 - val_beta: 0.0011\n",
      "Epoch 1728/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 663.0101 - recon_loss: 7.6826e-04 - KL loss: 24.1214 - beta: 0.0011 - val_val_loss: 669.5107 - val_val_recon_loss: 7.7616e-04 - val_val_KL loss: 24.0504 - val_beta: 0.0011\n",
      "Epoch 1729/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 665.4340 - recon_loss: 7.7109e-04 - KL loss: 24.1883 - beta: 0.0011 - val_val_loss: 669.7910 - val_val_recon_loss: 7.7653e-04 - val_val_KL loss: 24.0234 - val_beta: 0.0011\n",
      "Epoch 1730/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 659.9862 - recon_loss: 7.6461e-04 - KL loss: 24.1351 - beta: 0.0011 - val_val_loss: 669.9354 - val_val_recon_loss: 7.7665e-04 - val_val_KL loss: 24.0668 - val_beta: 0.0011\n",
      "Epoch 1731/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 664.6472 - recon_loss: 7.7019e-04 - KL loss: 24.1496 - beta: 0.0011\n",
      "Epoch 01731: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 664.6495 - recon_loss: 7.7020e-04 - KL loss: 24.1496 - beta: 0.0011 - val_val_loss: 670.7155 - val_val_recon_loss: 7.7760e-04 - val_val_KL loss: 24.0567 - val_beta: 0.0011\n",
      "Epoch 1732/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 668.2946 - recon_loss: 7.7463e-04 - KL loss: 24.1068 - beta: 0.0011 - val_val_loss: 669.5067 - val_val_recon_loss: 7.7622e-04 - val_val_KL loss: 24.0002 - val_beta: 0.0011\n",
      "Epoch 1733/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 661.0788 - recon_loss: 7.6587e-04 - KL loss: 24.1760 - beta: 0.0011 - val_val_loss: 668.4888 - val_val_recon_loss: 7.7498e-04 - val_val_KL loss: 24.0125 - val_beta: 0.0011\n",
      "Epoch 1734/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 663.7294 - recon_loss: 7.6909e-04 - KL loss: 24.1507 - beta: 0.0011 - val_val_loss: 668.1513 - val_val_recon_loss: 7.7454e-04 - val_val_KL loss: 24.0388 - val_beta: 0.0011\n",
      "Epoch 1735/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 669.6449 - recon_loss: 7.7614e-04 - KL loss: 24.1996 - beta: 0.0011 - val_val_loss: 668.0457 - val_val_recon_loss: 7.7442e-04 - val_val_KL loss: 24.0364 - val_beta: 0.0011\n",
      "Epoch 1736/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 665.2920 - recon_loss: 7.7089e-04 - KL loss: 24.2196 - beta: 0.0011 - val_val_loss: 668.9473 - val_val_recon_loss: 7.7552e-04 - val_val_KL loss: 24.0181 - val_beta: 0.0011\n",
      "Epoch 1737/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 661.8333 - recon_loss: 7.6690e-04 - KL loss: 24.0744 - beta: 0.0011 - val_val_loss: 668.1985 - val_val_recon_loss: 7.7457e-04 - val_val_KL loss: 24.0626 - val_beta: 0.0011\n",
      "Epoch 1738/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 666.5363 - recon_loss: 7.7243e-04 - KL loss: 24.1754 - beta: 0.0011 - val_val_loss: 669.5623 - val_val_recon_loss: 7.7615e-04 - val_val_KL loss: 24.1141 - val_beta: 0.0011\n",
      "Epoch 1739/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 664.7131 - recon_loss: 7.7040e-04 - KL loss: 24.0453 - beta: 0.0011 - val_val_loss: 668.3781 - val_val_recon_loss: 7.7477e-04 - val_val_KL loss: 24.0775 - val_beta: 0.0011\n",
      "Epoch 1740/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 666.3579 - recon_loss: 7.7224e-04 - KL loss: 24.1583 - beta: 0.0011\n",
      "Epoch 01740: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 666.3572 - recon_loss: 7.7224e-04 - KL loss: 24.1583 - beta: 0.0011 - val_val_loss: 668.4744 - val_val_recon_loss: 7.7490e-04 - val_val_KL loss: 24.0642 - val_beta: 0.0011\n",
      "Epoch 1741/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 665.2038 - recon_loss: 7.7072e-04 - KL loss: 24.2661 - beta: 0.0011 - val_val_loss: 668.3668 - val_val_recon_loss: 7.7476e-04 - val_val_KL loss: 24.0712 - val_beta: 0.0011\n",
      "Epoch 1742/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 670.4721 - recon_loss: 7.7705e-04 - KL loss: 24.2755 - beta: 0.0011 - val_val_loss: 669.2821 - val_val_recon_loss: 7.7586e-04 - val_val_KL loss: 24.0769 - val_beta: 0.0011\n",
      "Epoch 1743/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 666.5343 - recon_loss: 7.7229e-04 - KL loss: 24.2914 - beta: 0.0011 - val_val_loss: 668.1531 - val_val_recon_loss: 7.7448e-04 - val_val_KL loss: 24.0943 - val_beta: 0.0011\n",
      "Epoch 1744/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 666.5231 - recon_loss: 7.7256e-04 - KL loss: 24.0574 - beta: 0.0011 - val_val_loss: 669.1108 - val_val_recon_loss: 7.7566e-04 - val_val_KL loss: 24.0681 - val_beta: 0.0011\n",
      "Epoch 1745/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 671.9252 - recon_loss: 7.7888e-04 - KL loss: 24.2036 - beta: 0.0011\n",
      "Epoch 01745: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 671.9224 - recon_loss: 7.7888e-04 - KL loss: 24.2036 - beta: 0.0011 - val_val_loss: 668.5771 - val_val_recon_loss: 7.7500e-04 - val_val_KL loss: 24.0838 - val_beta: 0.0011\n",
      "Epoch 1745/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2268.5999 - recon_loss: 8.3183e-04 - KL loss: 30.0683 - beta: 6.0959e-04 - val_val_loss: 2236.0552 - val_val_recon_loss: 8.1913e-04 - val_val_KL loss: 31.6993 - val_beta: 6.0959e-04\n",
      "Epoch 1746/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2263.9401 - recon_loss: 8.2948e-04 - KL loss: 31.7369 - beta: 6.0959e-04 - val_val_loss: 2189.4712 - val_val_recon_loss: 8.0175e-04 - val_val_KL loss: 31.8903 - val_beta: 6.0959e-04\n",
      "Epoch 1747/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2214.4434 - recon_loss: 8.1082e-04 - KL loss: 32.4557 - beta: 6.0959e-04 - val_val_loss: 2177.6416 - val_val_recon_loss: 7.9693e-04 - val_val_KL loss: 33.0398 - val_beta: 6.0959e-04\n",
      "Epoch 1748/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2147.7940 - recon_loss: 7.8565e-04 - KL loss: 33.5436 - beta: 6.0959e-04 - val_val_loss: 2124.8743 - val_val_recon_loss: 7.7699e-04 - val_val_KL loss: 33.9361 - val_beta: 6.0959e-04\n",
      "Epoch 1749/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2120.4855 - recon_loss: 7.7517e-04 - KL loss: 34.4227 - beta: 6.0959e-04 - val_val_loss: 2106.3660 - val_val_recon_loss: 7.7017e-04 - val_val_KL loss: 33.7651 - val_beta: 6.0959e-04\n",
      "Epoch 1750/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2108.1808 - recon_loss: 7.7047e-04 - KL loss: 34.7739 - beta: 6.0959e-04 - val_val_loss: 2103.1260 - val_val_recon_loss: 7.6821e-04 - val_val_KL loss: 35.8161 - val_beta: 6.0959e-04\n",
      "Epoch 1751/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2109.1289 - recon_loss: 7.7035e-04 - KL loss: 36.0529 - beta: 6.0959e-04 - val_val_loss: 2135.4768 - val_val_recon_loss: 7.8056e-04 - val_val_KL loss: 34.9306 - val_beta: 6.0959e-04\n",
      "Epoch 1752/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2126.0068 - recon_loss: 7.7707e-04 - KL loss: 34.8540 - beta: 6.0959e-04 - val_val_loss: 2138.8452 - val_val_recon_loss: 7.8177e-04 - val_val_KL loss: 35.0236 - val_beta: 6.0959e-04\n",
      "Epoch 1753/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2141.6716 - recon_loss: 7.8256e-04 - KL loss: 35.7242 - beta: 6.0959e-04 - val_val_loss: 2099.5723 - val_val_recon_loss: 7.6667e-04 - val_val_KL loss: 36.4097 - val_beta: 6.0959e-04\n",
      "Epoch 1754/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2095.5979 - recon_loss: 7.6478e-04 - KL loss: 37.5098 - beta: 6.0959e-04 - val_val_loss: 2085.6462 - val_val_recon_loss: 7.6048e-04 - val_val_KL loss: 39.1266 - val_beta: 6.0959e-04\n",
      "Epoch 1755/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2029.1920 - recon_loss: 7.3909e-04 - KL loss: 40.2461 - beta: 6.0959e-04 - val_val_loss: 2044.3805 - val_val_recon_loss: 7.4484e-04 - val_val_KL loss: 39.9508 - val_beta: 6.0959e-04\n",
      "Epoch 1756/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2045.6001 - recon_loss: 7.4512e-04 - KL loss: 40.4057 - beta: 6.0959e-04 - val_val_loss: 2022.2484 - val_val_recon_loss: 7.3632e-04 - val_val_KL loss: 40.7523 - val_beta: 6.0959e-04\n",
      "Epoch 1757/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1994.7658 - recon_loss: 7.2570e-04 - KL loss: 41.8469 - beta: 6.0959e-04 - val_val_loss: 1993.5189 - val_val_recon_loss: 7.2547e-04 - val_val_KL loss: 41.2206 - val_beta: 6.0959e-04\n",
      "Epoch 1758/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2006.1204 - recon_loss: 7.2984e-04 - KL loss: 42.0613 - beta: 6.0959e-04 - val_val_loss: 2072.5532 - val_val_recon_loss: 7.5484e-04 - val_val_KL loss: 41.2143 - val_beta: 6.0959e-04\n",
      "Epoch 1759/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2029.3900 - recon_loss: 7.3831e-04 - KL loss: 42.5336 - beta: 6.0959e-04 - val_val_loss: 2102.3906 - val_val_recon_loss: 7.6574e-04 - val_val_KL loss: 41.7283 - val_beta: 6.0959e-04\n",
      "Epoch 1760/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 2032.5821 - recon_loss: 7.3983e-04 - KL loss: 41.6418 - beta: 6.0959e-04 - val_val_loss: 1975.5881 - val_val_recon_loss: 7.1824e-04 - val_val_KL loss: 42.7366 - val_beta: 6.0959e-04\n",
      "Epoch 1761/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1957.9065 - recon_loss: 7.1157e-04 - KL loss: 42.9994 - beta: 6.0959e-04 - val_val_loss: 1932.8232 - val_val_recon_loss: 7.0200e-04 - val_val_KL loss: 43.6831 - val_beta: 6.0959e-04\n",
      "Epoch 1762/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1897.1927 - recon_loss: 6.8835e-04 - KL loss: 44.7736 - beta: 6.0959e-04 - val_val_loss: 1861.1450 - val_val_recon_loss: 6.7416e-04 - val_val_KL loss: 46.9111 - val_beta: 6.0959e-04\n",
      "Epoch 1763/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1850.7940 - recon_loss: 6.7038e-04 - KL loss: 46.7509 - beta: 6.0959e-04 - val_val_loss: 1924.9766 - val_val_recon_loss: 6.9861e-04 - val_val_KL loss: 44.9701 - val_beta: 6.0959e-04\n",
      "Epoch 1764/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1868.0530 - recon_loss: 6.7678e-04 - KL loss: 46.7801 - beta: 6.0959e-04 - val_val_loss: 1893.4922 - val_val_recon_loss: 6.8410e-04 - val_val_KL loss: 52.5126 - val_beta: 6.0959e-04\n",
      "Epoch 1765/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1855.7243 - recon_loss: 6.7052e-04 - KL loss: 51.3066 - beta: 6.0959e-04 - val_val_loss: 1800.4106 - val_val_recon_loss: 6.4965e-04 - val_val_KL loss: 52.1366 - val_beta: 6.0959e-04\n",
      "Epoch 1766/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1785.2596 - recon_loss: 6.4428e-04 - KL loss: 51.4419 - beta: 6.0959e-04 - val_val_loss: 1827.5093 - val_val_recon_loss: 6.5828e-04 - val_val_KL loss: 56.0117 - val_beta: 6.0959e-04\n",
      "Epoch 1767/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1757.1834 - recon_loss: 6.3298e-04 - KL loss: 53.7821 - beta: 6.0959e-04 - val_val_loss: 1728.1168 - val_val_recon_loss: 6.2219e-04 - val_val_KL loss: 53.7363 - val_beta: 6.0959e-04\n",
      "Epoch 1768/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1679.7552 - recon_loss: 6.0472e-04 - KL loss: 52.4092 - beta: 6.0959e-04 - val_val_loss: 1722.1194 - val_val_recon_loss: 6.2095e-04 - val_val_KL loss: 51.1018 - val_beta: 6.0959e-04\n",
      "Epoch 1769/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1713.6927 - recon_loss: 6.1788e-04 - KL loss: 50.9336 - beta: 6.0959e-04 - val_val_loss: 1724.0659 - val_val_recon_loss: 6.2290e-04 - val_val_KL loss: 47.7794 - val_beta: 6.0959e-04\n",
      "Epoch 1770/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1721.8853 - recon_loss: 6.2215e-04 - KL loss: 47.6237 - beta: 6.0959e-04 - val_val_loss: 1674.7780 - val_val_recon_loss: 6.0445e-04 - val_val_KL loss: 48.1418 - val_beta: 6.0959e-04\n",
      "Epoch 1771/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1677.8244 - recon_loss: 6.0544e-04 - KL loss: 48.5312 - beta: 6.0959e-04 - val_val_loss: 1727.9750 - val_val_recon_loss: 6.2496e-04 - val_val_KL loss: 46.1472 - val_beta: 6.0959e-04\n",
      "Epoch 1772/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1722.0135 - recon_loss: 6.2250e-04 - KL loss: 46.8195 - beta: 6.0959e-04 - val_val_loss: 1720.8341 - val_val_recon_loss: 6.2230e-04 - val_val_KL loss: 46.1815 - val_beta: 6.0959e-04\n",
      "Epoch 1773/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1718.1445 - recon_loss: 6.2108e-04 - KL loss: 46.7561 - beta: 6.0959e-04 - val_val_loss: 1685.1814 - val_val_recon_loss: 6.0877e-04 - val_val_KL loss: 46.9329 - val_beta: 6.0959e-04\n",
      "Epoch 1774/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1731.5667 - recon_loss: 6.2602e-04 - KL loss: 46.8878 - beta: 6.0959e-04 - val_val_loss: 1794.4259 - val_val_recon_loss: 6.4995e-04 - val_val_KL loss: 45.3450 - val_beta: 6.0959e-04\n",
      "Epoch 1775/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1788.9577 - recon_loss: 6.4790e-04 - KL loss: 45.3957 - beta: 6.0959e-04\n",
      "Epoch 01775: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1788.9303 - recon_loss: 6.4789e-04 - KL loss: 45.3963 - beta: 6.0959e-04 - val_val_loss: 1688.5848 - val_val_recon_loss: 6.1016e-04 - val_val_KL loss: 46.5872 - val_beta: 6.0959e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1776/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1675.0297 - recon_loss: 6.0501e-04 - KL loss: 46.8984 - beta: 6.0959e-04 - val_val_loss: 1659.2410 - val_val_recon_loss: 5.9906e-04 - val_val_KL loss: 47.1180 - val_beta: 6.0959e-04\n",
      "Epoch 1777/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1680.6158 - recon_loss: 6.0700e-04 - KL loss: 47.1157 - beta: 6.0959e-04 - val_val_loss: 1654.1508 - val_val_recon_loss: 5.9710e-04 - val_val_KL loss: 47.3130 - val_beta: 6.0959e-04\n",
      "Epoch 1778/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1654.5388 - recon_loss: 5.9710e-04 - KL loss: 47.6863 - beta: 6.0959e-04 - val_val_loss: 1632.4280 - val_val_recon_loss: 5.8830e-04 - val_val_KL loss: 49.2548 - val_beta: 6.0959e-04\n",
      "Epoch 1779/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1609.8727 - recon_loss: 5.8024e-04 - KL loss: 48.3873 - beta: 6.0959e-04 - val_val_loss: 1602.5542 - val_val_recon_loss: 5.7758e-04 - val_val_KL loss: 48.2259 - val_beta: 6.0959e-04\n",
      "Epoch 1780/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1589.0372 - recon_loss: 5.7244e-04 - KL loss: 48.5606 - beta: 6.0959e-04 - val_val_loss: 1602.5962 - val_val_recon_loss: 5.7767e-04 - val_val_KL loss: 48.0390 - val_beta: 6.0959e-04\n",
      "Epoch 1781/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1599.7816 - recon_loss: 5.7665e-04 - KL loss: 47.9719 - beta: 6.0959e-04 - val_val_loss: 1593.2740 - val_val_recon_loss: 5.7389e-04 - val_val_KL loss: 48.8738 - val_beta: 6.0959e-04\n",
      "Epoch 1782/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1570.1426 - recon_loss: 5.6536e-04 - KL loss: 48.7044 - beta: 6.0959e-04 - val_val_loss: 1573.8374 - val_val_recon_loss: 5.6664e-04 - val_val_KL loss: 48.9720 - val_beta: 6.0959e-04\n",
      "Epoch 1783/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1572.9307 - recon_loss: 5.6616e-04 - KL loss: 49.3374 - beta: 6.0959e-04 - val_val_loss: 1568.7241 - val_val_recon_loss: 5.6494e-04 - val_val_KL loss: 48.4342 - val_beta: 6.0959e-04\n",
      "Epoch 1784/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1566.9689 - recon_loss: 5.6434e-04 - KL loss: 48.2867 - beta: 6.0959e-04 - val_val_loss: 1568.1914 - val_val_recon_loss: 5.6482e-04 - val_val_KL loss: 48.1996 - val_beta: 6.0959e-04\n",
      "Epoch 1785/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1571.1530 - recon_loss: 5.6588e-04 - KL loss: 48.3308 - beta: 6.0959e-04 - val_val_loss: 1568.6267 - val_val_recon_loss: 5.6467e-04 - val_val_KL loss: 49.0564 - val_beta: 6.0959e-04\n",
      "Epoch 1786/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1554.7230 - recon_loss: 5.5979e-04 - KL loss: 48.2671 - beta: 6.0959e-04 - val_val_loss: 1589.4189 - val_val_recon_loss: 5.7286e-04 - val_val_KL loss: 47.8061 - val_beta: 6.0959e-04\n",
      "Epoch 1787/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1587.5546 - recon_loss: 5.7205e-04 - KL loss: 48.1078 - beta: 6.0959e-04 - val_val_loss: 1583.2405 - val_val_recon_loss: 5.7020e-04 - val_val_KL loss: 48.7818 - val_beta: 6.0959e-04\n",
      "Epoch 1788/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1610.6356 - recon_loss: 5.8054e-04 - KL loss: 48.3625 - beta: 6.0959e-04 - val_val_loss: 1618.9067 - val_val_recon_loss: 5.8384e-04 - val_val_KL loss: 47.7467 - val_beta: 6.0959e-04\n",
      "Epoch 1789/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1623.2955 - recon_loss: 5.8540e-04 - KL loss: 47.9319 - beta: 6.0959e-04\n",
      "Epoch 01789: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1623.3007 - recon_loss: 5.8540e-04 - KL loss: 47.9317 - beta: 6.0959e-04 - val_val_loss: 1625.7775 - val_val_recon_loss: 5.8643e-04 - val_val_KL loss: 47.6397 - val_beta: 6.0959e-04\n",
      "Epoch 1790/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1623.8335 - recon_loss: 5.8568e-04 - KL loss: 47.7257 - beta: 6.0959e-04 - val_val_loss: 1616.5166 - val_val_recon_loss: 5.8292e-04 - val_val_KL loss: 47.8274 - val_beta: 6.0959e-04\n",
      "Epoch 1791/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1604.3046 - recon_loss: 5.7835e-04 - KL loss: 47.9270 - beta: 6.0959e-04 - val_val_loss: 1597.4258 - val_val_recon_loss: 5.7564e-04 - val_val_KL loss: 48.3404 - val_beta: 6.0959e-04\n",
      "Epoch 1792/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1590.5939 - recon_loss: 5.7317e-04 - KL loss: 48.1378 - beta: 6.0959e-04 - val_val_loss: 1592.9399 - val_val_recon_loss: 5.7405e-04 - val_val_KL loss: 48.1325 - val_beta: 6.0959e-04\n",
      "Epoch 1793/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1598.1111 - recon_loss: 5.7592e-04 - KL loss: 48.2691 - beta: 6.0959e-04 - val_val_loss: 1577.6586 - val_val_recon_loss: 5.6813e-04 - val_val_KL loss: 48.7678 - val_beta: 6.0959e-04\n",
      "Epoch 1794/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1590.7812 - recon_loss: 5.7312e-04 - KL loss: 48.4778 - beta: 6.0959e-04\n",
      "Epoch 01794: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1590.7720 - recon_loss: 5.7311e-04 - KL loss: 48.4777 - beta: 6.0959e-04 - val_val_loss: 1594.6128 - val_val_recon_loss: 5.7459e-04 - val_val_KL loss: 48.3444 - val_beta: 6.0959e-04\n",
      "Epoch 1794/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5739.3930 - recon_loss: 6.5243e-04 - KL loss: 57.7527 - beta: 3.3887e-04 - val_val_loss: 5338.3687 - val_val_recon_loss: 6.0523e-04 - val_val_KL loss: 67.8215 - val_beta: 3.3887e-04\n",
      "Epoch 1795/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 5229.2899 - recon_loss: 5.9256e-04 - KL loss: 69.0238 - beta: 3.3887e-04 - val_val_loss: 4997.3765 - val_val_recon_loss: 5.6553e-04 - val_val_KL loss: 72.5428 - val_beta: 3.3887e-04\n",
      "Epoch 1796/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4988.5889 - recon_loss: 5.6450e-04 - KL loss: 72.7329 - beta: 3.3887e-04 - val_val_loss: 5011.1245 - val_val_recon_loss: 5.6709e-04 - val_val_KL loss: 72.6982 - val_beta: 3.3887e-04\n",
      "Epoch 1797/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5049.7402 - recon_loss: 5.7142e-04 - KL loss: 73.6199 - beta: 3.3887e-04 - val_val_loss: 4972.6968 - val_val_recon_loss: 5.6234e-04 - val_val_KL loss: 75.5971 - val_beta: 3.3887e-04\n",
      "Epoch 1798/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 5014.5174 - recon_loss: 5.6703e-04 - KL loss: 76.6332 - beta: 3.3887e-04 - val_val_loss: 4922.0435 - val_val_recon_loss: 5.5624e-04 - val_val_KL loss: 78.0627 - val_beta: 3.3887e-04\n",
      "Epoch 1799/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4824.9038 - recon_loss: 5.4501e-04 - KL loss: 78.7566 - beta: 3.3887e-04 - val_val_loss: 4805.0645 - val_val_recon_loss: 5.4301e-04 - val_val_KL loss: 76.3542 - val_beta: 3.3887e-04\n",
      "Epoch 1800/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4674.2562 - recon_loss: 5.2770e-04 - KL loss: 78.8271 - beta: 3.3887e-04 - val_val_loss: 4734.3350 - val_val_recon_loss: 5.3420e-04 - val_val_KL loss: 82.3017 - val_beta: 3.3887e-04\n",
      "Epoch 1801/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4684.7971 - recon_loss: 5.2858e-04 - KL loss: 81.7443 - beta: 3.3887e-04 - val_val_loss: 4629.8555 - val_val_recon_loss: 5.2249e-04 - val_val_KL loss: 79.7914 - val_beta: 3.3887e-04\n",
      "Epoch 1802/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4573.1699 - recon_loss: 5.1587e-04 - KL loss: 80.7773 - beta: 3.3887e-04 - val_val_loss: 4521.5537 - val_val_recon_loss: 5.0997e-04 - val_val_KL loss: 80.5054 - val_beta: 3.3887e-04\n",
      "Epoch 1803/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4541.2363 - recon_loss: 5.1206e-04 - KL loss: 82.0148 - beta: 3.3887e-04 - val_val_loss: 4625.2056 - val_val_recon_loss: 5.2152e-04 - val_val_KL loss: 83.5657 - val_beta: 3.3887e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1804/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4530.7971 - recon_loss: 5.1065e-04 - KL loss: 83.8858 - beta: 3.3887e-04 - val_val_loss: 4493.0298 - val_val_recon_loss: 5.0608e-04 - val_val_KL loss: 85.8438 - val_beta: 3.3887e-04\n",
      "Epoch 1805/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4495.4664 - recon_loss: 5.0626e-04 - KL loss: 86.7485 - beta: 3.3887e-04 - val_val_loss: 4428.8652 - val_val_recon_loss: 4.9853e-04 - val_val_KL loss: 87.5033 - val_beta: 3.3887e-04\n",
      "Epoch 1806/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4350.8940 - recon_loss: 4.8981e-04 - KL loss: 85.4543 - beta: 3.3887e-04 - val_val_loss: 4411.5142 - val_val_recon_loss: 4.9685e-04 - val_val_KL loss: 84.7273 - val_beta: 3.3887e-04\n",
      "Epoch 1807/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4345.6407 - recon_loss: 4.8920e-04 - KL loss: 85.4986 - beta: 3.3887e-04 - val_val_loss: 4432.4668 - val_val_recon_loss: 4.9916e-04 - val_val_KL loss: 85.6144 - val_beta: 3.3887e-04\n",
      "Epoch 1808/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4339.8776 - recon_loss: 4.8878e-04 - KL loss: 83.4042 - beta: 3.3887e-04 - val_val_loss: 4368.3276 - val_val_recon_loss: 4.9228e-04 - val_val_KL loss: 81.3941 - val_beta: 3.3887e-04\n",
      "Epoch 1809/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4262.3087 - recon_loss: 4.7993e-04 - KL loss: 82.9038 - beta: 3.3887e-04 - val_val_loss: 4272.9004 - val_val_recon_loss: 4.8073e-04 - val_val_KL loss: 86.5194 - val_beta: 3.3887e-04\n",
      "Epoch 1810/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4271.3027 - recon_loss: 4.8067e-04 - KL loss: 85.4649 - beta: 3.3887e-04 - val_val_loss: 4688.6733 - val_val_recon_loss: 5.2776e-04 - val_val_KL loss: 92.7666 - val_beta: 3.3887e-04\n",
      "Epoch 1811/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4457.9692 - recon_loss: 5.0169e-04 - KL loss: 89.0450 - beta: 3.3887e-04 - val_val_loss: 4176.5293 - val_val_recon_loss: 4.6979e-04 - val_val_KL loss: 85.4325 - val_beta: 3.3887e-04\n",
      "Epoch 1812/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4189.8126 - recon_loss: 4.7111e-04 - KL loss: 87.2360 - beta: 3.3887e-04 - val_val_loss: 4263.2104 - val_val_recon_loss: 4.7975e-04 - val_val_KL loss: 85.3912 - val_beta: 3.3887e-04\n",
      "Epoch 1813/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4279.9904 - recon_loss: 4.8141e-04 - KL loss: 87.6792 - beta: 3.3887e-04 - val_val_loss: 4159.2568 - val_val_recon_loss: 4.6814e-04 - val_val_KL loss: 82.5458 - val_beta: 3.3887e-04\n",
      "Epoch 1814/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4145.4719 - recon_loss: 4.6634e-04 - KL loss: 84.4199 - beta: 3.3887e-04 - val_val_loss: 4149.9253 - val_val_recon_loss: 4.6696e-04 - val_val_KL loss: 83.4919 - val_beta: 3.3887e-04\n",
      "Epoch 1815/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4087.2239 - recon_loss: 4.5980e-04 - KL loss: 83.1235 - beta: 3.3887e-04 - val_val_loss: 4066.5271 - val_val_recon_loss: 4.5747e-04 - val_val_KL loss: 82.6770 - val_beta: 3.3887e-04\n",
      "Epoch 1816/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4076.6319 - recon_loss: 4.5871e-04 - KL loss: 82.0111 - beta: 3.3887e-04 - val_val_loss: 4087.9282 - val_val_recon_loss: 4.6009e-04 - val_val_KL loss: 81.3192 - val_beta: 3.3887e-04\n",
      "Epoch 1817/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4234.7969 - recon_loss: 4.7688e-04 - KL loss: 81.9642 - beta: 3.3887e-04 - val_val_loss: 4118.5752 - val_val_recon_loss: 4.6348e-04 - val_val_KL loss: 82.3829 - val_beta: 3.3887e-04\n",
      "Epoch 1818/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4062.2868 - recon_loss: 4.5695e-04 - KL loss: 82.9902 - beta: 3.3887e-04 - val_val_loss: 4148.2705 - val_val_recon_loss: 4.6685e-04 - val_val_KL loss: 82.7507 - val_beta: 3.3887e-04\n",
      "Epoch 1819/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4057.1632 - recon_loss: 4.5641e-04 - KL loss: 82.5861 - beta: 3.3887e-04 - val_val_loss: 3977.1841 - val_val_recon_loss: 4.4713e-04 - val_val_KL loss: 83.4182 - val_beta: 3.3887e-04\n",
      "Epoch 1820/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3932.5052 - recon_loss: 4.4201e-04 - KL loss: 83.3350 - beta: 3.3887e-04 - val_val_loss: 3972.8284 - val_val_recon_loss: 4.4656e-04 - val_val_KL loss: 84.0495 - val_beta: 3.3887e-04\n",
      "Epoch 1821/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3932.3824 - recon_loss: 4.4192e-04 - KL loss: 83.9659 - beta: 3.3887e-04 - val_val_loss: 3915.0649 - val_val_recon_loss: 4.4023e-04 - val_val_KL loss: 81.3790 - val_beta: 3.3887e-04\n",
      "Epoch 1822/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3910.9394 - recon_loss: 4.3963e-04 - KL loss: 82.5029 - beta: 3.3887e-04 - val_val_loss: 3940.6108 - val_val_recon_loss: 4.4278e-04 - val_val_KL loss: 84.7319 - val_beta: 3.3887e-04\n",
      "Epoch 1823/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3884.5689 - recon_loss: 4.3660e-04 - KL loss: 82.5239 - beta: 3.3887e-04 - val_val_loss: 3888.7959 - val_val_recon_loss: 4.3699e-04 - val_val_KL loss: 83.2866 - val_beta: 3.3887e-04\n",
      "Epoch 1824/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 4074.8013 - recon_loss: 4.5799e-04 - KL loss: 86.4578 - beta: 3.3887e-04 - val_val_loss: 4021.0127 - val_val_recon_loss: 4.5213e-04 - val_val_KL loss: 83.7184 - val_beta: 3.3887e-04\n",
      "Epoch 1825/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3943.0701 - recon_loss: 4.4302e-04 - KL loss: 85.0368 - beta: 3.3887e-04 - val_val_loss: 3934.4802 - val_val_recon_loss: 4.4186e-04 - val_val_KL loss: 86.6099 - val_beta: 3.3887e-04\n",
      "Epoch 1826/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3977.8068 - recon_loss: 4.4666e-04 - KL loss: 88.1209 - beta: 3.3887e-04 - val_val_loss: 4179.4678 - val_val_recon_loss: 4.6953e-04 - val_val_KL loss: 90.6498 - val_beta: 3.3887e-04\n",
      "Epoch 1827/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 4110.3751 - recon_loss: 4.6135e-04 - KL loss: 92.7603 - beta: 3.3887e-04 - val_val_loss: 4074.6436 - val_val_recon_loss: 4.5856e-04 - val_val_KL loss: 81.3125 - val_beta: 3.3887e-04\n",
      "Epoch 1828/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3918.8917 - recon_loss: 4.4033e-04 - KL loss: 84.3417 - beta: 3.3887e-04 - val_val_loss: 3856.7415 - val_val_recon_loss: 4.3312e-04 - val_val_KL loss: 84.9887 - val_beta: 3.3887e-04\n",
      "Epoch 1829/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3784.5746 - recon_loss: 4.2476e-04 - KL loss: 85.5791 - beta: 3.3887e-04 - val_val_loss: 3852.6738 - val_val_recon_loss: 4.3276e-04 - val_val_KL loss: 84.0314 - val_beta: 3.3887e-04\n",
      "Epoch 1830/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3888.4244 - recon_loss: 4.3699e-04 - KL loss: 82.9273 - beta: 3.3887e-04 - val_val_loss: 4097.6050 - val_val_recon_loss: 4.6089e-04 - val_val_KL loss: 83.9800 - val_beta: 3.3887e-04\n",
      "Epoch 1831/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3882.8700 - recon_loss: 4.3624e-04 - KL loss: 83.8859 - beta: 3.3887e-04 - val_val_loss: 3877.1140 - val_val_recon_loss: 4.3597e-04 - val_val_KL loss: 80.4815 - val_beta: 3.3887e-04\n",
      "Epoch 1832/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3887.2780 - recon_loss: 4.3708e-04 - KL loss: 81.0271 - beta: 3.3887e-04 - val_val_loss: 3847.3943 - val_val_recon_loss: 4.3240e-04 - val_val_KL loss: 81.8984 - val_beta: 3.3887e-04\n",
      "Epoch 1833/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3787.8441 - recon_loss: 4.2560e-04 - KL loss: 81.5282 - beta: 3.3887e-04 - val_val_loss: 3801.8950 - val_val_recon_loss: 4.2677e-04 - val_val_KL loss: 85.3750 - val_beta: 3.3887e-04\n",
      "Epoch 1834/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3764.4693 - recon_loss: 4.2268e-04 - KL loss: 83.6089 - beta: 3.3887e-04 - val_val_loss: 3779.3850 - val_val_recon_loss: 4.2461e-04 - val_val_KL loss: 81.7143 - val_beta: 3.3887e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1835/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3715.1573 - recon_loss: 4.1719e-04 - KL loss: 82.1329 - beta: 3.3887e-04 - val_val_loss: 3790.7910 - val_val_recon_loss: 4.2584e-04 - val_val_KL loss: 82.4490 - val_beta: 3.3887e-04\n",
      "Epoch 1836/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3836.7094 - recon_loss: 4.3107e-04 - KL loss: 82.7789 - beta: 3.3887e-04 - val_val_loss: 3899.6777 - val_val_recon_loss: 4.3793e-04 - val_val_KL loss: 85.9931 - val_beta: 3.3887e-04\n",
      "Epoch 1837/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3768.7500 - recon_loss: 4.2305e-04 - KL loss: 84.6398 - beta: 3.3887e-04 - val_val_loss: 3820.0437 - val_val_recon_loss: 4.2929e-04 - val_val_KL loss: 81.5918 - val_beta: 3.3887e-04\n",
      "Epoch 1838/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3718.5053 - recon_loss: 4.1764e-04 - KL loss: 81.5279 - beta: 3.3887e-04 - val_val_loss: 3679.4932 - val_val_recon_loss: 4.1320e-04 - val_val_KL loss: 81.2256 - val_beta: 3.3887e-04\n",
      "Epoch 1839/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3660.9505 - recon_loss: 4.1096e-04 - KL loss: 82.1529 - beta: 3.3887e-04 - val_val_loss: 3750.1670 - val_val_recon_loss: 4.2108e-04 - val_val_KL loss: 83.2232 - val_beta: 3.3887e-04\n",
      "Epoch 1840/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3752.5256 - recon_loss: 4.2132e-04 - KL loss: 83.4697 - beta: 3.3887e-04 - val_val_loss: 3701.1436 - val_val_recon_loss: 4.1510e-04 - val_val_KL loss: 86.3103 - val_beta: 3.3887e-04\n",
      "Epoch 1841/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3678.6144 - recon_loss: 4.1256e-04 - KL loss: 85.9159 - beta: 3.3887e-04 - val_val_loss: 3639.8071 - val_val_recon_loss: 4.0814e-04 - val_val_KL loss: 85.5957 - val_beta: 3.3887e-04\n",
      "Epoch 1842/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3628.4604 - recon_loss: 4.0714e-04 - KL loss: 82.9099 - beta: 3.3887e-04 - val_val_loss: 3605.7258 - val_val_recon_loss: 4.0467e-04 - val_val_KL loss: 81.7403 - val_beta: 3.3887e-04\n",
      "Epoch 1843/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3681.4049 - recon_loss: 4.1311e-04 - KL loss: 83.8627 - beta: 3.3887e-04 - val_val_loss: 3739.9844 - val_val_recon_loss: 4.1937e-04 - val_val_KL loss: 87.9698 - val_beta: 3.3887e-04\n",
      "Epoch 1844/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3782.9781 - recon_loss: 4.2418e-04 - KL loss: 89.0698 - beta: 3.3887e-04 - val_val_loss: 3780.3560 - val_val_recon_loss: 4.2445e-04 - val_val_KL loss: 84.1048 - val_beta: 3.3887e-04\n",
      "Epoch 1845/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3648.7240 - recon_loss: 4.0931e-04 - KL loss: 84.3231 - beta: 3.3887e-04 - val_val_loss: 3652.2854 - val_val_recon_loss: 4.0960e-04 - val_val_KL loss: 85.2934 - val_beta: 3.3887e-04\n",
      "Epoch 1846/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3733.8203 - recon_loss: 4.1860e-04 - KL loss: 88.4763 - beta: 3.3887e-04 - val_val_loss: 3681.7542 - val_val_recon_loss: 4.1266e-04 - val_val_KL loss: 88.1472 - val_beta: 3.3887e-04\n",
      "Epoch 1847/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3667.7186 - recon_loss: 4.1104e-04 - KL loss: 88.2298 - beta: 3.3887e-04\n",
      "Epoch 01847: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3667.7114 - recon_loss: 4.1104e-04 - KL loss: 88.2287 - beta: 3.3887e-04 - val_val_loss: 3626.4043 - val_val_recon_loss: 4.0668e-04 - val_val_KL loss: 84.8358 - val_beta: 3.3887e-04\n",
      "Epoch 1848/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3509.4056 - recon_loss: 3.9319e-04 - KL loss: 85.3358 - beta: 3.3887e-04 - val_val_loss: 3506.0840 - val_val_recon_loss: 3.9252e-04 - val_val_KL loss: 87.8309 - val_beta: 3.3887e-04\n",
      "Epoch 1849/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3439.3738 - recon_loss: 3.8489e-04 - KL loss: 87.5660 - beta: 3.3887e-04 - val_val_loss: 3504.1357 - val_val_recon_loss: 3.9230e-04 - val_val_KL loss: 87.8009 - val_beta: 3.3887e-04\n",
      "Epoch 1850/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3466.3163 - recon_loss: 3.8794e-04 - KL loss: 87.9844 - beta: 3.3887e-04 - val_val_loss: 3485.3472 - val_val_recon_loss: 3.9015e-04 - val_val_KL loss: 87.7953 - val_beta: 3.3887e-04\n",
      "Epoch 1851/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3447.8629 - recon_loss: 3.8589e-04 - KL loss: 87.3862 - beta: 3.3887e-04 - val_val_loss: 3503.3315 - val_val_recon_loss: 3.9216e-04 - val_val_KL loss: 88.2365 - val_beta: 3.3887e-04\n",
      "Epoch 1852/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3441.6846 - recon_loss: 3.8514e-04 - KL loss: 87.7080 - beta: 3.3887e-04 - val_val_loss: 3510.0125 - val_val_recon_loss: 3.9281e-04 - val_val_KL loss: 89.2558 - val_beta: 3.3887e-04\n",
      "Epoch 1853/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3457.9707 - recon_loss: 3.8686e-04 - KL loss: 89.0196 - beta: 3.3887e-04 - val_val_loss: 3499.4077 - val_val_recon_loss: 3.9173e-04 - val_val_KL loss: 88.0795 - val_beta: 3.3887e-04\n",
      "Epoch 1854/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3430.8306 - recon_loss: 3.8387e-04 - KL loss: 87.9460 - beta: 3.3887e-04 - val_val_loss: 3490.2949 - val_val_recon_loss: 3.9081e-04 - val_val_KL loss: 86.9752 - val_beta: 3.3887e-04\n",
      "Epoch 1855/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3422.9962 - recon_loss: 3.8299e-04 - KL loss: 87.8076 - beta: 3.3887e-04 - val_val_loss: 3459.9688 - val_val_recon_loss: 3.8719e-04 - val_val_KL loss: 88.1257 - val_beta: 3.3887e-04\n",
      "Epoch 1856/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3414.6657 - recon_loss: 3.8203e-04 - KL loss: 87.8219 - beta: 3.3887e-04 - val_val_loss: 3458.5969 - val_val_recon_loss: 3.8724e-04 - val_val_KL loss: 86.3950 - val_beta: 3.3887e-04\n",
      "Epoch 1857/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3392.2261 - recon_loss: 3.7965e-04 - KL loss: 86.0428 - beta: 3.3887e-04 - val_val_loss: 3446.1299 - val_val_recon_loss: 3.8584e-04 - val_val_KL loss: 86.0540 - val_beta: 3.3887e-04\n",
      "Epoch 1858/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3403.8914 - recon_loss: 3.8096e-04 - KL loss: 86.3316 - beta: 3.3887e-04 - val_val_loss: 3430.4937 - val_val_recon_loss: 3.8406e-04 - val_val_KL loss: 85.9796 - val_beta: 3.3887e-04\n",
      "Epoch 1859/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3405.3462 - recon_loss: 3.8103e-04 - KL loss: 87.2068 - beta: 3.3887e-04 - val_val_loss: 3422.1904 - val_val_recon_loss: 3.8314e-04 - val_val_KL loss: 85.6154 - val_beta: 3.3887e-04\n",
      "Epoch 1860/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3378.1673 - recon_loss: 3.7808e-04 - KL loss: 85.7401 - beta: 3.3887e-04 - val_val_loss: 3476.8784 - val_val_recon_loss: 3.8942e-04 - val_val_KL loss: 85.6177 - val_beta: 3.3887e-04\n",
      "Epoch 1861/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3424.2097 - recon_loss: 3.8337e-04 - KL loss: 85.6410 - beta: 3.3887e-04 - val_val_loss: 3425.3743 - val_val_recon_loss: 3.8334e-04 - val_val_KL loss: 87.0556 - val_beta: 3.3887e-04\n",
      "Epoch 1862/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3369.0969 - recon_loss: 3.7685e-04 - KL loss: 87.3790 - beta: 3.3887e-04 - val_val_loss: 3415.3091 - val_val_recon_loss: 3.8238e-04 - val_val_KL loss: 85.3865 - val_beta: 3.3887e-04\n",
      "Epoch 1863/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3374.2395 - recon_loss: 3.7770e-04 - KL loss: 85.0667 - beta: 3.3887e-04 - val_val_loss: 3441.8738 - val_val_recon_loss: 3.8562e-04 - val_val_KL loss: 83.7787 - val_beta: 3.3887e-04\n",
      "Epoch 1864/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3374.9355 - recon_loss: 3.7793e-04 - KL loss: 83.7901 - beta: 3.3887e-04 - val_val_loss: 3457.4653 - val_val_recon_loss: 3.8752e-04 - val_val_KL loss: 82.8084 - val_beta: 3.3887e-04\n",
      "Epoch 1865/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3423.8348 - recon_loss: 3.8369e-04 - KL loss: 82.5199 - beta: 3.3887e-04 - val_val_loss: 3413.5042 - val_val_recon_loss: 3.8250e-04 - val_val_KL loss: 82.5233 - val_beta: 3.3887e-04\n",
      "Epoch 1866/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3377.6561 - recon_loss: 3.7837e-04 - KL loss: 82.6871 - beta: 3.3887e-04 - val_val_loss: 3458.0806 - val_val_recon_loss: 3.8770e-04 - val_val_KL loss: 81.8557 - val_beta: 3.3887e-04\n",
      "Epoch 1867/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3396.3570 - recon_loss: 3.8057e-04 - KL loss: 82.2238 - beta: 3.3887e-04 - val_val_loss: 3395.9319 - val_val_recon_loss: 3.8048e-04 - val_val_KL loss: 82.5891 - val_beta: 3.3887e-04\n",
      "Epoch 1868/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3391.3522 - recon_loss: 3.7996e-04 - KL loss: 82.4726 - beta: 3.3887e-04 - val_val_loss: 3427.1965 - val_val_recon_loss: 3.8397e-04 - val_val_KL loss: 83.4276 - val_beta: 3.3887e-04\n",
      "Epoch 1869/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3369.5535 - recon_loss: 3.7737e-04 - KL loss: 83.2721 - beta: 3.3887e-04 - val_val_loss: 3403.4556 - val_val_recon_loss: 3.8133e-04 - val_val_KL loss: 82.6499 - val_beta: 3.3887e-04\n",
      "Epoch 1870/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3426.4639 - recon_loss: 3.8401e-04 - KL loss: 82.3556 - beta: 3.3887e-04 - val_val_loss: 3410.0212 - val_val_recon_loss: 3.8209e-04 - val_val_KL loss: 82.6060 - val_beta: 3.3887e-04\n",
      "Epoch 1871/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3387.4062 - recon_loss: 3.7945e-04 - KL loss: 83.0142 - beta: 3.3887e-04 - val_val_loss: 3442.8347 - val_val_recon_loss: 3.8569e-04 - val_val_KL loss: 84.0725 - val_beta: 3.3887e-04\n",
      "Epoch 1872/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3430.5604 - recon_loss: 3.8435e-04 - KL loss: 83.5015 - beta: 3.3887e-04\n",
      "Epoch 01872: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3430.5446 - recon_loss: 3.8435e-04 - KL loss: 83.5011 - beta: 3.3887e-04 - val_val_loss: 3444.7434 - val_val_recon_loss: 3.8611e-04 - val_val_KL loss: 82.3660 - val_beta: 3.3887e-04\n",
      "Epoch 1873/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3364.2693 - recon_loss: 3.7680e-04 - KL loss: 82.9599 - beta: 3.3887e-04 - val_val_loss: 3374.7075 - val_val_recon_loss: 3.7800e-04 - val_val_KL loss: 82.9375 - val_beta: 3.3887e-04\n",
      "Epoch 1874/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3346.2019 - recon_loss: 3.7470e-04 - KL loss: 83.1686 - beta: 3.3887e-04 - val_val_loss: 3383.3484 - val_val_recon_loss: 3.7895e-04 - val_val_KL loss: 83.3321 - val_beta: 3.3887e-04\n",
      "Epoch 1875/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 3341.9696 - recon_loss: 3.7419e-04 - KL loss: 83.3711 - beta: 3.3887e-04 - val_val_loss: 3376.9382 - val_val_recon_loss: 3.7822e-04 - val_val_KL loss: 83.2368 - val_beta: 3.3887e-04\n",
      "Epoch 1876/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3332.0885 - recon_loss: 3.7310e-04 - KL loss: 82.9887 - beta: 3.3887e-04 - val_val_loss: 3367.4751 - val_val_recon_loss: 3.7716e-04 - val_val_KL loss: 83.0385 - val_beta: 3.3887e-04\n",
      "Epoch 1877/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3327.6288 - recon_loss: 3.7259e-04 - KL loss: 82.9696 - beta: 3.3887e-04 - val_val_loss: 3378.9719 - val_val_recon_loss: 3.7848e-04 - val_val_KL loss: 83.0504 - val_beta: 3.3887e-04\n",
      "Epoch 1878/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3335.9093 - recon_loss: 3.7352e-04 - KL loss: 83.1230 - beta: 3.3887e-04 - val_val_loss: 3385.6094 - val_val_recon_loss: 3.7927e-04 - val_val_KL loss: 82.7873 - val_beta: 3.3887e-04\n",
      "Epoch 1879/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3334.4720 - recon_loss: 3.7340e-04 - KL loss: 82.7751 - beta: 3.3887e-04 - val_val_loss: 3367.7151 - val_val_recon_loss: 3.7718e-04 - val_val_KL loss: 83.0826 - val_beta: 3.3887e-04\n",
      "Epoch 1880/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3329.9787 - recon_loss: 3.7283e-04 - KL loss: 83.2231 - beta: 3.3887e-04 - val_val_loss: 3360.6790 - val_val_recon_loss: 3.7638e-04 - val_val_KL loss: 83.0475 - val_beta: 3.3887e-04\n",
      "Epoch 1881/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3314.4237 - recon_loss: 3.7105e-04 - KL loss: 83.1329 - beta: 3.3887e-04 - val_val_loss: 3353.0715 - val_val_recon_loss: 3.7552e-04 - val_val_KL loss: 82.8652 - val_beta: 3.3887e-04\n",
      "Epoch 1882/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3332.1288 - recon_loss: 3.7313e-04 - KL loss: 82.7714 - beta: 3.3887e-04 - val_val_loss: 3346.3562 - val_val_recon_loss: 3.7475e-04 - val_val_KL loss: 82.9026 - val_beta: 3.3887e-04\n",
      "Epoch 1883/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3320.4289 - recon_loss: 3.7178e-04 - KL loss: 82.8415 - beta: 3.3887e-04 - val_val_loss: 3344.8293 - val_val_recon_loss: 3.7456e-04 - val_val_KL loss: 82.9868 - val_beta: 3.3887e-04\n",
      "Epoch 1884/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3297.8564 - recon_loss: 3.6910e-04 - KL loss: 83.6061 - beta: 3.3887e-04 - val_val_loss: 3331.0234 - val_val_recon_loss: 3.7291e-04 - val_val_KL loss: 83.5616 - val_beta: 3.3887e-04\n",
      "Epoch 1885/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3293.6553 - recon_loss: 3.6863e-04 - KL loss: 83.4612 - beta: 3.3887e-04 - val_val_loss: 3338.8413 - val_val_recon_loss: 3.7380e-04 - val_val_KL loss: 83.6006 - val_beta: 3.3887e-04\n",
      "Epoch 1886/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3315.9650 - recon_loss: 3.7116e-04 - KL loss: 83.7994 - beta: 3.3887e-04 - val_val_loss: 3340.3806 - val_val_recon_loss: 3.7402e-04 - val_val_KL loss: 83.2469 - val_beta: 3.3887e-04\n",
      "Epoch 1887/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3278.9088 - recon_loss: 3.6700e-04 - KL loss: 82.9406 - beta: 3.3887e-04 - val_val_loss: 3346.3110 - val_val_recon_loss: 3.7472e-04 - val_val_KL loss: 83.0910 - val_beta: 3.3887e-04\n",
      "Epoch 1888/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3309.1712 - recon_loss: 3.7045e-04 - KL loss: 83.1840 - beta: 3.3887e-04 - val_val_loss: 3348.1064 - val_val_recon_loss: 3.7490e-04 - val_val_KL loss: 83.3407 - val_beta: 3.3887e-04\n",
      "Epoch 1889/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3298.7559 - recon_loss: 3.6922e-04 - KL loss: 83.4447 - beta: 3.3887e-04\n",
      "Epoch 01889: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3298.7593 - recon_loss: 3.6922e-04 - KL loss: 83.4448 - beta: 3.3887e-04 - val_val_loss: 3338.6101 - val_val_recon_loss: 3.7380e-04 - val_val_KL loss: 83.3902 - val_beta: 3.3887e-04\n",
      "Epoch 1890/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3279.2752 - recon_loss: 3.6702e-04 - KL loss: 83.0978 - beta: 3.3887e-04 - val_val_loss: 3325.9456 - val_val_recon_loss: 3.7234e-04 - val_val_KL loss: 83.4571 - val_beta: 3.3887e-04\n",
      "Epoch 1891/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3305.1523 - recon_loss: 3.6997e-04 - KL loss: 83.2900 - beta: 3.3887e-04 - val_val_loss: 3323.1584 - val_val_recon_loss: 3.7201e-04 - val_val_KL loss: 83.5485 - val_beta: 3.3887e-04\n",
      "Epoch 1892/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3263.7764 - recon_loss: 3.6519e-04 - KL loss: 83.5168 - beta: 3.3887e-04 - val_val_loss: 3319.0713 - val_val_recon_loss: 3.7151e-04 - val_val_KL loss: 83.7855 - val_beta: 3.3887e-04\n",
      "Epoch 1893/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3246.9073 - recon_loss: 3.6328e-04 - KL loss: 83.2814 - beta: 3.3887e-04 - val_val_loss: 3314.1484 - val_val_recon_loss: 3.7095e-04 - val_val_KL loss: 83.7763 - val_beta: 3.3887e-04\n",
      "Epoch 1894/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3258.3916 - recon_loss: 3.6460e-04 - KL loss: 83.2736 - beta: 3.3887e-04 - val_val_loss: 3317.8450 - val_val_recon_loss: 3.7137e-04 - val_val_KL loss: 83.8509 - val_beta: 3.3887e-04\n",
      "Epoch 1895/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3276.0029 - recon_loss: 3.6657e-04 - KL loss: 83.7507 - beta: 3.3887e-04 - val_val_loss: 3312.2102 - val_val_recon_loss: 3.7071e-04 - val_val_KL loss: 83.9516 - val_beta: 3.3887e-04\n",
      "Epoch 1896/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3263.9141 - recon_loss: 3.6515e-04 - KL loss: 84.0828 - beta: 3.3887e-04 - val_val_loss: 3314.0125 - val_val_recon_loss: 3.7092e-04 - val_val_KL loss: 83.9001 - val_beta: 3.3887e-04\n",
      "Epoch 1897/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3278.3485 - recon_loss: 3.6683e-04 - KL loss: 83.8074 - beta: 3.3887e-04 - val_val_loss: 3314.9009 - val_val_recon_loss: 3.7101e-04 - val_val_KL loss: 84.0324 - val_beta: 3.3887e-04\n",
      "Epoch 1898/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3264.3051 - recon_loss: 3.6519e-04 - KL loss: 84.0779 - beta: 3.3887e-04 - val_val_loss: 3316.4187 - val_val_recon_loss: 3.7118e-04 - val_val_KL loss: 84.0551 - val_beta: 3.3887e-04\n",
      "Epoch 1899/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3290.5298 - recon_loss: 3.6820e-04 - KL loss: 84.0641 - beta: 3.3887e-04 - val_val_loss: 3303.4707 - val_val_recon_loss: 3.6968e-04 - val_val_KL loss: 84.1167 - val_beta: 3.3887e-04\n",
      "Epoch 1900/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3235.7128 - recon_loss: 3.6195e-04 - KL loss: 83.7428 - beta: 3.3887e-04 - val_val_loss: 3299.1526 - val_val_recon_loss: 3.6921e-04 - val_val_KL loss: 83.9654 - val_beta: 3.3887e-04\n",
      "Epoch 1901/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3274.5809 - recon_loss: 3.6635e-04 - KL loss: 84.2896 - beta: 3.3887e-04 - val_val_loss: 3304.5356 - val_val_recon_loss: 3.6977e-04 - val_val_KL loss: 84.3928 - val_beta: 3.3887e-04\n",
      "Epoch 1902/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3252.5927 - recon_loss: 3.6383e-04 - KL loss: 84.1994 - beta: 3.3887e-04 - val_val_loss: 3311.2961 - val_val_recon_loss: 3.7060e-04 - val_val_KL loss: 83.9401 - val_beta: 3.3887e-04\n",
      "Epoch 1903/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3282.4149 - recon_loss: 3.6727e-04 - KL loss: 84.0567 - beta: 3.3887e-04 - val_val_loss: 3308.3381 - val_val_recon_loss: 3.7025e-04 - val_val_KL loss: 84.0732 - val_beta: 3.3887e-04\n",
      "Epoch 1904/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3267.3515 - recon_loss: 3.6554e-04 - KL loss: 84.0960 - beta: 3.3887e-04 - val_val_loss: 3315.1094 - val_val_recon_loss: 3.7105e-04 - val_val_KL loss: 83.8590 - val_beta: 3.3887e-04\n",
      "Epoch 1905/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3269.1115 - recon_loss: 3.6579e-04 - KL loss: 83.6695 - beta: 3.3887e-04\n",
      "Epoch 01905: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3269.1158 - recon_loss: 3.6579e-04 - KL loss: 83.6697 - beta: 3.3887e-04 - val_val_loss: 3314.2285 - val_val_recon_loss: 3.7096e-04 - val_val_KL loss: 83.7756 - val_beta: 3.3887e-04\n",
      "Epoch 1906/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3299.4164 - recon_loss: 3.6928e-04 - KL loss: 83.6187 - beta: 3.3887e-04 - val_val_loss: 3307.9343 - val_val_recon_loss: 3.7023e-04 - val_val_KL loss: 83.8018 - val_beta: 3.3887e-04\n",
      "Epoch 1907/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 3275.9201 - recon_loss: 3.6655e-04 - KL loss: 83.8941 - beta: 3.3887e-04 - val_val_loss: 3308.6130 - val_val_recon_loss: 3.7031e-04 - val_val_KL loss: 83.8305 - val_beta: 3.3887e-04\n",
      "Epoch 1908/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3260.6219 - recon_loss: 3.6482e-04 - KL loss: 83.6447 - beta: 3.3887e-04 - val_val_loss: 3313.2881 - val_val_recon_loss: 3.7084e-04 - val_val_KL loss: 83.8640 - val_beta: 3.3887e-04\n",
      "Epoch 1909/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3254.4809 - recon_loss: 3.6412e-04 - KL loss: 83.6027 - beta: 3.3887e-04 - val_val_loss: 3312.2671 - val_val_recon_loss: 3.7073e-04 - val_val_KL loss: 83.8348 - val_beta: 3.3887e-04\n",
      "Epoch 1910/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3256.0841 - recon_loss: 3.6427e-04 - KL loss: 83.8483 - beta: 3.3887e-04\n",
      "Epoch 01910: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3256.0954 - recon_loss: 3.6427e-04 - KL loss: 83.8483 - beta: 3.3887e-04 - val_val_loss: 3308.8779 - val_val_recon_loss: 3.7034e-04 - val_val_KL loss: 83.8034 - val_beta: 3.3887e-04\n",
      "Epoch 1910/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 12926.9833 - recon_loss: 4.5521e-04 - KL loss: 98.9758 - beta: 1.8838e-04 - val_val_loss: 11766.3223 - val_val_recon_loss: 4.1364e-04 - val_val_KL loss: 109.7642 - val_beta: 1.8838e-04\n",
      "Epoch 1911/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11666.0816 - recon_loss: 4.1003e-04 - KL loss: 111.1646 - beta: 1.8838e-04 - val_val_loss: 11550.7695 - val_val_recon_loss: 4.0585e-04 - val_val_KL loss: 113.7249 - val_beta: 1.8838e-04\n",
      "Epoch 1912/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 11402.2317 - recon_loss: 4.0053e-04 - KL loss: 115.1092 - beta: 1.8838e-04 - val_val_loss: 11170.0908 - val_val_recon_loss: 3.9212e-04 - val_val_KL loss: 120.0324 - val_beta: 1.8838e-04\n",
      "Epoch 1913/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11185.0348 - recon_loss: 3.9264e-04 - KL loss: 120.2260 - beta: 1.8838e-04 - val_val_loss: 11821.0479 - val_val_recon_loss: 4.1498e-04 - val_val_KL loss: 126.6432 - val_beta: 1.8838e-04\n",
      "Epoch 1914/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 11374.1418 - recon_loss: 3.9933e-04 - KL loss: 120.7363 - beta: 1.8838e-04 - val_val_loss: 11321.8652 - val_val_recon_loss: 3.9765e-04 - val_val_KL loss: 115.8471 - val_beta: 1.8838e-04\n",
      "Epoch 1915/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11054.1513 - recon_loss: 3.8811e-04 - KL loss: 116.9364 - beta: 1.8838e-04 - val_val_loss: 11501.2676 - val_val_recon_loss: 4.0368e-04 - val_val_KL loss: 125.2664 - val_beta: 1.8838e-04\n",
      "Epoch 1916/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11175.4909 - recon_loss: 3.9214e-04 - KL loss: 124.7064 - beta: 1.8838e-04 - val_val_loss: 11262.0049 - val_val_recon_loss: 3.9532e-04 - val_val_KL loss: 121.7876 - val_beta: 1.8838e-04\n",
      "Epoch 1917/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11082.5358 - recon_loss: 3.8895e-04 - KL loss: 121.7897 - beta: 1.8838e-04 - val_val_loss: 11039.8184 - val_val_recon_loss: 3.8745e-04 - val_val_KL loss: 121.2449 - val_beta: 1.8838e-04\n",
      "Epoch 1918/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11182.3905 - recon_loss: 3.9249e-04 - KL loss: 121.9132 - beta: 1.8838e-04 - val_val_loss: 11585.0371 - val_val_recon_loss: 4.0661e-04 - val_val_KL loss: 126.5166 - val_beta: 1.8838e-04\n",
      "Epoch 1919/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11296.5098 - recon_loss: 3.9642e-04 - KL loss: 125.2554 - beta: 1.8838e-04 - val_val_loss: 11240.1914 - val_val_recon_loss: 3.9452e-04 - val_val_KL loss: 122.5299 - val_beta: 1.8838e-04\n",
      "Epoch 1920/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11220.9828 - recon_loss: 3.9372e-04 - KL loss: 125.7640 - beta: 1.8838e-04 - val_val_loss: 11303.8076 - val_val_recon_loss: 3.9648e-04 - val_val_KL loss: 130.8015 - val_beta: 1.8838e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1921/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11847.9969 - recon_loss: 4.1557e-04 - KL loss: 137.1712 - beta: 1.8838e-04 - val_val_loss: 11486.1260 - val_val_recon_loss: 4.0285e-04 - val_val_KL loss: 133.6739 - val_beta: 1.8838e-04\n",
      "Epoch 1922/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11351.4788 - recon_loss: 3.9801e-04 - KL loss: 135.3007 - beta: 1.8838e-04\n",
      "Epoch 01922: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11351.4847 - recon_loss: 3.9801e-04 - KL loss: 135.3015 - beta: 1.8838e-04 - val_val_loss: 11350.3662 - val_val_recon_loss: 3.9805e-04 - val_val_KL loss: 133.0941 - val_beta: 1.8838e-04\n",
      "Epoch 1923/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10874.4420 - recon_loss: 3.8117e-04 - KL loss: 133.0091 - beta: 1.8838e-04 - val_val_loss: 10799.3242 - val_val_recon_loss: 3.7852e-04 - val_val_KL loss: 132.3400 - val_beta: 1.8838e-04\n",
      "Epoch 1924/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10653.0530 - recon_loss: 3.7323e-04 - KL loss: 135.2595 - beta: 1.8838e-04 - val_val_loss: 10840.5137 - val_val_recon_loss: 3.7978e-04 - val_val_KL loss: 138.0131 - val_beta: 1.8838e-04\n",
      "Epoch 1925/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10651.4011 - recon_loss: 3.7308e-04 - KL loss: 137.9165 - beta: 1.8838e-04 - val_val_loss: 10634.1201 - val_val_recon_loss: 3.7257e-04 - val_val_KL loss: 134.8661 - val_beta: 1.8838e-04\n",
      "Epoch 1926/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10583.5889 - recon_loss: 3.7076e-04 - KL loss: 135.3753 - beta: 1.8838e-04 - val_val_loss: 10639.1289 - val_val_recon_loss: 3.7282e-04 - val_val_KL loss: 132.7832 - val_beta: 1.8838e-04\n",
      "Epoch 1927/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10527.8654 - recon_loss: 3.6884e-04 - KL loss: 133.8624 - beta: 1.8838e-04 - val_val_loss: 10655.5527 - val_val_recon_loss: 3.7319e-04 - val_val_KL loss: 138.8546 - val_beta: 1.8838e-04\n",
      "Epoch 1928/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10578.8950 - recon_loss: 3.7041e-04 - KL loss: 140.4686 - beta: 1.8838e-04 - val_val_loss: 11469.2178 - val_val_recon_loss: 4.0162e-04 - val_val_KL loss: 151.3233 - val_beta: 1.8838e-04\n",
      "Epoch 1929/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 11250.9973 - recon_loss: 3.9390e-04 - KL loss: 150.7924 - beta: 1.8838e-04 - val_val_loss: 11026.0000 - val_val_recon_loss: 3.8603e-04 - val_val_KL loss: 147.5301 - val_beta: 1.8838e-04\n",
      "Epoch 1930/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10803.0551 - recon_loss: 3.7821e-04 - KL loss: 145.0329 - beta: 1.8838e-04\n",
      "Epoch 01930: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10803.0304 - recon_loss: 3.7820e-04 - KL loss: 145.0324 - beta: 1.8838e-04 - val_val_loss: 10929.1152 - val_val_recon_loss: 3.8267e-04 - val_val_KL loss: 145.3797 - val_beta: 1.8838e-04\n",
      "Epoch 1931/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10708.3599 - recon_loss: 3.7479e-04 - KL loss: 146.5668 - beta: 1.8838e-04 - val_val_loss: 10766.5059 - val_val_recon_loss: 3.7688e-04 - val_val_KL loss: 145.8800 - val_beta: 1.8838e-04\n",
      "Epoch 1932/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10639.3019 - recon_loss: 3.7239e-04 - KL loss: 145.3051 - beta: 1.8838e-04 - val_val_loss: 10701.8311 - val_val_recon_loss: 3.7464e-04 - val_val_KL loss: 144.2867 - val_beta: 1.8838e-04\n",
      "Epoch 1933/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 10459.8393 - recon_loss: 3.6602e-04 - KL loss: 145.2306 - beta: 1.8838e-04 - val_val_loss: 10684.2334 - val_val_recon_loss: 3.7394e-04 - val_val_KL loss: 146.5394 - val_beta: 1.8838e-04\n",
      "Epoch 1934/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 10655.2765 - recon_loss: 3.7289e-04 - KL loss: 147.1858 - beta: 1.8838e-04 - val_val_loss: 10773.0342 - val_val_recon_loss: 3.7696e-04 - val_val_KL loss: 150.2037 - val_beta: 1.8838e-04\n",
      "Epoch 1935/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 10601.1652 - recon_loss: 3.7088e-04 - KL loss: 149.5094 - beta: 1.8838e-04\n",
      "Epoch 01935: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 10601.1237 - recon_loss: 3.7088e-04 - KL loss: 149.5084 - beta: 1.8838e-04 - val_val_loss: 10642.1562 - val_val_recon_loss: 3.7249e-04 - val_val_KL loss: 145.2283 - val_beta: 1.8838e-04\n",
      "Epoch 1935/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 38565.3932 - recon_loss: 4.2103e-04 - KL loss: 170.9710 - beta: 1.0472e-04 - val_val_loss: 36004.0469 - val_val_recon_loss: 3.9280e-04 - val_val_KL loss: 183.9176 - val_beta: 1.0472e-04\n",
      "Epoch 1936/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35885.7042 - recon_loss: 3.9138e-04 - KL loss: 195.2031 - beta: 1.0472e-04 - val_val_loss: 35691.4531 - val_val_recon_loss: 3.8907e-04 - val_val_KL loss: 211.1354 - val_beta: 1.0472e-04\n",
      "Epoch 1937/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35175.3726 - recon_loss: 3.8348e-04 - KL loss: 205.0735 - beta: 1.0472e-04 - val_val_loss: 35813.7344 - val_val_recon_loss: 3.9059e-04 - val_val_KL loss: 194.5182 - val_beta: 1.0472e-04\n",
      "Epoch 1938/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35219.9747 - recon_loss: 3.8401e-04 - KL loss: 201.5699 - beta: 1.0472e-04 - val_val_loss: 34391.6094 - val_val_recon_loss: 3.7481e-04 - val_val_KL loss: 211.7545 - val_beta: 1.0472e-04\n",
      "Epoch 1939/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 34024.1449 - recon_loss: 3.7078e-04 - KL loss: 211.4980 - beta: 1.0472e-04 - val_val_loss: 34899.8555 - val_val_recon_loss: 3.8051e-04 - val_val_KL loss: 200.4304 - val_beta: 1.0472e-04\n",
      "Epoch 1940/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 34267.2442 - recon_loss: 3.7348e-04 - KL loss: 208.9093 - beta: 1.0472e-04 - val_val_loss: 34118.7148 - val_val_recon_loss: 3.7193e-04 - val_val_KL loss: 201.1625 - val_beta: 1.0472e-04\n",
      "Epoch 1941/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 35064.1810 - recon_loss: 3.8222e-04 - KL loss: 208.3522 - beta: 1.0472e-04 - val_val_loss: 35041.4023 - val_val_recon_loss: 3.8180e-04 - val_val_KL loss: 223.7919 - val_beta: 1.0472e-04\n",
      "Epoch 1942/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 34703.8410 - recon_loss: 3.7821e-04 - KL loss: 214.3364 - beta: 1.0472e-04 - val_val_loss: 34021.3906 - val_val_recon_loss: 3.7075e-04 - val_val_KL loss: 211.4742 - val_beta: 1.0472e-04\n",
      "Epoch 1943/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 35257.9396 - recon_loss: 3.8419e-04 - KL loss: 223.1425 - beta: 1.0472e-04 - val_val_loss: 42164.2734 - val_val_recon_loss: 4.5941e-04 - val_val_KL loss: 269.8879 - val_beta: 1.0472e-04\n",
      "Epoch 1944/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 39590.6398 - recon_loss: 4.3123e-04 - KL loss: 265.9643 - beta: 1.0472e-04 - val_val_loss: 36006.8750 - val_val_recon_loss: 3.9223e-04 - val_val_KL loss: 238.3408 - val_beta: 1.0472e-04\n",
      "Epoch 1945/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 36163.6814 - recon_loss: 3.9406e-04 - KL loss: 228.4842 - beta: 1.0472e-04 - val_val_loss: 36245.6562 - val_val_recon_loss: 3.9491e-04 - val_val_KL loss: 232.5460 - val_beta: 1.0472e-04\n",
      "Epoch 1946/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 40160.3048 - recon_loss: 4.3756e-04 - KL loss: 257.7382 - beta: 1.0472e-04 - val_val_loss: 35729.3164 - val_val_recon_loss: 3.8916e-04 - val_val_KL loss: 240.4613 - val_beta: 1.0472e-04\n",
      "Epoch 1947/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 34788.0751 - recon_loss: 3.7877e-04 - KL loss: 247.1917 - beta: 1.0472e-04\n",
      "Epoch 01947: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 34788.0758 - recon_loss: 3.7877e-04 - KL loss: 247.1960 - beta: 1.0472e-04 - val_val_loss: 35241.6133 - val_val_recon_loss: 3.8366e-04 - val_val_KL loss: 254.8901 - val_beta: 1.0472e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1948/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 33829.5249 - recon_loss: 3.6810e-04 - KL loss: 261.9456 - beta: 1.0472e-04 - val_val_loss: 33534.0234 - val_val_recon_loss: 3.6489e-04 - val_val_KL loss: 259.2631 - val_beta: 1.0472e-04\n",
      "Epoch 1949/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 33132.7133 - recon_loss: 3.6047e-04 - KL loss: 260.5226 - beta: 1.0472e-04 - val_val_loss: 33508.8008 - val_val_recon_loss: 3.6475e-04 - val_val_KL loss: 246.3950 - val_beta: 1.0472e-04\n",
      "Epoch 1950/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32838.2955 - recon_loss: 3.5738e-04 - KL loss: 247.9837 - beta: 1.0472e-04 - val_val_loss: 32906.3594 - val_val_recon_loss: 3.5811e-04 - val_val_KL loss: 249.4379 - val_beta: 1.0472e-04\n",
      "Epoch 1951/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32748.6559 - recon_loss: 3.5634e-04 - KL loss: 253.1429 - beta: 1.0472e-04 - val_val_loss: 32692.6641 - val_val_recon_loss: 3.5571e-04 - val_val_KL loss: 254.4685 - val_beta: 1.0472e-04\n",
      "Epoch 1952/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32461.3059 - recon_loss: 3.5319e-04 - KL loss: 252.9346 - beta: 1.0472e-04 - val_val_loss: 32783.5234 - val_val_recon_loss: 3.5678e-04 - val_val_KL loss: 248.3179 - val_beta: 1.0472e-04\n",
      "Epoch 1953/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32665.2798 - recon_loss: 3.5539e-04 - KL loss: 256.7566 - beta: 1.0472e-04 - val_val_loss: 33208.9375 - val_val_recon_loss: 3.6122e-04 - val_val_KL loss: 268.1165 - val_beta: 1.0472e-04\n",
      "Epoch 1954/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32931.9228 - recon_loss: 3.5820e-04 - KL loss: 266.6546 - beta: 1.0472e-04 - val_val_loss: 32972.4297 - val_val_recon_loss: 3.5875e-04 - val_val_KL loss: 257.0733 - val_beta: 1.0472e-04\n",
      "Epoch 1955/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32404.2370 - recon_loss: 3.5250e-04 - KL loss: 258.5632 - beta: 1.0472e-04 - val_val_loss: 32382.2422 - val_val_recon_loss: 3.5228e-04 - val_val_KL loss: 257.1192 - val_beta: 1.0472e-04\n",
      "Epoch 1956/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31851.8044 - recon_loss: 3.4645e-04 - KL loss: 258.1344 - beta: 1.0472e-04 - val_val_loss: 32405.7949 - val_val_recon_loss: 3.5251e-04 - val_val_KL loss: 259.8823 - val_beta: 1.0472e-04\n",
      "Epoch 1957/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 32108.3196 - recon_loss: 3.4927e-04 - KL loss: 257.3521 - beta: 1.0472e-04 - val_val_loss: 33162.8281 - val_val_recon_loss: 3.6084e-04 - val_val_KL loss: 257.3220 - val_beta: 1.0472e-04\n",
      "Epoch 1958/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32220.1593 - recon_loss: 3.5049e-04 - KL loss: 258.4786 - beta: 1.0472e-04 - val_val_loss: 32061.8203 - val_val_recon_loss: 3.4874e-04 - val_val_KL loss: 259.3027 - val_beta: 1.0472e-04\n",
      "Epoch 1959/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 31546.0536 - recon_loss: 3.4310e-04 - KL loss: 257.7240 - beta: 1.0472e-04 - val_val_loss: 31926.7598 - val_val_recon_loss: 3.4730e-04 - val_val_KL loss: 255.3885 - val_beta: 1.0472e-04\n",
      "Epoch 1960/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 32178.2215 - recon_loss: 3.5010e-04 - KL loss: 251.7041 - beta: 1.0472e-04 - val_val_loss: 32171.9707 - val_val_recon_loss: 3.5004e-04 - val_val_KL loss: 251.3265 - val_beta: 1.0472e-04\n",
      "Epoch 1961/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 31577.0592 - recon_loss: 3.4350e-04 - KL loss: 252.1392 - beta: 1.0472e-04 - val_val_loss: 32119.4668 - val_val_recon_loss: 3.4949e-04 - val_val_KL loss: 248.8904 - val_beta: 1.0472e-04\n",
      "Epoch 1962/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 31903.1050 - recon_loss: 3.4711e-04 - KL loss: 248.9202 - beta: 1.0472e-04 - val_val_loss: 31884.2051 - val_val_recon_loss: 3.4690e-04 - val_val_KL loss: 249.6753 - val_beta: 1.0472e-04\n",
      "Epoch 1963/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31447.7339 - recon_loss: 3.4211e-04 - KL loss: 249.8283 - beta: 1.0472e-04 - val_val_loss: 32307.9121 - val_val_recon_loss: 3.5156e-04 - val_val_KL loss: 248.6487 - val_beta: 1.0472e-04\n",
      "Epoch 1964/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 31918.5868 - recon_loss: 3.4727e-04 - KL loss: 249.8058 - beta: 1.0472e-04 - val_val_loss: 32001.6582 - val_val_recon_loss: 3.4813e-04 - val_val_KL loss: 254.8090 - val_beta: 1.0472e-04\n",
      "Epoch 1965/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31584.5910 - recon_loss: 3.4354e-04 - KL loss: 256.1353 - beta: 1.0472e-04 - val_val_loss: 31759.3730 - val_val_recon_loss: 3.4552e-04 - val_val_KL loss: 251.0221 - val_beta: 1.0472e-04\n",
      "Epoch 1966/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31359.7792 - recon_loss: 3.4110e-04 - KL loss: 253.6824 - beta: 1.0472e-04 - val_val_loss: 31691.5684 - val_val_recon_loss: 3.4475e-04 - val_val_KL loss: 253.1748 - val_beta: 1.0472e-04\n",
      "Epoch 1967/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31552.9413 - recon_loss: 3.4323e-04 - KL loss: 252.6282 - beta: 1.0472e-04 - val_val_loss: 31702.7656 - val_val_recon_loss: 3.4487e-04 - val_val_KL loss: 253.1664 - val_beta: 1.0472e-04\n",
      "Epoch 1968/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31356.8461 - recon_loss: 3.4102e-04 - KL loss: 258.2143 - beta: 1.0472e-04 - val_val_loss: 32043.3691 - val_val_recon_loss: 3.4849e-04 - val_val_KL loss: 263.9974 - val_beta: 1.0472e-04\n",
      "Epoch 1969/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31878.1599 - recon_loss: 3.4668e-04 - KL loss: 263.9821 - beta: 1.0472e-04 - val_val_loss: 31786.2832 - val_val_recon_loss: 3.4567e-04 - val_val_KL loss: 263.7391 - val_beta: 1.0472e-04\n",
      "Epoch 1970/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31265.4760 - recon_loss: 3.3992e-04 - KL loss: 267.4326 - beta: 1.0472e-04 - val_val_loss: 31915.5879 - val_val_recon_loss: 3.4705e-04 - val_val_KL loss: 267.6566 - val_beta: 1.0472e-04\n",
      "Epoch 1971/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31692.5002 - recon_loss: 3.4460e-04 - KL loss: 268.0193 - beta: 1.0472e-04\n",
      "Epoch 01971: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31692.5953 - recon_loss: 3.4460e-04 - KL loss: 268.0202 - beta: 1.0472e-04 - val_val_loss: 31748.0977 - val_val_recon_loss: 3.4521e-04 - val_val_KL loss: 267.9886 - val_beta: 1.0472e-04\n",
      "Epoch 1972/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31193.2959 - recon_loss: 3.3913e-04 - KL loss: 267.2754 - beta: 1.0472e-04 - val_val_loss: 31437.1992 - val_val_recon_loss: 3.4180e-04 - val_val_KL loss: 268.0531 - val_beta: 1.0472e-04\n",
      "Epoch 1973/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31121.9921 - recon_loss: 3.3835e-04 - KL loss: 266.7564 - beta: 1.0472e-04 - val_val_loss: 31410.6641 - val_val_recon_loss: 3.4151e-04 - val_val_KL loss: 267.2878 - val_beta: 1.0472e-04\n",
      "Epoch 1974/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 31150.3709 - recon_loss: 3.3864e-04 - KL loss: 268.8010 - beta: 1.0472e-04 - val_val_loss: 31373.2070 - val_val_recon_loss: 3.4104e-04 - val_val_KL loss: 272.9287 - val_beta: 1.0472e-04\n",
      "Epoch 1975/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31191.2782 - recon_loss: 3.3904e-04 - KL loss: 273.1855 - beta: 1.0472e-04 - val_val_loss: 31574.0332 - val_val_recon_loss: 3.4330e-04 - val_val_KL loss: 267.3471 - val_beta: 1.0472e-04\n",
      "Epoch 1976/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31150.8334 - recon_loss: 3.3866e-04 - KL loss: 267.1803 - beta: 1.0472e-04 - val_val_loss: 31091.0703 - val_val_recon_loss: 3.3804e-04 - val_val_KL loss: 264.3107 - val_beta: 1.0472e-04\n",
      "Epoch 1977/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30761.8107 - recon_loss: 3.3443e-04 - KL loss: 264.6445 - beta: 1.0472e-04 - val_val_loss: 31184.0859 - val_val_recon_loss: 3.3902e-04 - val_val_KL loss: 268.3842 - val_beta: 1.0472e-04\n",
      "Epoch 1978/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30759.3954 - recon_loss: 3.3435e-04 - KL loss: 269.1639 - beta: 1.0472e-04 - val_val_loss: 31135.5898 - val_val_recon_loss: 3.3851e-04 - val_val_KL loss: 265.8579 - val_beta: 1.0472e-04\n",
      "Epoch 1979/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30529.2964 - recon_loss: 3.3187e-04 - KL loss: 265.6665 - beta: 1.0472e-04 - val_val_loss: 31059.1250 - val_val_recon_loss: 3.3765e-04 - val_val_KL loss: 267.6901 - val_beta: 1.0472e-04\n",
      "Epoch 1980/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30856.8626 - recon_loss: 3.3541e-04 - KL loss: 269.9672 - beta: 1.0472e-04 - val_val_loss: 31373.8320 - val_val_recon_loss: 3.4104e-04 - val_val_KL loss: 273.6424 - val_beta: 1.0472e-04\n",
      "Epoch 1981/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30995.0204 - recon_loss: 3.3689e-04 - KL loss: 273.0525 - beta: 1.0472e-04 - val_val_loss: 31122.6875 - val_val_recon_loss: 3.3833e-04 - val_val_KL loss: 269.9547 - val_beta: 1.0472e-04\n",
      "Epoch 1982/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30515.2721 - recon_loss: 3.3165e-04 - KL loss: 270.9696 - beta: 1.0472e-04 - val_val_loss: 31145.6152 - val_val_recon_loss: 3.3853e-04 - val_val_KL loss: 274.3388 - val_beta: 1.0472e-04\n",
      "Epoch 1983/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30892.3693 - recon_loss: 3.3576e-04 - KL loss: 274.0327 - beta: 1.0472e-04 - val_val_loss: 31276.1895 - val_val_recon_loss: 3.3991e-04 - val_val_KL loss: 278.6480 - val_beta: 1.0472e-04\n",
      "Epoch 1984/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 31019.0087 - recon_loss: 3.3709e-04 - KL loss: 278.6771 - beta: 1.0472e-04- ETA: 5s - loss: 31024.4792 - recon_loss: \n",
      "Epoch 01984: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 31018.8984 - recon_loss: 3.3709e-04 - KL loss: 278.6779 - beta: 1.0472e-04 - val_val_loss: 31319.6445 - val_val_recon_loss: 3.4037e-04 - val_val_KL loss: 280.7059 - val_beta: 1.0472e-04\n",
      "Epoch 1985/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30772.6635 - recon_loss: 3.3438e-04 - KL loss: 280.1420 - beta: 1.0472e-04 - val_val_loss: 31146.0449 - val_val_recon_loss: 3.3848e-04 - val_val_KL loss: 278.8440 - val_beta: 1.0472e-04\n",
      "Epoch 1986/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30876.0032 - recon_loss: 3.3552e-04 - KL loss: 279.1381 - beta: 1.0472e-04 - val_val_loss: 31084.1992 - val_val_recon_loss: 3.3781e-04 - val_val_KL loss: 278.7748 - val_beta: 1.0472e-04\n",
      "Epoch 1987/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30750.6311 - recon_loss: 3.3416e-04 - KL loss: 277.8421 - beta: 1.0472e-04 - val_val_loss: 31071.1523 - val_val_recon_loss: 3.3766e-04 - val_val_KL loss: 278.6717 - val_beta: 1.0472e-04\n",
      "Epoch 1988/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30464.8337 - recon_loss: 3.3102e-04 - KL loss: 278.4083 - beta: 1.0472e-04 - val_val_loss: 31053.3457 - val_val_recon_loss: 3.3747e-04 - val_val_KL loss: 278.7924 - val_beta: 1.0472e-04\n",
      "Epoch 1989/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30965.1597 - recon_loss: 3.3650e-04 - KL loss: 279.2505 - beta: 1.0472e-04 - val_val_loss: 31101.0117 - val_val_recon_loss: 3.3797e-04 - val_val_KL loss: 280.9991 - val_beta: 1.0472e-04\n",
      "Epoch 1990/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30546.4817 - recon_loss: 3.3189e-04 - KL loss: 280.3904 - beta: 1.0472e-04 - val_val_loss: 31117.0059 - val_val_recon_loss: 3.3814e-04 - val_val_KL loss: 281.4272 - val_beta: 1.0472e-04\n",
      "Epoch 1991/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30647.7334 - recon_loss: 3.3299e-04 - KL loss: 281.8502 - beta: 1.0472e-04 - val_val_loss: 31026.4121 - val_val_recon_loss: 3.3715e-04 - val_val_KL loss: 281.0699 - val_beta: 1.0472e-04\n",
      "Epoch 1992/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30683.7827 - recon_loss: 3.3338e-04 - KL loss: 282.4885 - beta: 1.0472e-04 - val_val_loss: 31028.8105 - val_val_recon_loss: 3.3717e-04 - val_val_KL loss: 281.7570 - val_beta: 1.0472e-04\n",
      "Epoch 1993/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30835.4603 - recon_loss: 3.3505e-04 - KL loss: 281.7055 - beta: 1.0472e-04 - val_val_loss: 31011.4199 - val_val_recon_loss: 3.3699e-04 - val_val_KL loss: 280.7350 - val_beta: 1.0472e-04\n",
      "Epoch 1994/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30541.4028 - recon_loss: 3.3184e-04 - KL loss: 279.8997 - beta: 1.0472e-04 - val_val_loss: 30991.5020 - val_val_recon_loss: 3.3677e-04 - val_val_KL loss: 280.4916 - val_beta: 1.0472e-04\n",
      "Epoch 1995/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30708.4286 - recon_loss: 3.3366e-04 - KL loss: 280.9500 - beta: 1.0472e-04 - val_val_loss: 30978.4375 - val_val_recon_loss: 3.3663e-04 - val_val_KL loss: 280.5966 - val_beta: 1.0472e-04\n",
      "Epoch 1996/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30489.2697 - recon_loss: 3.3126e-04 - KL loss: 280.8319 - beta: 1.0472e-04 - val_val_loss: 31014.8906 - val_val_recon_loss: 3.3702e-04 - val_val_KL loss: 281.5975 - val_beta: 1.0472e-04\n",
      "Epoch 1997/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30871.2331 - recon_loss: 3.3543e-04 - KL loss: 282.4176 - beta: 1.0472e-04 - val_val_loss: 30983.6641 - val_val_recon_loss: 3.3669e-04 - val_val_KL loss: 280.3763 - val_beta: 1.0472e-04\n",
      "Epoch 1998/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30736.8365 - recon_loss: 3.3397e-04 - KL loss: 281.1522 - beta: 1.0472e-04 - val_val_loss: 30979.7129 - val_val_recon_loss: 3.3663e-04 - val_val_KL loss: 281.7362 - val_beta: 1.0472e-04\n",
      "Epoch 1999/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30625.4447 - recon_loss: 3.3275e-04 - KL loss: 280.7829 - beta: 1.0472e-04 - val_val_loss: 30924.7344 - val_val_recon_loss: 3.3604e-04 - val_val_KL loss: 280.2626 - val_beta: 1.0472e-04\n",
      "Epoch 2000/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30428.5801 - recon_loss: 3.3059e-04 - KL loss: 281.3391 - beta: 1.0472e-04 - val_val_loss: 30977.2344 - val_val_recon_loss: 3.3660e-04 - val_val_KL loss: 281.7056 - val_beta: 1.0472e-04\n",
      "Epoch 2001/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30761.0995 - recon_loss: 3.3423e-04 - KL loss: 282.3206 - beta: 1.0472e-04 - val_val_loss: 31005.3008 - val_val_recon_loss: 3.3690e-04 - val_val_KL loss: 282.3332 - val_beta: 1.0472e-04\n",
      "Epoch 2002/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30706.9137 - recon_loss: 3.3363e-04 - KL loss: 282.6858 - beta: 1.0472e-04 - val_val_loss: 30919.4922 - val_val_recon_loss: 3.3598e-04 - val_val_KL loss: 280.8941 - val_beta: 1.0472e-04\n",
      "Epoch 2003/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30265.9477 - recon_loss: 3.2881e-04 - KL loss: 281.0663 - beta: 1.0472e-04 - val_val_loss: 30950.2695 - val_val_recon_loss: 3.3631e-04 - val_val_KL loss: 281.5605 - val_beta: 1.0472e-04\n",
      "Epoch 2004/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30621.6082 - recon_loss: 3.3271e-04 - KL loss: 281.3062 - beta: 1.0472e-04 - val_val_loss: 31041.2168 - val_val_recon_loss: 3.3729e-04 - val_val_KL loss: 283.3168 - val_beta: 1.0472e-04\n",
      "Epoch 2005/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30536.0201 - recon_loss: 3.3175e-04 - KL loss: 282.6812 - beta: 1.0472e-04 - val_val_loss: 30953.2480 - val_val_recon_loss: 3.3633e-04 - val_val_KL loss: 282.5082 - val_beta: 1.0472e-04\n",
      "Epoch 2006/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30442.9943 - recon_loss: 3.3074e-04 - KL loss: 281.9721 - beta: 1.0472e-04 - val_val_loss: 30911.8691 - val_val_recon_loss: 3.3589e-04 - val_val_KL loss: 281.4202 - val_beta: 1.0472e-04\n",
      "Epoch 2007/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30420.2287 - recon_loss: 3.3050e-04 - KL loss: 281.3499 - beta: 1.0472e-04 - val_val_loss: 30865.1055 - val_val_recon_loss: 3.3538e-04 - val_val_KL loss: 281.0238 - val_beta: 1.0472e-04\n",
      "Epoch 2008/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30469.9662 - recon_loss: 3.3105e-04 - KL loss: 280.4010 - beta: 1.0472e-04 - val_val_loss: 30819.7676 - val_val_recon_loss: 3.3489e-04 - val_val_KL loss: 280.1097 - val_beta: 1.0472e-04\n",
      "Epoch 2009/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30363.1544 - recon_loss: 3.2990e-04 - KL loss: 279.2161 - beta: 1.0472e-04 - val_val_loss: 30836.5801 - val_val_recon_loss: 3.3507e-04 - val_val_KL loss: 280.6500 - val_beta: 1.0472e-04\n",
      "Epoch 2010/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30567.2159 - recon_loss: 3.3212e-04 - KL loss: 280.4078 - beta: 1.0472e-04 - val_val_loss: 30881.8320 - val_val_recon_loss: 3.3556e-04 - val_val_KL loss: 281.0027 - val_beta: 1.0472e-04\n",
      "Epoch 2011/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30374.6151 - recon_loss: 3.3000e-04 - KL loss: 281.4505 - beta: 1.0472e-04 - val_val_loss: 30922.1348 - val_val_recon_loss: 3.3598e-04 - val_val_KL loss: 282.8903 - val_beta: 1.0472e-04\n",
      "Epoch 2012/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30238.2304 - recon_loss: 3.2848e-04 - KL loss: 282.8969 - beta: 1.0472e-04 - val_val_loss: 30868.6641 - val_val_recon_loss: 3.3540e-04 - val_val_KL loss: 282.3518 - val_beta: 1.0472e-04\n",
      "Epoch 2013/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 29978.3449 - recon_loss: 3.2565e-04 - KL loss: 281.3503 - beta: 1.0472e-04\n",
      "Epoch 02013: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29978.6074 - recon_loss: 3.2565e-04 - KL loss: 281.3509 - beta: 1.0472e-04 - val_val_loss: 30860.0391 - val_val_recon_loss: 3.3532e-04 - val_val_KL loss: 281.7741 - val_beta: 1.0472e-04\n",
      "Epoch 2014/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30123.0363 - recon_loss: 3.2723e-04 - KL loss: 281.9258 - beta: 1.0472e-04 - val_val_loss: 30818.0469 - val_val_recon_loss: 3.3485e-04 - val_val_KL loss: 281.9654 - val_beta: 1.0472e-04\n",
      "Epoch 2015/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30183.1342 - recon_loss: 3.2789e-04 - KL loss: 282.0001 - beta: 1.0472e-04 - val_val_loss: 30802.2852 - val_val_recon_loss: 3.3468e-04 - val_val_KL loss: 281.8605 - val_beta: 1.0472e-04\n",
      "Epoch 2016/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30330.9425 - recon_loss: 3.2952e-04 - KL loss: 281.4012 - beta: 1.0472e-04 - val_val_loss: 30806.0293 - val_val_recon_loss: 3.3472e-04 - val_val_KL loss: 282.5323 - val_beta: 1.0472e-04\n",
      "Epoch 2017/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30397.3624 - recon_loss: 3.3023e-04 - KL loss: 282.5546 - beta: 1.0472e-04 - val_val_loss: 30795.5703 - val_val_recon_loss: 3.3461e-04 - val_val_KL loss: 281.8658 - val_beta: 1.0472e-04\n",
      "Epoch 2018/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30285.9178 - recon_loss: 3.2902e-04 - KL loss: 281.9128 - beta: 1.0472e-04 - val_val_loss: 30798.3145 - val_val_recon_loss: 3.3464e-04 - val_val_KL loss: 281.6091 - val_beta: 1.0472e-04\n",
      "Epoch 2019/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30159.3351 - recon_loss: 3.2762e-04 - KL loss: 282.5175 - beta: 1.0472e-04 - val_val_loss: 30795.1367 - val_val_recon_loss: 3.3460e-04 - val_val_KL loss: 281.9528 - val_beta: 1.0472e-04\n",
      "Epoch 2020/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30470.7225 - recon_loss: 3.3104e-04 - KL loss: 282.4417 - beta: 1.0472e-04 - val_val_loss: 30785.3945 - val_val_recon_loss: 3.3450e-04 - val_val_KL loss: 281.3453 - val_beta: 1.0472e-04\n",
      "Epoch 2021/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30256.1261 - recon_loss: 3.2870e-04 - KL loss: 281.6350 - beta: 1.0472e-04 - val_val_loss: 30736.4004 - val_val_recon_loss: 3.3396e-04 - val_val_KL loss: 281.4624 - val_beta: 1.0472e-04\n",
      "Epoch 2022/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30468.0531 - recon_loss: 3.3102e-04 - KL loss: 281.8930 - beta: 1.0472e-04 - val_val_loss: 30737.0332 - val_val_recon_loss: 3.3397e-04 - val_val_KL loss: 281.5047 - val_beta: 1.0472e-04\n",
      "Epoch 2023/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30410.9859 - recon_loss: 3.3040e-04 - KL loss: 281.3301 - beta: 1.0472e-04 - val_val_loss: 30727.3418 - val_val_recon_loss: 3.3387e-04 - val_val_KL loss: 281.1176 - val_beta: 1.0472e-04\n",
      "Epoch 2024/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30240.6402 - recon_loss: 3.2853e-04 - KL loss: 281.4720 - beta: 1.0472e-04 - val_val_loss: 30711.1641 - val_val_recon_loss: 3.3369e-04 - val_val_KL loss: 281.5170 - val_beta: 1.0472e-04\n",
      "Epoch 2025/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29931.1257 - recon_loss: 3.2514e-04 - KL loss: 281.2402 - beta: 1.0472e-04 - val_val_loss: 30719.8926 - val_val_recon_loss: 3.3378e-04 - val_val_KL loss: 281.4244 - val_beta: 1.0472e-04\n",
      "Epoch 2026/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30388.8413 - recon_loss: 3.3015e-04 - KL loss: 281.5996 - beta: 1.0472e-04 - val_val_loss: 30710.4258 - val_val_recon_loss: 3.3368e-04 - val_val_KL loss: 281.1454 - val_beta: 1.0472e-04\n",
      "Epoch 2027/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30213.7894 - recon_loss: 3.2824e-04 - KL loss: 280.4906 - beta: 1.0472e-04 - val_val_loss: 30741.3496 - val_val_recon_loss: 3.3402e-04 - val_val_KL loss: 280.8349 - val_beta: 1.0472e-04\n",
      "Epoch 2028/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30361.9745 - recon_loss: 3.2986e-04 - KL loss: 281.4177 - beta: 1.0472e-04 - val_val_loss: 30713.7832 - val_val_recon_loss: 3.3372e-04 - val_val_KL loss: 281.0781 - val_beta: 1.0472e-04\n",
      "Epoch 2029/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30244.0940 - recon_loss: 3.2858e-04 - KL loss: 280.2974 - beta: 1.0472e-04 - val_val_loss: 30755.1895 - val_val_recon_loss: 3.3417e-04 - val_val_KL loss: 281.1469 - val_beta: 1.0472e-04\n",
      "Epoch 2030/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30230.8789 - recon_loss: 3.2843e-04 - KL loss: 280.7885 - beta: 1.0472e-04 - val_val_loss: 30712.8418 - val_val_recon_loss: 3.3371e-04 - val_val_KL loss: 281.4853 - val_beta: 1.0472e-04\n",
      "Epoch 2031/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30615.5444 - recon_loss: 3.3264e-04 - KL loss: 281.7653 - beta: 1.0472e-04 - val_val_loss: 30698.9082 - val_val_recon_loss: 3.3356e-04 - val_val_KL loss: 281.0430 - val_beta: 1.0472e-04\n",
      "Epoch 2032/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30227.3993 - recon_loss: 3.2838e-04 - KL loss: 281.6156 - beta: 1.0472e-04 - val_val_loss: 30691.9727 - val_val_recon_loss: 3.3348e-04 - val_val_KL loss: 281.3565 - val_beta: 1.0472e-04\n",
      "Epoch 2033/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30323.1545 - recon_loss: 3.2944e-04 - KL loss: 280.9787 - beta: 1.0472e-04 - val_val_loss: 30687.7832 - val_val_recon_loss: 3.3343e-04 - val_val_KL loss: 281.0982 - val_beta: 1.0472e-04\n",
      "Epoch 2034/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30200.0385 - recon_loss: 3.2809e-04 - KL loss: 280.7688 - beta: 1.0472e-04 - val_val_loss: 30696.6230 - val_val_recon_loss: 3.3353e-04 - val_val_KL loss: 281.0844 - val_beta: 1.0472e-04\n",
      "Epoch 2035/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30041.7765 - recon_loss: 3.2636e-04 - KL loss: 280.5259 - beta: 1.0472e-04 - val_val_loss: 30696.2676 - val_val_recon_loss: 3.3353e-04 - val_val_KL loss: 280.4068 - val_beta: 1.0472e-04\n",
      "Epoch 2036/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30052.6203 - recon_loss: 3.2648e-04 - KL loss: 280.0686 - beta: 1.0472e-04 - val_val_loss: 30708.3516 - val_val_recon_loss: 3.3367e-04 - val_val_KL loss: 280.0273 - val_beta: 1.0472e-04\n",
      "Epoch 2037/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30126.3566 - recon_loss: 3.2729e-04 - KL loss: 280.2464 - beta: 1.0472e-04 - val_val_loss: 30671.3691 - val_val_recon_loss: 3.3327e-04 - val_val_KL loss: 279.7681 - val_beta: 1.0472e-04\n",
      "Epoch 2038/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30507.6116 - recon_loss: 3.3147e-04 - KL loss: 279.7065 - beta: 1.0472e-04 - val_val_loss: 30659.0176 - val_val_recon_loss: 3.3314e-04 - val_val_KL loss: 279.2246 - val_beta: 1.0472e-04\n",
      "Epoch 2039/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30386.4118 - recon_loss: 3.3014e-04 - KL loss: 279.9459 - beta: 1.0472e-04 - val_val_loss: 30675.1699 - val_val_recon_loss: 3.3331e-04 - val_val_KL loss: 279.5468 - val_beta: 1.0472e-04\n",
      "Epoch 2040/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30210.6584 - recon_loss: 3.2822e-04 - KL loss: 279.3938 - beta: 1.0472e-04 - val_val_loss: 30688.6016 - val_val_recon_loss: 3.3346e-04 - val_val_KL loss: 279.8803 - val_beta: 1.0472e-04\n",
      "Epoch 2041/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30180.2259 - recon_loss: 3.2788e-04 - KL loss: 279.8752 - beta: 1.0472e-04 - val_val_loss: 30647.6250 - val_val_recon_loss: 3.3301e-04 - val_val_KL loss: 279.4230 - val_beta: 1.0472e-04\n",
      "Epoch 2042/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30008.6162 - recon_loss: 3.2601e-04 - KL loss: 279.2830 - beta: 1.0472e-04 - val_val_loss: 30652.5195 - val_val_recon_loss: 3.3307e-04 - val_val_KL loss: 279.0798 - val_beta: 1.0472e-04\n",
      "Epoch 2043/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30251.7430 - recon_loss: 3.2868e-04 - KL loss: 279.0654 - beta: 1.0472e-04 - val_val_loss: 30638.4102 - val_val_recon_loss: 3.3291e-04 - val_val_KL loss: 279.3189 - val_beta: 1.0472e-04\n",
      "Epoch 2044/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30133.8568 - recon_loss: 3.2737e-04 - KL loss: 280.4951 - beta: 1.0472e-04 - val_val_loss: 30625.8477 - val_val_recon_loss: 3.3277e-04 - val_val_KL loss: 279.5839 - val_beta: 1.0472e-04\n",
      "Epoch 2045/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30208.5183 - recon_loss: 3.2820e-04 - KL loss: 279.3369 - beta: 1.0472e-04 - val_val_loss: 30632.5898 - val_val_recon_loss: 3.3285e-04 - val_val_KL loss: 279.4845 - val_beta: 1.0472e-04\n",
      "Epoch 2046/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30203.0517 - recon_loss: 3.2812e-04 - KL loss: 280.5846 - beta: 1.0472e-04 - val_val_loss: 30657.1758 - val_val_recon_loss: 3.3311e-04 - val_val_KL loss: 279.9133 - val_beta: 1.0472e-04\n",
      "Epoch 2047/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30079.4911 - recon_loss: 3.2678e-04 - KL loss: 279.7265 - beta: 1.0472e-04 - val_val_loss: 30637.1895 - val_val_recon_loss: 3.3290e-04 - val_val_KL loss: 279.3924 - val_beta: 1.0472e-04\n",
      "Epoch 2048/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30275.7652 - recon_loss: 3.2893e-04 - KL loss: 279.4392 - beta: 1.0472e-04 - val_val_loss: 30616.4258 - val_val_recon_loss: 3.3267e-04 - val_val_KL loss: 279.7211 - val_beta: 1.0472e-04\n",
      "Epoch 2049/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30125.5210 - recon_loss: 3.2728e-04 - KL loss: 279.8270 - beta: 1.0472e-04 - val_val_loss: 30612.3691 - val_val_recon_loss: 3.3262e-04 - val_val_KL loss: 280.0695 - val_beta: 1.0472e-04\n",
      "Epoch 2050/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30060.8874 - recon_loss: 3.2658e-04 - KL loss: 279.6822 - beta: 1.0472e-04 - val_val_loss: 30649.7773 - val_val_recon_loss: 3.3303e-04 - val_val_KL loss: 279.5310 - val_beta: 1.0472e-04\n",
      "Epoch 2051/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30233.2036 - recon_loss: 3.2846e-04 - KL loss: 279.8579 - beta: 1.0472e-04 - val_val_loss: 30653.1250 - val_val_recon_loss: 3.3307e-04 - val_val_KL loss: 280.0855 - val_beta: 1.0472e-04\n",
      "Epoch 2052/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30199.3286 - recon_loss: 3.2809e-04 - KL loss: 280.4157 - beta: 1.0472e-04 - val_val_loss: 30608.9980 - val_val_recon_loss: 3.3259e-04 - val_val_KL loss: 279.7028 - val_beta: 1.0472e-04\n",
      "Epoch 2053/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30247.3515 - recon_loss: 3.2861e-04 - KL loss: 280.5092 - beta: 1.0472e-04 - val_val_loss: 30611.9824 - val_val_recon_loss: 3.3262e-04 - val_val_KL loss: 279.8826 - val_beta: 1.0472e-04\n",
      "Epoch 2054/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30097.0217 - recon_loss: 3.2697e-04 - KL loss: 279.6577 - beta: 1.0472e-04 - val_val_loss: 30584.1016 - val_val_recon_loss: 3.3232e-04 - val_val_KL loss: 279.3199 - val_beta: 1.0472e-04\n",
      "Epoch 2055/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30075.2650 - recon_loss: 3.2674e-04 - KL loss: 279.2801 - beta: 1.0472e-04 - val_val_loss: 30609.0273 - val_val_recon_loss: 3.3258e-04 - val_val_KL loss: 280.0982 - val_beta: 1.0472e-04\n",
      "Epoch 2056/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30437.0559 - recon_loss: 3.3069e-04 - KL loss: 281.0004 - beta: 1.0472e-04 - val_val_loss: 30640.9297 - val_val_recon_loss: 3.3293e-04 - val_val_KL loss: 280.4686 - val_beta: 1.0472e-04\n",
      "Epoch 2057/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30304.9803 - recon_loss: 3.2924e-04 - KL loss: 281.0593 - beta: 1.0472e-04 - val_val_loss: 30623.5332 - val_val_recon_loss: 3.3274e-04 - val_val_KL loss: 280.0894 - val_beta: 1.0472e-04\n",
      "Epoch 2058/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 29981.4387 - recon_loss: 3.2570e-04 - KL loss: 279.7988 - beta: 1.0472e-04 - val_val_loss: 30631.8906 - val_val_recon_loss: 3.3283e-04 - val_val_KL loss: 280.6956 - val_beta: 1.0472e-04\n",
      "Epoch 2059/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 30119.0008 - recon_loss: 3.2720e-04 - KL loss: 280.9396 - beta: 1.0472e-04\n",
      "Epoch 02059: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30119.0742 - recon_loss: 3.2720e-04 - KL loss: 280.9399 - beta: 1.0472e-04 - val_val_loss: 30649.1309 - val_val_recon_loss: 3.3301e-04 - val_val_KL loss: 281.1491 - val_beta: 1.0472e-04\n",
      "Epoch 2060/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30328.9740 - recon_loss: 3.2950e-04 - KL loss: 281.1010 - beta: 1.0472e-04 - val_val_loss: 30659.6230 - val_val_recon_loss: 3.3313e-04 - val_val_KL loss: 280.9799 - val_beta: 1.0472e-04\n",
      "Epoch 2061/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30435.8036 - recon_loss: 3.3066e-04 - KL loss: 282.2059 - beta: 1.0472e-04 - val_val_loss: 30643.2383 - val_val_recon_loss: 3.3295e-04 - val_val_KL loss: 281.0012 - val_beta: 1.0472e-04\n",
      "Epoch 2062/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 30303.5752 - recon_loss: 3.2921e-04 - KL loss: 281.9794 - beta: 1.0472e-04 - val_val_loss: 30635.5918 - val_val_recon_loss: 3.3286e-04 - val_val_KL loss: 281.0115 - val_beta: 1.0472e-04\n",
      "Epoch 2063/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30243.4717 - recon_loss: 3.2856e-04 - KL loss: 281.2760 - beta: 1.0472e-04 - val_val_loss: 30621.4043 - val_val_recon_loss: 3.3270e-04 - val_val_KL loss: 281.3950 - val_beta: 1.0472e-04\n",
      "Epoch 2064/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 30256.4536 - recon_loss: 3.2869e-04 - KL loss: 282.1476 - beta: 1.0472e-04\n",
      "Epoch 02064: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 30256.4372 - recon_loss: 3.2869e-04 - KL loss: 282.1475 - beta: 1.0472e-04 - val_val_loss: 30618.6172 - val_val_recon_loss: 3.3267e-04 - val_val_KL loss: 281.1997 - val_beta: 1.0472e-04\n",
      "Epoch 2064/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 117191.2508 - recon_loss: 3.9610e-04 - KL loss: 301.6840 - beta: 5.8212e-05 - val_val_loss: 107085.6562 - val_val_recon_loss: 3.6177e-04 - val_val_KL loss: 327.9785 - val_beta: 5.8212e-05\n",
      "Epoch 2065/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 115231.0799 - recon_loss: 3.8929e-04 - KL loss: 351.3969 - beta: 5.8212e-05 - val_val_loss: 113293.8828 - val_val_recon_loss: 3.8263e-04 - val_val_KL loss: 380.0471 - val_beta: 5.8212e-05\n",
      "Epoch 2066/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 113387.5322 - recon_loss: 3.8294e-04 - KL loss: 382.3175 - beta: 5.8212e-05 - val_val_loss: 123392.6328 - val_val_recon_loss: 4.1677e-04 - val_val_KL loss: 404.6392 - val_beta: 5.8212e-05\n",
      "Epoch 2067/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 116484.8163 - recon_loss: 3.9341e-04 - KL loss: 388.9782 - beta: 5.8212e-05 - val_val_loss: 108313.1484 - val_val_recon_loss: 3.6591e-04 - val_val_KL loss: 332.5073 - val_beta: 5.8212e-05\n",
      "Epoch 2068/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 105935.9633 - recon_loss: 3.5786e-04 - KL loss: 330.5623 - beta: 5.8212e-05 - val_val_loss: 104567.5000 - val_val_recon_loss: 3.5321e-04 - val_val_KL loss: 334.6327 - val_beta: 5.8212e-05\n",
      "Epoch 2069/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 106011.7347 - recon_loss: 3.5812e-04 - KL loss: 330.3150 - beta: 5.8212e-05 - val_val_loss: 104636.9688 - val_val_recon_loss: 3.5344e-04 - val_val_KL loss: 337.4868 - val_beta: 5.8212e-05\n",
      "Epoch 2070/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 104215.0578 - recon_loss: 3.5200e-04 - KL loss: 339.7224 - beta: 5.8212e-05 - val_val_loss: 103714.7422 - val_val_recon_loss: 3.5030e-04 - val_val_KL loss: 340.9005 - val_beta: 5.8212e-05\n",
      "Epoch 2071/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 102999.2770 - recon_loss: 3.4787e-04 - KL loss: 342.0382 - beta: 5.8212e-05 - val_val_loss: 108187.3203 - val_val_recon_loss: 3.6538e-04 - val_val_KL loss: 362.4333 - val_beta: 5.8212e-05\n",
      "Epoch 2072/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 104690.4011 - recon_loss: 3.5354e-04 - KL loss: 359.6862 - beta: 5.8212e-05 - val_val_loss: 104852.5469 - val_val_recon_loss: 3.5416e-04 - val_val_KL loss: 339.5587 - val_beta: 5.8212e-05\n",
      "Epoch 2073/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 104934.0096 - recon_loss: 3.5440e-04 - KL loss: 349.6069 - beta: 5.8212e-05 - val_val_loss: 108650.1719 - val_val_recon_loss: 3.6689e-04 - val_val_KL loss: 379.7261 - val_beta: 5.8212e-05\n",
      "Epoch 2074/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 107086.6757 - recon_loss: 3.6164e-04 - KL loss: 368.0233 - beta: 5.8212e-05 - val_val_loss: 105983.9062 - val_val_recon_loss: 3.5794e-04 - val_val_KL loss: 356.2934 - val_beta: 5.8212e-05\n",
      "Epoch 2075/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 103620.0116 - recon_loss: 3.4996e-04 - KL loss: 347.3042 - beta: 5.8212e-05\n",
      "Epoch 02075: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 103621.4483 - recon_loss: 3.4996e-04 - KL loss: 347.2959 - beta: 5.8212e-05 - val_val_loss: 104581.1719 - val_val_recon_loss: 3.5329e-04 - val_val_KL loss: 323.9913 - val_beta: 5.8212e-05\n",
      "Epoch 2076/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 101539.3109 - recon_loss: 3.4296e-04 - KL loss: 330.4445 - beta: 5.8212e-05 - val_val_loss: 100439.7031 - val_val_recon_loss: 3.3919e-04 - val_val_KL loss: 345.4132 - val_beta: 5.8212e-05\n",
      "Epoch 2077/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 100458.6609 - recon_loss: 3.3927e-04 - KL loss: 341.3004 - beta: 5.8212e-05 - val_val_loss: 99405.2734 - val_val_recon_loss: 3.3568e-04 - val_val_KL loss: 344.7122 - val_beta: 5.8212e-05\n",
      "Epoch 2078/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 98533.4833 - recon_loss: 3.3272e-04 - KL loss: 346.4122 - beta: 5.8212e-05 - val_val_loss: 99841.8438 - val_val_recon_loss: 3.3716e-04 - val_val_KL loss: 346.8337 - val_beta: 5.8212e-05\n",
      "Epoch 2079/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 98222.5516 - recon_loss: 3.3166e-04 - KL loss: 349.3576 - beta: 5.8212e-05 - val_val_loss: 98394.5078 - val_val_recon_loss: 3.3224e-04 - val_val_KL loss: 351.3491 - val_beta: 5.8212e-05\n",
      "Epoch 2080/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 97841.6462 - recon_loss: 3.3036e-04 - KL loss: 353.0097 - beta: 5.8212e-05 - val_val_loss: 99898.2266 - val_val_recon_loss: 3.3732e-04 - val_val_KL loss: 355.8976 - val_beta: 5.8212e-05\n",
      "Epoch 2081/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 98214.5719 - recon_loss: 3.3163e-04 - KL loss: 349.9220 - beta: 5.8212e-05 - val_val_loss: 100141.5781 - val_val_recon_loss: 3.3816e-04 - val_val_KL loss: 350.5659 - val_beta: 5.8212e-05\n",
      "Epoch 2082/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 98105.5182 - recon_loss: 3.3125e-04 - KL loss: 352.7501 - beta: 5.8212e-05 - val_val_loss: 97863.4766 - val_val_recon_loss: 3.3042e-04 - val_val_KL loss: 355.4557 - val_beta: 5.8212e-05\n",
      "Epoch 2083/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96845.3386 - recon_loss: 3.2697e-04 - KL loss: 355.1516 - beta: 5.8212e-05 - val_val_loss: 98102.4922 - val_val_recon_loss: 3.3123e-04 - val_val_KL loss: 357.6984 - val_beta: 5.8212e-05\n",
      "Epoch 2084/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95757.7939 - recon_loss: 3.2328e-04 - KL loss: 357.9194 - beta: 5.8212e-05 - val_val_loss: 97901.5781 - val_val_recon_loss: 3.3053e-04 - val_val_KL loss: 363.0564 - val_beta: 5.8212e-05\n",
      "Epoch 2085/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96241.9193 - recon_loss: 3.2491e-04 - KL loss: 360.0428 - beta: 5.8212e-05 - val_val_loss: 97864.0078 - val_val_recon_loss: 3.3041e-04 - val_val_KL loss: 359.5671 - val_beta: 5.8212e-05\n",
      "Epoch 2086/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95588.4044 - recon_loss: 3.2270e-04 - KL loss: 359.9775 - beta: 5.8212e-05 - val_val_loss: 98231.1484 - val_val_recon_loss: 3.3166e-04 - val_val_KL loss: 358.3243 - val_beta: 5.8212e-05\n",
      "Epoch 2087/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 98181.9058 - recon_loss: 3.3149e-04 - KL loss: 360.7615 - beta: 5.8212e-05\n",
      "Epoch 02087: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 98182.0149 - recon_loss: 3.3149e-04 - KL loss: 360.7610 - beta: 5.8212e-05 - val_val_loss: 99801.8516 - val_val_recon_loss: 3.3699e-04 - val_val_KL loss: 355.2203 - val_beta: 5.8212e-05\n",
      "Epoch 2088/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96895.2116 - recon_loss: 3.2714e-04 - KL loss: 355.0887 - beta: 5.8212e-05 - val_val_loss: 97163.9531 - val_val_recon_loss: 3.2805e-04 - val_val_KL loss: 357.4428 - val_beta: 5.8212e-05\n",
      "Epoch 2089/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 96117.5057 - recon_loss: 3.2450e-04 - KL loss: 356.5558 - beta: 5.8212e-05 - val_val_loss: 97031.2109 - val_val_recon_loss: 3.2759e-04 - val_val_KL loss: 360.8096 - val_beta: 5.8212e-05\n",
      "Epoch 2090/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95080.2107 - recon_loss: 3.2097e-04 - KL loss: 360.6213 - beta: 5.8212e-05 - val_val_loss: 96506.7891 - val_val_recon_loss: 3.2581e-04 - val_val_KL loss: 359.1034 - val_beta: 5.8212e-05\n",
      "Epoch 2091/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95351.1382 - recon_loss: 3.2190e-04 - KL loss: 359.4056 - beta: 5.8212e-05 - val_val_loss: 96822.2109 - val_val_recon_loss: 3.2688e-04 - val_val_KL loss: 359.6653 - val_beta: 5.8212e-05\n",
      "Epoch 2092/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95664.7272 - recon_loss: 3.2295e-04 - KL loss: 361.3065 - beta: 5.8212e-05 - val_val_loss: 96564.1484 - val_val_recon_loss: 3.2601e-04 - val_val_KL loss: 358.1995 - val_beta: 5.8212e-05\n",
      "Epoch 2093/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94379.0335 - recon_loss: 3.1860e-04 - KL loss: 358.7517 - beta: 5.8212e-05 - val_val_loss: 96222.3125 - val_val_recon_loss: 3.2484e-04 - val_val_KL loss: 362.3177 - val_beta: 5.8212e-05\n",
      "Epoch 2094/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94213.8730 - recon_loss: 3.1804e-04 - KL loss: 359.6091 - beta: 5.8212e-05 - val_val_loss: 96293.0938 - val_val_recon_loss: 3.2508e-04 - val_val_KL loss: 362.2961 - val_beta: 5.8212e-05\n",
      "Epoch 2095/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94120.7945 - recon_loss: 3.1772e-04 - KL loss: 362.1273 - beta: 5.8212e-05 - val_val_loss: 95912.5000 - val_val_recon_loss: 3.2379e-04 - val_val_KL loss: 363.2479 - val_beta: 5.8212e-05\n",
      "Epoch 2096/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93972.8679 - recon_loss: 3.1721e-04 - KL loss: 364.0043 - beta: 5.8212e-05 - val_val_loss: 95745.7891 - val_val_recon_loss: 3.2321e-04 - val_val_KL loss: 365.3469 - val_beta: 5.8212e-05\n",
      "Epoch 2097/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94568.5972 - recon_loss: 3.1922e-04 - KL loss: 365.5043 - beta: 5.8212e-05 - val_val_loss: 95653.6719 - val_val_recon_loss: 3.2290e-04 - val_val_KL loss: 366.3509 - val_beta: 5.8212e-05\n",
      "Epoch 2098/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93961.7348 - recon_loss: 3.1717e-04 - KL loss: 366.3301 - beta: 5.8212e-05 - val_val_loss: 95531.7188 - val_val_recon_loss: 3.2249e-04 - val_val_KL loss: 366.1293 - val_beta: 5.8212e-05\n",
      "Epoch 2099/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93968.3360 - recon_loss: 3.1718e-04 - KL loss: 367.2312 - beta: 5.8212e-05 - val_val_loss: 95558.2109 - val_val_recon_loss: 3.2256e-04 - val_val_KL loss: 371.7963 - val_beta: 5.8212e-05\n",
      "Epoch 2100/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94154.0719 - recon_loss: 3.1781e-04 - KL loss: 368.3839 - beta: 5.8212e-05 - val_val_loss: 95374.4922 - val_val_recon_loss: 3.2194e-04 - val_val_KL loss: 369.2604 - val_beta: 5.8212e-05\n",
      "Epoch 2101/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 93879.4662 - recon_loss: 3.1688e-04 - KL loss: 368.1820 - beta: 5.8212e-05 - val_val_loss: 95500.3906 - val_val_recon_loss: 3.2238e-04 - val_val_KL loss: 366.4634 - val_beta: 5.8212e-05\n",
      "Epoch 2102/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 93643.2865 - recon_loss: 3.1608e-04 - KL loss: 367.4324 - beta: 5.8212e-05 - val_val_loss: 95376.8516 - val_val_recon_loss: 3.2196e-04 - val_val_KL loss: 367.1841 - val_beta: 5.8212e-05\n",
      "Epoch 2103/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93894.8141 - recon_loss: 3.1694e-04 - KL loss: 367.0508 - beta: 5.8212e-05 - val_val_loss: 95643.7578 - val_val_recon_loss: 3.2287e-04 - val_val_KL loss: 364.1941 - val_beta: 5.8212e-05\n",
      "Epoch 2104/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 93937.7119 - recon_loss: 3.1709e-04 - KL loss: 365.5708 - beta: 5.8212e-05 - val_val_loss: 95338.1797 - val_val_recon_loss: 3.2183e-04 - val_val_KL loss: 365.2115 - val_beta: 5.8212e-05\n",
      "Epoch 2105/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 94415.6579 - recon_loss: 3.1871e-04 - KL loss: 364.6873 - beta: 5.8212e-05 - val_val_loss: 95644.6172 - val_val_recon_loss: 3.2287e-04 - val_val_KL loss: 365.0780 - val_beta: 5.8212e-05\n",
      "Epoch 2106/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94287.5554 - recon_loss: 3.1827e-04 - KL loss: 365.1880 - beta: 5.8212e-05 - val_val_loss: 95548.2969 - val_val_recon_loss: 3.2255e-04 - val_val_KL loss: 364.2859 - val_beta: 5.8212e-05\n",
      "Epoch 2107/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 93873.7091 - recon_loss: 3.1687e-04 - KL loss: 365.2401 - beta: 5.8212e-05 - val_val_loss: 95444.2891 - val_val_recon_loss: 3.2219e-04 - val_val_KL loss: 366.5944 - val_beta: 5.8212e-05\n",
      "Epoch 2108/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93718.7757 - recon_loss: 3.1635e-04 - KL loss: 365.4692 - beta: 5.8212e-05 - val_val_loss: 96129.1562 - val_val_recon_loss: 3.2451e-04 - val_val_KL loss: 366.3144 - val_beta: 5.8212e-05\n",
      "Epoch 2109/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 93978.0038 - recon_loss: 3.1722e-04 - KL loss: 365.2729 - beta: 5.8212e-05\n",
      "Epoch 02109: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93978.5206 - recon_loss: 3.1723e-04 - KL loss: 365.2728 - beta: 5.8212e-05 - val_val_loss: 96864.3672 - val_val_recon_loss: 3.2702e-04 - val_val_KL loss: 362.2935 - val_beta: 5.8212e-05\n",
      "Epoch 2110/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 94807.9126 - recon_loss: 3.2004e-04 - KL loss: 363.0920 - beta: 5.8212e-05 - val_val_loss: 96303.4375 - val_val_recon_loss: 3.2511e-04 - val_val_KL loss: 362.9567 - val_beta: 5.8212e-05\n",
      "Epoch 2111/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93434.1252 - recon_loss: 3.1539e-04 - KL loss: 361.8322 - beta: 5.8212e-05 - val_val_loss: 95727.7891 - val_val_recon_loss: 3.2315e-04 - val_val_KL loss: 365.0109 - val_beta: 5.8212e-05\n",
      "Epoch 2112/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 93621.0426 - recon_loss: 3.1602e-04 - KL loss: 364.6498 - beta: 5.8212e-05 - val_val_loss: 95841.4375 - val_val_recon_loss: 3.2354e-04 - val_val_KL loss: 365.0339 - val_beta: 5.8212e-05\n",
      "Epoch 2113/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93951.9629 - recon_loss: 3.1714e-04 - KL loss: 365.3975 - beta: 5.8212e-05 - val_val_loss: 95515.9062 - val_val_recon_loss: 3.2243e-04 - val_val_KL loss: 366.5185 - val_beta: 5.8212e-05\n",
      "Epoch 2114/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 93452.7316 - recon_loss: 3.1544e-04 - KL loss: 366.2046 - beta: 5.8212e-05\n",
      "Epoch 02114: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 93452.6945 - recon_loss: 3.1544e-04 - KL loss: 366.2043 - beta: 5.8212e-05 - val_val_loss: 95923.7812 - val_val_recon_loss: 3.2381e-04 - val_val_KL loss: 366.0274 - val_beta: 5.8212e-05\n",
      "Epoch 2114/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 359066.6520 - recon_loss: 3.7564e-04 - KL loss: 353.0956 - beta: 3.2360e-05 - val_val_loss: 346066.2500 - val_val_recon_loss: 3.6200e-04 - val_val_KL loss: 379.4404 - val_beta: 3.2360e-05\n",
      "Epoch 2115/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 335783.7946 - recon_loss: 3.5122e-04 - KL loss: 386.6663 - beta: 3.2360e-05 - val_val_loss: 325084.6875 - val_val_recon_loss: 3.4000e-04 - val_val_KL loss: 407.1968 - val_beta: 3.2360e-05\n",
      "Epoch 2116/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 322015.2351 - recon_loss: 3.3678e-04 - KL loss: 411.1287 - beta: 3.2360e-05 - val_val_loss: 327860.9062 - val_val_recon_loss: 3.4290e-04 - val_val_KL loss: 409.5703 - val_beta: 3.2360e-05\n",
      "Epoch 2117/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 329984.9904 - recon_loss: 3.4512e-04 - KL loss: 413.2307 - beta: 3.2360e-05 - val_val_loss: 332707.9062 - val_val_recon_loss: 3.4798e-04 - val_val_KL loss: 408.0019 - val_beta: 3.2360e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2118/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 329646.6682 - recon_loss: 3.4476e-04 - KL loss: 415.2349 - beta: 3.2360e-05 - val_val_loss: 328472.2812 - val_val_recon_loss: 3.4352e-04 - val_val_KL loss: 431.0194 - val_beta: 3.2360e-05\n",
      "Epoch 2119/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 326351.4215 - recon_loss: 3.4129e-04 - KL loss: 434.4423 - beta: 3.2360e-05 - val_val_loss: 341316.8438 - val_val_recon_loss: 3.5696e-04 - val_val_KL loss: 435.2529 - val_beta: 3.2360e-05\n",
      "Epoch 2120/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 350956.3407 - recon_loss: 3.6706e-04 - KL loss: 435.5558 - beta: 3.2360e-05\n",
      "Epoch 02120: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 350951.4731 - recon_loss: 3.6705e-04 - KL loss: 435.5540 - beta: 3.2360e-05 - val_val_loss: 333202.9062 - val_val_recon_loss: 3.4848e-04 - val_val_KL loss: 420.1148 - val_beta: 3.2360e-05\n",
      "Epoch 2121/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 319534.5661 - recon_loss: 3.3416e-04 - KL loss: 425.5896 - beta: 3.2360e-05 - val_val_loss: 317853.5938 - val_val_recon_loss: 3.3239e-04 - val_val_KL loss: 437.0301 - val_beta: 3.2360e-05\n",
      "Epoch 2122/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 315846.4285 - recon_loss: 3.3029e-04 - KL loss: 438.4383 - beta: 3.2360e-05 - val_val_loss: 318231.6250 - val_val_recon_loss: 3.3278e-04 - val_val_KL loss: 443.1169 - val_beta: 3.2360e-05\n",
      "Epoch 2123/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 314334.7643 - recon_loss: 3.2870e-04 - KL loss: 443.6060 - beta: 3.2360e-05 - val_val_loss: 319442.5312 - val_val_recon_loss: 3.3405e-04 - val_val_KL loss: 443.5701 - val_beta: 3.2360e-05\n",
      "Epoch 2124/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 316917.0635 - recon_loss: 3.3140e-04 - KL loss: 446.3227 - beta: 3.2360e-05 - val_val_loss: 315125.4062 - val_val_recon_loss: 3.2952e-04 - val_val_KL loss: 447.5217 - val_beta: 3.2360e-05\n",
      "Epoch 2125/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 312534.1966 - recon_loss: 3.2681e-04 - KL loss: 448.0160 - beta: 3.2360e-05 - val_val_loss: 312835.3438 - val_val_recon_loss: 3.2712e-04 - val_val_KL loss: 454.2769 - val_beta: 3.2360e-05\n",
      "Epoch 2126/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 309362.9093 - recon_loss: 3.2349e-04 - KL loss: 451.0533 - beta: 3.2360e-05 - val_val_loss: 316684.5000 - val_val_recon_loss: 3.3116e-04 - val_val_KL loss: 448.0499 - val_beta: 3.2360e-05\n",
      "Epoch 2127/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 311949.3590 - recon_loss: 3.2619e-04 - KL loss: 450.7587 - beta: 3.2360e-05 - val_val_loss: 313112.5625 - val_val_recon_loss: 3.2741e-04 - val_val_KL loss: 454.9582 - val_beta: 3.2360e-05\n",
      "Epoch 2128/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 309654.1173 - recon_loss: 3.2379e-04 - KL loss: 455.9985 - beta: 3.2360e-05 - val_val_loss: 313726.1875 - val_val_recon_loss: 3.2805e-04 - val_val_KL loss: 458.6643 - val_beta: 3.2360e-05\n",
      "Epoch 2129/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308700.1123 - recon_loss: 3.2279e-04 - KL loss: 455.9555 - beta: 3.2360e-05 - val_val_loss: 313896.6875 - val_val_recon_loss: 3.2823e-04 - val_val_KL loss: 454.0961 - val_beta: 3.2360e-05\n",
      "Epoch 2130/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 304946.6540 - recon_loss: 3.1886e-04 - KL loss: 454.4910 - beta: 3.2360e-05 - val_val_loss: 311579.3125 - val_val_recon_loss: 3.2580e-04 - val_val_KL loss: 457.8214 - val_beta: 3.2360e-05\n",
      "Epoch 2131/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308059.3123 - recon_loss: 3.2212e-04 - KL loss: 456.2400 - beta: 3.2360e-05 - val_val_loss: 312390.6875 - val_val_recon_loss: 3.2665e-04 - val_val_KL loss: 453.7733 - val_beta: 3.2360e-05\n",
      "Epoch 2132/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306893.2302 - recon_loss: 3.2090e-04 - KL loss: 454.2789 - beta: 3.2360e-05 - val_val_loss: 309820.9688 - val_val_recon_loss: 3.2396e-04 - val_val_KL loss: 455.8039 - val_beta: 3.2360e-05\n",
      "Epoch 2133/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 308477.2076 - recon_loss: 3.2255e-04 - KL loss: 458.5766 - beta: 3.2360e-05 - val_val_loss: 312890.4062 - val_val_recon_loss: 3.2717e-04 - val_val_KL loss: 458.4325 - val_beta: 3.2360e-05\n",
      "Epoch 2134/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 309485.2606 - recon_loss: 3.2361e-04 - KL loss: 459.1542 - beta: 3.2360e-05 - val_val_loss: 313361.7188 - val_val_recon_loss: 3.2767e-04 - val_val_KL loss: 457.4814 - val_beta: 3.2360e-05\n",
      "Epoch 2135/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 306699.9852 - recon_loss: 3.2069e-04 - KL loss: 458.1481 - beta: 3.2360e-05 - val_val_loss: 312307.0625 - val_val_recon_loss: 3.2655e-04 - val_val_KL loss: 466.4692 - val_beta: 3.2360e-05\n",
      "Epoch 2136/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 304557.8867 - recon_loss: 3.1844e-04 - KL loss: 462.1513 - beta: 3.2360e-05 - val_val_loss: 311292.2812 - val_val_recon_loss: 3.2549e-04 - val_val_KL loss: 462.6033 - val_beta: 3.2360e-05\n",
      "Epoch 2137/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 305650.1842 - recon_loss: 3.1959e-04 - KL loss: 460.7531 - beta: 3.2360e-05 - val_val_loss: 308733.1562 - val_val_recon_loss: 3.2282e-04 - val_val_KL loss: 461.6325 - val_beta: 3.2360e-05\n",
      "Epoch 2138/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 308831.3779 - recon_loss: 3.2292e-04 - KL loss: 460.4637 - beta: 3.2360e-05 - val_val_loss: 308103.8125 - val_val_recon_loss: 3.2216e-04 - val_val_KL loss: 460.0796 - val_beta: 3.2360e-05\n",
      "Epoch 2139/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 306930.3075 - recon_loss: 3.2093e-04 - KL loss: 460.9153 - beta: 3.2360e-05 - val_val_loss: 314656.8750 - val_val_recon_loss: 3.2902e-04 - val_val_KL loss: 464.6577 - val_beta: 3.2360e-05\n",
      "Epoch 2140/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 309170.6118 - recon_loss: 3.2327e-04 - KL loss: 464.7685 - beta: 3.2360e-05 - val_val_loss: 317187.1250 - val_val_recon_loss: 3.3166e-04 - val_val_KL loss: 470.9457 - val_beta: 3.2360e-05\n",
      "Epoch 2141/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 308678.4134 - recon_loss: 3.2275e-04 - KL loss: 468.0801 - beta: 3.2360e-05 - val_val_loss: 311541.6250 - val_val_recon_loss: 3.2575e-04 - val_val_KL loss: 468.1915 - val_beta: 3.2360e-05\n",
      "Epoch 2142/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 309435.5923 - recon_loss: 3.2354e-04 - KL loss: 468.8155 - beta: 3.2360e-05 - val_val_loss: 307110.0625 - val_val_recon_loss: 3.2111e-04 - val_val_KL loss: 470.5109 - val_beta: 3.2360e-05\n",
      "Epoch 2143/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 302322.0251 - recon_loss: 3.1609e-04 - KL loss: 470.2942 - beta: 3.2360e-05 - val_val_loss: 307346.8125 - val_val_recon_loss: 3.2135e-04 - val_val_KL loss: 471.8997 - val_beta: 3.2360e-05\n",
      "Epoch 2144/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 296519.8915 - recon_loss: 3.1001e-04 - KL loss: 472.2515 - beta: 3.2360e-05 - val_val_loss: 305886.4062 - val_val_recon_loss: 3.1982e-04 - val_val_KL loss: 474.8055 - val_beta: 3.2360e-05\n",
      "Epoch 2145/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 299130.8713 - recon_loss: 3.1275e-04 - KL loss: 471.8163 - beta: 3.2360e-05 - val_val_loss: 304282.6562 - val_val_recon_loss: 3.1814e-04 - val_val_KL loss: 471.1151 - val_beta: 3.2360e-05\n",
      "Epoch 2146/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 302804.2816 - recon_loss: 3.1660e-04 - KL loss: 472.3894 - beta: 3.2360e-05 - val_val_loss: 303944.4688 - val_val_recon_loss: 3.1779e-04 - val_val_KL loss: 470.3246 - val_beta: 3.2360e-05\n",
      "Epoch 2147/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 300034.0145 - recon_loss: 3.1370e-04 - KL loss: 468.5246 - beta: 3.2360e-05 - val_val_loss: 306491.4062 - val_val_recon_loss: 3.2046e-04 - val_val_KL loss: 467.8434 - val_beta: 3.2360e-05\n",
      "Epoch 2148/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 304325.5089 - recon_loss: 3.1819e-04 - KL loss: 469.1834 - beta: 3.2360e-05 - val_val_loss: 303078.4062 - val_val_recon_loss: 3.1688e-04 - val_val_KL loss: 476.2138 - val_beta: 3.2360e-05\n",
      "Epoch 2149/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 300217.4650 - recon_loss: 3.1388e-04 - KL loss: 476.1687 - beta: 3.2360e-05 - val_val_loss: 303820.5938 - val_val_recon_loss: 3.1766e-04 - val_val_KL loss: 474.5779 - val_beta: 3.2360e-05\n",
      "Epoch 2150/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 298283.6833 - recon_loss: 3.1186e-04 - KL loss: 476.1240 - beta: 3.2360e-05 - val_val_loss: 304747.0312 - val_val_recon_loss: 3.1863e-04 - val_val_KL loss: 475.5521 - val_beta: 3.2360e-05\n",
      "Epoch 2151/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 297538.4938 - recon_loss: 3.1108e-04 - KL loss: 476.2750 - beta: 3.2360e-05 - val_val_loss: 301440.6250 - val_val_recon_loss: 3.1516e-04 - val_val_KL loss: 482.5945 - val_beta: 3.2360e-05\n",
      "Epoch 2152/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 299427.6125 - recon_loss: 3.1305e-04 - KL loss: 481.2788 - beta: 3.2360e-05 - val_val_loss: 301448.8125 - val_val_recon_loss: 3.1517e-04 - val_val_KL loss: 480.4847 - val_beta: 3.2360e-05\n",
      "Epoch 2153/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 300971.4201 - recon_loss: 3.1467e-04 - KL loss: 482.6352 - beta: 3.2360e-05 - val_val_loss: 301102.1875 - val_val_recon_loss: 3.1480e-04 - val_val_KL loss: 483.6618 - val_beta: 3.2360e-05\n",
      "Epoch 2154/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 297233.3657 - recon_loss: 3.1075e-04 - KL loss: 484.0570 - beta: 3.2360e-05 - val_val_loss: 306558.4062 - val_val_recon_loss: 3.2050e-04 - val_val_KL loss: 495.8857 - val_beta: 3.2360e-05\n",
      "Epoch 2155/10000\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 302912.6332 - recon_loss: 3.1669e-04 - KL loss: 493.3605 - beta: 3.2360e-05 - val_val_loss: 302358.8125 - val_val_recon_loss: 3.1611e-04 - val_val_KL loss: 487.3717 - val_beta: 3.2360e-05\n",
      "Epoch 2156/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 300680.8961 - recon_loss: 3.1435e-04 - KL loss: 490.1477 - beta: 3.2360e-05 - val_val_loss: 301089.3125 - val_val_recon_loss: 3.1478e-04 - val_val_KL loss: 490.3997 - val_beta: 3.2360e-05\n",
      "Epoch 2157/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 300208.0649 - recon_loss: 3.1385e-04 - KL loss: 493.7203 - beta: 3.2360e-05 - val_val_loss: 301933.6875 - val_val_recon_loss: 3.1566e-04 - val_val_KL loss: 491.9537 - val_beta: 3.2360e-05\n",
      "Epoch 2158/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 298797.1099 - recon_loss: 3.1238e-04 - KL loss: 490.9947 - beta: 3.2360e-05 - val_val_loss: 304201.0312 - val_val_recon_loss: 3.1805e-04 - val_val_KL loss: 479.9368 - val_beta: 3.2360e-05\n",
      "Epoch 2159/10000\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 297846.6230 - recon_loss: 3.1139e-04 - KL loss: 481.3560 - beta: 3.2360e-05 - val_val_loss: 302382.3750 - val_val_recon_loss: 3.1614e-04 - val_val_KL loss: 484.9713 - val_beta: 3.2360e-05\n",
      "Epoch 2160/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 295393.3522 - recon_loss: 3.0882e-04 - KL loss: 484.0246 - beta: 3.2360e-05 - val_val_loss: 298825.6875 - val_val_recon_loss: 3.1242e-04 - val_val_KL loss: 479.1363 - val_beta: 3.2360e-05\n",
      "Epoch 2161/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 295673.0113 - recon_loss: 3.0912e-04 - KL loss: 480.0637 - beta: 3.2360e-05 - val_val_loss: 300141.3125 - val_val_recon_loss: 3.1380e-04 - val_val_KL loss: 479.4684 - val_beta: 3.2360e-05\n",
      "Epoch 2162/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 295853.6452 - recon_loss: 3.0931e-04 - KL loss: 479.9688 - beta: 3.2360e-05 - val_val_loss: 296546.8125 - val_val_recon_loss: 3.1003e-04 - val_val_KL loss: 480.8022 - val_beta: 3.2360e-05\n",
      "Epoch 2163/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 296953.8911 - recon_loss: 3.1046e-04 - KL loss: 483.8659 - beta: 3.2360e-05 - val_val_loss: 301405.1562 - val_val_recon_loss: 3.1512e-04 - val_val_KL loss: 484.7676 - val_beta: 3.2360e-059478 - reco\n",
      "Epoch 2164/10000\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 297385.4169 - recon_loss: 3.1091e-04 - KL loss: 487.1901 - beta: 3.2360e-05 - val_val_loss: 300322.5938 - val_val_recon_loss: 3.1398e-04 - val_val_KL loss: 489.8914 - val_beta: 3.2360e-05\n",
      "Epoch 2165/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 299075.8569 - recon_loss: 3.1268e-04 - KL loss: 486.9270 - beta: 3.2360e-05 - val_val_loss: 298036.2188 - val_val_recon_loss: 3.1159e-04 - val_val_KL loss: 485.6565 - val_beta: 3.2360e-05\n",
      "Epoch 2166/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 293441.0687 - recon_loss: 3.0678e-04 - KL loss: 485.6719 - beta: 3.2360e-05 - val_val_loss: 298010.4062 - val_val_recon_loss: 3.1156e-04 - val_val_KL loss: 485.4921 - val_beta: 3.2360e-05\n",
      "Epoch 2167/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 292210.3645 - recon_loss: 3.0549e-04 - KL loss: 482.9679 - beta: 3.2360e-05 - ETA: 1s - loss: 292200.1254 - recon_loss: 3.0548e-04 - \n",
      "Epoch 02167: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 292211.0094 - recon_loss: 3.0549e-04 - KL loss: 482.9684 - beta: 3.2360e-05 - val_val_loss: 298059.5938 - val_val_recon_loss: 3.1161e-04 - val_val_KL loss: 486.7909 - val_beta: 3.2360e-05\n",
      "Epoch 2168/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 292213.5526 - recon_loss: 3.0549e-04 - KL loss: 485.7580 - beta: 3.2360e-05 - val_val_loss: 294679.0000 - val_val_recon_loss: 3.0807e-04 - val_val_KL loss: 484.7550 - val_beta: 3.2360e-05\n",
      "Epoch 2169/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 290992.9162 - recon_loss: 3.0421e-04 - KL loss: 484.9795 - beta: 3.2360e-05 - val_val_loss: 295391.6250 - val_val_recon_loss: 3.0882e-04 - val_val_KL loss: 483.8295 - val_beta: 3.2360e-05\n",
      "Epoch 2170/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 291603.8959 - recon_loss: 3.0486e-04 - KL loss: 483.3558 - beta: 3.2360e-05 - val_val_loss: 294457.5938 - val_val_recon_loss: 3.0784e-04 - val_val_KL loss: 482.9880 - val_beta: 3.2360e-05\n",
      "Epoch 2171/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 289122.4912 - recon_loss: 3.0226e-04 - KL loss: 483.4076 - beta: 3.2360e-05 - val_val_loss: 294480.6562 - val_val_recon_loss: 3.0787e-04 - val_val_KL loss: 484.5836 - val_beta: 3.2360e-05\n",
      "Epoch 2172/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 290063.7177 - recon_loss: 3.0324e-04 - KL loss: 485.0040 - beta: 3.2360e-05 - val_val_loss: 295540.1562 - val_val_recon_loss: 3.0897e-04 - val_val_KL loss: 486.8729 - val_beta: 3.2360e-05\n",
      "Epoch 2173/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 290874.7819 - recon_loss: 3.0409e-04 - KL loss: 486.5911 - beta: 3.2360e-05 - val_val_loss: 294532.1875 - val_val_recon_loss: 3.0792e-04 - val_val_KL loss: 487.8905 - val_beta: 3.2360e-050e-04 - KL\n",
      "Epoch 2174/10000\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 288372.2692 - recon_loss: 3.0147e-04 - KL loss: 488.7951 - beta: 3.2360e-05 - val_val_loss: 293419.3125 - val_val_recon_loss: 3.0675e-04 - val_val_KL loss: 491.2599 - val_beta: 3.2360e-05\n",
      "Epoch 2175/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 289380.3895 - recon_loss: 3.0252e-04 - KL loss: 492.1621 - beta: 3.2360e-05 - val_val_loss: 293825.7500 - val_val_recon_loss: 3.0717e-04 - val_val_KL loss: 494.6841 - val_beta: 3.2360e-05\n",
      "Epoch 2176/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 288598.5086 - recon_loss: 3.0170e-04 - KL loss: 495.5926 - beta: 3.2360e-05 - val_val_loss: 292384.4062 - val_val_recon_loss: 3.0566e-04 - val_val_KL loss: 495.9695 - val_beta: 3.2360e-05\n",
      "Epoch 2177/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 286678.3000 - recon_loss: 2.9968e-04 - KL loss: 495.4441 - beta: 3.2360e-05 - val_val_loss: 292226.7500 - val_val_recon_loss: 3.0549e-04 - val_val_KL loss: 497.3113 - val_beta: 3.2360e-05\n",
      "Epoch 2178/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 288984.5370 - recon_loss: 3.0210e-04 - KL loss: 495.7959 - beta: 3.2360e-05 - val_val_loss: 292829.2188 - val_val_recon_loss: 3.0613e-04 - val_val_KL loss: 495.0693 - val_beta: 3.2360e-05\n",
      "Epoch 2179/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 291378.1209 - recon_loss: 3.0461e-04 - KL loss: 494.2279 - beta: 3.2360e-05 - val_val_loss: 291773.7812 - val_val_recon_loss: 3.0502e-04 - val_val_KL loss: 497.2854 - val_beta: 3.2360e-05\n",
      "Epoch 2180/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 286271.2485 - recon_loss: 2.9926e-04 - KL loss: 496.2737 - beta: 3.2360e-05 - val_val_loss: 293139.0938 - val_val_recon_loss: 3.0645e-04 - val_val_KL loss: 494.5558 - val_beta: 3.2360e-05\n",
      "Epoch 2181/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 288295.7453 - recon_loss: 3.0138e-04 - KL loss: 494.4970 - beta: 3.2360e-05 - val_val_loss: 291766.7188 - val_val_recon_loss: 3.0501e-04 - val_val_KL loss: 494.0688 - val_beta: 3.2360e-05\n",
      "Epoch 2182/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 287557.0258 - recon_loss: 3.0061e-04 - KL loss: 494.1724 - beta: 3.2360e-05 - val_val_loss: 291703.0938 - val_val_recon_loss: 3.0495e-04 - val_val_KL loss: 494.8326 - val_beta: 3.2360e-05\n",
      "Epoch 2183/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 284964.1504 - recon_loss: 2.9789e-04 - KL loss: 494.1779 - beta: 3.2360e-05 - val_val_loss: 291493.4062 - val_val_recon_loss: 3.0473e-04 - val_val_KL loss: 495.1057 - val_beta: 3.2360e-05\n",
      "Epoch 2184/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 284454.1634 - recon_loss: 2.9736e-04 - KL loss: 495.3914 - beta: 3.2360e-05 - val_val_loss: 291237.7500 - val_val_recon_loss: 3.0446e-04 - val_val_KL loss: 496.4085 - val_beta: 3.2360e-05\n",
      "Epoch 2185/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 286822.4270 - recon_loss: 2.9983e-04 - KL loss: 497.8880 - beta: 3.2360e-05 - val_val_loss: 290869.8125 - val_val_recon_loss: 3.0407e-04 - val_val_KL loss: 497.8084 - val_beta: 3.2360e-05\n",
      "Epoch 2186/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 286717.7889 - recon_loss: 2.9972e-04 - KL loss: 496.8231 - beta: 3.2360e-05 - val_val_loss: 292231.2812 - val_val_recon_loss: 3.0550e-04 - val_val_KL loss: 498.5103 - val_beta: 3.2360e-05\n",
      "Epoch 2187/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 287064.8337 - recon_loss: 3.0009e-04 - KL loss: 499.1579 - beta: 3.2360e-05 - val_val_loss: 291135.9688 - val_val_recon_loss: 3.0435e-04 - val_val_KL loss: 500.4780 - val_beta: 3.2360e-05\n",
      "Epoch 2188/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 284124.1080 - recon_loss: 2.9701e-04 - KL loss: 499.8450 - beta: 3.2360e-05 - val_val_loss: 290958.2500 - val_val_recon_loss: 3.0416e-04 - val_val_KL loss: 499.8362 - val_beta: 3.2360e-05\n",
      "Epoch 2189/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 286243.6256 - recon_loss: 2.9922e-04 - KL loss: 500.1668 - beta: 3.2360e-05 - val_val_loss: 291365.9062 - val_val_recon_loss: 3.0459e-04 - val_val_KL loss: 499.8527 - val_beta: 3.2360e-05\n",
      "Epoch 2190/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 283334.2321 - recon_loss: 2.9618e-04 - KL loss: 499.9674 - beta: 3.2360e-05 - val_val_loss: 290432.7500 - val_val_recon_loss: 3.0361e-04 - val_val_KL loss: 500.5216 - val_beta: 3.2360e-05\n",
      "Epoch 2191/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 285459.0844 - recon_loss: 2.9840e-04 - KL loss: 500.8144 - beta: 3.2360e-05 - val_val_loss: 290684.3750 - val_val_recon_loss: 3.0387e-04 - val_val_KL loss: 501.4996 - val_beta: 3.2360e-05\n",
      "Epoch 2192/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 287435.8330 - recon_loss: 3.0047e-04 - KL loss: 502.3549 - beta: 3.2360e-05 - val_val_loss: 290150.0938 - val_val_recon_loss: 3.0331e-04 - val_val_KL loss: 501.9753 - val_beta: 3.2360e-05\n",
      "Epoch 2193/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 286798.6933 - recon_loss: 2.9980e-04 - KL loss: 502.4962 - beta: 3.2360e-05 - val_val_loss: 291386.5312 - val_val_recon_loss: 3.0461e-04 - val_val_KL loss: 504.6208 - val_beta: 3.2360e-05\n",
      "Epoch 2194/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 284237.6810 - recon_loss: 2.9712e-04 - KL loss: 504.9273 - beta: 3.2360e-05 - val_val_loss: 289771.4062 - val_val_recon_loss: 3.0291e-04 - val_val_KL loss: 505.9958 - val_beta: 3.2360e-05\n",
      "Epoch 2195/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 283736.0175 - recon_loss: 2.9659e-04 - KL loss: 504.6351 - beta: 3.2360e-05 - val_val_loss: 289506.4062 - val_val_recon_loss: 3.0264e-04 - val_val_KL loss: 503.4158 - val_beta: 3.2360e-05\n",
      "Epoch 2196/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 285557.0637 - recon_loss: 2.9850e-04 - KL loss: 504.0519 - beta: 3.2360e-05 - val_val_loss: 290233.2812 - val_val_recon_loss: 3.0340e-04 - val_val_KL loss: 501.1299 - val_beta: 3.2360e-05\n",
      "Epoch 2197/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 285132.0537 - recon_loss: 2.9806e-04 - KL loss: 501.2854 - beta: 3.2360e-05 - val_val_loss: 290372.6250 - val_val_recon_loss: 3.0355e-04 - val_val_KL loss: 500.4880 - val_beta: 3.2360e-05\n",
      "Epoch 2198/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 283386.6254 - recon_loss: 2.9623e-04 - KL loss: 500.8186 - beta: 3.2360e-05 - val_val_loss: 289732.1250 - val_val_recon_loss: 3.0288e-04 - val_val_KL loss: 500.2059 - val_beta: 3.2360e-05\n",
      "Epoch 2199/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 285839.3438 - recon_loss: 2.9880e-04 - KL loss: 499.1089 - beta: 3.2360e-05 - val_val_loss: 290363.7500 - val_val_recon_loss: 3.0354e-04 - val_val_KL loss: 496.4050 - val_beta: 3.2360e-05\n",
      "Epoch 2200/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 284335.0113 - recon_loss: 2.9723e-04 - KL loss: 496.7789 - beta: 3.2360e-05\n",
      "Epoch 02200: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 284335.3235 - recon_loss: 2.9723e-04 - KL loss: 496.7783 - beta: 3.2360e-05 - val_val_loss: 291152.0938 - val_val_recon_loss: 3.0437e-04 - val_val_KL loss: 495.9653 - val_beta: 3.2360e-05\n",
      "Epoch 2201/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 284475.6268 - recon_loss: 2.9738e-04 - KL loss: 496.6199 - beta: 3.2360e-05 - val_val_loss: 290532.5312 - val_val_recon_loss: 3.0372e-04 - val_val_KL loss: 495.6200 - val_beta: 3.2360e-05\n",
      "Epoch 2202/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 282923.6450 - recon_loss: 2.9575e-04 - KL loss: 495.8852 - beta: 3.2360e-05 - val_val_loss: 290492.4062 - val_val_recon_loss: 3.0368e-04 - val_val_KL loss: 496.1338 - val_beta: 3.2360e-05\n",
      "Epoch 2203/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 283592.8436 - recon_loss: 2.9645e-04 - KL loss: 495.7974 - beta: 3.2360e-05 - val_val_loss: 290217.9688 - val_val_recon_loss: 3.0339e-04 - val_val_KL loss: 497.0466 - val_beta: 3.2360e-05\n",
      "Epoch 2204/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 282864.9501 - recon_loss: 2.9569e-04 - KL loss: 497.3916 - beta: 3.2360e-05 - val_val_loss: 289969.9375 - val_val_recon_loss: 3.0313e-04 - val_val_KL loss: 495.8534 - val_beta: 3.2360e-05\n",
      "Epoch 2205/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 283872.8277 - recon_loss: 2.9675e-04 - KL loss: 495.9079 - beta: 3.2360e-05\n",
      "Epoch 02205: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 283872.7446 - recon_loss: 2.9675e-04 - KL loss: 495.9080 - beta: 3.2360e-05 - val_val_loss: 289999.5625 - val_val_recon_loss: 3.0316e-04 - val_val_KL loss: 497.0072 - val_beta: 3.2360e-05\n",
      "Epoch 2205/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1090684.9128 - recon_loss: 3.5279e-04 - KL loss: 488.6679 - beta: 1.7989e-05 - val_val_loss: 1033352.5000 - val_val_recon_loss: 3.3422e-04 - val_val_KL loss: 533.4770 - val_beta: 1.7989e-05\n",
      "Epoch 2206/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 1019621.0883 - recon_loss: 3.2978e-04 - KL loss: 528.1897 - beta: 1.7989e-05 - val_val_loss: 1009307.4375 - val_val_recon_loss: 3.2644e-04 - val_val_KL loss: 540.7252 - val_beta: 1.7989e-05\n",
      "Epoch 2207/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1044578.5947 - recon_loss: 3.3786e-04 - KL loss: 527.9650 - beta: 1.7989e-05 - val_val_loss: 1021977.1875 - val_val_recon_loss: 3.3054e-04 - val_val_KL loss: 529.0657 - val_beta: 1.7989e-05\n",
      "Epoch 2208/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1002986.3747 - recon_loss: 3.2440e-04 - KL loss: 528.4498 - beta: 1.7989e-05 - val_val_loss: 1042929.1250 - val_val_recon_loss: 3.3732e-04 - val_val_KL loss: 529.4520 - val_beta: 1.7989e-05\n",
      "Epoch 2209/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1004210.2532 - recon_loss: 3.2479e-04 - KL loss: 533.2699 - beta: 1.7989e-05 - val_val_loss: 1048495.8125 - val_val_recon_loss: 3.3912e-04 - val_val_KL loss: 553.1553 - val_beta: 1.7989e-05\n",
      "Epoch 2210/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 1008516.3899 - recon_loss: 3.2618e-04 - KL loss: 553.3757 - beta: 1.7989e-05 - val_val_loss: 1039932.5000 - val_val_recon_loss: 3.3634e-04 - val_val_KL loss: 561.9996 - val_beta: 1.7989e-05\n",
      "Epoch 2211/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1013590.6860 - recon_loss: 3.2782e-04 - KL loss: 558.6290 - beta: 1.7989e-05 - val_val_loss: 983016.6250 - val_val_recon_loss: 3.1792e-04 - val_val_KL loss: 562.5328 - val_beta: 1.7989e-05\n",
      "Epoch 2212/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 996740.1241 - recon_loss: 3.2236e-04 - KL loss: 566.7405 - beta: 1.7989e-05 - val_val_loss: 1003609.6875 - val_val_recon_loss: 3.2459e-04 - val_val_KL loss: 563.0518 - val_beta: 1.7989e-05\n",
      "Epoch 2213/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 985045.6173 - recon_loss: 3.1858e-04 - KL loss: 564.0429 - beta: 1.7989e-05 - val_val_loss: 987941.9375 - val_val_recon_loss: 3.1952e-04 - val_val_KL loss: 558.8907 - val_beta: 1.7989e-05\n",
      "Epoch 2214/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 995340.8605 - recon_loss: 3.2191e-04 - KL loss: 564.1654 - beta: 1.7989e-05 - val_val_loss: 1002543.4375 - val_val_recon_loss: 3.2424e-04 - val_val_KL loss: 573.0952 - val_beta: 1.7989e-05\n",
      "Epoch 2215/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 1015710.3038 - recon_loss: 3.2850e-04 - KL loss: 566.5831 - beta: 1.7989e-05 - val_val_loss: 1008812.6250 - val_val_recon_loss: 3.2627e-04 - val_val_KL loss: 574.8701 - val_beta: 1.7989e-05\n",
      "Epoch 2216/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1003302.8702 - recon_loss: 3.2448e-04 - KL loss: 574.8552 - beta: 1.7989e-05\n",
      "Epoch 02216: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 1003306.6139 - recon_loss: 3.2449e-04 - KL loss: 574.8562 - beta: 1.7989e-05 - val_val_loss: 992789.5000 - val_val_recon_loss: 3.2108e-04 - val_val_KL loss: 582.9706 - val_beta: 1.7989e-05\n",
      "Epoch 2217/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 952699.2065 - recon_loss: 3.0811e-04 - KL loss: 584.6639 - beta: 1.7989e-05 - val_val_loss: 950994.3125 - val_val_recon_loss: 3.0755e-04 - val_val_KL loss: 585.2320 - val_beta: 1.7989e-05\n",
      "Epoch 2218/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 947722.1453 - recon_loss: 3.0649e-04 - KL loss: 587.4998 - beta: 1.7989e-05 - val_val_loss: 953933.8125 - val_val_recon_loss: 3.0850e-04 - val_val_KL loss: 594.0423 - val_beta: 1.7989e-05\n",
      "Epoch 2219/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 951493.0688 - recon_loss: 3.0771e-04 - KL loss: 594.8605 - beta: 1.7989e-05 - val_val_loss: 955169.4375 - val_val_recon_loss: 3.0890e-04 - val_val_KL loss: 594.4808 - val_beta: 1.7989e-05\n",
      "Epoch 2220/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 953074.1742 - recon_loss: 3.0822e-04 - KL loss: 594.3478 - beta: 1.7989e-05 - val_val_loss: 953468.2500 - val_val_recon_loss: 3.0835e-04 - val_val_KL loss: 593.3464 - val_beta: 1.7989e-05\n",
      "Epoch 2221/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 948820.2522 - recon_loss: 3.0685e-04 - KL loss: 595.2399 - beta: 1.7989e-05 - val_val_loss: 947406.9375 - val_val_recon_loss: 3.0639e-04 - val_val_KL loss: 596.5862 - val_beta: 1.7989e-05\n",
      "Epoch 2222/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 949346.8272 - recon_loss: 3.0702e-04 - KL loss: 598.2038 - beta: 1.7989e-05 - val_val_loss: 943431.7500 - val_val_recon_loss: 3.0510e-04 - val_val_KL loss: 603.0574 - val_beta: 1.7989e-05\n",
      "Epoch 2223/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 939447.7182 - recon_loss: 3.0381e-04 - KL loss: 605.4089 - beta: 1.7989e-05 - val_val_loss: 950574.7500 - val_val_recon_loss: 3.0741e-04 - val_val_KL loss: 603.5151 - val_beta: 1.7989e-05\n",
      "Epoch 2224/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 953696.4650 - recon_loss: 3.0842e-04 - KL loss: 613.8319 - beta: 1.7989e-05 - val_val_loss: 956236.3750 - val_val_recon_loss: 3.0924e-04 - val_val_KL loss: 610.6609 - val_beta: 1.7989e-05\n",
      "Epoch 2225/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 949275.9758 - recon_loss: 3.0699e-04 - KL loss: 613.9958 - beta: 1.7989e-05 - val_val_loss: 946964.9375 - val_val_recon_loss: 3.0624e-04 - val_val_KL loss: 608.7277 - val_beta: 1.7989e-05\n",
      "Epoch 2226/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 943826.4063 - recon_loss: 3.0523e-04 - KL loss: 609.2382 - beta: 1.7989e-05 - val_val_loss: 941520.1875 - val_val_recon_loss: 3.0448e-04 - val_val_KL loss: 604.8860 - val_beta: 1.7989e-05\n",
      "Epoch 2227/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 928186.2053 - recon_loss: 3.0017e-04 - KL loss: 603.6678 - beta: 1.7989e-05 - val_val_loss: 938021.3750 - val_val_recon_loss: 3.0335e-04 - val_val_KL loss: 606.3466 - val_beta: 1.7989e-05\n",
      "Epoch 2228/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 921510.3959 - recon_loss: 2.9801e-04 - KL loss: 604.7958 - beta: 1.7989e-05 - val_val_loss: 938168.0000 - val_val_recon_loss: 3.0340e-04 - val_val_KL loss: 604.5085 - val_beta: 1.7989e-05\n",
      "Epoch 2229/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 935805.6502 - recon_loss: 3.0263e-04 - KL loss: 604.7817 - beta: 1.7989e-05 - val_val_loss: 928872.6250 - val_val_recon_loss: 3.0039e-04 - val_val_KL loss: 606.5671 - val_beta: 1.7989e-05\n",
      "Epoch 2230/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 923027.7782 - recon_loss: 2.9849e-04 - KL loss: 612.3331 - beta: 1.7989e-05 - val_val_loss: 944811.5000 - val_val_recon_loss: 3.0554e-04 - val_val_KL loss: 616.0114 - val_beta: 1.7989e-05\n",
      "Epoch 2231/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 931277.3309 - recon_loss: 3.0116e-04 - KL loss: 614.5239 - beta: 1.7989e-05 - val_val_loss: 931505.1250 - val_val_recon_loss: 3.0124e-04 - val_val_KL loss: 610.5760 - val_beta: 1.7989e-05\n",
      "Epoch 2232/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 913876.7624 - recon_loss: 2.9553e-04 - KL loss: 609.6064 - beta: 1.7989e-05 - val_val_loss: 933840.5000 - val_val_recon_loss: 3.0200e-04 - val_val_KL loss: 606.2501 - val_beta: 1.7989e-05\n",
      "Epoch 2233/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 924717.7646 - recon_loss: 2.9904e-04 - KL loss: 609.5976 - beta: 1.7989e-05 - val_val_loss: 930127.1250 - val_val_recon_loss: 3.0079e-04 - val_val_KL loss: 607.1639 - val_beta: 1.7989e-05\n",
      "Epoch 2234/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 923584.0104 - recon_loss: 2.9868e-04 - KL loss: 608.8556 - beta: 1.7989e-05 - val_val_loss: 927909.5000 - val_val_recon_loss: 3.0008e-04 - val_val_KL loss: 609.3643 - val_beta: 1.7989e-05\n",
      "Epoch 2235/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 918239.7140 - recon_loss: 2.9695e-04 - KL loss: 610.3550 - beta: 1.7989e-05 - val_val_loss: 919439.8125 - val_val_recon_loss: 2.9733e-04 - val_val_KL loss: 611.2357 - val_beta: 1.7989e-05\n",
      "Epoch 2236/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 908013.2912 - recon_loss: 2.9364e-04 - KL loss: 610.5666 - beta: 1.7989e-05 - val_val_loss: 918596.5000 - val_val_recon_loss: 2.9706e-04 - val_val_KL loss: 606.7784 - val_beta: 1.7989e-05\n",
      "Epoch 2237/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 915581.3378 - recon_loss: 2.9609e-04 - KL loss: 603.7273 - beta: 1.7989e-05 - val_val_loss: 920839.0625 - val_val_recon_loss: 2.9779e-04 - val_val_KL loss: 604.5983 - val_beta: 1.7989e-05\n",
      "Epoch 2238/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 908150.5225 - recon_loss: 2.9368e-04 - KL loss: 603.7102 - beta: 1.7989e-05 - val_val_loss: 921828.0625 - val_val_recon_loss: 2.9811e-04 - val_val_KL loss: 606.2049 - val_beta: 1.7989e-05\n",
      "Epoch 2239/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 917439.4897 - recon_loss: 2.9669e-04 - KL loss: 603.8341 - beta: 1.7989e-05 - val_val_loss: 919907.6875 - val_val_recon_loss: 2.9749e-04 - val_val_KL loss: 605.9593 - val_beta: 1.7989e-05\n",
      "Epoch 2240/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 909561.9002 - recon_loss: 2.9414e-04 - KL loss: 605.2660 - beta: 1.7989e-05 - val_val_loss: 920512.2500 - val_val_recon_loss: 2.9768e-04 - val_val_KL loss: 605.1206 - val_beta: 1.7989e-05\n",
      "Epoch 2241/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 907468.2742 - recon_loss: 2.9346e-04 - KL loss: 604.6469 - beta: 1.7989e-05\n",
      "Epoch 02241: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 907470.0004 - recon_loss: 2.9346e-04 - KL loss: 604.6460 - beta: 1.7989e-05 - val_val_loss: 919615.6875 - val_val_recon_loss: 2.9739e-04 - val_val_KL loss: 603.0120 - val_beta: 1.7989e-05\n",
      "Epoch 2242/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 885179.1962 - recon_loss: 2.8625e-04 - KL loss: 601.2820 - beta: 1.7989e-05 - val_val_loss: 905900.5000 - val_val_recon_loss: 2.9296e-04 - val_val_KL loss: 603.4515 - val_beta: 1.7989e-05\n",
      "Epoch 2243/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 893602.3232 - recon_loss: 2.8898e-04 - KL loss: 603.7198 - beta: 1.7989e-05 - val_val_loss: 905520.2500 - val_val_recon_loss: 2.9283e-04 - val_val_KL loss: 604.6606 - val_beta: 1.7989e-05\n",
      "Epoch 2244/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 891877.4037 - recon_loss: 2.8842e-04 - KL loss: 603.9590 - beta: 1.7989e-05 - val_val_loss: 905419.8125 - val_val_recon_loss: 2.9280e-04 - val_val_KL loss: 605.4501 - val_beta: 1.7989e-05\n",
      "Epoch 2245/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 895295.5914 - recon_loss: 2.8952e-04 - KL loss: 604.3325 - beta: 1.7989e-05 - val_val_loss: 907949.4375 - val_val_recon_loss: 2.9362e-04 - val_val_KL loss: 607.7219 - val_beta: 1.7989e-05\n",
      "Epoch 2246/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 895001.0576 - recon_loss: 2.8943e-04 - KL loss: 608.0324 - beta: 1.7989e-05 - val_val_loss: 907335.0625 - val_val_recon_loss: 2.9342e-04 - val_val_KL loss: 607.2711 - val_beta: 1.7989e-05\n",
      "Epoch 2247/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 895520.2086 - recon_loss: 2.8959e-04 - KL loss: 607.9294 - beta: 1.7989e-05 - val_val_loss: 907705.7500 - val_val_recon_loss: 2.9354e-04 - val_val_KL loss: 609.5842 - val_beta: 1.7989e-05\n",
      "Epoch 2248/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 900368.7401 - recon_loss: 2.9116e-04 - KL loss: 609.6456 - beta: 1.7989e-05 - val_val_loss: 907093.9375 - val_val_recon_loss: 2.9334e-04 - val_val_KL loss: 608.5615 - val_beta: 1.7989e-05\n",
      "Epoch 2249/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 890869.6713 - recon_loss: 2.8809e-04 - KL loss: 610.2617 - beta: 1.7989e-05\n",
      "Epoch 02249: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 890871.2903 - recon_loss: 2.8809e-04 - KL loss: 610.2618 - beta: 1.7989e-05 - val_val_loss: 907203.1875 - val_val_recon_loss: 2.9337e-04 - val_val_KL loss: 609.7665 - val_beta: 1.7989e-05\n",
      "Epoch 2250/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 882817.8706 - recon_loss: 2.8548e-04 - KL loss: 610.4834 - beta: 1.7989e-05 - val_val_loss: 903687.5000 - val_val_recon_loss: 2.9224e-04 - val_val_KL loss: 609.9137 - val_beta: 1.7989e-05\n",
      "Epoch 2251/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 892869.7930 - recon_loss: 2.8874e-04 - KL loss: 609.9734 - beta: 1.7989e-05 - val_val_loss: 902280.8125 - val_val_recon_loss: 2.9178e-04 - val_val_KL loss: 610.0922 - val_beta: 1.7989e-05\n",
      "Epoch 2252/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 888910.4191 - recon_loss: 2.8745e-04 - KL loss: 611.0091 - beta: 1.7989e-05 - val_val_loss: 901326.6250 - val_val_recon_loss: 2.9147e-04 - val_val_KL loss: 610.6022 - val_beta: 1.7989e-05\n",
      "Epoch 2253/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 890155.4030 - recon_loss: 2.8786e-04 - KL loss: 609.9363 - beta: 1.7989e-05 - val_val_loss: 899942.2500 - val_val_recon_loss: 2.9103e-04 - val_val_KL loss: 610.2921 - val_beta: 1.7989e-05\n",
      "Epoch 2254/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 887316.3976 - recon_loss: 2.8694e-04 - KL loss: 611.0362 - beta: 1.7989e-05 - val_val_loss: 900586.5000 - val_val_recon_loss: 2.9123e-04 - val_val_KL loss: 610.7922 - val_beta: 1.7989e-05\n",
      "Epoch 2255/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 883920.6802 - recon_loss: 2.8584e-04 - KL loss: 610.9898 - beta: 1.7989e-05 - val_val_loss: 901519.2500 - val_val_recon_loss: 2.9154e-04 - val_val_KL loss: 610.9030 - val_beta: 1.7989e-05\n",
      "Epoch 2256/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 891948.0393 - recon_loss: 2.8844e-04 - KL loss: 610.7511 - beta: 1.7989e-05 - val_val_loss: 900902.6250 - val_val_recon_loss: 2.9134e-04 - val_val_KL loss: 611.7466 - val_beta: 1.7989e-05\n",
      "Epoch 2257/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 884873.2982 - recon_loss: 2.8615e-04 - KL loss: 610.3313 - beta: 1.7989e-05 - val_val_loss: 901715.6875 - val_val_recon_loss: 2.9160e-04 - val_val_KL loss: 611.4840 - val_beta: 1.7989e-05\n",
      "Epoch 2258/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 889297.1667 - recon_loss: 2.8758e-04 - KL loss: 612.0259 - beta: 1.7989e-05\n",
      "Epoch 02258: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 889294.6261 - recon_loss: 2.8758e-04 - KL loss: 612.0253 - beta: 1.7989e-05 - val_val_loss: 900191.6875 - val_val_recon_loss: 2.9111e-04 - val_val_KL loss: 611.8738 - val_beta: 1.7989e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2259/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 882412.8659 - recon_loss: 2.8535e-04 - KL loss: 611.7063 - beta: 1.7989e-05 - val_val_loss: 899735.9375 - val_val_recon_loss: 2.9096e-04 - val_val_KL loss: 611.9022 - val_beta: 1.7989e-05\n",
      "Epoch 2260/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 884381.7954 - recon_loss: 2.8599e-04 - KL loss: 610.3818 - beta: 1.7989e-05 - val_val_loss: 899912.7500 - val_val_recon_loss: 2.9101e-04 - val_val_KL loss: 612.3926 - val_beta: 1.7989e-05\n",
      "Epoch 2261/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 886747.4387 - recon_loss: 2.8675e-04 - KL loss: 611.3628 - beta: 1.7989e-05 - val_val_loss: 899546.5000 - val_val_recon_loss: 2.9090e-04 - val_val_KL loss: 612.1264 - val_beta: 1.7989e-05\n",
      "Epoch 2262/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 880006.6916 - recon_loss: 2.8457e-04 - KL loss: 612.2947 - beta: 1.7989e-05 - val_val_loss: 899541.0625 - val_val_recon_loss: 2.9089e-04 - val_val_KL loss: 612.1406 - val_beta: 1.7989e-05\n",
      "Epoch 2263/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 882024.5503 - recon_loss: 2.8523e-04 - KL loss: 612.5431 - beta: 1.7989e-05 - val_val_loss: 899358.6250 - val_val_recon_loss: 2.9084e-04 - val_val_KL loss: 612.1058 - val_beta: 1.7989e-05\n",
      "Epoch 2264/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 878161.9389 - recon_loss: 2.8398e-04 - KL loss: 611.7391 - beta: 1.7989e-05 - val_val_loss: 899121.6250 - val_val_recon_loss: 2.9076e-04 - val_val_KL loss: 612.2088 - val_beta: 1.7989e-05\n",
      "Epoch 2265/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 880395.2635 - recon_loss: 2.8470e-04 - KL loss: 611.7982 - beta: 1.7989e-05 - val_val_loss: 898814.8125 - val_val_recon_loss: 2.9066e-04 - val_val_KL loss: 613.2258 - val_beta: 1.7989e-05\n",
      "Epoch 2266/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 877976.0125 - recon_loss: 2.8392e-04 - KL loss: 612.3995 - beta: 1.7989e-05 - val_val_loss: 898678.6250 - val_val_recon_loss: 2.9062e-04 - val_val_KL loss: 612.3552 - val_beta: 1.7989e-05\n",
      "Epoch 2267/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 894065.7962 - recon_loss: 2.8912e-04 - KL loss: 613.7254 - beta: 1.7989e-05 - val_val_loss: 899792.7500 - val_val_recon_loss: 2.9098e-04 - val_val_KL loss: 612.7365 - val_beta: 1.7989e-05\n",
      "Epoch 2268/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 885059.7617 - recon_loss: 2.8621e-04 - KL loss: 612.2762 - beta: 1.7989e-05 - val_val_loss: 899188.1875 - val_val_recon_loss: 2.9078e-04 - val_val_KL loss: 613.0644 - val_beta: 1.7989e-05\n",
      "Epoch 2269/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 880036.1098 - recon_loss: 2.8458e-04 - KL loss: 612.0495 - beta: 1.7989e-05 - val_val_loss: 898614.6250 - val_val_recon_loss: 2.9059e-04 - val_val_KL loss: 613.1782 - val_beta: 1.7989e-05\n",
      "Epoch 2270/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 881253.8496 - recon_loss: 2.8498e-04 - KL loss: 612.9330 - beta: 1.7989e-05 - val_val_loss: 899258.0000 - val_val_recon_loss: 2.9080e-04 - val_val_KL loss: 613.0161 - val_beta: 1.7989e-05\n",
      "Epoch 2271/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 886654.3210 - recon_loss: 2.8672e-04 - KL loss: 613.5482 - beta: 1.7989e-05 - val_val_loss: 898149.2500 - val_val_recon_loss: 2.9044e-04 - val_val_KL loss: 613.5090 - val_beta: 1.7989e-05\n",
      "Epoch 2272/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 886576.9146 - recon_loss: 2.8670e-04 - KL loss: 612.8332 - beta: 1.7989e-05 - val_val_loss: 899800.6250 - val_val_recon_loss: 2.9098e-04 - val_val_KL loss: 613.3920 - val_beta: 1.7989e-05\n",
      "Epoch 2273/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 882324.2304 - recon_loss: 2.8532e-04 - KL loss: 612.8155 - beta: 1.7989e-05 - val_val_loss: 899319.6250 - val_val_recon_loss: 2.9082e-04 - val_val_KL loss: 613.5240 - val_beta: 1.7989e-05\n",
      "Epoch 2274/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 884895.4500 - recon_loss: 2.8615e-04 - KL loss: 613.4249 - beta: 1.7989e-05 - val_val_loss: 898706.8750 - val_val_recon_loss: 2.9062e-04 - val_val_KL loss: 613.3112 - val_beta: 1.7989e-05\n",
      "Epoch 2275/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 888976.6612 - recon_loss: 2.8748e-04 - KL loss: 613.9163 - beta: 1.7989e-05 - val_val_loss: 898212.1875 - val_val_recon_loss: 2.9046e-04 - val_val_KL loss: 613.3937 - val_beta: 1.7989e-05\n",
      "Epoch 2276/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 880417.2257 - recon_loss: 2.8471e-04 - KL loss: 612.2370 - beta: 1.7989e-05 - val_val_loss: 897951.1250 - val_val_recon_loss: 2.9038e-04 - val_val_KL loss: 613.8203 - val_beta: 1.7989e-05\n",
      "Epoch 2277/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 879363.6677 - recon_loss: 2.8437e-04 - KL loss: 613.0236 - beta: 1.7989e-05 - val_val_loss: 898607.2500 - val_val_recon_loss: 2.9059e-04 - val_val_KL loss: 614.3041 - val_beta: 1.7989e-05\n",
      "Epoch 2278/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 873472.1625 - recon_loss: 2.8246e-04 - KL loss: 613.8167 - beta: 1.7989e-05 - val_val_loss: 898644.7500 - val_val_recon_loss: 2.9060e-04 - val_val_KL loss: 614.5125 - val_beta: 1.7989e-05\n",
      "Epoch 2279/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 891041.6204 - recon_loss: 2.8814e-04 - KL loss: 614.6717 - beta: 1.7989e-05 - val_val_loss: 898791.7500 - val_val_recon_loss: 2.9065e-04 - val_val_KL loss: 614.1768 - val_beta: 1.7989e-05\n",
      "Epoch 2280/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 884006.8167 - recon_loss: 2.8587e-04 - KL loss: 613.9153 - beta: 1.7989e-05 - val_val_loss: 898326.8125 - val_val_recon_loss: 2.9050e-04 - val_val_KL loss: 614.3057 - val_beta: 1.7989e-05\n",
      "Epoch 2281/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 881616.1252 - recon_loss: 2.8509e-04 - KL loss: 613.9495 - beta: 1.7989e-05\n",
      "Epoch 02281: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 881614.6361 - recon_loss: 2.8509e-04 - KL loss: 613.9496 - beta: 1.7989e-05 - val_val_loss: 898452.7500 - val_val_recon_loss: 2.9054e-04 - val_val_KL loss: 614.5393 - val_beta: 1.7989e-05\n",
      "Epoch 2282/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 898146.6053 - recon_loss: 2.9044e-04 - KL loss: 614.5140 - beta: 1.7989e-05 - val_val_loss: 898587.5000 - val_val_recon_loss: 2.9059e-04 - val_val_KL loss: 614.6011 - val_beta: 1.7989e-05\n",
      "Epoch 2283/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 874273.2589 - recon_loss: 2.8272e-04 - KL loss: 614.0492 - beta: 1.7989e-05 - val_val_loss: 898540.5625 - val_val_recon_loss: 2.9057e-04 - val_val_KL loss: 614.6328 - val_beta: 1.7989e-05\n",
      "Epoch 2284/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 871277.8339 - recon_loss: 2.8175e-04 - KL loss: 615.1159 - beta: 1.7989e-05 - val_val_loss: 898435.7500 - val_val_recon_loss: 2.9054e-04 - val_val_KL loss: 614.7710 - val_beta: 1.7989e-05\n",
      "Epoch 2285/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 883145.3647 - recon_loss: 2.8559e-04 - KL loss: 614.2921 - beta: 1.7989e-05 - val_val_loss: 898199.1875 - val_val_recon_loss: 2.9046e-04 - val_val_KL loss: 614.7738 - val_beta: 1.7989e-05\n",
      "Epoch 2286/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 883939.1487 - recon_loss: 2.8585e-04 - KL loss: 613.9068 - beta: 1.7989e-05 - val_val_loss: 897791.9375 - val_val_recon_loss: 2.9033e-04 - val_val_KL loss: 614.7870 - val_beta: 1.7989e-05\n",
      "Epoch 2287/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 886709.3426 - recon_loss: 2.8674e-04 - KL loss: 615.2498 - beta: 1.7989e-05 - val_val_loss: 898425.1250 - val_val_recon_loss: 2.9053e-04 - val_val_KL loss: 614.9612 - val_beta: 1.7989e-05\n",
      "Epoch 2288/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 878401.5694 - recon_loss: 2.8405e-04 - KL loss: 614.8378 - beta: 1.7989e-05 - val_val_loss: 898284.7500 - val_val_recon_loss: 2.9049e-04 - val_val_KL loss: 614.8737 - val_beta: 1.7989e-05\n",
      "Epoch 2289/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 881975.0162 - recon_loss: 2.8521e-04 - KL loss: 614.3368 - beta: 1.7989e-05 - val_val_loss: 898151.1875 - val_val_recon_loss: 2.9044e-04 - val_val_KL loss: 614.8562 - val_beta: 1.7989e-05\n",
      "Epoch 2290/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 891833.3118 - recon_loss: 2.8840e-04 - KL loss: 613.9460 - beta: 1.7989e-05 - val_val_loss: 898537.6875 - val_val_recon_loss: 2.9057e-04 - val_val_KL loss: 614.9637 - val_beta: 1.7989e-05\n",
      "Epoch 2291/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 877426.4106 - recon_loss: 2.8374e-04 - KL loss: 615.1955 - beta: 1.7989e-05\n",
      "Epoch 02291: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877426.8922 - recon_loss: 2.8374e-04 - KL loss: 615.1953 - beta: 1.7989e-05 - val_val_loss: 898175.5000 - val_val_recon_loss: 2.9045e-04 - val_val_KL loss: 615.0010 - val_beta: 1.7989e-05\n",
      "Epoch 2292/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 883877.9698 - recon_loss: 2.8583e-04 - KL loss: 614.3421 - beta: 1.7989e-05 - val_val_loss: 897995.5000 - val_val_recon_loss: 2.9039e-04 - val_val_KL loss: 615.0605 - val_beta: 1.7989e-05\n",
      "Epoch 2293/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 869384.7732 - recon_loss: 2.8114e-04 - KL loss: 614.7287 - beta: 1.7989e-05 - val_val_loss: 898096.0625 - val_val_recon_loss: 2.9043e-04 - val_val_KL loss: 615.0485 - val_beta: 1.7989e-05\n",
      "Epoch 2294/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877058.0891 - recon_loss: 2.8362e-04 - KL loss: 614.7723 - beta: 1.7989e-05 - val_val_loss: 898487.8125 - val_val_recon_loss: 2.9055e-04 - val_val_KL loss: 615.0436 - val_beta: 1.7989e-05\n",
      "Epoch 2295/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 873848.9955 - recon_loss: 2.8258e-04 - KL loss: 614.2632 - beta: 1.7989e-05 - val_val_loss: 898401.1875 - val_val_recon_loss: 2.9052e-04 - val_val_KL loss: 615.0604 - val_beta: 1.7989e-05\n",
      "Epoch 2296/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 877759.9852 - recon_loss: 2.8385e-04 - KL loss: 613.6181 - beta: 1.7989e-05\n",
      "Epoch 02296: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877759.8523 - recon_loss: 2.8385e-04 - KL loss: 613.6188 - beta: 1.7989e-05 - val_val_loss: 898145.0625 - val_val_recon_loss: 2.9044e-04 - val_val_KL loss: 615.0303 - val_beta: 1.7989e-05\n",
      "Epoch 2296/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3454970.8427 - recon_loss: 3.4544e-04 - KL loss: 603.0506 - beta: 1.0000e-05 - val_val_loss: 3213510.5000 - val_val_recon_loss: 3.2129e-04 - val_val_KL loss: 618.5917 - val_beta: 1.0000e-05\n",
      "Epoch 2297/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3169530.9166 - recon_loss: 3.1689e-04 - KL loss: 628.4295 - beta: 1.0000e-05 - val_val_loss: 3296051.2500 - val_val_recon_loss: 3.2954e-04 - val_val_KL loss: 652.2473 - val_beta: 1.0000e-05\n",
      "Epoch 2298/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3222458.7435 - recon_loss: 3.2218e-04 - KL loss: 639.9225 - beta: 1.0000e-05 - val_val_loss: 3149541.5000 - val_val_recon_loss: 3.1489e-04 - val_val_KL loss: 638.7961 - val_beta: 1.0000e-05\n",
      "Epoch 2299/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3092989.6751 - recon_loss: 3.0924e-04 - KL loss: 636.4006 - beta: 1.0000e-05 - val_val_loss: 3120829.0000 - val_val_recon_loss: 3.1202e-04 - val_val_KL loss: 635.0659 - val_beta: 1.0000e-05\n",
      "Epoch 2300/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3102001.5020 - recon_loss: 3.1014e-04 - KL loss: 629.5608 - beta: 1.0000e-05 - val_val_loss: 3098571.5000 - val_val_recon_loss: 3.0979e-04 - val_val_KL loss: 636.4141 - val_beta: 1.0000e-05\n",
      "Epoch 2301/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3077015.6778 - recon_loss: 3.0764e-04 - KL loss: 635.0210 - beta: 1.0000e-05 - val_val_loss: 3253201.0000 - val_val_recon_loss: 3.2525e-04 - val_val_KL loss: 675.1694 - val_beta: 1.0000e-05\n",
      "Epoch 2302/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3155347.9895 - recon_loss: 3.1547e-04 - KL loss: 664.1638 - beta: 1.0000e-05 - val_val_loss: 3078380.2500 - val_val_recon_loss: 3.0777e-04 - val_val_KL loss: 647.4334 - val_beta: 1.0000e-05\n",
      "Epoch 2303/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3107777.9630 - recon_loss: 3.1071e-04 - KL loss: 648.4314 - beta: 1.0000e-05 - val_val_loss: 3188648.2500 - val_val_recon_loss: 3.1880e-04 - val_val_KL loss: 649.5064 - val_beta: 1.0000e-05\n",
      "Epoch 2304/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 3152900.9770 - recon_loss: 3.1522e-04 - KL loss: 654.7722 - beta: 1.0000e-05 - val_val_loss: 3164033.5000 - val_val_recon_loss: 3.1634e-04 - val_val_KL loss: 666.2888 - val_beta: 1.0000e-05\n",
      "Epoch 2305/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3147491.4555 - recon_loss: 3.1468e-04 - KL loss: 671.8888 - beta: 1.0000e-05 - val_val_loss: 3231585.0000 - val_val_recon_loss: 3.2309e-04 - val_val_KL loss: 688.1216 - val_beta: 1.0000e-05\n",
      "Epoch 2306/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3229714.2590 - recon_loss: 3.2290e-04 - KL loss: 691.5973 - beta: 1.0000e-05 - val_val_loss: 3215420.2500 - val_val_recon_loss: 3.2147e-04 - val_val_KL loss: 706.8363 - val_beta: 1.0000e-05\n",
      "Epoch 2307/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 3178627.5360 - recon_loss: 3.1779e-04 - KL loss: 708.2388 - beta: 1.0000e-05\n",
      "Epoch 02307: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3178625.7905 - recon_loss: 3.1779e-04 - KL loss: 708.2379 - beta: 1.0000e-05 - val_val_loss: 3183478.5000 - val_val_recon_loss: 3.1828e-04 - val_val_KL loss: 704.8354 - val_beta: 1.0000e-05\n",
      "Epoch 2308/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 3008075.2365 - recon_loss: 3.0074e-04 - KL loss: 701.1326 - beta: 1.0000e-05 - val_val_loss: 3023344.7500 - val_val_recon_loss: 3.0226e-04 - val_val_KL loss: 705.4947 - val_beta: 1.0000e-05\n",
      "Epoch 2309/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2985982.1161 - recon_loss: 2.9853e-04 - KL loss: 703.4892 - beta: 1.0000e-05 - val_val_loss: 3003185.0000 - val_val_recon_loss: 3.0025e-04 - val_val_KL loss: 703.7880 - val_beta: 1.0000e-05\n",
      "Epoch 2310/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2995789.0385 - recon_loss: 2.9951e-04 - KL loss: 704.5927 - beta: 1.0000e-05 - val_val_loss: 2967106.2500 - val_val_recon_loss: 2.9664e-04 - val_val_KL loss: 707.8825 - val_beta: 1.0000e-05\n",
      "Epoch 2311/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2959442.2525 - recon_loss: 2.9587e-04 - KL loss: 708.0475 - beta: 1.0000e-05 - val_val_loss: 2971231.2500 - val_val_recon_loss: 2.9705e-04 - val_val_KL loss: 707.2488 - val_beta: 1.0000e-05\n",
      "Epoch 2312/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2914671.9518 - recon_loss: 2.9140e-04 - KL loss: 707.7186 - beta: 1.0000e-05 - val_val_loss: 2949702.5000 - val_val_recon_loss: 2.9490e-04 - val_val_KL loss: 704.4673 - val_beta: 1.0000e-05\n",
      "Epoch 2313/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2919975.9585 - recon_loss: 2.9193e-04 - KL loss: 706.5548 - beta: 1.0000e-05 - val_val_loss: 2958582.7500 - val_val_recon_loss: 2.9579e-04 - val_val_KL loss: 706.0988 - val_beta: 1.0000e-05\n",
      "Epoch 2314/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2904048.6768 - recon_loss: 2.9033e-04 - KL loss: 704.2227 - beta: 1.0000e-05 - val_val_loss: 2965854.7500 - val_val_recon_loss: 2.9652e-04 - val_val_KL loss: 703.8120 - val_beta: 1.0000e-05\n",
      "Epoch 2315/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2915563.8839 - recon_loss: 2.9149e-04 - KL loss: 703.9686 - beta: 1.0000e-05 - val_val_loss: 2955151.0000 - val_val_recon_loss: 2.9544e-04 - val_val_KL loss: 706.1060 - val_beta: 1.0000e-05\n",
      "Epoch 2316/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2948847.0440 - recon_loss: 2.9481e-04 - KL loss: 706.9006 - beta: 1.0000e-05 - val_val_loss: 2966728.2500 - val_val_recon_loss: 2.9660e-04 - val_val_KL loss: 710.4070 - val_beta: 1.0000e-05\n",
      "Epoch 2317/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2930900.8963 - recon_loss: 2.9302e-04 - KL loss: 708.7403 - beta: 1.0000e-05\n",
      "Epoch 02317: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2930894.6486 - recon_loss: 2.9302e-04 - KL loss: 708.7413 - beta: 1.0000e-05 - val_val_loss: 2961239.7500 - val_val_recon_loss: 2.9605e-04 - val_val_KL loss: 713.7335 - val_beta: 1.0000e-05\n",
      "Epoch 2318/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2897828.9006 - recon_loss: 2.8971e-04 - KL loss: 711.9934 - beta: 1.0000e-05 - val_val_loss: 2927363.7500 - val_val_recon_loss: 2.9266e-04 - val_val_KL loss: 713.6804 - val_beta: 1.0000e-05\n",
      "Epoch 2319/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2885403.7912 - recon_loss: 2.8847e-04 - KL loss: 715.3904 - beta: 1.0000e-05 - val_val_loss: 2920373.7500 - val_val_recon_loss: 2.9197e-04 - val_val_KL loss: 714.2808 - val_beta: 1.0000e-05\n",
      "Epoch 2320/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2851634.2125 - recon_loss: 2.8509e-04 - KL loss: 714.8456 - beta: 1.0000e-05 - val_val_loss: 2918655.0000 - val_val_recon_loss: 2.9179e-04 - val_val_KL loss: 716.5414 - val_beta: 1.0000e-05\n",
      "Epoch 2321/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2867233.9578 - recon_loss: 2.8665e-04 - KL loss: 716.5421 - beta: 1.0000e-05 - val_val_loss: 2912800.7500 - val_val_recon_loss: 2.9121e-04 - val_val_KL loss: 717.2277 - val_beta: 1.0000e-05\n",
      "Epoch 2322/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2852876.5617 - recon_loss: 2.8522e-04 - KL loss: 717.3269 - beta: 1.0000e-05 - val_val_loss: 2915382.0000 - val_val_recon_loss: 2.9147e-04 - val_val_KL loss: 716.1549 - val_beta: 1.0000e-05\n",
      "Epoch 2323/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2878126.1948 - recon_loss: 2.8774e-04 - KL loss: 717.2073 - beta: 1.0000e-05 - val_val_loss: 2909345.2500 - val_val_recon_loss: 2.9086e-04 - val_val_KL loss: 719.5070 - val_beta: 1.0000e-05\n",
      "Epoch 2324/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2876982.0542 - recon_loss: 2.8763e-04 - KL loss: 719.1661 - beta: 1.0000e-05 - val_val_loss: 2914883.0000 - val_val_recon_loss: 2.9142e-04 - val_val_KL loss: 720.3996 - val_beta: 1.0000e-05\n",
      "Epoch 2325/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2860845.2113 - recon_loss: 2.8601e-04 - KL loss: 719.6623 - beta: 1.0000e-05 - val_val_loss: 2924206.7500 - val_val_recon_loss: 2.9235e-04 - val_val_KL loss: 724.4875 - val_beta: 1.0000e-05\n",
      "Epoch 2326/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2888125.5342 - recon_loss: 2.8874e-04 - KL loss: 723.6635 - beta: 1.0000e-05 - val_val_loss: 2921769.2500 - val_val_recon_loss: 2.9210e-04 - val_val_KL loss: 722.5990 - val_beta: 1.0000e-05\n",
      "Epoch 2327/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2870521.9920 - recon_loss: 2.8698e-04 - KL loss: 722.8758 - beta: 1.0000e-05 - val_val_loss: 2934025.2500 - val_val_recon_loss: 2.9333e-04 - val_val_KL loss: 724.9891 - val_beta: 1.0000e-05\n",
      "Epoch 2328/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2890616.1940 - recon_loss: 2.8899e-04 - KL loss: 725.0059 - beta: 1.0000e-05\n",
      "Epoch 02328: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2890601.6918 - recon_loss: 2.8899e-04 - KL loss: 725.0063 - beta: 1.0000e-05 - val_val_loss: 2924036.2500 - val_val_recon_loss: 2.9233e-04 - val_val_KL loss: 725.9319 - val_beta: 1.0000e-05\n",
      "Epoch 2329/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2866285.3926 - recon_loss: 2.8656e-04 - KL loss: 724.8648 - beta: 1.0000e-05 - val_val_loss: 2908027.5000 - val_val_recon_loss: 2.9073e-04 - val_val_KL loss: 725.9888 - val_beta: 1.0000e-05\n",
      "Epoch 2330/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2872982.3531 - recon_loss: 2.8723e-04 - KL loss: 725.7753 - beta: 1.0000e-05 - val_val_loss: 2910661.0000 - val_val_recon_loss: 2.9099e-04 - val_val_KL loss: 726.2325 - val_beta: 1.0000e-05\n",
      "Epoch 2331/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2838926.0757 - recon_loss: 2.8382e-04 - KL loss: 725.3222 - beta: 1.0000e-05 - val_val_loss: 2911749.7500 - val_val_recon_loss: 2.9110e-04 - val_val_KL loss: 727.0541 - val_beta: 1.0000e-05\n",
      "Epoch 2332/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2874242.9166 - recon_loss: 2.8735e-04 - KL loss: 727.4156 - beta: 1.0000e-05 - val_val_loss: 2913515.2500 - val_val_recon_loss: 2.9128e-04 - val_val_KL loss: 728.2019 - val_beta: 1.0000e-05\n",
      "Epoch 2333/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2843955.7123 - recon_loss: 2.8432e-04 - KL loss: 726.9666 - beta: 1.0000e-05 - val_val_loss: 2914348.7500 - val_val_recon_loss: 2.9136e-04 - val_val_KL loss: 727.4863 - val_beta: 1.0000e-05\n",
      "Epoch 2334/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2863970.8510 - recon_loss: 2.8632e-04 - KL loss: 726.6221 - beta: 1.0000e-05\n",
      "Epoch 02334: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2863971.6966 - recon_loss: 2.8632e-04 - KL loss: 726.6219 - beta: 1.0000e-05 - val_val_loss: 2910167.7500 - val_val_recon_loss: 2.9094e-04 - val_val_KL loss: 726.4551 - val_beta: 1.0000e-05\n",
      "Epoch 2335/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2874076.3566 - recon_loss: 2.8734e-04 - KL loss: 725.8738 - beta: 1.0000e-05 - val_val_loss: 2906106.2500 - val_val_recon_loss: 2.9054e-04 - val_val_KL loss: 726.3480 - val_beta: 1.0000e-05\n",
      "Epoch 2336/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2853083.2997 - recon_loss: 2.8524e-04 - KL loss: 726.0234 - beta: 1.0000e-05 - val_val_loss: 2904304.2500 - val_val_recon_loss: 2.9036e-04 - val_val_KL loss: 726.2643 - val_beta: 1.0000e-05\n",
      "Epoch 2337/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2846373.2875 - recon_loss: 2.8456e-04 - KL loss: 726.5932 - beta: 1.0000e-05 - val_val_loss: 2902790.7500 - val_val_recon_loss: 2.9021e-04 - val_val_KL loss: 725.7319 - val_beta: 1.0000e-05\n",
      "Epoch 2338/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2855261.8387 - recon_loss: 2.8545e-04 - KL loss: 726.2676 - beta: 1.0000e-05 - val_val_loss: 2905109.7500 - val_val_recon_loss: 2.9044e-04 - val_val_KL loss: 726.2388 - val_beta: 1.0000e-05\n",
      "Epoch 2339/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2841795.6826 - recon_loss: 2.8411e-04 - KL loss: 726.3765 - beta: 1.0000e-05 - val_val_loss: 2904111.7500 - val_val_recon_loss: 2.9034e-04 - val_val_KL loss: 726.4036 - val_beta: 1.0000e-05\n",
      "Epoch 2340/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2856688.0617 - recon_loss: 2.8560e-04 - KL loss: 726.0558 - beta: 1.0000e-05 - val_val_loss: 2901268.2500 - val_val_recon_loss: 2.9005e-04 - val_val_KL loss: 727.1165 - val_beta: 1.0000e-05\n",
      "Epoch 2341/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2830457.8851 - recon_loss: 2.8297e-04 - KL loss: 726.2771 - beta: 1.0000e-05 - val_val_loss: 2900378.2500 - val_val_recon_loss: 2.8997e-04 - val_val_KL loss: 726.7467 - val_beta: 1.0000e-05\n",
      "Epoch 2342/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2864883.7620 - recon_loss: 2.8642e-04 - KL loss: 726.8654 - beta: 1.0000e-05 - val_val_loss: 2902621.7500 - val_val_recon_loss: 2.9019e-04 - val_val_KL loss: 727.6934 - val_beta: 1.0000e-05\n",
      "Epoch 2343/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2833675.7153 - recon_loss: 2.8329e-04 - KL loss: 727.7112 - beta: 1.0000e-05 - val_val_loss: 2899447.7500 - val_val_recon_loss: 2.8987e-04 - val_val_KL loss: 727.4595 - val_beta: 1.0000e-05\n",
      "Epoch 2344/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2829906.7540 - recon_loss: 2.8292e-04 - KL loss: 727.5084 - beta: 1.0000e-05 - val_val_loss: 2900767.7500 - val_val_recon_loss: 2.9000e-04 - val_val_KL loss: 727.8290 - val_beta: 1.0000e-05\n",
      "Epoch 2345/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2837978.9293 - recon_loss: 2.8373e-04 - KL loss: 726.7350 - beta: 1.0000e-05 - val_val_loss: 2898624.0000 - val_val_recon_loss: 2.8979e-04 - val_val_KL loss: 727.9992 - val_beta: 1.0000e-05\n",
      "Epoch 2346/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2841135.7760 - recon_loss: 2.8404e-04 - KL loss: 727.6665 - beta: 1.0000e-05 - val_val_loss: 2899601.5000 - val_val_recon_loss: 2.8989e-04 - val_val_KL loss: 727.4766 - val_beta: 1.0000e-05\n",
      "Epoch 2347/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2856773.9148 - recon_loss: 2.8560e-04 - KL loss: 726.9376 - beta: 1.0000e-05 - val_val_loss: 2900477.0000 - val_val_recon_loss: 2.8997e-04 - val_val_KL loss: 727.0720 - val_beta: 1.0000e-05\n",
      "Epoch 2348/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2838978.6379 - recon_loss: 2.8383e-04 - KL loss: 727.0980 - beta: 1.0000e-05 - val_val_loss: 2900242.0000 - val_val_recon_loss: 2.8995e-04 - val_val_KL loss: 727.7823 - val_beta: 1.0000e-05\n",
      "Epoch 2349/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2832888.5694 - recon_loss: 2.8322e-04 - KL loss: 727.9224 - beta: 1.0000e-05 - val_val_loss: 2899585.2500 - val_val_recon_loss: 2.8989e-04 - val_val_KL loss: 727.7307 - val_beta: 1.0000e-05\n",
      "Epoch 2350/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2863696.0410 - recon_loss: 2.8630e-04 - KL loss: 727.0441 - beta: 1.0000e-05\n",
      "Epoch 02350: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2863704.4241 - recon_loss: 2.8630e-04 - KL loss: 727.0442 - beta: 1.0000e-05 - val_val_loss: 2899355.7500 - val_val_recon_loss: 2.8986e-04 - val_val_KL loss: 727.6401 - val_beta: 1.0000e-05\n",
      "Epoch 2351/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2858441.4980 - recon_loss: 2.8577e-04 - KL loss: 727.8617 - beta: 1.0000e-05 - val_val_loss: 2898094.5000 - val_val_recon_loss: 2.8974e-04 - val_val_KL loss: 727.5042 - val_beta: 1.0000e-05\n",
      "Epoch 2352/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2834275.7265 - recon_loss: 2.8335e-04 - KL loss: 726.2296 - beta: 1.0000e-05 - val_val_loss: 2897145.0000 - val_val_recon_loss: 2.8964e-04 - val_val_KL loss: 727.6147 - val_beta: 1.0000e-05\n",
      "Epoch 2353/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2822225.8017 - recon_loss: 2.8215e-04 - KL loss: 727.0883 - beta: 1.0000e-05 - val_val_loss: 2897608.2500 - val_val_recon_loss: 2.8969e-04 - val_val_KL loss: 727.6956 - val_beta: 1.0000e-05\n",
      "Epoch 2354/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2855498.0360 - recon_loss: 2.8548e-04 - KL loss: 727.8582 - beta: 1.0000e-05 - val_val_loss: 2898382.7500 - val_val_recon_loss: 2.8977e-04 - val_val_KL loss: 727.9084 - val_beta: 1.0000e-05\n",
      "Epoch 2355/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2840465.4763 - recon_loss: 2.8397e-04 - KL loss: 728.3185 - beta: 1.0000e-05 - val_val_loss: 2897920.2500 - val_val_recon_loss: 2.8972e-04 - val_val_KL loss: 727.8809 - val_beta: 1.0000e-05\n",
      "Epoch 2356/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 2843451.6221 - recon_loss: 2.8427e-04 - KL loss: 728.0938 - beta: 1.0000e-05 - val_val_loss: 2897206.7500 - val_val_recon_loss: 2.8965e-04 - val_val_KL loss: 727.9741 - val_beta: 1.0000e-05\n",
      "Epoch 2357/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2812644.3424 - recon_loss: 2.8119e-04 - KL loss: 727.9958 - beta: 1.0000e-05 - val_val_loss: 2896361.5000 - val_val_recon_loss: 2.8956e-04 - val_val_KL loss: 728.0094 - val_beta: 1.0000e-05\n",
      "Epoch 2358/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2861219.5360 - recon_loss: 2.8605e-04 - KL loss: 728.5773 - beta: 1.0000e-05 - val_val_loss: 2897393.5000 - val_val_recon_loss: 2.8967e-04 - val_val_KL loss: 727.7567 - val_beta: 1.0000e-05\n",
      "Epoch 2359/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2858687.7755 - recon_loss: 2.8580e-04 - KL loss: 727.6881 - beta: 1.0000e-05 - val_val_loss: 2897079.7500 - val_val_recon_loss: 2.8964e-04 - val_val_KL loss: 727.8647 - val_beta: 1.0000e-05\n",
      "Epoch 2360/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2826806.0052 - recon_loss: 2.8261e-04 - KL loss: 727.2490 - beta: 1.0000e-05 - val_val_loss: 2897014.5000 - val_val_recon_loss: 2.8963e-04 - val_val_KL loss: 728.0010 - val_beta: 1.0000e-05\n",
      "Epoch 2361/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2829831.6766 - recon_loss: 2.8291e-04 - KL loss: 727.6396 - beta: 1.0000e-05 - val_val_loss: 2897249.2500 - val_val_recon_loss: 2.8965e-04 - val_val_KL loss: 727.9574 - val_beta: 1.0000e-05\n",
      "Epoch 2362/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2843559.2435 - recon_loss: 2.8428e-04 - KL loss: 727.3554 - beta: 1.0000e-05\n",
      "Epoch 02362: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2843573.1299 - recon_loss: 2.8428e-04 - KL loss: 727.3559 - beta: 1.0000e-05 - val_val_loss: 2897901.0000 - val_val_recon_loss: 2.8972e-04 - val_val_KL loss: 728.1110 - val_beta: 1.0000e-05\n",
      "Epoch 2363/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2849971.4903 - recon_loss: 2.8492e-04 - KL loss: 728.4095 - beta: 1.0000e-05 - val_val_loss: 2898332.2500 - val_val_recon_loss: 2.8976e-04 - val_val_KL loss: 727.9624 - val_beta: 1.0000e-05\n",
      "Epoch 2364/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2819047.1613 - recon_loss: 2.8183e-04 - KL loss: 727.0203 - beta: 1.0000e-05 - val_val_loss: 2898497.5000 - val_val_recon_loss: 2.8978e-04 - val_val_KL loss: 728.0359 - val_beta: 1.0000e-05\n",
      "Epoch 2365/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2834232.5342 - recon_loss: 2.8335e-04 - KL loss: 727.8333 - beta: 1.0000e-05 - val_val_loss: 2898684.5000 - val_val_recon_loss: 2.8980e-04 - val_val_KL loss: 728.1230 - val_beta: 1.0000e-05\n",
      "Epoch 2366/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2815397.9183 - recon_loss: 2.8147e-04 - KL loss: 727.7991 - beta: 1.0000e-05 - val_val_loss: 2898771.7500 - val_val_recon_loss: 2.8980e-04 - val_val_KL loss: 728.1155 - val_beta: 1.0000e-05\n",
      "Epoch 2367/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2835737.0737 - recon_loss: 2.8350e-04 - KL loss: 727.5446 - beta: 1.0000e-05\n",
      "Epoch 02367: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 2835742.6109 - recon_loss: 2.8350e-04 - KL loss: 727.5447 - beta: 1.0000e-05 - val_val_loss: 2898659.2500 - val_val_recon_loss: 2.8979e-04 - val_val_KL loss: 728.2251 - val_beta: 1.0000e-05\n",
      "Epoch 2367/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 117s 117ms/step - loss: 908613.9050 - recon_loss: 2.9379e-04 - KL loss: 724.7508 - beta: 1.7989e-05 - val_val_loss: 941309.0625 - val_val_recon_loss: 3.0437e-04 - val_val_KL loss: 725.9889 - val_beta: 1.7989e-05\n",
      "Epoch 2368/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 929042.8519 - recon_loss: 3.0041e-04 - KL loss: 716.6467 - beta: 1.7989e-05 - val_val_loss: 947799.2500 - val_val_recon_loss: 3.0649e-04 - val_val_KL loss: 691.4429 - val_beta: 1.7989e-05\n",
      "Epoch 2369/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 957860.1692 - recon_loss: 3.0974e-04 - KL loss: 699.0391 - beta: 1.7989e-05 - val_val_loss: 955961.4375 - val_val_recon_loss: 3.0913e-04 - val_val_KL loss: 678.8056 - val_beta: 1.7989e-05\n",
      "Epoch 2370/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 947781.2760 - recon_loss: 3.0649e-04 - KL loss: 670.1675 - beta: 1.7989e-05 - val_val_loss: 943423.4375 - val_val_recon_loss: 3.0508e-04 - val_val_KL loss: 650.2931 - val_beta: 1.7989e-05\n",
      "Epoch 2371/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 949187.3309 - recon_loss: 3.0695e-04 - KL loss: 643.0070 - beta: 1.7989e-05 - val_val_loss: 976932.1875 - val_val_recon_loss: 3.1592e-04 - val_val_KL loss: 655.9236 - val_beta: 1.7989e-05\n",
      "Epoch 2372/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 974087.0864 - recon_loss: 3.1500e-04 - KL loss: 656.2278 - beta: 1.7989e-05\n",
      "Epoch 02372: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 974093.5378 - recon_loss: 3.1501e-04 - KL loss: 656.2264 - beta: 1.7989e-05 - val_val_loss: 986494.6250 - val_val_recon_loss: 3.1902e-04 - val_val_KL loss: 652.4816 - val_beta: 1.7989e-05\n",
      "Epoch 2373/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 949449.4392 - recon_loss: 3.0703e-04 - KL loss: 654.9781 - beta: 1.7989e-05 - val_val_loss: 937743.5000 - val_val_recon_loss: 3.0324e-04 - val_val_KL loss: 655.6418 - val_beta: 1.7989e-05\n",
      "Epoch 2374/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 925880.7008 - recon_loss: 2.9940e-04 - KL loss: 655.6007 - beta: 1.7989e-05 - val_val_loss: 934897.9375 - val_val_recon_loss: 3.0232e-04 - val_val_KL loss: 653.5966 - val_beta: 1.7989e-05\n",
      "Epoch 2375/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 921785.9622 - recon_loss: 2.9808e-04 - KL loss: 654.1944 - beta: 1.7989e-05 - val_val_loss: 930516.9375 - val_val_recon_loss: 3.0091e-04 - val_val_KL loss: 645.3622 - val_beta: 1.7989e-05\n",
      "Epoch 2376/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 918145.1418 - recon_loss: 2.9690e-04 - KL loss: 646.8637 - beta: 1.7989e-05 - val_val_loss: 923129.5000 - val_val_recon_loss: 2.9852e-04 - val_val_KL loss: 648.7879 - val_beta: 1.7989e-05\n",
      "Epoch 2377/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 923648.9806 - recon_loss: 2.9868e-04 - KL loss: 650.1849 - beta: 1.7989e-05 - val_val_loss: 929958.0000 - val_val_recon_loss: 3.0073e-04 - val_val_KL loss: 650.8208 - val_beta: 1.7989e-05\n",
      "Epoch 2378/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 912374.6781 - recon_loss: 2.9503e-04 - KL loss: 651.8729 - beta: 1.7989e-05 - val_val_loss: 990255.8125 - val_val_recon_loss: 3.2023e-04 - val_val_KL loss: 665.1854 - val_beta: 1.7989e-05\n",
      "Epoch 2379/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 946125.6032 - recon_loss: 3.0595e-04 - KL loss: 661.2571 - beta: 1.7989e-05 - val_val_loss: 942815.7500 - val_val_recon_loss: 3.0488e-04 - val_val_KL loss: 655.8957 - val_beta: 1.7989e-05\n",
      "Epoch 2380/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 948207.1949 - recon_loss: 3.0663e-04 - KL loss: 658.7930 - beta: 1.7989e-05 - val_val_loss: 946311.1250 - val_val_recon_loss: 3.0602e-04 - val_val_KL loss: 656.3209 - val_beta: 1.7989e-05\n",
      "Epoch 2381/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 942793.3867 - recon_loss: 3.0488e-04 - KL loss: 657.4297 - beta: 1.7989e-05\n",
      "Epoch 02381: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 942783.0536 - recon_loss: 3.0487e-04 - KL loss: 657.4286 - beta: 1.7989e-05 - val_val_loss: 936613.9375 - val_val_recon_loss: 3.0288e-04 - val_val_KL loss: 654.0981 - val_beta: 1.7989e-05\n",
      "Epoch 2382/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 918621.5519 - recon_loss: 2.9705e-04 - KL loss: 655.5725 - beta: 1.7989e-05 - val_val_loss: 926940.5000 - val_val_recon_loss: 2.9975e-04 - val_val_KL loss: 654.2908 - val_beta: 1.7989e-05\n",
      "Epoch 2383/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 913831.3176 - recon_loss: 2.9550e-04 - KL loss: 655.7867 - beta: 1.7989e-05 - val_val_loss: 920770.0000 - val_val_recon_loss: 2.9775e-04 - val_val_KL loss: 654.7888 - val_beta: 1.7989e-05\n",
      "Epoch 2384/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 906520.5734 - recon_loss: 2.9314e-04 - KL loss: 655.2667 - beta: 1.7989e-05 - val_val_loss: 915320.1875 - val_val_recon_loss: 2.9599e-04 - val_val_KL loss: 654.5641 - val_beta: 1.7989e-05\n",
      "Epoch 2385/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 903191.1091 - recon_loss: 2.9206e-04 - KL loss: 655.5199 - beta: 1.7989e-05 - val_val_loss: 913614.1875 - val_val_recon_loss: 2.9543e-04 - val_val_KL loss: 654.3950 - val_beta: 1.7989e-05\n",
      "Epoch 2386/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 904901.9776 - recon_loss: 2.9262e-04 - KL loss: 655.0446 - beta: 1.7989e-05 - val_val_loss: 913976.8125 - val_val_recon_loss: 2.9555e-04 - val_val_KL loss: 656.8167 - val_beta: 1.7989e-05\n",
      "Epoch 2387/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 895731.9628 - recon_loss: 2.8965e-04 - KL loss: 654.9554 - beta: 1.7989e-05 - val_val_loss: 910241.9375 - val_val_recon_loss: 2.9434e-04 - val_val_KL loss: 652.7347 - val_beta: 1.7989e-05\n",
      "Epoch 2388/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 893391.3076 - recon_loss: 2.8889e-04 - KL loss: 654.8939 - beta: 1.7989e-05 - val_val_loss: 911720.2500 - val_val_recon_loss: 2.9482e-04 - val_val_KL loss: 654.5618 - val_beta: 1.7989e-05\n",
      "Epoch 2389/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 900613.2602 - recon_loss: 2.9123e-04 - KL loss: 654.1865 - beta: 1.7989e-05 - val_val_loss: 907825.3750 - val_val_recon_loss: 2.9356e-04 - val_val_KL loss: 652.9179 - val_beta: 1.7989e-05\n",
      "Epoch 2390/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 896228.2622 - recon_loss: 2.8981e-04 - KL loss: 652.6656 - beta: 1.7989e-05 - val_val_loss: 912573.7500 - val_val_recon_loss: 2.9510e-04 - val_val_KL loss: 655.7377 - val_beta: 1.7989e-05\n",
      "Epoch 2391/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 902245.0310 - recon_loss: 2.9176e-04 - KL loss: 656.4350 - beta: 1.7989e-05 - val_val_loss: 910414.1875 - val_val_recon_loss: 2.9440e-04 - val_val_KL loss: 656.2360 - val_beta: 1.7989e-05\n",
      "Epoch 2392/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 897612.0707 - recon_loss: 2.9026e-04 - KL loss: 656.4792 - beta: 1.7989e-05 - val_val_loss: 911482.7500 - val_val_recon_loss: 2.9475e-04 - val_val_KL loss: 655.2008 - val_beta: 1.7989e-05\n",
      "Epoch 2393/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 898374.8634 - recon_loss: 2.9050e-04 - KL loss: 655.7868 - beta: 1.7989e-05 - val_val_loss: 906804.2500 - val_val_recon_loss: 2.9323e-04 - val_val_KL loss: 654.2538 - val_beta: 1.7989e-05\n",
      "Epoch 2394/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 894400.9279 - recon_loss: 2.8922e-04 - KL loss: 655.2810 - beta: 1.7989e-05 - val_val_loss: 906514.7500 - val_val_recon_loss: 2.9314e-04 - val_val_KL loss: 655.2172 - val_beta: 1.7989e-05\n",
      "Epoch 2395/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 884899.5243 - recon_loss: 2.8614e-04 - KL loss: 655.1931 - beta: 1.7989e-05 - val_val_loss: 904084.3750 - val_val_recon_loss: 2.9235e-04 - val_val_KL loss: 653.7946 - val_beta: 1.7989e-05\n",
      "Epoch 2396/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 893178.6325 - recon_loss: 2.8882e-04 - KL loss: 653.6833 - beta: 1.7989e-05 - val_val_loss: 904652.2500 - val_val_recon_loss: 2.9254e-04 - val_val_KL loss: 650.6085 - val_beta: 1.7989e-05\n",
      "Epoch 2397/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 889157.5682 - recon_loss: 2.8752e-04 - KL loss: 651.9347 - beta: 1.7989e-05 - val_val_loss: 904803.5000 - val_val_recon_loss: 2.9258e-04 - val_val_KL loss: 651.5197 - val_beta: 1.7989e-05\n",
      "Epoch 2398/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 896964.7941 - recon_loss: 2.9005e-04 - KL loss: 652.8662 - beta: 1.7989e-05 - val_val_loss: 907941.1250 - val_val_recon_loss: 2.9360e-04 - val_val_KL loss: 652.1981 - val_beta: 1.7989e-05\n",
      "Epoch 2399/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 878985.0136 - recon_loss: 2.8423e-04 - KL loss: 653.0836 - beta: 1.7989e-05 - val_val_loss: 905155.3750 - val_val_recon_loss: 2.9270e-04 - val_val_KL loss: 651.9424 - val_beta: 1.7989e-05\n",
      "Epoch 2400/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 889214.6679 - recon_loss: 2.8754e-04 - KL loss: 652.7425 - beta: 1.7989e-05\n",
      "Epoch 02400: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 889215.2614 - recon_loss: 2.8754e-04 - KL loss: 652.7425 - beta: 1.7989e-05 - val_val_loss: 904345.7500 - val_val_recon_loss: 2.9244e-04 - val_val_KL loss: 653.4625 - val_beta: 1.7989e-05\n",
      "Epoch 2401/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 891332.3649 - recon_loss: 2.8822e-04 - KL loss: 654.1257 - beta: 1.7989e-05 - val_val_loss: 901308.0000 - val_val_recon_loss: 2.9145e-04 - val_val_KL loss: 654.3448 - val_beta: 1.7989e-05\n",
      "Epoch 2402/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 881817.4720 - recon_loss: 2.8515e-04 - KL loss: 654.4781 - beta: 1.7989e-05 - val_val_loss: 902300.3750 - val_val_recon_loss: 2.9177e-04 - val_val_KL loss: 655.0184 - val_beta: 1.7989e-05\n",
      "Epoch 2403/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 887162.9633 - recon_loss: 2.8687e-04 - KL loss: 655.2686 - beta: 1.7989e-05 - val_val_loss: 900851.5000 - val_val_recon_loss: 2.9131e-04 - val_val_KL loss: 654.0812 - val_beta: 1.7989e-05\n",
      "Epoch 2404/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 874072.2659 - recon_loss: 2.8264e-04 - KL loss: 653.5795 - beta: 1.7989e-05 - val_val_loss: 899122.5625 - val_val_recon_loss: 2.9075e-04 - val_val_KL loss: 653.3619 - val_beta: 1.7989e-05\n",
      "Epoch 2405/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 881951.4033 - recon_loss: 2.8519e-04 - KL loss: 653.2339 - beta: 1.7989e-05 - val_val_loss: 898003.4375 - val_val_recon_loss: 2.9038e-04 - val_val_KL loss: 653.2202 - val_beta: 1.7989e-05\n",
      "Epoch 2406/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 893486.9776 - recon_loss: 2.8892e-04 - KL loss: 653.2339 - beta: 1.7989e-05 - val_val_loss: 898289.1250 - val_val_recon_loss: 2.9048e-04 - val_val_KL loss: 652.6708 - val_beta: 1.7989e-05\n",
      "Epoch 2407/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 884905.6357 - recon_loss: 2.8614e-04 - KL loss: 653.8697 - beta: 1.7989e-05 - val_val_loss: 897172.3125 - val_val_recon_loss: 2.9011e-04 - val_val_KL loss: 653.4554 - val_beta: 1.7989e-05\n",
      "Epoch 2408/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 883287.7011 - recon_loss: 2.8562e-04 - KL loss: 654.4269 - beta: 1.7989e-05 - val_val_loss: 899358.2500 - val_val_recon_loss: 2.9082e-04 - val_val_KL loss: 654.5035 - val_beta: 1.7989e-05\n",
      "Epoch 2409/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 884579.9264 - recon_loss: 2.8604e-04 - KL loss: 654.4156 - beta: 1.7989e-05 - val_val_loss: 900327.3750 - val_val_recon_loss: 2.9114e-04 - val_val_KL loss: 655.1906 - val_beta: 1.7989e-05\n",
      "Epoch 2410/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 874823.6601 - recon_loss: 2.8288e-04 - KL loss: 655.1683 - beta: 1.7989e-05 - val_val_loss: 898546.2500 - val_val_recon_loss: 2.9056e-04 - val_val_KL loss: 653.9063 - val_beta: 1.7989e-05\n",
      "Epoch 2411/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 890212.9942 - recon_loss: 2.8786e-04 - KL loss: 655.3365 - beta: 1.7989e-05 - val_val_loss: 899069.4375 - val_val_recon_loss: 2.9073e-04 - val_val_KL loss: 654.7628 - val_beta: 1.7989e-05\n",
      "Epoch 2412/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 889794.9693 - recon_loss: 2.8773e-04 - KL loss: 655.8154 - beta: 1.7989e-05 - val_val_loss: 896914.9375 - val_val_recon_loss: 2.9003e-04 - val_val_KL loss: 654.4633 - val_beta: 1.7989e-05\n",
      "Epoch 2413/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 885633.8989 - recon_loss: 2.8638e-04 - KL loss: 654.6365 - beta: 1.7989e-05 - val_val_loss: 897434.0000 - val_val_recon_loss: 2.9020e-04 - val_val_KL loss: 654.6941 - val_beta: 1.7989e-05\n",
      "Epoch 2414/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 880058.7479 - recon_loss: 2.8458e-04 - KL loss: 654.9520 - beta: 1.7989e-05 - val_val_loss: 896922.9375 - val_val_recon_loss: 2.9003e-04 - val_val_KL loss: 654.4662 - val_beta: 1.7989e-05\n",
      "Epoch 2415/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 877159.4529 - recon_loss: 2.8364e-04 - KL loss: 653.6779 - beta: 1.7989e-05 - val_val_loss: 895401.8125 - val_val_recon_loss: 2.8954e-04 - val_val_KL loss: 653.4845 - val_beta: 1.7989e-05\n",
      "Epoch 2416/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 875881.6289 - recon_loss: 2.8322e-04 - KL loss: 653.8653 - beta: 1.7989e-05 - val_val_loss: 895996.3125 - val_val_recon_loss: 2.8973e-04 - val_val_KL loss: 655.1616 - val_beta: 1.7989e-05\n",
      "Epoch 2417/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 879972.5452 - recon_loss: 2.8455e-04 - KL loss: 655.3352 - beta: 1.7989e-05 - val_val_loss: 896541.6875 - val_val_recon_loss: 2.8991e-04 - val_val_KL loss: 655.0551 - val_beta: 1.7989e-05\n",
      "Epoch 2418/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 879083.4896 - recon_loss: 2.8426e-04 - KL loss: 655.8936 - beta: 1.7989e-05 - val_val_loss: 896294.1875 - val_val_recon_loss: 2.8983e-04 - val_val_KL loss: 655.3705 - val_beta: 1.7989e-05\n",
      "Epoch 2419/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 885093.5503 - recon_loss: 2.8621e-04 - KL loss: 655.7721 - beta: 1.7989e-05 - val_val_loss: 896432.1875 - val_val_recon_loss: 2.8987e-04 - val_val_KL loss: 654.6090 - val_beta: 1.7989e-05\n",
      "Epoch 2420/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 879310.3865 - recon_loss: 2.8433e-04 - KL loss: 654.5896 - beta: 1.7989e-05\n",
      "Epoch 02420: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 879308.7230 - recon_loss: 2.8433e-04 - KL loss: 654.5898 - beta: 1.7989e-05 - val_val_loss: 895806.2500 - val_val_recon_loss: 2.8967e-04 - val_val_KL loss: 655.6976 - val_beta: 1.7989e-05\n",
      "Epoch 2421/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 878415.8609 - recon_loss: 2.8404e-04 - KL loss: 655.7665 - beta: 1.7989e-05 - val_val_loss: 894083.6875 - val_val_recon_loss: 2.8911e-04 - val_val_KL loss: 655.6155 - val_beta: 1.7989e-05\n",
      "Epoch 2422/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877481.4450 - recon_loss: 2.8374e-04 - KL loss: 655.9907 - beta: 1.7989e-05 - val_val_loss: 894229.2500 - val_val_recon_loss: 2.8916e-04 - val_val_KL loss: 655.7866 - val_beta: 1.7989e-05\n",
      "Epoch 2423/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 118s 118ms/step - loss: 872799.8819 - recon_loss: 2.8223e-04 - KL loss: 656.0815 - beta: 1.7989e-05 - val_val_loss: 894301.2500 - val_val_recon_loss: 2.8918e-04 - val_val_KL loss: 656.1031 - val_beta: 1.7989e-05\n",
      "Epoch 2424/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 882966.4001 - recon_loss: 2.8552e-04 - KL loss: 656.3425 - beta: 1.7989e-05 - val_val_loss: 893844.6250 - val_val_recon_loss: 2.8904e-04 - val_val_KL loss: 655.8304 - val_beta: 1.7989e-05\n",
      "Epoch 2425/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 875119.5102 - recon_loss: 2.8298e-04 - KL loss: 655.4140 - beta: 1.7989e-05 - val_val_loss: 894959.8125 - val_val_recon_loss: 2.8940e-04 - val_val_KL loss: 655.5814 - val_beta: 1.7989e-05\n",
      "Epoch 2426/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 879421.5943 - recon_loss: 2.8437e-04 - KL loss: 656.2728 - beta: 1.7989e-05 - val_val_loss: 893967.9375 - val_val_recon_loss: 2.8908e-04 - val_val_KL loss: 655.9849 - val_beta: 1.7989e-05\n",
      "Epoch 2427/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 881762.4314 - recon_loss: 2.8513e-04 - KL loss: 655.9195 - beta: 1.7989e-05 - val_val_loss: 893737.2500 - val_val_recon_loss: 2.8900e-04 - val_val_KL loss: 655.9991 - val_beta: 1.7989e-05\n",
      "Epoch 2428/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 871075.6442 - recon_loss: 2.8167e-04 - KL loss: 656.1989 - beta: 1.7989e-05 - val_val_loss: 893365.7500 - val_val_recon_loss: 2.8888e-04 - val_val_KL loss: 656.1817 - val_beta: 1.7989e-05\n",
      "Epoch 2429/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 875605.3643 - recon_loss: 2.8313e-04 - KL loss: 656.0835 - beta: 1.7989e-05 - val_val_loss: 894558.5000 - val_val_recon_loss: 2.8927e-04 - val_val_KL loss: 655.2186 - val_beta: 1.7989e-05\n",
      "Epoch 2430/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 874663.1036 - recon_loss: 2.8283e-04 - KL loss: 656.1266 - beta: 1.7989e-05 - val_val_loss: 893647.0625 - val_val_recon_loss: 2.8897e-04 - val_val_KL loss: 655.5285 - val_beta: 1.7989e-05\n",
      "Epoch 2431/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 876916.4279 - recon_loss: 2.8356e-04 - KL loss: 656.0735 - beta: 1.7989e-05 - val_val_loss: 893040.8125 - val_val_recon_loss: 2.8878e-04 - val_val_KL loss: 655.2916 - val_beta: 1.7989e-05\n",
      "Epoch 2432/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 870833.5549 - recon_loss: 2.8159e-04 - KL loss: 655.5756 - beta: 1.7989e-05 - val_val_loss: 893218.0625 - val_val_recon_loss: 2.8883e-04 - val_val_KL loss: 655.2061 - val_beta: 1.7989e-05\n",
      "Epoch 2433/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 873729.6091 - recon_loss: 2.8253e-04 - KL loss: 655.7764 - beta: 1.7989e-05 - val_val_loss: 893204.5000 - val_val_recon_loss: 2.8883e-04 - val_val_KL loss: 654.7241 - val_beta: 1.7989e-05\n",
      "Epoch 2434/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877031.2722 - recon_loss: 2.8360e-04 - KL loss: 654.7697 - beta: 1.7989e-05 - val_val_loss: 893082.0625 - val_val_recon_loss: 2.8879e-04 - val_val_KL loss: 654.9927 - val_beta: 1.7989e-05\n",
      "Epoch 2435/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 874658.7173 - recon_loss: 2.8283e-04 - KL loss: 654.5980 - beta: 1.7989e-05 - val_val_loss: 892708.8125 - val_val_recon_loss: 2.8867e-04 - val_val_KL loss: 654.9647 - val_beta: 1.7989e-05\n",
      "Epoch 2436/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877827.7815 - recon_loss: 2.8385e-04 - KL loss: 656.5033 - beta: 1.7989e-05 - val_val_loss: 893374.7500 - val_val_recon_loss: 2.8889e-04 - val_val_KL loss: 655.3126 - val_beta: 1.7989e-05\n",
      "Epoch 2437/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 872193.8430 - recon_loss: 2.8203e-04 - KL loss: 656.3110 - beta: 1.7989e-05 - val_val_loss: 893545.7500 - val_val_recon_loss: 2.8894e-04 - val_val_KL loss: 655.2642 - val_beta: 1.7989e-05\n",
      "Epoch 2438/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 878020.7454 - recon_loss: 2.8392e-04 - KL loss: 655.0615 - beta: 1.7989e-05 - val_val_loss: 893451.6250 - val_val_recon_loss: 2.8891e-04 - val_val_KL loss: 656.1115 - val_beta: 1.7989e-05\n",
      "Epoch 2439/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 877343.5930 - recon_loss: 2.8370e-04 - KL loss: 656.2763 - beta: 1.7989e-05 - val_val_loss: 893956.7500 - val_val_recon_loss: 2.8907e-04 - val_val_KL loss: 656.1252 - val_beta: 1.7989e-05\n",
      "Epoch 2440/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 885346.6459 - recon_loss: 2.8629e-04 - KL loss: 655.8189 - beta: 1.7989e-05\n",
      "Epoch 02440: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 885339.5652 - recon_loss: 2.8628e-04 - KL loss: 655.8196 - beta: 1.7989e-05 - val_val_loss: 894577.8125 - val_val_recon_loss: 2.8927e-04 - val_val_KL loss: 655.8759 - val_beta: 1.7989e-05\n",
      "Epoch 2441/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 876307.2692 - recon_loss: 2.8336e-04 - KL loss: 655.9019 - beta: 1.7989e-05 - val_val_loss: 894033.4375 - val_val_recon_loss: 2.8910e-04 - val_val_KL loss: 655.8933 - val_beta: 1.7989e-05\n",
      "Epoch 2442/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 873442.3495 - recon_loss: 2.8244e-04 - KL loss: 655.5107 - beta: 1.7989e-05 - val_val_loss: 893910.1875 - val_val_recon_loss: 2.8906e-04 - val_val_KL loss: 656.0372 - val_beta: 1.7989e-05\n",
      "Epoch 2443/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 880373.2539 - recon_loss: 2.8468e-04 - KL loss: 656.0058 - beta: 1.7989e-05 - val_val_loss: 893834.8750 - val_val_recon_loss: 2.8903e-04 - val_val_KL loss: 655.8324 - val_beta: 1.7989e-05\n",
      "Epoch 2444/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 879449.9008 - recon_loss: 2.8438e-04 - KL loss: 656.7401 - beta: 1.7989e-05 - val_val_loss: 893762.5000 - val_val_recon_loss: 2.8901e-04 - val_val_KL loss: 656.0566 - val_beta: 1.7989e-05\n",
      "Epoch 2445/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 876022.1249 - recon_loss: 2.8327e-04 - KL loss: 656.6549 - beta: 1.7989e-05\n",
      "Epoch 02445: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 876023.8146 - recon_loss: 2.8327e-04 - KL loss: 656.6544 - beta: 1.7989e-05 - val_val_loss: 893678.1875 - val_val_recon_loss: 2.8898e-04 - val_val_KL loss: 655.8602 - val_beta: 1.7989e-05\n",
      "Epoch 2445/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 282177.5911 - recon_loss: 2.9481e-04 - KL loss: 653.6869 - beta: 3.2360e-05 - val_val_loss: 283704.5312 - val_val_recon_loss: 2.9643e-04 - val_val_KL loss: 625.6135 - val_beta: 3.2360e-05\n",
      "Epoch 2446/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 279273.4223 - recon_loss: 2.9180e-04 - KL loss: 615.3681 - beta: 3.2360e-05 - val_val_loss: 284173.6250 - val_val_recon_loss: 2.9697e-04 - val_val_KL loss: 584.0211 - val_beta: 3.2360e-05\n",
      "Epoch 2447/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 283928.1791 - recon_loss: 2.9672e-04 - KL loss: 575.7451 - beta: 3.2360e-05 - val_val_loss: 287683.4688 - val_val_recon_loss: 3.0067e-04 - val_val_KL loss: 562.4349 - val_beta: 3.2360e-05\n",
      "Epoch 2448/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 284666.2426 - recon_loss: 2.9751e-04 - KL loss: 556.1345 - beta: 3.2360e-05 - val_val_loss: 284301.7500 - val_val_recon_loss: 2.9714e-04 - val_val_KL loss: 547.3989 - val_beta: 3.2360e-05\n",
      "Epoch 2449/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 284516.9771 - recon_loss: 2.9736e-04 - KL loss: 549.1733 - beta: 3.2360e-05 - val_val_loss: 298938.5938 - val_val_recon_loss: 3.1246e-04 - val_val_KL loss: 555.4518 - val_beta: 3.2360e-05\n",
      "Epoch 2450/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 291978.2746 - recon_loss: 3.0518e-04 - KL loss: 545.0239 - beta: 3.2360e-05\n",
      "Epoch 02450: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 291976.1773 - recon_loss: 3.0518e-04 - KL loss: 545.0165 - beta: 3.2360e-05 - val_val_loss: 290850.5312 - val_val_recon_loss: 3.0400e-04 - val_val_KL loss: 542.6628 - val_beta: 3.2360e-05\n",
      "Epoch 2451/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 277598.0853 - recon_loss: 2.9013e-04 - KL loss: 541.7607 - beta: 3.2360e-05 - val_val_loss: 279475.0938 - val_val_recon_loss: 2.9209e-04 - val_val_KL loss: 544.1175 - val_beta: 3.2360e-05\n",
      "Epoch 2452/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 274560.7141 - recon_loss: 2.8694e-04 - KL loss: 543.8881 - beta: 3.2360e-05 - val_val_loss: 277777.6875 - val_val_recon_loss: 2.9031e-04 - val_val_KL loss: 546.7164 - val_beta: 3.2360e-05\n",
      "Epoch 2453/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 272304.2622 - recon_loss: 2.8458e-04 - KL loss: 547.2404 - beta: 3.2360e-05 - val_val_loss: 279607.0938 - val_val_recon_loss: 2.9222e-04 - val_val_KL loss: 549.1418 - val_beta: 3.2360e-05\n",
      "Epoch 2454/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 273964.6315 - recon_loss: 2.8632e-04 - KL loss: 548.1341 - beta: 3.2360e-05 - val_val_loss: 279714.4688 - val_val_recon_loss: 2.9233e-04 - val_val_KL loss: 553.5623 - val_beta: 3.2360e-05\n",
      "Epoch 2455/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 276523.7360 - recon_loss: 2.8899e-04 - KL loss: 554.2873 - beta: 3.2360e-05 - val_val_loss: 282087.1562 - val_val_recon_loss: 2.9481e-04 - val_val_KL loss: 559.7781 - val_beta: 3.2360e-05\n",
      "Epoch 2456/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 278022.4029 - recon_loss: 2.9055e-04 - KL loss: 562.6755 - beta: 3.2360e-05 - val_val_loss: 280565.2188 - val_val_recon_loss: 2.9321e-04 - val_val_KL loss: 564.4656 - val_beta: 3.2360e-05\n",
      "Epoch 2457/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 276061.4717 - recon_loss: 2.8849e-04 - KL loss: 565.9425 - beta: 3.2360e-05\n",
      "Epoch 02457: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 276063.5540 - recon_loss: 2.8850e-04 - KL loss: 565.9453 - beta: 3.2360e-05 - val_val_loss: 288196.7812 - val_val_recon_loss: 3.0119e-04 - val_val_KL loss: 573.0881 - val_beta: 3.2360e-05\n",
      "Epoch 2458/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 280609.8560 - recon_loss: 2.9325e-04 - KL loss: 574.1728 - beta: 3.2360e-05 - val_val_loss: 281059.0625 - val_val_recon_loss: 2.9372e-04 - val_val_KL loss: 575.4836 - val_beta: 3.2360e-05\n",
      "Epoch 2459/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 278361.5425 - recon_loss: 2.9089e-04 - KL loss: 575.1217 - beta: 3.2360e-05 - val_val_loss: 280389.2812 - val_val_recon_loss: 2.9301e-04 - val_val_KL loss: 576.0125 - val_beta: 3.2360e-05\n",
      "Epoch 2460/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 275578.2595 - recon_loss: 2.8798e-04 - KL loss: 575.6297 - beta: 3.2360e-05 - val_val_loss: 278739.6875 - val_val_recon_loss: 2.9129e-04 - val_val_KL loss: 574.4670 - val_beta: 3.2360e-05\n",
      "Epoch 2461/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 273908.0615 - recon_loss: 2.8623e-04 - KL loss: 574.2538 - beta: 3.2360e-05 - val_val_loss: 277555.8750 - val_val_recon_loss: 2.9005e-04 - val_val_KL loss: 573.6417 - val_beta: 3.2360e-05\n",
      "Epoch 2462/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 271362.2075 - recon_loss: 2.8356e-04 - KL loss: 573.0007 - beta: 3.2360e-05 - val_val_loss: 276707.5938 - val_val_recon_loss: 2.8916e-04 - val_val_KL loss: 572.9517 - val_beta: 3.2360e-05\n",
      "Epoch 2463/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 272264.6288 - recon_loss: 2.8451e-04 - KL loss: 573.9384 - beta: 3.2360e-05 - val_val_loss: 276782.5000 - val_val_recon_loss: 2.8924e-04 - val_val_KL loss: 573.4517 - val_beta: 3.2360e-05\n",
      "Epoch 2464/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 272128.5284 - recon_loss: 2.8437e-04 - KL loss: 572.3950 - beta: 3.2360e-05 - val_val_loss: 275955.3125 - val_val_recon_loss: 2.8838e-04 - val_val_KL loss: 569.7417 - val_beta: 3.2360e-05\n",
      "Epoch 2465/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 269416.9791 - recon_loss: 2.8153e-04 - KL loss: 570.0001 - beta: 3.2360e-05 - val_val_loss: 276214.5938 - val_val_recon_loss: 2.8865e-04 - val_val_KL loss: 568.4308 - val_beta: 3.2360e-05\n",
      "Epoch 2466/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 272992.6282 - recon_loss: 2.8527e-04 - KL loss: 570.1818 - beta: 3.2360e-05 - val_val_loss: 275894.9062 - val_val_recon_loss: 2.8831e-04 - val_val_KL loss: 571.4423 - val_beta: 3.2360e-05\n",
      "Epoch 2467/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 270693.4409 - recon_loss: 2.8287e-04 - KL loss: 570.7042 - beta: 3.2360e-05 - val_val_loss: 275596.9688 - val_val_recon_loss: 2.8800e-04 - val_val_KL loss: 570.8421 - val_beta: 3.2360e-05\n",
      "Epoch 2468/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 271100.4293 - recon_loss: 2.8329e-04 - KL loss: 571.6091 - beta: 3.2360e-05 - val_val_loss: 275990.8125 - val_val_recon_loss: 2.8841e-04 - val_val_KL loss: 572.1919 - val_beta: 3.2360e-05\n",
      "Epoch 2469/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 269833.3585 - recon_loss: 2.8197e-04 - KL loss: 571.5120 - beta: 3.2360e-05 - val_val_loss: 276299.9688 - val_val_recon_loss: 2.8874e-04 - val_val_KL loss: 571.3346 - val_beta: 3.2360e-05\n",
      "Epoch 2470/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 269832.3694 - recon_loss: 2.8196e-04 - KL loss: 572.1065 - beta: 3.2360e-05 - val_val_loss: 273593.5312 - val_val_recon_loss: 2.8590e-04 - val_val_KL loss: 570.8616 - val_beta: 3.2360e-05\n",
      "Epoch 2471/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 269973.4001 - recon_loss: 2.8211e-04 - KL loss: 572.7541 - beta: 3.2360e-05 - val_val_loss: 272892.0625 - val_val_recon_loss: 2.8517e-04 - val_val_KL loss: 572.3854 - val_beta: 3.2360e-05\n",
      "Epoch 2472/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 269566.4054 - recon_loss: 2.8168e-04 - KL loss: 572.6980 - beta: 3.2360e-05 - val_val_loss: 272680.0625 - val_val_recon_loss: 2.8495e-04 - val_val_KL loss: 571.2725 - val_beta: 3.2360e-05\n",
      "Epoch 2473/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 267552.7234 - recon_loss: 2.7958e-04 - KL loss: 571.4293 - beta: 3.2360e-05 - val_val_loss: 272149.8750 - val_val_recon_loss: 2.8439e-04 - val_val_KL loss: 570.9525 - val_beta: 3.2360e-05\n",
      "Epoch 2474/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 267315.8947 - recon_loss: 2.7933e-04 - KL loss: 571.2985 - beta: 3.2360e-05 - val_val_loss: 272534.9688 - val_val_recon_loss: 2.8480e-04 - val_val_KL loss: 569.6647 - val_beta: 3.2360e-05\n",
      "Epoch 2475/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264164.2983 - recon_loss: 2.7603e-04 - KL loss: 569.2815 - beta: 3.2360e-05 - val_val_loss: 272307.3750 - val_val_recon_loss: 2.8456e-04 - val_val_KL loss: 569.9006 - val_beta: 3.2360e-05\n",
      "Epoch 2476/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 271013.0736 - recon_loss: 2.8320e-04 - KL loss: 571.7244 - beta: 3.2360e-05 - val_val_loss: 273412.7500 - val_val_recon_loss: 2.8571e-04 - val_val_KL loss: 572.1266 - val_beta: 3.2360e-05\n",
      "Epoch 2477/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266410.7740 - recon_loss: 2.7838e-04 - KL loss: 572.1945 - beta: 3.2360e-05 - val_val_loss: 273983.9688 - val_val_recon_loss: 2.8631e-04 - val_val_KL loss: 569.8759 - val_beta: 3.2360e-05\n",
      "Epoch 2478/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 269958.8075 - recon_loss: 2.8210e-04 - KL loss: 570.8831 - beta: 3.2360e-05\n",
      "Epoch 02478: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 269958.3858 - recon_loss: 2.8210e-04 - KL loss: 570.8830 - beta: 3.2360e-05 - val_val_loss: 272158.0938 - val_val_recon_loss: 2.8440e-04 - val_val_KL loss: 570.5865 - val_beta: 3.2360e-05\n",
      "Epoch 2479/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 267152.2721 - recon_loss: 2.7916e-04 - KL loss: 571.6440 - beta: 3.2360e-05 - val_val_loss: 271890.5000 - val_val_recon_loss: 2.8412e-04 - val_val_KL loss: 570.4731 - val_beta: 3.2360e-05\n",
      "Epoch 2480/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 264914.4218 - recon_loss: 2.7681e-04 - KL loss: 571.6652 - beta: 3.2360e-05 - val_val_loss: 271441.6875 - val_val_recon_loss: 2.8365e-04 - val_val_KL loss: 571.6622 - val_beta: 3.2360e-05\n",
      "Epoch 2481/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264594.6557 - recon_loss: 2.7648e-04 - KL loss: 571.9243 - beta: 3.2360e-05 - val_val_loss: 271470.2500 - val_val_recon_loss: 2.8368e-04 - val_val_KL loss: 572.1317 - val_beta: 3.2360e-05\n",
      "Epoch 2482/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 264677.3513 - recon_loss: 2.7656e-04 - KL loss: 572.3597 - beta: 3.2360e-05 - val_val_loss: 271775.5938 - val_val_recon_loss: 2.8400e-04 - val_val_KL loss: 571.6602 - val_beta: 3.2360e-05\n",
      "Epoch 2483/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 267485.5384 - recon_loss: 2.7951e-04 - KL loss: 572.1812 - beta: 3.2360e-05 - val_val_loss: 271435.9062 - val_val_recon_loss: 2.8364e-04 - val_val_KL loss: 571.9886 - val_beta: 3.2360e-05\n",
      "Epoch 2484/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 267280.5897 - recon_loss: 2.7929e-04 - KL loss: 572.2521 - beta: 3.2360e-05 - val_val_loss: 271738.9375 - val_val_recon_loss: 2.8396e-04 - val_val_KL loss: 571.8267 - val_beta: 3.2360e-05\n",
      "Epoch 2485/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264104.9673 - recon_loss: 2.7597e-04 - KL loss: 571.8300 - beta: 3.2360e-05 - val_val_loss: 271542.3750 - val_val_recon_loss: 2.8375e-04 - val_val_KL loss: 572.2039 - val_beta: 3.2360e-05\n",
      "Epoch 2486/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 267647.7875 - recon_loss: 2.7967e-04 - KL loss: 573.7673 - beta: 3.2360e-05 - val_val_loss: 271805.4375 - val_val_recon_loss: 2.8403e-04 - val_val_KL loss: 573.3004 - val_beta: 3.2360e-05\n",
      "Epoch 2487/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 262897.8587 - recon_loss: 2.7470e-04 - KL loss: 573.7093 - beta: 3.2360e-05 - val_val_loss: 271521.3125 - val_val_recon_loss: 2.8373e-04 - val_val_KL loss: 573.7185 - val_beta: 3.2360e-05\n",
      "Epoch 2488/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 265816.5613 - recon_loss: 2.7776e-04 - KL loss: 573.8025 - beta: 3.2360e-05\n",
      "Epoch 02488: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265817.8246 - recon_loss: 2.7776e-04 - KL loss: 573.8025 - beta: 3.2360e-05 - val_val_loss: 271657.7500 - val_val_recon_loss: 2.8387e-04 - val_val_KL loss: 574.0180 - val_beta: 3.2360e-05\n",
      "Epoch 2489/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264051.8869 - recon_loss: 2.7591e-04 - KL loss: 573.6161 - beta: 3.2360e-05 - val_val_loss: 271287.5938 - val_val_recon_loss: 2.8349e-04 - val_val_KL loss: 573.6197 - val_beta: 3.2360e-05\n",
      "Epoch 2490/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266899.6791 - recon_loss: 2.7889e-04 - KL loss: 573.6098 - beta: 3.2360e-05 - val_val_loss: 271234.5000 - val_val_recon_loss: 2.8343e-04 - val_val_KL loss: 573.7648 - val_beta: 3.2360e-05\n",
      "Epoch 2491/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266739.6813 - recon_loss: 2.7872e-04 - KL loss: 574.2400 - beta: 3.2360e-05 - val_val_loss: 271687.5938 - val_val_recon_loss: 2.8390e-04 - val_val_KL loss: 574.0987 - val_beta: 3.2360e-05\n",
      "Epoch 2492/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 264950.1915 - recon_loss: 2.7685e-04 - KL loss: 574.2711 - beta: 3.2360e-05 - val_val_loss: 271178.1250 - val_val_recon_loss: 2.8337e-04 - val_val_KL loss: 574.1799 - val_beta: 3.2360e-05\n",
      "Epoch 2493/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 264772.7117 - recon_loss: 2.7666e-04 - KL loss: 574.1927 - beta: 3.2360e-05 - val_val_loss: 271273.0625 - val_val_recon_loss: 2.8347e-04 - val_val_KL loss: 574.2121 - val_beta: 3.2360e-05\n",
      "Epoch 2494/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 263978.8305 - recon_loss: 2.7583e-04 - KL loss: 573.5580 - beta: 3.2360e-05 - val_val_loss: 271153.0625 - val_val_recon_loss: 2.8334e-04 - val_val_KL loss: 573.9656 - val_beta: 3.2360e-05\n",
      "Epoch 2495/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265327.5473 - recon_loss: 2.7724e-04 - KL loss: 574.0343 - beta: 3.2360e-05 - val_val_loss: 271280.8750 - val_val_recon_loss: 2.8348e-04 - val_val_KL loss: 574.5823 - val_beta: 3.2360e-05\n",
      "Epoch 2496/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265929.4200 - recon_loss: 2.7787e-04 - KL loss: 574.3404 - beta: 3.2360e-05 - val_val_loss: 271019.4062 - val_val_recon_loss: 2.8320e-04 - val_val_KL loss: 574.4773 - val_beta: 3.2360e-05\n",
      "Epoch 2497/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266773.6585 - recon_loss: 2.7876e-04 - KL loss: 574.6724 - beta: 3.2360e-05 - val_val_loss: 270989.3750 - val_val_recon_loss: 2.8317e-04 - val_val_KL loss: 574.3219 - val_beta: 3.2360e-05\n",
      "Epoch 2498/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 266501.3264 - recon_loss: 2.7847e-04 - KL loss: 574.4012 - beta: 3.2360e-05 - val_val_loss: 271163.6875 - val_val_recon_loss: 2.8336e-04 - val_val_KL loss: 574.2444 - val_beta: 3.2360e-05\n",
      "Epoch 2499/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 263995.8588 - recon_loss: 2.7585e-04 - KL loss: 574.6972 - beta: 3.2360e-05 - val_val_loss: 271235.6562 - val_val_recon_loss: 2.8343e-04 - val_val_KL loss: 574.7355 - val_beta: 3.2360e-05\n",
      "Epoch 2500/10000\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 264336.1354 - recon_loss: 2.7621e-04 - KL loss: 574.5448 - beta: 3.2360e-05 - val_val_loss: 271165.5625 - val_val_recon_loss: 2.8336e-04 - val_val_KL loss: 574.5131 - val_beta: 3.2360e-05\n",
      "Epoch 2501/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265736.9885 - recon_loss: 2.7767e-04 - KL loss: 575.9039 - beta: 3.2360e-05 - val_val_loss: 271031.3750 - val_val_recon_loss: 2.8322e-04 - val_val_KL loss: 574.9777 - val_beta: 3.2360e-05\n",
      "Epoch 2502/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 263428.4070 - recon_loss: 2.7525e-04 - KL loss: 575.1283 - beta: 3.2360e-05\n",
      "Epoch 02502: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 263430.4929 - recon_loss: 2.7526e-04 - KL loss: 575.1286 - beta: 3.2360e-05 - val_val_loss: 271110.3750 - val_val_recon_loss: 2.8330e-04 - val_val_KL loss: 574.9935 - val_beta: 3.2360e-05\n",
      "Epoch 2503/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 266775.8994 - recon_loss: 2.7876e-04 - KL loss: 576.2317 - beta: 3.2360e-05 - val_val_loss: 271054.6250 - val_val_recon_loss: 2.8324e-04 - val_val_KL loss: 574.8461 - val_beta: 3.2360e-05\n",
      "Epoch 2504/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 265205.4625 - recon_loss: 2.7712e-04 - KL loss: 575.2466 - beta: 3.2360e-05 - val_val_loss: 271098.2188 - val_val_recon_loss: 2.8329e-04 - val_val_KL loss: 574.7294 - val_beta: 3.2360e-05\n",
      "Epoch 2505/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 267734.5861 - recon_loss: 2.7976e-04 - KL loss: 575.0524 - beta: 3.2360e-05 - val_val_loss: 271221.9688 - val_val_recon_loss: 2.8342e-04 - val_val_KL loss: 574.9198 - val_beta: 3.2360e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2506/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 264340.1816 - recon_loss: 2.7621e-04 - KL loss: 574.9579 - beta: 3.2360e-05 - val_val_loss: 271151.0312 - val_val_recon_loss: 2.8334e-04 - val_val_KL loss: 574.8605 - val_beta: 3.2360e-05\n",
      "Epoch 2507/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 262778.1948 - recon_loss: 2.7457e-04 - KL loss: 575.4402 - beta: 3.2360e-05\n",
      "Epoch 02507: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 262780.0092 - recon_loss: 2.7457e-04 - KL loss: 575.4403 - beta: 3.2360e-05 - val_val_loss: 271136.1562 - val_val_recon_loss: 2.8333e-04 - val_val_KL loss: 574.9332 - val_beta: 3.2360e-05\n",
      "Epoch 2507/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 85200.3785 - recon_loss: 2.8682e-04 - KL loss: 559.0300 - beta: 5.8212e-05 - val_val_loss: 87768.2500 - val_val_recon_loss: 2.9565e-04 - val_val_KL loss: 523.1606 - val_beta: 5.8212e-05\n",
      "Epoch 2508/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 87260.9803 - recon_loss: 2.9396e-04 - KL loss: 513.9755 - beta: 5.8212e-05 - val_val_loss: 89802.1406 - val_val_recon_loss: 3.0265e-04 - val_val_KL loss: 491.0803 - val_beta: 5.8212e-05\n",
      "Epoch 2509/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 89299.9869 - recon_loss: 3.0094e-04 - KL loss: 491.1847 - beta: 5.8212e-05 - val_val_loss: 89969.7500 - val_val_recon_loss: 3.0326e-04 - val_val_KL loss: 477.4188 - val_beta: 5.8212e-05\n",
      "Epoch 2510/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 88162.8581 - recon_loss: 2.9718e-04 - KL loss: 466.4533 - beta: 5.8212e-05 - val_val_loss: 87133.0391 - val_val_recon_loss: 2.9370e-04 - val_val_KL loss: 461.5467 - val_beta: 5.8212e-05\n",
      "Epoch 2511/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 87796.6684 - recon_loss: 2.9593e-04 - KL loss: 467.7728 - beta: 5.8212e-05 - val_val_loss: 89928.8672 - val_val_recon_loss: 3.0313e-04 - val_val_KL loss: 476.1548 - val_beta: 5.8212e-05\n",
      "Epoch 2512/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 89453.9218 - recon_loss: 3.0150e-04 - KL loss: 480.6314 - beta: 5.8212e-05 - val_val_loss: 94102.7422 - val_val_recon_loss: 3.1727e-04 - val_val_KL loss: 477.1838 - val_beta: 5.8212e-05\n",
      "Epoch 2513/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 99412.2671 - recon_loss: 3.3516e-04 - KL loss: 505.3603 - beta: 5.8212e-05 - val_val_loss: 98183.1406 - val_val_recon_loss: 3.3104e-04 - val_val_KL loss: 492.1324 - val_beta: 5.8212e-05\n",
      "Epoch 2514/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 95169.1400 - recon_loss: 3.2089e-04 - KL loss: 474.0261 - beta: 5.8212e-05 - val_val_loss: 91140.0391 - val_val_recon_loss: 3.0725e-04 - val_val_KL loss: 471.7370 - val_beta: 5.8212e-05\n",
      "Epoch 2515/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 89277.0118 - recon_loss: 3.0097e-04 - KL loss: 461.8648 - beta: 5.8212e-05\n",
      "Epoch 02515: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 89276.3292 - recon_loss: 3.0096e-04 - KL loss: 461.8646 - beta: 5.8212e-05 - val_val_loss: 88973.9375 - val_val_recon_loss: 2.9992e-04 - val_val_KL loss: 466.6274 - val_beta: 5.8212e-05\n",
      "Epoch 2516/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 84444.9538 - recon_loss: 2.8457e-04 - KL loss: 469.4992 - beta: 5.8212e-05 - val_val_loss: 85024.0312 - val_val_recon_loss: 2.8652e-04 - val_val_KL loss: 473.1319 - val_beta: 5.8212e-05\n",
      "Epoch 2517/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 84242.9881 - recon_loss: 2.8386e-04 - KL loss: 475.7279 - beta: 5.8212e-05 - val_val_loss: 84466.0469 - val_val_recon_loss: 2.8462e-04 - val_val_KL loss: 474.6087 - val_beta: 5.8212e-05\n",
      "Epoch 2518/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 83236.9994 - recon_loss: 2.8044e-04 - KL loss: 479.0911 - beta: 5.8212e-05 - val_val_loss: 83890.5234 - val_val_recon_loss: 2.8266e-04 - val_val_KL loss: 477.6901 - val_beta: 5.8212e-05\n",
      "Epoch 2519/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 82447.2632 - recon_loss: 2.7777e-04 - KL loss: 477.9153 - beta: 5.8212e-05 - val_val_loss: 83685.6094 - val_val_recon_loss: 2.8197e-04 - val_val_KL loss: 477.0750 - val_beta: 5.8212e-05\n",
      "Epoch 2520/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81990.5922 - recon_loss: 2.7623e-04 - KL loss: 474.3635 - beta: 5.8212e-05 - val_val_loss: 84030.1797 - val_val_recon_loss: 2.8315e-04 - val_val_KL loss: 471.6098 - val_beta: 5.8212e-05\n",
      "Epoch 2521/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 82870.4948 - recon_loss: 2.7923e-04 - KL loss: 470.8229 - beta: 5.8212e-05 - val_val_loss: 82836.4375 - val_val_recon_loss: 2.7911e-04 - val_val_KL loss: 469.8975 - val_beta: 5.8212e-05\n",
      "Epoch 2522/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81624.1372 - recon_loss: 2.7500e-04 - KL loss: 472.1822 - beta: 5.8212e-05 - val_val_loss: 82527.0000 - val_val_recon_loss: 2.7805e-04 - val_val_KL loss: 475.3277 - val_beta: 5.8212e-05\n",
      "Epoch 2523/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 82398.3259 - recon_loss: 2.7762e-04 - KL loss: 471.5304 - beta: 5.8212e-05 - val_val_loss: 82506.3516 - val_val_recon_loss: 2.7798e-04 - val_val_KL loss: 474.5482 - val_beta: 5.8212e-05\n",
      "Epoch 2524/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 81238.0178 - recon_loss: 2.7369e-04 - KL loss: 471.9924 - beta: 5.8212e-05 - val_val_loss: 82681.1562 - val_val_recon_loss: 2.7860e-04 - val_val_KL loss: 467.0157 - val_beta: 5.8212e-05\n",
      "Epoch 2525/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81589.0100 - recon_loss: 2.7488e-04 - KL loss: 470.9693 - beta: 5.8212e-05 - val_val_loss: 82314.5391 - val_val_recon_loss: 2.7734e-04 - val_val_KL loss: 472.0271 - val_beta: 5.8212e-05\n",
      "Epoch 2526/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 81128.4288 - recon_loss: 2.7332e-04 - KL loss: 472.6751 - beta: 5.8212e-05 - val_val_loss: 81830.0703 - val_val_recon_loss: 2.7568e-04 - val_val_KL loss: 476.7408 - val_beta: 5.8212e-05\n",
      "Epoch 2527/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 80793.0068 - recon_loss: 2.7217e-04 - KL loss: 476.2956 - beta: 5.8212e-05 - val_val_loss: 82349.2500 - val_val_recon_loss: 2.7745e-04 - val_val_KL loss: 474.0510 - val_beta: 5.8212e-05\n",
      "Epoch 2528/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 80188.5287 - recon_loss: 2.7012e-04 - KL loss: 475.0780 - beta: 5.8212e-05 - val_val_loss: 81948.0000 - val_val_recon_loss: 2.7609e-04 - val_val_KL loss: 473.5084 - val_beta: 5.8212e-05\n",
      "Epoch 2529/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81302.3196 - recon_loss: 2.7390e-04 - KL loss: 475.0602 - beta: 5.8212e-05 - val_val_loss: 81895.3984 - val_val_recon_loss: 2.7590e-04 - val_val_KL loss: 477.1858 - val_beta: 5.8212e-05\n",
      "Epoch 2530/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80790.6785 - recon_loss: 2.7216e-04 - KL loss: 476.9966 - beta: 5.8212e-05 - val_val_loss: 82673.4766 - val_val_recon_loss: 2.7853e-04 - val_val_KL loss: 480.3725 - val_beta: 5.8212e-05\n",
      "Epoch 2531/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 81364.0261 - recon_loss: 2.7410e-04 - KL loss: 478.5328 - beta: 5.8212e-05\n",
      "Epoch 02531: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 81364.1750 - recon_loss: 2.7410e-04 - KL loss: 478.5336 - beta: 5.8212e-05 - val_val_loss: 83232.7734 - val_val_recon_loss: 2.8041e-04 - val_val_KL loss: 483.4545 - val_beta: 5.8212e-05\n",
      "Epoch 2532/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80298.9295 - recon_loss: 2.7047e-04 - KL loss: 482.4870 - beta: 5.8212e-05 - val_val_loss: 81224.0000 - val_val_recon_loss: 2.7360e-04 - val_val_KL loss: 483.5193 - val_beta: 5.8212e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2533/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 80324.8313 - recon_loss: 2.7055e-04 - KL loss: 484.0915 - beta: 5.8212e-05 - val_val_loss: 81185.7969 - val_val_recon_loss: 2.7348e-04 - val_val_KL loss: 481.9892 - val_beta: 5.8212e-05\n",
      "Epoch 2534/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80672.7840 - recon_loss: 2.7174e-04 - KL loss: 483.1789 - beta: 5.8212e-05 - val_val_loss: 81078.6094 - val_val_recon_loss: 2.7311e-04 - val_val_KL loss: 485.1581 - val_beta: 5.8212e-05\n",
      "Epoch 2535/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 79657.8084 - recon_loss: 2.6830e-04 - KL loss: 483.8371 - beta: 5.8212e-05 - val_val_loss: 81365.9219 - val_val_recon_loss: 2.7407e-04 - val_val_KL loss: 486.6000 - val_beta: 5.8212e-05\n",
      "Epoch 2536/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80004.3853 - recon_loss: 2.6946e-04 - KL loss: 485.7593 - beta: 5.8212e-05 - val_val_loss: 81098.2812 - val_val_recon_loss: 2.7316e-04 - val_val_KL loss: 487.4651 - val_beta: 5.8212e-05\n",
      "Epoch 2537/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79417.6842 - recon_loss: 2.6747e-04 - KL loss: 487.0960 - beta: 5.8212e-05 - val_val_loss: 80967.5312 - val_val_recon_loss: 2.7273e-04 - val_val_KL loss: 485.9956 - val_beta: 5.8212e-05\n",
      "Epoch 2538/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80329.2431 - recon_loss: 2.7056e-04 - KL loss: 485.9922 - beta: 5.8212e-05 - val_val_loss: 80786.2344 - val_val_recon_loss: 2.7211e-04 - val_val_KL loss: 485.8827 - val_beta: 5.8212e-05\n",
      "Epoch 2539/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80105.0206 - recon_loss: 2.6980e-04 - KL loss: 486.1826 - beta: 5.8212e-05 - val_val_loss: 80873.4609 - val_val_recon_loss: 2.7241e-04 - val_val_KL loss: 486.5912 - val_beta: 5.8212e-05\n",
      "Epoch 2540/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 80121.3623 - recon_loss: 2.6986e-04 - KL loss: 486.1222 - beta: 5.8212e-05 - val_val_loss: 80444.6562 - val_val_recon_loss: 2.7096e-04 - val_val_KL loss: 485.3160 - val_beta: 5.8212e-05\n",
      "Epoch 2541/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79071.7275 - recon_loss: 2.6630e-04 - KL loss: 486.2814 - beta: 5.8212e-05 - val_val_loss: 80581.9062 - val_val_recon_loss: 2.7141e-04 - val_val_KL loss: 487.9920 - val_beta: 5.8212e-05\n",
      "Epoch 2542/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 79643.1437 - recon_loss: 2.6824e-04 - KL loss: 486.4040 - beta: 5.8212e-05 - val_val_loss: 80482.1719 - val_val_recon_loss: 2.7108e-04 - val_val_KL loss: 486.7122 - val_beta: 5.8212e-05\n",
      "Epoch 2543/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79228.1205 - recon_loss: 2.6684e-04 - KL loss: 484.4713 - beta: 5.8212e-05 - val_val_loss: 80505.8984 - val_val_recon_loss: 2.7116e-04 - val_val_KL loss: 485.7428 - val_beta: 5.8212e-05\n",
      "Epoch 2544/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79829.8216 - recon_loss: 2.6887e-04 - KL loss: 487.0747 - beta: 5.8212e-05 - val_val_loss: 80698.9531 - val_val_recon_loss: 2.7182e-04 - val_val_KL loss: 484.7943 - val_beta: 5.8212e-05\n",
      "Epoch 2545/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 79222.4387 - recon_loss: 2.6682e-04 - KL loss: 485.0322 - beta: 5.8212e-05\n",
      "Epoch 02545: ReduceLROnPlateau reducing learning rate to 9.48683259704384e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79222.5676 - recon_loss: 2.6682e-04 - KL loss: 485.0328 - beta: 5.8212e-05 - val_val_loss: 80693.6016 - val_val_recon_loss: 2.7180e-04 - val_val_KL loss: 485.9272 - val_beta: 5.8212e-05\n",
      "Epoch 2546/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78894.3517 - recon_loss: 2.6570e-04 - KL loss: 486.3081 - beta: 5.8212e-05 - val_val_loss: 80227.4062 - val_val_recon_loss: 2.7022e-04 - val_val_KL loss: 485.0730 - val_beta: 5.8212e-05\n",
      "Epoch 2547/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78938.7252 - recon_loss: 2.6585e-04 - KL loss: 485.9889 - beta: 5.8212e-05 - val_val_loss: 80147.4688 - val_val_recon_loss: 2.6995e-04 - val_val_KL loss: 486.5014 - val_beta: 5.8212e-05\n",
      "Epoch 2548/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79448.4417 - recon_loss: 2.6758e-04 - KL loss: 486.3103 - beta: 5.8212e-05 - val_val_loss: 80166.2969 - val_val_recon_loss: 2.7002e-04 - val_val_KL loss: 484.8665 - val_beta: 5.8212e-05\n",
      "Epoch 2549/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 78694.8263 - recon_loss: 2.6503e-04 - KL loss: 484.9518 - beta: 5.8212e-05 - val_val_loss: 79951.5312 - val_val_recon_loss: 2.6929e-04 - val_val_KL loss: 485.5802 - val_beta: 5.8212e-05\n",
      "Epoch 2550/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78316.4568 - recon_loss: 2.6374e-04 - KL loss: 485.7831 - beta: 5.8212e-05 - val_val_loss: 79943.9062 - val_val_recon_loss: 2.6926e-04 - val_val_KL loss: 485.1504 - val_beta: 5.8212e-05\n",
      "Epoch 2551/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78116.5005 - recon_loss: 2.6307e-04 - KL loss: 484.9877 - beta: 5.8212e-05 - val_val_loss: 80053.1328 - val_val_recon_loss: 2.6963e-04 - val_val_KL loss: 485.8207 - val_beta: 5.8212e-05\n",
      "Epoch 2552/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78262.1167 - recon_loss: 2.6356e-04 - KL loss: 485.8830 - beta: 5.8212e-05 - val_val_loss: 80110.3594 - val_val_recon_loss: 2.6983e-04 - val_val_KL loss: 485.0107 - val_beta: 5.8212e-05\n",
      "Epoch 2553/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78484.5308 - recon_loss: 2.6432e-04 - KL loss: 484.9433 - beta: 5.8212e-05 - val_val_loss: 80023.7812 - val_val_recon_loss: 2.6953e-04 - val_val_KL loss: 485.8507 - val_beta: 5.8212e-05\n",
      "Epoch 2554/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78304.6504 - recon_loss: 2.6370e-04 - KL loss: 485.9629 - beta: 5.8212e-05 - val_val_loss: 79984.7734 - val_val_recon_loss: 2.6939e-04 - val_val_KL loss: 486.5711 - val_beta: 5.8212e-05\n",
      "Epoch 2555/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 78132.9516 - recon_loss: 2.6312e-04 - KL loss: 485.8073 - beta: 5.8212e-05\n",
      "Epoch 02555: ReduceLROnPlateau reducing learning rate to 2.9999998064878395e-07.\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78133.3140 - recon_loss: 2.6312e-04 - KL loss: 485.8077 - beta: 5.8212e-05 - val_val_loss: 80034.7656 - val_val_recon_loss: 2.6957e-04 - val_val_KL loss: 486.1093 - val_beta: 5.8212e-05\n",
      "Epoch 2556/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 79113.8664 - recon_loss: 2.6644e-04 - KL loss: 487.1619 - beta: 5.8212e-05 - val_val_loss: 79909.4062 - val_val_recon_loss: 2.6914e-04 - val_val_KL loss: 486.8780 - val_beta: 5.8212e-05\n",
      "Epoch 2557/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78289.1181 - recon_loss: 2.6365e-04 - KL loss: 486.6589 - beta: 5.8212e-05 - val_val_loss: 79879.0000 - val_val_recon_loss: 2.6904e-04 - val_val_KL loss: 486.5330 - val_beta: 5.8212e-05\n",
      "Epoch 2558/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78920.0017 - recon_loss: 2.6579e-04 - KL loss: 486.5030 - beta: 5.8212e-05 - val_val_loss: 79894.0781 - val_val_recon_loss: 2.6909e-04 - val_val_KL loss: 486.7914 - val_beta: 5.8212e-05\n",
      "Epoch 2559/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 78551.1028 - recon_loss: 2.6453e-04 - KL loss: 487.4214 - beta: 5.8212e-05 - val_val_loss: 79905.2266 - val_val_recon_loss: 2.6912e-04 - val_val_KL loss: 486.8318 - val_beta: 5.8212e-05\n",
      "Epoch 2560/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 78722.2727 - recon_loss: 2.6511e-04 - KL loss: 486.9353 - beta: 5.8212e-05 - val_val_loss: 79848.6484 - val_val_recon_loss: 2.6893e-04 - val_val_KL loss: 486.5870 - val_beta: 5.8212e-05\n",
      "Epoch 2561/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78455.8972 - recon_loss: 2.6421e-04 - KL loss: 486.6996 - beta: 5.8212e-05 - val_val_loss: 79866.1641 - val_val_recon_loss: 2.6899e-04 - val_val_KL loss: 486.7551 - val_beta: 5.8212e-05\n",
      "Epoch 2562/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 78783.2251 - recon_loss: 2.6532e-04 - KL loss: 486.8215 - beta: 5.8212e-05 - val_val_loss: 79846.4688 - val_val_recon_loss: 2.6892e-04 - val_val_KL loss: 486.8573 - val_beta: 5.8212e-05\n",
      "Epoch 2563/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78517.5607 - recon_loss: 2.6442e-04 - KL loss: 486.9429 - beta: 5.8212e-05 - val_val_loss: 79875.4531 - val_val_recon_loss: 2.6902e-04 - val_val_KL loss: 486.7966 - val_beta: 5.8212e-05\n",
      "Epoch 2564/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78436.6378 - recon_loss: 2.6415e-04 - KL loss: 487.2449 - beta: 5.8212e-05 - val_val_loss: 79875.7422 - val_val_recon_loss: 2.6902e-04 - val_val_KL loss: 486.7436 - val_beta: 5.8212e-05\n",
      "Epoch 2565/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 77971.9721 - recon_loss: 2.6257e-04 - KL loss: 486.2575 - beta: 5.8212e-05 - val_val_loss: 79824.1250 - val_val_recon_loss: 2.6885e-04 - val_val_KL loss: 486.4280 - val_beta: 5.8212e-05\n",
      "Epoch 2566/10000\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 78379.9974 - recon_loss: 2.6396e-04 - KL loss: 485.8361 - beta: 5.8212e-05 - val_val_loss: 79809.3281 - val_val_recon_loss: 2.6880e-04 - val_val_KL loss: 486.8463 - val_beta: 5.8212e-05\n",
      "Epoch 2567/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 77738.9833 - recon_loss: 2.6178e-04 - KL loss: 486.3182 - beta: 5.8212e-05 - val_val_loss: 79806.3672 - val_val_recon_loss: 2.6879e-04 - val_val_KL loss: 486.7211 - val_beta: 5.8212e-05\n",
      "Epoch 2568/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78849.8373 - recon_loss: 2.6555e-04 - KL loss: 487.0943 - beta: 5.8212e-05 - val_val_loss: 79774.1016 - val_val_recon_loss: 2.6868e-04 - val_val_KL loss: 487.2054 - val_beta: 5.8212e-05\n",
      "Epoch 2569/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78047.2842 - recon_loss: 2.6283e-04 - KL loss: 487.0622 - beta: 5.8212e-05 - val_val_loss: 79730.7109 - val_val_recon_loss: 2.6853e-04 - val_val_KL loss: 487.0976 - val_beta: 5.8212e-05\n",
      "Epoch 2570/10000\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 78188.3821 - recon_loss: 2.6331e-04 - KL loss: 486.5964 - beta: 5.8212e-05 - val_val_loss: 79751.0469 - val_val_recon_loss: 2.6860e-04 - val_val_KL loss: 486.8380 - val_beta: 5.8212e-05\n",
      "Epoch 2571/10000\n",
      "1000/1000 [==============================] - 126s 126ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2572/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2573/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2574/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05\n",
      "Epoch 02574: ReduceLROnPlateau reducing learning rate to 9.486832417289166e-08.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2575/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2576/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2577/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2578/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2579/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05\n",
      "Epoch 02579: ReduceLROnPlateau reducing learning rate to 2.9999998963651765e-08.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 5.8212e-05 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 5.8212e-05\n",
      "Epoch 2579/10000\n",
      "1000/1000 [==============================] - 127s 127ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2580/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2581/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2582/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2583/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04\n",
      "Epoch 02583: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2584/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2585/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2586/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2587/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2588/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04\n",
      "Epoch 02588: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.0472e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.0472e-04\n",
      "Epoch 2588/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2589/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2590/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2591/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2592/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04\n",
      "Epoch 02592: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2593/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2594/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2595/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2596/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2597/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04\n",
      "Epoch 02597: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 1.8838e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 1.8838e-04\n",
      "Epoch 2597/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2598/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2599/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2600/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2601/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04\n",
      "Epoch 02601: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2602/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2603/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2604/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2605/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2606/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04\n",
      "Epoch 02606: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 3.3887e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 3.3887e-04\n",
      "Epoch 2606/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2607/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2608/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2609/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2610/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04\n",
      "Epoch 02610: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2611/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2612/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2613/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2614/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2615/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04\n",
      "Epoch 02615: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 6.0959e-04 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 6.0959e-04\n",
      "Epoch 2615/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2616/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2617/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2618/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2619/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011\n",
      "Epoch 02619: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2620/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2621/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2622/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2623/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2624/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011\n",
      "Epoch 02624: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0011 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0011\n",
      "Epoch 2624/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2625/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2626/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2627/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2628/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020\n",
      "Epoch 02628: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2629/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2630/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2631/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2632/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2633/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020\n",
      "Epoch 02633: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0020 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0020\n",
      "Epoch 2633/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2634/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2635/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2636/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2637/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035\n",
      "Epoch 02637: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2638/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2639/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2640/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2641/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2642/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035\n",
      "Epoch 02642: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0035 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0035\n",
      "Epoch 2642/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2643/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2644/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2645/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2646/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064\n",
      "Epoch 02646: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2647/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2648/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2649/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2650/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2651/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064\n",
      "Epoch 02651: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0064 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0064\n",
      "Epoch 2651/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2652/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2653/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2654/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2655/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115\n",
      "Epoch 02655: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2656/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2657/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2658/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2659/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2660/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115\n",
      "Epoch 02660: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0115 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0115\n",
      "Epoch 2660/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2661/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2662/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2663/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2664/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207\n",
      "Epoch 02664: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2665/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2666/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2667/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2668/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2669/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207\n",
      "Epoch 02669: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0207 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0207\n",
      "Epoch 2669/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2670/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2671/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2672/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2673/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372\n",
      "Epoch 02673: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2674/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2675/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2676/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2677/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2678/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372\n",
      "Epoch 02678: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0372 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0372\n",
      "Epoch 2678/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2679/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2680/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2681/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2682/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668\n",
      "Epoch 02682: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2683/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2684/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2685/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2686/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2687/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668\n",
      "Epoch 02687: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.0668 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.0668\n",
      "Epoch 2687/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2688/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2689/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2690/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2691/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202\n",
      "Epoch 02691: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2692/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2693/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2694/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2695/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2696/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202\n",
      "Epoch 02696: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.1202 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.1202\n",
      "Epoch 2696/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2697/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2698/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2699/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2700/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163\n",
      "Epoch 02700: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2701/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2702/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2703/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2704/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2705/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163\n",
      "Epoch 02705: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.2163 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.2163\n",
      "Epoch 2705/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2706/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2707/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2708/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2709/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891\n",
      "Epoch 02709: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2710/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2711/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2712/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2713/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2714/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891\n",
      "Epoch 02714: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.3891 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.3891\n",
      "Epoch 2714/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2715/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2716/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2717/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2718/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000\n",
      "Epoch 02718: ReduceLROnPlateau reducing learning rate to 9.486832740847579e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2719/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2720/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2721/10000\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2722/10000\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n",
      "Epoch 2723/10000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000\n",
      "Epoch 02723: ReduceLROnPlateau reducing learning rate to 2.9999999502915785e-06.\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: nan - recon_loss: nan - KL loss: nan - beta: 0.7000 - val_val_loss: nan - val_val_recon_loss: nan - val_val_KL loss: nan - val_beta: 0.7000\n"
     ]
    }
   ],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_val_loss', min_delta=0., patience=10, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "\n",
    "for beta in np.concatenate((np.logspace(-4,np.log10(0.7),15),\n",
    "               np.logspace(np.log10(0.7),-5,20)[1:],\n",
    "                np.logspace(-5,np.log10(0.7),20)[1:])):\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,3e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b956daf2b92b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'my_history' is not defined"
     ]
    }
   ],
   "source": [
    "my_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.94342112e-01, -8.01087950e-03, -9.59239693e-02,\n",
       "         5.94732045e-01],\n",
       "       [ 3.20266890e-01,  1.36259927e-02,  1.71835828e-01,\n",
       "         3.20508258e-01],\n",
       "       [ 2.70634347e-02, -5.70251954e-02,  2.03458772e-01,\n",
       "         2.71074501e-02],\n",
       "       [ 1.67915073e-02, -5.83480486e-02,  1.27207984e-01,\n",
       "         1.68200987e-02],\n",
       "       [ 1.65186960e-02,  5.90673387e-02, -1.34921235e-01,\n",
       "         1.65475208e-02],\n",
       "       [ 4.71925992e-03,  9.60208657e-01,  2.47662626e-01,\n",
       "         7.06722029e-03],\n",
       "       [ 4.24085623e-03, -6.37045126e-02, -1.61667501e-01,\n",
       "         4.24946440e-03],\n",
       "       [ 3.17943365e-03, -3.47312263e-01, -8.84293165e-01,\n",
       "         3.37312991e-03],\n",
       "       [ 3.15840949e-03,  1.84969735e-02, -2.06772569e-01,\n",
       "         3.15894981e-03],\n",
       "       [ 2.70254265e-03, -8.54734571e-01,  1.71867674e-01,\n",
       "         3.75132707e-03],\n",
       "       [ 1.88874218e-03,  7.52684646e-01, -2.48769901e-01,\n",
       "         2.44950139e-03],\n",
       "       [ 1.53140233e-03, -5.97810065e-01, -2.43046386e-01,\n",
       "         2.42206498e-03],\n",
       "       [ 9.73207088e-04,  2.45642873e-03,  4.44749771e-01,\n",
       "         9.73210024e-04],\n",
       "       [ 9.48412427e-04,  1.52024855e-01,  1.22599145e-01,\n",
       "         9.59393195e-04],\n",
       "       [ 6.04432723e-04,  2.90407388e-01, -3.44442884e-01,\n",
       "         6.30100212e-04],\n",
       "       [ 3.97123277e-04, -2.05377039e-01, -9.00767365e-01,\n",
       "         4.05528033e-04],\n",
       "       [ 2.90979703e-04, -5.48501009e-01, -4.66053749e-01,\n",
       "         3.35859268e-04],\n",
       "       [ 1.98330908e-04, -2.77912763e-01, -6.78513741e-01,\n",
       "         2.06039425e-04],\n",
       "       [ 1.01832898e-04,  1.95487263e-01,  2.22977253e-01,\n",
       "         1.03784888e-04],\n",
       "       [ 4.74774761e-05,  7.16436690e-01, -1.76010884e-01,\n",
       "         6.01923111e-05],\n",
       "       [ 3.49167341e-05, -4.07727633e-01,  3.25300168e-01,\n",
       "         3.78594754e-05],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[344577]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4.75817262e-01,  2.66602718e-02,  9.90336365e-01,\n",
       "         -1.38686278e-01, -7.42237833e-01],\n",
       "        [ 3.78478884e-01, -1.23382600e-02,  9.84472615e-01,\n",
       "          1.75538232e-01, -9.71309188e-01],\n",
       "        [ 3.88847388e-02, -5.61368658e-02,  9.98044277e-01,\n",
       "          6.25109604e-02, -3.24557832e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01]],\n",
       "\n",
       "       [[ 9.21532888e-01, -3.50221957e-02,  9.99996328e-01,\n",
       "         -2.70998044e-03, -8.09998991e-02],\n",
       "        [ 1.66717116e-02,  1.09351969e-01,  9.99491337e-01,\n",
       "          3.18914776e-02, -4.08241210e+00],\n",
       "        [ 1.05050968e-02, -3.16219896e-02,  9.90696950e-01,\n",
       "          1.36086569e-01, -4.54110070e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01]],\n",
       "\n",
       "       [[ 5.27065277e-01, -4.65420074e-02,  9.92720395e-01,\n",
       "          1.20441759e-01, -6.39315265e-01],\n",
       "        [ 3.74650562e-01,  6.47182471e-02,  9.86742438e-01,\n",
       "         -1.62294057e-01, -9.79346033e-01],\n",
       "        [ 6.26936816e-02, -5.41253648e-02,  9.99769673e-01,\n",
       "          2.14616040e-02, -2.76782812e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 5.04941221e-01, -1.45442798e-01,  9.99076107e-01,\n",
       "          4.29759453e-02, -6.72323535e-01],\n",
       "        [ 4.27118872e-01,  1.54132651e-01,  9.99063081e-01,\n",
       "         -4.32777017e-02, -8.38376622e-01],\n",
       "        [ 2.77872638e-02,  2.26747931e-01,  9.97389692e-01,\n",
       "         -7.22066638e-02, -3.55423968e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01]],\n",
       "\n",
       "       [[ 5.03551740e-01, -9.53539035e-02,  9.98895825e-01,\n",
       "         -4.69801207e-02, -6.80969432e-01],\n",
       "        [ 3.49003398e-01,  1.63410362e-01,  9.95083541e-01,\n",
       "          9.90391174e-02, -1.03919140e+00],\n",
       "        [ 8.58754468e-02, -3.58760659e-02,  9.94611172e-01,\n",
       "         -1.03675535e-01, -2.45308432e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01]],\n",
       "\n",
       "       [[ 4.88555593e-01, -6.52367141e-02,  9.93347638e-01,\n",
       "          1.15154114e-01, -7.14077929e-01],\n",
       "        [ 4.14467559e-01,  7.98555861e-02,  9.91791028e-01,\n",
       "         -1.27869293e-01, -8.77397333e-01],\n",
       "        [ 7.68246266e-02, -7.69388662e-03,  9.99527208e-01,\n",
       "         -3.07467225e-02, -2.56465037e+00],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00, -1.84206807e+01]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[344599:344699]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_dir + '/model_weights_{epoch:02d}_' + str(beta) + '.hdf5'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
